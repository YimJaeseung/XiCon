Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7786
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.343536615371704
Epoch: 1, Steps: 69 Train Loss: 1.9687 (Forecasting Loss:0.1324 + XiCon Loss:1.8363 x Lambda(1.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.285083).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 1.022773027420044
Epoch: 2, Steps: 69 Train Loss: 1.9409 (Forecasting Loss:0.1111 + XiCon Loss:1.8297 x Lambda(1.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1226
Validation loss decreased (0.285083 --> 0.213842).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.0456359386444092
Epoch: 3, Steps: 69 Train Loss: 1.9344 (Forecasting Loss:0.1023 + XiCon Loss:1.8321 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1203
Validation loss decreased (0.213842 --> 0.209150).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.037954330444336
Epoch: 4, Steps: 69 Train Loss: 1.9212 (Forecasting Loss:0.1006 + XiCon Loss:1.8206 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.1192
Validation loss decreased (0.209150 --> 0.207607).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 1.0232670307159424
Epoch: 5, Steps: 69 Train Loss: 1.9198 (Forecasting Loss:0.1000 + XiCon Loss:1.8199 x Lambda(1.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1187
Validation loss decreased (0.207607 --> 0.206741).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 1.0887041091918945
Epoch: 6, Steps: 69 Train Loss: 1.9145 (Forecasting Loss:0.0998 + XiCon Loss:1.8147 x Lambda(1.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1184
Validation loss decreased (0.206741 --> 0.206473).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.9994528293609619
Epoch: 7, Steps: 69 Train Loss: 1.9212 (Forecasting Loss:0.0996 + XiCon Loss:1.8216 x Lambda(1.0)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1182
Validation loss decreased (0.206473 --> 0.206287).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.055985927581787
Epoch: 8, Steps: 69 Train Loss: 1.9100 (Forecasting Loss:0.0996 + XiCon Loss:1.8104 x Lambda(1.0)), Vali MSE Loss: 0.2063 Test MSE Loss: 0.1181
Validation loss decreased (0.206287 --> 0.206261).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 1.0440165996551514
Epoch: 9, Steps: 69 Train Loss: 1.9087 (Forecasting Loss:0.0997 + XiCon Loss:1.8090 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1181
Validation loss decreased (0.206261 --> 0.206218).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.0994868278503418
Epoch: 10, Steps: 69 Train Loss: 1.9171 (Forecasting Loss:0.0997 + XiCon Loss:1.8175 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206218 --> 0.206197).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9815082550048828
Epoch: 11, Steps: 69 Train Loss: 1.9171 (Forecasting Loss:0.0996 + XiCon Loss:1.8175 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206197 --> 0.206189).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9919977188110352
Epoch: 12, Steps: 69 Train Loss: 1.9116 (Forecasting Loss:0.0993 + XiCon Loss:1.8123 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206189 --> 0.206183).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.0020158290863037
Epoch: 13, Steps: 69 Train Loss: 1.9151 (Forecasting Loss:0.0995 + XiCon Loss:1.8157 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206183 --> 0.206180).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 1.0742812156677246
Epoch: 14, Steps: 69 Train Loss: 1.9144 (Forecasting Loss:0.0996 + XiCon Loss:1.8148 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206180 --> 0.206179).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9527103900909424
Epoch: 15, Steps: 69 Train Loss: 1.9156 (Forecasting Loss:0.0996 + XiCon Loss:1.8160 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206179 --> 0.206178).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.982280969619751
Epoch: 16, Steps: 69 Train Loss: 1.9132 (Forecasting Loss:0.0995 + XiCon Loss:1.8137 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206178 --> 0.206178).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9750642776489258
Epoch: 17, Steps: 69 Train Loss: 1.9101 (Forecasting Loss:0.0995 + XiCon Loss:1.8106 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206178 --> 0.206177).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 1.0286648273468018
Epoch: 18, Steps: 69 Train Loss: 1.9120 (Forecasting Loss:0.0995 + XiCon Loss:1.8125 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9283428192138672
Epoch: 19, Steps: 69 Train Loss: 1.9114 (Forecasting Loss:0.0994 + XiCon Loss:1.8120 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 1.0375831127166748
Epoch: 20, Steps: 69 Train Loss: 1.9168 (Forecasting Loss:0.0998 + XiCon Loss:1.8171 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9997622966766357
Epoch: 21, Steps: 69 Train Loss: 1.9096 (Forecasting Loss:0.0996 + XiCon Loss:1.8100 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9493656158447266
Epoch: 22, Steps: 69 Train Loss: 1.9076 (Forecasting Loss:0.0996 + XiCon Loss:1.8080 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9150681495666504
Epoch: 23, Steps: 69 Train Loss: 1.9143 (Forecasting Loss:0.0997 + XiCon Loss:1.8146 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9519553184509277
Epoch: 24, Steps: 69 Train Loss: 1.9109 (Forecasting Loss:0.0992 + XiCon Loss:1.8117 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9261250495910645
Epoch: 25, Steps: 69 Train Loss: 1.9168 (Forecasting Loss:0.0995 + XiCon Loss:1.8173 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9052174091339111
Epoch: 26, Steps: 69 Train Loss: 1.9122 (Forecasting Loss:0.0994 + XiCon Loss:1.8129 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8873629570007324
Epoch: 27, Steps: 69 Train Loss: 1.9120 (Forecasting Loss:0.0996 + XiCon Loss:1.8124 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8908569812774658
Epoch: 28, Steps: 69 Train Loss: 1.9139 (Forecasting Loss:0.0995 + XiCon Loss:1.8144 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9444437026977539
Epoch: 29, Steps: 69 Train Loss: 1.9104 (Forecasting Loss:0.0995 + XiCon Loss:1.8109 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.9467353820800781
Epoch: 30, Steps: 69 Train Loss: 1.9113 (Forecasting Loss:0.0996 + XiCon Loss:1.8117 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9227292537689209
Epoch: 31, Steps: 69 Train Loss: 1.9104 (Forecasting Loss:0.0995 + XiCon Loss:1.8109 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9002516269683838
Epoch: 32, Steps: 69 Train Loss: 1.9127 (Forecasting Loss:0.0997 + XiCon Loss:1.8129 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9053699970245361
Epoch: 33, Steps: 69 Train Loss: 1.9107 (Forecasting Loss:0.0996 + XiCon Loss:1.8111 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9384841918945312
Epoch: 34, Steps: 69 Train Loss: 1.9114 (Forecasting Loss:0.0994 + XiCon Loss:1.8120 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.897071361541748
Epoch: 35, Steps: 69 Train Loss: 1.9139 (Forecasting Loss:0.0996 + XiCon Loss:1.8143 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8664028644561768
Epoch: 36, Steps: 69 Train Loss: 1.9082 (Forecasting Loss:0.0995 + XiCon Loss:1.8087 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8621025085449219
Epoch: 37, Steps: 69 Train Loss: 1.9143 (Forecasting Loss:0.0995 + XiCon Loss:1.8148 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.916109561920166
Epoch: 38, Steps: 69 Train Loss: 1.9131 (Forecasting Loss:0.0994 + XiCon Loss:1.8137 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.9018034934997559
Epoch: 39, Steps: 69 Train Loss: 1.9141 (Forecasting Loss:0.0996 + XiCon Loss:1.8145 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9190776348114014
Epoch: 40, Steps: 69 Train Loss: 1.9119 (Forecasting Loss:0.0994 + XiCon Loss:1.8124 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9501094818115234
Epoch: 41, Steps: 69 Train Loss: 1.9112 (Forecasting Loss:0.0996 + XiCon Loss:1.8115 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8534324169158936
Epoch: 42, Steps: 69 Train Loss: 1.9131 (Forecasting Loss:0.0992 + XiCon Loss:1.8139 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9148101806640625
Epoch: 43, Steps: 69 Train Loss: 1.9151 (Forecasting Loss:0.0997 + XiCon Loss:1.8154 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8776779174804688
Epoch: 44, Steps: 69 Train Loss: 1.9146 (Forecasting Loss:0.0996 + XiCon Loss:1.8150 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.9328963756561279
Epoch: 45, Steps: 69 Train Loss: 1.9104 (Forecasting Loss:0.0994 + XiCon Loss:1.8110 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.9512944221496582
Epoch: 46, Steps: 69 Train Loss: 1.9068 (Forecasting Loss:0.0996 + XiCon Loss:1.8072 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.9325499534606934
Epoch: 47, Steps: 69 Train Loss: 1.9117 (Forecasting Loss:0.0997 + XiCon Loss:1.8121 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8241374492645264
Epoch: 48, Steps: 69 Train Loss: 1.9170 (Forecasting Loss:0.0994 + XiCon Loss:1.8176 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
Validation loss decreased (0.206177 --> 0.206177).  Saving model ...
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8519573211669922
Epoch: 49, Steps: 69 Train Loss: 1.9112 (Forecasting Loss:0.0995 + XiCon Loss:1.8117 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8372023105621338
Epoch: 50, Steps: 69 Train Loss: 1.9106 (Forecasting Loss:0.0997 + XiCon Loss:1.8108 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.8866126537322998
Epoch: 51, Steps: 69 Train Loss: 1.9154 (Forecasting Loss:0.0996 + XiCon Loss:1.8158 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.9106225967407227
Epoch: 52, Steps: 69 Train Loss: 1.9137 (Forecasting Loss:0.0997 + XiCon Loss:1.8141 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8314304351806641
Epoch: 53, Steps: 69 Train Loss: 1.9104 (Forecasting Loss:0.0994 + XiCon Loss:1.8109 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8428237438201904
Epoch: 54, Steps: 69 Train Loss: 1.9103 (Forecasting Loss:0.0995 + XiCon Loss:1.8108 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.9446151256561279
Epoch: 55, Steps: 69 Train Loss: 1.9117 (Forecasting Loss:0.0997 + XiCon Loss:1.8121 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.9018809795379639
Epoch: 56, Steps: 69 Train Loss: 1.9116 (Forecasting Loss:0.0995 + XiCon Loss:1.8121 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.8756513595581055
Epoch: 57, Steps: 69 Train Loss: 1.9099 (Forecasting Loss:0.0994 + XiCon Loss:1.8105 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.8778839111328125
Epoch: 58, Steps: 69 Train Loss: 1.9075 (Forecasting Loss:0.0996 + XiCon Loss:1.8079 x Lambda(1.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1180
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05576079338788986, mae:0.18025174736976624, mape:0.12637776136398315, mspe:0.037637095898389816 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5650
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8293519020080566
Epoch: 1, Steps: 69 Train Loss: 1.9722 (Forecasting Loss:0.1374 + XiCon Loss:1.8348 x Lambda(1.0)), Vali MSE Loss: 0.2959 Test MSE Loss: 0.1516
Validation loss decreased (inf --> 0.295903).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8565921783447266
Epoch: 2, Steps: 69 Train Loss: 1.9471 (Forecasting Loss:0.1146 + XiCon Loss:1.8326 x Lambda(1.0)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1222
Validation loss decreased (0.295903 --> 0.215827).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8084957599639893
Epoch: 3, Steps: 69 Train Loss: 1.9361 (Forecasting Loss:0.1035 + XiCon Loss:1.8326 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1204
Validation loss decreased (0.215827 --> 0.210825).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8189277648925781
Epoch: 4, Steps: 69 Train Loss: 1.9223 (Forecasting Loss:0.1018 + XiCon Loss:1.8205 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1197
Validation loss decreased (0.210825 --> 0.209785).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8172867298126221
Epoch: 5, Steps: 69 Train Loss: 1.9257 (Forecasting Loss:0.1016 + XiCon Loss:1.8241 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1190
Validation loss decreased (0.209785 --> 0.209632).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7811048030853271
Epoch: 6, Steps: 69 Train Loss: 1.9216 (Forecasting Loss:0.1011 + XiCon Loss:1.8206 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8622334003448486
Epoch: 7, Steps: 69 Train Loss: 1.9221 (Forecasting Loss:0.1012 + XiCon Loss:1.8209 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1185
Validation loss decreased (0.209632 --> 0.209591).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.848041296005249
Epoch: 8, Steps: 69 Train Loss: 1.9246 (Forecasting Loss:0.1010 + XiCon Loss:1.8236 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209591 --> 0.209540).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.7839615345001221
Epoch: 9, Steps: 69 Train Loss: 1.9284 (Forecasting Loss:0.1010 + XiCon Loss:1.8273 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209540 --> 0.209519).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8173692226409912
Epoch: 10, Steps: 69 Train Loss: 1.9192 (Forecasting Loss:0.1011 + XiCon Loss:1.8181 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209519 --> 0.209502).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.7917978763580322
Epoch: 11, Steps: 69 Train Loss: 1.9307 (Forecasting Loss:0.1011 + XiCon Loss:1.8296 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209502 --> 0.209491).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.7939682006835938
Epoch: 12, Steps: 69 Train Loss: 1.9255 (Forecasting Loss:0.1009 + XiCon Loss:1.8245 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209491 --> 0.209485).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8259830474853516
Epoch: 13, Steps: 69 Train Loss: 1.9282 (Forecasting Loss:0.1008 + XiCon Loss:1.8275 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209485 --> 0.209482).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8088054656982422
Epoch: 14, Steps: 69 Train Loss: 1.9236 (Forecasting Loss:0.1011 + XiCon Loss:1.8225 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209482 --> 0.209480).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.88895583152771
Epoch: 15, Steps: 69 Train Loss: 1.9275 (Forecasting Loss:0.1011 + XiCon Loss:1.8265 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209480 --> 0.209479).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8405916690826416
Epoch: 16, Steps: 69 Train Loss: 1.9239 (Forecasting Loss:0.1013 + XiCon Loss:1.8226 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209479 --> 0.209479).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8481230735778809
Epoch: 17, Steps: 69 Train Loss: 1.9295 (Forecasting Loss:0.1012 + XiCon Loss:1.8283 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209479 --> 0.209478).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.7948412895202637
Epoch: 18, Steps: 69 Train Loss: 1.9257 (Forecasting Loss:0.1011 + XiCon Loss:1.8246 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8341493606567383
Epoch: 19, Steps: 69 Train Loss: 1.9267 (Forecasting Loss:0.1010 + XiCon Loss:1.8256 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.854694128036499
Epoch: 20, Steps: 69 Train Loss: 1.9288 (Forecasting Loss:0.1011 + XiCon Loss:1.8277 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8824653625488281
Epoch: 21, Steps: 69 Train Loss: 1.9266 (Forecasting Loss:0.1012 + XiCon Loss:1.8254 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8665390014648438
Epoch: 22, Steps: 69 Train Loss: 1.9279 (Forecasting Loss:0.1011 + XiCon Loss:1.8268 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8310353755950928
Epoch: 23, Steps: 69 Train Loss: 1.9217 (Forecasting Loss:0.1009 + XiCon Loss:1.8208 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.824016809463501
Epoch: 24, Steps: 69 Train Loss: 1.9231 (Forecasting Loss:0.1010 + XiCon Loss:1.8221 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.792515754699707
Epoch: 25, Steps: 69 Train Loss: 1.9280 (Forecasting Loss:0.1010 + XiCon Loss:1.8270 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.7914793491363525
Epoch: 26, Steps: 69 Train Loss: 1.9253 (Forecasting Loss:0.1012 + XiCon Loss:1.8241 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.7905805110931396
Epoch: 27, Steps: 69 Train Loss: 1.9270 (Forecasting Loss:0.1010 + XiCon Loss:1.8260 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.7958369255065918
Epoch: 28, Steps: 69 Train Loss: 1.9255 (Forecasting Loss:0.1012 + XiCon Loss:1.8244 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.7975664138793945
Epoch: 29, Steps: 69 Train Loss: 1.9313 (Forecasting Loss:0.1010 + XiCon Loss:1.8303 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.852658748626709
Epoch: 30, Steps: 69 Train Loss: 1.9298 (Forecasting Loss:0.1013 + XiCon Loss:1.8285 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.7874724864959717
Epoch: 31, Steps: 69 Train Loss: 1.9281 (Forecasting Loss:0.1012 + XiCon Loss:1.8269 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.925628662109375
Epoch: 32, Steps: 69 Train Loss: 1.9258 (Forecasting Loss:0.1009 + XiCon Loss:1.8249 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.793874979019165
Epoch: 33, Steps: 69 Train Loss: 1.9267 (Forecasting Loss:0.1012 + XiCon Loss:1.8255 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8491613864898682
Epoch: 34, Steps: 69 Train Loss: 1.9293 (Forecasting Loss:0.1010 + XiCon Loss:1.8283 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 1.0017921924591064
Epoch: 35, Steps: 69 Train Loss: 1.9251 (Forecasting Loss:0.1012 + XiCon Loss:1.8238 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.9127967357635498
Epoch: 36, Steps: 69 Train Loss: 1.9254 (Forecasting Loss:0.1011 + XiCon Loss:1.8244 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8643627166748047
Epoch: 37, Steps: 69 Train Loss: 1.9280 (Forecasting Loss:0.1011 + XiCon Loss:1.8269 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8542163372039795
Epoch: 38, Steps: 69 Train Loss: 1.9247 (Forecasting Loss:0.1010 + XiCon Loss:1.8237 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.849703311920166
Epoch: 39, Steps: 69 Train Loss: 1.9266 (Forecasting Loss:0.1010 + XiCon Loss:1.8256 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
Validation loss decreased (0.209478 --> 0.209478).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8869435787200928
Epoch: 40, Steps: 69 Train Loss: 1.9212 (Forecasting Loss:0.1012 + XiCon Loss:1.8200 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9365675449371338
Epoch: 41, Steps: 69 Train Loss: 1.9216 (Forecasting Loss:0.1010 + XiCon Loss:1.8205 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.843468189239502
Epoch: 42, Steps: 69 Train Loss: 1.9276 (Forecasting Loss:0.1011 + XiCon Loss:1.8265 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9011003971099854
Epoch: 43, Steps: 69 Train Loss: 1.9235 (Forecasting Loss:0.1011 + XiCon Loss:1.8224 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8896756172180176
Epoch: 44, Steps: 69 Train Loss: 1.9309 (Forecasting Loss:0.1010 + XiCon Loss:1.8300 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8373610973358154
Epoch: 45, Steps: 69 Train Loss: 1.9282 (Forecasting Loss:0.1012 + XiCon Loss:1.8271 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8343727588653564
Epoch: 46, Steps: 69 Train Loss: 1.9214 (Forecasting Loss:0.1012 + XiCon Loss:1.8201 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.890204668045044
Epoch: 47, Steps: 69 Train Loss: 1.9306 (Forecasting Loss:0.1011 + XiCon Loss:1.8295 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.925696849822998
Epoch: 48, Steps: 69 Train Loss: 1.9246 (Forecasting Loss:0.1012 + XiCon Loss:1.8234 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8337893486022949
Epoch: 49, Steps: 69 Train Loss: 1.9262 (Forecasting Loss:0.1009 + XiCon Loss:1.8252 x Lambda(1.0)), Vali MSE Loss: 0.2095 Test MSE Loss: 0.1184
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05580907315015793, mae:0.18089251220226288, mape:0.1262294054031372, mspe:0.03696836158633232 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5903
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9268903732299805
Epoch: 1, Steps: 69 Train Loss: 1.9686 (Forecasting Loss:0.1328 + XiCon Loss:1.8357 x Lambda(1.0)), Vali MSE Loss: 0.2857 Test MSE Loss: 0.1485
Validation loss decreased (inf --> 0.285720).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9184267520904541
Epoch: 2, Steps: 69 Train Loss: 1.9443 (Forecasting Loss:0.1115 + XiCon Loss:1.8329 x Lambda(1.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1227
Validation loss decreased (0.285720 --> 0.213781).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9483113288879395
Epoch: 3, Steps: 69 Train Loss: 1.9240 (Forecasting Loss:0.1031 + XiCon Loss:1.8209 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1185
Validation loss decreased (0.213781 --> 0.211365).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8486320972442627
Epoch: 4, Steps: 69 Train Loss: 1.9358 (Forecasting Loss:0.1018 + XiCon Loss:1.8340 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1171
Validation loss decreased (0.211365 --> 0.208743).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8370444774627686
Epoch: 5, Steps: 69 Train Loss: 1.9638 (Forecasting Loss:0.1009 + XiCon Loss:1.8629 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1173
Validation loss decreased (0.208743 --> 0.207528).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9299745559692383
Epoch: 6, Steps: 69 Train Loss: 1.9782 (Forecasting Loss:0.1004 + XiCon Loss:1.8777 x Lambda(1.0)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1173
Validation loss decreased (0.207528 --> 0.207240).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8670728206634521
Epoch: 7, Steps: 69 Train Loss: 1.9834 (Forecasting Loss:0.1007 + XiCon Loss:1.8827 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1172
Validation loss decreased (0.207240 --> 0.207053).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 1.2059845924377441
Epoch: 8, Steps: 69 Train Loss: 1.9761 (Forecasting Loss:0.1005 + XiCon Loss:1.8756 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1172
Validation loss decreased (0.207053 --> 0.206892).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8716127872467041
Epoch: 9, Steps: 69 Train Loss: 1.9687 (Forecasting Loss:0.1001 + XiCon Loss:1.8686 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206892 --> 0.206830).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8788161277770996
Epoch: 10, Steps: 69 Train Loss: 1.9798 (Forecasting Loss:0.1004 + XiCon Loss:1.8794 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206830 --> 0.206794).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8642542362213135
Epoch: 11, Steps: 69 Train Loss: 1.9817 (Forecasting Loss:0.1004 + XiCon Loss:1.8814 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206794 --> 0.206777).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8286640644073486
Epoch: 12, Steps: 69 Train Loss: 1.9810 (Forecasting Loss:0.1001 + XiCon Loss:1.8809 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206777 --> 0.206770).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9230225086212158
Epoch: 13, Steps: 69 Train Loss: 1.9824 (Forecasting Loss:0.1004 + XiCon Loss:1.8820 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206770 --> 0.206761).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9101974964141846
Epoch: 14, Steps: 69 Train Loss: 1.9839 (Forecasting Loss:0.1004 + XiCon Loss:1.8835 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206761 --> 0.206760).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8779499530792236
Epoch: 15, Steps: 69 Train Loss: 1.9761 (Forecasting Loss:0.1002 + XiCon Loss:1.8759 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206760 --> 0.206760).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8446590900421143
Epoch: 16, Steps: 69 Train Loss: 1.9811 (Forecasting Loss:0.1004 + XiCon Loss:1.8807 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206760 --> 0.206760).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8525404930114746
Epoch: 17, Steps: 69 Train Loss: 1.9738 (Forecasting Loss:0.1005 + XiCon Loss:1.8733 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206760 --> 0.206760).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9118402004241943
Epoch: 18, Steps: 69 Train Loss: 1.9769 (Forecasting Loss:0.1001 + XiCon Loss:1.8768 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206760 --> 0.206759).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8453748226165771
Epoch: 19, Steps: 69 Train Loss: 1.9798 (Forecasting Loss:0.1001 + XiCon Loss:1.8797 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8286221027374268
Epoch: 20, Steps: 69 Train Loss: 1.9798 (Forecasting Loss:0.1003 + XiCon Loss:1.8795 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8851847648620605
Epoch: 21, Steps: 69 Train Loss: 1.9823 (Forecasting Loss:0.1001 + XiCon Loss:1.8822 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9365663528442383
Epoch: 22, Steps: 69 Train Loss: 1.9780 (Forecasting Loss:0.1001 + XiCon Loss:1.8779 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8498601913452148
Epoch: 23, Steps: 69 Train Loss: 1.9787 (Forecasting Loss:0.1003 + XiCon Loss:1.8784 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9419741630554199
Epoch: 24, Steps: 69 Train Loss: 1.9814 (Forecasting Loss:0.1003 + XiCon Loss:1.8811 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9530677795410156
Epoch: 25, Steps: 69 Train Loss: 1.9780 (Forecasting Loss:0.1001 + XiCon Loss:1.8779 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9060826301574707
Epoch: 26, Steps: 69 Train Loss: 1.9781 (Forecasting Loss:0.1003 + XiCon Loss:1.8779 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8866109848022461
Epoch: 27, Steps: 69 Train Loss: 1.9896 (Forecasting Loss:0.0999 + XiCon Loss:1.8897 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.89792799949646
Epoch: 28, Steps: 69 Train Loss: 1.9814 (Forecasting Loss:0.1001 + XiCon Loss:1.8813 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8976352214813232
Epoch: 29, Steps: 69 Train Loss: 1.9818 (Forecasting Loss:0.1003 + XiCon Loss:1.8815 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8707013130187988
Epoch: 30, Steps: 69 Train Loss: 1.9823 (Forecasting Loss:0.1000 + XiCon Loss:1.8823 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8052976131439209
Epoch: 31, Steps: 69 Train Loss: 1.9777 (Forecasting Loss:0.1003 + XiCon Loss:1.8774 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8671247959136963
Epoch: 32, Steps: 69 Train Loss: 1.9755 (Forecasting Loss:0.1001 + XiCon Loss:1.8754 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
Validation loss decreased (0.206759 --> 0.206759).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 1.064208984375
Epoch: 33, Steps: 69 Train Loss: 1.9904 (Forecasting Loss:0.1003 + XiCon Loss:1.8901 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8000202178955078
Epoch: 34, Steps: 69 Train Loss: 1.9881 (Forecasting Loss:0.1003 + XiCon Loss:1.8878 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.9072854518890381
Epoch: 35, Steps: 69 Train Loss: 1.9835 (Forecasting Loss:0.1002 + XiCon Loss:1.8833 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8589811325073242
Epoch: 36, Steps: 69 Train Loss: 1.9704 (Forecasting Loss:0.0999 + XiCon Loss:1.8704 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9015800952911377
Epoch: 37, Steps: 69 Train Loss: 1.9894 (Forecasting Loss:0.1004 + XiCon Loss:1.8890 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8306214809417725
Epoch: 38, Steps: 69 Train Loss: 1.9801 (Forecasting Loss:0.1004 + XiCon Loss:1.8797 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8284413814544678
Epoch: 39, Steps: 69 Train Loss: 1.9850 (Forecasting Loss:0.1003 + XiCon Loss:1.8847 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9421548843383789
Epoch: 40, Steps: 69 Train Loss: 1.9780 (Forecasting Loss:0.1002 + XiCon Loss:1.8778 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8931853771209717
Epoch: 41, Steps: 69 Train Loss: 1.9782 (Forecasting Loss:0.1002 + XiCon Loss:1.8780 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8574926853179932
Epoch: 42, Steps: 69 Train Loss: 1.9855 (Forecasting Loss:0.1002 + XiCon Loss:1.8853 x Lambda(1.0)), Vali MSE Loss: 0.2068 Test MSE Loss: 0.1172
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05509046092629433, mae:0.17925673723220825, mape:0.12546811997890472, mspe:0.036956582218408585 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5880
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8264889717102051
Epoch: 1, Steps: 69 Train Loss: 1.9666 (Forecasting Loss:0.1341 + XiCon Loss:1.8325 x Lambda(1.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.1490
Validation loss decreased (inf --> 0.288523).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8586030006408691
Epoch: 2, Steps: 69 Train Loss: 1.9363 (Forecasting Loss:0.1117 + XiCon Loss:1.8246 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1222
Validation loss decreased (0.288523 --> 0.211369).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9147310256958008
Epoch: 3, Steps: 69 Train Loss: 1.9203 (Forecasting Loss:0.1020 + XiCon Loss:1.8182 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1188
Validation loss decreased (0.211369 --> 0.210437).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8603360652923584
Epoch: 4, Steps: 69 Train Loss: 1.9380 (Forecasting Loss:0.1013 + XiCon Loss:1.8367 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1186
Validation loss decreased (0.210437 --> 0.209634).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8332393169403076
Epoch: 5, Steps: 69 Train Loss: 1.9582 (Forecasting Loss:0.1009 + XiCon Loss:1.8573 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1180
Validation loss decreased (0.209634 --> 0.208922).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.778766393661499
Epoch: 6, Steps: 69 Train Loss: 1.9602 (Forecasting Loss:0.1010 + XiCon Loss:1.8593 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1178
Validation loss decreased (0.208922 --> 0.208623).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8825016021728516
Epoch: 7, Steps: 69 Train Loss: 1.9723 (Forecasting Loss:0.1007 + XiCon Loss:1.8715 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1177
Validation loss decreased (0.208623 --> 0.208505).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9583778381347656
Epoch: 8, Steps: 69 Train Loss: 1.9662 (Forecasting Loss:0.1009 + XiCon Loss:1.8652 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1176
Validation loss decreased (0.208505 --> 0.208412).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9082663059234619
Epoch: 9, Steps: 69 Train Loss: 1.9623 (Forecasting Loss:0.1008 + XiCon Loss:1.8615 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208412 --> 0.208337).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8172810077667236
Epoch: 10, Steps: 69 Train Loss: 1.9621 (Forecasting Loss:0.1005 + XiCon Loss:1.8616 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208337 --> 0.208303).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8672659397125244
Epoch: 11, Steps: 69 Train Loss: 1.9658 (Forecasting Loss:0.1007 + XiCon Loss:1.8652 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208303 --> 0.208284).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.932828426361084
Epoch: 12, Steps: 69 Train Loss: 1.9671 (Forecasting Loss:0.1005 + XiCon Loss:1.8665 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208284 --> 0.208271).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9273781776428223
Epoch: 13, Steps: 69 Train Loss: 1.9672 (Forecasting Loss:0.1006 + XiCon Loss:1.8665 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208271 --> 0.208267).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8356266021728516
Epoch: 14, Steps: 69 Train Loss: 1.9599 (Forecasting Loss:0.1006 + XiCon Loss:1.8593 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208267 --> 0.208264).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.7722897529602051
Epoch: 15, Steps: 69 Train Loss: 1.9699 (Forecasting Loss:0.1004 + XiCon Loss:1.8694 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208264 --> 0.208263).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9123940467834473
Epoch: 16, Steps: 69 Train Loss: 1.9739 (Forecasting Loss:0.1006 + XiCon Loss:1.8733 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208263 --> 0.208262).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.904653787612915
Epoch: 17, Steps: 69 Train Loss: 1.9638 (Forecasting Loss:0.1005 + XiCon Loss:1.8633 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8976352214813232
Epoch: 18, Steps: 69 Train Loss: 1.9600 (Forecasting Loss:0.1007 + XiCon Loss:1.8593 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.7940030097961426
Epoch: 19, Steps: 69 Train Loss: 1.9716 (Forecasting Loss:0.1005 + XiCon Loss:1.8712 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8711972236633301
Epoch: 20, Steps: 69 Train Loss: 1.9712 (Forecasting Loss:0.1006 + XiCon Loss:1.8706 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8814094066619873
Epoch: 21, Steps: 69 Train Loss: 1.9621 (Forecasting Loss:0.1006 + XiCon Loss:1.8615 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9391777515411377
Epoch: 22, Steps: 69 Train Loss: 1.9682 (Forecasting Loss:0.1007 + XiCon Loss:1.8675 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8520171642303467
Epoch: 23, Steps: 69 Train Loss: 1.9715 (Forecasting Loss:0.1008 + XiCon Loss:1.8707 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.7800004482269287
Epoch: 24, Steps: 69 Train Loss: 1.9682 (Forecasting Loss:0.1005 + XiCon Loss:1.8677 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.921137809753418
Epoch: 25, Steps: 69 Train Loss: 1.9713 (Forecasting Loss:0.1005 + XiCon Loss:1.8708 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9783935546875
Epoch: 26, Steps: 69 Train Loss: 1.9654 (Forecasting Loss:0.1005 + XiCon Loss:1.8649 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8392055034637451
Epoch: 27, Steps: 69 Train Loss: 1.9694 (Forecasting Loss:0.1006 + XiCon Loss:1.8688 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9389925003051758
Epoch: 28, Steps: 69 Train Loss: 1.9717 (Forecasting Loss:0.1006 + XiCon Loss:1.8712 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9341979026794434
Epoch: 29, Steps: 69 Train Loss: 1.9654 (Forecasting Loss:0.1005 + XiCon Loss:1.8649 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.944399356842041
Epoch: 30, Steps: 69 Train Loss: 1.9718 (Forecasting Loss:0.1006 + XiCon Loss:1.8712 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8230299949645996
Epoch: 31, Steps: 69 Train Loss: 1.9622 (Forecasting Loss:0.1007 + XiCon Loss:1.8615 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8129105567932129
Epoch: 32, Steps: 69 Train Loss: 1.9646 (Forecasting Loss:0.1006 + XiCon Loss:1.8640 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9087321758270264
Epoch: 33, Steps: 69 Train Loss: 1.9705 (Forecasting Loss:0.1004 + XiCon Loss:1.8702 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9870567321777344
Epoch: 34, Steps: 69 Train Loss: 1.9643 (Forecasting Loss:0.1005 + XiCon Loss:1.8638 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8066902160644531
Epoch: 35, Steps: 69 Train Loss: 1.9633 (Forecasting Loss:0.1004 + XiCon Loss:1.8629 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.7968344688415527
Epoch: 36, Steps: 69 Train Loss: 1.9666 (Forecasting Loss:0.1006 + XiCon Loss:1.8660 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8761651515960693
Epoch: 37, Steps: 69 Train Loss: 1.9754 (Forecasting Loss:0.1006 + XiCon Loss:1.8748 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
Validation loss decreased (0.208262 --> 0.208262).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8783998489379883
Epoch: 38, Steps: 69 Train Loss: 1.9639 (Forecasting Loss:0.1003 + XiCon Loss:1.8636 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8926870822906494
Epoch: 39, Steps: 69 Train Loss: 1.9701 (Forecasting Loss:0.1006 + XiCon Loss:1.8695 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.7925577163696289
Epoch: 40, Steps: 69 Train Loss: 1.9725 (Forecasting Loss:0.1005 + XiCon Loss:1.8720 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8709805011749268
Epoch: 41, Steps: 69 Train Loss: 1.9666 (Forecasting Loss:0.1004 + XiCon Loss:1.8662 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8964767456054688
Epoch: 42, Steps: 69 Train Loss: 1.9627 (Forecasting Loss:0.1007 + XiCon Loss:1.8620 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8667418956756592
Epoch: 43, Steps: 69 Train Loss: 1.9743 (Forecasting Loss:0.1005 + XiCon Loss:1.8738 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.7864716053009033
Epoch: 44, Steps: 69 Train Loss: 1.9639 (Forecasting Loss:0.1006 + XiCon Loss:1.8634 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8861398696899414
Epoch: 45, Steps: 69 Train Loss: 1.9656 (Forecasting Loss:0.1003 + XiCon Loss:1.8654 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.9305994510650635
Epoch: 46, Steps: 69 Train Loss: 1.9678 (Forecasting Loss:0.1006 + XiCon Loss:1.8672 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.9418196678161621
Epoch: 47, Steps: 69 Train Loss: 1.9695 (Forecasting Loss:0.1006 + XiCon Loss:1.8689 x Lambda(1.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1176
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055372025817632675, mae:0.17974840104579926, mape:0.12574239075183868, mspe:0.03708471730351448 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5843
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8343212604522705
Epoch: 1, Steps: 69 Train Loss: 1.9703 (Forecasting Loss:0.1348 + XiCon Loss:1.8355 x Lambda(1.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.1528
Validation loss decreased (inf --> 0.291071).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.7924191951751709
Epoch: 2, Steps: 69 Train Loss: 1.9450 (Forecasting Loss:0.1128 + XiCon Loss:1.8322 x Lambda(1.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1207
Validation loss decreased (0.291071 --> 0.214302).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9595563411712646
Epoch: 3, Steps: 69 Train Loss: 1.9300 (Forecasting Loss:0.1025 + XiCon Loss:1.8275 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1185
Validation loss decreased (0.214302 --> 0.209423).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9021401405334473
Epoch: 4, Steps: 69 Train Loss: 1.9168 (Forecasting Loss:0.1010 + XiCon Loss:1.8158 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1182
Validation loss decreased (0.209423 --> 0.209117).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.892552375793457
Epoch: 5, Steps: 69 Train Loss: 1.9255 (Forecasting Loss:0.1012 + XiCon Loss:1.8243 x Lambda(1.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1184
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.845435380935669
Epoch: 6, Steps: 69 Train Loss: 1.9320 (Forecasting Loss:0.1011 + XiCon Loss:1.8310 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1183
Validation loss decreased (0.209117 --> 0.209100).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8453865051269531
Epoch: 7, Steps: 69 Train Loss: 1.9357 (Forecasting Loss:0.1010 + XiCon Loss:1.8347 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1182
Validation loss decreased (0.209100 --> 0.208947).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8854610919952393
Epoch: 8, Steps: 69 Train Loss: 1.9442 (Forecasting Loss:0.1009 + XiCon Loss:1.8433 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1181
Validation loss decreased (0.208947 --> 0.208879).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.898402214050293
Epoch: 9, Steps: 69 Train Loss: 1.9387 (Forecasting Loss:0.1009 + XiCon Loss:1.8378 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208879 --> 0.208825).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8533804416656494
Epoch: 10, Steps: 69 Train Loss: 1.9383 (Forecasting Loss:0.1010 + XiCon Loss:1.8373 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208825 --> 0.208793).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8002140522003174
Epoch: 11, Steps: 69 Train Loss: 1.9254 (Forecasting Loss:0.1010 + XiCon Loss:1.8243 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208793 --> 0.208789).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8930294513702393
Epoch: 12, Steps: 69 Train Loss: 1.9350 (Forecasting Loss:0.1009 + XiCon Loss:1.8341 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208789 --> 0.208783).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.0072660446166992
Epoch: 13, Steps: 69 Train Loss: 1.9258 (Forecasting Loss:0.1009 + XiCon Loss:1.8249 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208783 --> 0.208780).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8364484310150146
Epoch: 14, Steps: 69 Train Loss: 1.9330 (Forecasting Loss:0.1008 + XiCon Loss:1.8322 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208780 --> 0.208778).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.834850549697876
Epoch: 15, Steps: 69 Train Loss: 1.9328 (Forecasting Loss:0.1007 + XiCon Loss:1.8322 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208778 --> 0.208777).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9164230823516846
Epoch: 16, Steps: 69 Train Loss: 1.9363 (Forecasting Loss:0.1009 + XiCon Loss:1.8354 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208777 --> 0.208776).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9133789539337158
Epoch: 17, Steps: 69 Train Loss: 1.9388 (Forecasting Loss:0.1009 + XiCon Loss:1.8379 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.850170373916626
Epoch: 18, Steps: 69 Train Loss: 1.9367 (Forecasting Loss:0.1009 + XiCon Loss:1.8358 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8250668048858643
Epoch: 19, Steps: 69 Train Loss: 1.9363 (Forecasting Loss:0.1008 + XiCon Loss:1.8355 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9533519744873047
Epoch: 20, Steps: 69 Train Loss: 1.9345 (Forecasting Loss:0.1010 + XiCon Loss:1.8335 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9828476905822754
Epoch: 21, Steps: 69 Train Loss: 1.9357 (Forecasting Loss:0.1009 + XiCon Loss:1.8348 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8112239837646484
Epoch: 22, Steps: 69 Train Loss: 1.9341 (Forecasting Loss:0.1009 + XiCon Loss:1.8332 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8054065704345703
Epoch: 23, Steps: 69 Train Loss: 1.9341 (Forecasting Loss:0.1009 + XiCon Loss:1.8333 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9374041557312012
Epoch: 24, Steps: 69 Train Loss: 1.9332 (Forecasting Loss:0.1009 + XiCon Loss:1.8324 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8672182559967041
Epoch: 25, Steps: 69 Train Loss: 1.9379 (Forecasting Loss:0.1008 + XiCon Loss:1.8370 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8699522018432617
Epoch: 26, Steps: 69 Train Loss: 1.9438 (Forecasting Loss:0.1008 + XiCon Loss:1.8430 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8271393775939941
Epoch: 27, Steps: 69 Train Loss: 1.9341 (Forecasting Loss:0.1007 + XiCon Loss:1.8333 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9471614360809326
Epoch: 28, Steps: 69 Train Loss: 1.9351 (Forecasting Loss:0.1008 + XiCon Loss:1.8343 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8836724758148193
Epoch: 29, Steps: 69 Train Loss: 1.9365 (Forecasting Loss:0.1006 + XiCon Loss:1.8359 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.79093337059021
Epoch: 30, Steps: 69 Train Loss: 1.9407 (Forecasting Loss:0.1008 + XiCon Loss:1.8399 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8045141696929932
Epoch: 31, Steps: 69 Train Loss: 1.9352 (Forecasting Loss:0.1009 + XiCon Loss:1.8343 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9337413311004639
Epoch: 32, Steps: 69 Train Loss: 1.9324 (Forecasting Loss:0.1009 + XiCon Loss:1.8315 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8920204639434814
Epoch: 33, Steps: 69 Train Loss: 1.9440 (Forecasting Loss:0.1009 + XiCon Loss:1.8431 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8589940071105957
Epoch: 34, Steps: 69 Train Loss: 1.9333 (Forecasting Loss:0.1007 + XiCon Loss:1.8326 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8308300971984863
Epoch: 35, Steps: 69 Train Loss: 1.9339 (Forecasting Loss:0.1008 + XiCon Loss:1.8331 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.9416601657867432
Epoch: 36, Steps: 69 Train Loss: 1.9356 (Forecasting Loss:0.1009 + XiCon Loss:1.8347 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9436459541320801
Epoch: 37, Steps: 69 Train Loss: 1.9324 (Forecasting Loss:0.1006 + XiCon Loss:1.8318 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8335587978363037
Epoch: 38, Steps: 69 Train Loss: 1.9324 (Forecasting Loss:0.1008 + XiCon Loss:1.8316 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8251490592956543
Epoch: 39, Steps: 69 Train Loss: 1.9403 (Forecasting Loss:0.1010 + XiCon Loss:1.8393 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
Validation loss decreased (0.208776 --> 0.208776).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9009220600128174
Epoch: 40, Steps: 69 Train Loss: 1.9372 (Forecasting Loss:0.1010 + XiCon Loss:1.8362 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9255752563476562
Epoch: 41, Steps: 69 Train Loss: 1.9432 (Forecasting Loss:0.1006 + XiCon Loss:1.8426 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8558528423309326
Epoch: 42, Steps: 69 Train Loss: 1.9449 (Forecasting Loss:0.1010 + XiCon Loss:1.8439 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.835841178894043
Epoch: 43, Steps: 69 Train Loss: 1.9346 (Forecasting Loss:0.1010 + XiCon Loss:1.8336 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8234481811523438
Epoch: 44, Steps: 69 Train Loss: 1.9327 (Forecasting Loss:0.1007 + XiCon Loss:1.8321 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.885857343673706
Epoch: 45, Steps: 69 Train Loss: 1.9411 (Forecasting Loss:0.1006 + XiCon Loss:1.8404 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8946316242218018
Epoch: 46, Steps: 69 Train Loss: 1.9323 (Forecasting Loss:0.1008 + XiCon Loss:1.8316 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8970310688018799
Epoch: 47, Steps: 69 Train Loss: 1.9406 (Forecasting Loss:0.1008 + XiCon Loss:1.8398 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8651485443115234
Epoch: 48, Steps: 69 Train Loss: 1.9393 (Forecasting Loss:0.1008 + XiCon Loss:1.8386 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.901761531829834
Epoch: 49, Steps: 69 Train Loss: 1.9292 (Forecasting Loss:0.1009 + XiCon Loss:1.8283 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055655837059020996, mae:0.18048815429210663, mape:0.12592913210391998, mspe:0.036812711507081985 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0555+-0.00037, MAE:0.1801+-0.00079, MAPE:0.1259+-0.00045, MSPE:0.0371+-0.00040, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6676
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.2533633708953857
Epoch: 1, Steps: 64 Train Loss: 2.4439 (Forecasting Loss:0.5016 + XiCon Loss:1.9424 x Lambda(1.0)), Vali MSE Loss: 0.9639 Test MSE Loss: 0.5135
Validation loss decreased (inf --> 0.963853).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9466817378997803
Epoch: 2, Steps: 64 Train Loss: 2.4386 (Forecasting Loss:0.4974 + XiCon Loss:1.9413 x Lambda(1.0)), Vali MSE Loss: 0.9529 Test MSE Loss: 0.5067
Validation loss decreased (0.963853 --> 0.952920).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.0039045810699463
Epoch: 3, Steps: 64 Train Loss: 2.4319 (Forecasting Loss:0.4909 + XiCon Loss:1.9411 x Lambda(1.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.5041
Validation loss decreased (0.952920 --> 0.942570).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8892917633056641
Epoch: 4, Steps: 64 Train Loss: 2.4275 (Forecasting Loss:0.4890 + XiCon Loss:1.9386 x Lambda(1.0)), Vali MSE Loss: 0.9451 Test MSE Loss: 0.5029
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9118931293487549
Epoch: 5, Steps: 64 Train Loss: 2.4261 (Forecasting Loss:0.4864 + XiCon Loss:1.9397 x Lambda(1.0)), Vali MSE Loss: 0.9387 Test MSE Loss: 0.5023
Validation loss decreased (0.942570 --> 0.938705).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9578907489776611
Epoch: 6, Steps: 64 Train Loss: 2.4256 (Forecasting Loss:0.4857 + XiCon Loss:1.9399 x Lambda(1.0)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9516620635986328
Epoch: 7, Steps: 64 Train Loss: 2.4256 (Forecasting Loss:0.4858 + XiCon Loss:1.9398 x Lambda(1.0)), Vali MSE Loss: 0.9369 Test MSE Loss: 0.5018
Validation loss decreased (0.938705 --> 0.936921).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8855957984924316
Epoch: 8, Steps: 64 Train Loss: 2.4267 (Forecasting Loss:0.4855 + XiCon Loss:1.9412 x Lambda(1.0)), Vali MSE Loss: 0.9367 Test MSE Loss: 0.5017
Validation loss decreased (0.936921 --> 0.936703).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9252235889434814
Epoch: 9, Steps: 64 Train Loss: 2.4250 (Forecasting Loss:0.4848 + XiCon Loss:1.9402 x Lambda(1.0)), Vali MSE Loss: 0.9376 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9430422782897949
Epoch: 10, Steps: 64 Train Loss: 2.4239 (Forecasting Loss:0.4843 + XiCon Loss:1.9396 x Lambda(1.0)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9082381725311279
Epoch: 11, Steps: 64 Train Loss: 2.4244 (Forecasting Loss:0.4856 + XiCon Loss:1.9388 x Lambda(1.0)), Vali MSE Loss: 0.9384 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.950786828994751
Epoch: 12, Steps: 64 Train Loss: 2.4277 (Forecasting Loss:0.4851 + XiCon Loss:1.9425 x Lambda(1.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9627621173858643
Epoch: 13, Steps: 64 Train Loss: 2.4240 (Forecasting Loss:0.4854 + XiCon Loss:1.9386 x Lambda(1.0)), Vali MSE Loss: 0.9396 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9681921005249023
Epoch: 14, Steps: 64 Train Loss: 2.4244 (Forecasting Loss:0.4847 + XiCon Loss:1.9398 x Lambda(1.0)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8991062641143799
Epoch: 15, Steps: 64 Train Loss: 2.4242 (Forecasting Loss:0.4858 + XiCon Loss:1.9384 x Lambda(1.0)), Vali MSE Loss: 0.9418 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9950597286224365
Epoch: 16, Steps: 64 Train Loss: 2.4230 (Forecasting Loss:0.4849 + XiCon Loss:1.9381 x Lambda(1.0)), Vali MSE Loss: 0.9382 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9779541492462158
Epoch: 17, Steps: 64 Train Loss: 2.4260 (Forecasting Loss:0.4858 + XiCon Loss:1.9402 x Lambda(1.0)), Vali MSE Loss: 0.9357 Test MSE Loss: 0.5017
Validation loss decreased (0.936703 --> 0.935708).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.941906213760376
Epoch: 18, Steps: 64 Train Loss: 2.4250 (Forecasting Loss:0.4857 + XiCon Loss:1.9394 x Lambda(1.0)), Vali MSE Loss: 0.9374 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9885478019714355
Epoch: 19, Steps: 64 Train Loss: 2.4253 (Forecasting Loss:0.4856 + XiCon Loss:1.9397 x Lambda(1.0)), Vali MSE Loss: 0.9390 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8659384250640869
Epoch: 20, Steps: 64 Train Loss: 2.4235 (Forecasting Loss:0.4852 + XiCon Loss:1.9384 x Lambda(1.0)), Vali MSE Loss: 0.9392 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9186668395996094
Epoch: 21, Steps: 64 Train Loss: 2.4249 (Forecasting Loss:0.4846 + XiCon Loss:1.9403 x Lambda(1.0)), Vali MSE Loss: 0.9366 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9145169258117676
Epoch: 22, Steps: 64 Train Loss: 2.4266 (Forecasting Loss:0.4847 + XiCon Loss:1.9420 x Lambda(1.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 1.0157761573791504
Epoch: 23, Steps: 64 Train Loss: 2.4242 (Forecasting Loss:0.4845 + XiCon Loss:1.9397 x Lambda(1.0)), Vali MSE Loss: 0.9372 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9052739143371582
Epoch: 24, Steps: 64 Train Loss: 2.4237 (Forecasting Loss:0.4857 + XiCon Loss:1.9381 x Lambda(1.0)), Vali MSE Loss: 0.9393 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9818503856658936
Epoch: 25, Steps: 64 Train Loss: 2.4247 (Forecasting Loss:0.4846 + XiCon Loss:1.9402 x Lambda(1.0)), Vali MSE Loss: 0.9401 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8934242725372314
Epoch: 26, Steps: 64 Train Loss: 2.4258 (Forecasting Loss:0.4845 + XiCon Loss:1.9413 x Lambda(1.0)), Vali MSE Loss: 0.9379 Test MSE Loss: 0.5017
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8768184185028076
Epoch: 27, Steps: 64 Train Loss: 2.4243 (Forecasting Loss:0.4851 + XiCon Loss:1.9392 x Lambda(1.0)), Vali MSE Loss: 0.9398 Test MSE Loss: 0.5017
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4701157510280609, mae:0.5332261919975281, mape:0.44955143332481384, mspe:0.5998883843421936 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5522
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9047820568084717
Epoch: 1, Steps: 64 Train Loss: 2.4313 (Forecasting Loss:0.4928 + XiCon Loss:1.9385 x Lambda(1.0)), Vali MSE Loss: 0.9330 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932955).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.8541796207427979
Epoch: 2, Steps: 64 Train Loss: 2.4277 (Forecasting Loss:0.4901 + XiCon Loss:1.9376 x Lambda(1.0)), Vali MSE Loss: 0.9151 Test MSE Loss: 0.5154
Validation loss decreased (0.932955 --> 0.915080).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8624579906463623
Epoch: 3, Steps: 64 Train Loss: 2.4215 (Forecasting Loss:0.4837 + XiCon Loss:1.9378 x Lambda(1.0)), Vali MSE Loss: 0.9127 Test MSE Loss: 0.5130
Validation loss decreased (0.915080 --> 0.912747).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9007704257965088
Epoch: 4, Steps: 64 Train Loss: 2.4207 (Forecasting Loss:0.4808 + XiCon Loss:1.9399 x Lambda(1.0)), Vali MSE Loss: 0.9096 Test MSE Loss: 0.5118
Validation loss decreased (0.912747 --> 0.909645).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.8684201240539551
Epoch: 5, Steps: 64 Train Loss: 2.4192 (Forecasting Loss:0.4797 + XiCon Loss:1.9395 x Lambda(1.0)), Vali MSE Loss: 0.9071 Test MSE Loss: 0.5113
Validation loss decreased (0.909645 --> 0.907077).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9047806262969971
Epoch: 6, Steps: 64 Train Loss: 2.4166 (Forecasting Loss:0.4799 + XiCon Loss:1.9368 x Lambda(1.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5110
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8643078804016113
Epoch: 7, Steps: 64 Train Loss: 2.4158 (Forecasting Loss:0.4789 + XiCon Loss:1.9369 x Lambda(1.0)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5109
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8607039451599121
Epoch: 8, Steps: 64 Train Loss: 2.4162 (Forecasting Loss:0.4784 + XiCon Loss:1.9378 x Lambda(1.0)), Vali MSE Loss: 0.9073 Test MSE Loss: 0.5108
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.895052433013916
Epoch: 9, Steps: 64 Train Loss: 2.4182 (Forecasting Loss:0.4793 + XiCon Loss:1.9389 x Lambda(1.0)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5108
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8538038730621338
Epoch: 10, Steps: 64 Train Loss: 2.4189 (Forecasting Loss:0.4788 + XiCon Loss:1.9401 x Lambda(1.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9147183895111084
Epoch: 11, Steps: 64 Train Loss: 2.4168 (Forecasting Loss:0.4778 + XiCon Loss:1.9391 x Lambda(1.0)), Vali MSE Loss: 0.9084 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9431014060974121
Epoch: 12, Steps: 64 Train Loss: 2.4156 (Forecasting Loss:0.4791 + XiCon Loss:1.9365 x Lambda(1.0)), Vali MSE Loss: 0.9063 Test MSE Loss: 0.5107
Validation loss decreased (0.907077 --> 0.906345).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8430371284484863
Epoch: 13, Steps: 64 Train Loss: 2.4154 (Forecasting Loss:0.4778 + XiCon Loss:1.9376 x Lambda(1.0)), Vali MSE Loss: 0.9061 Test MSE Loss: 0.5107
Validation loss decreased (0.906345 --> 0.906127).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8604617118835449
Epoch: 14, Steps: 64 Train Loss: 2.4167 (Forecasting Loss:0.4780 + XiCon Loss:1.9388 x Lambda(1.0)), Vali MSE Loss: 0.9093 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8505122661590576
Epoch: 15, Steps: 64 Train Loss: 2.4166 (Forecasting Loss:0.4800 + XiCon Loss:1.9366 x Lambda(1.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.8663558959960938
Epoch: 16, Steps: 64 Train Loss: 2.4163 (Forecasting Loss:0.4789 + XiCon Loss:1.9374 x Lambda(1.0)), Vali MSE Loss: 0.9061 Test MSE Loss: 0.5107
Validation loss decreased (0.906127 --> 0.906100).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8490040302276611
Epoch: 17, Steps: 64 Train Loss: 2.4168 (Forecasting Loss:0.4784 + XiCon Loss:1.9384 x Lambda(1.0)), Vali MSE Loss: 0.9034 Test MSE Loss: 0.5107
Validation loss decreased (0.906100 --> 0.903406).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.0699396133422852
Epoch: 18, Steps: 64 Train Loss: 2.4173 (Forecasting Loss:0.4780 + XiCon Loss:1.9393 x Lambda(1.0)), Vali MSE Loss: 0.9085 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9151806831359863
Epoch: 19, Steps: 64 Train Loss: 2.4169 (Forecasting Loss:0.4789 + XiCon Loss:1.9380 x Lambda(1.0)), Vali MSE Loss: 0.9041 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8613641262054443
Epoch: 20, Steps: 64 Train Loss: 2.4154 (Forecasting Loss:0.4784 + XiCon Loss:1.9371 x Lambda(1.0)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.8856678009033203
Epoch: 21, Steps: 64 Train Loss: 2.4167 (Forecasting Loss:0.4780 + XiCon Loss:1.9387 x Lambda(1.0)), Vali MSE Loss: 0.9075 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.8783183097839355
Epoch: 22, Steps: 64 Train Loss: 2.4157 (Forecasting Loss:0.4784 + XiCon Loss:1.9373 x Lambda(1.0)), Vali MSE Loss: 0.9011 Test MSE Loss: 0.5107
Validation loss decreased (0.903406 --> 0.901112).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8702654838562012
Epoch: 23, Steps: 64 Train Loss: 2.4162 (Forecasting Loss:0.4780 + XiCon Loss:1.9382 x Lambda(1.0)), Vali MSE Loss: 0.9052 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8513238430023193
Epoch: 24, Steps: 64 Train Loss: 2.4162 (Forecasting Loss:0.4785 + XiCon Loss:1.9377 x Lambda(1.0)), Vali MSE Loss: 0.9063 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.8702149391174316
Epoch: 25, Steps: 64 Train Loss: 2.4156 (Forecasting Loss:0.4777 + XiCon Loss:1.9379 x Lambda(1.0)), Vali MSE Loss: 0.9027 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8838539123535156
Epoch: 26, Steps: 64 Train Loss: 2.4177 (Forecasting Loss:0.4797 + XiCon Loss:1.9379 x Lambda(1.0)), Vali MSE Loss: 0.9049 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8565447330474854
Epoch: 27, Steps: 64 Train Loss: 2.4170 (Forecasting Loss:0.4790 + XiCon Loss:1.9380 x Lambda(1.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.8576383590698242
Epoch: 28, Steps: 64 Train Loss: 2.4158 (Forecasting Loss:0.4781 + XiCon Loss:1.9376 x Lambda(1.0)), Vali MSE Loss: 0.9073 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 0.8587632179260254
Epoch: 29, Steps: 64 Train Loss: 2.4169 (Forecasting Loss:0.4786 + XiCon Loss:1.9384 x Lambda(1.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5107
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 0.8703131675720215
Epoch: 30, Steps: 64 Train Loss: 2.4155 (Forecasting Loss:0.4778 + XiCon Loss:1.9377 x Lambda(1.0)), Vali MSE Loss: 0.9103 Test MSE Loss: 0.5107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 0.848090648651123
Epoch: 31, Steps: 64 Train Loss: 2.4180 (Forecasting Loss:0.4793 + XiCon Loss:1.9387 x Lambda(1.0)), Vali MSE Loss: 0.9041 Test MSE Loss: 0.5107
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 0.8402450084686279
Epoch: 32, Steps: 64 Train Loss: 2.4158 (Forecasting Loss:0.4787 + XiCon Loss:1.9372 x Lambda(1.0)), Vali MSE Loss: 0.9078 Test MSE Loss: 0.5107
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4846416413784027, mae:0.5368142127990723, mape:0.45702168345451355, mspe:0.6300063729286194 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5630
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.8461341857910156
Epoch: 1, Steps: 64 Train Loss: 2.4421 (Forecasting Loss:0.5013 + XiCon Loss:1.9408 x Lambda(1.0)), Vali MSE Loss: 0.9739 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973865).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.8988628387451172
Epoch: 2, Steps: 64 Train Loss: 2.4422 (Forecasting Loss:0.4983 + XiCon Loss:1.9440 x Lambda(1.0)), Vali MSE Loss: 0.9576 Test MSE Loss: 0.5002
Validation loss decreased (0.973865 --> 0.957610).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8519935607910156
Epoch: 3, Steps: 64 Train Loss: 2.4315 (Forecasting Loss:0.4914 + XiCon Loss:1.9401 x Lambda(1.0)), Vali MSE Loss: 0.9523 Test MSE Loss: 0.4982
Validation loss decreased (0.957610 --> 0.952272).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8853399753570557
Epoch: 4, Steps: 64 Train Loss: 2.4322 (Forecasting Loss:0.4902 + XiCon Loss:1.9421 x Lambda(1.0)), Vali MSE Loss: 0.9502 Test MSE Loss: 0.4973
Validation loss decreased (0.952272 --> 0.950216).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.851872444152832
Epoch: 5, Steps: 64 Train Loss: 2.4279 (Forecasting Loss:0.4876 + XiCon Loss:1.9403 x Lambda(1.0)), Vali MSE Loss: 0.9466 Test MSE Loss: 0.4969
Validation loss decreased (0.950216 --> 0.946555).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9136908054351807
Epoch: 6, Steps: 64 Train Loss: 2.4280 (Forecasting Loss:0.4875 + XiCon Loss:1.9405 x Lambda(1.0)), Vali MSE Loss: 0.9495 Test MSE Loss: 0.4968
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8824758529663086
Epoch: 7, Steps: 64 Train Loss: 2.4271 (Forecasting Loss:0.4861 + XiCon Loss:1.9410 x Lambda(1.0)), Vali MSE Loss: 0.9431 Test MSE Loss: 0.4967
Validation loss decreased (0.946555 --> 0.943060).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9823682308197021
Epoch: 8, Steps: 64 Train Loss: 2.4270 (Forecasting Loss:0.4870 + XiCon Loss:1.9400 x Lambda(1.0)), Vali MSE Loss: 0.9452 Test MSE Loss: 0.4966
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9800066947937012
Epoch: 9, Steps: 64 Train Loss: 2.4274 (Forecasting Loss:0.4857 + XiCon Loss:1.9417 x Lambda(1.0)), Vali MSE Loss: 0.9493 Test MSE Loss: 0.4966
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9696106910705566
Epoch: 10, Steps: 64 Train Loss: 2.4250 (Forecasting Loss:0.4856 + XiCon Loss:1.9394 x Lambda(1.0)), Vali MSE Loss: 0.9416 Test MSE Loss: 0.4966
Validation loss decreased (0.943060 --> 0.941620).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.847327470779419
Epoch: 11, Steps: 64 Train Loss: 2.4274 (Forecasting Loss:0.4862 + XiCon Loss:1.9411 x Lambda(1.0)), Vali MSE Loss: 0.9430 Test MSE Loss: 0.4966
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.95570969581604
Epoch: 12, Steps: 64 Train Loss: 2.4301 (Forecasting Loss:0.4869 + XiCon Loss:1.9433 x Lambda(1.0)), Vali MSE Loss: 0.9497 Test MSE Loss: 0.4966
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9425747394561768
Epoch: 13, Steps: 64 Train Loss: 2.4256 (Forecasting Loss:0.4868 + XiCon Loss:1.9388 x Lambda(1.0)), Vali MSE Loss: 0.9458 Test MSE Loss: 0.4966
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9655447006225586
Epoch: 14, Steps: 64 Train Loss: 2.4294 (Forecasting Loss:0.4865 + XiCon Loss:1.9429 x Lambda(1.0)), Vali MSE Loss: 0.9439 Test MSE Loss: 0.4966
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8510823249816895
Epoch: 15, Steps: 64 Train Loss: 2.4289 (Forecasting Loss:0.4859 + XiCon Loss:1.9430 x Lambda(1.0)), Vali MSE Loss: 0.9456 Test MSE Loss: 0.4966
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.8821060657501221
Epoch: 16, Steps: 64 Train Loss: 2.4282 (Forecasting Loss:0.4867 + XiCon Loss:1.9414 x Lambda(1.0)), Vali MSE Loss: 0.9476 Test MSE Loss: 0.4966
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9464342594146729
Epoch: 17, Steps: 64 Train Loss: 2.4277 (Forecasting Loss:0.4871 + XiCon Loss:1.9406 x Lambda(1.0)), Vali MSE Loss: 0.9458 Test MSE Loss: 0.4966
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9425292015075684
Epoch: 18, Steps: 64 Train Loss: 2.4244 (Forecasting Loss:0.4856 + XiCon Loss:1.9388 x Lambda(1.0)), Vali MSE Loss: 0.9470 Test MSE Loss: 0.4966
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9163615703582764
Epoch: 19, Steps: 64 Train Loss: 2.4266 (Forecasting Loss:0.4858 + XiCon Loss:1.9409 x Lambda(1.0)), Vali MSE Loss: 0.9435 Test MSE Loss: 0.4966
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.0200214385986328
Epoch: 20, Steps: 64 Train Loss: 2.4299 (Forecasting Loss:0.4857 + XiCon Loss:1.9442 x Lambda(1.0)), Vali MSE Loss: 0.9417 Test MSE Loss: 0.4966
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4629831612110138, mae:0.5302016139030457, mape:0.4450642466545105, mspe:0.5862990021705627 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7186
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.054542064666748
Epoch: 1, Steps: 64 Train Loss: 2.4349 (Forecasting Loss:0.4951 + XiCon Loss:1.9398 x Lambda(1.0)), Vali MSE Loss: 0.9334 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933424).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9341702461242676
Epoch: 2, Steps: 64 Train Loss: 2.4283 (Forecasting Loss:0.4905 + XiCon Loss:1.9378 x Lambda(1.0)), Vali MSE Loss: 0.9191 Test MSE Loss: 0.5152
Validation loss decreased (0.933424 --> 0.919052).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8714985847473145
Epoch: 3, Steps: 64 Train Loss: 2.4224 (Forecasting Loss:0.4818 + XiCon Loss:1.9406 x Lambda(1.0)), Vali MSE Loss: 0.9149 Test MSE Loss: 0.5118
Validation loss decreased (0.919052 --> 0.914859).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.0156784057617188
Epoch: 4, Steps: 64 Train Loss: 2.4200 (Forecasting Loss:0.4802 + XiCon Loss:1.9398 x Lambda(1.0)), Vali MSE Loss: 0.9105 Test MSE Loss: 0.5102
Validation loss decreased (0.914859 --> 0.910460).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9995095729827881
Epoch: 5, Steps: 64 Train Loss: 2.4213 (Forecasting Loss:0.4790 + XiCon Loss:1.9423 x Lambda(1.0)), Vali MSE Loss: 0.9054 Test MSE Loss: 0.5095
Validation loss decreased (0.910460 --> 0.905376).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9381136894226074
Epoch: 6, Steps: 64 Train Loss: 2.4178 (Forecasting Loss:0.4791 + XiCon Loss:1.9388 x Lambda(1.0)), Vali MSE Loss: 0.9063 Test MSE Loss: 0.5091
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.8851087093353271
Epoch: 7, Steps: 64 Train Loss: 2.4195 (Forecasting Loss:0.4784 + XiCon Loss:1.9411 x Lambda(1.0)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5089
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9189403057098389
Epoch: 8, Steps: 64 Train Loss: 2.4168 (Forecasting Loss:0.4773 + XiCon Loss:1.9395 x Lambda(1.0)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5088
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9773409366607666
Epoch: 9, Steps: 64 Train Loss: 2.4156 (Forecasting Loss:0.4765 + XiCon Loss:1.9391 x Lambda(1.0)), Vali MSE Loss: 0.9033 Test MSE Loss: 0.5087
Validation loss decreased (0.905376 --> 0.903266).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.041626214981079
Epoch: 10, Steps: 64 Train Loss: 2.4155 (Forecasting Loss:0.4776 + XiCon Loss:1.9379 x Lambda(1.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5087
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8795444965362549
Epoch: 11, Steps: 64 Train Loss: 2.4176 (Forecasting Loss:0.4775 + XiCon Loss:1.9401 x Lambda(1.0)), Vali MSE Loss: 0.9058 Test MSE Loss: 0.5087
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8961389064788818
Epoch: 12, Steps: 64 Train Loss: 2.4169 (Forecasting Loss:0.4776 + XiCon Loss:1.9393 x Lambda(1.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5087
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.00547456741333
Epoch: 13, Steps: 64 Train Loss: 2.4204 (Forecasting Loss:0.4775 + XiCon Loss:1.9429 x Lambda(1.0)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5087
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9760513305664062
Epoch: 14, Steps: 64 Train Loss: 2.4168 (Forecasting Loss:0.4772 + XiCon Loss:1.9397 x Lambda(1.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5087
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9244015216827393
Epoch: 15, Steps: 64 Train Loss: 2.4165 (Forecasting Loss:0.4779 + XiCon Loss:1.9386 x Lambda(1.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5087
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9112086296081543
Epoch: 16, Steps: 64 Train Loss: 2.4162 (Forecasting Loss:0.4769 + XiCon Loss:1.9393 x Lambda(1.0)), Vali MSE Loss: 0.9008 Test MSE Loss: 0.5087
Validation loss decreased (0.903266 --> 0.900765).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.965559720993042
Epoch: 17, Steps: 64 Train Loss: 2.4178 (Forecasting Loss:0.4771 + XiCon Loss:1.9407 x Lambda(1.0)), Vali MSE Loss: 0.9051 Test MSE Loss: 0.5087
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9544668197631836
Epoch: 18, Steps: 64 Train Loss: 2.4178 (Forecasting Loss:0.4784 + XiCon Loss:1.9394 x Lambda(1.0)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5087
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8814980983734131
Epoch: 19, Steps: 64 Train Loss: 2.4185 (Forecasting Loss:0.4781 + XiCon Loss:1.9404 x Lambda(1.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5087
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8889484405517578
Epoch: 20, Steps: 64 Train Loss: 2.4143 (Forecasting Loss:0.4768 + XiCon Loss:1.9375 x Lambda(1.0)), Vali MSE Loss: 0.9061 Test MSE Loss: 0.5087
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.013073444366455
Epoch: 21, Steps: 64 Train Loss: 2.4170 (Forecasting Loss:0.4779 + XiCon Loss:1.9391 x Lambda(1.0)), Vali MSE Loss: 0.9051 Test MSE Loss: 0.5087
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9566032886505127
Epoch: 22, Steps: 64 Train Loss: 2.4152 (Forecasting Loss:0.4775 + XiCon Loss:1.9376 x Lambda(1.0)), Vali MSE Loss: 0.9056 Test MSE Loss: 0.5087
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9362058639526367
Epoch: 23, Steps: 64 Train Loss: 2.4152 (Forecasting Loss:0.4771 + XiCon Loss:1.9382 x Lambda(1.0)), Vali MSE Loss: 0.9038 Test MSE Loss: 0.5087
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8825953006744385
Epoch: 24, Steps: 64 Train Loss: 2.4173 (Forecasting Loss:0.4771 + XiCon Loss:1.9402 x Lambda(1.0)), Vali MSE Loss: 0.9073 Test MSE Loss: 0.5087
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 1.059239387512207
Epoch: 25, Steps: 64 Train Loss: 2.4174 (Forecasting Loss:0.4771 + XiCon Loss:1.9403 x Lambda(1.0)), Vali MSE Loss: 0.9041 Test MSE Loss: 0.5087
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9836668968200684
Epoch: 26, Steps: 64 Train Loss: 2.4147 (Forecasting Loss:0.4770 + XiCon Loss:1.9378 x Lambda(1.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5087
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4821901023387909, mae:0.5351738929748535, mape:0.45558932423591614, mspe:0.625545084476471 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5587
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.02994966506958
Epoch: 1, Steps: 64 Train Loss: 2.4346 (Forecasting Loss:0.4949 + XiCon Loss:1.9398 x Lambda(1.0)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908221).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9703061580657959
Epoch: 2, Steps: 64 Train Loss: 2.4308 (Forecasting Loss:0.4914 + XiCon Loss:1.9394 x Lambda(1.0)), Vali MSE Loss: 0.8924 Test MSE Loss: 0.5398
Validation loss decreased (0.908221 --> 0.892403).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.8939647674560547
Epoch: 3, Steps: 64 Train Loss: 2.4260 (Forecasting Loss:0.4865 + XiCon Loss:1.9395 x Lambda(1.0)), Vali MSE Loss: 0.8929 Test MSE Loss: 0.5365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9300892353057861
Epoch: 4, Steps: 64 Train Loss: 2.4205 (Forecasting Loss:0.4826 + XiCon Loss:1.9378 x Lambda(1.0)), Vali MSE Loss: 0.8856 Test MSE Loss: 0.5348
Validation loss decreased (0.892403 --> 0.885563).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.991605281829834
Epoch: 5, Steps: 64 Train Loss: 2.4200 (Forecasting Loss:0.4818 + XiCon Loss:1.9382 x Lambda(1.0)), Vali MSE Loss: 0.8840 Test MSE Loss: 0.5341
Validation loss decreased (0.885563 --> 0.884043).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9120733737945557
Epoch: 6, Steps: 64 Train Loss: 2.4186 (Forecasting Loss:0.4802 + XiCon Loss:1.9384 x Lambda(1.0)), Vali MSE Loss: 0.8865 Test MSE Loss: 0.5337
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9051330089569092
Epoch: 7, Steps: 64 Train Loss: 2.4210 (Forecasting Loss:0.4804 + XiCon Loss:1.9407 x Lambda(1.0)), Vali MSE Loss: 0.8883 Test MSE Loss: 0.5335
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9206085205078125
Epoch: 8, Steps: 64 Train Loss: 2.4218 (Forecasting Loss:0.4828 + XiCon Loss:1.9390 x Lambda(1.0)), Vali MSE Loss: 0.8900 Test MSE Loss: 0.5334
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9676098823547363
Epoch: 9, Steps: 64 Train Loss: 2.4182 (Forecasting Loss:0.4790 + XiCon Loss:1.9391 x Lambda(1.0)), Vali MSE Loss: 0.8859 Test MSE Loss: 0.5334
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9645674228668213
Epoch: 10, Steps: 64 Train Loss: 2.4187 (Forecasting Loss:0.4807 + XiCon Loss:1.9380 x Lambda(1.0)), Vali MSE Loss: 0.8857 Test MSE Loss: 0.5334
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.0183303356170654
Epoch: 11, Steps: 64 Train Loss: 2.4220 (Forecasting Loss:0.4812 + XiCon Loss:1.9408 x Lambda(1.0)), Vali MSE Loss: 0.8845 Test MSE Loss: 0.5333
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9758856296539307
Epoch: 12, Steps: 64 Train Loss: 2.4189 (Forecasting Loss:0.4796 + XiCon Loss:1.9394 x Lambda(1.0)), Vali MSE Loss: 0.8854 Test MSE Loss: 0.5333
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9791872501373291
Epoch: 13, Steps: 64 Train Loss: 2.4197 (Forecasting Loss:0.4812 + XiCon Loss:1.9385 x Lambda(1.0)), Vali MSE Loss: 0.8868 Test MSE Loss: 0.5333
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.8948981761932373
Epoch: 14, Steps: 64 Train Loss: 2.4205 (Forecasting Loss:0.4804 + XiCon Loss:1.9401 x Lambda(1.0)), Vali MSE Loss: 0.8851 Test MSE Loss: 0.5333
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.913172721862793
Epoch: 15, Steps: 64 Train Loss: 2.4201 (Forecasting Loss:0.4812 + XiCon Loss:1.9389 x Lambda(1.0)), Vali MSE Loss: 0.8853 Test MSE Loss: 0.5333
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5174331665039062, mae:0.5507322549819946, mape:0.47552379965782166, mspe:0.6888113021850586 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4835+-0.02601, MAE:0.5372+-0.00986, MAPE:0.4566+-0.01445, MSPE:0.6261+-0.04896, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5861
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.5798068046569824
Epoch: 1, Steps: 59 Train Loss: 2.8003 (Forecasting Loss:0.9906 + XiCon Loss:1.8097 x Lambda(1.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248621).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2588472366333008
Epoch: 2, Steps: 59 Train Loss: 2.7983 (Forecasting Loss:0.9903 + XiCon Loss:1.8080 x Lambda(1.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9825
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2188694477081299
Epoch: 3, Steps: 59 Train Loss: 2.8002 (Forecasting Loss:0.9892 + XiCon Loss:1.8110 x Lambda(1.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.210724115371704
Epoch: 4, Steps: 59 Train Loss: 2.7960 (Forecasting Loss:0.9890 + XiCon Loss:1.8070 x Lambda(1.0)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9822
Validation loss decreased (1.248621 --> 1.246878).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1742887496948242
Epoch: 5, Steps: 59 Train Loss: 2.8004 (Forecasting Loss:0.9890 + XiCon Loss:1.8114 x Lambda(1.0)), Vali MSE Loss: 1.2510 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2225499153137207
Epoch: 6, Steps: 59 Train Loss: 2.7970 (Forecasting Loss:0.9899 + XiCon Loss:1.8071 x Lambda(1.0)), Vali MSE Loss: 1.2460 Test MSE Loss: 0.9822
Validation loss decreased (1.246878 --> 1.246014).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2354581356048584
Epoch: 7, Steps: 59 Train Loss: 2.7981 (Forecasting Loss:0.9887 + XiCon Loss:1.8094 x Lambda(1.0)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9822
Validation loss decreased (1.246014 --> 1.244961).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1987476348876953
Epoch: 8, Steps: 59 Train Loss: 2.8020 (Forecasting Loss:0.9880 + XiCon Loss:1.8139 x Lambda(1.0)), Vali MSE Loss: 1.2478 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1812505722045898
Epoch: 9, Steps: 59 Train Loss: 2.7982 (Forecasting Loss:0.9890 + XiCon Loss:1.8093 x Lambda(1.0)), Vali MSE Loss: 1.2444 Test MSE Loss: 0.9822
Validation loss decreased (1.244961 --> 1.244422).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2152295112609863
Epoch: 10, Steps: 59 Train Loss: 2.7990 (Forecasting Loss:0.9889 + XiCon Loss:1.8101 x Lambda(1.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2105886936187744
Epoch: 11, Steps: 59 Train Loss: 2.7962 (Forecasting Loss:0.9878 + XiCon Loss:1.8084 x Lambda(1.0)), Vali MSE Loss: 1.2445 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1655569076538086
Epoch: 12, Steps: 59 Train Loss: 2.8043 (Forecasting Loss:0.9887 + XiCon Loss:1.8156 x Lambda(1.0)), Vali MSE Loss: 1.2522 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2214844226837158
Epoch: 13, Steps: 59 Train Loss: 2.7971 (Forecasting Loss:0.9890 + XiCon Loss:1.8081 x Lambda(1.0)), Vali MSE Loss: 1.2456 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.155548334121704
Epoch: 14, Steps: 59 Train Loss: 2.7958 (Forecasting Loss:0.9889 + XiCon Loss:1.8069 x Lambda(1.0)), Vali MSE Loss: 1.2449 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1881422996520996
Epoch: 15, Steps: 59 Train Loss: 2.7998 (Forecasting Loss:0.9888 + XiCon Loss:1.8110 x Lambda(1.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.223081111907959
Epoch: 16, Steps: 59 Train Loss: 2.7994 (Forecasting Loss:0.9894 + XiCon Loss:1.8100 x Lambda(1.0)), Vali MSE Loss: 1.2489 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.2004947662353516
Epoch: 17, Steps: 59 Train Loss: 2.8017 (Forecasting Loss:0.9889 + XiCon Loss:1.8128 x Lambda(1.0)), Vali MSE Loss: 1.2553 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.2264983654022217
Epoch: 18, Steps: 59 Train Loss: 2.7982 (Forecasting Loss:0.9896 + XiCon Loss:1.8086 x Lambda(1.0)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.156841516494751
Epoch: 19, Steps: 59 Train Loss: 2.8053 (Forecasting Loss:0.9895 + XiCon Loss:1.8159 x Lambda(1.0)), Vali MSE Loss: 1.2416 Test MSE Loss: 0.9822
Validation loss decreased (1.244422 --> 1.241610).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.2045321464538574
Epoch: 20, Steps: 59 Train Loss: 2.8021 (Forecasting Loss:0.9888 + XiCon Loss:1.8133 x Lambda(1.0)), Vali MSE Loss: 1.2439 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.180238962173462
Epoch: 21, Steps: 59 Train Loss: 2.8013 (Forecasting Loss:0.9898 + XiCon Loss:1.8115 x Lambda(1.0)), Vali MSE Loss: 1.2514 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.2001290321350098
Epoch: 22, Steps: 59 Train Loss: 2.7960 (Forecasting Loss:0.9903 + XiCon Loss:1.8057 x Lambda(1.0)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.1917822360992432
Epoch: 23, Steps: 59 Train Loss: 2.8016 (Forecasting Loss:0.9880 + XiCon Loss:1.8136 x Lambda(1.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.2172002792358398
Epoch: 24, Steps: 59 Train Loss: 2.7977 (Forecasting Loss:0.9893 + XiCon Loss:1.8084 x Lambda(1.0)), Vali MSE Loss: 1.2547 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.2136528491973877
Epoch: 25, Steps: 59 Train Loss: 2.7959 (Forecasting Loss:0.9890 + XiCon Loss:1.8069 x Lambda(1.0)), Vali MSE Loss: 1.2521 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.2136192321777344
Epoch: 26, Steps: 59 Train Loss: 2.7962 (Forecasting Loss:0.9891 + XiCon Loss:1.8072 x Lambda(1.0)), Vali MSE Loss: 1.2574 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.2228631973266602
Epoch: 27, Steps: 59 Train Loss: 2.8005 (Forecasting Loss:0.9887 + XiCon Loss:1.8118 x Lambda(1.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.184222936630249
Epoch: 28, Steps: 59 Train Loss: 2.7955 (Forecasting Loss:0.9901 + XiCon Loss:1.8054 x Lambda(1.0)), Vali MSE Loss: 1.2508 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.2230138778686523
Epoch: 29, Steps: 59 Train Loss: 2.7985 (Forecasting Loss:0.9886 + XiCon Loss:1.8099 x Lambda(1.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9822
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1456222534179688, mae:0.8187258839607239, mape:0.7821657061576843, mspe:1.830508828163147 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5663
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2006936073303223
Epoch: 1, Steps: 59 Train Loss: 2.7953 (Forecasting Loss:0.9892 + XiCon Loss:1.8061 x Lambda(1.0)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236818).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2544937133789062
Epoch: 2, Steps: 59 Train Loss: 2.7988 (Forecasting Loss:0.9886 + XiCon Loss:1.8102 x Lambda(1.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9931
Validation loss decreased (1.236818 --> 1.234314).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.212754726409912
Epoch: 3, Steps: 59 Train Loss: 2.7910 (Forecasting Loss:0.9873 + XiCon Loss:1.8037 x Lambda(1.0)), Vali MSE Loss: 1.2391 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2356367111206055
Epoch: 4, Steps: 59 Train Loss: 2.8032 (Forecasting Loss:0.9879 + XiCon Loss:1.8154 x Lambda(1.0)), Vali MSE Loss: 1.2406 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2143218517303467
Epoch: 5, Steps: 59 Train Loss: 2.7943 (Forecasting Loss:0.9886 + XiCon Loss:1.8057 x Lambda(1.0)), Vali MSE Loss: 1.2296 Test MSE Loss: 0.9929
Validation loss decreased (1.234314 --> 1.229620).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2233421802520752
Epoch: 6, Steps: 59 Train Loss: 2.7980 (Forecasting Loss:0.9885 + XiCon Loss:1.8095 x Lambda(1.0)), Vali MSE Loss: 1.2380 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1827738285064697
Epoch: 7, Steps: 59 Train Loss: 2.7969 (Forecasting Loss:0.9858 + XiCon Loss:1.8111 x Lambda(1.0)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2289164066314697
Epoch: 8, Steps: 59 Train Loss: 2.7997 (Forecasting Loss:0.9868 + XiCon Loss:1.8129 x Lambda(1.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1731371879577637
Epoch: 9, Steps: 59 Train Loss: 2.7976 (Forecasting Loss:0.9867 + XiCon Loss:1.8108 x Lambda(1.0)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1921274662017822
Epoch: 10, Steps: 59 Train Loss: 2.7928 (Forecasting Loss:0.9879 + XiCon Loss:1.8049 x Lambda(1.0)), Vali MSE Loss: 1.2337 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2223320007324219
Epoch: 11, Steps: 59 Train Loss: 2.7952 (Forecasting Loss:0.9873 + XiCon Loss:1.8079 x Lambda(1.0)), Vali MSE Loss: 1.2398 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2015783786773682
Epoch: 12, Steps: 59 Train Loss: 2.7967 (Forecasting Loss:0.9877 + XiCon Loss:1.8090 x Lambda(1.0)), Vali MSE Loss: 1.2262 Test MSE Loss: 0.9928
Validation loss decreased (1.229620 --> 1.226217).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2131679058074951
Epoch: 13, Steps: 59 Train Loss: 2.8017 (Forecasting Loss:0.9882 + XiCon Loss:1.8135 x Lambda(1.0)), Vali MSE Loss: 1.2305 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.2283282279968262
Epoch: 14, Steps: 59 Train Loss: 2.7995 (Forecasting Loss:0.9877 + XiCon Loss:1.8118 x Lambda(1.0)), Vali MSE Loss: 1.2352 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.2468464374542236
Epoch: 15, Steps: 59 Train Loss: 2.7987 (Forecasting Loss:0.9883 + XiCon Loss:1.8105 x Lambda(1.0)), Vali MSE Loss: 1.2264 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.1940550804138184
Epoch: 16, Steps: 59 Train Loss: 2.7974 (Forecasting Loss:0.9869 + XiCon Loss:1.8105 x Lambda(1.0)), Vali MSE Loss: 1.2418 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1881864070892334
Epoch: 17, Steps: 59 Train Loss: 2.7988 (Forecasting Loss:0.9875 + XiCon Loss:1.8113 x Lambda(1.0)), Vali MSE Loss: 1.2281 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.2371723651885986
Epoch: 18, Steps: 59 Train Loss: 2.7960 (Forecasting Loss:0.9880 + XiCon Loss:1.8080 x Lambda(1.0)), Vali MSE Loss: 1.2301 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.2189579010009766
Epoch: 19, Steps: 59 Train Loss: 2.7981 (Forecasting Loss:0.9874 + XiCon Loss:1.8107 x Lambda(1.0)), Vali MSE Loss: 1.2360 Test MSE Loss: 0.9928
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.1945762634277344
Epoch: 20, Steps: 59 Train Loss: 2.7939 (Forecasting Loss:0.9875 + XiCon Loss:1.8064 x Lambda(1.0)), Vali MSE Loss: 1.2332 Test MSE Loss: 0.9928
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1836481094360352
Epoch: 21, Steps: 59 Train Loss: 2.7921 (Forecasting Loss:0.9875 + XiCon Loss:1.8045 x Lambda(1.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9928
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.2155406475067139
Epoch: 22, Steps: 59 Train Loss: 2.7993 (Forecasting Loss:0.9885 + XiCon Loss:1.8108 x Lambda(1.0)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9928
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1612298488616943, mae:0.8244405388832092, mape:0.787647545337677, mspe:1.850738763809204 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6101
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.171236276626587
Epoch: 1, Steps: 59 Train Loss: 2.7929 (Forecasting Loss:0.9902 + XiCon Loss:1.8027 x Lambda(1.0)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247578).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1731555461883545
Epoch: 2, Steps: 59 Train Loss: 2.8030 (Forecasting Loss:0.9906 + XiCon Loss:1.8124 x Lambda(1.0)), Vali MSE Loss: 1.2355 Test MSE Loss: 0.9844
Validation loss decreased (1.247578 --> 1.235461).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1930406093597412
Epoch: 3, Steps: 59 Train Loss: 2.7922 (Forecasting Loss:0.9898 + XiCon Loss:1.8024 x Lambda(1.0)), Vali MSE Loss: 1.2346 Test MSE Loss: 0.9842
Validation loss decreased (1.235461 --> 1.234635).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2430133819580078
Epoch: 4, Steps: 59 Train Loss: 2.7971 (Forecasting Loss:0.9884 + XiCon Loss:1.8087 x Lambda(1.0)), Vali MSE Loss: 1.2539 Test MSE Loss: 0.9842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.1652741432189941
Epoch: 5, Steps: 59 Train Loss: 2.7950 (Forecasting Loss:0.9886 + XiCon Loss:1.8064 x Lambda(1.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9841
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2033319473266602
Epoch: 6, Steps: 59 Train Loss: 2.8023 (Forecasting Loss:0.9893 + XiCon Loss:1.8130 x Lambda(1.0)), Vali MSE Loss: 1.2440 Test MSE Loss: 0.9841
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2826793193817139
Epoch: 7, Steps: 59 Train Loss: 2.7941 (Forecasting Loss:0.9893 + XiCon Loss:1.8048 x Lambda(1.0)), Vali MSE Loss: 1.2497 Test MSE Loss: 0.9841
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2147681713104248
Epoch: 8, Steps: 59 Train Loss: 2.7949 (Forecasting Loss:0.9882 + XiCon Loss:1.8067 x Lambda(1.0)), Vali MSE Loss: 1.2580 Test MSE Loss: 0.9841
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2653911113739014
Epoch: 9, Steps: 59 Train Loss: 2.7989 (Forecasting Loss:0.9876 + XiCon Loss:1.8113 x Lambda(1.0)), Vali MSE Loss: 1.2504 Test MSE Loss: 0.9841
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.216801643371582
Epoch: 10, Steps: 59 Train Loss: 2.7984 (Forecasting Loss:0.9892 + XiCon Loss:1.8092 x Lambda(1.0)), Vali MSE Loss: 1.2536 Test MSE Loss: 0.9841
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.1808018684387207
Epoch: 11, Steps: 59 Train Loss: 2.7994 (Forecasting Loss:0.9878 + XiCon Loss:1.8116 x Lambda(1.0)), Vali MSE Loss: 1.2473 Test MSE Loss: 0.9841
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.211904764175415
Epoch: 12, Steps: 59 Train Loss: 2.7902 (Forecasting Loss:0.9884 + XiCon Loss:1.8018 x Lambda(1.0)), Vali MSE Loss: 1.2409 Test MSE Loss: 0.9841
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.333160400390625
Epoch: 13, Steps: 59 Train Loss: 2.7944 (Forecasting Loss:0.9888 + XiCon Loss:1.8056 x Lambda(1.0)), Vali MSE Loss: 1.2571 Test MSE Loss: 0.9841
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1480103731155396, mae:0.8204483985900879, mape:0.7830677628517151, mspe:1.831402063369751 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5878
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2153542041778564
Epoch: 1, Steps: 59 Train Loss: 2.7992 (Forecasting Loss:0.9890 + XiCon Loss:1.8102 x Lambda(1.0)), Vali MSE Loss: 1.2401 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240052).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.163651466369629
Epoch: 2, Steps: 59 Train Loss: 2.7985 (Forecasting Loss:0.9898 + XiCon Loss:1.8087 x Lambda(1.0)), Vali MSE Loss: 1.2226 Test MSE Loss: 0.9958
Validation loss decreased (1.240052 --> 1.222576).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2546544075012207
Epoch: 3, Steps: 59 Train Loss: 2.7955 (Forecasting Loss:0.9878 + XiCon Loss:1.8077 x Lambda(1.0)), Vali MSE Loss: 1.2321 Test MSE Loss: 0.9957
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1797399520874023
Epoch: 4, Steps: 59 Train Loss: 2.7966 (Forecasting Loss:0.9888 + XiCon Loss:1.8078 x Lambda(1.0)), Vali MSE Loss: 1.2314 Test MSE Loss: 0.9956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2325074672698975
Epoch: 5, Steps: 59 Train Loss: 2.7977 (Forecasting Loss:0.9883 + XiCon Loss:1.8094 x Lambda(1.0)), Vali MSE Loss: 1.2233 Test MSE Loss: 0.9956
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1710453033447266
Epoch: 6, Steps: 59 Train Loss: 2.7999 (Forecasting Loss:0.9890 + XiCon Loss:1.8109 x Lambda(1.0)), Vali MSE Loss: 1.2342 Test MSE Loss: 0.9956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.239302635192871
Epoch: 7, Steps: 59 Train Loss: 2.7996 (Forecasting Loss:0.9881 + XiCon Loss:1.8116 x Lambda(1.0)), Vali MSE Loss: 1.2252 Test MSE Loss: 0.9956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2292981147766113
Epoch: 8, Steps: 59 Train Loss: 2.8020 (Forecasting Loss:0.9873 + XiCon Loss:1.8146 x Lambda(1.0)), Vali MSE Loss: 1.2240 Test MSE Loss: 0.9956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2017107009887695
Epoch: 9, Steps: 59 Train Loss: 2.7977 (Forecasting Loss:0.9874 + XiCon Loss:1.8104 x Lambda(1.0)), Vali MSE Loss: 1.2347 Test MSE Loss: 0.9956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1982042789459229
Epoch: 10, Steps: 59 Train Loss: 2.7929 (Forecasting Loss:0.9883 + XiCon Loss:1.8047 x Lambda(1.0)), Vali MSE Loss: 1.2329 Test MSE Loss: 0.9956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2249863147735596
Epoch: 11, Steps: 59 Train Loss: 2.7980 (Forecasting Loss:0.9864 + XiCon Loss:1.8116 x Lambda(1.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2108674049377441
Epoch: 12, Steps: 59 Train Loss: 2.7998 (Forecasting Loss:0.9881 + XiCon Loss:1.8117 x Lambda(1.0)), Vali MSE Loss: 1.2323 Test MSE Loss: 0.9956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1653941869735718, mae:0.8261145353317261, mape:0.7890932559967041, mspe:1.854975938796997 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5538
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.1799800395965576
Epoch: 1, Steps: 59 Train Loss: 2.7996 (Forecasting Loss:0.9941 + XiCon Loss:1.8055 x Lambda(1.0)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275613).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1825954914093018
Epoch: 2, Steps: 59 Train Loss: 2.8022 (Forecasting Loss:0.9928 + XiCon Loss:1.8094 x Lambda(1.0)), Vali MSE Loss: 1.2745 Test MSE Loss: 0.9658
Validation loss decreased (1.275613 --> 1.274487).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2680044174194336
Epoch: 3, Steps: 59 Train Loss: 2.8022 (Forecasting Loss:0.9934 + XiCon Loss:1.8088 x Lambda(1.0)), Vali MSE Loss: 1.2849 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2260916233062744
Epoch: 4, Steps: 59 Train Loss: 2.7948 (Forecasting Loss:0.9923 + XiCon Loss:1.8025 x Lambda(1.0)), Vali MSE Loss: 1.2803 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.3044970035552979
Epoch: 5, Steps: 59 Train Loss: 2.8013 (Forecasting Loss:0.9928 + XiCon Loss:1.8086 x Lambda(1.0)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9657
Validation loss decreased (1.274487 --> 1.274256).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1919763088226318
Epoch: 6, Steps: 59 Train Loss: 2.8008 (Forecasting Loss:0.9935 + XiCon Loss:1.8073 x Lambda(1.0)), Vali MSE Loss: 1.2845 Test MSE Loss: 0.9657
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2275290489196777
Epoch: 7, Steps: 59 Train Loss: 2.7989 (Forecasting Loss:0.9924 + XiCon Loss:1.8064 x Lambda(1.0)), Vali MSE Loss: 1.2775 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1994132995605469
Epoch: 8, Steps: 59 Train Loss: 2.7970 (Forecasting Loss:0.9920 + XiCon Loss:1.8049 x Lambda(1.0)), Vali MSE Loss: 1.2824 Test MSE Loss: 0.9657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1780107021331787
Epoch: 9, Steps: 59 Train Loss: 2.8010 (Forecasting Loss:0.9931 + XiCon Loss:1.8079 x Lambda(1.0)), Vali MSE Loss: 1.2886 Test MSE Loss: 0.9657
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2109622955322266
Epoch: 10, Steps: 59 Train Loss: 2.7962 (Forecasting Loss:0.9923 + XiCon Loss:1.8039 x Lambda(1.0)), Vali MSE Loss: 1.2792 Test MSE Loss: 0.9657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2143654823303223
Epoch: 11, Steps: 59 Train Loss: 2.8017 (Forecasting Loss:0.9928 + XiCon Loss:1.8090 x Lambda(1.0)), Vali MSE Loss: 1.2748 Test MSE Loss: 0.9657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2206151485443115
Epoch: 12, Steps: 59 Train Loss: 2.7915 (Forecasting Loss:0.9933 + XiCon Loss:1.7981 x Lambda(1.0)), Vali MSE Loss: 1.2767 Test MSE Loss: 0.9657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.232410192489624
Epoch: 13, Steps: 59 Train Loss: 2.7984 (Forecasting Loss:0.9922 + XiCon Loss:1.8062 x Lambda(1.0)), Vali MSE Loss: 1.2820 Test MSE Loss: 0.9657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.1644818782806396
Epoch: 14, Steps: 59 Train Loss: 2.8063 (Forecasting Loss:0.9917 + XiCon Loss:1.8146 x Lambda(1.0)), Vali MSE Loss: 1.2818 Test MSE Loss: 0.9657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.194512128829956
Epoch: 15, Steps: 59 Train Loss: 2.7956 (Forecasting Loss:0.9928 + XiCon Loss:1.8028 x Lambda(1.0)), Vali MSE Loss: 1.2801 Test MSE Loss: 0.9657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1206176280975342, mae:0.8108511567115784, mape:0.7731294631958008, mspe:1.7925790548324585 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02180, MAE:0.8201+-0.00741, MAPE:0.7830+-0.00778, MSPE:1.8320+-0.03064, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6279
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.8930861949920654
Epoch: 1, Steps: 53 Train Loss: 3.3138 (Forecasting Loss:1.4862 + XiCon Loss:1.8276 x Lambda(1.0)), Vali MSE Loss: 1.8588 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858840).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5304007530212402
Epoch: 2, Steps: 53 Train Loss: 3.3028 (Forecasting Loss:1.4799 + XiCon Loss:1.8229 x Lambda(1.0)), Vali MSE Loss: 1.8423 Test MSE Loss: 0.9177
Validation loss decreased (1.858840 --> 1.842259).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5770041942596436
Epoch: 3, Steps: 53 Train Loss: 3.2975 (Forecasting Loss:1.4740 + XiCon Loss:1.8235 x Lambda(1.0)), Vali MSE Loss: 1.8454 Test MSE Loss: 0.9224
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.502661943435669
Epoch: 4, Steps: 53 Train Loss: 3.2979 (Forecasting Loss:1.4722 + XiCon Loss:1.8256 x Lambda(1.0)), Vali MSE Loss: 1.8424 Test MSE Loss: 0.9246
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6146790981292725
Epoch: 5, Steps: 53 Train Loss: 3.2961 (Forecasting Loss:1.4680 + XiCon Loss:1.8281 x Lambda(1.0)), Vali MSE Loss: 1.8227 Test MSE Loss: 0.9256
Validation loss decreased (1.842259 --> 1.822675).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5225005149841309
Epoch: 6, Steps: 53 Train Loss: 3.2948 (Forecasting Loss:1.4708 + XiCon Loss:1.8240 x Lambda(1.0)), Vali MSE Loss: 1.8257 Test MSE Loss: 0.9261
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5052082538604736
Epoch: 7, Steps: 53 Train Loss: 3.2906 (Forecasting Loss:1.4676 + XiCon Loss:1.8231 x Lambda(1.0)), Vali MSE Loss: 1.7960 Test MSE Loss: 0.9264
Validation loss decreased (1.822675 --> 1.795988).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5945918560028076
Epoch: 8, Steps: 53 Train Loss: 3.2847 (Forecasting Loss:1.4665 + XiCon Loss:1.8182 x Lambda(1.0)), Vali MSE Loss: 1.8516 Test MSE Loss: 0.9266
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.618410348892212
Epoch: 9, Steps: 53 Train Loss: 3.2860 (Forecasting Loss:1.4675 + XiCon Loss:1.8185 x Lambda(1.0)), Vali MSE Loss: 1.8150 Test MSE Loss: 0.9266
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.4697153568267822
Epoch: 10, Steps: 53 Train Loss: 3.2927 (Forecasting Loss:1.4690 + XiCon Loss:1.8236 x Lambda(1.0)), Vali MSE Loss: 1.8538 Test MSE Loss: 0.9267
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5041167736053467
Epoch: 11, Steps: 53 Train Loss: 3.2890 (Forecasting Loss:1.4658 + XiCon Loss:1.8232 x Lambda(1.0)), Vali MSE Loss: 1.8365 Test MSE Loss: 0.9267
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4775161743164062
Epoch: 12, Steps: 53 Train Loss: 3.2868 (Forecasting Loss:1.4668 + XiCon Loss:1.8200 x Lambda(1.0)), Vali MSE Loss: 1.8123 Test MSE Loss: 0.9267
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.514049768447876
Epoch: 13, Steps: 53 Train Loss: 3.2962 (Forecasting Loss:1.4675 + XiCon Loss:1.8287 x Lambda(1.0)), Vali MSE Loss: 1.8491 Test MSE Loss: 0.9267
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.4656507968902588
Epoch: 14, Steps: 53 Train Loss: 3.2916 (Forecasting Loss:1.4687 + XiCon Loss:1.8229 x Lambda(1.0)), Vali MSE Loss: 1.8039 Test MSE Loss: 0.9267
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.4873478412628174
Epoch: 15, Steps: 53 Train Loss: 3.2874 (Forecasting Loss:1.4655 + XiCon Loss:1.8219 x Lambda(1.0)), Vali MSE Loss: 1.8460 Test MSE Loss: 0.9267
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5123071670532227
Epoch: 16, Steps: 53 Train Loss: 3.2842 (Forecasting Loss:1.4663 + XiCon Loss:1.8180 x Lambda(1.0)), Vali MSE Loss: 1.8260 Test MSE Loss: 0.9267
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.474367380142212
Epoch: 17, Steps: 53 Train Loss: 3.2874 (Forecasting Loss:1.4681 + XiCon Loss:1.8194 x Lambda(1.0)), Vali MSE Loss: 1.8432 Test MSE Loss: 0.9267
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.057556390762329, mae:0.7952963709831238, mape:0.794647753238678, mspe:1.7958271503448486 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5641
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5283877849578857
Epoch: 1, Steps: 53 Train Loss: 3.3085 (Forecasting Loss:1.4830 + XiCon Loss:1.8255 x Lambda(1.0)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828230).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.4876658916473389
Epoch: 2, Steps: 53 Train Loss: 3.3038 (Forecasting Loss:1.4788 + XiCon Loss:1.8250 x Lambda(1.0)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9332
Validation loss decreased (1.828230 --> 1.821666).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.4894754886627197
Epoch: 3, Steps: 53 Train Loss: 3.3000 (Forecasting Loss:1.4731 + XiCon Loss:1.8268 x Lambda(1.0)), Vali MSE Loss: 1.7985 Test MSE Loss: 0.9349
Validation loss decreased (1.821666 --> 1.798491).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.497058629989624
Epoch: 4, Steps: 53 Train Loss: 3.3063 (Forecasting Loss:1.4714 + XiCon Loss:1.8349 x Lambda(1.0)), Vali MSE Loss: 1.7999 Test MSE Loss: 0.9358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.481090784072876
Epoch: 5, Steps: 53 Train Loss: 3.3024 (Forecasting Loss:1.4744 + XiCon Loss:1.8280 x Lambda(1.0)), Vali MSE Loss: 1.8208 Test MSE Loss: 0.9363
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6223878860473633
Epoch: 6, Steps: 53 Train Loss: 3.2967 (Forecasting Loss:1.4694 + XiCon Loss:1.8273 x Lambda(1.0)), Vali MSE Loss: 1.8074 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5004456043243408
Epoch: 7, Steps: 53 Train Loss: 3.2963 (Forecasting Loss:1.4680 + XiCon Loss:1.8283 x Lambda(1.0)), Vali MSE Loss: 1.7817 Test MSE Loss: 0.9366
Validation loss decreased (1.798491 --> 1.781716).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.538982629776001
Epoch: 8, Steps: 53 Train Loss: 3.2993 (Forecasting Loss:1.4693 + XiCon Loss:1.8299 x Lambda(1.0)), Vali MSE Loss: 1.8241 Test MSE Loss: 0.9367
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5200681686401367
Epoch: 9, Steps: 53 Train Loss: 3.2901 (Forecasting Loss:1.4655 + XiCon Loss:1.8246 x Lambda(1.0)), Vali MSE Loss: 1.8212 Test MSE Loss: 0.9367
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5452313423156738
Epoch: 10, Steps: 53 Train Loss: 3.2998 (Forecasting Loss:1.4708 + XiCon Loss:1.8290 x Lambda(1.0)), Vali MSE Loss: 1.8316 Test MSE Loss: 0.9367
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.4919791221618652
Epoch: 11, Steps: 53 Train Loss: 3.2950 (Forecasting Loss:1.4697 + XiCon Loss:1.8253 x Lambda(1.0)), Vali MSE Loss: 1.8395 Test MSE Loss: 0.9367
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.4731225967407227
Epoch: 12, Steps: 53 Train Loss: 3.3018 (Forecasting Loss:1.4692 + XiCon Loss:1.8326 x Lambda(1.0)), Vali MSE Loss: 1.7650 Test MSE Loss: 0.9367
Validation loss decreased (1.781716 --> 1.765043).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.4886682033538818
Epoch: 13, Steps: 53 Train Loss: 3.3010 (Forecasting Loss:1.4701 + XiCon Loss:1.8309 x Lambda(1.0)), Vali MSE Loss: 1.8079 Test MSE Loss: 0.9367
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5109519958496094
Epoch: 14, Steps: 53 Train Loss: 3.2959 (Forecasting Loss:1.4707 + XiCon Loss:1.8253 x Lambda(1.0)), Vali MSE Loss: 1.8029 Test MSE Loss: 0.9367
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5046026706695557
Epoch: 15, Steps: 53 Train Loss: 3.2927 (Forecasting Loss:1.4672 + XiCon Loss:1.8254 x Lambda(1.0)), Vali MSE Loss: 1.7968 Test MSE Loss: 0.9367
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.4860153198242188
Epoch: 16, Steps: 53 Train Loss: 3.2980 (Forecasting Loss:1.4709 + XiCon Loss:1.8271 x Lambda(1.0)), Vali MSE Loss: 1.7898 Test MSE Loss: 0.9367
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.4836399555206299
Epoch: 17, Steps: 53 Train Loss: 3.2961 (Forecasting Loss:1.4683 + XiCon Loss:1.8278 x Lambda(1.0)), Vali MSE Loss: 1.8287 Test MSE Loss: 0.9367
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.5387017726898193
Epoch: 18, Steps: 53 Train Loss: 3.2976 (Forecasting Loss:1.4688 + XiCon Loss:1.8288 x Lambda(1.0)), Vali MSE Loss: 1.8225 Test MSE Loss: 0.9367
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.6889817714691162
Epoch: 19, Steps: 53 Train Loss: 3.3012 (Forecasting Loss:1.4719 + XiCon Loss:1.8292 x Lambda(1.0)), Vali MSE Loss: 1.8118 Test MSE Loss: 0.9367
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.5539665222167969
Epoch: 20, Steps: 53 Train Loss: 3.2940 (Forecasting Loss:1.4678 + XiCon Loss:1.8261 x Lambda(1.0)), Vali MSE Loss: 1.8106 Test MSE Loss: 0.9367
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.619523286819458
Epoch: 21, Steps: 53 Train Loss: 3.2944 (Forecasting Loss:1.4692 + XiCon Loss:1.8253 x Lambda(1.0)), Vali MSE Loss: 1.8070 Test MSE Loss: 0.9367
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.6146092414855957
Epoch: 22, Steps: 53 Train Loss: 3.2996 (Forecasting Loss:1.4708 + XiCon Loss:1.8288 x Lambda(1.0)), Vali MSE Loss: 1.8212 Test MSE Loss: 0.9367
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.073358178138733, mae:0.8001077771186829, mape:0.8006793260574341, mspe:1.8217865228652954 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6299
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6023213863372803
Epoch: 1, Steps: 53 Train Loss: 3.3160 (Forecasting Loss:1.4859 + XiCon Loss:1.8300 x Lambda(1.0)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899233).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6728184223175049
Epoch: 2, Steps: 53 Train Loss: 3.3129 (Forecasting Loss:1.4837 + XiCon Loss:1.8292 x Lambda(1.0)), Vali MSE Loss: 1.8449 Test MSE Loss: 0.9160
Validation loss decreased (1.899233 --> 1.844899).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.553138017654419
Epoch: 3, Steps: 53 Train Loss: 3.3047 (Forecasting Loss:1.4806 + XiCon Loss:1.8241 x Lambda(1.0)), Vali MSE Loss: 1.8758 Test MSE Loss: 0.9184
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5411548614501953
Epoch: 4, Steps: 53 Train Loss: 3.2991 (Forecasting Loss:1.4688 + XiCon Loss:1.8302 x Lambda(1.0)), Vali MSE Loss: 1.8569 Test MSE Loss: 0.9197
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.7171757221221924
Epoch: 5, Steps: 53 Train Loss: 3.3010 (Forecasting Loss:1.4731 + XiCon Loss:1.8279 x Lambda(1.0)), Vali MSE Loss: 1.8096 Test MSE Loss: 0.9203
Validation loss decreased (1.844899 --> 1.809556).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.616509199142456
Epoch: 6, Steps: 53 Train Loss: 3.3003 (Forecasting Loss:1.4735 + XiCon Loss:1.8267 x Lambda(1.0)), Vali MSE Loss: 1.8722 Test MSE Loss: 0.9206
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.590754508972168
Epoch: 7, Steps: 53 Train Loss: 3.3060 (Forecasting Loss:1.4750 + XiCon Loss:1.8310 x Lambda(1.0)), Vali MSE Loss: 1.8680 Test MSE Loss: 0.9208
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5623559951782227
Epoch: 8, Steps: 53 Train Loss: 3.2969 (Forecasting Loss:1.4730 + XiCon Loss:1.8239 x Lambda(1.0)), Vali MSE Loss: 1.8526 Test MSE Loss: 0.9209
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6323039531707764
Epoch: 9, Steps: 53 Train Loss: 3.2962 (Forecasting Loss:1.4724 + XiCon Loss:1.8238 x Lambda(1.0)), Vali MSE Loss: 1.8347 Test MSE Loss: 0.9209
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.633228063583374
Epoch: 10, Steps: 53 Train Loss: 3.3001 (Forecasting Loss:1.4687 + XiCon Loss:1.8314 x Lambda(1.0)), Vali MSE Loss: 1.8593 Test MSE Loss: 0.9209
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5396909713745117
Epoch: 11, Steps: 53 Train Loss: 3.3034 (Forecasting Loss:1.4736 + XiCon Loss:1.8298 x Lambda(1.0)), Vali MSE Loss: 1.8453 Test MSE Loss: 0.9210
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5621938705444336
Epoch: 12, Steps: 53 Train Loss: 3.2944 (Forecasting Loss:1.4695 + XiCon Loss:1.8249 x Lambda(1.0)), Vali MSE Loss: 1.8319 Test MSE Loss: 0.9210
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.569535732269287
Epoch: 13, Steps: 53 Train Loss: 3.2977 (Forecasting Loss:1.4688 + XiCon Loss:1.8289 x Lambda(1.0)), Vali MSE Loss: 1.8590 Test MSE Loss: 0.9210
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.6319818496704102
Epoch: 14, Steps: 53 Train Loss: 3.2996 (Forecasting Loss:1.4695 + XiCon Loss:1.8301 x Lambda(1.0)), Vali MSE Loss: 1.8342 Test MSE Loss: 0.9210
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5772459506988525
Epoch: 15, Steps: 53 Train Loss: 3.2951 (Forecasting Loss:1.4699 + XiCon Loss:1.8251 x Lambda(1.0)), Vali MSE Loss: 1.8914 Test MSE Loss: 0.9210
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0484143495559692, mae:0.7921512722969055, mape:0.7909529805183411, mspe:1.7792798280715942 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5957
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5660345554351807
Epoch: 1, Steps: 53 Train Loss: 3.3279 (Forecasting Loss:1.4999 + XiCon Loss:1.8280 x Lambda(1.0)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995550).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6658971309661865
Epoch: 2, Steps: 53 Train Loss: 3.3304 (Forecasting Loss:1.4973 + XiCon Loss:1.8331 x Lambda(1.0)), Vali MSE Loss: 1.9557 Test MSE Loss: 0.8733
Validation loss decreased (1.995550 --> 1.955725).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5772593021392822
Epoch: 3, Steps: 53 Train Loss: 3.3200 (Forecasting Loss:1.4911 + XiCon Loss:1.8289 x Lambda(1.0)), Vali MSE Loss: 1.9766 Test MSE Loss: 0.8795
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5751051902770996
Epoch: 4, Steps: 53 Train Loss: 3.3102 (Forecasting Loss:1.4833 + XiCon Loss:1.8268 x Lambda(1.0)), Vali MSE Loss: 1.9662 Test MSE Loss: 0.8832
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5727343559265137
Epoch: 5, Steps: 53 Train Loss: 3.3046 (Forecasting Loss:1.4779 + XiCon Loss:1.8267 x Lambda(1.0)), Vali MSE Loss: 1.9319 Test MSE Loss: 0.8851
Validation loss decreased (1.955725 --> 1.931867).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5901098251342773
Epoch: 6, Steps: 53 Train Loss: 3.3050 (Forecasting Loss:1.4791 + XiCon Loss:1.8259 x Lambda(1.0)), Vali MSE Loss: 1.9779 Test MSE Loss: 0.8862
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.585270881652832
Epoch: 7, Steps: 53 Train Loss: 3.3161 (Forecasting Loss:1.4818 + XiCon Loss:1.8343 x Lambda(1.0)), Vali MSE Loss: 1.9277 Test MSE Loss: 0.8868
Validation loss decreased (1.931867 --> 1.927702).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5656018257141113
Epoch: 8, Steps: 53 Train Loss: 3.3066 (Forecasting Loss:1.4778 + XiCon Loss:1.8288 x Lambda(1.0)), Vali MSE Loss: 1.9382 Test MSE Loss: 0.8870
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6312251091003418
Epoch: 9, Steps: 53 Train Loss: 3.3065 (Forecasting Loss:1.4780 + XiCon Loss:1.8285 x Lambda(1.0)), Vali MSE Loss: 1.9418 Test MSE Loss: 0.8871
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.6104426383972168
Epoch: 10, Steps: 53 Train Loss: 3.3101 (Forecasting Loss:1.4792 + XiCon Loss:1.8309 x Lambda(1.0)), Vali MSE Loss: 1.9170 Test MSE Loss: 0.8872
Validation loss decreased (1.927702 --> 1.916982).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.6261754035949707
Epoch: 11, Steps: 53 Train Loss: 3.3040 (Forecasting Loss:1.4788 + XiCon Loss:1.8252 x Lambda(1.0)), Vali MSE Loss: 1.9314 Test MSE Loss: 0.8872
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5746502876281738
Epoch: 12, Steps: 53 Train Loss: 3.3025 (Forecasting Loss:1.4782 + XiCon Loss:1.8242 x Lambda(1.0)), Vali MSE Loss: 1.8974 Test MSE Loss: 0.8873
Validation loss decreased (1.916982 --> 1.897434).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6122422218322754
Epoch: 13, Steps: 53 Train Loss: 3.3106 (Forecasting Loss:1.4792 + XiCon Loss:1.8315 x Lambda(1.0)), Vali MSE Loss: 1.9306 Test MSE Loss: 0.8873
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5834267139434814
Epoch: 14, Steps: 53 Train Loss: 3.3061 (Forecasting Loss:1.4810 + XiCon Loss:1.8251 x Lambda(1.0)), Vali MSE Loss: 1.9345 Test MSE Loss: 0.8873
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6321847438812256
Epoch: 15, Steps: 53 Train Loss: 3.3078 (Forecasting Loss:1.4810 + XiCon Loss:1.8268 x Lambda(1.0)), Vali MSE Loss: 1.9336 Test MSE Loss: 0.8873
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.657649040222168
Epoch: 16, Steps: 53 Train Loss: 3.3042 (Forecasting Loss:1.4778 + XiCon Loss:1.8264 x Lambda(1.0)), Vali MSE Loss: 1.9237 Test MSE Loss: 0.8873
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5685734748840332
Epoch: 17, Steps: 53 Train Loss: 3.3022 (Forecasting Loss:1.4766 + XiCon Loss:1.8256 x Lambda(1.0)), Vali MSE Loss: 1.9440 Test MSE Loss: 0.8873
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.5418643951416016
Epoch: 18, Steps: 53 Train Loss: 3.3119 (Forecasting Loss:1.4774 + XiCon Loss:1.8345 x Lambda(1.0)), Vali MSE Loss: 1.9599 Test MSE Loss: 0.8873
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.6181972026824951
Epoch: 19, Steps: 53 Train Loss: 3.3074 (Forecasting Loss:1.4744 + XiCon Loss:1.8330 x Lambda(1.0)), Vali MSE Loss: 1.9225 Test MSE Loss: 0.8873
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.651918888092041
Epoch: 20, Steps: 53 Train Loss: 3.3084 (Forecasting Loss:1.4806 + XiCon Loss:1.8278 x Lambda(1.0)), Vali MSE Loss: 1.9410 Test MSE Loss: 0.8873
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.5875437259674072
Epoch: 21, Steps: 53 Train Loss: 3.3089 (Forecasting Loss:1.4773 + XiCon Loss:1.8317 x Lambda(1.0)), Vali MSE Loss: 1.9057 Test MSE Loss: 0.8873
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.5597858428955078
Epoch: 22, Steps: 53 Train Loss: 3.3115 (Forecasting Loss:1.4796 + XiCon Loss:1.8319 x Lambda(1.0)), Vali MSE Loss: 1.9338 Test MSE Loss: 0.8873
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:0.9986083507537842, mae:0.7759146094322205, mape:0.7707273960113525, mspe:1.6967054605484009 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5634
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6505522727966309
Epoch: 1, Steps: 53 Train Loss: 3.3024 (Forecasting Loss:1.4764 + XiCon Loss:1.8260 x Lambda(1.0)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740654).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5631051063537598
Epoch: 2, Steps: 53 Train Loss: 3.3012 (Forecasting Loss:1.4733 + XiCon Loss:1.8279 x Lambda(1.0)), Vali MSE Loss: 1.7212 Test MSE Loss: 0.9604
Validation loss decreased (1.740654 --> 1.721194).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.610915184020996
Epoch: 3, Steps: 53 Train Loss: 3.2900 (Forecasting Loss:1.4665 + XiCon Loss:1.8235 x Lambda(1.0)), Vali MSE Loss: 1.7422 Test MSE Loss: 0.9635
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.6212520599365234
Epoch: 4, Steps: 53 Train Loss: 3.2912 (Forecasting Loss:1.4646 + XiCon Loss:1.8266 x Lambda(1.0)), Vali MSE Loss: 1.7445 Test MSE Loss: 0.9650
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.610806941986084
Epoch: 5, Steps: 53 Train Loss: 3.2932 (Forecasting Loss:1.4632 + XiCon Loss:1.8299 x Lambda(1.0)), Vali MSE Loss: 1.7464 Test MSE Loss: 0.9658
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5893633365631104
Epoch: 6, Steps: 53 Train Loss: 3.2913 (Forecasting Loss:1.4633 + XiCon Loss:1.8280 x Lambda(1.0)), Vali MSE Loss: 1.7558 Test MSE Loss: 0.9662
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6879539489746094
Epoch: 7, Steps: 53 Train Loss: 3.2881 (Forecasting Loss:1.4647 + XiCon Loss:1.8234 x Lambda(1.0)), Vali MSE Loss: 1.7558 Test MSE Loss: 0.9664
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6354491710662842
Epoch: 8, Steps: 53 Train Loss: 3.2878 (Forecasting Loss:1.4620 + XiCon Loss:1.8258 x Lambda(1.0)), Vali MSE Loss: 1.7267 Test MSE Loss: 0.9666
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5808937549591064
Epoch: 9, Steps: 53 Train Loss: 3.2924 (Forecasting Loss:1.4637 + XiCon Loss:1.8287 x Lambda(1.0)), Vali MSE Loss: 1.7716 Test MSE Loss: 0.9666
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5766127109527588
Epoch: 10, Steps: 53 Train Loss: 3.2863 (Forecasting Loss:1.4610 + XiCon Loss:1.8254 x Lambda(1.0)), Vali MSE Loss: 1.7476 Test MSE Loss: 0.9666
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.577829360961914
Epoch: 11, Steps: 53 Train Loss: 3.2934 (Forecasting Loss:1.4635 + XiCon Loss:1.8299 x Lambda(1.0)), Vali MSE Loss: 1.7539 Test MSE Loss: 0.9666
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5436878204345703
Epoch: 12, Steps: 53 Train Loss: 3.2972 (Forecasting Loss:1.4601 + XiCon Loss:1.8371 x Lambda(1.0)), Vali MSE Loss: 1.7532 Test MSE Loss: 0.9666
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.1084884405136108, mae:0.8123292326927185, mape:0.8143032789230347, mspe:1.8777859210968018 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0573+-0.04967, MAE:0.7952+-0.01641, MAPE:0.7943+-0.01971, MSPE:1.7943+-0.08208, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 3.3707972
	speed: 0.0195s/iter; left time: 945.3826s
	iters: 200, epoch: 1 | loss: 3.3816028
	speed: 0.0137s/iter; left time: 666.0198s
	iters: 300, epoch: 1 | loss: 3.0830209
	speed: 0.0133s/iter; left time: 642.9201s
	iters: 400, epoch: 1 | loss: 3.0734138
	speed: 0.0138s/iter; left time: 667.2498s
Epoch: 1 cost time: 7.231624126434326
Epoch: 1, Steps: 487 Train Loss: 3.2315 (Forecasting Loss:0.7418 + XiCon Loss:2.4898 x Lambda(1.0)), Vali MSE Loss: 1.0369 Test MSE Loss: 0.6311
Validation loss decreased (inf --> 1.036879).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 2.9557431
	speed: 0.0158s/iter; left time: 759.0703s
	iters: 200, epoch: 2 | loss: 2.9457381
	speed: 0.0141s/iter; left time: 675.1053s
	iters: 300, epoch: 2 | loss: 2.9625945
	speed: 0.0143s/iter; left time: 684.8718s
	iters: 400, epoch: 2 | loss: 2.9046898
	speed: 0.0150s/iter; left time: 715.6194s
Epoch: 2 cost time: 7.139555931091309
Epoch: 2, Steps: 487 Train Loss: 2.8991 (Forecasting Loss:0.4347 + XiCon Loss:2.4644 x Lambda(1.0)), Vali MSE Loss: 0.7456 Test MSE Loss: 0.5259
Validation loss decreased (1.036879 --> 0.745584).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 2.8539555
	speed: 0.0162s/iter; left time: 769.9936s
	iters: 200, epoch: 3 | loss: 2.7961402
	speed: 0.0136s/iter; left time: 647.6840s
	iters: 300, epoch: 3 | loss: 2.9178023
	speed: 0.0150s/iter; left time: 709.1159s
	iters: 400, epoch: 3 | loss: 2.6843996
	speed: 0.0148s/iter; left time: 701.4766s
Epoch: 3 cost time: 7.272863149642944
Epoch: 3, Steps: 487 Train Loss: 2.8387 (Forecasting Loss:0.4049 + XiCon Loss:2.4338 x Lambda(1.0)), Vali MSE Loss: 0.7353 Test MSE Loss: 0.5172
Validation loss decreased (0.745584 --> 0.735297).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 2.9219065
	speed: 0.0157s/iter; left time: 740.3116s
	iters: 200, epoch: 4 | loss: 2.8543360
	speed: 0.0141s/iter; left time: 663.0185s
	iters: 300, epoch: 4 | loss: 2.7898312
	speed: 0.0136s/iter; left time: 637.7416s
	iters: 400, epoch: 4 | loss: 2.8470225
	speed: 0.0119s/iter; left time: 557.2477s
Epoch: 4 cost time: 6.6613709926605225
Epoch: 4, Steps: 487 Train Loss: 2.8265 (Forecasting Loss:0.3995 + XiCon Loss:2.4271 x Lambda(1.0)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5122
Validation loss decreased (0.735297 --> 0.727592).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 2.8510780
	speed: 0.0163s/iter; left time: 758.5961s
	iters: 200, epoch: 5 | loss: 2.8844736
	speed: 0.0137s/iter; left time: 639.1431s
	iters: 300, epoch: 5 | loss: 2.8132472
	speed: 0.0144s/iter; left time: 670.9830s
	iters: 400, epoch: 5 | loss: 2.8977933
	speed: 0.0138s/iter; left time: 641.0658s
Epoch: 5 cost time: 7.084007978439331
Epoch: 5, Steps: 487 Train Loss: 2.8209 (Forecasting Loss:0.3973 + XiCon Loss:2.4236 x Lambda(1.0)), Vali MSE Loss: 0.7253 Test MSE Loss: 0.5084
Validation loss decreased (0.727592 --> 0.725308).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 2.8039339
	speed: 0.0160s/iter; left time: 738.3501s
	iters: 200, epoch: 6 | loss: 2.8643427
	speed: 0.0137s/iter; left time: 631.0463s
	iters: 300, epoch: 6 | loss: 2.7879055
	speed: 0.0136s/iter; left time: 627.4162s
	iters: 400, epoch: 6 | loss: 2.7021811
	speed: 0.0141s/iter; left time: 648.3784s
Epoch: 6 cost time: 7.03729510307312
Epoch: 6, Steps: 487 Train Loss: 2.8170 (Forecasting Loss:0.3963 + XiCon Loss:2.4208 x Lambda(1.0)), Vali MSE Loss: 0.7259 Test MSE Loss: 0.5102
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 2.8481386
	speed: 0.0168s/iter; left time: 765.9279s
	iters: 200, epoch: 7 | loss: 2.7206855
	speed: 0.0135s/iter; left time: 615.1576s
	iters: 300, epoch: 7 | loss: 2.9343736
	speed: 0.0134s/iter; left time: 611.5804s
	iters: 400, epoch: 7 | loss: 2.8274322
	speed: 0.0140s/iter; left time: 635.4366s
Epoch: 7 cost time: 7.025182485580444
Epoch: 7, Steps: 487 Train Loss: 2.8151 (Forecasting Loss:0.3957 + XiCon Loss:2.4194 x Lambda(1.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5095
Validation loss decreased (0.725308 --> 0.724891).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 2.6739893
	speed: 0.0163s/iter; left time: 737.8282s
	iters: 200, epoch: 8 | loss: 2.7290888
	speed: 0.0137s/iter; left time: 619.9904s
	iters: 300, epoch: 8 | loss: 2.7774606
	speed: 0.0141s/iter; left time: 633.7857s
	iters: 400, epoch: 8 | loss: 2.9147198
	speed: 0.0139s/iter; left time: 625.5451s
Epoch: 8 cost time: 7.072978734970093
Epoch: 8, Steps: 487 Train Loss: 2.8156 (Forecasting Loss:0.3955 + XiCon Loss:2.4201 x Lambda(1.0)), Vali MSE Loss: 0.7248 Test MSE Loss: 0.5092
Validation loss decreased (0.724891 --> 0.724762).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 2.9586937
	speed: 0.0165s/iter; left time: 737.2251s
	iters: 200, epoch: 9 | loss: 2.7194800
	speed: 0.0137s/iter; left time: 612.9552s
	iters: 300, epoch: 9 | loss: 2.8120599
	speed: 0.0142s/iter; left time: 631.3821s
	iters: 400, epoch: 9 | loss: 2.8955090
	speed: 0.0140s/iter; left time: 622.4052s
Epoch: 9 cost time: 7.09551739692688
Epoch: 9, Steps: 487 Train Loss: 2.8175 (Forecasting Loss:0.3951 + XiCon Loss:2.4224 x Lambda(1.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5091
Validation loss decreased (0.724762 --> 0.724433).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 2.6868563
	speed: 0.0174s/iter; left time: 769.9678s
	iters: 200, epoch: 10 | loss: 2.7347393
	speed: 0.0135s/iter; left time: 594.4655s
	iters: 300, epoch: 10 | loss: 2.7393641
	speed: 0.0136s/iter; left time: 597.5443s
	iters: 400, epoch: 10 | loss: 2.6406803
	speed: 0.0127s/iter; left time: 559.7585s
Epoch: 10 cost time: 6.792008638381958
Epoch: 10, Steps: 487 Train Loss: 2.8180 (Forecasting Loss:0.3951 + XiCon Loss:2.4228 x Lambda(1.0)), Vali MSE Loss: 0.7245 Test MSE Loss: 0.5090
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 2.6881433
	speed: 0.0166s/iter; left time: 726.8437s
	iters: 200, epoch: 11 | loss: 2.7228746
	speed: 0.0152s/iter; left time: 663.0944s
	iters: 300, epoch: 11 | loss: 2.8584261
	speed: 0.0137s/iter; left time: 595.3106s
	iters: 400, epoch: 11 | loss: 2.7362931
	speed: 0.0117s/iter; left time: 510.0162s
Epoch: 11 cost time: 6.756255149841309
Epoch: 11, Steps: 487 Train Loss: 2.8171 (Forecasting Loss:0.3952 + XiCon Loss:2.4219 x Lambda(1.0)), Vali MSE Loss: 0.7241 Test MSE Loss: 0.5090
Validation loss decreased (0.724433 --> 0.724125).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 2.9584818
	speed: 0.0168s/iter; left time: 726.6797s
	iters: 200, epoch: 12 | loss: 2.7252424
	speed: 0.0140s/iter; left time: 604.1551s
	iters: 300, epoch: 12 | loss: 2.8834803
	speed: 0.0140s/iter; left time: 604.5864s
	iters: 400, epoch: 12 | loss: 2.7462299
	speed: 0.0146s/iter; left time: 628.8718s
Epoch: 12 cost time: 7.266592979431152
Epoch: 12, Steps: 487 Train Loss: 2.8152 (Forecasting Loss:0.3950 + XiCon Loss:2.4202 x Lambda(1.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5090
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 2.8896255
	speed: 0.0158s/iter; left time: 677.5982s
	iters: 200, epoch: 13 | loss: 2.9064260
	speed: 0.0140s/iter; left time: 597.1151s
	iters: 300, epoch: 13 | loss: 2.8083260
	speed: 0.0145s/iter; left time: 616.7547s
	iters: 400, epoch: 13 | loss: 2.7667108
	speed: 0.0157s/iter; left time: 665.7220s
Epoch: 13 cost time: 7.267658710479736
Epoch: 13, Steps: 487 Train Loss: 2.8144 (Forecasting Loss:0.3950 + XiCon Loss:2.4194 x Lambda(1.0)), Vali MSE Loss: 0.7248 Test MSE Loss: 0.5090
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 2.8750334
	speed: 0.0156s/iter; left time: 657.6159s
	iters: 200, epoch: 14 | loss: 2.9223268
	speed: 0.0141s/iter; left time: 592.7306s
	iters: 300, epoch: 14 | loss: 2.7259119
	speed: 0.0138s/iter; left time: 582.0918s
	iters: 400, epoch: 14 | loss: 2.8992796
	speed: 0.0152s/iter; left time: 638.5874s
Epoch: 14 cost time: 7.088821887969971
Epoch: 14, Steps: 487 Train Loss: 2.8169 (Forecasting Loss:0.3951 + XiCon Loss:2.4217 x Lambda(1.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5090
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 2.8394938
	speed: 0.0156s/iter; left time: 649.7999s
	iters: 200, epoch: 15 | loss: 2.7836599
	speed: 0.0133s/iter; left time: 555.8126s
	iters: 300, epoch: 15 | loss: 2.8624740
	speed: 0.0138s/iter; left time: 571.8392s
	iters: 400, epoch: 15 | loss: 2.8010252
	speed: 0.0135s/iter; left time: 560.7725s
Epoch: 15 cost time: 6.903062582015991
Epoch: 15, Steps: 487 Train Loss: 2.8166 (Forecasting Loss:0.3950 + XiCon Loss:2.4216 x Lambda(1.0)), Vali MSE Loss: 0.7243 Test MSE Loss: 0.5090
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 2.8987098
	speed: 0.0155s/iter; left time: 639.6913s
	iters: 200, epoch: 16 | loss: 2.9170880
	speed: 0.0139s/iter; left time: 572.7873s
	iters: 300, epoch: 16 | loss: 2.7816961
	speed: 0.0143s/iter; left time: 589.2917s
	iters: 400, epoch: 16 | loss: 2.8274860
	speed: 0.0149s/iter; left time: 610.3525s
Epoch: 16 cost time: 7.215068817138672
Epoch: 16, Steps: 487 Train Loss: 2.8120 (Forecasting Loss:0.3952 + XiCon Loss:2.4168 x Lambda(1.0)), Vali MSE Loss: 0.7248 Test MSE Loss: 0.5090
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 2.8564794
	speed: 0.0160s/iter; left time: 653.4312s
	iters: 200, epoch: 17 | loss: 2.7722349
	speed: 0.0140s/iter; left time: 567.9528s
	iters: 300, epoch: 17 | loss: 2.8981204
	speed: 0.0142s/iter; left time: 575.0323s
	iters: 400, epoch: 17 | loss: 2.7498260
	speed: 0.0140s/iter; left time: 568.9927s
Epoch: 17 cost time: 7.117919445037842
Epoch: 17, Steps: 487 Train Loss: 2.8162 (Forecasting Loss:0.3951 + XiCon Loss:2.4211 x Lambda(1.0)), Vali MSE Loss: 0.7242 Test MSE Loss: 0.5090
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 2.7809150
	speed: 0.0166s/iter; left time: 670.8318s
	iters: 200, epoch: 18 | loss: 2.8819335
	speed: 0.0156s/iter; left time: 628.7436s
	iters: 300, epoch: 18 | loss: 2.7693732
	speed: 0.0142s/iter; left time: 570.9174s
	iters: 400, epoch: 18 | loss: 2.7660046
	speed: 0.0115s/iter; left time: 458.6791s
Epoch: 18 cost time: 6.8306355476379395
Epoch: 18, Steps: 487 Train Loss: 2.8177 (Forecasting Loss:0.3949 + XiCon Loss:2.4228 x Lambda(1.0)), Vali MSE Loss: 0.7240 Test MSE Loss: 0.5090
Validation loss decreased (0.724125 --> 0.723978).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 2.8429277
	speed: 0.0154s/iter; left time: 614.6877s
	iters: 200, epoch: 19 | loss: 2.8825467
	speed: 0.0142s/iter; left time: 563.3999s
	iters: 300, epoch: 19 | loss: 2.7753568
	speed: 0.0135s/iter; left time: 535.0152s
	iters: 400, epoch: 19 | loss: 3.0258620
	speed: 0.0137s/iter; left time: 539.8834s
Epoch: 19 cost time: 6.9015116691589355
Epoch: 19, Steps: 487 Train Loss: 2.8139 (Forecasting Loss:0.3949 + XiCon Loss:2.4190 x Lambda(1.0)), Vali MSE Loss: 0.7241 Test MSE Loss: 0.5090
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 2.7667181
	speed: 0.0157s/iter; left time: 617.6887s
	iters: 200, epoch: 20 | loss: 2.7277327
	speed: 0.0130s/iter; left time: 508.8401s
	iters: 300, epoch: 20 | loss: 2.6598284
	speed: 0.0137s/iter; left time: 534.9208s
	iters: 400, epoch: 20 | loss: 2.8890646
	speed: 0.0137s/iter; left time: 534.7108s
Epoch: 20 cost time: 6.782148838043213
Epoch: 20, Steps: 487 Train Loss: 2.8191 (Forecasting Loss:0.3952 + XiCon Loss:2.4239 x Lambda(1.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5090
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 2.7042882
	speed: 0.0152s/iter; left time: 591.7080s
	iters: 200, epoch: 21 | loss: 2.8669333
	speed: 0.0135s/iter; left time: 522.0243s
	iters: 300, epoch: 21 | loss: 2.7339587
	speed: 0.0135s/iter; left time: 523.6237s
	iters: 400, epoch: 21 | loss: 2.8834357
	speed: 0.0142s/iter; left time: 547.2157s
Epoch: 21 cost time: 6.8433732986450195
Epoch: 21, Steps: 487 Train Loss: 2.8149 (Forecasting Loss:0.3952 + XiCon Loss:2.4196 x Lambda(1.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5090
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 2.8434684
	speed: 0.0159s/iter; left time: 608.5802s
	iters: 200, epoch: 22 | loss: 2.7349913
	speed: 0.0138s/iter; left time: 528.5467s
	iters: 300, epoch: 22 | loss: 2.9211762
	speed: 0.0140s/iter; left time: 535.0996s
	iters: 400, epoch: 22 | loss: 2.8162525
	speed: 0.0145s/iter; left time: 553.3942s
Epoch: 22 cost time: 7.039295434951782
Epoch: 22, Steps: 487 Train Loss: 2.8200 (Forecasting Loss:0.3953 + XiCon Loss:2.4247 x Lambda(1.0)), Vali MSE Loss: 0.7245 Test MSE Loss: 0.5090
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 2.8513620
	speed: 0.0160s/iter; left time: 604.7725s
	iters: 200, epoch: 23 | loss: 2.8249938
	speed: 0.0133s/iter; left time: 504.3729s
	iters: 300, epoch: 23 | loss: 2.7475693
	speed: 0.0134s/iter; left time: 504.9270s
	iters: 400, epoch: 23 | loss: 2.7553058
	speed: 0.0133s/iter; left time: 500.8904s
Epoch: 23 cost time: 6.803263187408447
Epoch: 23, Steps: 487 Train Loss: 2.8137 (Forecasting Loss:0.3950 + XiCon Loss:2.4187 x Lambda(1.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5090
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 2.8722644
	speed: 0.0162s/iter; left time: 604.8664s
	iters: 200, epoch: 24 | loss: 2.8614295
	speed: 0.0134s/iter; left time: 499.7888s
	iters: 300, epoch: 24 | loss: 2.7774391
	speed: 0.0134s/iter; left time: 498.1792s
	iters: 400, epoch: 24 | loss: 2.6645360
	speed: 0.0136s/iter; left time: 505.2980s
Epoch: 24 cost time: 6.8796820640563965
Epoch: 24, Steps: 487 Train Loss: 2.8175 (Forecasting Loss:0.3950 + XiCon Loss:2.4224 x Lambda(1.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5090
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 2.7625432
	speed: 0.0158s/iter; left time: 582.5024s
	iters: 200, epoch: 25 | loss: 2.8474870
	speed: 0.0137s/iter; left time: 503.3191s
	iters: 300, epoch: 25 | loss: 2.8069417
	speed: 0.0141s/iter; left time: 518.7520s
	iters: 400, epoch: 25 | loss: 2.8565729
	speed: 0.0163s/iter; left time: 596.3706s
Epoch: 25 cost time: 7.264753341674805
Epoch: 25, Steps: 487 Train Loss: 2.8151 (Forecasting Loss:0.3950 + XiCon Loss:2.4201 x Lambda(1.0)), Vali MSE Loss: 0.7239 Test MSE Loss: 0.5090
Validation loss decreased (0.723978 --> 0.723902).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 2.7878294
	speed: 0.0162s/iter; left time: 591.4595s
	iters: 200, epoch: 26 | loss: 2.7571187
	speed: 0.0140s/iter; left time: 507.8910s
	iters: 300, epoch: 26 | loss: 2.8437839
	speed: 0.0147s/iter; left time: 533.7894s
	iters: 400, epoch: 26 | loss: 2.6339531
	speed: 0.0142s/iter; left time: 513.6840s
Epoch: 26 cost time: 7.23018217086792
Epoch: 26, Steps: 487 Train Loss: 2.8180 (Forecasting Loss:0.3951 + XiCon Loss:2.4230 x Lambda(1.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5090
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 2.8254609
	speed: 0.0166s/iter; left time: 597.3906s
	iters: 200, epoch: 27 | loss: 2.9487436
	speed: 0.0138s/iter; left time: 494.9460s
	iters: 300, epoch: 27 | loss: 2.7684550
	speed: 0.0145s/iter; left time: 518.0906s
	iters: 400, epoch: 27 | loss: 2.6947465
	speed: 0.0153s/iter; left time: 545.6556s
Epoch: 27 cost time: 7.365461111068726
Epoch: 27, Steps: 487 Train Loss: 2.8154 (Forecasting Loss:0.3952 + XiCon Loss:2.4202 x Lambda(1.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5090
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 2.8721123
	speed: 0.0170s/iter; left time: 602.2595s
	iters: 200, epoch: 28 | loss: 2.7243350
	speed: 0.0143s/iter; left time: 506.9873s
	iters: 300, epoch: 28 | loss: 2.8056617
	speed: 0.0154s/iter; left time: 541.6360s
	iters: 400, epoch: 28 | loss: 2.8910840
	speed: 0.0152s/iter; left time: 533.9786s
Epoch: 28 cost time: 7.422389507293701
Epoch: 28, Steps: 487 Train Loss: 2.8150 (Forecasting Loss:0.3949 + XiCon Loss:2.4200 x Lambda(1.0)), Vali MSE Loss: 0.7245 Test MSE Loss: 0.5090
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 2.7886188
	speed: 0.0160s/iter; left time: 558.4575s
	iters: 200, epoch: 29 | loss: 2.9699087
	speed: 0.0146s/iter; left time: 509.7598s
	iters: 300, epoch: 29 | loss: 2.7780290
	speed: 0.0137s/iter; left time: 475.6383s
	iters: 400, epoch: 29 | loss: 2.8521144
	speed: 0.0145s/iter; left time: 501.1290s
Epoch: 29 cost time: 7.175450325012207
Epoch: 29, Steps: 487 Train Loss: 2.8172 (Forecasting Loss:0.3952 + XiCon Loss:2.4220 x Lambda(1.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5090
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 2.8057985
	speed: 0.0171s/iter; left time: 590.5061s
	iters: 200, epoch: 30 | loss: 2.8966684
	speed: 0.0154s/iter; left time: 528.4662s
	iters: 300, epoch: 30 | loss: 3.0392661
	speed: 0.0140s/iter; left time: 478.8010s
	iters: 400, epoch: 30 | loss: 2.8154054
	speed: 0.0145s/iter; left time: 497.0096s
Epoch: 30 cost time: 7.472092390060425
Epoch: 30, Steps: 487 Train Loss: 2.8188 (Forecasting Loss:0.3949 + XiCon Loss:2.4239 x Lambda(1.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5090
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 2.8877637
	speed: 0.0171s/iter; left time: 579.5605s
	iters: 200, epoch: 31 | loss: 2.8029556
	speed: 0.0146s/iter; left time: 496.4514s
	iters: 300, epoch: 31 | loss: 2.8188930
	speed: 0.0158s/iter; left time: 533.7839s
	iters: 400, epoch: 31 | loss: 2.8024387
	speed: 0.0143s/iter; left time: 480.8287s
Epoch: 31 cost time: 7.504412651062012
Epoch: 31, Steps: 487 Train Loss: 2.8165 (Forecasting Loss:0.3950 + XiCon Loss:2.4215 x Lambda(1.0)), Vali MSE Loss: 0.7240 Test MSE Loss: 0.5090
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 2.8064198
	speed: 0.0168s/iter; left time: 561.4882s
	iters: 200, epoch: 32 | loss: 2.8382444
	speed: 0.0139s/iter; left time: 463.2341s
	iters: 300, epoch: 32 | loss: 2.7172103
	speed: 0.0146s/iter; left time: 487.0352s
	iters: 400, epoch: 32 | loss: 2.7300591
	speed: 0.0142s/iter; left time: 470.1990s
Epoch: 32 cost time: 7.217817306518555
Epoch: 32, Steps: 487 Train Loss: 2.8149 (Forecasting Loss:0.3948 + XiCon Loss:2.4200 x Lambda(1.0)), Vali MSE Loss: 0.7245 Test MSE Loss: 0.5090
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 2.7888441
	speed: 0.0162s/iter; left time: 533.4668s
	iters: 200, epoch: 33 | loss: 2.7825308
	speed: 0.0149s/iter; left time: 490.6732s
	iters: 300, epoch: 33 | loss: 2.7735934
	speed: 0.0149s/iter; left time: 489.6793s
	iters: 400, epoch: 33 | loss: 2.8748195
	speed: 0.0142s/iter; left time: 464.7465s
Epoch: 33 cost time: 7.3138720989227295
Epoch: 33, Steps: 487 Train Loss: 2.8165 (Forecasting Loss:0.3951 + XiCon Loss:2.4214 x Lambda(1.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5090
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 2.7733912
	speed: 0.0182s/iter; left time: 591.9403s
	iters: 200, epoch: 34 | loss: 2.9161682
	speed: 0.0141s/iter; left time: 456.1658s
	iters: 300, epoch: 34 | loss: 2.7532079
	speed: 0.0146s/iter; left time: 471.2826s
	iters: 400, epoch: 34 | loss: 2.8625901
	speed: 0.0147s/iter; left time: 474.3135s
Epoch: 34 cost time: 7.467055559158325
Epoch: 34, Steps: 487 Train Loss: 2.8146 (Forecasting Loss:0.3949 + XiCon Loss:2.4198 x Lambda(1.0)), Vali MSE Loss: 0.7240 Test MSE Loss: 0.5090
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 2.8189344
	speed: 0.0157s/iter; left time: 503.6264s
	iters: 200, epoch: 35 | loss: 2.7493744
	speed: 0.0140s/iter; left time: 447.2366s
	iters: 300, epoch: 35 | loss: 2.7425966
	speed: 0.0145s/iter; left time: 461.1630s
	iters: 400, epoch: 35 | loss: 2.7263355
	speed: 0.0149s/iter; left time: 471.6148s
Epoch: 35 cost time: 7.2092125415802
Epoch: 35, Steps: 487 Train Loss: 2.8185 (Forecasting Loss:0.3950 + XiCon Loss:2.4235 x Lambda(1.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5090
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5146052837371826, mae:0.503319501876831, mape:3.4790823459625244, mspe:1132.8016357421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0486
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 3.1355929
	speed: 0.0175s/iter; left time: 852.2186s
	iters: 200, epoch: 1 | loss: 3.4001956
	speed: 0.0140s/iter; left time: 680.2352s
	iters: 300, epoch: 1 | loss: 2.9915516
	speed: 0.0138s/iter; left time: 667.5443s
	iters: 400, epoch: 1 | loss: 2.9968607
	speed: 0.0145s/iter; left time: 701.4614s
Epoch: 1 cost time: 7.2601025104522705
Epoch: 1, Steps: 487 Train Loss: 3.2132 (Forecasting Loss:0.7351 + XiCon Loss:2.4781 x Lambda(1.0)), Vali MSE Loss: 1.0316 Test MSE Loss: 0.6261
Validation loss decreased (inf --> 1.031557).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 2.8987606
	speed: 0.0164s/iter; left time: 789.8381s
	iters: 200, epoch: 2 | loss: 2.9619427
	speed: 0.0140s/iter; left time: 669.8760s
	iters: 300, epoch: 2 | loss: 2.9552207
	speed: 0.0142s/iter; left time: 682.1250s
	iters: 400, epoch: 2 | loss: 2.9779994
	speed: 0.0148s/iter; left time: 705.2990s
Epoch: 2 cost time: 7.1972222328186035
Epoch: 2, Steps: 487 Train Loss: 2.9001 (Forecasting Loss:0.4385 + XiCon Loss:2.4615 x Lambda(1.0)), Vali MSE Loss: 0.7331 Test MSE Loss: 0.5318
Validation loss decreased (1.031557 --> 0.733107).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 2.8626533
	speed: 0.0162s/iter; left time: 772.1002s
	iters: 200, epoch: 3 | loss: 2.7720895
	speed: 0.0147s/iter; left time: 696.7107s
	iters: 300, epoch: 3 | loss: 2.9277086
	speed: 0.0150s/iter; left time: 710.5878s
	iters: 400, epoch: 3 | loss: 2.8152106
	speed: 0.0151s/iter; left time: 712.5947s
Epoch: 3 cost time: 7.365962266921997
Epoch: 3, Steps: 487 Train Loss: 2.8323 (Forecasting Loss:0.4061 + XiCon Loss:2.4262 x Lambda(1.0)), Vali MSE Loss: 0.7170 Test MSE Loss: 0.5237
Validation loss decreased (0.733107 --> 0.717024).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 2.9729609
	speed: 0.0168s/iter; left time: 792.2441s
	iters: 200, epoch: 4 | loss: 2.8077590
	speed: 0.0155s/iter; left time: 730.5121s
	iters: 300, epoch: 4 | loss: 2.9039230
	speed: 0.0154s/iter; left time: 723.4058s
	iters: 400, epoch: 4 | loss: 3.0034711
	speed: 0.0149s/iter; left time: 696.6681s
Epoch: 4 cost time: 7.551797389984131
Epoch: 4, Steps: 487 Train Loss: 2.8159 (Forecasting Loss:0.4005 + XiCon Loss:2.4154 x Lambda(1.0)), Vali MSE Loss: 0.7117 Test MSE Loss: 0.5220
Validation loss decreased (0.717024 --> 0.711665).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 2.8711064
	speed: 0.0172s/iter; left time: 802.4505s
	iters: 200, epoch: 5 | loss: 2.8091469
	speed: 0.0138s/iter; left time: 643.7062s
	iters: 300, epoch: 5 | loss: 2.8451672
	speed: 0.0142s/iter; left time: 658.7177s
	iters: 400, epoch: 5 | loss: 2.7485065
	speed: 0.0144s/iter; left time: 667.6271s
Epoch: 5 cost time: 7.257745981216431
Epoch: 5, Steps: 487 Train Loss: 2.8154 (Forecasting Loss:0.3981 + XiCon Loss:2.4173 x Lambda(1.0)), Vali MSE Loss: 0.7087 Test MSE Loss: 0.5194
Validation loss decreased (0.711665 --> 0.708671).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 2.7554266
	speed: 0.0168s/iter; left time: 775.3787s
	iters: 200, epoch: 6 | loss: 2.7198875
	speed: 0.0143s/iter; left time: 661.0453s
	iters: 300, epoch: 6 | loss: 2.8019850
	speed: 0.0141s/iter; left time: 647.4568s
	iters: 400, epoch: 6 | loss: 2.7760568
	speed: 0.0151s/iter; left time: 690.8817s
Epoch: 6 cost time: 7.360226631164551
Epoch: 6, Steps: 487 Train Loss: 2.8151 (Forecasting Loss:0.3970 + XiCon Loss:2.4180 x Lambda(1.0)), Vali MSE Loss: 0.7064 Test MSE Loss: 0.5186
Validation loss decreased (0.708671 --> 0.706410).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 2.9011822
	speed: 0.0154s/iter; left time: 704.1523s
	iters: 200, epoch: 7 | loss: 2.7274742
	speed: 0.0139s/iter; left time: 633.7802s
	iters: 300, epoch: 7 | loss: 2.8244295
	speed: 0.0137s/iter; left time: 623.1429s
	iters: 400, epoch: 7 | loss: 2.6959393
	speed: 0.0143s/iter; left time: 650.0220s
Epoch: 7 cost time: 7.06352686882019
Epoch: 7, Steps: 487 Train Loss: 2.8071 (Forecasting Loss:0.3964 + XiCon Loss:2.4107 x Lambda(1.0)), Vali MSE Loss: 0.7065 Test MSE Loss: 0.5188
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 2.8389597
	speed: 0.0180s/iter; left time: 814.8246s
	iters: 200, epoch: 8 | loss: 2.8889608
	speed: 0.0146s/iter; left time: 656.6365s
	iters: 300, epoch: 8 | loss: 2.7533588
	speed: 0.0147s/iter; left time: 660.0605s
	iters: 400, epoch: 8 | loss: 2.6815686
	speed: 0.0139s/iter; left time: 623.0004s
Epoch: 8 cost time: 7.399621248245239
Epoch: 8, Steps: 487 Train Loss: 2.8054 (Forecasting Loss:0.3960 + XiCon Loss:2.4094 x Lambda(1.0)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5184
Validation loss decreased (0.706410 --> 0.705979).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 2.8444679
	speed: 0.0168s/iter; left time: 751.2123s
	iters: 200, epoch: 9 | loss: 2.8412399
	speed: 0.0138s/iter; left time: 614.6680s
	iters: 300, epoch: 9 | loss: 2.6871171
	speed: 0.0144s/iter; left time: 641.3631s
	iters: 400, epoch: 9 | loss: 2.9526467
	speed: 0.0140s/iter; left time: 623.3005s
Epoch: 9 cost time: 7.233407735824585
Epoch: 9, Steps: 487 Train Loss: 2.8051 (Forecasting Loss:0.3957 + XiCon Loss:2.4093 x Lambda(1.0)), Vali MSE Loss: 0.7052 Test MSE Loss: 0.5182
Validation loss decreased (0.705979 --> 0.705151).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 2.8000865
	speed: 0.0166s/iter; left time: 733.9259s
	iters: 200, epoch: 10 | loss: 2.8079453
	speed: 0.0145s/iter; left time: 637.6039s
	iters: 300, epoch: 10 | loss: 2.6652682
	speed: 0.0129s/iter; left time: 568.8862s
	iters: 400, epoch: 10 | loss: 2.7068236
	speed: 0.0120s/iter; left time: 528.1133s
Epoch: 10 cost time: 6.7662270069122314
Epoch: 10, Steps: 487 Train Loss: 2.8050 (Forecasting Loss:0.3959 + XiCon Loss:2.4092 x Lambda(1.0)), Vali MSE Loss: 0.7059 Test MSE Loss: 0.5182
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 2.7110007
	speed: 0.0166s/iter; left time: 724.7999s
	iters: 200, epoch: 11 | loss: 2.7746496
	speed: 0.0161s/iter; left time: 702.5806s
	iters: 300, epoch: 11 | loss: 2.7386985
	speed: 0.0141s/iter; left time: 613.5693s
	iters: 400, epoch: 11 | loss: 2.9855311
	speed: 0.0146s/iter; left time: 632.4584s
Epoch: 11 cost time: 7.44734263420105
Epoch: 11, Steps: 487 Train Loss: 2.7981 (Forecasting Loss:0.3956 + XiCon Loss:2.4025 x Lambda(1.0)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5182
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 2.8058209
	speed: 0.0179s/iter; left time: 773.9637s
	iters: 200, epoch: 12 | loss: 2.7940345
	speed: 0.0142s/iter; left time: 614.4942s
	iters: 300, epoch: 12 | loss: 2.7456362
	speed: 0.0137s/iter; left time: 590.2576s
	iters: 400, epoch: 12 | loss: 2.7434149
	speed: 0.0144s/iter; left time: 619.6724s
Epoch: 12 cost time: 7.405904531478882
Epoch: 12, Steps: 487 Train Loss: 2.8045 (Forecasting Loss:0.3957 + XiCon Loss:2.4088 x Lambda(1.0)), Vali MSE Loss: 0.7059 Test MSE Loss: 0.5182
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 2.7457523
	speed: 0.0169s/iter; left time: 720.4762s
	iters: 200, epoch: 13 | loss: 2.9240987
	speed: 0.0138s/iter; left time: 588.8603s
	iters: 300, epoch: 13 | loss: 2.8102553
	speed: 0.0150s/iter; left time: 639.3134s
	iters: 400, epoch: 13 | loss: 2.8345313
	speed: 0.0144s/iter; left time: 611.5413s
Epoch: 13 cost time: 7.275645732879639
Epoch: 13, Steps: 487 Train Loss: 2.8093 (Forecasting Loss:0.3959 + XiCon Loss:2.4135 x Lambda(1.0)), Vali MSE Loss: 0.7058 Test MSE Loss: 0.5182
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 2.9330418
	speed: 0.0168s/iter; left time: 711.1954s
	iters: 200, epoch: 14 | loss: 2.7763424
	speed: 0.0141s/iter; left time: 595.8702s
	iters: 300, epoch: 14 | loss: 2.7449613
	speed: 0.0154s/iter; left time: 646.3983s
	iters: 400, epoch: 14 | loss: 2.8520033
	speed: 0.0143s/iter; left time: 602.0285s
Epoch: 14 cost time: 7.326031923294067
Epoch: 14, Steps: 487 Train Loss: 2.8068 (Forecasting Loss:0.3956 + XiCon Loss:2.4112 x Lambda(1.0)), Vali MSE Loss: 0.7058 Test MSE Loss: 0.5182
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 2.9671087
	speed: 0.0164s/iter; left time: 686.7375s
	iters: 200, epoch: 15 | loss: 2.8223708
	speed: 0.0144s/iter; left time: 601.8859s
	iters: 300, epoch: 15 | loss: 2.8024831
	speed: 0.0146s/iter; left time: 607.7036s
	iters: 400, epoch: 15 | loss: 2.7146537
	speed: 0.0154s/iter; left time: 640.2236s
Epoch: 15 cost time: 7.395409107208252
Epoch: 15, Steps: 487 Train Loss: 2.8007 (Forecasting Loss:0.3955 + XiCon Loss:2.4052 x Lambda(1.0)), Vali MSE Loss: 0.7058 Test MSE Loss: 0.5182
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 2.7907391
	speed: 0.0163s/iter; left time: 671.8686s
	iters: 200, epoch: 16 | loss: 2.8093314
	speed: 0.0138s/iter; left time: 570.5367s
	iters: 300, epoch: 16 | loss: 2.8389807
	speed: 0.0145s/iter; left time: 597.0602s
	iters: 400, epoch: 16 | loss: 2.8287745
	speed: 0.0159s/iter; left time: 650.4599s
Epoch: 16 cost time: 7.343646049499512
Epoch: 16, Steps: 487 Train Loss: 2.8040 (Forecasting Loss:0.3956 + XiCon Loss:2.4085 x Lambda(1.0)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5182
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 2.7181845
	speed: 0.0163s/iter; left time: 663.4396s
	iters: 200, epoch: 17 | loss: 2.8158612
	speed: 0.0144s/iter; left time: 586.7198s
	iters: 300, epoch: 17 | loss: 2.7740402
	speed: 0.0158s/iter; left time: 640.8949s
	iters: 400, epoch: 17 | loss: 2.8855619
	speed: 0.0145s/iter; left time: 587.9328s
Epoch: 17 cost time: 7.4225013256073
Epoch: 17, Steps: 487 Train Loss: 2.8061 (Forecasting Loss:0.3957 + XiCon Loss:2.4104 x Lambda(1.0)), Vali MSE Loss: 0.7057 Test MSE Loss: 0.5182
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 2.7435470
	speed: 0.0168s/iter; left time: 675.9447s
	iters: 200, epoch: 18 | loss: 2.7773280
	speed: 0.0138s/iter; left time: 556.0172s
	iters: 300, epoch: 18 | loss: 2.9901786
	speed: 0.0142s/iter; left time: 570.6606s
	iters: 400, epoch: 18 | loss: 2.8676054
	speed: 0.0144s/iter; left time: 575.8308s
Epoch: 18 cost time: 7.217972278594971
Epoch: 18, Steps: 487 Train Loss: 2.8027 (Forecasting Loss:0.3955 + XiCon Loss:2.4072 x Lambda(1.0)), Vali MSE Loss: 0.7054 Test MSE Loss: 0.5182
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 2.7227433
	speed: 0.0169s/iter; left time: 671.7285s
	iters: 200, epoch: 19 | loss: 2.9059992
	speed: 0.0149s/iter; left time: 591.7592s
	iters: 300, epoch: 19 | loss: 2.8001025
	speed: 0.0154s/iter; left time: 611.9835s
	iters: 400, epoch: 19 | loss: 2.6413739
	speed: 0.0141s/iter; left time: 557.5851s
Epoch: 19 cost time: 7.438211441040039
Epoch: 19, Steps: 487 Train Loss: 2.8050 (Forecasting Loss:0.3958 + XiCon Loss:2.4092 x Lambda(1.0)), Vali MSE Loss: 0.7061 Test MSE Loss: 0.5182
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5263769626617432, mae:0.5100439786911011, mape:3.5089564323425293, mspe:1134.430419921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.0563
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 3.6378644
	speed: 0.0150s/iter; left time: 727.1799s
	iters: 200, epoch: 1 | loss: 3.2454753
	speed: 0.0128s/iter; left time: 618.9290s
	iters: 300, epoch: 1 | loss: 3.2716775
	speed: 0.0138s/iter; left time: 670.1068s
	iters: 400, epoch: 1 | loss: 3.2284238
	speed: 0.0135s/iter; left time: 652.6263s
Epoch: 1 cost time: 6.7300355434417725
Epoch: 1, Steps: 487 Train Loss: 3.3362 (Forecasting Loss:0.8410 + XiCon Loss:2.4952 x Lambda(1.0)), Vali MSE Loss: 1.1913 Test MSE Loss: 0.6741
Validation loss decreased (inf --> 1.191345).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 2.8346603
	speed: 0.0153s/iter; left time: 734.9568s
	iters: 200, epoch: 2 | loss: 2.8693976
	speed: 0.0129s/iter; left time: 621.3371s
	iters: 300, epoch: 2 | loss: 2.8348184
	speed: 0.0134s/iter; left time: 643.9286s
	iters: 400, epoch: 2 | loss: 2.9612153
	speed: 0.0133s/iter; left time: 636.3303s
Epoch: 2 cost time: 6.725656747817993
Epoch: 2, Steps: 487 Train Loss: 2.9038 (Forecasting Loss:0.4543 + XiCon Loss:2.4495 x Lambda(1.0)), Vali MSE Loss: 0.7444 Test MSE Loss: 0.5333
Validation loss decreased (1.191345 --> 0.744360).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 2.8170223
	speed: 0.0150s/iter; left time: 712.9564s
	iters: 200, epoch: 3 | loss: 2.7136083
	speed: 0.0131s/iter; left time: 624.3289s
	iters: 300, epoch: 3 | loss: 2.6767528
	speed: 0.0148s/iter; left time: 699.9015s
	iters: 400, epoch: 3 | loss: 2.7086637
	speed: 0.0136s/iter; left time: 645.6248s
Epoch: 3 cost time: 6.868811845779419
Epoch: 3, Steps: 487 Train Loss: 2.8346 (Forecasting Loss:0.4083 + XiCon Loss:2.4262 x Lambda(1.0)), Vali MSE Loss: 0.7307 Test MSE Loss: 0.5277
Validation loss decreased (0.744360 --> 0.730700).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 2.7881031
	speed: 0.0145s/iter; left time: 684.0406s
	iters: 200, epoch: 4 | loss: 2.6501257
	speed: 0.0140s/iter; left time: 659.5639s
	iters: 300, epoch: 4 | loss: 2.7364633
	speed: 0.0136s/iter; left time: 637.3396s
	iters: 400, epoch: 4 | loss: 2.7843156
	speed: 0.0129s/iter; left time: 603.8444s
Epoch: 4 cost time: 6.744047164916992
Epoch: 4, Steps: 487 Train Loss: 2.8183 (Forecasting Loss:0.4037 + XiCon Loss:2.4146 x Lambda(1.0)), Vali MSE Loss: 0.7250 Test MSE Loss: 0.5235
Validation loss decreased (0.730700 --> 0.725002).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 2.7242861
	speed: 0.0145s/iter; left time: 677.7106s
	iters: 200, epoch: 5 | loss: 2.7978802
	speed: 0.0138s/iter; left time: 643.2940s
	iters: 300, epoch: 5 | loss: 2.8865938
	speed: 0.0137s/iter; left time: 634.5883s
	iters: 400, epoch: 5 | loss: 2.8262560
	speed: 0.0139s/iter; left time: 643.8630s
Epoch: 5 cost time: 6.810196161270142
Epoch: 5, Steps: 487 Train Loss: 2.8163 (Forecasting Loss:0.4015 + XiCon Loss:2.4149 x Lambda(1.0)), Vali MSE Loss: 0.7242 Test MSE Loss: 0.5199
Validation loss decreased (0.725002 --> 0.724222).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 2.8173611
	speed: 0.0146s/iter; left time: 674.8018s
	iters: 200, epoch: 6 | loss: 2.7157919
	speed: 0.0131s/iter; left time: 602.6757s
	iters: 300, epoch: 6 | loss: 2.7897303
	speed: 0.0130s/iter; left time: 598.5113s
	iters: 400, epoch: 6 | loss: 2.7330058
	speed: 0.0136s/iter; left time: 621.6815s
Epoch: 6 cost time: 6.646114826202393
Epoch: 6, Steps: 487 Train Loss: 2.8129 (Forecasting Loss:0.3999 + XiCon Loss:2.4129 x Lambda(1.0)), Vali MSE Loss: 0.7215 Test MSE Loss: 0.5189
Validation loss decreased (0.724222 --> 0.721466).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 2.7497847
	speed: 0.0190s/iter; left time: 868.8751s
	iters: 200, epoch: 7 | loss: 2.7477539
	speed: 0.0136s/iter; left time: 619.9638s
	iters: 300, epoch: 7 | loss: 2.8993533
	speed: 0.0147s/iter; left time: 667.4590s
	iters: 400, epoch: 7 | loss: 2.8548155
	speed: 0.0152s/iter; left time: 688.7157s
Epoch: 7 cost time: 7.633374214172363
Epoch: 7, Steps: 487 Train Loss: 2.8150 (Forecasting Loss:0.3997 + XiCon Loss:2.4153 x Lambda(1.0)), Vali MSE Loss: 0.7213 Test MSE Loss: 0.5183
Validation loss decreased (0.721466 --> 0.721257).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 2.8219464
	speed: 0.0174s/iter; left time: 784.9162s
	iters: 200, epoch: 8 | loss: 2.7587218
	speed: 0.0139s/iter; left time: 624.9203s
	iters: 300, epoch: 8 | loss: 2.7874608
	speed: 0.0136s/iter; left time: 611.7056s
	iters: 400, epoch: 8 | loss: 2.6723628
	speed: 0.0148s/iter; left time: 666.5764s
Epoch: 8 cost time: 7.282095909118652
Epoch: 8, Steps: 487 Train Loss: 2.8113 (Forecasting Loss:0.3995 + XiCon Loss:2.4118 x Lambda(1.0)), Vali MSE Loss: 0.7215 Test MSE Loss: 0.5181
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 2.8510094
	speed: 0.0164s/iter; left time: 734.0303s
	iters: 200, epoch: 9 | loss: 2.8424711
	speed: 0.0137s/iter; left time: 611.8287s
	iters: 300, epoch: 9 | loss: 2.9205177
	speed: 0.0138s/iter; left time: 613.7923s
	iters: 400, epoch: 9 | loss: 2.7336030
	speed: 0.0152s/iter; left time: 673.4190s
Epoch: 9 cost time: 7.19455623626709
Epoch: 9, Steps: 487 Train Loss: 2.8128 (Forecasting Loss:0.3994 + XiCon Loss:2.4134 x Lambda(1.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.5180
Validation loss decreased (0.721257 --> 0.721117).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 2.8869612
	speed: 0.0160s/iter; left time: 708.3287s
	iters: 200, epoch: 10 | loss: 2.8830609
	speed: 0.0133s/iter; left time: 584.7533s
	iters: 300, epoch: 10 | loss: 2.7349668
	speed: 0.0134s/iter; left time: 587.8093s
	iters: 400, epoch: 10 | loss: 2.7609105
	speed: 0.0130s/iter; left time: 570.4190s
Epoch: 10 cost time: 6.670857667922974
Epoch: 10, Steps: 487 Train Loss: 2.8101 (Forecasting Loss:0.3991 + XiCon Loss:2.4110 x Lambda(1.0)), Vali MSE Loss: 0.7210 Test MSE Loss: 0.5179
Validation loss decreased (0.721117 --> 0.721018).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 2.7455962
	speed: 0.0166s/iter; left time: 727.3691s
	iters: 200, epoch: 11 | loss: 2.7388232
	speed: 0.0148s/iter; left time: 647.4366s
	iters: 300, epoch: 11 | loss: 2.8555651
	speed: 0.0150s/iter; left time: 650.8187s
	iters: 400, epoch: 11 | loss: 2.7921505
	speed: 0.0145s/iter; left time: 630.8702s
Epoch: 11 cost time: 7.415830612182617
Epoch: 11, Steps: 487 Train Loss: 2.8117 (Forecasting Loss:0.3993 + XiCon Loss:2.4123 x Lambda(1.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.5179
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 2.7859735
	speed: 0.0156s/iter; left time: 672.7557s
	iters: 200, epoch: 12 | loss: 2.8584466
	speed: 0.0123s/iter; left time: 531.8032s
	iters: 300, epoch: 12 | loss: 2.8219006
	speed: 0.0147s/iter; left time: 631.6349s
	iters: 400, epoch: 12 | loss: 2.7941058
	speed: 0.0149s/iter; left time: 641.3781s
Epoch: 12 cost time: 6.991321325302124
Epoch: 12, Steps: 487 Train Loss: 2.8110 (Forecasting Loss:0.3996 + XiCon Loss:2.4114 x Lambda(1.0)), Vali MSE Loss: 0.7210 Test MSE Loss: 0.5179
Validation loss decreased (0.721018 --> 0.720990).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 2.7181530
	speed: 0.0162s/iter; left time: 691.6858s
	iters: 200, epoch: 13 | loss: 2.7665615
	speed: 0.0152s/iter; left time: 646.3816s
	iters: 300, epoch: 13 | loss: 2.8423142
	speed: 0.0153s/iter; left time: 649.5038s
	iters: 400, epoch: 13 | loss: 2.8219659
	speed: 0.0149s/iter; left time: 632.2825s
Epoch: 13 cost time: 7.432652235031128
Epoch: 13, Steps: 487 Train Loss: 2.8100 (Forecasting Loss:0.3994 + XiCon Loss:2.4106 x Lambda(1.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.5179
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 2.7293067
	speed: 0.0166s/iter; left time: 702.8844s
	iters: 200, epoch: 14 | loss: 3.0163071
	speed: 0.0143s/iter; left time: 601.0468s
	iters: 300, epoch: 14 | loss: 2.8088479
	speed: 0.0138s/iter; left time: 580.8312s
	iters: 400, epoch: 14 | loss: 2.9862247
	speed: 0.0145s/iter; left time: 609.9602s
Epoch: 14 cost time: 7.2277727127075195
Epoch: 14, Steps: 487 Train Loss: 2.8072 (Forecasting Loss:0.3991 + XiCon Loss:2.4081 x Lambda(1.0)), Vali MSE Loss: 0.7206 Test MSE Loss: 0.5179
Validation loss decreased (0.720990 --> 0.720576).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 2.8001540
	speed: 0.0159s/iter; left time: 664.7169s
	iters: 200, epoch: 15 | loss: 2.8123665
	speed: 0.0150s/iter; left time: 624.4279s
	iters: 300, epoch: 15 | loss: 2.7528768
	speed: 0.0146s/iter; left time: 605.2619s
	iters: 400, epoch: 15 | loss: 2.7045133
	speed: 0.0145s/iter; left time: 603.0090s
Epoch: 15 cost time: 7.302801847457886
Epoch: 15, Steps: 487 Train Loss: 2.8094 (Forecasting Loss:0.3993 + XiCon Loss:2.4101 x Lambda(1.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5179
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 2.7467175
	speed: 0.0157s/iter; left time: 648.4419s
	iters: 200, epoch: 16 | loss: 2.8366423
	speed: 0.0146s/iter; left time: 603.4885s
	iters: 300, epoch: 16 | loss: 2.8071654
	speed: 0.0148s/iter; left time: 606.8037s
	iters: 400, epoch: 16 | loss: 2.8251810
	speed: 0.0143s/iter; left time: 587.2013s
Epoch: 16 cost time: 7.276670694351196
Epoch: 16, Steps: 487 Train Loss: 2.8127 (Forecasting Loss:0.3991 + XiCon Loss:2.4137 x Lambda(1.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.5179
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 2.8168092
	speed: 0.0156s/iter; left time: 637.3974s
	iters: 200, epoch: 17 | loss: 2.7826283
	speed: 0.0134s/iter; left time: 546.7398s
	iters: 300, epoch: 17 | loss: 2.8318510
	speed: 0.0149s/iter; left time: 604.1796s
	iters: 400, epoch: 17 | loss: 2.6834707
	speed: 0.0151s/iter; left time: 609.6919s
Epoch: 17 cost time: 7.211441278457642
Epoch: 17, Steps: 487 Train Loss: 2.8139 (Forecasting Loss:0.3997 + XiCon Loss:2.4142 x Lambda(1.0)), Vali MSE Loss: 0.7213 Test MSE Loss: 0.5179
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 2.7395277
	speed: 0.0154s/iter; left time: 621.2147s
	iters: 200, epoch: 18 | loss: 2.8992672
	speed: 0.0137s/iter; left time: 552.6891s
	iters: 300, epoch: 18 | loss: 2.7000411
	speed: 0.0143s/iter; left time: 574.5676s
	iters: 400, epoch: 18 | loss: 2.8832119
	speed: 0.0151s/iter; left time: 603.3254s
Epoch: 18 cost time: 7.064091920852661
Epoch: 18, Steps: 487 Train Loss: 2.8076 (Forecasting Loss:0.3991 + XiCon Loss:2.4085 x Lambda(1.0)), Vali MSE Loss: 0.7210 Test MSE Loss: 0.5179
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 2.7730927
	speed: 0.0163s/iter; left time: 647.8262s
	iters: 200, epoch: 19 | loss: 2.7822115
	speed: 0.0130s/iter; left time: 517.1371s
	iters: 300, epoch: 19 | loss: 2.8350892
	speed: 0.0138s/iter; left time: 546.0550s
	iters: 400, epoch: 19 | loss: 2.8007507
	speed: 0.0138s/iter; left time: 546.6189s
Epoch: 19 cost time: 6.799053907394409
Epoch: 19, Steps: 487 Train Loss: 2.8079 (Forecasting Loss:0.3994 + XiCon Loss:2.4086 x Lambda(1.0)), Vali MSE Loss: 0.7215 Test MSE Loss: 0.5179
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 2.6754336
	speed: 0.0162s/iter; left time: 638.3151s
	iters: 200, epoch: 20 | loss: 2.8247757
	speed: 0.0137s/iter; left time: 538.5164s
	iters: 300, epoch: 20 | loss: 2.7987509
	speed: 0.0151s/iter; left time: 591.6741s
	iters: 400, epoch: 20 | loss: 2.8633552
	speed: 0.0160s/iter; left time: 623.9499s
Epoch: 20 cost time: 7.463852167129517
Epoch: 20, Steps: 487 Train Loss: 2.8123 (Forecasting Loss:0.3994 + XiCon Loss:2.4129 x Lambda(1.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5179
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 2.8152380
	speed: 0.0157s/iter; left time: 608.3581s
	iters: 200, epoch: 21 | loss: 2.7985904
	speed: 0.0140s/iter; left time: 540.8512s
	iters: 300, epoch: 21 | loss: 2.7495625
	speed: 0.0135s/iter; left time: 522.9981s
	iters: 400, epoch: 21 | loss: 2.9395747
	speed: 0.0152s/iter; left time: 585.5321s
Epoch: 21 cost time: 7.1202404499053955
Epoch: 21, Steps: 487 Train Loss: 2.8129 (Forecasting Loss:0.3987 + XiCon Loss:2.4143 x Lambda(1.0)), Vali MSE Loss: 0.7213 Test MSE Loss: 0.5179
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 2.8741760
	speed: 0.0161s/iter; left time: 619.4488s
	iters: 200, epoch: 22 | loss: 2.9193051
	speed: 0.0146s/iter; left time: 559.5267s
	iters: 300, epoch: 22 | loss: 2.8242900
	speed: 0.0144s/iter; left time: 551.3782s
	iters: 400, epoch: 22 | loss: 2.8118949
	speed: 0.0152s/iter; left time: 577.6956s
Epoch: 22 cost time: 7.349641799926758
Epoch: 22, Steps: 487 Train Loss: 2.8119 (Forecasting Loss:0.3992 + XiCon Loss:2.4128 x Lambda(1.0)), Vali MSE Loss: 0.7205 Test MSE Loss: 0.5179
Validation loss decreased (0.720576 --> 0.720484).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 2.8612647
	speed: 0.0162s/iter; left time: 612.7554s
	iters: 200, epoch: 23 | loss: 2.7585967
	speed: 0.0139s/iter; left time: 524.1779s
	iters: 300, epoch: 23 | loss: 2.8285108
	speed: 0.0150s/iter; left time: 564.6540s
	iters: 400, epoch: 23 | loss: 2.7357781
	speed: 0.0148s/iter; left time: 555.0818s
Epoch: 23 cost time: 7.325358867645264
Epoch: 23, Steps: 487 Train Loss: 2.8157 (Forecasting Loss:0.3992 + XiCon Loss:2.4165 x Lambda(1.0)), Vali MSE Loss: 0.7212 Test MSE Loss: 0.5179
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 2.8095536
	speed: 0.0162s/iter; left time: 605.9473s
	iters: 200, epoch: 24 | loss: 2.7196703
	speed: 0.0136s/iter; left time: 506.2631s
	iters: 300, epoch: 24 | loss: 2.6986244
	speed: 0.0144s/iter; left time: 536.9143s
	iters: 400, epoch: 24 | loss: 2.9836969
	speed: 0.0141s/iter; left time: 523.7862s
Epoch: 24 cost time: 7.160682916641235
Epoch: 24, Steps: 487 Train Loss: 2.8123 (Forecasting Loss:0.3989 + XiCon Loss:2.4133 x Lambda(1.0)), Vali MSE Loss: 0.7214 Test MSE Loss: 0.5179
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 2.8325739
	speed: 0.0167s/iter; left time: 617.2021s
	iters: 200, epoch: 25 | loss: 2.4930553
	speed: 0.0136s/iter; left time: 499.5779s
	iters: 300, epoch: 25 | loss: 2.7479119
	speed: 0.0133s/iter; left time: 488.5346s
	iters: 400, epoch: 25 | loss: 2.7139823
	speed: 0.0137s/iter; left time: 500.0928s
Epoch: 25 cost time: 7.0100531578063965
Epoch: 25, Steps: 487 Train Loss: 2.8117 (Forecasting Loss:0.3993 + XiCon Loss:2.4123 x Lambda(1.0)), Vali MSE Loss: 0.7212 Test MSE Loss: 0.5179
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 2.9068880
	speed: 0.0178s/iter; left time: 649.3863s
	iters: 200, epoch: 26 | loss: 2.7414474
	speed: 0.0142s/iter; left time: 515.6464s
	iters: 300, epoch: 26 | loss: 2.8163898
	speed: 0.0140s/iter; left time: 505.8273s
	iters: 400, epoch: 26 | loss: 2.8122165
	speed: 0.0147s/iter; left time: 529.6249s
Epoch: 26 cost time: 7.404515981674194
Epoch: 26, Steps: 487 Train Loss: 2.8161 (Forecasting Loss:0.3993 + XiCon Loss:2.4168 x Lambda(1.0)), Vali MSE Loss: 0.7206 Test MSE Loss: 0.5179
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 2.7351940
	speed: 0.0166s/iter; left time: 596.2943s
	iters: 200, epoch: 27 | loss: 2.7198923
	speed: 0.0136s/iter; left time: 488.3541s
	iters: 300, epoch: 27 | loss: 2.8843298
	speed: 0.0140s/iter; left time: 501.2115s
	iters: 400, epoch: 27 | loss: 2.8172586
	speed: 0.0148s/iter; left time: 527.4995s
Epoch: 27 cost time: 7.194820404052734
Epoch: 27, Steps: 487 Train Loss: 2.8094 (Forecasting Loss:0.3990 + XiCon Loss:2.4104 x Lambda(1.0)), Vali MSE Loss: 0.7208 Test MSE Loss: 0.5179
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 2.8580551
	speed: 0.0159s/iter; left time: 563.4225s
	iters: 200, epoch: 28 | loss: 2.8433793
	speed: 0.0145s/iter; left time: 512.6976s
	iters: 300, epoch: 28 | loss: 2.8824992
	speed: 0.0141s/iter; left time: 498.0742s
	iters: 400, epoch: 28 | loss: 2.8036373
	speed: 0.0146s/iter; left time: 511.5860s
Epoch: 28 cost time: 7.188549280166626
Epoch: 28, Steps: 487 Train Loss: 2.8160 (Forecasting Loss:0.3993 + XiCon Loss:2.4168 x Lambda(1.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5179
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 2.8646326
	speed: 0.0163s/iter; left time: 570.3469s
	iters: 200, epoch: 29 | loss: 2.8313384
	speed: 0.0138s/iter; left time: 479.6333s
	iters: 300, epoch: 29 | loss: 2.8874526
	speed: 0.0144s/iter; left time: 501.9381s
	iters: 400, epoch: 29 | loss: 2.8716867
	speed: 0.0154s/iter; left time: 534.4342s
Epoch: 29 cost time: 7.25724983215332
Epoch: 29, Steps: 487 Train Loss: 2.8124 (Forecasting Loss:0.3994 + XiCon Loss:2.4129 x Lambda(1.0)), Vali MSE Loss: 0.7208 Test MSE Loss: 0.5179
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 2.9530671
	speed: 0.0157s/iter; left time: 540.9039s
	iters: 200, epoch: 30 | loss: 2.8393512
	speed: 0.0140s/iter; left time: 480.2556s
	iters: 300, epoch: 30 | loss: 2.9537315
	speed: 0.0149s/iter; left time: 512.3874s
	iters: 400, epoch: 30 | loss: 2.7362831
	speed: 0.0155s/iter; left time: 530.8002s
Epoch: 30 cost time: 7.2482428550720215
Epoch: 30, Steps: 487 Train Loss: 2.8067 (Forecasting Loss:0.3994 + XiCon Loss:2.4073 x Lambda(1.0)), Vali MSE Loss: 0.7205 Test MSE Loss: 0.5179
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 2.8184938
	speed: 0.0163s/iter; left time: 552.9243s
	iters: 200, epoch: 31 | loss: 2.7122118
	speed: 0.0153s/iter; left time: 519.7238s
	iters: 300, epoch: 31 | loss: 2.8622499
	speed: 0.0153s/iter; left time: 516.4223s
	iters: 400, epoch: 31 | loss: 2.7877331
	speed: 0.0145s/iter; left time: 489.0207s
Epoch: 31 cost time: 7.441417694091797
Epoch: 31, Steps: 487 Train Loss: 2.8157 (Forecasting Loss:0.3991 + XiCon Loss:2.4167 x Lambda(1.0)), Vali MSE Loss: 0.7203 Test MSE Loss: 0.5179
Validation loss decreased (0.720484 --> 0.720303).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 2.6164415
	speed: 0.0153s/iter; left time: 511.9422s
	iters: 200, epoch: 32 | loss: 2.7533550
	speed: 0.0139s/iter; left time: 464.0527s
	iters: 300, epoch: 32 | loss: 2.7810004
	speed: 0.0151s/iter; left time: 502.7018s
	iters: 400, epoch: 32 | loss: 2.7720761
	speed: 0.0144s/iter; left time: 478.5972s
Epoch: 32 cost time: 7.140994071960449
Epoch: 32, Steps: 487 Train Loss: 2.8039 (Forecasting Loss:0.3994 + XiCon Loss:2.4045 x Lambda(1.0)), Vali MSE Loss: 0.7214 Test MSE Loss: 0.5179
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 2.7571855
	speed: 0.0163s/iter; left time: 536.8599s
	iters: 200, epoch: 33 | loss: 3.0104971
	speed: 0.0142s/iter; left time: 466.9275s
	iters: 300, epoch: 33 | loss: 2.8190458
	speed: 0.0147s/iter; left time: 483.8746s
	iters: 400, epoch: 33 | loss: 2.7670794
	speed: 0.0143s/iter; left time: 466.7778s
Epoch: 33 cost time: 7.222781658172607
Epoch: 33, Steps: 487 Train Loss: 2.8110 (Forecasting Loss:0.3991 + XiCon Loss:2.4119 x Lambda(1.0)), Vali MSE Loss: 0.7214 Test MSE Loss: 0.5179
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 2.9222844
	speed: 0.0164s/iter; left time: 534.9714s
	iters: 200, epoch: 34 | loss: 2.8797619
	speed: 0.0141s/iter; left time: 455.9205s
	iters: 300, epoch: 34 | loss: 2.7753158
	speed: 0.0148s/iter; left time: 477.7035s
	iters: 400, epoch: 34 | loss: 2.7463810
	speed: 0.0152s/iter; left time: 488.7225s
Epoch: 34 cost time: 7.39647912979126
Epoch: 34, Steps: 487 Train Loss: 2.8136 (Forecasting Loss:0.3991 + XiCon Loss:2.4145 x Lambda(1.0)), Vali MSE Loss: 0.7215 Test MSE Loss: 0.5179
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 2.7877398
	speed: 0.0163s/iter; left time: 523.2579s
	iters: 200, epoch: 35 | loss: 2.6308825
	speed: 0.0138s/iter; left time: 442.0042s
	iters: 300, epoch: 35 | loss: 2.7983031
	speed: 0.0148s/iter; left time: 470.0771s
	iters: 400, epoch: 35 | loss: 2.9098694
	speed: 0.0147s/iter; left time: 465.8916s
Epoch: 35 cost time: 7.299588918685913
Epoch: 35, Steps: 487 Train Loss: 2.8129 (Forecasting Loss:0.3990 + XiCon Loss:2.4139 x Lambda(1.0)), Vali MSE Loss: 0.7207 Test MSE Loss: 0.5179
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 2.9656360
	speed: 0.0164s/iter; left time: 517.3689s
	iters: 200, epoch: 36 | loss: 2.8793960
	speed: 0.0143s/iter; left time: 451.1264s
	iters: 300, epoch: 36 | loss: 2.8403645
	speed: 0.0140s/iter; left time: 437.5403s
	iters: 400, epoch: 36 | loss: 2.8606830
	speed: 0.0141s/iter; left time: 441.7250s
Epoch: 36 cost time: 7.222951650619507
Epoch: 36, Steps: 487 Train Loss: 2.8105 (Forecasting Loss:0.3993 + XiCon Loss:2.4112 x Lambda(1.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.5179
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 2.8436506
	speed: 0.0156s/iter; left time: 483.6747s
	iters: 200, epoch: 37 | loss: 2.6881278
	speed: 0.0131s/iter; left time: 406.5389s
	iters: 300, epoch: 37 | loss: 2.8195362
	speed: 0.0148s/iter; left time: 456.0821s
	iters: 400, epoch: 37 | loss: 2.9323869
	speed: 0.0141s/iter; left time: 434.3440s
Epoch: 37 cost time: 6.9799439907073975
Epoch: 37, Steps: 487 Train Loss: 2.8135 (Forecasting Loss:0.3993 + XiCon Loss:2.4142 x Lambda(1.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5179
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 2.8274944
	speed: 0.0160s/iter; left time: 488.9336s
	iters: 200, epoch: 38 | loss: 2.8390357
	speed: 0.0136s/iter; left time: 414.7700s
	iters: 300, epoch: 38 | loss: 2.7463143
	speed: 0.0138s/iter; left time: 418.3916s
	iters: 400, epoch: 38 | loss: 2.8519456
	speed: 0.0145s/iter; left time: 437.8367s
Epoch: 38 cost time: 7.088821649551392
Epoch: 38, Steps: 487 Train Loss: 2.8148 (Forecasting Loss:0.3992 + XiCon Loss:2.4156 x Lambda(1.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5179
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 2.8901100
	speed: 0.0156s/iter; left time: 469.9462s
	iters: 200, epoch: 39 | loss: 2.7544782
	speed: 0.0134s/iter; left time: 402.2682s
	iters: 300, epoch: 39 | loss: 2.8344953
	speed: 0.0149s/iter; left time: 445.9132s
	iters: 400, epoch: 39 | loss: 2.8833144
	speed: 0.0153s/iter; left time: 457.2966s
Epoch: 39 cost time: 7.238767147064209
Epoch: 39, Steps: 487 Train Loss: 2.8073 (Forecasting Loss:0.3989 + XiCon Loss:2.4084 x Lambda(1.0)), Vali MSE Loss: 0.7208 Test MSE Loss: 0.5179
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 3.0107059
	speed: 0.0149s/iter; left time: 440.4258s
	iters: 200, epoch: 40 | loss: 2.6824913
	speed: 0.0127s/iter; left time: 374.2987s
	iters: 300, epoch: 40 | loss: 2.7648406
	speed: 0.0129s/iter; left time: 380.3808s
	iters: 400, epoch: 40 | loss: 2.7060089
	speed: 0.0144s/iter; left time: 421.3625s
Epoch: 40 cost time: 6.7086615562438965
Epoch: 40, Steps: 487 Train Loss: 2.8089 (Forecasting Loss:0.3994 + XiCon Loss:2.4095 x Lambda(1.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5179
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 2.9629827
	speed: 0.0151s/iter; left time: 440.4610s
	iters: 200, epoch: 41 | loss: 2.6248357
	speed: 0.0132s/iter; left time: 381.6446s
	iters: 300, epoch: 41 | loss: 2.8065767
	speed: 0.0136s/iter; left time: 392.1032s
	iters: 400, epoch: 41 | loss: 2.7922010
	speed: 0.0138s/iter; left time: 397.9792s
Epoch: 41 cost time: 6.787398099899292
Epoch: 41, Steps: 487 Train Loss: 2.8087 (Forecasting Loss:0.3991 + XiCon Loss:2.4096 x Lambda(1.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.5179
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5253067016601562, mae:0.5104525089263916, mape:3.561997175216675, mspe:1185.8778076171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7106
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 3.5693669
	speed: 0.0147s/iter; left time: 716.7978s
	iters: 200, epoch: 1 | loss: 3.1759312
	speed: 0.0126s/iter; left time: 608.8895s
	iters: 300, epoch: 1 | loss: 3.2219033
	speed: 0.0132s/iter; left time: 639.1671s
	iters: 400, epoch: 1 | loss: 3.1815460
	speed: 0.0132s/iter; left time: 636.2807s
Epoch: 1 cost time: 6.596838474273682
Epoch: 1, Steps: 487 Train Loss: 3.2537 (Forecasting Loss:0.8033 + XiCon Loss:2.4504 x Lambda(1.0)), Vali MSE Loss: 1.1102 Test MSE Loss: 0.6633
Validation loss decreased (inf --> 1.110160).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 3.0032320
	speed: 0.0148s/iter; left time: 710.1308s
	iters: 200, epoch: 2 | loss: 2.9133039
	speed: 0.0131s/iter; left time: 628.5904s
	iters: 300, epoch: 2 | loss: 2.7513261
	speed: 0.0131s/iter; left time: 626.2718s
	iters: 400, epoch: 2 | loss: 2.6526809
	speed: 0.0133s/iter; left time: 634.1888s
Epoch: 2 cost time: 6.644769668579102
Epoch: 2, Steps: 487 Train Loss: 2.8666 (Forecasting Loss:0.4358 + XiCon Loss:2.4308 x Lambda(1.0)), Vali MSE Loss: 0.7501 Test MSE Loss: 0.5134
Validation loss decreased (1.110160 --> 0.750126).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 2.9487619
	speed: 0.0149s/iter; left time: 711.3024s
	iters: 200, epoch: 3 | loss: 2.8468232
	speed: 0.0129s/iter; left time: 610.9561s
	iters: 300, epoch: 3 | loss: 2.7876492
	speed: 0.0141s/iter; left time: 667.2632s
	iters: 400, epoch: 3 | loss: 2.9065926
	speed: 0.0140s/iter; left time: 664.6305s
Epoch: 3 cost time: 7.064005136489868
Epoch: 3, Steps: 487 Train Loss: 2.8194 (Forecasting Loss:0.4029 + XiCon Loss:2.4164 x Lambda(1.0)), Vali MSE Loss: 0.7446 Test MSE Loss: 0.5071
Validation loss decreased (0.750126 --> 0.744556).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 2.8756223
	speed: 0.0163s/iter; left time: 767.8971s
	iters: 200, epoch: 4 | loss: 2.7901855
	speed: 0.0135s/iter; left time: 636.3719s
	iters: 300, epoch: 4 | loss: 2.9335146
	speed: 0.0140s/iter; left time: 658.4941s
	iters: 400, epoch: 4 | loss: 2.7495012
	speed: 0.0164s/iter; left time: 766.3145s
Epoch: 4 cost time: 7.383363723754883
Epoch: 4, Steps: 487 Train Loss: 2.8106 (Forecasting Loss:0.3982 + XiCon Loss:2.4124 x Lambda(1.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5060
Validation loss decreased (0.744556 --> 0.736406).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 2.8535712
	speed: 0.0160s/iter; left time: 748.6523s
	iters: 200, epoch: 5 | loss: 2.9378343
	speed: 0.0142s/iter; left time: 661.2765s
	iters: 300, epoch: 5 | loss: 2.8525000
	speed: 0.0140s/iter; left time: 649.1210s
	iters: 400, epoch: 5 | loss: 2.7668636
	speed: 0.0152s/iter; left time: 702.5294s
Epoch: 5 cost time: 7.2150983810424805
Epoch: 5, Steps: 487 Train Loss: 2.8083 (Forecasting Loss:0.3960 + XiCon Loss:2.4123 x Lambda(1.0)), Vali MSE Loss: 0.7338 Test MSE Loss: 0.5053
Validation loss decreased (0.736406 --> 0.733776).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 2.7544987
	speed: 0.0164s/iter; left time: 759.0223s
	iters: 200, epoch: 6 | loss: 2.7564538
	speed: 0.0138s/iter; left time: 637.7169s
	iters: 300, epoch: 6 | loss: 2.7927575
	speed: 0.0136s/iter; left time: 625.5451s
	iters: 400, epoch: 6 | loss: 2.9851062
	speed: 0.0145s/iter; left time: 665.4170s
Epoch: 6 cost time: 7.111491441726685
Epoch: 6, Steps: 487 Train Loss: 2.8035 (Forecasting Loss:0.3949 + XiCon Loss:2.4086 x Lambda(1.0)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5053
Validation loss decreased (0.733776 --> 0.731867).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 2.8076477
	speed: 0.0164s/iter; left time: 751.4041s
	iters: 200, epoch: 7 | loss: 2.6397917
	speed: 0.0148s/iter; left time: 674.7937s
	iters: 300, epoch: 7 | loss: 2.7949896
	speed: 0.0145s/iter; left time: 659.6487s
	iters: 400, epoch: 7 | loss: 2.7318912
	speed: 0.0150s/iter; left time: 679.7730s
Epoch: 7 cost time: 7.421358823776245
Epoch: 7, Steps: 487 Train Loss: 2.7974 (Forecasting Loss:0.3945 + XiCon Loss:2.4029 x Lambda(1.0)), Vali MSE Loss: 0.7320 Test MSE Loss: 0.5048
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 2.8263040
	speed: 0.0175s/iter; left time: 789.9976s
	iters: 200, epoch: 8 | loss: 2.9192719
	speed: 0.0140s/iter; left time: 629.1906s
	iters: 300, epoch: 8 | loss: 2.7854497
	speed: 0.0138s/iter; left time: 619.0248s
	iters: 400, epoch: 8 | loss: 2.6656742
	speed: 0.0145s/iter; left time: 652.7167s
Epoch: 8 cost time: 7.317350625991821
Epoch: 8, Steps: 487 Train Loss: 2.7974 (Forecasting Loss:0.3944 + XiCon Loss:2.4031 x Lambda(1.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5045
Validation loss decreased (0.731867 --> 0.731320).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 2.8219619
	speed: 0.0165s/iter; left time: 736.3414s
	iters: 200, epoch: 9 | loss: 2.6604376
	speed: 0.0144s/iter; left time: 641.4817s
	iters: 300, epoch: 9 | loss: 2.8242202
	speed: 0.0140s/iter; left time: 624.7693s
	iters: 400, epoch: 9 | loss: 2.7049987
	speed: 0.0147s/iter; left time: 651.4621s
Epoch: 9 cost time: 7.2045440673828125
Epoch: 9, Steps: 487 Train Loss: 2.8013 (Forecasting Loss:0.3942 + XiCon Loss:2.4072 x Lambda(1.0)), Vali MSE Loss: 0.7315 Test MSE Loss: 0.5044
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 2.8288121
	speed: 0.0160s/iter; left time: 707.1867s
	iters: 200, epoch: 10 | loss: 2.8887346
	speed: 0.0133s/iter; left time: 587.7780s
	iters: 300, epoch: 10 | loss: 2.9328432
	speed: 0.0159s/iter; left time: 698.5964s
	iters: 400, epoch: 10 | loss: 2.8503428
	speed: 0.0144s/iter; left time: 630.9481s
Epoch: 10 cost time: 7.292336702346802
Epoch: 10, Steps: 487 Train Loss: 2.7975 (Forecasting Loss:0.3941 + XiCon Loss:2.4033 x Lambda(1.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5044
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 2.7393241
	speed: 0.0159s/iter; left time: 695.7566s
	iters: 200, epoch: 11 | loss: 2.7963090
	speed: 0.0127s/iter; left time: 551.9820s
	iters: 300, epoch: 11 | loss: 2.6752317
	speed: 0.0150s/iter; left time: 651.2254s
	iters: 400, epoch: 11 | loss: 2.8165612
	speed: 0.0146s/iter; left time: 634.1232s
Epoch: 11 cost time: 7.17371129989624
Epoch: 11, Steps: 487 Train Loss: 2.7981 (Forecasting Loss:0.3941 + XiCon Loss:2.4040 x Lambda(1.0)), Vali MSE Loss: 0.7311 Test MSE Loss: 0.5044
Validation loss decreased (0.731320 --> 0.731116).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 2.9254613
	speed: 0.0162s/iter; left time: 700.1518s
	iters: 200, epoch: 12 | loss: 2.7102864
	speed: 0.0143s/iter; left time: 617.0022s
	iters: 300, epoch: 12 | loss: 2.6972079
	speed: 0.0143s/iter; left time: 617.6309s
	iters: 400, epoch: 12 | loss: 2.7116442
	speed: 0.0140s/iter; left time: 599.5961s
Epoch: 12 cost time: 7.162380695343018
Epoch: 12, Steps: 487 Train Loss: 2.8029 (Forecasting Loss:0.3941 + XiCon Loss:2.4088 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 2.8081932
	speed: 0.0164s/iter; left time: 700.0977s
	iters: 200, epoch: 13 | loss: 2.7931116
	speed: 0.0146s/iter; left time: 624.7456s
	iters: 300, epoch: 13 | loss: 2.6414044
	speed: 0.0144s/iter; left time: 613.4658s
	iters: 400, epoch: 13 | loss: 2.7343035
	speed: 0.0145s/iter; left time: 615.9530s
Epoch: 13 cost time: 7.3299548625946045
Epoch: 13, Steps: 487 Train Loss: 2.7972 (Forecasting Loss:0.3939 + XiCon Loss:2.4032 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 2.7881558
	speed: 0.0163s/iter; left time: 687.1886s
	iters: 200, epoch: 14 | loss: 2.8119259
	speed: 0.0142s/iter; left time: 600.0371s
	iters: 300, epoch: 14 | loss: 2.7185650
	speed: 0.0148s/iter; left time: 621.3573s
	iters: 400, epoch: 14 | loss: 2.7459583
	speed: 0.0144s/iter; left time: 604.9494s
Epoch: 14 cost time: 7.176009654998779
Epoch: 14, Steps: 487 Train Loss: 2.7980 (Forecasting Loss:0.3939 + XiCon Loss:2.4041 x Lambda(1.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5044
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 2.7778728
	speed: 0.0164s/iter; left time: 685.2199s
	iters: 200, epoch: 15 | loss: 2.7949538
	speed: 0.0144s/iter; left time: 599.4291s
	iters: 300, epoch: 15 | loss: 2.9307346
	speed: 0.0147s/iter; left time: 610.6925s
	iters: 400, epoch: 15 | loss: 2.8748369
	speed: 0.0144s/iter; left time: 595.3166s
Epoch: 15 cost time: 7.280115365982056
Epoch: 15, Steps: 487 Train Loss: 2.7959 (Forecasting Loss:0.3942 + XiCon Loss:2.4017 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 2.7144504
	speed: 0.0158s/iter; left time: 652.6807s
	iters: 200, epoch: 16 | loss: 2.6765528
	speed: 0.0144s/iter; left time: 592.4402s
	iters: 300, epoch: 16 | loss: 2.7197073
	speed: 0.0144s/iter; left time: 591.5909s
	iters: 400, epoch: 16 | loss: 2.6739302
	speed: 0.0146s/iter; left time: 599.6344s
Epoch: 16 cost time: 7.209967374801636
Epoch: 16, Steps: 487 Train Loss: 2.7939 (Forecasting Loss:0.3942 + XiCon Loss:2.3997 x Lambda(1.0)), Vali MSE Loss: 0.7316 Test MSE Loss: 0.5044
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 2.8105121
	speed: 0.0169s/iter; left time: 688.5219s
	iters: 200, epoch: 17 | loss: 2.8145492
	speed: 0.0151s/iter; left time: 613.8234s
	iters: 300, epoch: 17 | loss: 2.7405136
	speed: 0.0149s/iter; left time: 605.3261s
	iters: 400, epoch: 17 | loss: 2.8676310
	speed: 0.0143s/iter; left time: 579.0967s
Epoch: 17 cost time: 7.397152900695801
Epoch: 17, Steps: 487 Train Loss: 2.8041 (Forecasting Loss:0.3939 + XiCon Loss:2.4102 x Lambda(1.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5044
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 2.8837986
	speed: 0.0167s/iter; left time: 674.7891s
	iters: 200, epoch: 18 | loss: 2.8312912
	speed: 0.0141s/iter; left time: 566.3230s
	iters: 300, epoch: 18 | loss: 2.7443500
	speed: 0.0139s/iter; left time: 559.1656s
	iters: 400, epoch: 18 | loss: 2.8323011
	speed: 0.0144s/iter; left time: 577.1184s
Epoch: 18 cost time: 7.264435052871704
Epoch: 18, Steps: 487 Train Loss: 2.7996 (Forecasting Loss:0.3941 + XiCon Loss:2.4055 x Lambda(1.0)), Vali MSE Loss: 0.7311 Test MSE Loss: 0.5044
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 2.8009107
	speed: 0.0164s/iter; left time: 652.4920s
	iters: 200, epoch: 19 | loss: 2.7016959
	speed: 0.0140s/iter; left time: 556.7672s
	iters: 300, epoch: 19 | loss: 2.6610599
	speed: 0.0149s/iter; left time: 589.6001s
	iters: 400, epoch: 19 | loss: 2.9909461
	speed: 0.0145s/iter; left time: 574.8917s
Epoch: 19 cost time: 7.317006587982178
Epoch: 19, Steps: 487 Train Loss: 2.8011 (Forecasting Loss:0.3942 + XiCon Loss:2.4069 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 2.8460197
	speed: 0.0155s/iter; left time: 611.4710s
	iters: 200, epoch: 20 | loss: 2.8129351
	speed: 0.0141s/iter; left time: 551.7692s
	iters: 300, epoch: 20 | loss: 2.6478548
	speed: 0.0142s/iter; left time: 556.2297s
	iters: 400, epoch: 20 | loss: 2.8129416
	speed: 0.0154s/iter; left time: 601.5899s
Epoch: 20 cost time: 7.234373569488525
Epoch: 20, Steps: 487 Train Loss: 2.7998 (Forecasting Loss:0.3942 + XiCon Loss:2.4056 x Lambda(1.0)), Vali MSE Loss: 0.7311 Test MSE Loss: 0.5044
Validation loss decreased (0.731116 --> 0.731053).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 2.8974197
	speed: 0.0163s/iter; left time: 631.8321s
	iters: 200, epoch: 21 | loss: 2.6499426
	speed: 0.0136s/iter; left time: 528.3750s
	iters: 300, epoch: 21 | loss: 2.7534134
	speed: 0.0139s/iter; left time: 535.4654s
	iters: 400, epoch: 21 | loss: 2.8100305
	speed: 0.0150s/iter; left time: 578.6188s
Epoch: 21 cost time: 7.165345668792725
Epoch: 21, Steps: 487 Train Loss: 2.8042 (Forecasting Loss:0.3941 + XiCon Loss:2.4102 x Lambda(1.0)), Vali MSE Loss: 0.7316 Test MSE Loss: 0.5044
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 2.7224336
	speed: 0.0156s/iter; left time: 598.7266s
	iters: 200, epoch: 22 | loss: 2.7824585
	speed: 0.0144s/iter; left time: 551.6523s
	iters: 300, epoch: 22 | loss: 2.9065416
	speed: 0.0136s/iter; left time: 519.5337s
	iters: 400, epoch: 22 | loss: 2.7689986
	speed: 0.0149s/iter; left time: 566.5110s
Epoch: 22 cost time: 7.143736839294434
Epoch: 22, Steps: 487 Train Loss: 2.8023 (Forecasting Loss:0.3939 + XiCon Loss:2.4084 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 2.7538662
	speed: 0.0160s/iter; left time: 604.4077s
	iters: 200, epoch: 23 | loss: 2.6986837
	speed: 0.0150s/iter; left time: 567.4887s
	iters: 300, epoch: 23 | loss: 2.8010817
	speed: 0.0148s/iter; left time: 557.2065s
	iters: 400, epoch: 23 | loss: 2.9101760
	speed: 0.0143s/iter; left time: 539.2177s
Epoch: 23 cost time: 7.038236856460571
Epoch: 23, Steps: 487 Train Loss: 2.8007 (Forecasting Loss:0.3941 + XiCon Loss:2.4066 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 2.8101079
	speed: 0.0161s/iter; left time: 601.4782s
	iters: 200, epoch: 24 | loss: 2.8959169
	speed: 0.0142s/iter; left time: 530.9187s
	iters: 300, epoch: 24 | loss: 2.7230937
	speed: 0.0140s/iter; left time: 519.8746s
	iters: 400, epoch: 24 | loss: 2.8511977
	speed: 0.0151s/iter; left time: 561.8496s
Epoch: 24 cost time: 7.140740633010864
Epoch: 24, Steps: 487 Train Loss: 2.7965 (Forecasting Loss:0.3941 + XiCon Loss:2.4024 x Lambda(1.0)), Vali MSE Loss: 0.7314 Test MSE Loss: 0.5044
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 2.7672224
	speed: 0.0155s/iter; left time: 573.7592s
	iters: 200, epoch: 25 | loss: 2.7403400
	speed: 0.0134s/iter; left time: 494.9591s
	iters: 300, epoch: 25 | loss: 2.8434384
	speed: 0.0137s/iter; left time: 502.3326s
	iters: 400, epoch: 25 | loss: 2.8286791
	speed: 0.0147s/iter; left time: 538.4192s
Epoch: 25 cost time: 7.088346004486084
Epoch: 25, Steps: 487 Train Loss: 2.8023 (Forecasting Loss:0.3939 + XiCon Loss:2.4084 x Lambda(1.0)), Vali MSE Loss: 0.7308 Test MSE Loss: 0.5044
Validation loss decreased (0.731053 --> 0.730782).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 2.7466862
	speed: 0.0159s/iter; left time: 578.6984s
	iters: 200, epoch: 26 | loss: 2.7546728
	speed: 0.0140s/iter; left time: 509.1343s
	iters: 300, epoch: 26 | loss: 2.8761072
	speed: 0.0141s/iter; left time: 509.6953s
	iters: 400, epoch: 26 | loss: 2.9261553
	speed: 0.0145s/iter; left time: 524.3744s
Epoch: 26 cost time: 7.272026062011719
Epoch: 26, Steps: 487 Train Loss: 2.7974 (Forecasting Loss:0.3937 + XiCon Loss:2.4037 x Lambda(1.0)), Vali MSE Loss: 0.7316 Test MSE Loss: 0.5044
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 2.8552895
	speed: 0.0157s/iter; left time: 563.4917s
	iters: 200, epoch: 27 | loss: 2.8701138
	speed: 0.0137s/iter; left time: 491.5420s
	iters: 300, epoch: 27 | loss: 2.7525287
	speed: 0.0143s/iter; left time: 510.2012s
	iters: 400, epoch: 27 | loss: 2.7857873
	speed: 0.0151s/iter; left time: 536.7879s
Epoch: 27 cost time: 7.198421955108643
Epoch: 27, Steps: 487 Train Loss: 2.8018 (Forecasting Loss:0.3938 + XiCon Loss:2.4080 x Lambda(1.0)), Vali MSE Loss: 0.7314 Test MSE Loss: 0.5044
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 2.8207538
	speed: 0.0158s/iter; left time: 558.8726s
	iters: 200, epoch: 28 | loss: 2.7590098
	speed: 0.0144s/iter; left time: 508.8944s
	iters: 300, epoch: 28 | loss: 2.7272196
	speed: 0.0152s/iter; left time: 537.4975s
	iters: 400, epoch: 28 | loss: 2.8612707
	speed: 0.0140s/iter; left time: 491.2107s
Epoch: 28 cost time: 7.222437858581543
Epoch: 28, Steps: 487 Train Loss: 2.7989 (Forecasting Loss:0.3942 + XiCon Loss:2.4048 x Lambda(1.0)), Vali MSE Loss: 0.7307 Test MSE Loss: 0.5044
Validation loss decreased (0.730782 --> 0.730686).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 2.8188601
	speed: 0.0153s/iter; left time: 533.4215s
	iters: 200, epoch: 29 | loss: 2.8023567
	speed: 0.0133s/iter; left time: 461.9633s
	iters: 300, epoch: 29 | loss: 2.8215983
	speed: 0.0138s/iter; left time: 481.3085s
	iters: 400, epoch: 29 | loss: 2.8827496
	speed: 0.0148s/iter; left time: 511.5624s
Epoch: 29 cost time: 6.871935606002808
Epoch: 29, Steps: 487 Train Loss: 2.7994 (Forecasting Loss:0.3941 + XiCon Loss:2.4052 x Lambda(1.0)), Vali MSE Loss: 0.7309 Test MSE Loss: 0.5044
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 2.8082798
	speed: 0.0162s/iter; left time: 557.5016s
	iters: 200, epoch: 30 | loss: 2.8148921
	speed: 0.0137s/iter; left time: 471.7218s
	iters: 300, epoch: 30 | loss: 2.7611561
	speed: 0.0139s/iter; left time: 477.8572s
	iters: 400, epoch: 30 | loss: 2.7826104
	speed: 0.0150s/iter; left time: 511.6929s
Epoch: 30 cost time: 7.252405643463135
Epoch: 30, Steps: 487 Train Loss: 2.8029 (Forecasting Loss:0.3942 + XiCon Loss:2.4088 x Lambda(1.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5044
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 2.6538017
	speed: 0.0157s/iter; left time: 531.9905s
	iters: 200, epoch: 31 | loss: 2.6314416
	speed: 0.0136s/iter; left time: 460.9288s
	iters: 300, epoch: 31 | loss: 2.9015241
	speed: 0.0147s/iter; left time: 495.6344s
	iters: 400, epoch: 31 | loss: 2.8105218
	speed: 0.0148s/iter; left time: 498.3242s
Epoch: 31 cost time: 7.206629276275635
Epoch: 31, Steps: 487 Train Loss: 2.7988 (Forecasting Loss:0.3939 + XiCon Loss:2.4049 x Lambda(1.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5044
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 2.9114287
	speed: 0.0164s/iter; left time: 550.5256s
	iters: 200, epoch: 32 | loss: 2.9470885
	speed: 0.0137s/iter; left time: 457.5235s
	iters: 300, epoch: 32 | loss: 2.7358704
	speed: 0.0139s/iter; left time: 463.2417s
	iters: 400, epoch: 32 | loss: 2.7421958
	speed: 0.0142s/iter; left time: 470.1598s
Epoch: 32 cost time: 7.24111533164978
Epoch: 32, Steps: 487 Train Loss: 2.8004 (Forecasting Loss:0.3941 + XiCon Loss:2.4063 x Lambda(1.0)), Vali MSE Loss: 0.7310 Test MSE Loss: 0.5044
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 2.8215408
	speed: 0.0162s/iter; left time: 536.1352s
	iters: 200, epoch: 33 | loss: 2.9145880
	speed: 0.0153s/iter; left time: 503.3460s
	iters: 300, epoch: 33 | loss: 2.8199377
	speed: 0.0147s/iter; left time: 482.1003s
	iters: 400, epoch: 33 | loss: 2.7182381
	speed: 0.0144s/iter; left time: 471.9905s
Epoch: 33 cost time: 7.353252172470093
Epoch: 33, Steps: 487 Train Loss: 2.7963 (Forecasting Loss:0.3939 + XiCon Loss:2.4024 x Lambda(1.0)), Vali MSE Loss: 0.7312 Test MSE Loss: 0.5044
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 2.6823611
	speed: 0.0158s/iter; left time: 514.5197s
	iters: 200, epoch: 34 | loss: 2.9461837
	speed: 0.0136s/iter; left time: 440.2455s
	iters: 300, epoch: 34 | loss: 2.7075572
	speed: 0.0144s/iter; left time: 466.6918s
	iters: 400, epoch: 34 | loss: 2.8127289
	speed: 0.0150s/iter; left time: 483.9025s
Epoch: 34 cost time: 7.2216410636901855
Epoch: 34, Steps: 487 Train Loss: 2.7984 (Forecasting Loss:0.3942 + XiCon Loss:2.4043 x Lambda(1.0)), Vali MSE Loss: 0.7316 Test MSE Loss: 0.5044
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 2.7963660
	speed: 0.0160s/iter; left time: 511.3745s
	iters: 200, epoch: 35 | loss: 2.7663040
	speed: 0.0153s/iter; left time: 490.1479s
	iters: 300, epoch: 35 | loss: 2.8352578
	speed: 0.0146s/iter; left time: 464.0039s
	iters: 400, epoch: 35 | loss: 2.8242579
	speed: 0.0146s/iter; left time: 462.1317s
Epoch: 35 cost time: 7.393622636795044
Epoch: 35, Steps: 487 Train Loss: 2.7975 (Forecasting Loss:0.3942 + XiCon Loss:2.4033 x Lambda(1.0)), Vali MSE Loss: 0.7310 Test MSE Loss: 0.5044
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 2.7277915
	speed: 0.0163s/iter; left time: 515.7880s
	iters: 200, epoch: 36 | loss: 2.8645813
	speed: 0.0138s/iter; left time: 434.8552s
	iters: 300, epoch: 36 | loss: 2.6748252
	speed: 0.0146s/iter; left time: 458.4280s
	iters: 400, epoch: 36 | loss: 2.7310417
	speed: 0.0135s/iter; left time: 423.3300s
Epoch: 36 cost time: 7.0559563636779785
Epoch: 36, Steps: 487 Train Loss: 2.7985 (Forecasting Loss:0.3938 + XiCon Loss:2.4047 x Lambda(1.0)), Vali MSE Loss: 0.7308 Test MSE Loss: 0.5044
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 2.6049163
	speed: 0.0153s/iter; left time: 474.9629s
	iters: 200, epoch: 37 | loss: 2.7724547
	speed: 0.0129s/iter; left time: 399.7832s
	iters: 300, epoch: 37 | loss: 2.7692721
	speed: 0.0131s/iter; left time: 404.2482s
	iters: 400, epoch: 37 | loss: 2.7062578
	speed: 0.0145s/iter; left time: 447.5480s
Epoch: 37 cost time: 6.846171855926514
Epoch: 37, Steps: 487 Train Loss: 2.7963 (Forecasting Loss:0.3941 + XiCon Loss:2.4022 x Lambda(1.0)), Vali MSE Loss: 0.7311 Test MSE Loss: 0.5044
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 2.7488291
	speed: 0.0151s/iter; left time: 460.6496s
	iters: 200, epoch: 38 | loss: 2.7408519
	speed: 0.0137s/iter; left time: 418.5493s
	iters: 300, epoch: 38 | loss: 2.7995601
	speed: 0.0133s/iter; left time: 405.1317s
	iters: 400, epoch: 38 | loss: 2.8740187
	speed: 0.0132s/iter; left time: 398.2213s
Epoch: 38 cost time: 6.760968208312988
Epoch: 38, Steps: 487 Train Loss: 2.8047 (Forecasting Loss:0.3941 + XiCon Loss:2.4106 x Lambda(1.0)), Vali MSE Loss: 0.7314 Test MSE Loss: 0.5044
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5073215961456299, mae:0.5014951229095459, mape:3.6259584426879883, mspe:1224.5228271484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.2972
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 3.3260651
	speed: 0.0200s/iter; left time: 973.3529s
	iters: 200, epoch: 1 | loss: 3.3742480
	speed: 0.0121s/iter; left time: 587.1703s
	iters: 300, epoch: 1 | loss: 3.1503797
	speed: 0.0111s/iter; left time: 537.4919s
	iters: 400, epoch: 1 | loss: 3.1973929
	speed: 0.0114s/iter; left time: 551.4207s
Epoch: 1 cost time: 6.470568656921387
Epoch: 1, Steps: 487 Train Loss: 3.2397 (Forecasting Loss:0.7532 + XiCon Loss:2.4865 x Lambda(1.0)), Vali MSE Loss: 1.0054 Test MSE Loss: 0.6212
Validation loss decreased (inf --> 1.005448).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 3.0583606
	speed: 0.0153s/iter; left time: 735.2368s
	iters: 200, epoch: 2 | loss: 2.8538966
	speed: 0.0113s/iter; left time: 541.5070s
	iters: 300, epoch: 2 | loss: 3.0129731
	speed: 0.0115s/iter; left time: 550.1050s
	iters: 400, epoch: 2 | loss: 2.7009306
	speed: 0.0113s/iter; left time: 539.9573s
Epoch: 2 cost time: 5.917789936065674
Epoch: 2, Steps: 487 Train Loss: 2.8849 (Forecasting Loss:0.4359 + XiCon Loss:2.4490 x Lambda(1.0)), Vali MSE Loss: 0.7634 Test MSE Loss: 0.5380
Validation loss decreased (1.005448 --> 0.763381).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 2.8391171
	speed: 0.0140s/iter; left time: 665.7976s
	iters: 200, epoch: 3 | loss: 2.7448263
	speed: 0.0116s/iter; left time: 550.4081s
	iters: 300, epoch: 3 | loss: 2.9557405
	speed: 0.0109s/iter; left time: 517.8712s
	iters: 400, epoch: 3 | loss: 2.7318888
	speed: 0.0111s/iter; left time: 526.1299s
Epoch: 3 cost time: 6.10983943939209
Epoch: 3, Steps: 487 Train Loss: 2.8285 (Forecasting Loss:0.4059 + XiCon Loss:2.4226 x Lambda(1.0)), Vali MSE Loss: 0.7470 Test MSE Loss: 0.5202
Validation loss decreased (0.763381 --> 0.747017).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 2.9955623
	speed: 0.0157s/iter; left time: 740.3702s
	iters: 200, epoch: 4 | loss: 2.7673912
	speed: 0.0129s/iter; left time: 607.1116s
	iters: 300, epoch: 4 | loss: 2.7391591
	speed: 0.0136s/iter; left time: 640.4584s
	iters: 400, epoch: 4 | loss: 2.7562501
	speed: 0.0136s/iter; left time: 638.0889s
Epoch: 4 cost time: 6.740483283996582
Epoch: 4, Steps: 487 Train Loss: 2.8133 (Forecasting Loss:0.4001 + XiCon Loss:2.4132 x Lambda(1.0)), Vali MSE Loss: 0.7477 Test MSE Loss: 0.5189
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 2.8579078
	speed: 0.0149s/iter; left time: 695.0085s
	iters: 200, epoch: 5 | loss: 2.8416896
	speed: 0.0123s/iter; left time: 572.5555s
	iters: 300, epoch: 5 | loss: 2.8545694
	speed: 0.0114s/iter; left time: 531.0549s
	iters: 400, epoch: 5 | loss: 2.9292068
	speed: 0.0148s/iter; left time: 688.1393s
Epoch: 5 cost time: 6.4153547286987305
Epoch: 5, Steps: 487 Train Loss: 2.8116 (Forecasting Loss:0.3981 + XiCon Loss:2.4136 x Lambda(1.0)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5141
Validation loss decreased (0.747017 --> 0.738960).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 2.9243248
	speed: 0.0147s/iter; left time: 678.1571s
	iters: 200, epoch: 6 | loss: 2.9232416
	speed: 0.0122s/iter; left time: 561.1510s
	iters: 300, epoch: 6 | loss: 2.9268758
	speed: 0.0122s/iter; left time: 562.7811s
	iters: 400, epoch: 6 | loss: 2.9010217
	speed: 0.0115s/iter; left time: 525.6969s
Epoch: 6 cost time: 6.1318113803863525
Epoch: 6, Steps: 487 Train Loss: 2.8135 (Forecasting Loss:0.3970 + XiCon Loss:2.4165 x Lambda(1.0)), Vali MSE Loss: 0.7373 Test MSE Loss: 0.5132
Validation loss decreased (0.738960 --> 0.737276).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 2.7237830
	speed: 0.0145s/iter; left time: 662.8902s
	iters: 200, epoch: 7 | loss: 2.8661573
	speed: 0.0116s/iter; left time: 530.3583s
	iters: 300, epoch: 7 | loss: 2.6889689
	speed: 0.0114s/iter; left time: 517.3436s
	iters: 400, epoch: 7 | loss: 2.8495524
	speed: 0.0128s/iter; left time: 583.0517s
Epoch: 7 cost time: 6.177323579788208
Epoch: 7, Steps: 487 Train Loss: 2.8068 (Forecasting Loss:0.3965 + XiCon Loss:2.4103 x Lambda(1.0)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5141
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 2.7337244
	speed: 0.0156s/iter; left time: 706.4690s
	iters: 200, epoch: 8 | loss: 2.8470016
	speed: 0.0125s/iter; left time: 565.0808s
	iters: 300, epoch: 8 | loss: 2.8796358
	speed: 0.0134s/iter; left time: 604.7188s
	iters: 400, epoch: 8 | loss: 2.8168166
	speed: 0.0125s/iter; left time: 562.0035s
Epoch: 8 cost time: 6.516624689102173
Epoch: 8, Steps: 487 Train Loss: 2.8085 (Forecasting Loss:0.3961 + XiCon Loss:2.4123 x Lambda(1.0)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5133
Validation loss decreased (0.737276 --> 0.736885).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 2.7585998
	speed: 0.0153s/iter; left time: 681.8700s
	iters: 200, epoch: 9 | loss: 2.8297157
	speed: 0.0122s/iter; left time: 545.6225s
	iters: 300, epoch: 9 | loss: 2.9374199
	speed: 0.0124s/iter; left time: 553.3024s
	iters: 400, epoch: 9 | loss: 2.8503110
	speed: 0.0121s/iter; left time: 536.1942s
Epoch: 9 cost time: 6.330158948898315
Epoch: 9, Steps: 487 Train Loss: 2.8092 (Forecasting Loss:0.3959 + XiCon Loss:2.4133 x Lambda(1.0)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5134
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 2.7779784
	speed: 0.0155s/iter; left time: 686.2034s
	iters: 200, epoch: 10 | loss: 2.7828491
	speed: 0.0137s/iter; left time: 605.1066s
	iters: 300, epoch: 10 | loss: 2.6680851
	speed: 0.0120s/iter; left time: 527.8106s
	iters: 400, epoch: 10 | loss: 2.8415341
	speed: 0.0113s/iter; left time: 495.7414s
Epoch: 10 cost time: 6.501074552536011
Epoch: 10, Steps: 487 Train Loss: 2.8119 (Forecasting Loss:0.3961 + XiCon Loss:2.4157 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5133
Validation loss decreased (0.736885 --> 0.736737).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 2.7893164
	speed: 0.0153s/iter; left time: 667.8564s
	iters: 200, epoch: 11 | loss: 2.7820709
	speed: 0.0124s/iter; left time: 540.8165s
	iters: 300, epoch: 11 | loss: 2.6826217
	speed: 0.0132s/iter; left time: 575.4629s
	iters: 400, epoch: 11 | loss: 2.8431370
	speed: 0.0131s/iter; left time: 570.0168s
Epoch: 11 cost time: 6.558365345001221
Epoch: 11, Steps: 487 Train Loss: 2.8073 (Forecasting Loss:0.3959 + XiCon Loss:2.4114 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 2.7976594
	speed: 0.0149s/iter; left time: 644.2862s
	iters: 200, epoch: 12 | loss: 2.7047138
	speed: 0.0123s/iter; left time: 529.6295s
	iters: 300, epoch: 12 | loss: 2.7936778
	speed: 0.0130s/iter; left time: 561.0960s
	iters: 400, epoch: 12 | loss: 2.8708286
	speed: 0.0119s/iter; left time: 510.0867s
Epoch: 12 cost time: 6.342337608337402
Epoch: 12, Steps: 487 Train Loss: 2.8041 (Forecasting Loss:0.3960 + XiCon Loss:2.4081 x Lambda(1.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5132
Validation loss decreased (0.736737 --> 0.736381).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 2.7307734
	speed: 0.0161s/iter; left time: 687.3143s
	iters: 200, epoch: 13 | loss: 2.8130260
	speed: 0.0126s/iter; left time: 536.6589s
	iters: 300, epoch: 13 | loss: 2.7494624
	speed: 0.0126s/iter; left time: 535.6691s
	iters: 400, epoch: 13 | loss: 2.7328122
	speed: 0.0123s/iter; left time: 520.6947s
Epoch: 13 cost time: 6.417218208312988
Epoch: 13, Steps: 487 Train Loss: 2.8104 (Forecasting Loss:0.3959 + XiCon Loss:2.4145 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 2.8387914
	speed: 0.0157s/iter; left time: 664.8991s
	iters: 200, epoch: 14 | loss: 2.7029696
	speed: 0.0132s/iter; left time: 556.0651s
	iters: 300, epoch: 14 | loss: 2.8658423
	speed: 0.0125s/iter; left time: 525.9269s
	iters: 400, epoch: 14 | loss: 2.7644510
	speed: 0.0130s/iter; left time: 544.5606s
Epoch: 14 cost time: 6.6440699100494385
Epoch: 14, Steps: 487 Train Loss: 2.8101 (Forecasting Loss:0.3957 + XiCon Loss:2.4144 x Lambda(1.0)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 2.8493052
	speed: 0.0152s/iter; left time: 634.4978s
	iters: 200, epoch: 15 | loss: 2.7364206
	speed: 0.0126s/iter; left time: 525.8856s
	iters: 300, epoch: 15 | loss: 2.8803110
	speed: 0.0122s/iter; left time: 506.5592s
	iters: 400, epoch: 15 | loss: 2.9790695
	speed: 0.0127s/iter; left time: 527.4103s
Epoch: 15 cost time: 6.381420850753784
Epoch: 15, Steps: 487 Train Loss: 2.8123 (Forecasting Loss:0.3959 + XiCon Loss:2.4164 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 2.7853892
	speed: 0.0152s/iter; left time: 625.9081s
	iters: 200, epoch: 16 | loss: 2.8369632
	speed: 0.0132s/iter; left time: 542.9659s
	iters: 300, epoch: 16 | loss: 2.7460084
	speed: 0.0125s/iter; left time: 513.7182s
	iters: 400, epoch: 16 | loss: 2.7835617
	speed: 0.0130s/iter; left time: 531.9310s
Epoch: 16 cost time: 6.499498128890991
Epoch: 16, Steps: 487 Train Loss: 2.8065 (Forecasting Loss:0.3960 + XiCon Loss:2.4105 x Lambda(1.0)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5132
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 2.8103695
	speed: 0.0147s/iter; left time: 598.4057s
	iters: 200, epoch: 17 | loss: 2.7321727
	speed: 0.0133s/iter; left time: 542.4468s
	iters: 300, epoch: 17 | loss: 2.8083041
	speed: 0.0126s/iter; left time: 512.8239s
	iters: 400, epoch: 17 | loss: 2.6097503
	speed: 0.0128s/iter; left time: 518.4773s
Epoch: 17 cost time: 6.4523961544036865
Epoch: 17, Steps: 487 Train Loss: 2.8058 (Forecasting Loss:0.3958 + XiCon Loss:2.4100 x Lambda(1.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5132
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 2.8017371
	speed: 0.0146s/iter; left time: 588.9384s
	iters: 200, epoch: 18 | loss: 2.7649584
	speed: 0.0120s/iter; left time: 481.7352s
	iters: 300, epoch: 18 | loss: 2.8463464
	speed: 0.0117s/iter; left time: 470.1285s
	iters: 400, epoch: 18 | loss: 2.6473789
	speed: 0.0118s/iter; left time: 472.9708s
Epoch: 18 cost time: 6.176668405532837
Epoch: 18, Steps: 487 Train Loss: 2.8088 (Forecasting Loss:0.3959 + XiCon Loss:2.4129 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 2.8461254
	speed: 0.0154s/iter; left time: 611.6743s
	iters: 200, epoch: 19 | loss: 2.8665431
	speed: 0.0140s/iter; left time: 556.6536s
	iters: 300, epoch: 19 | loss: 2.7649312
	speed: 0.0133s/iter; left time: 526.8452s
	iters: 400, epoch: 19 | loss: 2.8880615
	speed: 0.0121s/iter; left time: 477.8661s
Epoch: 19 cost time: 6.585997581481934
Epoch: 19, Steps: 487 Train Loss: 2.8068 (Forecasting Loss:0.3959 + XiCon Loss:2.4110 x Lambda(1.0)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5132
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 2.7509460
	speed: 0.0151s/iter; left time: 592.3359s
	iters: 200, epoch: 20 | loss: 2.7100720
	speed: 0.0133s/iter; left time: 523.8257s
	iters: 300, epoch: 20 | loss: 2.9393108
	speed: 0.0138s/iter; left time: 538.7253s
	iters: 400, epoch: 20 | loss: 2.8599579
	speed: 0.0129s/iter; left time: 502.7799s
Epoch: 20 cost time: 6.692195177078247
Epoch: 20, Steps: 487 Train Loss: 2.8092 (Forecasting Loss:0.3958 + XiCon Loss:2.4134 x Lambda(1.0)), Vali MSE Loss: 0.7361 Test MSE Loss: 0.5132
Validation loss decreased (0.736381 --> 0.736074).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 2.8420434
	speed: 0.0155s/iter; left time: 600.4570s
	iters: 200, epoch: 21 | loss: 2.7357161
	speed: 0.0129s/iter; left time: 499.4011s
	iters: 300, epoch: 21 | loss: 2.6803861
	speed: 0.0131s/iter; left time: 507.9164s
	iters: 400, epoch: 21 | loss: 2.7811522
	speed: 0.0151s/iter; left time: 581.3263s
Epoch: 21 cost time: 7.0119781494140625
Epoch: 21, Steps: 487 Train Loss: 2.8077 (Forecasting Loss:0.3958 + XiCon Loss:2.4120 x Lambda(1.0)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 2.8341091
	speed: 0.0166s/iter; left time: 637.5889s
	iters: 200, epoch: 22 | loss: 2.7915339
	speed: 0.0127s/iter; left time: 487.0581s
	iters: 300, epoch: 22 | loss: 2.6551147
	speed: 0.0123s/iter; left time: 469.0544s
	iters: 400, epoch: 22 | loss: 2.6914570
	speed: 0.0129s/iter; left time: 492.3631s
Epoch: 22 cost time: 6.529516935348511
Epoch: 22, Steps: 487 Train Loss: 2.8056 (Forecasting Loss:0.3959 + XiCon Loss:2.4097 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 2.8161552
	speed: 0.0157s/iter; left time: 595.5291s
	iters: 200, epoch: 23 | loss: 2.8185375
	speed: 0.0130s/iter; left time: 489.6959s
	iters: 300, epoch: 23 | loss: 2.9185064
	speed: 0.0128s/iter; left time: 480.8997s
	iters: 400, epoch: 23 | loss: 2.9153764
	speed: 0.0131s/iter; left time: 493.0557s
Epoch: 23 cost time: 6.554747104644775
Epoch: 23, Steps: 487 Train Loss: 2.8064 (Forecasting Loss:0.3960 + XiCon Loss:2.4103 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 2.7420940
	speed: 0.0159s/iter; left time: 592.8103s
	iters: 200, epoch: 24 | loss: 2.8632898
	speed: 0.0129s/iter; left time: 483.0149s
	iters: 300, epoch: 24 | loss: 2.7014360
	speed: 0.0122s/iter; left time: 452.7840s
	iters: 400, epoch: 24 | loss: 2.8661072
	speed: 0.0121s/iter; left time: 447.3182s
Epoch: 24 cost time: 6.46404504776001
Epoch: 24, Steps: 487 Train Loss: 2.8051 (Forecasting Loss:0.3960 + XiCon Loss:2.4091 x Lambda(1.0)), Vali MSE Loss: 0.7360 Test MSE Loss: 0.5132
Validation loss decreased (0.736074 --> 0.735987).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 2.9509068
	speed: 0.0162s/iter; left time: 597.7835s
	iters: 200, epoch: 25 | loss: 2.8765965
	speed: 0.0125s/iter; left time: 460.5597s
	iters: 300, epoch: 25 | loss: 2.8588295
	speed: 0.0137s/iter; left time: 504.3812s
	iters: 400, epoch: 25 | loss: 2.8064542
	speed: 0.0131s/iter; left time: 478.0394s
Epoch: 25 cost time: 6.663180351257324
Epoch: 25, Steps: 487 Train Loss: 2.8107 (Forecasting Loss:0.3959 + XiCon Loss:2.4148 x Lambda(1.0)), Vali MSE Loss: 0.7362 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 2.9288321
	speed: 0.0147s/iter; left time: 533.6729s
	iters: 200, epoch: 26 | loss: 2.8317370
	speed: 0.0128s/iter; left time: 463.9383s
	iters: 300, epoch: 26 | loss: 2.7409701
	speed: 0.0127s/iter; left time: 459.3481s
	iters: 400, epoch: 26 | loss: 2.8502421
	speed: 0.0125s/iter; left time: 450.3791s
Epoch: 26 cost time: 6.407074928283691
Epoch: 26, Steps: 487 Train Loss: 2.8073 (Forecasting Loss:0.3957 + XiCon Loss:2.4116 x Lambda(1.0)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 2.9148111
	speed: 0.0149s/iter; left time: 534.9433s
	iters: 200, epoch: 27 | loss: 3.0859265
	speed: 0.0125s/iter; left time: 449.5399s
	iters: 300, epoch: 27 | loss: 2.8095860
	speed: 0.0125s/iter; left time: 445.9008s
	iters: 400, epoch: 27 | loss: 2.6866744
	speed: 0.0118s/iter; left time: 419.3671s
Epoch: 27 cost time: 6.275027513504028
Epoch: 27, Steps: 487 Train Loss: 2.8074 (Forecasting Loss:0.3957 + XiCon Loss:2.4116 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 2.6081085
	speed: 0.0148s/iter; left time: 523.7928s
	iters: 200, epoch: 28 | loss: 2.7759075
	speed: 0.0122s/iter; left time: 430.3800s
	iters: 300, epoch: 28 | loss: 2.9075615
	speed: 0.0124s/iter; left time: 438.7916s
	iters: 400, epoch: 28 | loss: 2.9774041
	speed: 0.0129s/iter; left time: 452.9348s
Epoch: 28 cost time: 6.375206470489502
Epoch: 28, Steps: 487 Train Loss: 2.8066 (Forecasting Loss:0.3960 + XiCon Loss:2.4106 x Lambda(1.0)), Vali MSE Loss: 0.7362 Test MSE Loss: 0.5132
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 2.7654829
	speed: 0.0154s/iter; left time: 539.9071s
	iters: 200, epoch: 29 | loss: 2.7740040
	speed: 0.0127s/iter; left time: 442.7458s
	iters: 300, epoch: 29 | loss: 2.7979288
	speed: 0.0126s/iter; left time: 439.6329s
	iters: 400, epoch: 29 | loss: 2.8019133
	speed: 0.0125s/iter; left time: 433.0953s
Epoch: 29 cost time: 6.488483667373657
Epoch: 29, Steps: 487 Train Loss: 2.8085 (Forecasting Loss:0.3959 + XiCon Loss:2.4125 x Lambda(1.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5132
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 2.8471189
	speed: 0.0163s/iter; left time: 561.5170s
	iters: 200, epoch: 30 | loss: 2.7499180
	speed: 0.0128s/iter; left time: 441.1265s
	iters: 300, epoch: 30 | loss: 2.6645706
	speed: 0.0123s/iter; left time: 423.0042s
	iters: 400, epoch: 30 | loss: 2.8756671
	speed: 0.0127s/iter; left time: 435.6707s
Epoch: 30 cost time: 6.449796438217163
Epoch: 30, Steps: 487 Train Loss: 2.8114 (Forecasting Loss:0.3957 + XiCon Loss:2.4158 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 2.8221893
	speed: 0.0162s/iter; left time: 551.0369s
	iters: 200, epoch: 31 | loss: 2.7276101
	speed: 0.0122s/iter; left time: 413.5050s
	iters: 300, epoch: 31 | loss: 2.7014506
	speed: 0.0120s/iter; left time: 406.9754s
	iters: 400, epoch: 31 | loss: 2.8194642
	speed: 0.0128s/iter; left time: 430.5252s
Epoch: 31 cost time: 6.428077220916748
Epoch: 31, Steps: 487 Train Loss: 2.8116 (Forecasting Loss:0.3957 + XiCon Loss:2.4158 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 2.6437433
	speed: 0.0155s/iter; left time: 518.8672s
	iters: 200, epoch: 32 | loss: 2.8828375
	speed: 0.0128s/iter; left time: 427.9134s
	iters: 300, epoch: 32 | loss: 2.7881868
	speed: 0.0141s/iter; left time: 468.7803s
	iters: 400, epoch: 32 | loss: 2.9395916
	speed: 0.0134s/iter; left time: 443.7600s
Epoch: 32 cost time: 6.690999507904053
Epoch: 32, Steps: 487 Train Loss: 2.8129 (Forecasting Loss:0.3958 + XiCon Loss:2.4170 x Lambda(1.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5132
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 2.8140609
	speed: 0.0147s/iter; left time: 483.9194s
	iters: 200, epoch: 33 | loss: 2.7948790
	speed: 0.0121s/iter; left time: 399.3648s
	iters: 300, epoch: 33 | loss: 2.7898517
	speed: 0.0125s/iter; left time: 409.2340s
	iters: 400, epoch: 33 | loss: 2.8643866
	speed: 0.0129s/iter; left time: 422.3761s
Epoch: 33 cost time: 6.503635883331299
Epoch: 33, Steps: 487 Train Loss: 2.8074 (Forecasting Loss:0.3959 + XiCon Loss:2.4114 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 2.7655101
	speed: 0.0147s/iter; left time: 477.6445s
	iters: 200, epoch: 34 | loss: 2.7855761
	speed: 0.0123s/iter; left time: 400.0393s
	iters: 300, epoch: 34 | loss: 2.8423903
	speed: 0.0124s/iter; left time: 400.6254s
	iters: 400, epoch: 34 | loss: 2.8663435
	speed: 0.0121s/iter; left time: 391.0202s
Epoch: 34 cost time: 6.237570524215698
Epoch: 34, Steps: 487 Train Loss: 2.8086 (Forecasting Loss:0.3957 + XiCon Loss:2.4128 x Lambda(1.0)), Vali MSE Loss: 0.7357 Test MSE Loss: 0.5132
Validation loss decreased (0.735987 --> 0.735670).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 2.8472488
	speed: 0.0160s/iter; left time: 512.2178s
	iters: 200, epoch: 35 | loss: 2.6724045
	speed: 0.0140s/iter; left time: 447.5254s
	iters: 300, epoch: 35 | loss: 2.9339273
	speed: 0.0125s/iter; left time: 396.8228s
	iters: 400, epoch: 35 | loss: 2.7072513
	speed: 0.0116s/iter; left time: 368.6613s
Epoch: 35 cost time: 6.473161220550537
Epoch: 35, Steps: 487 Train Loss: 2.8135 (Forecasting Loss:0.3958 + XiCon Loss:2.4177 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 2.9071202
	speed: 0.0151s/iter; left time: 477.3349s
	iters: 200, epoch: 36 | loss: 2.7900350
	speed: 0.0127s/iter; left time: 399.2061s
	iters: 300, epoch: 36 | loss: 2.7425225
	speed: 0.0123s/iter; left time: 387.0732s
	iters: 400, epoch: 36 | loss: 2.7259257
	speed: 0.0124s/iter; left time: 388.2011s
Epoch: 36 cost time: 6.405555725097656
Epoch: 36, Steps: 487 Train Loss: 2.8084 (Forecasting Loss:0.3956 + XiCon Loss:2.4128 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 2.9368510
	speed: 0.0147s/iter; left time: 458.2251s
	iters: 200, epoch: 37 | loss: 2.9025943
	speed: 0.0125s/iter; left time: 387.1404s
	iters: 300, epoch: 37 | loss: 2.7496433
	speed: 0.0123s/iter; left time: 380.2987s
	iters: 400, epoch: 37 | loss: 2.8430533
	speed: 0.0126s/iter; left time: 386.4182s
Epoch: 37 cost time: 6.364640235900879
Epoch: 37, Steps: 487 Train Loss: 2.8095 (Forecasting Loss:0.3957 + XiCon Loss:2.4138 x Lambda(1.0)), Vali MSE Loss: 0.7369 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 2.7526188
	speed: 0.0167s/iter; left time: 510.5149s
	iters: 200, epoch: 38 | loss: 2.8944247
	speed: 0.0126s/iter; left time: 383.5451s
	iters: 300, epoch: 38 | loss: 2.7814193
	speed: 0.0120s/iter; left time: 365.1821s
	iters: 400, epoch: 38 | loss: 2.9206269
	speed: 0.0119s/iter; left time: 361.6304s
Epoch: 38 cost time: 6.495008945465088
Epoch: 38, Steps: 487 Train Loss: 2.8129 (Forecasting Loss:0.3958 + XiCon Loss:2.4171 x Lambda(1.0)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5132
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 2.8323026
	speed: 0.0150s/iter; left time: 452.6731s
	iters: 200, epoch: 39 | loss: 2.7850647
	speed: 0.0123s/iter; left time: 368.7615s
	iters: 300, epoch: 39 | loss: 2.9060264
	speed: 0.0128s/iter; left time: 383.8057s
	iters: 400, epoch: 39 | loss: 2.7787149
	speed: 0.0142s/iter; left time: 423.4762s
Epoch: 39 cost time: 6.493895530700684
Epoch: 39, Steps: 487 Train Loss: 2.8102 (Forecasting Loss:0.3960 + XiCon Loss:2.4142 x Lambda(1.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5132
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 2.9376330
	speed: 0.0143s/iter; left time: 424.3119s
	iters: 200, epoch: 40 | loss: 2.8295426
	speed: 0.0114s/iter; left time: 337.2293s
	iters: 300, epoch: 40 | loss: 2.8821270
	speed: 0.0119s/iter; left time: 350.4479s
	iters: 400, epoch: 40 | loss: 2.9148431
	speed: 0.0119s/iter; left time: 349.6163s
Epoch: 40 cost time: 6.023809432983398
Epoch: 40, Steps: 487 Train Loss: 2.8069 (Forecasting Loss:0.3960 + XiCon Loss:2.4110 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 2.8259432
	speed: 0.0145s/iter; left time: 421.5327s
	iters: 200, epoch: 41 | loss: 2.7158875
	speed: 0.0121s/iter; left time: 350.6092s
	iters: 300, epoch: 41 | loss: 2.8703799
	speed: 0.0115s/iter; left time: 331.4193s
	iters: 400, epoch: 41 | loss: 2.7242548
	speed: 0.0119s/iter; left time: 343.3594s
Epoch: 41 cost time: 6.017464637756348
Epoch: 41, Steps: 487 Train Loss: 2.8070 (Forecasting Loss:0.3958 + XiCon Loss:2.4112 x Lambda(1.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5132
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 2.7919052
	speed: 0.0145s/iter; left time: 414.0528s
	iters: 200, epoch: 42 | loss: 2.6267958
	speed: 0.0119s/iter; left time: 338.5898s
	iters: 300, epoch: 42 | loss: 2.8189065
	speed: 0.0126s/iter; left time: 357.2183s
	iters: 400, epoch: 42 | loss: 2.9815969
	speed: 0.0125s/iter; left time: 353.9841s
Epoch: 42 cost time: 6.187174320220947
Epoch: 42, Steps: 487 Train Loss: 2.8096 (Forecasting Loss:0.3959 + XiCon Loss:2.4137 x Lambda(1.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5132
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 2.8790855
	speed: 0.0136s/iter; left time: 382.9508s
	iters: 200, epoch: 43 | loss: 2.8906753
	speed: 0.0107s/iter; left time: 300.6799s
	iters: 300, epoch: 43 | loss: 2.7696152
	speed: 0.0121s/iter; left time: 337.8114s
	iters: 400, epoch: 43 | loss: 2.8886282
	speed: 0.0131s/iter; left time: 364.4046s
Epoch: 43 cost time: 6.007324457168579
Epoch: 43, Steps: 487 Train Loss: 2.8146 (Forecasting Loss:0.3960 + XiCon Loss:2.4186 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 2.7834969
	speed: 0.0142s/iter; left time: 394.0440s
	iters: 200, epoch: 44 | loss: 2.8862894
	speed: 0.0118s/iter; left time: 324.1862s
	iters: 300, epoch: 44 | loss: 2.8596489
	speed: 0.0116s/iter; left time: 317.5174s
	iters: 400, epoch: 44 | loss: 2.8546879
	speed: 0.0117s/iter; left time: 319.8797s
Epoch: 44 cost time: 6.0505383014678955
Epoch: 44, Steps: 487 Train Loss: 2.8089 (Forecasting Loss:0.3957 + XiCon Loss:2.4132 x Lambda(1.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5132
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5204351544380188, mae:0.5060081481933594, mape:3.464428186416626, mspe:1078.3551025390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5188+-0.00985, MAE:0.5063+-0.00494, MAPE:3.5281+-0.08224, MSPE:1151.1975+-69.42469, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.8604
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 3.5842814
	speed: 0.0312s/iter; left time: 739.9394s
	iters: 200, epoch: 1 | loss: 3.5460052
	speed: 0.0259s/iter; left time: 610.2701s
Epoch: 1 cost time: 6.587370872497559
Epoch: 1, Steps: 238 Train Loss: 3.5664 (Forecasting Loss:0.9803 + XiCon Loss:2.5861 x Lambda(1.0)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755401).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.1698747
	speed: 0.0285s/iter; left time: 668.5738s
	iters: 200, epoch: 2 | loss: 3.1787744
	speed: 0.0260s/iter; left time: 608.4914s
Epoch: 2 cost time: 6.441485404968262
Epoch: 2, Steps: 238 Train Loss: 3.1967 (Forecasting Loss:0.6170 + XiCon Loss:2.5798 x Lambda(1.0)), Vali MSE Loss: 1.0370 Test MSE Loss: 0.8577
Validation loss decreased (1.755401 --> 1.037004).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.1472921
	speed: 0.0265s/iter; left time: 616.3024s
	iters: 200, epoch: 3 | loss: 3.1627324
	speed: 0.0273s/iter; left time: 631.6050s
Epoch: 3 cost time: 6.3957200050354
Epoch: 3, Steps: 238 Train Loss: 3.1280 (Forecasting Loss:0.5527 + XiCon Loss:2.5753 x Lambda(1.0)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8511
Validation loss decreased (1.037004 --> 1.018107).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.0395448
	speed: 0.0282s/iter; left time: 647.8010s
	iters: 200, epoch: 4 | loss: 3.0628080
	speed: 0.0264s/iter; left time: 603.9242s
Epoch: 4 cost time: 6.471670866012573
Epoch: 4, Steps: 238 Train Loss: 3.1129 (Forecasting Loss:0.5446 + XiCon Loss:2.5683 x Lambda(1.0)), Vali MSE Loss: 1.0107 Test MSE Loss: 0.8491
Validation loss decreased (1.018107 --> 1.010728).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.1214561
	speed: 0.0279s/iter; left time: 633.6319s
	iters: 200, epoch: 5 | loss: 3.1015887
	speed: 0.0255s/iter; left time: 577.7649s
Epoch: 5 cost time: 6.289501428604126
Epoch: 5, Steps: 238 Train Loss: 3.1099 (Forecasting Loss:0.5414 + XiCon Loss:2.5685 x Lambda(1.0)), Vali MSE Loss: 1.0077 Test MSE Loss: 0.8488
Validation loss decreased (1.010728 --> 1.007735).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.1335831
	speed: 0.0284s/iter; left time: 640.2708s
	iters: 200, epoch: 6 | loss: 3.0783143
	speed: 0.0254s/iter; left time: 569.3927s
Epoch: 6 cost time: 6.340136528015137
Epoch: 6, Steps: 238 Train Loss: 3.1037 (Forecasting Loss:0.5400 + XiCon Loss:2.5638 x Lambda(1.0)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8484
Validation loss decreased (1.007735 --> 1.006420).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.0745599
	speed: 0.0282s/iter; left time: 629.1800s
	iters: 200, epoch: 7 | loss: 3.1261899
	speed: 0.0260s/iter; left time: 576.7158s
Epoch: 7 cost time: 6.468911409378052
Epoch: 7, Steps: 238 Train Loss: 3.1073 (Forecasting Loss:0.5392 + XiCon Loss:2.5682 x Lambda(1.0)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8484
Validation loss decreased (1.006420 --> 1.004732).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.0728579
	speed: 0.0294s/iter; left time: 646.9570s
	iters: 200, epoch: 8 | loss: 3.0941472
	speed: 0.0253s/iter; left time: 555.8059s
Epoch: 8 cost time: 6.531373500823975
Epoch: 8, Steps: 238 Train Loss: 3.1013 (Forecasting Loss:0.5387 + XiCon Loss:2.5626 x Lambda(1.0)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8483
Validation loss decreased (1.004732 --> 1.004666).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1710958
	speed: 0.0278s/iter; left time: 606.4005s
	iters: 200, epoch: 9 | loss: 3.0726810
	speed: 0.0256s/iter; left time: 556.1859s
Epoch: 9 cost time: 6.304527759552002
Epoch: 9, Steps: 238 Train Loss: 3.1059 (Forecasting Loss:0.5387 + XiCon Loss:2.5672 x Lambda(1.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.1319518
	speed: 0.0285s/iter; left time: 614.6053s
	iters: 200, epoch: 10 | loss: 3.1161482
	speed: 0.0256s/iter; left time: 550.0100s
Epoch: 10 cost time: 6.457758665084839
Epoch: 10, Steps: 238 Train Loss: 3.1081 (Forecasting Loss:0.5385 + XiCon Loss:2.5696 x Lambda(1.0)), Vali MSE Loss: 1.0046 Test MSE Loss: 0.8483
Validation loss decreased (1.004666 --> 1.004617).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.0846381
	speed: 0.0284s/iter; left time: 606.2082s
	iters: 200, epoch: 11 | loss: 3.1420646
	speed: 0.0253s/iter; left time: 535.8570s
Epoch: 11 cost time: 6.422094345092773
Epoch: 11, Steps: 238 Train Loss: 3.1024 (Forecasting Loss:0.5382 + XiCon Loss:2.5642 x Lambda(1.0)), Vali MSE Loss: 1.0038 Test MSE Loss: 0.8483
Validation loss decreased (1.004617 --> 1.003833).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1026404
	speed: 0.0285s/iter; left time: 601.3364s
	iters: 200, epoch: 12 | loss: 3.0610948
	speed: 0.0260s/iter; left time: 544.8808s
Epoch: 12 cost time: 6.410764694213867
Epoch: 12, Steps: 238 Train Loss: 3.1044 (Forecasting Loss:0.5383 + XiCon Loss:2.5661 x Lambda(1.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1258445
	speed: 0.0288s/iter; left time: 600.1344s
	iters: 200, epoch: 13 | loss: 3.1026001
	speed: 0.0260s/iter; left time: 539.1417s
Epoch: 13 cost time: 6.532343864440918
Epoch: 13, Steps: 238 Train Loss: 3.1040 (Forecasting Loss:0.5383 + XiCon Loss:2.5657 x Lambda(1.0)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8483
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.0365591
	speed: 0.0279s/iter; left time: 575.4876s
	iters: 200, epoch: 14 | loss: 3.1463001
	speed: 0.0255s/iter; left time: 522.7307s
Epoch: 14 cost time: 6.352293014526367
Epoch: 14, Steps: 238 Train Loss: 3.1008 (Forecasting Loss:0.5382 + XiCon Loss:2.5626 x Lambda(1.0)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8483
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.1001587
	speed: 0.0294s/iter; left time: 599.5062s
	iters: 200, epoch: 15 | loss: 3.0468707
	speed: 0.0256s/iter; left time: 517.8803s
Epoch: 15 cost time: 6.4803102016448975
Epoch: 15, Steps: 238 Train Loss: 3.0977 (Forecasting Loss:0.5382 + XiCon Loss:2.5594 x Lambda(1.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.1140504
	speed: 0.0282s/iter; left time: 566.8557s
	iters: 200, epoch: 16 | loss: 3.1198757
	speed: 0.0256s/iter; left time: 512.6224s
Epoch: 16 cost time: 6.417788505554199
Epoch: 16, Steps: 238 Train Loss: 3.1003 (Forecasting Loss:0.5385 + XiCon Loss:2.5617 x Lambda(1.0)), Vali MSE Loss: 1.0046 Test MSE Loss: 0.8483
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.0764472
	speed: 0.0284s/iter; left time: 564.6664s
	iters: 200, epoch: 17 | loss: 3.0329759
	speed: 0.0266s/iter; left time: 525.5141s
Epoch: 17 cost time: 6.571610689163208
Epoch: 17, Steps: 238 Train Loss: 3.1078 (Forecasting Loss:0.5380 + XiCon Loss:2.5698 x Lambda(1.0)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8483
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.0409553
	speed: 0.0295s/iter; left time: 579.6985s
	iters: 200, epoch: 18 | loss: 3.0403044
	speed: 0.0278s/iter; left time: 543.2330s
Epoch: 18 cost time: 6.738564729690552
Epoch: 18, Steps: 238 Train Loss: 3.1021 (Forecasting Loss:0.5382 + XiCon Loss:2.5638 x Lambda(1.0)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8483
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1406543
	speed: 0.0286s/iter; left time: 554.5002s
	iters: 200, epoch: 19 | loss: 3.1294854
	speed: 0.0258s/iter; left time: 498.9491s
Epoch: 19 cost time: 6.476251602172852
Epoch: 19, Steps: 238 Train Loss: 3.1020 (Forecasting Loss:0.5384 + XiCon Loss:2.5636 x Lambda(1.0)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.0805957
	speed: 0.0281s/iter; left time: 538.8873s
	iters: 200, epoch: 20 | loss: 3.1025913
	speed: 0.0255s/iter; left time: 487.3134s
Epoch: 20 cost time: 6.368534088134766
Epoch: 20, Steps: 238 Train Loss: 3.1069 (Forecasting Loss:0.5381 + XiCon Loss:2.5688 x Lambda(1.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.1055844
	speed: 0.0289s/iter; left time: 547.5881s
	iters: 200, epoch: 21 | loss: 3.0865819
	speed: 0.0262s/iter; left time: 492.7317s
Epoch: 21 cost time: 6.579139709472656
Epoch: 21, Steps: 238 Train Loss: 3.1042 (Forecasting Loss:0.5384 + XiCon Loss:2.5657 x Lambda(1.0)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9774024486541748, mae:0.7191464900970459, mape:4.775698661804199, mspe:2686.13720703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7533
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 3.5925972
	speed: 0.0278s/iter; left time: 658.5742s
	iters: 200, epoch: 1 | loss: 3.6950192
	speed: 0.0251s/iter; left time: 591.8879s
Epoch: 1 cost time: 6.24278998374939
Epoch: 1, Steps: 238 Train Loss: 3.6760 (Forecasting Loss:1.0993 + XiCon Loss:2.5767 x Lambda(1.0)), Vali MSE Loss: 1.9683 Test MSE Loss: 1.0363
Validation loss decreased (inf --> 1.968327).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.1944594
	speed: 0.0272s/iter; left time: 638.7059s
	iters: 200, epoch: 2 | loss: 3.0784426
	speed: 0.0255s/iter; left time: 595.5464s
Epoch: 2 cost time: 6.313035249710083
Epoch: 2, Steps: 238 Train Loss: 3.1964 (Forecasting Loss:0.6339 + XiCon Loss:2.5625 x Lambda(1.0)), Vali MSE Loss: 1.0206 Test MSE Loss: 0.8594
Validation loss decreased (1.968327 --> 1.020615).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.1236563
	speed: 0.0279s/iter; left time: 647.9895s
	iters: 200, epoch: 3 | loss: 3.1058245
	speed: 0.0261s/iter; left time: 602.6922s
Epoch: 3 cost time: 6.44233512878418
Epoch: 3, Steps: 238 Train Loss: 3.1038 (Forecasting Loss:0.5519 + XiCon Loss:2.5519 x Lambda(1.0)), Vali MSE Loss: 0.9993 Test MSE Loss: 0.8538
Validation loss decreased (1.020615 --> 0.999283).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.0520725
	speed: 0.0280s/iter; left time: 644.6129s
	iters: 200, epoch: 4 | loss: 3.1934795
	speed: 0.0264s/iter; left time: 603.3974s
Epoch: 4 cost time: 6.430323600769043
Epoch: 4, Steps: 238 Train Loss: 3.0938 (Forecasting Loss:0.5434 + XiCon Loss:2.5504 x Lambda(1.0)), Vali MSE Loss: 0.9931 Test MSE Loss: 0.8525
Validation loss decreased (0.999283 --> 0.993074).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.0613334
	speed: 0.0276s/iter; left time: 628.9361s
	iters: 200, epoch: 5 | loss: 3.0629728
	speed: 0.0255s/iter; left time: 576.8080s
Epoch: 5 cost time: 6.344181537628174
Epoch: 5, Steps: 238 Train Loss: 3.0850 (Forecasting Loss:0.5401 + XiCon Loss:2.5449 x Lambda(1.0)), Vali MSE Loss: 0.9880 Test MSE Loss: 0.8518
Validation loss decreased (0.993074 --> 0.988020).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.0412228
	speed: 0.0277s/iter; left time: 624.2716s
	iters: 200, epoch: 6 | loss: 3.1666265
	speed: 0.0250s/iter; left time: 560.4152s
Epoch: 6 cost time: 6.25848650932312
Epoch: 6, Steps: 238 Train Loss: 3.0864 (Forecasting Loss:0.5389 + XiCon Loss:2.5475 x Lambda(1.0)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8517
Validation loss decreased (0.988020 --> 0.987064).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.0951567
	speed: 0.0268s/iter; left time: 597.0997s
	iters: 200, epoch: 7 | loss: 3.0182323
	speed: 0.0253s/iter; left time: 559.9330s
Epoch: 7 cost time: 6.208646774291992
Epoch: 7, Steps: 238 Train Loss: 3.0818 (Forecasting Loss:0.5379 + XiCon Loss:2.5439 x Lambda(1.0)), Vali MSE Loss: 0.9862 Test MSE Loss: 0.8516
Validation loss decreased (0.987064 --> 0.986150).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1463394
	speed: 0.0272s/iter; left time: 599.2462s
	iters: 200, epoch: 8 | loss: 3.0229187
	speed: 0.0249s/iter; left time: 545.3141s
Epoch: 8 cost time: 6.215836763381958
Epoch: 8, Steps: 238 Train Loss: 3.0822 (Forecasting Loss:0.5378 + XiCon Loss:2.5444 x Lambda(1.0)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8516
Validation loss decreased (0.986150 --> 0.986124).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.0989635
	speed: 0.0274s/iter; left time: 598.2626s
	iters: 200, epoch: 9 | loss: 3.1264966
	speed: 0.0248s/iter; left time: 538.1177s
Epoch: 9 cost time: 6.232896566390991
Epoch: 9, Steps: 238 Train Loss: 3.0832 (Forecasting Loss:0.5374 + XiCon Loss:2.5457 x Lambda(1.0)), Vali MSE Loss: 0.9851 Test MSE Loss: 0.8515
Validation loss decreased (0.986124 --> 0.985081).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.0717573
	speed: 0.0285s/iter; left time: 614.5560s
	iters: 200, epoch: 10 | loss: 3.1793833
	speed: 0.0261s/iter; left time: 560.4933s
Epoch: 10 cost time: 6.546044111251831
Epoch: 10, Steps: 238 Train Loss: 3.0813 (Forecasting Loss:0.5373 + XiCon Loss:2.5440 x Lambda(1.0)), Vali MSE Loss: 0.9847 Test MSE Loss: 0.8515
Validation loss decreased (0.985081 --> 0.984686).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1361384
	speed: 0.0282s/iter; left time: 600.6997s
	iters: 200, epoch: 11 | loss: 3.2293117
	speed: 0.0254s/iter; left time: 539.9385s
Epoch: 11 cost time: 6.303820371627808
Epoch: 11, Steps: 238 Train Loss: 3.0806 (Forecasting Loss:0.5372 + XiCon Loss:2.5434 x Lambda(1.0)), Vali MSE Loss: 0.9853 Test MSE Loss: 0.8515
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1271310
	speed: 0.0275s/iter; left time: 579.8572s
	iters: 200, epoch: 12 | loss: 3.0430903
	speed: 0.0250s/iter; left time: 525.3955s
Epoch: 12 cost time: 6.282587289810181
Epoch: 12, Steps: 238 Train Loss: 3.0796 (Forecasting Loss:0.5371 + XiCon Loss:2.5425 x Lambda(1.0)), Vali MSE Loss: 0.9849 Test MSE Loss: 0.8515
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1009822
	speed: 0.0275s/iter; left time: 573.5152s
	iters: 200, epoch: 13 | loss: 3.0760541
	speed: 0.0258s/iter; left time: 535.7351s
Epoch: 13 cost time: 6.369230508804321
Epoch: 13, Steps: 238 Train Loss: 3.0833 (Forecasting Loss:0.5370 + XiCon Loss:2.5463 x Lambda(1.0)), Vali MSE Loss: 0.9857 Test MSE Loss: 0.8515
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.0257187
	speed: 0.0275s/iter; left time: 565.9717s
	iters: 200, epoch: 14 | loss: 3.0389006
	speed: 0.0248s/iter; left time: 508.6676s
Epoch: 14 cost time: 6.174882888793945
Epoch: 14, Steps: 238 Train Loss: 3.0859 (Forecasting Loss:0.5371 + XiCon Loss:2.5488 x Lambda(1.0)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8515
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.0961330
	speed: 0.0256s/iter; left time: 522.4309s
	iters: 200, epoch: 15 | loss: 3.0688853
	speed: 0.0232s/iter; left time: 469.3234s
Epoch: 15 cost time: 5.854418039321899
Epoch: 15, Steps: 238 Train Loss: 3.0839 (Forecasting Loss:0.5370 + XiCon Loss:2.5469 x Lambda(1.0)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8515
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.1115921
	speed: 0.0254s/iter; left time: 511.5702s
	iters: 200, epoch: 16 | loss: 3.1358612
	speed: 0.0238s/iter; left time: 476.0257s
Epoch: 16 cost time: 5.868598937988281
Epoch: 16, Steps: 238 Train Loss: 3.0838 (Forecasting Loss:0.5371 + XiCon Loss:2.5467 x Lambda(1.0)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8515
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.0086734
	speed: 0.0266s/iter; left time: 529.7784s
	iters: 200, epoch: 17 | loss: 3.1241937
	speed: 0.0232s/iter; left time: 459.4349s
Epoch: 17 cost time: 5.920889616012573
Epoch: 17, Steps: 238 Train Loss: 3.0781 (Forecasting Loss:0.5373 + XiCon Loss:2.5408 x Lambda(1.0)), Vali MSE Loss: 0.9850 Test MSE Loss: 0.8515
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.0445867
	speed: 0.0273s/iter; left time: 536.6270s
	iters: 200, epoch: 18 | loss: 3.2951822
	speed: 0.0245s/iter; left time: 479.4078s
Epoch: 18 cost time: 6.153741359710693
Epoch: 18, Steps: 238 Train Loss: 3.0802 (Forecasting Loss:0.5374 + XiCon Loss:2.5427 x Lambda(1.0)), Vali MSE Loss: 0.9848 Test MSE Loss: 0.8515
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1100936
	speed: 0.0255s/iter; left time: 495.1231s
	iters: 200, epoch: 19 | loss: 3.0627000
	speed: 0.0245s/iter; left time: 473.4838s
Epoch: 19 cost time: 5.962895154953003
Epoch: 19, Steps: 238 Train Loss: 3.0859 (Forecasting Loss:0.5371 + XiCon Loss:2.5488 x Lambda(1.0)), Vali MSE Loss: 0.9850 Test MSE Loss: 0.8515
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.0891619
	speed: 0.0258s/iter; left time: 494.4773s
	iters: 200, epoch: 20 | loss: 3.0622382
	speed: 0.0237s/iter; left time: 452.6973s
Epoch: 20 cost time: 5.909400701522827
Epoch: 20, Steps: 238 Train Loss: 3.0825 (Forecasting Loss:0.5372 + XiCon Loss:2.5452 x Lambda(1.0)), Vali MSE Loss: 0.9847 Test MSE Loss: 0.8515
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9812905192375183, mae:0.7217128276824951, mape:4.75503396987915, mspe:2648.935302734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.2888
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 3.5915318
	speed: 0.0259s/iter; left time: 613.9025s
	iters: 200, epoch: 1 | loss: 3.4993434
	speed: 0.0228s/iter; left time: 537.4626s
Epoch: 1 cost time: 5.751543760299683
Epoch: 1, Steps: 238 Train Loss: 3.5819 (Forecasting Loss:1.0009 + XiCon Loss:2.5810 x Lambda(1.0)), Vali MSE Loss: 1.7925 Test MSE Loss: 0.9697
Validation loss decreased (inf --> 1.792505).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.1569295
	speed: 0.0270s/iter; left time: 634.6005s
	iters: 200, epoch: 2 | loss: 3.0653057
	speed: 0.0226s/iter; left time: 527.9313s
Epoch: 2 cost time: 5.866759300231934
Epoch: 2, Steps: 238 Train Loss: 3.2007 (Forecasting Loss:0.6191 + XiCon Loss:2.5816 x Lambda(1.0)), Vali MSE Loss: 1.0417 Test MSE Loss: 0.8611
Validation loss decreased (1.792505 --> 1.041710).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.0927410
	speed: 0.0258s/iter; left time: 599.8874s
	iters: 200, epoch: 3 | loss: 3.1621895
	speed: 0.0240s/iter; left time: 553.8947s
Epoch: 3 cost time: 5.842328310012817
Epoch: 3, Steps: 238 Train Loss: 3.1153 (Forecasting Loss:0.5526 + XiCon Loss:2.5627 x Lambda(1.0)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8554
Validation loss decreased (1.041710 --> 1.019625).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.1113584
	speed: 0.0257s/iter; left time: 589.9650s
	iters: 200, epoch: 4 | loss: 3.1095853
	speed: 0.0218s/iter; left time: 498.0610s
Epoch: 4 cost time: 5.638031482696533
Epoch: 4, Steps: 238 Train Loss: 3.1103 (Forecasting Loss:0.5443 + XiCon Loss:2.5660 x Lambda(1.0)), Vali MSE Loss: 1.0138 Test MSE Loss: 0.8539
Validation loss decreased (1.019625 --> 1.013760).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.0756049
	speed: 0.0263s/iter; left time: 597.8652s
	iters: 200, epoch: 5 | loss: 3.1013231
	speed: 0.0223s/iter; left time: 504.2549s
Epoch: 5 cost time: 5.783586025238037
Epoch: 5, Steps: 238 Train Loss: 3.1060 (Forecasting Loss:0.5407 + XiCon Loss:2.5653 x Lambda(1.0)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8534
Validation loss decreased (1.013760 --> 1.010455).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.1462536
	speed: 0.0266s/iter; left time: 597.8552s
	iters: 200, epoch: 6 | loss: 3.0850315
	speed: 0.0235s/iter; left time: 525.8476s
Epoch: 6 cost time: 5.902169704437256
Epoch: 6, Steps: 238 Train Loss: 3.0985 (Forecasting Loss:0.5395 + XiCon Loss:2.5590 x Lambda(1.0)), Vali MSE Loss: 1.0089 Test MSE Loss: 0.8532
Validation loss decreased (1.010455 --> 1.008922).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.1244695
	speed: 0.0260s/iter; left time: 578.3568s
	iters: 200, epoch: 7 | loss: 3.0790284
	speed: 0.0230s/iter; left time: 509.8493s
Epoch: 7 cost time: 5.714043855667114
Epoch: 7, Steps: 238 Train Loss: 3.0998 (Forecasting Loss:0.5386 + XiCon Loss:2.5611 x Lambda(1.0)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8531
Validation loss decreased (1.008922 --> 1.007879).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1130748
	speed: 0.0273s/iter; left time: 602.0594s
	iters: 200, epoch: 8 | loss: 3.1090679
	speed: 0.0223s/iter; left time: 488.2112s
Epoch: 8 cost time: 5.818847179412842
Epoch: 8, Steps: 238 Train Loss: 3.1035 (Forecasting Loss:0.5383 + XiCon Loss:2.5652 x Lambda(1.0)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8530
Validation loss decreased (1.007879 --> 1.007551).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.0527985
	speed: 0.0272s/iter; left time: 593.2099s
	iters: 200, epoch: 9 | loss: 3.1037607
	speed: 0.0226s/iter; left time: 489.7061s
Epoch: 9 cost time: 5.900960922241211
Epoch: 9, Steps: 238 Train Loss: 3.1013 (Forecasting Loss:0.5379 + XiCon Loss:2.5634 x Lambda(1.0)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8530
Validation loss decreased (1.007551 --> 1.006962).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.0285974
	speed: 0.0257s/iter; left time: 555.0773s
	iters: 200, epoch: 10 | loss: 3.0703096
	speed: 0.0225s/iter; left time: 483.0636s
Epoch: 10 cost time: 5.730711221694946
Epoch: 10, Steps: 238 Train Loss: 3.1005 (Forecasting Loss:0.5378 + XiCon Loss:2.5627 x Lambda(1.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8530
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.0791497
	speed: 0.0270s/iter; left time: 574.8267s
	iters: 200, epoch: 11 | loss: 3.1220770
	speed: 0.0225s/iter; left time: 478.2085s
Epoch: 11 cost time: 5.805032014846802
Epoch: 11, Steps: 238 Train Loss: 3.1013 (Forecasting Loss:0.5378 + XiCon Loss:2.5635 x Lambda(1.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8530
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1040483
	speed: 0.0270s/iter; left time: 568.6956s
	iters: 200, epoch: 12 | loss: 3.0809772
	speed: 0.0232s/iter; left time: 486.2147s
Epoch: 12 cost time: 5.823695659637451
Epoch: 12, Steps: 238 Train Loss: 3.1004 (Forecasting Loss:0.5376 + XiCon Loss:2.5628 x Lambda(1.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8530
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1470399
	speed: 0.0264s/iter; left time: 551.3479s
	iters: 200, epoch: 13 | loss: 3.0303974
	speed: 0.0224s/iter; left time: 465.0415s
Epoch: 13 cost time: 5.74450945854187
Epoch: 13, Steps: 238 Train Loss: 3.0997 (Forecasting Loss:0.5378 + XiCon Loss:2.5620 x Lambda(1.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8530
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1027732
	speed: 0.0267s/iter; left time: 549.8852s
	iters: 200, epoch: 14 | loss: 3.1456156
	speed: 0.0225s/iter; left time: 461.4583s
Epoch: 14 cost time: 5.828526496887207
Epoch: 14, Steps: 238 Train Loss: 3.0991 (Forecasting Loss:0.5379 + XiCon Loss:2.5612 x Lambda(1.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8530
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.1806560
	speed: 0.0262s/iter; left time: 534.0817s
	iters: 200, epoch: 15 | loss: 3.1451955
	speed: 0.0223s/iter; left time: 452.4027s
Epoch: 15 cost time: 5.750296592712402
Epoch: 15, Steps: 238 Train Loss: 3.0995 (Forecasting Loss:0.5379 + XiCon Loss:2.5616 x Lambda(1.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8530
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.0385866
	speed: 0.0266s/iter; left time: 534.6813s
	iters: 200, epoch: 16 | loss: 3.0463951
	speed: 0.0223s/iter; left time: 446.7958s
Epoch: 16 cost time: 5.708593130111694
Epoch: 16, Steps: 238 Train Loss: 3.0999 (Forecasting Loss:0.5378 + XiCon Loss:2.5621 x Lambda(1.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8530
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.1934774
	speed: 0.0262s/iter; left time: 522.0128s
	iters: 200, epoch: 17 | loss: 3.0202394
	speed: 0.0226s/iter; left time: 447.2020s
Epoch: 17 cost time: 5.723221778869629
Epoch: 17, Steps: 238 Train Loss: 3.0987 (Forecasting Loss:0.5378 + XiCon Loss:2.5608 x Lambda(1.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8530
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.0725510
	speed: 0.0258s/iter; left time: 507.0084s
	iters: 200, epoch: 18 | loss: 3.0418921
	speed: 0.0244s/iter; left time: 477.2583s
Epoch: 18 cost time: 5.933717250823975
Epoch: 18, Steps: 238 Train Loss: 3.1009 (Forecasting Loss:0.5377 + XiCon Loss:2.5632 x Lambda(1.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8530
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.0522192
	speed: 0.0267s/iter; left time: 518.5415s
	iters: 200, epoch: 19 | loss: 3.0858700
	speed: 0.0230s/iter; left time: 443.5630s
Epoch: 19 cost time: 5.980260133743286
Epoch: 19, Steps: 238 Train Loss: 3.1014 (Forecasting Loss:0.5377 + XiCon Loss:2.5637 x Lambda(1.0)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8530
Validation loss decreased (1.006962 --> 1.006885).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.1061029
	speed: 0.0270s/iter; left time: 517.9529s
	iters: 200, epoch: 20 | loss: 3.0417001
	speed: 0.0232s/iter; left time: 443.0072s
Epoch: 20 cost time: 5.85901665687561
Epoch: 20, Steps: 238 Train Loss: 3.0955 (Forecasting Loss:0.5377 + XiCon Loss:2.5578 x Lambda(1.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8530
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.0990119
	speed: 0.0264s/iter; left time: 500.5811s
	iters: 200, epoch: 21 | loss: 3.1162992
	speed: 0.0237s/iter; left time: 447.1996s
Epoch: 21 cost time: 5.814610242843628
Epoch: 21, Steps: 238 Train Loss: 3.0946 (Forecasting Loss:0.5377 + XiCon Loss:2.5569 x Lambda(1.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8530
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.1064725
	speed: 0.0263s/iter; left time: 491.9433s
	iters: 200, epoch: 22 | loss: 3.0173974
	speed: 0.0218s/iter; left time: 405.5766s
Epoch: 22 cost time: 5.764528036117554
Epoch: 22, Steps: 238 Train Loss: 3.0933 (Forecasting Loss:0.5378 + XiCon Loss:2.5556 x Lambda(1.0)), Vali MSE Loss: 1.0078 Test MSE Loss: 0.8530
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.0959086
	speed: 0.0276s/iter; left time: 508.9114s
	iters: 200, epoch: 23 | loss: 3.1725311
	speed: 0.0219s/iter; left time: 402.4834s
Epoch: 23 cost time: 5.838271141052246
Epoch: 23, Steps: 238 Train Loss: 3.1022 (Forecasting Loss:0.5378 + XiCon Loss:2.5644 x Lambda(1.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8530
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.1228728
	speed: 0.0268s/iter; left time: 487.8809s
	iters: 200, epoch: 24 | loss: 3.1305888
	speed: 0.0235s/iter; left time: 426.7784s
Epoch: 24 cost time: 5.8898561000823975
Epoch: 24, Steps: 238 Train Loss: 3.1014 (Forecasting Loss:0.5378 + XiCon Loss:2.5636 x Lambda(1.0)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8530
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.1081674
	speed: 0.0252s/iter; left time: 453.3436s
	iters: 200, epoch: 25 | loss: 3.1534486
	speed: 0.0231s/iter; left time: 413.1453s
Epoch: 25 cost time: 5.637212753295898
Epoch: 25, Steps: 238 Train Loss: 3.0974 (Forecasting Loss:0.5376 + XiCon Loss:2.5598 x Lambda(1.0)), Vali MSE Loss: 1.0083 Test MSE Loss: 0.8530
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.1584649
	speed: 0.0270s/iter; left time: 479.7241s
	iters: 200, epoch: 26 | loss: 3.1434417
	speed: 0.0224s/iter; left time: 396.1962s
Epoch: 26 cost time: 5.816385984420776
Epoch: 26, Steps: 238 Train Loss: 3.0989 (Forecasting Loss:0.5378 + XiCon Loss:2.5611 x Lambda(1.0)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8530
Validation loss decreased (1.006885 --> 1.006858).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 2.9730620
	speed: 0.0268s/iter; left time: 468.5588s
	iters: 200, epoch: 27 | loss: 3.2164216
	speed: 0.0225s/iter; left time: 392.1243s
Epoch: 27 cost time: 5.795710802078247
Epoch: 27, Steps: 238 Train Loss: 3.1046 (Forecasting Loss:0.5377 + XiCon Loss:2.5669 x Lambda(1.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8530
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.1216993
	speed: 0.0264s/iter; left time: 456.4682s
	iters: 200, epoch: 28 | loss: 3.1102078
	speed: 0.0227s/iter; left time: 389.4637s
Epoch: 28 cost time: 5.724549770355225
Epoch: 28, Steps: 238 Train Loss: 3.0972 (Forecasting Loss:0.5378 + XiCon Loss:2.5594 x Lambda(1.0)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8530
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.1157150
	speed: 0.0269s/iter; left time: 457.5172s
	iters: 200, epoch: 29 | loss: 3.0613763
	speed: 0.0220s/iter; left time: 373.3388s
Epoch: 29 cost time: 5.776355981826782
Epoch: 29, Steps: 238 Train Loss: 3.1009 (Forecasting Loss:0.5377 + XiCon Loss:2.5632 x Lambda(1.0)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8530
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.0847507
	speed: 0.0263s/iter; left time: 442.0069s
	iters: 200, epoch: 30 | loss: 3.1434543
	speed: 0.0227s/iter; left time: 379.7335s
Epoch: 30 cost time: 5.777769327163696
Epoch: 30, Steps: 238 Train Loss: 3.0939 (Forecasting Loss:0.5379 + XiCon Loss:2.5560 x Lambda(1.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8530
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.0719440
	speed: 0.0268s/iter; left time: 443.1255s
	iters: 200, epoch: 31 | loss: 3.0274148
	speed: 0.0236s/iter; left time: 388.6040s
Epoch: 31 cost time: 5.828998804092407
Epoch: 31, Steps: 238 Train Loss: 3.0990 (Forecasting Loss:0.5376 + XiCon Loss:2.5613 x Lambda(1.0)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8530
Validation loss decreased (1.006858 --> 1.006799).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 3.1662614
	speed: 0.0261s/iter; left time: 425.6627s
	iters: 200, epoch: 32 | loss: 3.1132469
	speed: 0.0216s/iter; left time: 351.1907s
Epoch: 32 cost time: 5.671788692474365
Epoch: 32, Steps: 238 Train Loss: 3.0962 (Forecasting Loss:0.5378 + XiCon Loss:2.5584 x Lambda(1.0)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8530
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 3.1196351
	speed: 0.0266s/iter; left time: 427.3488s
	iters: 200, epoch: 33 | loss: 3.0455465
	speed: 0.0224s/iter; left time: 357.5891s
Epoch: 33 cost time: 5.794710397720337
Epoch: 33, Steps: 238 Train Loss: 3.1007 (Forecasting Loss:0.5377 + XiCon Loss:2.5629 x Lambda(1.0)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8530
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 3.1306052
	speed: 0.0253s/iter; left time: 401.2317s
	iters: 200, epoch: 34 | loss: 3.1916108
	speed: 0.0235s/iter; left time: 369.7999s
Epoch: 34 cost time: 5.717894554138184
Epoch: 34, Steps: 238 Train Loss: 3.1001 (Forecasting Loss:0.5379 + XiCon Loss:2.5622 x Lambda(1.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8530
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 3.0668340
	speed: 0.0263s/iter; left time: 410.0097s
	iters: 200, epoch: 35 | loss: 3.0174003
	speed: 0.0214s/iter; left time: 331.4177s
Epoch: 35 cost time: 5.6402318477630615
Epoch: 35, Steps: 238 Train Loss: 3.0958 (Forecasting Loss:0.5378 + XiCon Loss:2.5580 x Lambda(1.0)), Vali MSE Loss: 1.0074 Test MSE Loss: 0.8530
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 3.0937476
	speed: 0.0263s/iter; left time: 404.3338s
	iters: 200, epoch: 36 | loss: 3.1133592
	speed: 0.0220s/iter; left time: 336.6289s
Epoch: 36 cost time: 5.7857584953308105
Epoch: 36, Steps: 238 Train Loss: 3.0988 (Forecasting Loss:0.5379 + XiCon Loss:2.5609 x Lambda(1.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8530
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 3.1496539
	speed: 0.0266s/iter; left time: 402.9208s
	iters: 200, epoch: 37 | loss: 3.1790552
	speed: 0.0228s/iter; left time: 343.1498s
Epoch: 37 cost time: 5.834627866744995
Epoch: 37, Steps: 238 Train Loss: 3.0995 (Forecasting Loss:0.5378 + XiCon Loss:2.5616 x Lambda(1.0)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8530
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 3.1015120
	speed: 0.0258s/iter; left time: 384.7783s
	iters: 200, epoch: 38 | loss: 3.0222502
	speed: 0.0227s/iter; left time: 336.1246s
Epoch: 38 cost time: 5.637166500091553
Epoch: 38, Steps: 238 Train Loss: 3.1056 (Forecasting Loss:0.5376 + XiCon Loss:2.5680 x Lambda(1.0)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8530
Validation loss decreased (1.006799 --> 1.006732).  Saving model ...
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 3.1580160
	speed: 0.0256s/iter; left time: 375.7766s
	iters: 200, epoch: 39 | loss: 3.0415490
	speed: 0.0221s/iter; left time: 321.4418s
Epoch: 39 cost time: 5.676764011383057
Epoch: 39, Steps: 238 Train Loss: 3.1027 (Forecasting Loss:0.5378 + XiCon Loss:2.5649 x Lambda(1.0)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8530
Validation loss decreased (1.006732 --> 1.006391).  Saving model ...
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 3.0583229
	speed: 0.0277s/iter; left time: 399.5956s
	iters: 200, epoch: 40 | loss: 3.1368456
	speed: 0.0211s/iter; left time: 302.0262s
Epoch: 40 cost time: 5.697784423828125
Epoch: 40, Steps: 238 Train Loss: 3.1008 (Forecasting Loss:0.5379 + XiCon Loss:2.5629 x Lambda(1.0)), Vali MSE Loss: 1.0078 Test MSE Loss: 0.8530
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 3.1272736
	speed: 0.0246s/iter; left time: 348.4599s
	iters: 200, epoch: 41 | loss: 3.0834022
	speed: 0.0222s/iter; left time: 312.0998s
Epoch: 41 cost time: 5.518793821334839
Epoch: 41, Steps: 238 Train Loss: 3.1027 (Forecasting Loss:0.5378 + XiCon Loss:2.5648 x Lambda(1.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8530
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 3.1246004
	speed: 0.0247s/iter; left time: 343.8370s
	iters: 200, epoch: 42 | loss: 3.1747742
	speed: 0.0209s/iter; left time: 289.7243s
Epoch: 42 cost time: 5.40335488319397
Epoch: 42, Steps: 238 Train Loss: 3.1012 (Forecasting Loss:0.5379 + XiCon Loss:2.5633 x Lambda(1.0)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8530
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 3.0259621
	speed: 0.0240s/iter; left time: 329.4835s
	iters: 200, epoch: 43 | loss: 3.1401255
	speed: 0.0213s/iter; left time: 290.1706s
Epoch: 43 cost time: 5.292731761932373
Epoch: 43, Steps: 238 Train Loss: 3.1012 (Forecasting Loss:0.5377 + XiCon Loss:2.5634 x Lambda(1.0)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8530
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323207e-17
	iters: 100, epoch: 44 | loss: 3.1221657
	speed: 0.0258s/iter; left time: 347.5144s
	iters: 200, epoch: 44 | loss: 3.0030725
	speed: 0.0231s/iter; left time: 308.2881s
Epoch: 44 cost time: 5.696722030639648
Epoch: 44, Steps: 238 Train Loss: 3.0982 (Forecasting Loss:0.5378 + XiCon Loss:2.5605 x Lambda(1.0)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8530
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161604e-17
	iters: 100, epoch: 45 | loss: 3.0897195
	speed: 0.0255s/iter; left time: 337.7294s
	iters: 200, epoch: 45 | loss: 3.1459064
	speed: 0.0220s/iter; left time: 289.4038s
Epoch: 45 cost time: 5.59226655960083
Epoch: 45, Steps: 238 Train Loss: 3.1044 (Forecasting Loss:0.5376 + XiCon Loss:2.5668 x Lambda(1.0)), Vali MSE Loss: 1.0081 Test MSE Loss: 0.8530
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-18
	iters: 100, epoch: 46 | loss: 3.0958133
	speed: 0.0244s/iter; left time: 316.4180s
	iters: 200, epoch: 46 | loss: 3.1385520
	speed: 0.0207s/iter; left time: 266.4533s
Epoch: 46 cost time: 5.318951606750488
Epoch: 46, Steps: 238 Train Loss: 3.1019 (Forecasting Loss:0.5379 + XiCon Loss:2.5641 x Lambda(1.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8530
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-18
	iters: 100, epoch: 47 | loss: 3.0865192
	speed: 0.0258s/iter; left time: 329.5635s
	iters: 200, epoch: 47 | loss: 3.0313320
	speed: 0.0205s/iter; left time: 259.0964s
Epoch: 47 cost time: 5.413944959640503
Epoch: 47, Steps: 238 Train Loss: 3.1032 (Forecasting Loss:0.5379 + XiCon Loss:2.5653 x Lambda(1.0)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8530
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-18
	iters: 100, epoch: 48 | loss: 3.0443811
	speed: 0.0243s/iter; left time: 303.5445s
	iters: 200, epoch: 48 | loss: 3.1502223
	speed: 0.0203s/iter; left time: 251.6240s
Epoch: 48 cost time: 5.2471513748168945
Epoch: 48, Steps: 238 Train Loss: 3.1045 (Forecasting Loss:0.5378 + XiCon Loss:2.5667 x Lambda(1.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8530
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-19
	iters: 100, epoch: 49 | loss: 3.0780816
	speed: 0.0268s/iter; left time: 328.5982s
	iters: 200, epoch: 49 | loss: 3.1163890
	speed: 0.0217s/iter; left time: 264.2121s
Epoch: 49 cost time: 5.76934552192688
Epoch: 49, Steps: 238 Train Loss: 3.1008 (Forecasting Loss:0.5377 + XiCon Loss:2.5631 x Lambda(1.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8530
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9841187000274658, mae:0.7218130826950073, mape:4.797693729400635, mspe:2738.636474609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.2678
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 3.5930760
	speed: 0.0298s/iter; left time: 705.3014s
	iters: 200, epoch: 1 | loss: 3.4235606
	speed: 0.0217s/iter; left time: 511.4402s
Epoch: 1 cost time: 6.075539588928223
Epoch: 1, Steps: 238 Train Loss: 3.5629 (Forecasting Loss:0.9872 + XiCon Loss:2.5757 x Lambda(1.0)), Vali MSE Loss: 1.7718 Test MSE Loss: 0.9677
Validation loss decreased (inf --> 1.771849).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.2433648
	speed: 0.0256s/iter; left time: 599.7511s
	iters: 200, epoch: 2 | loss: 3.1381054
	speed: 0.0222s/iter; left time: 518.7087s
Epoch: 2 cost time: 5.678864240646362
Epoch: 2, Steps: 238 Train Loss: 3.1852 (Forecasting Loss:0.6170 + XiCon Loss:2.5682 x Lambda(1.0)), Vali MSE Loss: 1.0394 Test MSE Loss: 0.8536
Validation loss decreased (1.771849 --> 1.039381).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.0242774
	speed: 0.0269s/iter; left time: 624.2426s
	iters: 200, epoch: 3 | loss: 3.1489797
	speed: 0.0213s/iter; left time: 491.9384s
Epoch: 3 cost time: 5.769363641738892
Epoch: 3, Steps: 238 Train Loss: 3.1113 (Forecasting Loss:0.5500 + XiCon Loss:2.5613 x Lambda(1.0)), Vali MSE Loss: 1.0171 Test MSE Loss: 0.8455
Validation loss decreased (1.039381 --> 1.017115).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 2.9975076
	speed: 0.0255s/iter; left time: 585.9424s
	iters: 200, epoch: 4 | loss: 3.1317704
	speed: 0.0223s/iter; left time: 510.7718s
Epoch: 4 cost time: 5.665111541748047
Epoch: 4, Steps: 238 Train Loss: 3.0991 (Forecasting Loss:0.5407 + XiCon Loss:2.5584 x Lambda(1.0)), Vali MSE Loss: 1.0102 Test MSE Loss: 0.8433
Validation loss decreased (1.017115 --> 1.010159).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.1472530
	speed: 0.0270s/iter; left time: 614.2742s
	iters: 200, epoch: 5 | loss: 3.2258017
	speed: 0.0230s/iter; left time: 520.9353s
Epoch: 5 cost time: 5.851803779602051
Epoch: 5, Steps: 238 Train Loss: 3.0906 (Forecasting Loss:0.5367 + XiCon Loss:2.5539 x Lambda(1.0)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8427
Validation loss decreased (1.010159 --> 1.006481).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.0119090
	speed: 0.0269s/iter; left time: 605.3163s
	iters: 200, epoch: 6 | loss: 3.1335986
	speed: 0.0229s/iter; left time: 512.4203s
Epoch: 6 cost time: 5.78668737411499
Epoch: 6, Steps: 238 Train Loss: 3.0825 (Forecasting Loss:0.5348 + XiCon Loss:2.5478 x Lambda(1.0)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8425
Validation loss decreased (1.006481 --> 1.005059).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.0203853
	speed: 0.0270s/iter; left time: 601.5726s
	iters: 200, epoch: 7 | loss: 3.0386314
	speed: 0.0214s/iter; left time: 474.5114s
Epoch: 7 cost time: 5.724322319030762
Epoch: 7, Steps: 238 Train Loss: 3.0866 (Forecasting Loss:0.5338 + XiCon Loss:2.5528 x Lambda(1.0)), Vali MSE Loss: 1.0035 Test MSE Loss: 0.8424
Validation loss decreased (1.005059 --> 1.003486).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.0798540
	speed: 0.0262s/iter; left time: 576.7846s
	iters: 200, epoch: 8 | loss: 3.0719588
	speed: 0.0231s/iter; left time: 505.8219s
Epoch: 8 cost time: 5.720799207687378
Epoch: 8, Steps: 238 Train Loss: 3.0888 (Forecasting Loss:0.5334 + XiCon Loss:2.5554 x Lambda(1.0)), Vali MSE Loss: 1.0037 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1314213
	speed: 0.0265s/iter; left time: 577.2152s
	iters: 200, epoch: 9 | loss: 3.0496936
	speed: 0.0220s/iter; left time: 477.9077s
Epoch: 9 cost time: 5.775115966796875
Epoch: 9, Steps: 238 Train Loss: 3.0831 (Forecasting Loss:0.5332 + XiCon Loss:2.5498 x Lambda(1.0)), Vali MSE Loss: 1.0033 Test MSE Loss: 0.8423
Validation loss decreased (1.003486 --> 1.003279).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.0382271
	speed: 0.0262s/iter; left time: 564.3844s
	iters: 200, epoch: 10 | loss: 3.0709162
	speed: 0.0226s/iter; left time: 483.9622s
Epoch: 10 cost time: 5.779661417007446
Epoch: 10, Steps: 238 Train Loss: 3.0851 (Forecasting Loss:0.5330 + XiCon Loss:2.5521 x Lambda(1.0)), Vali MSE Loss: 1.0034 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1151457
	speed: 0.0265s/iter; left time: 563.9914s
	iters: 200, epoch: 11 | loss: 3.1092687
	speed: 0.0229s/iter; left time: 486.6841s
Epoch: 11 cost time: 5.871208190917969
Epoch: 11, Steps: 238 Train Loss: 3.0886 (Forecasting Loss:0.5330 + XiCon Loss:2.5556 x Lambda(1.0)), Vali MSE Loss: 1.0029 Test MSE Loss: 0.8423
Validation loss decreased (1.003279 --> 1.002912).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.0322981
	speed: 0.0258s/iter; left time: 543.2180s
	iters: 200, epoch: 12 | loss: 3.0392087
	speed: 0.0229s/iter; left time: 480.7136s
Epoch: 12 cost time: 5.651206731796265
Epoch: 12, Steps: 238 Train Loss: 3.0855 (Forecasting Loss:0.5330 + XiCon Loss:2.5526 x Lambda(1.0)), Vali MSE Loss: 1.0025 Test MSE Loss: 0.8423
Validation loss decreased (1.002912 --> 1.002505).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1226599
	speed: 0.0256s/iter; left time: 533.5315s
	iters: 200, epoch: 13 | loss: 3.0574970
	speed: 0.0232s/iter; left time: 480.4631s
Epoch: 13 cost time: 5.790497779846191
Epoch: 13, Steps: 238 Train Loss: 3.0861 (Forecasting Loss:0.5331 + XiCon Loss:2.5531 x Lambda(1.0)), Vali MSE Loss: 1.0030 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1383395
	speed: 0.0255s/iter; left time: 524.5115s
	iters: 200, epoch: 14 | loss: 3.1286776
	speed: 0.0227s/iter; left time: 466.4126s
Epoch: 14 cost time: 5.6664137840271
Epoch: 14, Steps: 238 Train Loss: 3.0800 (Forecasting Loss:0.5331 + XiCon Loss:2.5469 x Lambda(1.0)), Vali MSE Loss: 1.0031 Test MSE Loss: 0.8423
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.0811119
	speed: 0.0258s/iter; left time: 525.9465s
	iters: 200, epoch: 15 | loss: 3.1131005
	speed: 0.0222s/iter; left time: 449.5736s
Epoch: 15 cost time: 5.710177421569824
Epoch: 15, Steps: 238 Train Loss: 3.0874 (Forecasting Loss:0.5329 + XiCon Loss:2.5545 x Lambda(1.0)), Vali MSE Loss: 1.0030 Test MSE Loss: 0.8423
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.0685577
	speed: 0.0263s/iter; left time: 528.7472s
	iters: 200, epoch: 16 | loss: 3.0394006
	speed: 0.0219s/iter; left time: 438.5780s
Epoch: 16 cost time: 5.7290425300598145
Epoch: 16, Steps: 238 Train Loss: 3.0868 (Forecasting Loss:0.5328 + XiCon Loss:2.5539 x Lambda(1.0)), Vali MSE Loss: 1.0018 Test MSE Loss: 0.8423
Validation loss decreased (1.002505 --> 1.001805).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.1684914
	speed: 0.0261s/iter; left time: 519.9751s
	iters: 200, epoch: 17 | loss: 3.1497126
	speed: 0.0221s/iter; left time: 437.4637s
Epoch: 17 cost time: 5.654033184051514
Epoch: 17, Steps: 238 Train Loss: 3.0847 (Forecasting Loss:0.5328 + XiCon Loss:2.5518 x Lambda(1.0)), Vali MSE Loss: 1.0026 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1411662
	speed: 0.0260s/iter; left time: 510.5010s
	iters: 200, epoch: 18 | loss: 3.0161152
	speed: 0.0220s/iter; left time: 430.2121s
Epoch: 18 cost time: 5.697085618972778
Epoch: 18, Steps: 238 Train Loss: 3.0823 (Forecasting Loss:0.5331 + XiCon Loss:2.5492 x Lambda(1.0)), Vali MSE Loss: 1.0037 Test MSE Loss: 0.8423
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1273313
	speed: 0.0279s/iter; left time: 541.6690s
	iters: 200, epoch: 19 | loss: 3.1611719
	speed: 0.0228s/iter; left time: 440.0737s
Epoch: 19 cost time: 5.998272895812988
Epoch: 19, Steps: 238 Train Loss: 3.0900 (Forecasting Loss:0.5332 + XiCon Loss:2.5568 x Lambda(1.0)), Vali MSE Loss: 1.0025 Test MSE Loss: 0.8423
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.0636334
	speed: 0.0254s/iter; left time: 487.6034s
	iters: 200, epoch: 20 | loss: 3.0869761
	speed: 0.0225s/iter; left time: 430.0869s
Epoch: 20 cost time: 5.650250673294067
Epoch: 20, Steps: 238 Train Loss: 3.0863 (Forecasting Loss:0.5330 + XiCon Loss:2.5532 x Lambda(1.0)), Vali MSE Loss: 1.0026 Test MSE Loss: 0.8423
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.0872154
	speed: 0.0273s/iter; left time: 516.1902s
	iters: 200, epoch: 21 | loss: 3.2033398
	speed: 0.0239s/iter; left time: 451.0543s
Epoch: 21 cost time: 6.026197195053101
Epoch: 21, Steps: 238 Train Loss: 3.0887 (Forecasting Loss:0.5331 + XiCon Loss:2.5556 x Lambda(1.0)), Vali MSE Loss: 1.0031 Test MSE Loss: 0.8423
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 2.9744549
	speed: 0.0266s/iter; left time: 496.5918s
	iters: 200, epoch: 22 | loss: 3.1202893
	speed: 0.0237s/iter; left time: 441.7702s
Epoch: 22 cost time: 5.84453272819519
Epoch: 22, Steps: 238 Train Loss: 3.0822 (Forecasting Loss:0.5331 + XiCon Loss:2.5491 x Lambda(1.0)), Vali MSE Loss: 1.0027 Test MSE Loss: 0.8423
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.0555041
	speed: 0.0262s/iter; left time: 483.0314s
	iters: 200, epoch: 23 | loss: 3.0743070
	speed: 0.0222s/iter; left time: 407.4023s
Epoch: 23 cost time: 5.755268096923828
Epoch: 23, Steps: 238 Train Loss: 3.0817 (Forecasting Loss:0.5330 + XiCon Loss:2.5487 x Lambda(1.0)), Vali MSE Loss: 1.0027 Test MSE Loss: 0.8423
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.0526936
	speed: 0.0255s/iter; left time: 465.6361s
	iters: 200, epoch: 24 | loss: 3.1566849
	speed: 0.0220s/iter; left time: 399.2955s
Epoch: 24 cost time: 5.684227466583252
Epoch: 24, Steps: 238 Train Loss: 3.0821 (Forecasting Loss:0.5332 + XiCon Loss:2.5488 x Lambda(1.0)), Vali MSE Loss: 1.0035 Test MSE Loss: 0.8423
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.1209006
	speed: 0.0257s/iter; left time: 461.8985s
	iters: 200, epoch: 25 | loss: 3.1311510
	speed: 0.0228s/iter; left time: 407.0889s
Epoch: 25 cost time: 5.719933271408081
Epoch: 25, Steps: 238 Train Loss: 3.0849 (Forecasting Loss:0.5330 + XiCon Loss:2.5519 x Lambda(1.0)), Vali MSE Loss: 1.0033 Test MSE Loss: 0.8423
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.0690677
	speed: 0.0263s/iter; left time: 466.2530s
	iters: 200, epoch: 26 | loss: 3.1172943
	speed: 0.0229s/iter; left time: 404.0058s
Epoch: 26 cost time: 5.6919145584106445
Epoch: 26, Steps: 238 Train Loss: 3.0814 (Forecasting Loss:0.5332 + XiCon Loss:2.5483 x Lambda(1.0)), Vali MSE Loss: 1.0033 Test MSE Loss: 0.8423
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9684892296791077, mae:0.7161211967468262, mape:4.663336753845215, mspe:2553.3017578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.9005
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 3.6949253
	speed: 0.0305s/iter; left time: 723.8717s
	iters: 200, epoch: 1 | loss: 3.8262718
	speed: 0.0235s/iter; left time: 555.7401s
Epoch: 1 cost time: 6.267101764678955
Epoch: 1, Steps: 238 Train Loss: 3.7432 (Forecasting Loss:1.1894 + XiCon Loss:2.5538 x Lambda(1.0)), Vali MSE Loss: 2.1399 Test MSE Loss: 1.0912
Validation loss decreased (inf --> 2.139891).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.0443945
	speed: 0.0276s/iter; left time: 647.1849s
	iters: 200, epoch: 2 | loss: 3.0506320
	speed: 0.0231s/iter; left time: 540.5468s
Epoch: 2 cost time: 5.931212425231934
Epoch: 2, Steps: 238 Train Loss: 3.1961 (Forecasting Loss:0.6458 + XiCon Loss:2.5503 x Lambda(1.0)), Vali MSE Loss: 1.0210 Test MSE Loss: 0.8670
Validation loss decreased (2.139891 --> 1.020983).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.0540819
	speed: 0.0269s/iter; left time: 624.5227s
	iters: 200, epoch: 3 | loss: 3.0557733
	speed: 0.0229s/iter; left time: 528.4469s
Epoch: 3 cost time: 5.778875112533569
Epoch: 3, Steps: 238 Train Loss: 3.1005 (Forecasting Loss:0.5519 + XiCon Loss:2.5487 x Lambda(1.0)), Vali MSE Loss: 1.0015 Test MSE Loss: 0.8627
Validation loss decreased (1.020983 --> 1.001478).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 2.9993019
	speed: 0.0273s/iter; left time: 627.3040s
	iters: 200, epoch: 4 | loss: 3.0777342
	speed: 0.0235s/iter; left time: 537.2040s
Epoch: 4 cost time: 5.96580696105957
Epoch: 4, Steps: 238 Train Loss: 3.0803 (Forecasting Loss:0.5433 + XiCon Loss:2.5370 x Lambda(1.0)), Vali MSE Loss: 0.9959 Test MSE Loss: 0.8615
Validation loss decreased (1.001478 --> 0.995871).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.0122261
	speed: 0.0257s/iter; left time: 583.5586s
	iters: 200, epoch: 5 | loss: 3.0238664
	speed: 0.0233s/iter; left time: 528.0018s
Epoch: 5 cost time: 5.78109884262085
Epoch: 5, Steps: 238 Train Loss: 3.0791 (Forecasting Loss:0.5399 + XiCon Loss:2.5392 x Lambda(1.0)), Vali MSE Loss: 0.9914 Test MSE Loss: 0.8611
Validation loss decreased (0.995871 --> 0.991433).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.1276679
	speed: 0.0260s/iter; left time: 584.7232s
	iters: 200, epoch: 6 | loss: 3.0438073
	speed: 0.0226s/iter; left time: 505.9683s
Epoch: 6 cost time: 5.751568794250488
Epoch: 6, Steps: 238 Train Loss: 3.0800 (Forecasting Loss:0.5383 + XiCon Loss:2.5417 x Lambda(1.0)), Vali MSE Loss: 0.9899 Test MSE Loss: 0.8610
Validation loss decreased (0.991433 --> 0.989883).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.1035755
	speed: 0.0263s/iter; left time: 585.7716s
	iters: 200, epoch: 7 | loss: 3.0166376
	speed: 0.0220s/iter; left time: 487.4679s
Epoch: 7 cost time: 5.6759679317474365
Epoch: 7, Steps: 238 Train Loss: 3.0827 (Forecasting Loss:0.5374 + XiCon Loss:2.5452 x Lambda(1.0)), Vali MSE Loss: 0.9905 Test MSE Loss: 0.8607
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.0862489
	speed: 0.0266s/iter; left time: 585.5476s
	iters: 200, epoch: 8 | loss: 3.0274484
	speed: 0.0216s/iter; left time: 473.9978s
Epoch: 8 cost time: 5.739847183227539
Epoch: 8, Steps: 238 Train Loss: 3.0795 (Forecasting Loss:0.5368 + XiCon Loss:2.5427 x Lambda(1.0)), Vali MSE Loss: 0.9889 Test MSE Loss: 0.8607
Validation loss decreased (0.989883 --> 0.988860).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.0873013
	speed: 0.0252s/iter; left time: 549.6962s
	iters: 200, epoch: 9 | loss: 3.0425785
	speed: 0.0214s/iter; left time: 464.8282s
Epoch: 9 cost time: 5.551684141159058
Epoch: 9, Steps: 238 Train Loss: 3.0784 (Forecasting Loss:0.5365 + XiCon Loss:2.5419 x Lambda(1.0)), Vali MSE Loss: 0.9892 Test MSE Loss: 0.8607
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.0846295
	speed: 0.0253s/iter; left time: 544.4841s
	iters: 200, epoch: 10 | loss: 2.9860005
	speed: 0.0212s/iter; left time: 453.9424s
Epoch: 10 cost time: 5.412400484085083
Epoch: 10, Steps: 238 Train Loss: 3.0796 (Forecasting Loss:0.5368 + XiCon Loss:2.5429 x Lambda(1.0)), Vali MSE Loss: 0.9898 Test MSE Loss: 0.8607
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.0081158
	speed: 0.0254s/iter; left time: 540.8046s
	iters: 200, epoch: 11 | loss: 3.0529382
	speed: 0.0212s/iter; left time: 450.1431s
Epoch: 11 cost time: 5.478719711303711
Epoch: 11, Steps: 238 Train Loss: 3.0814 (Forecasting Loss:0.5366 + XiCon Loss:2.5448 x Lambda(1.0)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8606
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1479578
	speed: 0.0251s/iter; left time: 528.4344s
	iters: 200, epoch: 12 | loss: 3.0611415
	speed: 0.0216s/iter; left time: 453.7749s
Epoch: 12 cost time: 5.470793008804321
Epoch: 12, Steps: 238 Train Loss: 3.0776 (Forecasting Loss:0.5365 + XiCon Loss:2.5411 x Lambda(1.0)), Vali MSE Loss: 0.9894 Test MSE Loss: 0.8606
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.0497484
	speed: 0.0266s/iter; left time: 555.1307s
	iters: 200, epoch: 13 | loss: 3.1310608
	speed: 0.0216s/iter; left time: 447.2582s
Epoch: 13 cost time: 5.630302906036377
Epoch: 13, Steps: 238 Train Loss: 3.0808 (Forecasting Loss:0.5368 + XiCon Loss:2.5440 x Lambda(1.0)), Vali MSE Loss: 0.9885 Test MSE Loss: 0.8606
Validation loss decreased (0.988860 --> 0.988506).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1706085
	speed: 0.0253s/iter; left time: 520.7888s
	iters: 200, epoch: 14 | loss: 3.0148780
	speed: 0.0209s/iter; left time: 428.4728s
Epoch: 14 cost time: 5.4353392124176025
Epoch: 14, Steps: 238 Train Loss: 3.0805 (Forecasting Loss:0.5365 + XiCon Loss:2.5440 x Lambda(1.0)), Vali MSE Loss: 0.9888 Test MSE Loss: 0.8606
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.0635202
	speed: 0.0254s/iter; left time: 516.5404s
	iters: 200, epoch: 15 | loss: 3.0608726
	speed: 0.0213s/iter; left time: 431.0722s
Epoch: 15 cost time: 5.455298900604248
Epoch: 15, Steps: 238 Train Loss: 3.0776 (Forecasting Loss:0.5364 + XiCon Loss:2.5412 x Lambda(1.0)), Vali MSE Loss: 0.9887 Test MSE Loss: 0.8606
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.0168056
	speed: 0.0246s/iter; left time: 495.8727s
	iters: 200, epoch: 16 | loss: 3.0278757
	speed: 0.0216s/iter; left time: 433.2336s
Epoch: 16 cost time: 5.472238540649414
Epoch: 16, Steps: 238 Train Loss: 3.0738 (Forecasting Loss:0.5366 + XiCon Loss:2.5372 x Lambda(1.0)), Vali MSE Loss: 0.9888 Test MSE Loss: 0.8606
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.0504777
	speed: 0.0251s/iter; left time: 499.3325s
	iters: 200, epoch: 17 | loss: 3.1939685
	speed: 0.0231s/iter; left time: 456.2297s
Epoch: 17 cost time: 5.79811692237854
Epoch: 17, Steps: 238 Train Loss: 3.0785 (Forecasting Loss:0.5366 + XiCon Loss:2.5419 x Lambda(1.0)), Vali MSE Loss: 0.9888 Test MSE Loss: 0.8606
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1298337
	speed: 0.0274s/iter; left time: 538.8157s
	iters: 200, epoch: 18 | loss: 3.1104641
	speed: 0.0231s/iter; left time: 451.8573s
Epoch: 18 cost time: 5.853189468383789
Epoch: 18, Steps: 238 Train Loss: 3.0761 (Forecasting Loss:0.5368 + XiCon Loss:2.5394 x Lambda(1.0)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8606
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1188574
	speed: 0.0267s/iter; left time: 518.4213s
	iters: 200, epoch: 19 | loss: 3.0277829
	speed: 0.0219s/iter; left time: 422.3387s
Epoch: 19 cost time: 5.76093864440918
Epoch: 19, Steps: 238 Train Loss: 3.0741 (Forecasting Loss:0.5366 + XiCon Loss:2.5375 x Lambda(1.0)), Vali MSE Loss: 0.9889 Test MSE Loss: 0.8606
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.0050759
	speed: 0.0269s/iter; left time: 515.7852s
	iters: 200, epoch: 20 | loss: 3.1019435
	speed: 0.0230s/iter; left time: 438.4172s
Epoch: 20 cost time: 5.905782461166382
Epoch: 20, Steps: 238 Train Loss: 3.0838 (Forecasting Loss:0.5363 + XiCon Loss:2.5474 x Lambda(1.0)), Vali MSE Loss: 0.9888 Test MSE Loss: 0.8606
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.0644989
	speed: 0.0282s/iter; left time: 534.0815s
	iters: 200, epoch: 21 | loss: 3.1166904
	speed: 0.0231s/iter; left time: 434.4775s
Epoch: 21 cost time: 6.025637149810791
Epoch: 21, Steps: 238 Train Loss: 3.0757 (Forecasting Loss:0.5364 + XiCon Loss:2.5393 x Lambda(1.0)), Vali MSE Loss: 0.9893 Test MSE Loss: 0.8606
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.0300369
	speed: 0.0264s/iter; left time: 494.2444s
	iters: 200, epoch: 22 | loss: 3.1626563
	speed: 0.0225s/iter; left time: 419.0062s
Epoch: 22 cost time: 5.752022743225098
Epoch: 22, Steps: 238 Train Loss: 3.0760 (Forecasting Loss:0.5365 + XiCon Loss:2.5395 x Lambda(1.0)), Vali MSE Loss: 0.9891 Test MSE Loss: 0.8606
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.0011518
	speed: 0.0270s/iter; left time: 498.1635s
	iters: 200, epoch: 23 | loss: 3.0475981
	speed: 0.0228s/iter; left time: 419.5737s
Epoch: 23 cost time: 5.8988847732543945
Epoch: 23, Steps: 238 Train Loss: 3.0751 (Forecasting Loss:0.5363 + XiCon Loss:2.5387 x Lambda(1.0)), Vali MSE Loss: 0.9892 Test MSE Loss: 0.8606
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9947250485420227, mae:0.7265664339065552, mape:4.846462726593018, mspe:2774.85595703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9812+-0.01190, MAE:0.7211+-0.00478, MAPE:4.7676+-0.08380, MSPE:2680.3735+-106.61389, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.6368
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 3.7662740
	speed: 0.0371s/iter; left time: 861.8655s
	iters: 200, epoch: 1 | loss: 3.7108920
	speed: 0.0305s/iter; left time: 705.6457s
Epoch: 1 cost time: 7.801001071929932
Epoch: 1, Steps: 233 Train Loss: 3.8378 (Forecasting Loss:1.0189 + XiCon Loss:2.8189 x Lambda(1.0)), Vali MSE Loss: 1.8607 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860678).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3582537
	speed: 0.0329s/iter; left time: 756.3762s
	iters: 200, epoch: 2 | loss: 3.5253277
	speed: 0.0316s/iter; left time: 723.4625s
Epoch: 2 cost time: 7.546929597854614
Epoch: 2, Steps: 233 Train Loss: 3.4595 (Forecasting Loss:0.6524 + XiCon Loss:2.8071 x Lambda(1.0)), Vali MSE Loss: 1.1263 Test MSE Loss: 1.1493
Validation loss decreased (1.860678 --> 1.126283).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3911908
	speed: 0.0344s/iter; left time: 782.2774s
	iters: 200, epoch: 3 | loss: 3.3407850
	speed: 0.0307s/iter; left time: 695.1337s
Epoch: 3 cost time: 7.63850474357605
Epoch: 3, Steps: 233 Train Loss: 3.3679 (Forecasting Loss:0.5887 + XiCon Loss:2.7792 x Lambda(1.0)), Vali MSE Loss: 1.1041 Test MSE Loss: 1.1426
Validation loss decreased (1.126283 --> 1.104139).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3094907
	speed: 0.0343s/iter; left time: 772.5879s
	iters: 200, epoch: 4 | loss: 3.4007599
	speed: 0.0317s/iter; left time: 710.4499s
Epoch: 4 cost time: 7.64199423789978
Epoch: 4, Steps: 233 Train Loss: 3.3342 (Forecasting Loss:0.5810 + XiCon Loss:2.7532 x Lambda(1.0)), Vali MSE Loss: 1.0970 Test MSE Loss: 1.1401
Validation loss decreased (1.104139 --> 1.096972).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2901769
	speed: 0.0335s/iter; left time: 745.6953s
	iters: 200, epoch: 5 | loss: 3.3379400
	speed: 0.0309s/iter; left time: 684.6613s
Epoch: 5 cost time: 7.566765546798706
Epoch: 5, Steps: 233 Train Loss: 3.3182 (Forecasting Loss:0.5781 + XiCon Loss:2.7402 x Lambda(1.0)), Vali MSE Loss: 1.0942 Test MSE Loss: 1.1391
Validation loss decreased (1.096972 --> 1.094155).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3802190
	speed: 0.0329s/iter; left time: 724.7347s
	iters: 200, epoch: 6 | loss: 3.3560085
	speed: 0.0305s/iter; left time: 668.9639s
Epoch: 6 cost time: 7.438327074050903
Epoch: 6, Steps: 233 Train Loss: 3.3119 (Forecasting Loss:0.5767 + XiCon Loss:2.7352 x Lambda(1.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1388
Validation loss decreased (1.094155 --> 1.092561).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2566869
	speed: 0.0330s/iter; left time: 718.4240s
	iters: 200, epoch: 7 | loss: 3.3260269
	speed: 0.0330s/iter; left time: 716.0799s
Epoch: 7 cost time: 7.684331893920898
Epoch: 7, Steps: 233 Train Loss: 3.3045 (Forecasting Loss:0.5760 + XiCon Loss:2.7285 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1388
Validation loss decreased (1.092561 --> 1.091934).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2991576
	speed: 0.0331s/iter; left time: 712.9886s
	iters: 200, epoch: 8 | loss: 3.2966273
	speed: 0.0310s/iter; left time: 665.7627s
Epoch: 8 cost time: 7.541068077087402
Epoch: 8, Steps: 233 Train Loss: 3.3061 (Forecasting Loss:0.5756 + XiCon Loss:2.7304 x Lambda(1.0)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1387
Validation loss decreased (1.091934 --> 1.091818).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3330631
	speed: 0.0339s/iter; left time: 723.2037s
	iters: 200, epoch: 9 | loss: 3.3529048
	speed: 0.0303s/iter; left time: 643.9783s
Epoch: 9 cost time: 7.520744800567627
Epoch: 9, Steps: 233 Train Loss: 3.3064 (Forecasting Loss:0.5754 + XiCon Loss:2.7310 x Lambda(1.0)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1386
Validation loss decreased (1.091818 --> 1.091371).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2126205
	speed: 0.0333s/iter; left time: 702.7761s
	iters: 200, epoch: 10 | loss: 3.2850850
	speed: 0.0317s/iter; left time: 666.8513s
Epoch: 10 cost time: 7.570688009262085
Epoch: 10, Steps: 233 Train Loss: 3.3024 (Forecasting Loss:0.5754 + XiCon Loss:2.7271 x Lambda(1.0)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1386
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2396116
	speed: 0.0348s/iter; left time: 726.2030s
	iters: 200, epoch: 11 | loss: 3.2758164
	speed: 0.0304s/iter; left time: 632.2324s
Epoch: 11 cost time: 7.543330430984497
Epoch: 11, Steps: 233 Train Loss: 3.2998 (Forecasting Loss:0.5753 + XiCon Loss:2.7245 x Lambda(1.0)), Vali MSE Loss: 1.0912 Test MSE Loss: 1.1386
Validation loss decreased (1.091371 --> 1.091157).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2651515
	speed: 0.0340s/iter; left time: 701.4811s
	iters: 200, epoch: 12 | loss: 3.3581028
	speed: 0.0318s/iter; left time: 654.1102s
Epoch: 12 cost time: 7.660665988922119
Epoch: 12, Steps: 233 Train Loss: 3.2986 (Forecasting Loss:0.5753 + XiCon Loss:2.7234 x Lambda(1.0)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1386
Validation loss decreased (1.091157 --> 1.090996).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3117352
	speed: 0.0331s/iter; left time: 674.4537s
	iters: 200, epoch: 13 | loss: 3.2929635
	speed: 0.0305s/iter; left time: 619.5234s
Epoch: 13 cost time: 7.430480003356934
Epoch: 13, Steps: 233 Train Loss: 3.3030 (Forecasting Loss:0.5753 + XiCon Loss:2.7277 x Lambda(1.0)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1386
Validation loss decreased (1.090996 --> 1.090932).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3462684
	speed: 0.0333s/iter; left time: 671.6937s
	iters: 200, epoch: 14 | loss: 3.3234134
	speed: 0.0317s/iter; left time: 635.3592s
Epoch: 14 cost time: 7.544619798660278
Epoch: 14, Steps: 233 Train Loss: 3.2973 (Forecasting Loss:0.5752 + XiCon Loss:2.7220 x Lambda(1.0)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1386
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2895060
	speed: 0.0328s/iter; left time: 653.3790s
	iters: 200, epoch: 15 | loss: 3.3908997
	speed: 0.0315s/iter; left time: 625.3664s
Epoch: 15 cost time: 7.4847588539123535
Epoch: 15, Steps: 233 Train Loss: 3.2997 (Forecasting Loss:0.5753 + XiCon Loss:2.7244 x Lambda(1.0)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1386
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3175359
	speed: 0.0332s/iter; left time: 654.2167s
	iters: 200, epoch: 16 | loss: 3.2809174
	speed: 0.0305s/iter; left time: 597.0220s
Epoch: 16 cost time: 7.411648511886597
Epoch: 16, Steps: 233 Train Loss: 3.2998 (Forecasting Loss:0.5752 + XiCon Loss:2.7246 x Lambda(1.0)), Vali MSE Loss: 1.0905 Test MSE Loss: 1.1386
Validation loss decreased (1.090932 --> 1.090542).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.1946111
	speed: 0.0338s/iter; left time: 658.7720s
	iters: 200, epoch: 17 | loss: 3.2650943
	speed: 0.0308s/iter; left time: 596.2045s
Epoch: 17 cost time: 7.511806488037109
Epoch: 17, Steps: 233 Train Loss: 3.2976 (Forecasting Loss:0.5752 + XiCon Loss:2.7223 x Lambda(1.0)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1386
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3748665
	speed: 0.0350s/iter; left time: 673.8136s
	iters: 200, epoch: 18 | loss: 3.2546453
	speed: 0.0308s/iter; left time: 588.7829s
Epoch: 18 cost time: 7.605914354324341
Epoch: 18, Steps: 233 Train Loss: 3.3011 (Forecasting Loss:0.5752 + XiCon Loss:2.7259 x Lambda(1.0)), Vali MSE Loss: 1.0908 Test MSE Loss: 1.1386
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2451444
	speed: 0.0317s/iter; left time: 602.6243s
	iters: 200, epoch: 19 | loss: 3.3822584
	speed: 0.0305s/iter; left time: 576.4422s
Epoch: 19 cost time: 7.300615549087524
Epoch: 19, Steps: 233 Train Loss: 3.3023 (Forecasting Loss:0.5753 + XiCon Loss:2.7271 x Lambda(1.0)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1386
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2525272
	speed: 0.0335s/iter; left time: 628.9101s
	iters: 200, epoch: 20 | loss: 3.2235379
	speed: 0.0315s/iter; left time: 588.8148s
Epoch: 20 cost time: 7.5696539878845215
Epoch: 20, Steps: 233 Train Loss: 3.3005 (Forecasting Loss:0.5752 + XiCon Loss:2.7253 x Lambda(1.0)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1386
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2801456
	speed: 0.0339s/iter; left time: 628.4070s
	iters: 200, epoch: 21 | loss: 3.2625253
	speed: 0.0320s/iter; left time: 590.6102s
Epoch: 21 cost time: 7.650811672210693
Epoch: 21, Steps: 233 Train Loss: 3.3015 (Forecasting Loss:0.5753 + XiCon Loss:2.7262 x Lambda(1.0)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1386
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2678213
	speed: 0.0340s/iter; left time: 623.0585s
	iters: 200, epoch: 22 | loss: 3.3256121
	speed: 0.0321s/iter; left time: 584.1656s
Epoch: 22 cost time: 7.59555196762085
Epoch: 22, Steps: 233 Train Loss: 3.3026 (Forecasting Loss:0.5753 + XiCon Loss:2.7273 x Lambda(1.0)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1386
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2256165
	speed: 0.0346s/iter; left time: 625.1304s
	iters: 200, epoch: 23 | loss: 3.2544096
	speed: 0.0307s/iter; left time: 551.1303s
Epoch: 23 cost time: 7.607609272003174
Epoch: 23, Steps: 233 Train Loss: 3.2977 (Forecasting Loss:0.5752 + XiCon Loss:2.7225 x Lambda(1.0)), Vali MSE Loss: 1.0909 Test MSE Loss: 1.1386
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3081923
	speed: 0.0345s/iter; left time: 615.4601s
	iters: 200, epoch: 24 | loss: 3.2610471
	speed: 0.0312s/iter; left time: 552.8669s
Epoch: 24 cost time: 7.5355730056762695
Epoch: 24, Steps: 233 Train Loss: 3.3024 (Forecasting Loss:0.5752 + XiCon Loss:2.7272 x Lambda(1.0)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1386
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3086989
	speed: 0.0318s/iter; left time: 560.7243s
	iters: 200, epoch: 25 | loss: 3.3277860
	speed: 0.0299s/iter; left time: 523.6391s
Epoch: 25 cost time: 7.164585113525391
Epoch: 25, Steps: 233 Train Loss: 3.3055 (Forecasting Loss:0.5753 + XiCon Loss:2.7302 x Lambda(1.0)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1386
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2170062
	speed: 0.0319s/iter; left time: 554.8814s
	iters: 200, epoch: 26 | loss: 3.2662158
	speed: 0.0294s/iter; left time: 507.5007s
Epoch: 26 cost time: 7.136072874069214
Epoch: 26, Steps: 233 Train Loss: 3.2953 (Forecasting Loss:0.5753 + XiCon Loss:2.7200 x Lambda(1.0)), Vali MSE Loss: 1.0912 Test MSE Loss: 1.1386
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3975944519042969, mae:0.8795880675315857, mape:6.160369396209717, mspe:4567.5810546875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.2028
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 3.9278076
	speed: 0.0293s/iter; left time: 679.0641s
	iters: 200, epoch: 1 | loss: 4.0479126
	speed: 0.0248s/iter; left time: 572.8888s
Epoch: 1 cost time: 6.261855125427246
Epoch: 1, Steps: 233 Train Loss: 3.9756 (Forecasting Loss:1.1345 + XiCon Loss:2.8410 x Lambda(1.0)), Vali MSE Loss: 2.0440 Test MSE Loss: 1.3325
Validation loss decreased (inf --> 2.043989).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.5643129
	speed: 0.0284s/iter; left time: 651.8928s
	iters: 200, epoch: 2 | loss: 3.3954520
	speed: 0.0246s/iter; left time: 562.5027s
Epoch: 2 cost time: 6.139140844345093
Epoch: 2, Steps: 233 Train Loss: 3.4882 (Forecasting Loss:0.6629 + XiCon Loss:2.8253 x Lambda(1.0)), Vali MSE Loss: 1.1179 Test MSE Loss: 1.1418
Validation loss decreased (2.043989 --> 1.117858).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.4342003
	speed: 0.0279s/iter; left time: 634.6081s
	iters: 200, epoch: 3 | loss: 3.4023819
	speed: 0.0252s/iter; left time: 570.3578s
Epoch: 3 cost time: 6.291348218917847
Epoch: 3, Steps: 233 Train Loss: 3.3997 (Forecasting Loss:0.5895 + XiCon Loss:2.8102 x Lambda(1.0)), Vali MSE Loss: 1.0966 Test MSE Loss: 1.1362
Validation loss decreased (1.117858 --> 1.096587).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5307748
	speed: 0.0312s/iter; left time: 701.1113s
	iters: 200, epoch: 4 | loss: 3.3790522
	speed: 0.0271s/iter; left time: 607.2046s
Epoch: 4 cost time: 6.728865385055542
Epoch: 4, Steps: 233 Train Loss: 3.3805 (Forecasting Loss:0.5814 + XiCon Loss:2.7991 x Lambda(1.0)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1343
Validation loss decreased (1.096587 --> 1.090325).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.4625673
	speed: 0.0302s/iter; left time: 671.6533s
	iters: 200, epoch: 5 | loss: 3.4200974
	speed: 0.0277s/iter; left time: 615.1445s
Epoch: 5 cost time: 6.714231252670288
Epoch: 5, Steps: 233 Train Loss: 3.3774 (Forecasting Loss:0.5783 + XiCon Loss:2.7990 x Lambda(1.0)), Vali MSE Loss: 1.0864 Test MSE Loss: 1.1337
Validation loss decreased (1.090325 --> 1.086406).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.4173143
	speed: 0.0320s/iter; left time: 705.3218s
	iters: 200, epoch: 6 | loss: 3.3696749
	speed: 0.0266s/iter; left time: 583.4845s
Epoch: 6 cost time: 6.801064491271973
Epoch: 6, Steps: 233 Train Loss: 3.3737 (Forecasting Loss:0.5768 + XiCon Loss:2.7968 x Lambda(1.0)), Vali MSE Loss: 1.0856 Test MSE Loss: 1.1329
Validation loss decreased (1.086406 --> 1.085631).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.4260194
	speed: 0.0309s/iter; left time: 673.9744s
	iters: 200, epoch: 7 | loss: 3.2972989
	speed: 0.0276s/iter; left time: 598.8217s
Epoch: 7 cost time: 6.779037237167358
Epoch: 7, Steps: 233 Train Loss: 3.3684 (Forecasting Loss:0.5762 + XiCon Loss:2.7923 x Lambda(1.0)), Vali MSE Loss: 1.0845 Test MSE Loss: 1.1329
Validation loss decreased (1.085631 --> 1.084452).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3746872
	speed: 0.0300s/iter; left time: 647.0942s
	iters: 200, epoch: 8 | loss: 3.3677523
	speed: 0.0266s/iter; left time: 570.3535s
Epoch: 8 cost time: 6.627176284790039
Epoch: 8, Steps: 233 Train Loss: 3.3675 (Forecasting Loss:0.5757 + XiCon Loss:2.7918 x Lambda(1.0)), Vali MSE Loss: 1.0840 Test MSE Loss: 1.1328
Validation loss decreased (1.084452 --> 1.083966).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3473949
	speed: 0.0301s/iter; left time: 641.4714s
	iters: 200, epoch: 9 | loss: 3.3613207
	speed: 0.0270s/iter; left time: 573.4051s
Epoch: 9 cost time: 6.648801803588867
Epoch: 9, Steps: 233 Train Loss: 3.3630 (Forecasting Loss:0.5755 + XiCon Loss:2.7874 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
Validation loss decreased (1.083966 --> 1.083711).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4225700
	speed: 0.0309s/iter; left time: 652.5774s
	iters: 200, epoch: 10 | loss: 3.3990226
	speed: 0.0272s/iter; left time: 571.0406s
Epoch: 10 cost time: 6.65131139755249
Epoch: 10, Steps: 233 Train Loss: 3.3730 (Forecasting Loss:0.5756 + XiCon Loss:2.7974 x Lambda(1.0)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1327
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2997413
	speed: 0.0298s/iter; left time: 622.9358s
	iters: 200, epoch: 11 | loss: 3.3450661
	speed: 0.0269s/iter; left time: 558.0359s
Epoch: 11 cost time: 6.657959699630737
Epoch: 11, Steps: 233 Train Loss: 3.3624 (Forecasting Loss:0.5755 + XiCon Loss:2.7869 x Lambda(1.0)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1327
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3726578
	speed: 0.0308s/iter; left time: 636.1534s
	iters: 200, epoch: 12 | loss: 3.3776903
	speed: 0.0267s/iter; left time: 548.1510s
Epoch: 12 cost time: 6.577357769012451
Epoch: 12, Steps: 233 Train Loss: 3.3638 (Forecasting Loss:0.5754 + XiCon Loss:2.7884 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
Validation loss decreased (1.083711 --> 1.083700).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3161025
	speed: 0.0292s/iter; left time: 595.1632s
	iters: 200, epoch: 13 | loss: 3.3835659
	speed: 0.0270s/iter; left time: 547.8607s
Epoch: 13 cost time: 6.570439100265503
Epoch: 13, Steps: 233 Train Loss: 3.3638 (Forecasting Loss:0.5754 + XiCon Loss:2.7884 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3779440
	speed: 0.0303s/iter; left time: 610.7523s
	iters: 200, epoch: 14 | loss: 3.3812780
	speed: 0.0272s/iter; left time: 546.4333s
Epoch: 14 cost time: 6.647280931472778
Epoch: 14, Steps: 233 Train Loss: 3.3608 (Forecasting Loss:0.5755 + XiCon Loss:2.7854 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
Validation loss decreased (1.083700 --> 1.083660).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3701825
	speed: 0.0307s/iter; left time: 611.4593s
	iters: 200, epoch: 15 | loss: 3.3072286
	speed: 0.0280s/iter; left time: 555.1821s
Epoch: 15 cost time: 6.792787313461304
Epoch: 15, Steps: 233 Train Loss: 3.3635 (Forecasting Loss:0.5753 + XiCon Loss:2.7882 x Lambda(1.0)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1327
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3801994
	speed: 0.0311s/iter; left time: 613.6447s
	iters: 200, epoch: 16 | loss: 3.4270606
	speed: 0.0275s/iter; left time: 539.3535s
Epoch: 16 cost time: 6.801084756851196
Epoch: 16, Steps: 233 Train Loss: 3.3650 (Forecasting Loss:0.5754 + XiCon Loss:2.7896 x Lambda(1.0)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1327
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3140926
	speed: 0.0311s/iter; left time: 606.4229s
	iters: 200, epoch: 17 | loss: 3.2968936
	speed: 0.0272s/iter; left time: 527.0732s
Epoch: 17 cost time: 6.752769231796265
Epoch: 17, Steps: 233 Train Loss: 3.3656 (Forecasting Loss:0.5753 + XiCon Loss:2.7904 x Lambda(1.0)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1327
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.4276378
	speed: 0.0304s/iter; left time: 584.2373s
	iters: 200, epoch: 18 | loss: 3.3676546
	speed: 0.0273s/iter; left time: 523.4549s
Epoch: 18 cost time: 6.727955102920532
Epoch: 18, Steps: 233 Train Loss: 3.3668 (Forecasting Loss:0.5754 + XiCon Loss:2.7915 x Lambda(1.0)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1327
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3220041
	speed: 0.0314s/iter; left time: 596.8797s
	iters: 200, epoch: 19 | loss: 3.3588815
	speed: 0.0269s/iter; left time: 507.7113s
Epoch: 19 cost time: 6.794874668121338
Epoch: 19, Steps: 233 Train Loss: 3.3676 (Forecasting Loss:0.5754 + XiCon Loss:2.7922 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.4240601
	speed: 0.0320s/iter; left time: 601.2682s
	iters: 200, epoch: 20 | loss: 3.3160222
	speed: 0.0267s/iter; left time: 498.6617s
Epoch: 20 cost time: 6.733362197875977
Epoch: 20, Steps: 233 Train Loss: 3.3621 (Forecasting Loss:0.5754 + XiCon Loss:2.7867 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2564425
	speed: 0.0308s/iter; left time: 570.3813s
	iters: 200, epoch: 21 | loss: 3.3485191
	speed: 0.0275s/iter; left time: 507.6005s
Epoch: 21 cost time: 6.7441487312316895
Epoch: 21, Steps: 233 Train Loss: 3.3662 (Forecasting Loss:0.5756 + XiCon Loss:2.7905 x Lambda(1.0)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1327
Validation loss decreased (1.083660 --> 1.083528).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3508229
	speed: 0.0308s/iter; left time: 563.0719s
	iters: 200, epoch: 22 | loss: 3.3679368
	speed: 0.0268s/iter; left time: 487.7886s
Epoch: 22 cost time: 6.688120603561401
Epoch: 22, Steps: 233 Train Loss: 3.3635 (Forecasting Loss:0.5754 + XiCon Loss:2.7881 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3578820
	speed: 0.0311s/iter; left time: 562.4359s
	iters: 200, epoch: 23 | loss: 3.4525318
	speed: 0.0270s/iter; left time: 485.9123s
Epoch: 23 cost time: 6.660387754440308
Epoch: 23, Steps: 233 Train Loss: 3.3661 (Forecasting Loss:0.5755 + XiCon Loss:2.7906 x Lambda(1.0)), Vali MSE Loss: 1.0837 Test MSE Loss: 1.1327
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3713536
	speed: 0.0310s/iter; left time: 552.5891s
	iters: 200, epoch: 24 | loss: 3.2965870
	speed: 0.0279s/iter; left time: 494.2510s
Epoch: 24 cost time: 6.8021135330200195
Epoch: 24, Steps: 233 Train Loss: 3.3681 (Forecasting Loss:0.5753 + XiCon Loss:2.7929 x Lambda(1.0)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1327
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3977261
	speed: 0.0308s/iter; left time: 542.0255s
	iters: 200, epoch: 25 | loss: 3.3393164
	speed: 0.0268s/iter; left time: 469.6085s
Epoch: 25 cost time: 6.6734490394592285
Epoch: 25, Steps: 233 Train Loss: 3.3658 (Forecasting Loss:0.5753 + XiCon Loss:2.7905 x Lambda(1.0)), Vali MSE Loss: 1.0834 Test MSE Loss: 1.1327
Validation loss decreased (1.083528 --> 1.083438).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.4029019
	speed: 0.0309s/iter; left time: 536.6131s
	iters: 200, epoch: 26 | loss: 3.3133981
	speed: 0.0269s/iter; left time: 464.6757s
Epoch: 26 cost time: 6.629347801208496
Epoch: 26, Steps: 233 Train Loss: 3.3645 (Forecasting Loss:0.5753 + XiCon Loss:2.7892 x Lambda(1.0)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1327
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.3870077
	speed: 0.0304s/iter; left time: 521.8495s
	iters: 200, epoch: 27 | loss: 3.4764380
	speed: 0.0267s/iter; left time: 454.7072s
Epoch: 27 cost time: 6.70257568359375
Epoch: 27, Steps: 233 Train Loss: 3.3677 (Forecasting Loss:0.5755 + XiCon Loss:2.7921 x Lambda(1.0)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1327
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.2808599
	speed: 0.0306s/iter; left time: 516.8734s
	iters: 200, epoch: 28 | loss: 3.3752666
	speed: 0.0268s/iter; left time: 449.9777s
Epoch: 28 cost time: 6.68618106842041
Epoch: 28, Steps: 233 Train Loss: 3.3640 (Forecasting Loss:0.5753 + XiCon Loss:2.7887 x Lambda(1.0)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1327
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.3837862
	speed: 0.0305s/iter; left time: 508.3318s
	iters: 200, epoch: 29 | loss: 3.3461080
	speed: 0.0272s/iter; left time: 450.1106s
Epoch: 29 cost time: 6.669797420501709
Epoch: 29, Steps: 233 Train Loss: 3.3669 (Forecasting Loss:0.5754 + XiCon Loss:2.7916 x Lambda(1.0)), Vali MSE Loss: 1.0841 Test MSE Loss: 1.1327
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.3301840
	speed: 0.0301s/iter; left time: 494.5015s
	iters: 200, epoch: 30 | loss: 3.4654729
	speed: 0.0279s/iter; left time: 456.5996s
Epoch: 30 cost time: 6.707746267318726
Epoch: 30, Steps: 233 Train Loss: 3.3640 (Forecasting Loss:0.5755 + XiCon Loss:2.7885 x Lambda(1.0)), Vali MSE Loss: 1.0835 Test MSE Loss: 1.1327
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.2851181
	speed: 0.0300s/iter; left time: 485.8095s
	iters: 200, epoch: 31 | loss: 3.2839198
	speed: 0.0271s/iter; left time: 437.0634s
Epoch: 31 cost time: 6.677443742752075
Epoch: 31, Steps: 233 Train Loss: 3.3642 (Forecasting Loss:0.5753 + XiCon Loss:2.7889 x Lambda(1.0)), Vali MSE Loss: 1.0840 Test MSE Loss: 1.1327
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 3.4149759
	speed: 0.0308s/iter; left time: 491.7000s
	iters: 200, epoch: 32 | loss: 3.4048715
	speed: 0.0274s/iter; left time: 435.0023s
Epoch: 32 cost time: 6.758748531341553
Epoch: 32, Steps: 233 Train Loss: 3.3647 (Forecasting Loss:0.5754 + XiCon Loss:2.7893 x Lambda(1.0)), Vali MSE Loss: 1.0838 Test MSE Loss: 1.1327
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 3.3253546
	speed: 0.0309s/iter; left time: 487.0381s
	iters: 200, epoch: 33 | loss: 3.3036199
	speed: 0.0270s/iter; left time: 423.1630s
Epoch: 33 cost time: 6.72837495803833
Epoch: 33, Steps: 233 Train Loss: 3.3633 (Forecasting Loss:0.5755 + XiCon Loss:2.7878 x Lambda(1.0)), Vali MSE Loss: 1.0839 Test MSE Loss: 1.1327
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 3.3516650
	speed: 0.0306s/iter; left time: 474.9456s
	iters: 200, epoch: 34 | loss: 3.3513603
	speed: 0.0273s/iter; left time: 421.3921s
Epoch: 34 cost time: 6.766782283782959
Epoch: 34, Steps: 233 Train Loss: 3.3638 (Forecasting Loss:0.5755 + XiCon Loss:2.7884 x Lambda(1.0)), Vali MSE Loss: 1.0840 Test MSE Loss: 1.1327
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 3.3448300
	speed: 0.0302s/iter; left time: 461.0410s
	iters: 200, epoch: 35 | loss: 3.3482752
	speed: 0.0271s/iter; left time: 410.9898s
Epoch: 35 cost time: 6.637148141860962
Epoch: 35, Steps: 233 Train Loss: 3.3671 (Forecasting Loss:0.5753 + XiCon Loss:2.7919 x Lambda(1.0)), Vali MSE Loss: 1.0836 Test MSE Loss: 1.1327
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.389882206916809, mae:0.8754931688308716, mape:6.040558338165283, mspe:4366.17333984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5312
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 4.0309277
	speed: 0.0324s/iter; left time: 752.6429s
	iters: 200, epoch: 1 | loss: 3.8410494
	speed: 0.0296s/iter; left time: 682.7467s
Epoch: 1 cost time: 7.2292234897613525
Epoch: 1, Steps: 233 Train Loss: 3.8609 (Forecasting Loss:1.0137 + XiCon Loss:2.8473 x Lambda(1.0)), Vali MSE Loss: 1.8334 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833387).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4525518
	speed: 0.0317s/iter; left time: 727.5521s
	iters: 200, epoch: 2 | loss: 3.4600720
	speed: 0.0300s/iter; left time: 685.4731s
Epoch: 2 cost time: 7.178559064865112
Epoch: 2, Steps: 233 Train Loss: 3.4863 (Forecasting Loss:0.6537 + XiCon Loss:2.8325 x Lambda(1.0)), Vali MSE Loss: 1.1236 Test MSE Loss: 1.1463
Validation loss decreased (1.833387 --> 1.123616).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3351822
	speed: 0.0322s/iter; left time: 731.8480s
	iters: 200, epoch: 3 | loss: 3.3378425
	speed: 0.0292s/iter; left time: 661.5047s
Epoch: 3 cost time: 7.15041971206665
Epoch: 3, Steps: 233 Train Loss: 3.3967 (Forecasting Loss:0.5894 + XiCon Loss:2.8073 x Lambda(1.0)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1380
Validation loss decreased (1.123616 --> 1.104250).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.4201560
	speed: 0.0337s/iter; left time: 758.0993s
	iters: 200, epoch: 4 | loss: 3.4040263
	speed: 0.0290s/iter; left time: 650.6851s
Epoch: 4 cost time: 7.311755657196045
Epoch: 4, Steps: 233 Train Loss: 3.3784 (Forecasting Loss:0.5815 + XiCon Loss:2.7969 x Lambda(1.0)), Vali MSE Loss: 1.0980 Test MSE Loss: 1.1359
Validation loss decreased (1.104250 --> 1.097982).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2862115
	speed: 0.0317s/iter; left time: 705.9423s
	iters: 200, epoch: 5 | loss: 3.2827172
	speed: 0.0288s/iter; left time: 638.0675s
Epoch: 5 cost time: 7.0386271476745605
Epoch: 5, Steps: 233 Train Loss: 3.3661 (Forecasting Loss:0.5783 + XiCon Loss:2.7878 x Lambda(1.0)), Vali MSE Loss: 1.0948 Test MSE Loss: 1.1349
Validation loss decreased (1.097982 --> 1.094772).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3210406
	speed: 0.0318s/iter; left time: 700.3579s
	iters: 200, epoch: 6 | loss: 3.3650951
	speed: 0.0295s/iter; left time: 647.8146s
Epoch: 6 cost time: 7.150525331497192
Epoch: 6, Steps: 233 Train Loss: 3.3662 (Forecasting Loss:0.5769 + XiCon Loss:2.7894 x Lambda(1.0)), Vali MSE Loss: 1.0934 Test MSE Loss: 1.1346
Validation loss decreased (1.094772 --> 1.093394).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3528826
	speed: 0.0315s/iter; left time: 686.9168s
	iters: 200, epoch: 7 | loss: 3.3735895
	speed: 0.0316s/iter; left time: 686.7863s
Epoch: 7 cost time: 7.411921739578247
Epoch: 7, Steps: 233 Train Loss: 3.3590 (Forecasting Loss:0.5761 + XiCon Loss:2.7829 x Lambda(1.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1344
Validation loss decreased (1.093394 --> 1.092621).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3464973
	speed: 0.0332s/iter; left time: 716.9856s
	iters: 200, epoch: 8 | loss: 3.3224144
	speed: 0.0316s/iter; left time: 677.7729s
Epoch: 8 cost time: 7.580114126205444
Epoch: 8, Steps: 233 Train Loss: 3.3571 (Forecasting Loss:0.5758 + XiCon Loss:2.7813 x Lambda(1.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1343
Validation loss decreased (1.092621 --> 1.092240).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3190353
	speed: 0.0338s/iter; left time: 721.5236s
	iters: 200, epoch: 9 | loss: 3.3553030
	speed: 0.0310s/iter; left time: 657.4602s
Epoch: 9 cost time: 7.535777807235718
Epoch: 9, Steps: 233 Train Loss: 3.3653 (Forecasting Loss:0.5756 + XiCon Loss:2.7897 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
Validation loss decreased (1.092240 --> 1.091949).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3281112
	speed: 0.0352s/iter; left time: 742.0501s
	iters: 200, epoch: 10 | loss: 3.3760576
	speed: 0.0322s/iter; left time: 676.7608s
Epoch: 10 cost time: 7.849088907241821
Epoch: 10, Steps: 233 Train Loss: 3.3607 (Forecasting Loss:0.5755 + XiCon Loss:2.7852 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.3153663
	speed: 0.0342s/iter; left time: 713.0704s
	iters: 200, epoch: 11 | loss: 3.3882041
	speed: 0.0307s/iter; left time: 637.8039s
Epoch: 11 cost time: 7.6069090366363525
Epoch: 11, Steps: 233 Train Loss: 3.3559 (Forecasting Loss:0.5755 + XiCon Loss:2.7804 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
Validation loss decreased (1.091949 --> 1.091879).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3703890
	speed: 0.0334s/iter; left time: 690.3262s
	iters: 200, epoch: 12 | loss: 3.4335527
	speed: 0.0322s/iter; left time: 660.4869s
Epoch: 12 cost time: 7.638294219970703
Epoch: 12, Steps: 233 Train Loss: 3.3560 (Forecasting Loss:0.5754 + XiCon Loss:2.7806 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3795891
	speed: 0.0338s/iter; left time: 689.6969s
	iters: 200, epoch: 13 | loss: 3.3198624
	speed: 0.0311s/iter; left time: 630.9528s
Epoch: 13 cost time: 7.5947182178497314
Epoch: 13, Steps: 233 Train Loss: 3.3589 (Forecasting Loss:0.5755 + XiCon Loss:2.7835 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3450108
	speed: 0.0344s/iter; left time: 694.0356s
	iters: 200, epoch: 14 | loss: 3.4302099
	speed: 0.0311s/iter; left time: 623.2392s
Epoch: 14 cost time: 7.636305093765259
Epoch: 14, Steps: 233 Train Loss: 3.3553 (Forecasting Loss:0.5754 + XiCon Loss:2.7799 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3348434
	speed: 0.0344s/iter; left time: 685.1767s
	iters: 200, epoch: 15 | loss: 3.3511953
	speed: 0.0312s/iter; left time: 618.2571s
Epoch: 15 cost time: 7.593598127365112
Epoch: 15, Steps: 233 Train Loss: 3.3564 (Forecasting Loss:0.5754 + XiCon Loss:2.7810 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.3430495
	speed: 0.0341s/iter; left time: 671.1350s
	iters: 200, epoch: 16 | loss: 3.3727660
	speed: 0.0312s/iter; left time: 611.3013s
Epoch: 16 cost time: 7.660034894943237
Epoch: 16, Steps: 233 Train Loss: 3.3586 (Forecasting Loss:0.5755 + XiCon Loss:2.7831 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3417001
	speed: 0.0325s/iter; left time: 633.6474s
	iters: 200, epoch: 17 | loss: 3.3207190
	speed: 0.0324s/iter; left time: 627.1580s
Epoch: 17 cost time: 7.53560996055603
Epoch: 17, Steps: 233 Train Loss: 3.3588 (Forecasting Loss:0.5755 + XiCon Loss:2.7833 x Lambda(1.0)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1343
Validation loss decreased (1.091879 --> 1.091844).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2994249
	speed: 0.0346s/iter; left time: 665.6063s
	iters: 200, epoch: 18 | loss: 3.3227043
	speed: 0.0308s/iter; left time: 588.6978s
Epoch: 18 cost time: 7.6508190631866455
Epoch: 18, Steps: 233 Train Loss: 3.3540 (Forecasting Loss:0.5754 + XiCon Loss:2.7786 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3770661
	speed: 0.0341s/iter; left time: 647.9822s
	iters: 200, epoch: 19 | loss: 3.4112940
	speed: 0.0315s/iter; left time: 594.7840s
Epoch: 19 cost time: 7.724220514297485
Epoch: 19, Steps: 233 Train Loss: 3.3589 (Forecasting Loss:0.5754 + XiCon Loss:2.7835 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.3539419
	speed: 0.0350s/iter; left time: 657.2879s
	iters: 200, epoch: 20 | loss: 3.3866749
	speed: 0.0319s/iter; left time: 595.0882s
Epoch: 20 cost time: 7.705657720565796
Epoch: 20, Steps: 233 Train Loss: 3.3566 (Forecasting Loss:0.5754 + XiCon Loss:2.7812 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.4886334
	speed: 0.0348s/iter; left time: 645.8893s
	iters: 200, epoch: 21 | loss: 3.3517461
	speed: 0.0306s/iter; left time: 565.0186s
Epoch: 21 cost time: 7.627850770950317
Epoch: 21, Steps: 233 Train Loss: 3.3622 (Forecasting Loss:0.5754 + XiCon Loss:2.7868 x Lambda(1.0)), Vali MSE Loss: 1.0917 Test MSE Loss: 1.1343
Validation loss decreased (1.091844 --> 1.091739).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3050299
	speed: 0.0337s/iter; left time: 617.6008s
	iters: 200, epoch: 22 | loss: 3.3907671
	speed: 0.0326s/iter; left time: 593.1275s
Epoch: 22 cost time: 7.640910387039185
Epoch: 22, Steps: 233 Train Loss: 3.3592 (Forecasting Loss:0.5753 + XiCon Loss:2.7839 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3836985
	speed: 0.0332s/iter; left time: 600.9782s
	iters: 200, epoch: 23 | loss: 3.4097803
	speed: 0.0315s/iter; left time: 566.6781s
Epoch: 23 cost time: 7.641196012496948
Epoch: 23, Steps: 233 Train Loss: 3.3550 (Forecasting Loss:0.5754 + XiCon Loss:2.7796 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3028893
	speed: 0.0351s/iter; left time: 625.3972s
	iters: 200, epoch: 24 | loss: 3.3391171
	speed: 0.0312s/iter; left time: 553.7529s
Epoch: 24 cost time: 7.7081077098846436
Epoch: 24, Steps: 233 Train Loss: 3.3577 (Forecasting Loss:0.5754 + XiCon Loss:2.7823 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1343
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3806493
	speed: 0.0340s/iter; left time: 598.0463s
	iters: 200, epoch: 25 | loss: 3.3446858
	speed: 0.0313s/iter; left time: 548.8839s
Epoch: 25 cost time: 7.631476402282715
Epoch: 25, Steps: 233 Train Loss: 3.3552 (Forecasting Loss:0.5755 + XiCon Loss:2.7797 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.3281021
	speed: 0.0339s/iter; left time: 588.8859s
	iters: 200, epoch: 26 | loss: 3.3497252
	speed: 0.0310s/iter; left time: 535.4270s
Epoch: 26 cost time: 7.655252933502197
Epoch: 26, Steps: 233 Train Loss: 3.3533 (Forecasting Loss:0.5754 + XiCon Loss:2.7778 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.3455997
	speed: 0.0346s/iter; left time: 592.9406s
	iters: 200, epoch: 27 | loss: 3.3666644
	speed: 0.0317s/iter; left time: 540.4206s
Epoch: 27 cost time: 7.651144504547119
Epoch: 27, Steps: 233 Train Loss: 3.3502 (Forecasting Loss:0.5753 + XiCon Loss:2.7749 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.2856512
	speed: 0.0350s/iter; left time: 592.2783s
	iters: 200, epoch: 28 | loss: 3.3738852
	speed: 0.0315s/iter; left time: 528.8514s
Epoch: 28 cost time: 7.761502981185913
Epoch: 28, Steps: 233 Train Loss: 3.3587 (Forecasting Loss:0.5754 + XiCon Loss:2.7833 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.3096161
	speed: 0.0344s/iter; left time: 573.9352s
	iters: 200, epoch: 29 | loss: 3.3502796
	speed: 0.0312s/iter; left time: 518.0256s
Epoch: 29 cost time: 7.584371089935303
Epoch: 29, Steps: 233 Train Loss: 3.3618 (Forecasting Loss:0.5754 + XiCon Loss:2.7864 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1343
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.4381492
	speed: 0.0327s/iter; left time: 538.0297s
	iters: 200, epoch: 30 | loss: 3.2643116
	speed: 0.0320s/iter; left time: 522.9595s
Epoch: 30 cost time: 7.530626058578491
Epoch: 30, Steps: 233 Train Loss: 3.3572 (Forecasting Loss:0.5753 + XiCon Loss:2.7819 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.3611987
	speed: 0.0346s/iter; left time: 561.3271s
	iters: 200, epoch: 31 | loss: 3.3187041
	speed: 0.0309s/iter; left time: 498.3600s
Epoch: 31 cost time: 7.645905256271362
Epoch: 31, Steps: 233 Train Loss: 3.3581 (Forecasting Loss:0.5754 + XiCon Loss:2.7827 x Lambda(1.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1343
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3912746906280518, mae:0.8772337436676025, mape:6.126641750335693, mspe:4497.845703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.9730
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 3.8788958
	speed: 0.0324s/iter; left time: 751.6961s
	iters: 200, epoch: 1 | loss: 3.8007803
	speed: 0.0275s/iter; left time: 635.4615s
Epoch: 1 cost time: 6.853058338165283
Epoch: 1, Steps: 233 Train Loss: 3.8946 (Forecasting Loss:1.0278 + XiCon Loss:2.8669 x Lambda(1.0)), Vali MSE Loss: 1.8646 Test MSE Loss: 1.2526
Validation loss decreased (inf --> 1.864629).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4308059
	speed: 0.0305s/iter; left time: 699.4879s
	iters: 200, epoch: 2 | loss: 3.4469516
	speed: 0.0272s/iter; left time: 621.1147s
Epoch: 2 cost time: 6.7106077671051025
Epoch: 2, Steps: 233 Train Loss: 3.5012 (Forecasting Loss:0.6549 + XiCon Loss:2.8463 x Lambda(1.0)), Vali MSE Loss: 1.1225 Test MSE Loss: 1.1474
Validation loss decreased (1.864629 --> 1.122508).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3469052
	speed: 0.0313s/iter; left time: 711.0348s
	iters: 200, epoch: 3 | loss: 3.4644980
	speed: 0.0273s/iter; left time: 618.3621s
Epoch: 3 cost time: 6.81073522567749
Epoch: 3, Steps: 233 Train Loss: 3.4049 (Forecasting Loss:0.5899 + XiCon Loss:2.8149 x Lambda(1.0)), Vali MSE Loss: 1.1041 Test MSE Loss: 1.1403
Validation loss decreased (1.122508 --> 1.104129).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.3525128
	speed: 0.0303s/iter; left time: 682.4833s
	iters: 200, epoch: 4 | loss: 3.4288907
	speed: 0.0271s/iter; left time: 607.2485s
Epoch: 4 cost time: 6.679964065551758
Epoch: 4, Steps: 233 Train Loss: 3.3680 (Forecasting Loss:0.5822 + XiCon Loss:2.7859 x Lambda(1.0)), Vali MSE Loss: 1.0975 Test MSE Loss: 1.1381
Validation loss decreased (1.104129 --> 1.097480).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2453594
	speed: 0.0300s/iter; left time: 667.8753s
	iters: 200, epoch: 5 | loss: 3.3637900
	speed: 0.0268s/iter; left time: 593.4951s
Epoch: 5 cost time: 6.613173246383667
Epoch: 5, Steps: 233 Train Loss: 3.3487 (Forecasting Loss:0.5792 + XiCon Loss:2.7695 x Lambda(1.0)), Vali MSE Loss: 1.0948 Test MSE Loss: 1.1376
Validation loss decreased (1.097480 --> 1.094784).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3069882
	speed: 0.0281s/iter; left time: 620.1391s
	iters: 200, epoch: 6 | loss: 3.3988562
	speed: 0.0250s/iter; left time: 548.2077s
Epoch: 6 cost time: 6.19001317024231
Epoch: 6, Steps: 233 Train Loss: 3.3446 (Forecasting Loss:0.5778 + XiCon Loss:2.7668 x Lambda(1.0)), Vali MSE Loss: 1.0935 Test MSE Loss: 1.1374
Validation loss decreased (1.094784 --> 1.093490).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.4000502
	speed: 0.0281s/iter; left time: 612.7347s
	iters: 200, epoch: 7 | loss: 3.3845959
	speed: 0.0252s/iter; left time: 547.9594s
Epoch: 7 cost time: 6.193302631378174
Epoch: 7, Steps: 233 Train Loss: 3.3347 (Forecasting Loss:0.5770 + XiCon Loss:2.7576 x Lambda(1.0)), Vali MSE Loss: 1.0928 Test MSE Loss: 1.1373
Validation loss decreased (1.093490 --> 1.092769).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3304873
	speed: 0.0287s/iter; left time: 618.1475s
	iters: 200, epoch: 8 | loss: 3.3868303
	speed: 0.0245s/iter; left time: 526.0277s
Epoch: 8 cost time: 6.169349670410156
Epoch: 8, Steps: 233 Train Loss: 3.3318 (Forecasting Loss:0.5767 + XiCon Loss:2.7551 x Lambda(1.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1372
Validation loss decreased (1.092769 --> 1.092599).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.3522618
	speed: 0.0283s/iter; left time: 604.1274s
	iters: 200, epoch: 9 | loss: 3.4015346
	speed: 0.0262s/iter; left time: 556.8468s
Epoch: 9 cost time: 6.329087257385254
Epoch: 9, Steps: 233 Train Loss: 3.3304 (Forecasting Loss:0.5764 + XiCon Loss:2.7540 x Lambda(1.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
Validation loss decreased (1.092599 --> 1.092199).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.3362875
	speed: 0.0288s/iter; left time: 608.6588s
	iters: 200, epoch: 10 | loss: 3.3816159
	speed: 0.0253s/iter; left time: 531.1789s
Epoch: 10 cost time: 6.23873233795166
Epoch: 10, Steps: 233 Train Loss: 3.3333 (Forecasting Loss:0.5763 + XiCon Loss:2.7570 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
Validation loss decreased (1.092199 --> 1.092094).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2512360
	speed: 0.0283s/iter; left time: 589.9059s
	iters: 200, epoch: 11 | loss: 3.3525183
	speed: 0.0251s/iter; left time: 520.4521s
Epoch: 11 cost time: 6.177712917327881
Epoch: 11, Steps: 233 Train Loss: 3.3337 (Forecasting Loss:0.5763 + XiCon Loss:2.7574 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
Validation loss decreased (1.092094 --> 1.092019).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3129392
	speed: 0.0277s/iter; left time: 571.3082s
	iters: 200, epoch: 12 | loss: 3.2272074
	speed: 0.0249s/iter; left time: 510.7214s
Epoch: 12 cost time: 6.121991157531738
Epoch: 12, Steps: 233 Train Loss: 3.3350 (Forecasting Loss:0.5762 + XiCon Loss:2.7588 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3212473
	speed: 0.0279s/iter; left time: 568.7454s
	iters: 200, epoch: 13 | loss: 3.3263414
	speed: 0.0275s/iter; left time: 557.7023s
Epoch: 13 cost time: 6.5038933753967285
Epoch: 13, Steps: 233 Train Loss: 3.3286 (Forecasting Loss:0.5763 + XiCon Loss:2.7524 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2153800
	speed: 0.0306s/iter; left time: 616.9409s
	iters: 200, epoch: 14 | loss: 3.4269791
	speed: 0.0278s/iter; left time: 558.5012s
Epoch: 14 cost time: 6.697360992431641
Epoch: 14, Steps: 233 Train Loss: 3.3312 (Forecasting Loss:0.5762 + XiCon Loss:2.7550 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4188693
	speed: 0.0300s/iter; left time: 597.8105s
	iters: 200, epoch: 15 | loss: 3.3238106
	speed: 0.0271s/iter; left time: 537.8967s
Epoch: 15 cost time: 6.655624866485596
Epoch: 15, Steps: 233 Train Loss: 3.3317 (Forecasting Loss:0.5762 + XiCon Loss:2.7555 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2548027
	speed: 0.0302s/iter; left time: 595.2178s
	iters: 200, epoch: 16 | loss: 3.3047454
	speed: 0.0275s/iter; left time: 539.4682s
Epoch: 16 cost time: 6.768012762069702
Epoch: 16, Steps: 233 Train Loss: 3.3325 (Forecasting Loss:0.5762 + XiCon Loss:2.7563 x Lambda(1.0)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1372
Validation loss decreased (1.092019 --> 1.091786).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2583737
	speed: 0.0307s/iter; left time: 598.2996s
	iters: 200, epoch: 17 | loss: 3.4644685
	speed: 0.0263s/iter; left time: 510.4658s
Epoch: 17 cost time: 6.563234329223633
Epoch: 17, Steps: 233 Train Loss: 3.3340 (Forecasting Loss:0.5762 + XiCon Loss:2.7578 x Lambda(1.0)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1372
Validation loss decreased (1.091786 --> 1.091770).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2612810
	speed: 0.0302s/iter; left time: 581.0812s
	iters: 200, epoch: 18 | loss: 3.3418193
	speed: 0.0265s/iter; left time: 507.6500s
Epoch: 18 cost time: 6.608306884765625
Epoch: 18, Steps: 233 Train Loss: 3.3328 (Forecasting Loss:0.5763 + XiCon Loss:2.7565 x Lambda(1.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.3520975
	speed: 0.0307s/iter; left time: 583.5810s
	iters: 200, epoch: 19 | loss: 3.3913946
	speed: 0.0274s/iter; left time: 517.4185s
Epoch: 19 cost time: 6.754922389984131
Epoch: 19, Steps: 233 Train Loss: 3.3320 (Forecasting Loss:0.5762 + XiCon Loss:2.7557 x Lambda(1.0)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.4590940
	speed: 0.0307s/iter; left time: 577.1156s
	iters: 200, epoch: 20 | loss: 3.3819420
	speed: 0.0271s/iter; left time: 505.8981s
Epoch: 20 cost time: 6.617410659790039
Epoch: 20, Steps: 233 Train Loss: 3.3343 (Forecasting Loss:0.5762 + XiCon Loss:2.7581 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2985253
	speed: 0.0300s/iter; left time: 555.7717s
	iters: 200, epoch: 21 | loss: 3.3718398
	speed: 0.0269s/iter; left time: 496.1789s
Epoch: 21 cost time: 6.624398946762085
Epoch: 21, Steps: 233 Train Loss: 3.3252 (Forecasting Loss:0.5762 + XiCon Loss:2.7490 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.3022583
	speed: 0.0317s/iter; left time: 579.6122s
	iters: 200, epoch: 22 | loss: 3.3313804
	speed: 0.0269s/iter; left time: 489.0552s
Epoch: 22 cost time: 6.71806001663208
Epoch: 22, Steps: 233 Train Loss: 3.3294 (Forecasting Loss:0.5763 + XiCon Loss:2.7531 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3470161
	speed: 0.0299s/iter; left time: 540.0749s
	iters: 200, epoch: 23 | loss: 3.3480105
	speed: 0.0270s/iter; left time: 485.5509s
Epoch: 23 cost time: 6.656214714050293
Epoch: 23, Steps: 233 Train Loss: 3.3291 (Forecasting Loss:0.5762 + XiCon Loss:2.7529 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.3487079
	speed: 0.0301s/iter; left time: 536.6235s
	iters: 200, epoch: 24 | loss: 3.2837057
	speed: 0.0269s/iter; left time: 477.9100s
Epoch: 24 cost time: 6.621289253234863
Epoch: 24, Steps: 233 Train Loss: 3.3252 (Forecasting Loss:0.5762 + XiCon Loss:2.7490 x Lambda(1.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.3168225
	speed: 0.0315s/iter; left time: 553.9367s
	iters: 200, epoch: 25 | loss: 3.3330803
	speed: 0.0274s/iter; left time: 480.1751s
Epoch: 25 cost time: 6.799647092819214
Epoch: 25, Steps: 233 Train Loss: 3.3312 (Forecasting Loss:0.5762 + XiCon Loss:2.7550 x Lambda(1.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.3674879
	speed: 0.0301s/iter; left time: 523.4850s
	iters: 200, epoch: 26 | loss: 3.3137674
	speed: 0.0271s/iter; left time: 467.5124s
Epoch: 26 cost time: 6.675445795059204
Epoch: 26, Steps: 233 Train Loss: 3.3340 (Forecasting Loss:0.5762 + XiCon Loss:2.7578 x Lambda(1.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.3833237
	speed: 0.0299s/iter; left time: 513.3292s
	iters: 200, epoch: 27 | loss: 3.2857382
	speed: 0.0270s/iter; left time: 460.3157s
Epoch: 27 cost time: 6.656172275543213
Epoch: 27, Steps: 233 Train Loss: 3.3283 (Forecasting Loss:0.5762 + XiCon Loss:2.7521 x Lambda(1.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.395528793334961, mae:0.8788812756538391, mape:6.14140510559082, mspe:4534.7958984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.9022
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 4.0011349
	speed: 0.0310s/iter; left time: 719.3009s
	iters: 200, epoch: 1 | loss: 3.9271650
	speed: 0.0272s/iter; left time: 627.5502s
Epoch: 1 cost time: 6.668360948562622
Epoch: 1, Steps: 233 Train Loss: 3.8673 (Forecasting Loss:1.0269 + XiCon Loss:2.8404 x Lambda(1.0)), Vali MSE Loss: 1.8520 Test MSE Loss: 1.2639
Validation loss decreased (inf --> 1.851997).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4428675
	speed: 0.0295s/iter; left time: 677.3100s
	iters: 200, epoch: 2 | loss: 3.4170961
	speed: 0.0272s/iter; left time: 621.6380s
Epoch: 2 cost time: 6.625732898712158
Epoch: 2, Steps: 233 Train Loss: 3.4831 (Forecasting Loss:0.6514 + XiCon Loss:2.8317 x Lambda(1.0)), Vali MSE Loss: 1.1127 Test MSE Loss: 1.1474
Validation loss decreased (1.851997 --> 1.112706).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3536143
	speed: 0.0300s/iter; left time: 682.0293s
	iters: 200, epoch: 3 | loss: 3.3922958
	speed: 0.0261s/iter; left time: 589.7978s
Epoch: 3 cost time: 6.457594871520996
Epoch: 3, Steps: 233 Train Loss: 3.3993 (Forecasting Loss:0.5869 + XiCon Loss:2.8124 x Lambda(1.0)), Vali MSE Loss: 1.0888 Test MSE Loss: 1.1415
Validation loss decreased (1.112706 --> 1.088764).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.4211640
	speed: 0.0303s/iter; left time: 682.8545s
	iters: 200, epoch: 4 | loss: 3.3436215
	speed: 0.0269s/iter; left time: 602.8752s
Epoch: 4 cost time: 6.692721366882324
Epoch: 4, Steps: 233 Train Loss: 3.3832 (Forecasting Loss:0.5787 + XiCon Loss:2.8045 x Lambda(1.0)), Vali MSE Loss: 1.0801 Test MSE Loss: 1.1397
Validation loss decreased (1.088764 --> 1.080060).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3246856
	speed: 0.0295s/iter; left time: 656.7460s
	iters: 200, epoch: 5 | loss: 3.3669689
	speed: 0.0276s/iter; left time: 612.5120s
Epoch: 5 cost time: 6.689208269119263
Epoch: 5, Steps: 233 Train Loss: 3.3791 (Forecasting Loss:0.5753 + XiCon Loss:2.8037 x Lambda(1.0)), Vali MSE Loss: 1.0760 Test MSE Loss: 1.1394
Validation loss decreased (1.080060 --> 1.075964).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5243211
	speed: 0.0304s/iter; left time: 670.2633s
	iters: 200, epoch: 6 | loss: 3.3247714
	speed: 0.0271s/iter; left time: 595.0636s
Epoch: 6 cost time: 6.657817602157593
Epoch: 6, Steps: 233 Train Loss: 3.3756 (Forecasting Loss:0.5737 + XiCon Loss:2.8019 x Lambda(1.0)), Vali MSE Loss: 1.0740 Test MSE Loss: 1.1390
Validation loss decreased (1.075964 --> 1.073956).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.3828368
	speed: 0.0299s/iter; left time: 651.4520s
	iters: 200, epoch: 7 | loss: 3.3802671
	speed: 0.0281s/iter; left time: 610.1836s
Epoch: 7 cost time: 6.646428346633911
Epoch: 7, Steps: 233 Train Loss: 3.3757 (Forecasting Loss:0.5730 + XiCon Loss:2.8027 x Lambda(1.0)), Vali MSE Loss: 1.0729 Test MSE Loss: 1.1389
Validation loss decreased (1.073956 --> 1.072862).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.3484406
	speed: 0.0300s/iter; left time: 646.4132s
	iters: 200, epoch: 8 | loss: 3.3495631
	speed: 0.0265s/iter; left time: 567.8859s
Epoch: 8 cost time: 6.584287881851196
Epoch: 8, Steps: 233 Train Loss: 3.3712 (Forecasting Loss:0.5726 + XiCon Loss:2.7986 x Lambda(1.0)), Vali MSE Loss: 1.0723 Test MSE Loss: 1.1389
Validation loss decreased (1.072862 --> 1.072253).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.4229965
	speed: 0.0307s/iter; left time: 655.2977s
	iters: 200, epoch: 9 | loss: 3.3247256
	speed: 0.0270s/iter; left time: 573.4244s
Epoch: 9 cost time: 6.746179580688477
Epoch: 9, Steps: 233 Train Loss: 3.3725 (Forecasting Loss:0.5723 + XiCon Loss:2.8002 x Lambda(1.0)), Vali MSE Loss: 1.0718 Test MSE Loss: 1.1389
Validation loss decreased (1.072253 --> 1.071803).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4098177
	speed: 0.0307s/iter; left time: 647.6980s
	iters: 200, epoch: 10 | loss: 3.3298583
	speed: 0.0277s/iter; left time: 581.2397s
Epoch: 10 cost time: 6.715508460998535
Epoch: 10, Steps: 233 Train Loss: 3.3708 (Forecasting Loss:0.5722 + XiCon Loss:2.7987 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.4944758
	speed: 0.0300s/iter; left time: 625.8946s
	iters: 200, epoch: 11 | loss: 3.3408613
	speed: 0.0270s/iter; left time: 561.7472s
Epoch: 11 cost time: 6.650144100189209
Epoch: 11, Steps: 233 Train Loss: 3.3715 (Forecasting Loss:0.5722 + XiCon Loss:2.7994 x Lambda(1.0)), Vali MSE Loss: 1.0718 Test MSE Loss: 1.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.3573225
	speed: 0.0294s/iter; left time: 607.1511s
	iters: 200, epoch: 12 | loss: 3.3542809
	speed: 0.0271s/iter; left time: 556.7738s
Epoch: 12 cost time: 6.557282209396362
Epoch: 12, Steps: 233 Train Loss: 3.3723 (Forecasting Loss:0.5722 + XiCon Loss:2.8001 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
Validation loss decreased (1.071803 --> 1.071723).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.3857560
	speed: 0.0312s/iter; left time: 636.0579s
	iters: 200, epoch: 13 | loss: 3.3551307
	speed: 0.0269s/iter; left time: 546.2666s
Epoch: 13 cost time: 6.7166900634765625
Epoch: 13, Steps: 233 Train Loss: 3.3667 (Forecasting Loss:0.5722 + XiCon Loss:2.7946 x Lambda(1.0)), Vali MSE Loss: 1.0718 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.3956757
	speed: 0.0295s/iter; left time: 596.0275s
	iters: 200, epoch: 14 | loss: 3.3881326
	speed: 0.0269s/iter; left time: 540.6977s
Epoch: 14 cost time: 6.603632926940918
Epoch: 14, Steps: 233 Train Loss: 3.3758 (Forecasting Loss:0.5721 + XiCon Loss:2.8036 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
Validation loss decreased (1.071723 --> 1.071710).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.3254232
	speed: 0.0297s/iter; left time: 592.5267s
	iters: 200, epoch: 15 | loss: 3.3133988
	speed: 0.0276s/iter; left time: 548.1217s
Epoch: 15 cost time: 6.658523321151733
Epoch: 15, Steps: 233 Train Loss: 3.3701 (Forecasting Loss:0.5721 + XiCon Loss:2.7980 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.4296219
	speed: 0.0297s/iter; left time: 585.9677s
	iters: 200, epoch: 16 | loss: 3.3377213
	speed: 0.0279s/iter; left time: 546.7605s
Epoch: 16 cost time: 6.60825777053833
Epoch: 16, Steps: 233 Train Loss: 3.3747 (Forecasting Loss:0.5721 + XiCon Loss:2.8026 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
Validation loss decreased (1.071710 --> 1.071690).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.4074159
	speed: 0.0296s/iter; left time: 577.2273s
	iters: 200, epoch: 17 | loss: 3.3580484
	speed: 0.0273s/iter; left time: 528.4485s
Epoch: 17 cost time: 6.657240629196167
Epoch: 17, Steps: 233 Train Loss: 3.3684 (Forecasting Loss:0.5720 + XiCon Loss:2.7963 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3422909
	speed: 0.0298s/iter; left time: 572.4962s
	iters: 200, epoch: 18 | loss: 3.4043350
	speed: 0.0274s/iter; left time: 524.6055s
Epoch: 18 cost time: 6.592132091522217
Epoch: 18, Steps: 233 Train Loss: 3.3718 (Forecasting Loss:0.5721 + XiCon Loss:2.7997 x Lambda(1.0)), Vali MSE Loss: 1.0716 Test MSE Loss: 1.1389
Validation loss decreased (1.071690 --> 1.071645).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.4018347
	speed: 0.0282s/iter; left time: 536.1275s
	iters: 200, epoch: 19 | loss: 3.4226770
	speed: 0.0254s/iter; left time: 480.3598s
Epoch: 19 cost time: 6.242934226989746
Epoch: 19, Steps: 233 Train Loss: 3.3733 (Forecasting Loss:0.5720 + XiCon Loss:2.8012 x Lambda(1.0)), Vali MSE Loss: 1.0716 Test MSE Loss: 1.1389
Validation loss decreased (1.071645 --> 1.071571).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.3703370
	speed: 0.0279s/iter; left time: 523.3403s
	iters: 200, epoch: 20 | loss: 3.4819717
	speed: 0.0251s/iter; left time: 469.5326s
Epoch: 20 cost time: 6.168931007385254
Epoch: 20, Steps: 233 Train Loss: 3.3678 (Forecasting Loss:0.5721 + XiCon Loss:2.7957 x Lambda(1.0)), Vali MSE Loss: 1.0716 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.3659322
	speed: 0.0278s/iter; left time: 516.0543s
	iters: 200, epoch: 21 | loss: 3.4349337
	speed: 0.0252s/iter; left time: 463.8836s
Epoch: 21 cost time: 6.150596618652344
Epoch: 21, Steps: 233 Train Loss: 3.3737 (Forecasting Loss:0.5721 + XiCon Loss:2.8016 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2996266
	speed: 0.0287s/iter; left time: 524.6149s
	iters: 200, epoch: 22 | loss: 3.3536897
	speed: 0.0257s/iter; left time: 467.2057s
Epoch: 22 cost time: 6.294231176376343
Epoch: 22, Steps: 233 Train Loss: 3.3694 (Forecasting Loss:0.5720 + XiCon Loss:2.7974 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3892944
	speed: 0.0283s/iter; left time: 511.3703s
	iters: 200, epoch: 23 | loss: 3.3333604
	speed: 0.0248s/iter; left time: 445.4897s
Epoch: 23 cost time: 6.173451900482178
Epoch: 23, Steps: 233 Train Loss: 3.3747 (Forecasting Loss:0.5721 + XiCon Loss:2.8026 x Lambda(1.0)), Vali MSE Loss: 1.0716 Test MSE Loss: 1.1389
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.4048643
	speed: 0.0280s/iter; left time: 499.3225s
	iters: 200, epoch: 24 | loss: 3.4066675
	speed: 0.0253s/iter; left time: 448.6754s
Epoch: 24 cost time: 6.1620192527771
Epoch: 24, Steps: 233 Train Loss: 3.3703 (Forecasting Loss:0.5721 + XiCon Loss:2.7982 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.4469056
	speed: 0.0278s/iter; left time: 489.0557s
	iters: 200, epoch: 25 | loss: 3.4551020
	speed: 0.0249s/iter; left time: 436.4554s
Epoch: 25 cost time: 6.124954462051392
Epoch: 25, Steps: 233 Train Loss: 3.3761 (Forecasting Loss:0.5721 + XiCon Loss:2.8040 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.3374901
	speed: 0.0305s/iter; left time: 529.7405s
	iters: 200, epoch: 26 | loss: 3.3093638
	speed: 0.0267s/iter; left time: 460.4166s
Epoch: 26 cost time: 6.673394680023193
Epoch: 26, Steps: 233 Train Loss: 3.3734 (Forecasting Loss:0.5720 + XiCon Loss:2.8014 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.4070024
	speed: 0.0305s/iter; left time: 523.6322s
	iters: 200, epoch: 27 | loss: 3.3178191
	speed: 0.0269s/iter; left time: 458.5641s
Epoch: 27 cost time: 6.630438327789307
Epoch: 27, Steps: 233 Train Loss: 3.3764 (Forecasting Loss:0.5721 + XiCon Loss:2.8042 x Lambda(1.0)), Vali MSE Loss: 1.0716 Test MSE Loss: 1.1389
Validation loss decreased (1.071571 --> 1.071567).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.3876123
	speed: 0.0295s/iter; left time: 499.4207s
	iters: 200, epoch: 28 | loss: 3.2829762
	speed: 0.0267s/iter; left time: 449.1668s
Epoch: 28 cost time: 6.585966348648071
Epoch: 28, Steps: 233 Train Loss: 3.3744 (Forecasting Loss:0.5721 + XiCon Loss:2.8023 x Lambda(1.0)), Vali MSE Loss: 1.0715 Test MSE Loss: 1.1389
Validation loss decreased (1.071567 --> 1.071525).  Saving model ...
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.3803561
	speed: 0.0295s/iter; left time: 492.4355s
	iters: 200, epoch: 29 | loss: 3.4054551
	speed: 0.0269s/iter; left time: 446.3411s
Epoch: 29 cost time: 6.5942347049713135
Epoch: 29, Steps: 233 Train Loss: 3.3671 (Forecasting Loss:0.5722 + XiCon Loss:2.7950 x Lambda(1.0)), Vali MSE Loss: 1.0718 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.4227500
	speed: 0.0305s/iter; left time: 501.1293s
	iters: 200, epoch: 30 | loss: 3.4244785
	speed: 0.0270s/iter; left time: 440.4940s
Epoch: 30 cost time: 6.6109442710876465
Epoch: 30, Steps: 233 Train Loss: 3.3752 (Forecasting Loss:0.5720 + XiCon Loss:2.8031 x Lambda(1.0)), Vali MSE Loss: 1.0713 Test MSE Loss: 1.1389
Validation loss decreased (1.071525 --> 1.071325).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.3649206
	speed: 0.0307s/iter; left time: 498.4428s
	iters: 200, epoch: 31 | loss: 3.4153442
	speed: 0.0271s/iter; left time: 436.0517s
Epoch: 31 cost time: 6.713750839233398
Epoch: 31, Steps: 233 Train Loss: 3.3706 (Forecasting Loss:0.5720 + XiCon Loss:2.7985 x Lambda(1.0)), Vali MSE Loss: 1.0718 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 3.3200145
	speed: 0.0300s/iter; left time: 478.5668s
	iters: 200, epoch: 32 | loss: 3.4443736
	speed: 0.0268s/iter; left time: 424.9820s
Epoch: 32 cost time: 6.540001153945923
Epoch: 32, Steps: 233 Train Loss: 3.3705 (Forecasting Loss:0.5720 + XiCon Loss:2.7985 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 3.3203106
	speed: 0.0298s/iter; left time: 469.4428s
	iters: 200, epoch: 33 | loss: 3.3902740
	speed: 0.0269s/iter; left time: 421.3682s
Epoch: 33 cost time: 6.6314404010772705
Epoch: 33, Steps: 233 Train Loss: 3.3724 (Forecasting Loss:0.5722 + XiCon Loss:2.8002 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 3.3804266
	speed: 0.0302s/iter; left time: 468.4689s
	iters: 200, epoch: 34 | loss: 3.3195906
	speed: 0.0268s/iter; left time: 412.6101s
Epoch: 34 cost time: 6.685150861740112
Epoch: 34, Steps: 233 Train Loss: 3.3730 (Forecasting Loss:0.5723 + XiCon Loss:2.8007 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 3.4250855
	speed: 0.0311s/iter; left time: 475.4917s
	iters: 200, epoch: 35 | loss: 3.3333180
	speed: 0.0273s/iter; left time: 414.4146s
Epoch: 35 cost time: 6.743891000747681
Epoch: 35, Steps: 233 Train Loss: 3.3693 (Forecasting Loss:0.5721 + XiCon Loss:2.7972 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 3.4276555
	speed: 0.0292s/iter; left time: 439.8916s
	iters: 200, epoch: 36 | loss: 3.4242296
	speed: 0.0267s/iter; left time: 399.7466s
Epoch: 36 cost time: 6.5754852294921875
Epoch: 36, Steps: 233 Train Loss: 3.3653 (Forecasting Loss:0.5722 + XiCon Loss:2.7931 x Lambda(1.0)), Vali MSE Loss: 1.0718 Test MSE Loss: 1.1389
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 3.4176946
	speed: 0.0296s/iter; left time: 438.7715s
	iters: 200, epoch: 37 | loss: 3.3103294
	speed: 0.0275s/iter; left time: 404.0398s
Epoch: 37 cost time: 6.6414220333099365
Epoch: 37, Steps: 233 Train Loss: 3.3757 (Forecasting Loss:0.5721 + XiCon Loss:2.8036 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 3.3905518
	speed: 0.0289s/iter; left time: 421.8944s
	iters: 200, epoch: 38 | loss: 3.5029426
	speed: 0.0274s/iter; left time: 397.1754s
Epoch: 38 cost time: 6.551994323730469
Epoch: 38, Steps: 233 Train Loss: 3.3763 (Forecasting Loss:0.5722 + XiCon Loss:2.8041 x Lambda(1.0)), Vali MSE Loss: 1.0717 Test MSE Loss: 1.1389
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 3.3841205
	speed: 0.0300s/iter; left time: 430.9174s
	iters: 200, epoch: 39 | loss: 3.3128319
	speed: 0.0269s/iter; left time: 382.9890s
Epoch: 39 cost time: 6.64775276184082
Epoch: 39, Steps: 233 Train Loss: 3.3698 (Forecasting Loss:0.5722 + XiCon Loss:2.7976 x Lambda(1.0)), Vali MSE Loss: 1.0719 Test MSE Loss: 1.1389
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 3.3277485
	speed: 0.0307s/iter; left time: 433.0965s
	iters: 200, epoch: 40 | loss: 3.3502512
	speed: 0.0267s/iter; left time: 374.0149s
Epoch: 40 cost time: 6.6380884647369385
Epoch: 40, Steps: 233 Train Loss: 3.3720 (Forecasting Loss:0.5720 + XiCon Loss:2.8000 x Lambda(1.0)), Vali MSE Loss: 1.0716 Test MSE Loss: 1.1389
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3978012800216675, mae:0.8800197243690491, mape:6.150980472564697, mspe:4546.10986328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3944+-0.00453, MAE:0.8782+-0.00232, MAPE:6.1240+-0.05995, MSPE:4502.5010+-99.69528, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8300
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 3.8772318
	speed: 0.0562s/iter; left time: 1269.3361s
	iters: 200, epoch: 1 | loss: 3.6408570
	speed: 0.0509s/iter; left time: 1146.3265s
Epoch: 1 cost time: 12.09086012840271
Epoch: 1, Steps: 227 Train Loss: 3.7208 (Forecasting Loss:1.0262 + XiCon Loss:2.6946 x Lambda(1.0)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.936041).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3137057
	speed: 0.0524s/iter; left time: 1172.5956s
	iters: 200, epoch: 2 | loss: 3.3084111
	speed: 0.0511s/iter; left time: 1138.0953s
Epoch: 2 cost time: 11.751749277114868
Epoch: 2, Steps: 227 Train Loss: 3.3525 (Forecasting Loss:0.6690 + XiCon Loss:2.6835 x Lambda(1.0)), Vali MSE Loss: 1.2115 Test MSE Loss: 1.2840
Validation loss decreased (1.936041 --> 1.211496).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2359488
	speed: 0.0530s/iter; left time: 1173.0531s
	iters: 200, epoch: 3 | loss: 3.3147187
	speed: 0.0515s/iter; left time: 1135.0302s
Epoch: 3 cost time: 11.85898470878601
Epoch: 3, Steps: 227 Train Loss: 3.2612 (Forecasting Loss:0.6064 + XiCon Loss:2.6548 x Lambda(1.0)), Vali MSE Loss: 1.1894 Test MSE Loss: 1.2754
Validation loss decreased (1.211496 --> 1.189356).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.1522825
	speed: 0.0534s/iter; left time: 1169.7688s
	iters: 200, epoch: 4 | loss: 3.1601641
	speed: 0.0530s/iter; left time: 1155.9980s
Epoch: 4 cost time: 12.091935396194458
Epoch: 4, Steps: 227 Train Loss: 3.2272 (Forecasting Loss:0.5989 + XiCon Loss:2.6283 x Lambda(1.0)), Vali MSE Loss: 1.1839 Test MSE Loss: 1.2736
Validation loss decreased (1.189356 --> 1.183933).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.1353700
	speed: 0.0543s/iter; left time: 1176.9831s
	iters: 200, epoch: 5 | loss: 3.2826052
	speed: 0.0526s/iter; left time: 1134.9259s
Epoch: 5 cost time: 12.09088134765625
Epoch: 5, Steps: 227 Train Loss: 3.2108 (Forecasting Loss:0.5961 + XiCon Loss:2.6147 x Lambda(1.0)), Vali MSE Loss: 1.1815 Test MSE Loss: 1.2726
Validation loss decreased (1.183933 --> 1.181468).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.1670961
	speed: 0.0550s/iter; left time: 1179.8464s
	iters: 200, epoch: 6 | loss: 3.2003694
	speed: 0.0528s/iter; left time: 1127.2590s
Epoch: 6 cost time: 12.23532509803772
Epoch: 6, Steps: 227 Train Loss: 3.1950 (Forecasting Loss:0.5948 + XiCon Loss:2.6003 x Lambda(1.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2723
Validation loss decreased (1.181468 --> 1.179867).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2463303
	speed: 0.0543s/iter; left time: 1154.1067s
	iters: 200, epoch: 7 | loss: 3.1545272
	speed: 0.0515s/iter; left time: 1088.8360s
Epoch: 7 cost time: 11.983917713165283
Epoch: 7, Steps: 227 Train Loss: 3.1951 (Forecasting Loss:0.5940 + XiCon Loss:2.6010 x Lambda(1.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2721
Validation loss decreased (1.179867 --> 1.179336).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2572060
	speed: 0.0559s/iter; left time: 1175.5777s
	iters: 200, epoch: 8 | loss: 3.3043485
	speed: 0.0512s/iter; left time: 1069.8041s
Epoch: 8 cost time: 12.116233348846436
Epoch: 8, Steps: 227 Train Loss: 3.1921 (Forecasting Loss:0.5937 + XiCon Loss:2.5984 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2721
Validation loss decreased (1.179336 --> 1.178531).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1819344
	speed: 0.0552s/iter; left time: 1147.8789s
	iters: 200, epoch: 9 | loss: 3.1892357
	speed: 0.0522s/iter; left time: 1079.5892s
Epoch: 9 cost time: 12.132885932922363
Epoch: 9, Steps: 227 Train Loss: 3.1940 (Forecasting Loss:0.5935 + XiCon Loss:2.6005 x Lambda(1.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.1740515
	speed: 0.0544s/iter; left time: 1118.5088s
	iters: 200, epoch: 10 | loss: 3.2394857
	speed: 0.0532s/iter; left time: 1087.5595s
Epoch: 10 cost time: 12.180077314376831
Epoch: 10, Steps: 227 Train Loss: 3.1898 (Forecasting Loss:0.5935 + XiCon Loss:2.5964 x Lambda(1.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2229042
	speed: 0.0514s/iter; left time: 1046.0192s
	iters: 200, epoch: 11 | loss: 3.1974518
	speed: 0.0502s/iter; left time: 1015.0779s
Epoch: 11 cost time: 11.580235481262207
Epoch: 11, Steps: 227 Train Loss: 3.1927 (Forecasting Loss:0.5932 + XiCon Loss:2.5995 x Lambda(1.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1785417
	speed: 0.0517s/iter; left time: 1039.5616s
	iters: 200, epoch: 12 | loss: 3.1973429
	speed: 0.0495s/iter; left time: 989.5326s
Epoch: 12 cost time: 11.55233120918274
Epoch: 12, Steps: 227 Train Loss: 3.1903 (Forecasting Loss:0.5933 + XiCon Loss:2.5970 x Lambda(1.0)), Vali MSE Loss: 1.1783 Test MSE Loss: 1.2720
Validation loss decreased (1.178531 --> 1.178324).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1000288
	speed: 0.0532s/iter; left time: 1058.0318s
	iters: 200, epoch: 13 | loss: 3.1995556
	speed: 0.0492s/iter; left time: 972.0638s
Epoch: 13 cost time: 11.617144107818604
Epoch: 13, Steps: 227 Train Loss: 3.1897 (Forecasting Loss:0.5935 + XiCon Loss:2.5962 x Lambda(1.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2103908
	speed: 0.0510s/iter; left time: 1001.7806s
	iters: 200, epoch: 14 | loss: 3.1563780
	speed: 0.0497s/iter; left time: 971.2106s
Epoch: 14 cost time: 11.4460768699646
Epoch: 14, Steps: 227 Train Loss: 3.1893 (Forecasting Loss:0.5934 + XiCon Loss:2.5958 x Lambda(1.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2130268
	speed: 0.0533s/iter; left time: 1034.4602s
	iters: 200, epoch: 15 | loss: 3.1958275
	speed: 0.0500s/iter; left time: 966.5464s
Epoch: 15 cost time: 11.760631561279297
Epoch: 15, Steps: 227 Train Loss: 3.1876 (Forecasting Loss:0.5935 + XiCon Loss:2.5942 x Lambda(1.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.1258140
	speed: 0.0557s/iter; left time: 1069.5717s
	iters: 200, epoch: 16 | loss: 3.2357574
	speed: 0.0512s/iter; left time: 978.2220s
Epoch: 16 cost time: 12.134191513061523
Epoch: 16, Steps: 227 Train Loss: 3.1935 (Forecasting Loss:0.5932 + XiCon Loss:2.6003 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.3121865
	speed: 0.0550s/iter; left time: 1042.8443s
	iters: 200, epoch: 17 | loss: 3.2216330
	speed: 0.0506s/iter; left time: 953.9942s
Epoch: 17 cost time: 11.972099304199219
Epoch: 17, Steps: 227 Train Loss: 3.1858 (Forecasting Loss:0.5933 + XiCon Loss:2.5925 x Lambda(1.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1605871
	speed: 0.0542s/iter; left time: 1015.5977s
	iters: 200, epoch: 18 | loss: 3.2409627
	speed: 0.0520s/iter; left time: 970.2405s
Epoch: 18 cost time: 12.018335819244385
Epoch: 18, Steps: 227 Train Loss: 3.1897 (Forecasting Loss:0.5934 + XiCon Loss:2.5963 x Lambda(1.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2720
Validation loss decreased (1.178324 --> 1.178173).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2286835
	speed: 0.0554s/iter; left time: 1025.6277s
	iters: 200, epoch: 19 | loss: 3.2385364
	speed: 0.0500s/iter; left time: 921.1597s
Epoch: 19 cost time: 11.953519105911255
Epoch: 19, Steps: 227 Train Loss: 3.1941 (Forecasting Loss:0.5933 + XiCon Loss:2.6009 x Lambda(1.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.1168613
	speed: 0.0545s/iter; left time: 997.3039s
	iters: 200, epoch: 20 | loss: 3.1170583
	speed: 0.0517s/iter; left time: 939.6918s
Epoch: 20 cost time: 12.050570011138916
Epoch: 20, Steps: 227 Train Loss: 3.1929 (Forecasting Loss:0.5933 + XiCon Loss:2.5995 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.1926427
	speed: 0.0548s/iter; left time: 988.8948s
	iters: 200, epoch: 21 | loss: 3.2185600
	speed: 0.0539s/iter; left time: 968.3738s
Epoch: 21 cost time: 12.276341438293457
Epoch: 21, Steps: 227 Train Loss: 3.1932 (Forecasting Loss:0.5934 + XiCon Loss:2.5999 x Lambda(1.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.1766236
	speed: 0.0553s/iter; left time: 985.4564s
	iters: 200, epoch: 22 | loss: 3.3249974
	speed: 0.0508s/iter; left time: 900.0560s
Epoch: 22 cost time: 12.056997537612915
Epoch: 22, Steps: 227 Train Loss: 3.1913 (Forecasting Loss:0.5934 + XiCon Loss:2.5979 x Lambda(1.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.3403234
	speed: 0.0532s/iter; left time: 936.9389s
	iters: 200, epoch: 23 | loss: 3.1500444
	speed: 0.0512s/iter; left time: 896.1774s
Epoch: 23 cost time: 11.82946515083313
Epoch: 23, Steps: 227 Train Loss: 3.1944 (Forecasting Loss:0.5933 + XiCon Loss:2.6011 x Lambda(1.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.1933856
	speed: 0.0542s/iter; left time: 942.2291s
	iters: 200, epoch: 24 | loss: 3.2031879
	speed: 0.0522s/iter; left time: 902.6599s
Epoch: 24 cost time: 12.074099779129028
Epoch: 24, Steps: 227 Train Loss: 3.1918 (Forecasting Loss:0.5934 + XiCon Loss:2.5983 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.1468205
	speed: 0.0524s/iter; left time: 899.3165s
	iters: 200, epoch: 25 | loss: 3.2463591
	speed: 0.0525s/iter; left time: 894.8674s
Epoch: 25 cost time: 11.922710657119751
Epoch: 25, Steps: 227 Train Loss: 3.1923 (Forecasting Loss:0.5933 + XiCon Loss:2.5990 x Lambda(1.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2190483
	speed: 0.0565s/iter; left time: 956.9700s
	iters: 200, epoch: 26 | loss: 3.1542463
	speed: 0.0511s/iter; left time: 859.4177s
Epoch: 26 cost time: 12.198752880096436
Epoch: 26, Steps: 227 Train Loss: 3.1899 (Forecasting Loss:0.5932 + XiCon Loss:2.5967 x Lambda(1.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.2580662
	speed: 0.0532s/iter; left time: 889.1135s
	iters: 200, epoch: 27 | loss: 3.1906362
	speed: 0.0525s/iter; left time: 871.4364s
Epoch: 27 cost time: 12.003950357437134
Epoch: 27, Steps: 227 Train Loss: 3.1924 (Forecasting Loss:0.5933 + XiCon Loss:2.5991 x Lambda(1.0)), Vali MSE Loss: 1.1776 Test MSE Loss: 1.2720
Validation loss decreased (1.178173 --> 1.177636).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.1765854
	speed: 0.0560s/iter; left time: 922.2562s
	iters: 200, epoch: 28 | loss: 3.2869239
	speed: 0.0512s/iter; left time: 837.4531s
Epoch: 28 cost time: 12.184533596038818
Epoch: 28, Steps: 227 Train Loss: 3.1940 (Forecasting Loss:0.5933 + XiCon Loss:2.6007 x Lambda(1.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.2067220
	speed: 0.0541s/iter; left time: 878.5810s
	iters: 200, epoch: 29 | loss: 3.2243810
	speed: 0.0514s/iter; left time: 829.8572s
Epoch: 29 cost time: 11.958545207977295
Epoch: 29, Steps: 227 Train Loss: 3.1890 (Forecasting Loss:0.5935 + XiCon Loss:2.5955 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.1821091
	speed: 0.0537s/iter; left time: 860.6820s
	iters: 200, epoch: 30 | loss: 3.1961823
	speed: 0.0521s/iter; left time: 829.6753s
Epoch: 30 cost time: 11.955936431884766
Epoch: 30, Steps: 227 Train Loss: 3.1869 (Forecasting Loss:0.5933 + XiCon Loss:2.5936 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.1827192
	speed: 0.0537s/iter; left time: 847.8428s
	iters: 200, epoch: 31 | loss: 3.2508647
	speed: 0.0521s/iter; left time: 816.8692s
Epoch: 31 cost time: 12.029422521591187
Epoch: 31, Steps: 227 Train Loss: 3.1907 (Forecasting Loss:0.5935 + XiCon Loss:2.5972 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 3.1453941
	speed: 0.0544s/iter; left time: 846.0817s
	iters: 200, epoch: 32 | loss: 3.1967142
	speed: 0.0524s/iter; left time: 809.9930s
Epoch: 32 cost time: 12.158625602722168
Epoch: 32, Steps: 227 Train Loss: 3.1895 (Forecasting Loss:0.5934 + XiCon Loss:2.5961 x Lambda(1.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 3.1647162
	speed: 0.0545s/iter; left time: 835.9904s
	iters: 200, epoch: 33 | loss: 3.2006402
	speed: 0.0519s/iter; left time: 790.7088s
Epoch: 33 cost time: 12.044978618621826
Epoch: 33, Steps: 227 Train Loss: 3.1892 (Forecasting Loss:0.5934 + XiCon Loss:2.5958 x Lambda(1.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 3.1986167
	speed: 0.0533s/iter; left time: 804.6176s
	iters: 200, epoch: 34 | loss: 3.1353521
	speed: 0.0533s/iter; left time: 800.5022s
Epoch: 34 cost time: 12.103492975234985
Epoch: 34, Steps: 227 Train Loss: 3.1930 (Forecasting Loss:0.5933 + XiCon Loss:2.5997 x Lambda(1.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 3.1812184
	speed: 0.0529s/iter; left time: 787.8635s
	iters: 200, epoch: 35 | loss: 3.0985346
	speed: 0.0481s/iter; left time: 710.5970s
Epoch: 35 cost time: 11.46975040435791
Epoch: 35, Steps: 227 Train Loss: 3.1910 (Forecasting Loss:0.5933 + XiCon Loss:2.5976 x Lambda(1.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 3.1984150
	speed: 0.0529s/iter; left time: 774.6637s
	iters: 200, epoch: 36 | loss: 3.2304997
	speed: 0.0476s/iter; left time: 692.7946s
Epoch: 36 cost time: 11.383069276809692
Epoch: 36, Steps: 227 Train Loss: 3.1931 (Forecasting Loss:0.5935 + XiCon Loss:2.5996 x Lambda(1.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 3.2092876
	speed: 0.0534s/iter; left time: 770.3163s
	iters: 200, epoch: 37 | loss: 3.1874309
	speed: 0.0496s/iter; left time: 711.1752s
Epoch: 37 cost time: 11.713798761367798
Epoch: 37, Steps: 227 Train Loss: 3.1942 (Forecasting Loss:0.5933 + XiCon Loss:2.6009 x Lambda(1.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5892586708068848, mae:0.9546672701835632, mape:6.265625953674316, mspe:4854.044921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.8666
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 3.7768707
	speed: 0.0542s/iter; left time: 1224.0586s
	iters: 200, epoch: 1 | loss: 3.7294698
	speed: 0.0503s/iter; left time: 1132.2029s
Epoch: 1 cost time: 11.866425514221191
Epoch: 1, Steps: 227 Train Loss: 3.7330 (Forecasting Loss:1.0243 + XiCon Loss:2.7087 x Lambda(1.0)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932089).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.2510481
	speed: 0.0546s/iter; left time: 1221.0592s
	iters: 200, epoch: 2 | loss: 3.3082137
	speed: 0.0517s/iter; left time: 1151.2954s
Epoch: 2 cost time: 12.017184972763062
Epoch: 2, Steps: 227 Train Loss: 3.3747 (Forecasting Loss:0.6694 + XiCon Loss:2.7054 x Lambda(1.0)), Vali MSE Loss: 1.2131 Test MSE Loss: 1.2808
Validation loss decreased (1.932089 --> 1.213096).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3049667
	speed: 0.0545s/iter; left time: 1207.0694s
	iters: 200, epoch: 3 | loss: 3.3136106
	speed: 0.0513s/iter; left time: 1131.0044s
Epoch: 3 cost time: 11.974074840545654
Epoch: 3, Steps: 227 Train Loss: 3.2984 (Forecasting Loss:0.6076 + XiCon Loss:2.6908 x Lambda(1.0)), Vali MSE Loss: 1.1942 Test MSE Loss: 1.2731
Validation loss decreased (1.213096 --> 1.194164).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2614496
	speed: 0.0546s/iter; left time: 1195.8673s
	iters: 200, epoch: 4 | loss: 3.1762433
	speed: 0.0508s/iter; left time: 1109.3734s
Epoch: 4 cost time: 11.965163707733154
Epoch: 4, Steps: 227 Train Loss: 3.2818 (Forecasting Loss:0.6004 + XiCon Loss:2.6814 x Lambda(1.0)), Vali MSE Loss: 1.1883 Test MSE Loss: 1.2712
Validation loss decreased (1.194164 --> 1.188343).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.3263407
	speed: 0.0532s/iter; left time: 1153.6398s
	iters: 200, epoch: 5 | loss: 3.3323722
	speed: 0.0530s/iter; left time: 1143.7630s
Epoch: 5 cost time: 12.012270212173462
Epoch: 5, Steps: 227 Train Loss: 3.2752 (Forecasting Loss:0.5976 + XiCon Loss:2.6777 x Lambda(1.0)), Vali MSE Loss: 1.1857 Test MSE Loss: 1.2705
Validation loss decreased (1.188343 --> 1.185723).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.3017442
	speed: 0.0546s/iter; left time: 1170.9866s
	iters: 200, epoch: 6 | loss: 3.2325475
	speed: 0.0521s/iter; left time: 1113.7280s
Epoch: 6 cost time: 12.056742429733276
Epoch: 6, Steps: 227 Train Loss: 3.2690 (Forecasting Loss:0.5962 + XiCon Loss:2.6728 x Lambda(1.0)), Vali MSE Loss: 1.1840 Test MSE Loss: 1.2702
Validation loss decreased (1.185723 --> 1.184000).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2335944
	speed: 0.0550s/iter; left time: 1168.2438s
	iters: 200, epoch: 7 | loss: 3.3121438
	speed: 0.0526s/iter; left time: 1112.5181s
Epoch: 7 cost time: 12.17496371269226
Epoch: 7, Steps: 227 Train Loss: 3.2709 (Forecasting Loss:0.5954 + XiCon Loss:2.6755 x Lambda(1.0)), Vali MSE Loss: 1.1837 Test MSE Loss: 1.2700
Validation loss decreased (1.184000 --> 1.183719).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2670751
	speed: 0.0540s/iter; left time: 1133.9756s
	iters: 200, epoch: 8 | loss: 3.3360393
	speed: 0.0526s/iter; left time: 1100.0983s
Epoch: 8 cost time: 12.025307178497314
Epoch: 8, Steps: 227 Train Loss: 3.2733 (Forecasting Loss:0.5952 + XiCon Loss:2.6781 x Lambda(1.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2699
Validation loss decreased (1.183719 --> 1.183295).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1944287
	speed: 0.0556s/iter; left time: 1156.5624s
	iters: 200, epoch: 9 | loss: 3.2270589
	speed: 0.0528s/iter; left time: 1092.9486s
Epoch: 9 cost time: 12.228184223175049
Epoch: 9, Steps: 227 Train Loss: 3.2672 (Forecasting Loss:0.5950 + XiCon Loss:2.6722 x Lambda(1.0)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2699
Validation loss decreased (1.183295 --> 1.182054).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.1797345
	speed: 0.0532s/iter; left time: 1093.4509s
	iters: 200, epoch: 10 | loss: 3.2837186
	speed: 0.0525s/iter; left time: 1073.9955s
Epoch: 10 cost time: 12.01843786239624
Epoch: 10, Steps: 227 Train Loss: 3.2709 (Forecasting Loss:0.5948 + XiCon Loss:2.6761 x Lambda(1.0)), Vali MSE Loss: 1.1825 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2021756
	speed: 0.0536s/iter; left time: 1090.7140s
	iters: 200, epoch: 11 | loss: 3.4096127
	speed: 0.0514s/iter; left time: 1039.7659s
Epoch: 11 cost time: 11.958934545516968
Epoch: 11, Steps: 227 Train Loss: 3.2686 (Forecasting Loss:0.5948 + XiCon Loss:2.6738 x Lambda(1.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2904952
	speed: 0.0530s/iter; left time: 1064.6598s
	iters: 200, epoch: 12 | loss: 3.2481296
	speed: 0.0519s/iter; left time: 1039.2032s
Epoch: 12 cost time: 11.906257152557373
Epoch: 12, Steps: 227 Train Loss: 3.2696 (Forecasting Loss:0.5948 + XiCon Loss:2.6748 x Lambda(1.0)), Vali MSE Loss: 1.1830 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2608764
	speed: 0.0555s/iter; left time: 1102.2696s
	iters: 200, epoch: 13 | loss: 3.2204559
	speed: 0.0519s/iter; left time: 1026.5539s
Epoch: 13 cost time: 12.125484704971313
Epoch: 13, Steps: 227 Train Loss: 3.2688 (Forecasting Loss:0.5948 + XiCon Loss:2.6740 x Lambda(1.0)), Vali MSE Loss: 1.1830 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2546785
	speed: 0.0548s/iter; left time: 1076.0874s
	iters: 200, epoch: 14 | loss: 3.3446565
	speed: 0.0513s/iter; left time: 1001.9437s
Epoch: 14 cost time: 11.9877347946167
Epoch: 14, Steps: 227 Train Loss: 3.2660 (Forecasting Loss:0.5948 + XiCon Loss:2.6712 x Lambda(1.0)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2873654
	speed: 0.0545s/iter; left time: 1058.1126s
	iters: 200, epoch: 15 | loss: 3.3890977
	speed: 0.0517s/iter; left time: 998.4040s
Epoch: 15 cost time: 12.020608186721802
Epoch: 15, Steps: 227 Train Loss: 3.2703 (Forecasting Loss:0.5947 + XiCon Loss:2.6756 x Lambda(1.0)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2698
Validation loss decreased (1.182054 --> 1.181781).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2210348
	speed: 0.0542s/iter; left time: 1040.3112s
	iters: 200, epoch: 16 | loss: 3.2578847
	speed: 0.0536s/iter; left time: 1022.8937s
Epoch: 16 cost time: 12.254359006881714
Epoch: 16, Steps: 227 Train Loss: 3.2704 (Forecasting Loss:0.5946 + XiCon Loss:2.6758 x Lambda(1.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2509332
	speed: 0.0541s/iter; left time: 1025.5167s
	iters: 200, epoch: 17 | loss: 3.2769330
	speed: 0.0517s/iter; left time: 976.2963s
Epoch: 17 cost time: 12.123857736587524
Epoch: 17, Steps: 227 Train Loss: 3.2705 (Forecasting Loss:0.5948 + XiCon Loss:2.6757 x Lambda(1.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.3360815
	speed: 0.0535s/iter; left time: 1003.5920s
	iters: 200, epoch: 18 | loss: 3.1792905
	speed: 0.0531s/iter; left time: 990.0616s
Epoch: 18 cost time: 12.037305355072021
Epoch: 18, Steps: 227 Train Loss: 3.2656 (Forecasting Loss:0.5947 + XiCon Loss:2.6709 x Lambda(1.0)), Vali MSE Loss: 1.1830 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2437263
	speed: 0.0547s/iter; left time: 1013.3721s
	iters: 200, epoch: 19 | loss: 3.2474658
	speed: 0.0512s/iter; left time: 942.4873s
Epoch: 19 cost time: 12.038066387176514
Epoch: 19, Steps: 227 Train Loss: 3.2697 (Forecasting Loss:0.5947 + XiCon Loss:2.6750 x Lambda(1.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2304068
	speed: 0.0531s/iter; left time: 972.0015s
	iters: 200, epoch: 20 | loss: 3.3030949
	speed: 0.0511s/iter; left time: 928.8495s
Epoch: 20 cost time: 11.779191493988037
Epoch: 20, Steps: 227 Train Loss: 3.2712 (Forecasting Loss:0.5947 + XiCon Loss:2.6765 x Lambda(1.0)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2433691
	speed: 0.0512s/iter; left time: 924.5351s
	iters: 200, epoch: 21 | loss: 3.2204971
	speed: 0.0521s/iter; left time: 935.1975s
Epoch: 21 cost time: 11.790353536605835
Epoch: 21, Steps: 227 Train Loss: 3.2671 (Forecasting Loss:0.5947 + XiCon Loss:2.6723 x Lambda(1.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2213082
	speed: 0.0509s/iter; left time: 908.6418s
	iters: 200, epoch: 22 | loss: 3.2289648
	speed: 0.0492s/iter; left time: 872.2269s
Epoch: 22 cost time: 11.459602117538452
Epoch: 22, Steps: 227 Train Loss: 3.2703 (Forecasting Loss:0.5947 + XiCon Loss:2.6757 x Lambda(1.0)), Vali MSE Loss: 1.1823 Test MSE Loss: 1.2698
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2538927
	speed: 0.0531s/iter; left time: 935.0266s
	iters: 200, epoch: 23 | loss: 3.2773650
	speed: 0.0488s/iter; left time: 854.3208s
Epoch: 23 cost time: 11.545273542404175
Epoch: 23, Steps: 227 Train Loss: 3.2641 (Forecasting Loss:0.5947 + XiCon Loss:2.6693 x Lambda(1.0)), Vali MSE Loss: 1.1823 Test MSE Loss: 1.2698
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2997580
	speed: 0.0522s/iter; left time: 907.9256s
	iters: 200, epoch: 24 | loss: 3.3180280
	speed: 0.0490s/iter; left time: 846.8233s
Epoch: 24 cost time: 11.48630976676941
Epoch: 24, Steps: 227 Train Loss: 3.2652 (Forecasting Loss:0.5946 + XiCon Loss:2.6706 x Lambda(1.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2841718
	speed: 0.0538s/iter; left time: 923.0348s
	iters: 200, epoch: 25 | loss: 3.2077990
	speed: 0.0537s/iter; left time: 915.5635s
Epoch: 25 cost time: 12.300320625305176
Epoch: 25, Steps: 227 Train Loss: 3.2674 (Forecasting Loss:0.5947 + XiCon Loss:2.6727 x Lambda(1.0)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2698
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5867691040039062, mae:0.9528781771659851, mape:6.205631256103516, mspe:4738.9375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8643
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 3.8127122
	speed: 0.0492s/iter; left time: 1111.0885s
	iters: 200, epoch: 1 | loss: 3.8460844
	speed: 0.0451s/iter; left time: 1015.0297s
Epoch: 1 cost time: 10.671127557754517
Epoch: 1, Steps: 227 Train Loss: 3.7604 (Forecasting Loss:1.0400 + XiCon Loss:2.7204 x Lambda(1.0)), Vali MSE Loss: 1.9472 Test MSE Loss: 1.3972
Validation loss decreased (inf --> 1.947190).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.2219617
	speed: 0.0487s/iter; left time: 1089.6181s
	iters: 200, epoch: 2 | loss: 3.2921894
	speed: 0.0464s/iter; left time: 1034.2892s
Epoch: 2 cost time: 10.76878023147583
Epoch: 2, Steps: 227 Train Loss: 3.3722 (Forecasting Loss:0.6714 + XiCon Loss:2.7008 x Lambda(1.0)), Vali MSE Loss: 1.2051 Test MSE Loss: 1.2769
Validation loss decreased (1.947190 --> 1.205123).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2529504
	speed: 0.0496s/iter; left time: 1099.1756s
	iters: 200, epoch: 3 | loss: 3.1731844
	speed: 0.0469s/iter; left time: 1033.5916s
Epoch: 3 cost time: 10.988188028335571
Epoch: 3, Steps: 227 Train Loss: 3.2705 (Forecasting Loss:0.6071 + XiCon Loss:2.6634 x Lambda(1.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2704
Validation loss decreased (1.205123 --> 1.186755).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2172751
	speed: 0.0518s/iter; left time: 1134.7358s
	iters: 200, epoch: 4 | loss: 3.2805893
	speed: 0.0490s/iter; left time: 1069.4628s
Epoch: 4 cost time: 11.380592346191406
Epoch: 4, Steps: 227 Train Loss: 3.2232 (Forecasting Loss:0.5999 + XiCon Loss:2.6233 x Lambda(1.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2693
Validation loss decreased (1.186755 --> 1.182816).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.1590900
	speed: 0.0498s/iter; left time: 1081.2557s
	iters: 200, epoch: 5 | loss: 3.2084174
	speed: 0.0487s/iter; left time: 1052.3959s
Epoch: 5 cost time: 11.168716669082642
Epoch: 5, Steps: 227 Train Loss: 3.1959 (Forecasting Loss:0.5971 + XiCon Loss:2.5988 x Lambda(1.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2687
Validation loss decreased (1.182816 --> 1.179646).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2107615
	speed: 0.0512s/iter; left time: 1098.4696s
	iters: 200, epoch: 6 | loss: 3.1648781
	speed: 0.0468s/iter; left time: 999.5260s
Epoch: 6 cost time: 11.093801975250244
Epoch: 6, Steps: 227 Train Loss: 3.1836 (Forecasting Loss:0.5960 + XiCon Loss:2.5877 x Lambda(1.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2683
Validation loss decreased (1.179646 --> 1.179350).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.1241026
	speed: 0.0480s/iter; left time: 1018.9748s
	iters: 200, epoch: 7 | loss: 3.0890665
	speed: 0.0472s/iter; left time: 997.2884s
Epoch: 7 cost time: 10.784058570861816
Epoch: 7, Steps: 227 Train Loss: 3.1760 (Forecasting Loss:0.5952 + XiCon Loss:2.5808 x Lambda(1.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2681
Validation loss decreased (1.179350 --> 1.178963).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2883754
	speed: 0.0507s/iter; left time: 1066.2820s
	iters: 200, epoch: 8 | loss: 3.1082916
	speed: 0.0474s/iter; left time: 990.8715s
Epoch: 8 cost time: 11.096487283706665
Epoch: 8, Steps: 227 Train Loss: 3.1706 (Forecasting Loss:0.5950 + XiCon Loss:2.5756 x Lambda(1.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2680
Validation loss decreased (1.178963 --> 1.178216).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1648843
	speed: 0.0510s/iter; left time: 1060.9590s
	iters: 200, epoch: 9 | loss: 3.0685384
	speed: 0.0471s/iter; left time: 973.9512s
Epoch: 9 cost time: 11.111236095428467
Epoch: 9, Steps: 227 Train Loss: 3.1729 (Forecasting Loss:0.5949 + XiCon Loss:2.5780 x Lambda(1.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2680
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.1311162
	speed: 0.0506s/iter; left time: 1039.2580s
	iters: 200, epoch: 10 | loss: 3.2453542
	speed: 0.0466s/iter; left time: 952.8091s
Epoch: 10 cost time: 11.065282583236694
Epoch: 10, Steps: 227 Train Loss: 3.1698 (Forecasting Loss:0.5947 + XiCon Loss:2.5751 x Lambda(1.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2680
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1081591
	speed: 0.0522s/iter; left time: 1062.1234s
	iters: 200, epoch: 11 | loss: 3.1433256
	speed: 0.0486s/iter; left time: 983.8306s
Epoch: 11 cost time: 11.42770791053772
Epoch: 11, Steps: 227 Train Loss: 3.1744 (Forecasting Loss:0.5945 + XiCon Loss:2.5798 x Lambda(1.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2680
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1206770
	speed: 0.0507s/iter; left time: 1019.4041s
	iters: 200, epoch: 12 | loss: 3.1471806
	speed: 0.0462s/iter; left time: 923.6954s
Epoch: 12 cost time: 10.993853330612183
Epoch: 12, Steps: 227 Train Loss: 3.1739 (Forecasting Loss:0.5946 + XiCon Loss:2.5793 x Lambda(1.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2680
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1269958
	speed: 0.0524s/iter; left time: 1041.7797s
	iters: 200, epoch: 13 | loss: 3.1813257
	speed: 0.0467s/iter; left time: 923.9531s
Epoch: 13 cost time: 11.21665072441101
Epoch: 13, Steps: 227 Train Loss: 3.1734 (Forecasting Loss:0.5945 + XiCon Loss:2.5789 x Lambda(1.0)), Vali MSE Loss: 1.1784 Test MSE Loss: 1.2680
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.0988536
	speed: 0.0498s/iter; left time: 977.6857s
	iters: 200, epoch: 14 | loss: 3.1877234
	speed: 0.0489s/iter; left time: 956.9089s
Epoch: 14 cost time: 11.285930395126343
Epoch: 14, Steps: 227 Train Loss: 3.1670 (Forecasting Loss:0.5947 + XiCon Loss:2.5723 x Lambda(1.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2680
Validation loss decreased (1.178216 --> 1.177973).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2525535
	speed: 0.0498s/iter; left time: 967.3441s
	iters: 200, epoch: 15 | loss: 3.1350060
	speed: 0.0468s/iter; left time: 904.1569s
Epoch: 15 cost time: 10.977209329605103
Epoch: 15, Steps: 227 Train Loss: 3.1673 (Forecasting Loss:0.5945 + XiCon Loss:2.5728 x Lambda(1.0)), Vali MSE Loss: 1.1777 Test MSE Loss: 1.2680
Validation loss decreased (1.177973 --> 1.177747).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.1723566
	speed: 0.0518s/iter; left time: 994.1559s
	iters: 200, epoch: 16 | loss: 3.1232820
	speed: 0.0472s/iter; left time: 902.2109s
Epoch: 16 cost time: 11.270640850067139
Epoch: 16, Steps: 227 Train Loss: 3.1713 (Forecasting Loss:0.5945 + XiCon Loss:2.5768 x Lambda(1.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2680
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2593412
	speed: 0.0507s/iter; left time: 962.4942s
	iters: 200, epoch: 17 | loss: 3.1469960
	speed: 0.0483s/iter; left time: 911.5753s
Epoch: 17 cost time: 11.199070930480957
Epoch: 17, Steps: 227 Train Loss: 3.1704 (Forecasting Loss:0.5946 + XiCon Loss:2.5758 x Lambda(1.0)), Vali MSE Loss: 1.1781 Test MSE Loss: 1.2680
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1864262
	speed: 0.0515s/iter; left time: 964.8207s
	iters: 200, epoch: 18 | loss: 3.1756909
	speed: 0.0475s/iter; left time: 885.1889s
Epoch: 18 cost time: 11.297309398651123
Epoch: 18, Steps: 227 Train Loss: 3.1666 (Forecasting Loss:0.5946 + XiCon Loss:2.5720 x Lambda(1.0)), Vali MSE Loss: 1.1777 Test MSE Loss: 1.2680
Validation loss decreased (1.177747 --> 1.177707).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1629932
	speed: 0.0487s/iter; left time: 902.3990s
	iters: 200, epoch: 19 | loss: 3.1805351
	speed: 0.0449s/iter; left time: 826.7686s
Epoch: 19 cost time: 10.578464984893799
Epoch: 19, Steps: 227 Train Loss: 3.1730 (Forecasting Loss:0.5947 + XiCon Loss:2.5783 x Lambda(1.0)), Vali MSE Loss: 1.1781 Test MSE Loss: 1.2680
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.0968058
	speed: 0.0469s/iter; left time: 858.5905s
	iters: 200, epoch: 20 | loss: 3.2084475
	speed: 0.0440s/iter; left time: 799.7627s
Epoch: 20 cost time: 10.311652898788452
Epoch: 20, Steps: 227 Train Loss: 3.1712 (Forecasting Loss:0.5946 + XiCon Loss:2.5766 x Lambda(1.0)), Vali MSE Loss: 1.1781 Test MSE Loss: 1.2680
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.1527805
	speed: 0.0463s/iter; left time: 836.5391s
	iters: 200, epoch: 21 | loss: 3.1188121
	speed: 0.0440s/iter; left time: 789.3968s
Epoch: 21 cost time: 10.331690549850464
Epoch: 21, Steps: 227 Train Loss: 3.1694 (Forecasting Loss:0.5945 + XiCon Loss:2.5750 x Lambda(1.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2680
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2616749
	speed: 0.0480s/iter; left time: 855.7789s
	iters: 200, epoch: 22 | loss: 3.2367768
	speed: 0.0446s/iter; left time: 791.4042s
Epoch: 22 cost time: 10.485010147094727
Epoch: 22, Steps: 227 Train Loss: 3.1691 (Forecasting Loss:0.5947 + XiCon Loss:2.5744 x Lambda(1.0)), Vali MSE Loss: 1.1782 Test MSE Loss: 1.2680
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.1781120
	speed: 0.0486s/iter; left time: 855.5087s
	iters: 200, epoch: 23 | loss: 3.2329783
	speed: 0.0432s/iter; left time: 756.2852s
Epoch: 23 cost time: 10.424877882003784
Epoch: 23, Steps: 227 Train Loss: 3.1705 (Forecasting Loss:0.5945 + XiCon Loss:2.5760 x Lambda(1.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2680
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.1457651
	speed: 0.0464s/iter; left time: 806.9565s
	iters: 200, epoch: 24 | loss: 3.2047625
	speed: 0.0429s/iter; left time: 741.1860s
Epoch: 24 cost time: 10.126640558242798
Epoch: 24, Steps: 227 Train Loss: 3.1696 (Forecasting Loss:0.5945 + XiCon Loss:2.5751 x Lambda(1.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2680
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.1579242
	speed: 0.0490s/iter; left time: 840.7591s
	iters: 200, epoch: 25 | loss: 3.1287031
	speed: 0.0436s/iter; left time: 743.6208s
Epoch: 25 cost time: 10.490812063217163
Epoch: 25, Steps: 227 Train Loss: 3.1699 (Forecasting Loss:0.5946 + XiCon Loss:2.5753 x Lambda(1.0)), Vali MSE Loss: 1.1779 Test MSE Loss: 1.2680
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.1528034
	speed: 0.0465s/iter; left time: 786.4220s
	iters: 200, epoch: 26 | loss: 3.1961980
	speed: 0.0445s/iter; left time: 747.9365s
Epoch: 26 cost time: 10.370740413665771
Epoch: 26, Steps: 227 Train Loss: 3.1723 (Forecasting Loss:0.5946 + XiCon Loss:2.5777 x Lambda(1.0)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2680
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.1482966
	speed: 0.1011s/iter; left time: 1688.5575s
	iters: 200, epoch: 27 | loss: 3.1194265
	speed: 0.1044s/iter; left time: 1732.9352s
Epoch: 27 cost time: 23.397523403167725
Epoch: 27, Steps: 227 Train Loss: 3.1705 (Forecasting Loss:0.5947 + XiCon Loss:2.5758 x Lambda(1.0)), Vali MSE Loss: 1.1779 Test MSE Loss: 1.2680
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.1195235
	speed: 0.1138s/iter; left time: 1874.4184s
	iters: 200, epoch: 28 | loss: 3.1432924
	speed: 0.1091s/iter; left time: 1785.6082s
Epoch: 28 cost time: 25.407544374465942
Epoch: 28, Steps: 227 Train Loss: 3.1722 (Forecasting Loss:0.5946 + XiCon Loss:2.5776 x Lambda(1.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5843687057495117, mae:0.9515770673751831, mape:6.12272310256958, mspe:4591.40087890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 26.5531
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 3.8428974
	speed: 0.1210s/iter; left time: 2735.0208s
	iters: 200, epoch: 1 | loss: 3.8420570
	speed: 0.1114s/iter; left time: 2507.6845s
Epoch: 1 cost time: 26.046847343444824
Epoch: 1, Steps: 227 Train Loss: 3.8541 (Forecasting Loss:1.1623 + XiCon Loss:2.6918 x Lambda(1.0)), Vali MSE Loss: 2.2086 Test MSE Loss: 1.4657
Validation loss decreased (inf --> 2.208574).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4350238
	speed: 0.1033s/iter; left time: 2311.9459s
	iters: 200, epoch: 2 | loss: 3.3523681
	speed: 0.0924s/iter; left time: 2058.5161s
Epoch: 2 cost time: 22.053816318511963
Epoch: 2, Steps: 227 Train Loss: 3.4295 (Forecasting Loss:0.7518 + XiCon Loss:2.6777 x Lambda(1.0)), Vali MSE Loss: 1.2627 Test MSE Loss: 1.3130
Validation loss decreased (2.208574 --> 1.262715).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2961037
	speed: 0.0920s/iter; left time: 2037.1312s
	iters: 200, epoch: 3 | loss: 3.3074999
	speed: 0.0836s/iter; left time: 1843.9744s
Epoch: 3 cost time: 19.816689014434814
Epoch: 3, Steps: 227 Train Loss: 3.2906 (Forecasting Loss:0.6310 + XiCon Loss:2.6596 x Lambda(1.0)), Vali MSE Loss: 1.2051 Test MSE Loss: 1.2917
Validation loss decreased (1.262715 --> 1.205069).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2642372
	speed: 0.0778s/iter; left time: 1706.1690s
	iters: 200, epoch: 4 | loss: 3.2455993
	speed: 0.0617s/iter; left time: 1346.2545s
Epoch: 4 cost time: 15.627115964889526
Epoch: 4, Steps: 227 Train Loss: 3.2560 (Forecasting Loss:0.6092 + XiCon Loss:2.6468 x Lambda(1.0)), Vali MSE Loss: 1.1852 Test MSE Loss: 1.2830
Validation loss decreased (1.205069 --> 1.185244).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2158108
	speed: 0.0563s/iter; left time: 1221.8546s
	iters: 200, epoch: 5 | loss: 3.2135658
	speed: 0.0518s/iter; left time: 1118.1238s
Epoch: 5 cost time: 12.168561458587646
Epoch: 5, Steps: 227 Train Loss: 3.2385 (Forecasting Loss:0.6013 + XiCon Loss:2.6372 x Lambda(1.0)), Vali MSE Loss: 1.1813 Test MSE Loss: 1.2800
Validation loss decreased (1.185244 --> 1.181292).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2671924
	speed: 0.0535s/iter; left time: 1147.9552s
	iters: 200, epoch: 6 | loss: 3.2295222
	speed: 0.0475s/iter; left time: 1015.6276s
Epoch: 6 cost time: 11.389406204223633
Epoch: 6, Steps: 227 Train Loss: 3.2305 (Forecasting Loss:0.5984 + XiCon Loss:2.6322 x Lambda(1.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2784
Validation loss decreased (1.181292 --> 1.179075).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2179656
	speed: 0.0507s/iter; left time: 1075.9733s
	iters: 200, epoch: 7 | loss: 3.1884096
	speed: 0.0473s/iter; left time: 999.1354s
Epoch: 7 cost time: 11.083110332489014
Epoch: 7, Steps: 227 Train Loss: 3.2305 (Forecasting Loss:0.5971 + XiCon Loss:2.6334 x Lambda(1.0)), Vali MSE Loss: 1.1778 Test MSE Loss: 1.2776
Validation loss decreased (1.179075 --> 1.177814).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2032881
	speed: 0.0504s/iter; left time: 1058.1364s
	iters: 200, epoch: 8 | loss: 3.2708747
	speed: 0.0477s/iter; left time: 997.3580s
Epoch: 8 cost time: 11.128149032592773
Epoch: 8, Steps: 227 Train Loss: 3.2297 (Forecasting Loss:0.5964 + XiCon Loss:2.6333 x Lambda(1.0)), Vali MSE Loss: 1.1779 Test MSE Loss: 1.2773
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2109601
	speed: 0.0497s/iter; left time: 1032.3086s
	iters: 200, epoch: 9 | loss: 3.2360258
	speed: 0.0472s/iter; left time: 976.3363s
Epoch: 9 cost time: 11.056242942810059
Epoch: 9, Steps: 227 Train Loss: 3.2253 (Forecasting Loss:0.5958 + XiCon Loss:2.6294 x Lambda(1.0)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2771
Validation loss decreased (1.177814 --> 1.177043).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2939792
	speed: 0.0505s/iter; left time: 1037.7523s
	iters: 200, epoch: 10 | loss: 3.2585888
	speed: 0.0467s/iter; left time: 955.4353s
Epoch: 10 cost time: 11.030968189239502
Epoch: 10, Steps: 227 Train Loss: 3.2333 (Forecasting Loss:0.5959 + XiCon Loss:2.6374 x Lambda(1.0)), Vali MSE Loss: 1.1775 Test MSE Loss: 1.2770
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2057450
	speed: 0.0489s/iter; left time: 993.3329s
	iters: 200, epoch: 11 | loss: 3.2165980
	speed: 0.0463s/iter; left time: 937.2100s
Epoch: 11 cost time: 10.795587301254272
Epoch: 11, Steps: 227 Train Loss: 3.2270 (Forecasting Loss:0.5959 + XiCon Loss:2.6311 x Lambda(1.0)), Vali MSE Loss: 1.1768 Test MSE Loss: 1.2770
Validation loss decreased (1.177043 --> 1.176813).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1561518
	speed: 0.0490s/iter; left time: 985.1752s
	iters: 200, epoch: 12 | loss: 3.2727780
	speed: 0.0461s/iter; left time: 921.2961s
Epoch: 12 cost time: 10.784559726715088
Epoch: 12, Steps: 227 Train Loss: 3.2336 (Forecasting Loss:0.5958 + XiCon Loss:2.6378 x Lambda(1.0)), Vali MSE Loss: 1.1776 Test MSE Loss: 1.2769
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1513305
	speed: 0.0509s/iter; left time: 1012.4808s
	iters: 200, epoch: 13 | loss: 3.2252326
	speed: 0.0464s/iter; left time: 918.2273s
Epoch: 13 cost time: 11.016027927398682
Epoch: 13, Steps: 227 Train Loss: 3.2267 (Forecasting Loss:0.5957 + XiCon Loss:2.6309 x Lambda(1.0)), Vali MSE Loss: 1.1772 Test MSE Loss: 1.2769
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2224498
	speed: 0.0494s/iter; left time: 969.7382s
	iters: 200, epoch: 14 | loss: 3.1842375
	speed: 0.0456s/iter; left time: 890.8586s
Epoch: 14 cost time: 10.761842727661133
Epoch: 14, Steps: 227 Train Loss: 3.2276 (Forecasting Loss:0.5958 + XiCon Loss:2.6317 x Lambda(1.0)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2769
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2823644
	speed: 0.0490s/iter; left time: 951.1967s
	iters: 200, epoch: 15 | loss: 3.2074103
	speed: 0.0455s/iter; left time: 879.8116s
Epoch: 15 cost time: 10.723222732543945
Epoch: 15, Steps: 227 Train Loss: 3.2279 (Forecasting Loss:0.5958 + XiCon Loss:2.6321 x Lambda(1.0)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2769
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.1351676
	speed: 0.0488s/iter; left time: 937.3906s
	iters: 200, epoch: 16 | loss: 3.2038403
	speed: 0.0465s/iter; left time: 887.8289s
Epoch: 16 cost time: 10.830349683761597
Epoch: 16, Steps: 227 Train Loss: 3.2253 (Forecasting Loss:0.5958 + XiCon Loss:2.6295 x Lambda(1.0)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2769
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.1768856
	speed: 0.0493s/iter; left time: 934.5935s
	iters: 200, epoch: 17 | loss: 3.3172660
	speed: 0.0489s/iter; left time: 922.0951s
Epoch: 17 cost time: 11.148758888244629
Epoch: 17, Steps: 227 Train Loss: 3.2291 (Forecasting Loss:0.5957 + XiCon Loss:2.6334 x Lambda(1.0)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2769
Validation loss decreased (1.176813 --> 1.176559).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2817755
	speed: 0.0543s/iter; left time: 1018.0263s
	iters: 200, epoch: 18 | loss: 3.1945975
	speed: 0.0514s/iter; left time: 957.7456s
Epoch: 18 cost time: 11.924536943435669
Epoch: 18, Steps: 227 Train Loss: 3.2309 (Forecasting Loss:0.5959 + XiCon Loss:2.6350 x Lambda(1.0)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2769
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2400002
	speed: 0.0530s/iter; left time: 982.0318s
	iters: 200, epoch: 19 | loss: 3.1821170
	speed: 0.0504s/iter; left time: 928.0437s
Epoch: 19 cost time: 11.819719314575195
Epoch: 19, Steps: 227 Train Loss: 3.2253 (Forecasting Loss:0.5957 + XiCon Loss:2.6296 x Lambda(1.0)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2769
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2712409
	speed: 0.0515s/iter; left time: 941.8957s
	iters: 200, epoch: 20 | loss: 3.2435775
	speed: 0.0501s/iter; left time: 912.0153s
Epoch: 20 cost time: 11.562440872192383
Epoch: 20, Steps: 227 Train Loss: 3.2322 (Forecasting Loss:0.5959 + XiCon Loss:2.6364 x Lambda(1.0)), Vali MSE Loss: 1.1777 Test MSE Loss: 1.2769
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.1500278
	speed: 0.0516s/iter; left time: 932.5214s
	iters: 200, epoch: 21 | loss: 3.2235034
	speed: 0.0512s/iter; left time: 919.6076s
Epoch: 21 cost time: 11.740261793136597
Epoch: 21, Steps: 227 Train Loss: 3.2264 (Forecasting Loss:0.5957 + XiCon Loss:2.6306 x Lambda(1.0)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2769
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2668512
	speed: 0.0536s/iter; left time: 956.2135s
	iters: 200, epoch: 22 | loss: 3.2138391
	speed: 0.0510s/iter; left time: 903.6386s
Epoch: 22 cost time: 11.818565845489502
Epoch: 22, Steps: 227 Train Loss: 3.2304 (Forecasting Loss:0.5957 + XiCon Loss:2.6347 x Lambda(1.0)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2769
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2513704
	speed: 0.0525s/iter; left time: 924.8990s
	iters: 200, epoch: 23 | loss: 3.2068577
	speed: 0.0517s/iter; left time: 905.1887s
Epoch: 23 cost time: 11.8120858669281
Epoch: 23, Steps: 227 Train Loss: 3.2276 (Forecasting Loss:0.5956 + XiCon Loss:2.6320 x Lambda(1.0)), Vali MSE Loss: 1.1772 Test MSE Loss: 1.2769
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.1524589
	speed: 0.0541s/iter; left time: 940.8255s
	iters: 200, epoch: 24 | loss: 3.2432699
	speed: 0.0509s/iter; left time: 879.4721s
Epoch: 24 cost time: 11.903897047042847
Epoch: 24, Steps: 227 Train Loss: 3.2302 (Forecasting Loss:0.5957 + XiCon Loss:2.6345 x Lambda(1.0)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2769
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2910020
	speed: 0.0521s/iter; left time: 893.6163s
	iters: 200, epoch: 25 | loss: 3.1465807
	speed: 0.0505s/iter; left time: 860.8832s
Epoch: 25 cost time: 11.634428262710571
Epoch: 25, Steps: 227 Train Loss: 3.2292 (Forecasting Loss:0.5956 + XiCon Loss:2.6336 x Lambda(1.0)), Vali MSE Loss: 1.1772 Test MSE Loss: 1.2769
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2743196
	speed: 0.0518s/iter; left time: 876.5918s
	iters: 200, epoch: 26 | loss: 3.1429319
	speed: 0.0509s/iter; left time: 856.5646s
Epoch: 26 cost time: 11.679437637329102
Epoch: 26, Steps: 227 Train Loss: 3.2243 (Forecasting Loss:0.5958 + XiCon Loss:2.6285 x Lambda(1.0)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2769
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.2308953
	speed: 0.0521s/iter; left time: 869.6594s
	iters: 200, epoch: 27 | loss: 3.2107177
	speed: 0.0515s/iter; left time: 854.8684s
Epoch: 27 cost time: 11.760149717330933
Epoch: 27, Steps: 227 Train Loss: 3.2288 (Forecasting Loss:0.5957 + XiCon Loss:2.6331 x Lambda(1.0)), Vali MSE Loss: 1.1775 Test MSE Loss: 1.2769
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5967319011688232, mae:0.9570958018302917, mape:6.303819179534912, mspe:4936.87744140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.3737
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 3.7759814
	speed: 0.0500s/iter; left time: 1130.9354s
	iters: 200, epoch: 1 | loss: 3.6559651
	speed: 0.0469s/iter; left time: 1054.6868s
Epoch: 1 cost time: 10.963276863098145
Epoch: 1, Steps: 227 Train Loss: 3.7572 (Forecasting Loss:1.0351 + XiCon Loss:2.7222 x Lambda(1.0)), Vali MSE Loss: 1.9647 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964662).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.2990746
	speed: 0.0491s/iter; left time: 1099.3419s
	iters: 200, epoch: 2 | loss: 3.3282752
	speed: 0.0469s/iter; left time: 1043.7108s
Epoch: 2 cost time: 10.877896785736084
Epoch: 2, Steps: 227 Train Loss: 3.3784 (Forecasting Loss:0.6715 + XiCon Loss:2.7068 x Lambda(1.0)), Vali MSE Loss: 1.2183 Test MSE Loss: 1.2817
Validation loss decreased (1.964662 --> 1.218347).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2906475
	speed: 0.0495s/iter; left time: 1095.1764s
	iters: 200, epoch: 3 | loss: 3.2318385
	speed: 0.0469s/iter; left time: 1033.2555s
Epoch: 3 cost time: 10.939712285995483
Epoch: 3, Steps: 227 Train Loss: 3.2899 (Forecasting Loss:0.6086 + XiCon Loss:2.6812 x Lambda(1.0)), Vali MSE Loss: 1.1995 Test MSE Loss: 1.2742
Validation loss decreased (1.218347 --> 1.199513).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2331893
	speed: 0.0501s/iter; left time: 1099.1944s
	iters: 200, epoch: 4 | loss: 3.2603230
	speed: 0.0471s/iter; left time: 1028.3743s
Epoch: 4 cost time: 11.029658317565918
Epoch: 4, Steps: 227 Train Loss: 3.2707 (Forecasting Loss:0.6010 + XiCon Loss:2.6698 x Lambda(1.0)), Vali MSE Loss: 1.1923 Test MSE Loss: 1.2721
Validation loss decreased (1.199513 --> 1.192252).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2361984
	speed: 0.0508s/iter; left time: 1102.8307s
	iters: 200, epoch: 5 | loss: 3.2103240
	speed: 0.0483s/iter; left time: 1042.2551s
Epoch: 5 cost time: 11.337695837020874
Epoch: 5, Steps: 227 Train Loss: 3.2596 (Forecasting Loss:0.5980 + XiCon Loss:2.6616 x Lambda(1.0)), Vali MSE Loss: 1.1891 Test MSE Loss: 1.2712
Validation loss decreased (1.192252 --> 1.189083).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2634513
	speed: 0.0512s/iter; left time: 1098.0333s
	iters: 200, epoch: 6 | loss: 3.3047571
	speed: 0.0480s/iter; left time: 1025.8735s
Epoch: 6 cost time: 11.170166492462158
Epoch: 6, Steps: 227 Train Loss: 3.2551 (Forecasting Loss:0.5967 + XiCon Loss:2.6584 x Lambda(1.0)), Vali MSE Loss: 1.1878 Test MSE Loss: 1.2707
Validation loss decreased (1.189083 --> 1.187838).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2189407
	speed: 0.0500s/iter; left time: 1061.3336s
	iters: 200, epoch: 7 | loss: 3.3303208
	speed: 0.0480s/iter; left time: 1013.6533s
Epoch: 7 cost time: 11.099361419677734
Epoch: 7, Steps: 227 Train Loss: 3.2534 (Forecasting Loss:0.5962 + XiCon Loss:2.6573 x Lambda(1.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2706
Validation loss decreased (1.187838 --> 1.186809).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1953301
	speed: 0.0496s/iter; left time: 1042.6695s
	iters: 200, epoch: 8 | loss: 3.2340007
	speed: 0.0430s/iter; left time: 899.5075s
Epoch: 8 cost time: 10.494025230407715
Epoch: 8, Steps: 227 Train Loss: 3.2527 (Forecasting Loss:0.5958 + XiCon Loss:2.6569 x Lambda(1.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2705
Validation loss decreased (1.186809 --> 1.186677).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2116172
	speed: 0.0484s/iter; left time: 1006.0383s
	iters: 200, epoch: 9 | loss: 3.2707801
	speed: 0.0443s/iter; left time: 915.9423s
Epoch: 9 cost time: 10.493021726608276
Epoch: 9, Steps: 227 Train Loss: 3.2502 (Forecasting Loss:0.5955 + XiCon Loss:2.6546 x Lambda(1.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2721236
	speed: 0.0470s/iter; left time: 966.6411s
	iters: 200, epoch: 10 | loss: 3.2839828
	speed: 0.0463s/iter; left time: 946.7805s
Epoch: 10 cost time: 10.545056819915771
Epoch: 10, Steps: 227 Train Loss: 3.2522 (Forecasting Loss:0.5953 + XiCon Loss:2.6569 x Lambda(1.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2894409
	speed: 0.0479s/iter; left time: 974.6997s
	iters: 200, epoch: 11 | loss: 3.2350850
	speed: 0.0450s/iter; left time: 910.4803s
Epoch: 11 cost time: 10.54527497291565
Epoch: 11, Steps: 227 Train Loss: 3.2478 (Forecasting Loss:0.5952 + XiCon Loss:2.6526 x Lambda(1.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2576308
	speed: 0.0476s/iter; left time: 956.9878s
	iters: 200, epoch: 12 | loss: 3.2414374
	speed: 0.0442s/iter; left time: 884.9245s
Epoch: 12 cost time: 10.37104868888855
Epoch: 12, Steps: 227 Train Loss: 3.2485 (Forecasting Loss:0.5952 + XiCon Loss:2.6533 x Lambda(1.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2705
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2143023
	speed: 0.0518s/iter; left time: 1028.8175s
	iters: 200, epoch: 13 | loss: 3.2177830
	speed: 0.0481s/iter; left time: 950.8379s
Epoch: 13 cost time: 11.322724342346191
Epoch: 13, Steps: 227 Train Loss: 3.2497 (Forecasting Loss:0.5952 + XiCon Loss:2.6545 x Lambda(1.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2705
Validation loss decreased (1.186677 --> 1.186674).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2714224
	speed: 0.0509s/iter; left time: 999.7528s
	iters: 200, epoch: 14 | loss: 3.2304955
	speed: 0.0466s/iter; left time: 910.4437s
Epoch: 14 cost time: 11.009268045425415
Epoch: 14, Steps: 227 Train Loss: 3.2519 (Forecasting Loss:0.5952 + XiCon Loss:2.6567 x Lambda(1.0)), Vali MSE Loss: 1.1859 Test MSE Loss: 1.2705
Validation loss decreased (1.186674 --> 1.185884).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2506051
	speed: 0.0537s/iter; left time: 1043.7925s
	iters: 200, epoch: 15 | loss: 3.2740815
	speed: 0.0468s/iter; left time: 903.8481s
Epoch: 15 cost time: 11.355412244796753
Epoch: 15, Steps: 227 Train Loss: 3.2508 (Forecasting Loss:0.5953 + XiCon Loss:2.6555 x Lambda(1.0)), Vali MSE Loss: 1.1864 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2580514
	speed: 0.0515s/iter; left time: 988.6964s
	iters: 200, epoch: 16 | loss: 3.2326236
	speed: 0.0485s/iter; left time: 926.7960s
Epoch: 16 cost time: 11.30653715133667
Epoch: 16, Steps: 227 Train Loss: 3.2520 (Forecasting Loss:0.5952 + XiCon Loss:2.6568 x Lambda(1.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.1872134
	speed: 0.0533s/iter; left time: 1011.5783s
	iters: 200, epoch: 17 | loss: 3.2779078
	speed: 0.0477s/iter; left time: 900.8515s
Epoch: 17 cost time: 11.391141176223755
Epoch: 17, Steps: 227 Train Loss: 3.2497 (Forecasting Loss:0.5952 + XiCon Loss:2.6545 x Lambda(1.0)), Vali MSE Loss: 1.1867 Test MSE Loss: 1.2705
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2395420
	speed: 0.0495s/iter; left time: 927.1706s
	iters: 200, epoch: 18 | loss: 3.2123425
	speed: 0.0492s/iter; left time: 916.8528s
Epoch: 18 cost time: 11.20296597480774
Epoch: 18, Steps: 227 Train Loss: 3.2493 (Forecasting Loss:0.5952 + XiCon Loss:2.6542 x Lambda(1.0)), Vali MSE Loss: 1.1866 Test MSE Loss: 1.2705
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1669014
	speed: 0.0504s/iter; left time: 932.8352s
	iters: 200, epoch: 19 | loss: 3.2225287
	speed: 0.0475s/iter; left time: 874.3646s
Epoch: 19 cost time: 11.140840291976929
Epoch: 19, Steps: 227 Train Loss: 3.2515 (Forecasting Loss:0.5950 + XiCon Loss:2.6565 x Lambda(1.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2705
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2027943
	speed: 0.0504s/iter; left time: 921.5070s
	iters: 200, epoch: 20 | loss: 3.2630799
	speed: 0.0472s/iter; left time: 858.4310s
Epoch: 20 cost time: 11.046036958694458
Epoch: 20, Steps: 227 Train Loss: 3.2522 (Forecasting Loss:0.5951 + XiCon Loss:2.6571 x Lambda(1.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2705
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.1809416
	speed: 0.0508s/iter; left time: 917.2463s
	iters: 200, epoch: 21 | loss: 3.3381171
	speed: 0.0474s/iter; left time: 850.5076s
Epoch: 21 cost time: 11.2005774974823
Epoch: 21, Steps: 227 Train Loss: 3.2502 (Forecasting Loss:0.5952 + XiCon Loss:2.6551 x Lambda(1.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2006764
	speed: 0.0524s/iter; left time: 934.6402s
	iters: 200, epoch: 22 | loss: 3.2172451
	speed: 0.0472s/iter; left time: 836.8505s
Epoch: 22 cost time: 11.414541721343994
Epoch: 22, Steps: 227 Train Loss: 3.2493 (Forecasting Loss:0.5953 + XiCon Loss:2.6539 x Lambda(1.0)), Vali MSE Loss: 1.1865 Test MSE Loss: 1.2705
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2296522
	speed: 0.0518s/iter; left time: 911.4009s
	iters: 200, epoch: 23 | loss: 3.3172579
	speed: 0.0489s/iter; left time: 855.5363s
Epoch: 23 cost time: 11.450042486190796
Epoch: 23, Steps: 227 Train Loss: 3.2510 (Forecasting Loss:0.5953 + XiCon Loss:2.6557 x Lambda(1.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2705
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2300081
	speed: 0.0500s/iter; left time: 869.6284s
	iters: 200, epoch: 24 | loss: 3.2863111
	speed: 0.0478s/iter; left time: 825.6730s
Epoch: 24 cost time: 11.105479955673218
Epoch: 24, Steps: 227 Train Loss: 3.2511 (Forecasting Loss:0.5953 + XiCon Loss:2.6558 x Lambda(1.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2705
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5879802703857422, mae:0.9529595375061035, mape:6.184459686279297, mspe:4715.4951171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5890+-0.00580, MAE:0.9538+-0.00264, MAPE:6.2165+-0.08775, MSPE:4767.3506+-165.08745, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
