Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3843
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.4034495
	speed: 0.0243s/iter; left time: 309.1162s
Epoch: 1 cost time: 3.059871196746826
Epoch: 1, Steps: 128 Train Loss: 3.4262 (Forecasting Loss:0.2444 + XiCon Loss:3.1818 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173707).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1942441
	speed: 0.0253s/iter; left time: 318.5262s
Epoch: 2 cost time: 3.1436996459960938
Epoch: 2, Steps: 128 Train Loss: 3.1962 (Forecasting Loss:0.2460 + XiCon Loss:2.9502 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1331
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 2.9483094
	speed: 0.0234s/iter; left time: 290.8950s
Epoch: 3 cost time: 2.948638439178467
Epoch: 3, Steps: 128 Train Loss: 3.0796 (Forecasting Loss:0.2298 + XiCon Loss:2.8498 x Lambda(1.0)), Vali MSE Loss: 0.1817 Test MSE Loss: 0.1272
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2583160
	speed: 0.0235s/iter; left time: 289.4285s
Epoch: 4 cost time: 3.071155309677124
Epoch: 4, Steps: 128 Train Loss: 3.1585 (Forecasting Loss:0.2150 + XiCon Loss:2.9435 x Lambda(1.0)), Vali MSE Loss: 0.1807 Test MSE Loss: 0.1232
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0737231
	speed: 0.0233s/iter; left time: 284.3533s
Epoch: 5 cost time: 2.976701498031616
Epoch: 5, Steps: 128 Train Loss: 3.1250 (Forecasting Loss:0.2074 + XiCon Loss:2.9177 x Lambda(1.0)), Vali MSE Loss: 0.1907 Test MSE Loss: 0.1267
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0574827
	speed: 0.0250s/iter; left time: 301.1945s
Epoch: 6 cost time: 3.148066759109497
Epoch: 6, Steps: 128 Train Loss: 3.1107 (Forecasting Loss:0.2043 + XiCon Loss:2.9064 x Lambda(1.0)), Vali MSE Loss: 0.1812 Test MSE Loss: 0.1203
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0198793
	speed: 0.0223s/iter; left time: 266.5591s
Epoch: 7 cost time: 2.783902406692505
Epoch: 7, Steps: 128 Train Loss: 3.1054 (Forecasting Loss:0.2021 + XiCon Loss:2.9033 x Lambda(1.0)), Vali MSE Loss: 0.1780 Test MSE Loss: 0.1227
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0599761
	speed: 0.0243s/iter; left time: 286.7138s
Epoch: 8 cost time: 3.0801618099212646
Epoch: 8, Steps: 128 Train Loss: 3.0988 (Forecasting Loss:0.2016 + XiCon Loss:2.8972 x Lambda(1.0)), Vali MSE Loss: 0.1831 Test MSE Loss: 0.1237
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1585321
	speed: 0.0251s/iter; left time: 293.2058s
Epoch: 9 cost time: 3.045515537261963
Epoch: 9, Steps: 128 Train Loss: 3.0938 (Forecasting Loss:0.2013 + XiCon Loss:2.8925 x Lambda(1.0)), Vali MSE Loss: 0.1815 Test MSE Loss: 0.1224
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1129625
	speed: 0.0244s/iter; left time: 281.9733s
Epoch: 10 cost time: 3.1119327545166016
Epoch: 10, Steps: 128 Train Loss: 3.0948 (Forecasting Loss:0.2011 + XiCon Loss:2.8936 x Lambda(1.0)), Vali MSE Loss: 0.1812 Test MSE Loss: 0.1231
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1363294
	speed: 0.0237s/iter; left time: 271.1117s
Epoch: 11 cost time: 2.9157509803771973
Epoch: 11, Steps: 128 Train Loss: 3.0874 (Forecasting Loss:0.2009 + XiCon Loss:2.8866 x Lambda(1.0)), Vali MSE Loss: 0.1805 Test MSE Loss: 0.1232
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05883800610899925, mae:0.1869674175977707, mape:0.1485580950975418, mspe:0.04107961431145668 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3948
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3464203
	speed: 0.0223s/iter; left time: 283.7311s
Epoch: 1 cost time: 2.784813642501831
Epoch: 1, Steps: 128 Train Loss: 3.4097 (Forecasting Loss:0.2439 + XiCon Loss:3.1657 x Lambda(1.0)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.1219
Validation loss decreased (inf --> 0.172285).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2013283
	speed: 0.0227s/iter; left time: 285.3218s
Epoch: 2 cost time: 2.745556592941284
Epoch: 2, Steps: 128 Train Loss: 3.2832 (Forecasting Loss:0.2475 + XiCon Loss:3.0357 x Lambda(1.0)), Vali MSE Loss: 0.1794 Test MSE Loss: 0.1223
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1356525
	speed: 0.0231s/iter; left time: 286.9040s
Epoch: 3 cost time: 2.9332573413848877
Epoch: 3, Steps: 128 Train Loss: 3.1605 (Forecasting Loss:0.2272 + XiCon Loss:2.9333 x Lambda(1.0)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1197
Validation loss decreased (0.172285 --> 0.171636).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2603464
	speed: 0.0267s/iter; left time: 329.2561s
Epoch: 4 cost time: 3.2877767086029053
Epoch: 4, Steps: 128 Train Loss: 3.1092 (Forecasting Loss:0.2189 + XiCon Loss:2.8902 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1147
Validation loss decreased (0.171636 --> 0.163219).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0883636
	speed: 0.0250s/iter; left time: 304.7952s
Epoch: 5 cost time: 3.145806074142456
Epoch: 5, Steps: 128 Train Loss: 3.0687 (Forecasting Loss:0.2134 + XiCon Loss:2.8553 x Lambda(1.0)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1151
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1747336
	speed: 0.0236s/iter; left time: 284.1009s
Epoch: 6 cost time: 2.9686670303344727
Epoch: 6, Steps: 128 Train Loss: 3.1890 (Forecasting Loss:0.2115 + XiCon Loss:2.9775 x Lambda(1.0)), Vali MSE Loss: 0.1627 Test MSE Loss: 0.1178
Validation loss decreased (0.163219 --> 0.162744).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1539004
	speed: 0.0251s/iter; left time: 299.8903s
Epoch: 7 cost time: 3.0567634105682373
Epoch: 7, Steps: 128 Train Loss: 3.1628 (Forecasting Loss:0.2090 + XiCon Loss:2.9538 x Lambda(1.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1154
Validation loss decreased (0.162744 --> 0.162186).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1236339
	speed: 0.0224s/iter; left time: 264.7310s
Epoch: 8 cost time: 2.708630084991455
Epoch: 8, Steps: 128 Train Loss: 3.1662 (Forecasting Loss:0.2080 + XiCon Loss:2.9582 x Lambda(1.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1642370
	speed: 0.0257s/iter; left time: 300.3933s
Epoch: 9 cost time: 3.297316074371338
Epoch: 9, Steps: 128 Train Loss: 3.1638 (Forecasting Loss:0.2072 + XiCon Loss:2.9566 x Lambda(1.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1159
Validation loss decreased (0.162186 --> 0.162126).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1698282
	speed: 0.0263s/iter; left time: 303.9177s
Epoch: 10 cost time: 3.2568893432617188
Epoch: 10, Steps: 128 Train Loss: 3.1639 (Forecasting Loss:0.2072 + XiCon Loss:2.9567 x Lambda(1.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1127007
	speed: 0.0282s/iter; left time: 321.9443s
Epoch: 11 cost time: 3.4300131797790527
Epoch: 11, Steps: 128 Train Loss: 3.1543 (Forecasting Loss:0.2068 + XiCon Loss:2.9475 x Lambda(1.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1781471
	speed: 0.0246s/iter; left time: 277.7137s
Epoch: 12 cost time: 3.1030092239379883
Epoch: 12, Steps: 128 Train Loss: 3.1592 (Forecasting Loss:0.2067 + XiCon Loss:2.9525 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1158
Validation loss decreased (0.162126 --> 0.161994).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1506705
	speed: 0.0241s/iter; left time: 268.6600s
Epoch: 13 cost time: 3.018548011779785
Epoch: 13, Steps: 128 Train Loss: 3.1596 (Forecasting Loss:0.2065 + XiCon Loss:2.9532 x Lambda(1.0)), Vali MSE Loss: 0.1624 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1997311
	speed: 0.0215s/iter; left time: 237.5939s
Epoch: 14 cost time: 2.692683219909668
Epoch: 14, Steps: 128 Train Loss: 3.1650 (Forecasting Loss:0.2065 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1156981
	speed: 0.0177s/iter; left time: 192.8957s
Epoch: 15 cost time: 2.092449903488159
Epoch: 15, Steps: 128 Train Loss: 3.1585 (Forecasting Loss:0.2065 + XiCon Loss:2.9520 x Lambda(1.0)), Vali MSE Loss: 0.1625 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2750709
	speed: 0.0535s/iter; left time: 577.0737s
Epoch: 16 cost time: 6.618982791900635
Epoch: 16, Steps: 128 Train Loss: 3.1665 (Forecasting Loss:0.2067 + XiCon Loss:2.9598 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1158
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1092696
	speed: 0.0208s/iter; left time: 221.9460s
Epoch: 17 cost time: 2.5017170906066895
Epoch: 17, Steps: 128 Train Loss: 3.1599 (Forecasting Loss:0.2065 + XiCon Loss:2.9534 x Lambda(1.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1158
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1339216
	speed: 0.0146s/iter; left time: 153.6345s
Epoch: 18 cost time: 1.812964677810669
Epoch: 18, Steps: 128 Train Loss: 3.1671 (Forecasting Loss:0.2067 + XiCon Loss:2.9604 x Lambda(1.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1158
Validation loss decreased (0.161994 --> 0.161932).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1797595
	speed: 0.0134s/iter; left time: 139.5444s
Epoch: 19 cost time: 1.6681175231933594
Epoch: 19, Steps: 128 Train Loss: 3.1586 (Forecasting Loss:0.2067 + XiCon Loss:2.9519 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1111369
	speed: 0.0245s/iter; left time: 251.7614s
Epoch: 20 cost time: 3.077988862991333
Epoch: 20, Steps: 128 Train Loss: 3.1643 (Forecasting Loss:0.2068 + XiCon Loss:2.9576 x Lambda(1.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.2548087
	speed: 0.0251s/iter; left time: 254.5980s
Epoch: 21 cost time: 3.1582882404327393
Epoch: 21, Steps: 128 Train Loss: 3.1547 (Forecasting Loss:0.2065 + XiCon Loss:2.9482 x Lambda(1.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1666670
	speed: 0.0251s/iter; left time: 251.6785s
Epoch: 22 cost time: 3.1065893173217773
Epoch: 22, Steps: 128 Train Loss: 3.1687 (Forecasting Loss:0.2067 + XiCon Loss:2.9620 x Lambda(1.0)), Vali MSE Loss: 0.1624 Test MSE Loss: 0.1158
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1859112
	speed: 0.0263s/iter; left time: 259.5227s
Epoch: 23 cost time: 3.382155656814575
Epoch: 23, Steps: 128 Train Loss: 3.1650 (Forecasting Loss:0.2065 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1158
Validation loss decreased (0.161932 --> 0.161771).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.3018689
	speed: 0.0262s/iter; left time: 255.7636s
Epoch: 24 cost time: 3.154433488845825
Epoch: 24, Steps: 128 Train Loss: 3.1631 (Forecasting Loss:0.2064 + XiCon Loss:2.9567 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1205096
	speed: 0.0228s/iter; left time: 219.2020s
Epoch: 25 cost time: 2.7564916610717773
Epoch: 25, Steps: 128 Train Loss: 3.1668 (Forecasting Loss:0.2068 + XiCon Loss:2.9599 x Lambda(1.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.1655478
	speed: 0.0254s/iter; left time: 241.3052s
Epoch: 26 cost time: 3.1397252082824707
Epoch: 26, Steps: 128 Train Loss: 3.1557 (Forecasting Loss:0.2065 + XiCon Loss:2.9492 x Lambda(1.0)), Vali MSE Loss: 0.1624 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1134763
	speed: 0.0263s/iter; left time: 246.3763s
Epoch: 27 cost time: 3.2554640769958496
Epoch: 27, Steps: 128 Train Loss: 3.1597 (Forecasting Loss:0.2065 + XiCon Loss:2.9532 x Lambda(1.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1158
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.2800641
	speed: 0.0251s/iter; left time: 232.0664s
Epoch: 28 cost time: 3.1551337242126465
Epoch: 28, Steps: 128 Train Loss: 3.1691 (Forecasting Loss:0.2067 + XiCon Loss:2.9624 x Lambda(1.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1158
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.2050633
	speed: 0.0256s/iter; left time: 233.7809s
Epoch: 29 cost time: 3.263610363006592
Epoch: 29, Steps: 128 Train Loss: 3.1666 (Forecasting Loss:0.2066 + XiCon Loss:2.9600 x Lambda(1.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1158
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.2325072
	speed: 0.0223s/iter; left time: 200.8976s
Epoch: 30 cost time: 2.8438780307769775
Epoch: 30, Steps: 128 Train Loss: 3.1664 (Forecasting Loss:0.2066 + XiCon Loss:2.9597 x Lambda(1.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1158
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1702812
	speed: 0.0213s/iter; left time: 188.3579s
Epoch: 31 cost time: 2.600505828857422
Epoch: 31, Steps: 128 Train Loss: 3.1583 (Forecasting Loss:0.2067 + XiCon Loss:2.9516 x Lambda(1.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1158
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.1223874
	speed: 0.0254s/iter; left time: 221.9701s
Epoch: 32 cost time: 3.32564640045166
Epoch: 32, Steps: 128 Train Loss: 3.1586 (Forecasting Loss:0.2063 + XiCon Loss:2.9523 x Lambda(1.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1158
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.1385043
	speed: 0.0254s/iter; left time: 218.5318s
Epoch: 33 cost time: 3.1672773361206055
Epoch: 33, Steps: 128 Train Loss: 3.1670 (Forecasting Loss:0.2066 + XiCon Loss:2.9604 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1158
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05397907644510269, mae:0.17754550278186798, mape:0.1429557353258133, mspe:0.04003865644335747 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4288
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3925912
	speed: 0.0267s/iter; left time: 339.3588s
Epoch: 1 cost time: 3.4267454147338867
Epoch: 1, Steps: 128 Train Loss: 3.4140 (Forecasting Loss:0.2455 + XiCon Loss:3.1685 x Lambda(1.0)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1235
Validation loss decreased (inf --> 0.173081).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1934061
	speed: 0.0257s/iter; left time: 323.2501s
Epoch: 2 cost time: 3.1743738651275635
Epoch: 2, Steps: 128 Train Loss: 3.2356 (Forecasting Loss:0.2419 + XiCon Loss:2.9937 x Lambda(1.0)), Vali MSE Loss: 0.1768 Test MSE Loss: 0.1298
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1872821
	speed: 0.0216s/iter; left time: 268.1921s
Epoch: 3 cost time: 2.6592652797698975
Epoch: 3, Steps: 128 Train Loss: 3.1904 (Forecasting Loss:0.2298 + XiCon Loss:2.9605 x Lambda(1.0)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1170
Validation loss decreased (0.173081 --> 0.171561).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2408259
	speed: 0.0280s/iter; left time: 345.0458s
Epoch: 4 cost time: 3.500493049621582
Epoch: 4, Steps: 128 Train Loss: 3.1889 (Forecasting Loss:0.2231 + XiCon Loss:2.9658 x Lambda(1.0)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1189
Validation loss decreased (0.171561 --> 0.168319).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1740429
	speed: 0.0280s/iter; left time: 341.3973s
Epoch: 5 cost time: 3.4233944416046143
Epoch: 5, Steps: 128 Train Loss: 3.2722 (Forecasting Loss:0.2175 + XiCon Loss:3.0546 x Lambda(1.0)), Vali MSE Loss: 0.1651 Test MSE Loss: 0.1194
Validation loss decreased (0.168319 --> 0.165112).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.3204267
	speed: 0.0277s/iter; left time: 333.9269s
Epoch: 6 cost time: 3.483478546142578
Epoch: 6, Steps: 128 Train Loss: 3.2403 (Forecasting Loss:0.2161 + XiCon Loss:3.0242 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1165
Validation loss decreased (0.165112 --> 0.163700).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1866970
	speed: 0.0249s/iter; left time: 297.5897s
Epoch: 7 cost time: 3.1442668437957764
Epoch: 7, Steps: 128 Train Loss: 3.2279 (Forecasting Loss:0.2145 + XiCon Loss:3.0134 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1969769
	speed: 0.0230s/iter; left time: 271.6792s
Epoch: 8 cost time: 2.90665864944458
Epoch: 8, Steps: 128 Train Loss: 3.2140 (Forecasting Loss:0.2142 + XiCon Loss:2.9998 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1529026
	speed: 0.0213s/iter; left time: 248.6615s
Epoch: 9 cost time: 2.7820444107055664
Epoch: 9, Steps: 128 Train Loss: 3.2087 (Forecasting Loss:0.2135 + XiCon Loss:2.9952 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1168
Validation loss decreased (0.163700 --> 0.163670).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2164128
	speed: 0.0249s/iter; left time: 287.1704s
Epoch: 10 cost time: 3.1179378032684326
Epoch: 10, Steps: 128 Train Loss: 3.2048 (Forecasting Loss:0.2135 + XiCon Loss:2.9913 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1169
Validation loss decreased (0.163670 --> 0.163627).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1305692
	speed: 0.0251s/iter; left time: 287.0726s
Epoch: 11 cost time: 3.101818561553955
Epoch: 11, Steps: 128 Train Loss: 3.2059 (Forecasting Loss:0.2135 + XiCon Loss:2.9924 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1170
Validation loss decreased (0.163627 --> 0.163523).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.3042436
	speed: 0.0278s/iter; left time: 314.3441s
Epoch: 12 cost time: 3.4745447635650635
Epoch: 12, Steps: 128 Train Loss: 3.2073 (Forecasting Loss:0.2132 + XiCon Loss:2.9941 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1488318
	speed: 0.0250s/iter; left time: 278.9639s
Epoch: 13 cost time: 3.106090784072876
Epoch: 13, Steps: 128 Train Loss: 3.1997 (Forecasting Loss:0.2134 + XiCon Loss:2.9864 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1169
Validation loss decreased (0.163523 --> 0.163401).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1528363
	speed: 0.0216s/iter; left time: 238.4788s
Epoch: 14 cost time: 2.7764670848846436
Epoch: 14, Steps: 128 Train Loss: 3.2120 (Forecasting Loss:0.2134 + XiCon Loss:2.9986 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1576715
	speed: 0.0263s/iter; left time: 286.7134s
Epoch: 15 cost time: 3.2408089637756348
Epoch: 15, Steps: 128 Train Loss: 3.1969 (Forecasting Loss:0.2132 + XiCon Loss:2.9837 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1170
Validation loss decreased (0.163401 --> 0.163240).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2318962
	speed: 0.0295s/iter; left time: 318.5055s
Epoch: 16 cost time: 3.590318202972412
Epoch: 16, Steps: 128 Train Loss: 3.2116 (Forecasting Loss:0.2132 + XiCon Loss:2.9984 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.3668461
	speed: 0.0260s/iter; left time: 276.6044s
Epoch: 17 cost time: 3.26214337348938
Epoch: 17, Steps: 128 Train Loss: 3.2099 (Forecasting Loss:0.2133 + XiCon Loss:2.9966 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1169
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.3911295
	speed: 0.0293s/iter; left time: 308.3359s
Epoch: 18 cost time: 3.626415729522705
Epoch: 18, Steps: 128 Train Loss: 3.2110 (Forecasting Loss:0.2133 + XiCon Loss:2.9978 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1169
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2494287
	speed: 0.0230s/iter; left time: 238.7621s
Epoch: 19 cost time: 2.809159517288208
Epoch: 19, Steps: 128 Train Loss: 3.2073 (Forecasting Loss:0.2131 + XiCon Loss:2.9941 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1169
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1137536
	speed: 0.0211s/iter; left time: 216.3926s
Epoch: 20 cost time: 2.608640670776367
Epoch: 20, Steps: 128 Train Loss: 3.1992 (Forecasting Loss:0.2133 + XiCon Loss:2.9859 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1169
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1054788
	speed: 0.0269s/iter; left time: 273.2262s
Epoch: 21 cost time: 3.2657597064971924
Epoch: 21, Steps: 128 Train Loss: 3.2043 (Forecasting Loss:0.2134 + XiCon Loss:2.9909 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1169
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.2073860
	speed: 0.0253s/iter; left time: 253.2027s
Epoch: 22 cost time: 3.203843116760254
Epoch: 22, Steps: 128 Train Loss: 3.2130 (Forecasting Loss:0.2134 + XiCon Loss:2.9996 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1169
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1787026
	speed: 0.0247s/iter; left time: 244.2933s
Epoch: 23 cost time: 3.1482064723968506
Epoch: 23, Steps: 128 Train Loss: 3.2061 (Forecasting Loss:0.2134 + XiCon Loss:2.9928 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1169
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1789432
	speed: 0.0253s/iter; left time: 247.0047s
Epoch: 24 cost time: 3.1604981422424316
Epoch: 24, Steps: 128 Train Loss: 3.2063 (Forecasting Loss:0.2133 + XiCon Loss:2.9930 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1169
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1519732
	speed: 0.0234s/iter; left time: 225.5806s
Epoch: 25 cost time: 2.8999991416931152
Epoch: 25, Steps: 128 Train Loss: 3.2112 (Forecasting Loss:0.2133 + XiCon Loss:2.9979 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1169
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05504787340760231, mae:0.1788521707057953, mape:0.14196601510047913, mspe:0.03765198960900307 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4627
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3982415
	speed: 0.0275s/iter; left time: 349.8547s
Epoch: 1 cost time: 3.4891090393066406
Epoch: 1, Steps: 128 Train Loss: 3.4154 (Forecasting Loss:0.2453 + XiCon Loss:3.1700 x Lambda(1.0)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1223
Validation loss decreased (inf --> 0.172663).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.4147716
	speed: 0.0265s/iter; left time: 333.2181s
Epoch: 2 cost time: 3.266806125640869
Epoch: 2, Steps: 128 Train Loss: 3.3147 (Forecasting Loss:0.2501 + XiCon Loss:3.0646 x Lambda(1.0)), Vali MSE Loss: 0.1795 Test MSE Loss: 0.1306
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2753057
	speed: 0.0251s/iter; left time: 312.7314s
Epoch: 3 cost time: 3.22645902633667
Epoch: 3, Steps: 128 Train Loss: 3.2236 (Forecasting Loss:0.2300 + XiCon Loss:2.9936 x Lambda(1.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1231
Validation loss decreased (0.172663 --> 0.169652).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1441600
	speed: 0.0268s/iter; left time: 330.0040s
Epoch: 4 cost time: 3.402087926864624
Epoch: 4, Steps: 128 Train Loss: 3.1638 (Forecasting Loss:0.2216 + XiCon Loss:2.9422 x Lambda(1.0)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1184223
	speed: 0.0223s/iter; left time: 272.3708s
Epoch: 5 cost time: 2.6701955795288086
Epoch: 5, Steps: 128 Train Loss: 3.1498 (Forecasting Loss:0.2177 + XiCon Loss:2.9320 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1147
Validation loss decreased (0.169652 --> 0.165575).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1306643
	speed: 0.0225s/iter; left time: 271.2771s
Epoch: 6 cost time: 2.927802085876465
Epoch: 6, Steps: 128 Train Loss: 3.1479 (Forecasting Loss:0.2155 + XiCon Loss:2.9324 x Lambda(1.0)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1162
Validation loss decreased (0.165575 --> 0.164923).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0923223
	speed: 0.0267s/iter; left time: 318.9129s
Epoch: 7 cost time: 3.285329580307007
Epoch: 7, Steps: 128 Train Loss: 3.1503 (Forecasting Loss:0.2143 + XiCon Loss:2.9359 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1156
Validation loss decreased (0.164923 --> 0.163829).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1014481
	speed: 0.0294s/iter; left time: 347.0547s
Epoch: 8 cost time: 3.5498557090759277
Epoch: 8, Steps: 128 Train Loss: 3.1458 (Forecasting Loss:0.2137 + XiCon Loss:2.9322 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0859635
	speed: 0.0271s/iter; left time: 315.8968s
Epoch: 9 cost time: 3.343238353729248
Epoch: 9, Steps: 128 Train Loss: 3.1423 (Forecasting Loss:0.2134 + XiCon Loss:2.9289 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1158
Validation loss decreased (0.163829 --> 0.163624).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0942941
	speed: 0.0247s/iter; left time: 285.8276s
Epoch: 10 cost time: 3.140444755554199
Epoch: 10, Steps: 128 Train Loss: 3.1429 (Forecasting Loss:0.2133 + XiCon Loss:2.9297 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
Validation loss decreased (0.163624 --> 0.163492).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1096129
	speed: 0.0231s/iter; left time: 263.5526s
Epoch: 11 cost time: 2.7961373329162598
Epoch: 11, Steps: 128 Train Loss: 3.1370 (Forecasting Loss:0.2132 + XiCon Loss:2.9238 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1531830
	speed: 0.0243s/iter; left time: 274.6289s
Epoch: 12 cost time: 3.0995588302612305
Epoch: 12, Steps: 128 Train Loss: 3.1386 (Forecasting Loss:0.2129 + XiCon Loss:2.9257 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1430538
	speed: 0.0258s/iter; left time: 287.5412s
Epoch: 13 cost time: 3.3085384368896484
Epoch: 13, Steps: 128 Train Loss: 3.1408 (Forecasting Loss:0.2130 + XiCon Loss:2.9278 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0982816
	speed: 0.0260s/iter; left time: 287.3680s
Epoch: 14 cost time: 3.2414753437042236
Epoch: 14, Steps: 128 Train Loss: 3.1461 (Forecasting Loss:0.2131 + XiCon Loss:2.9330 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0682490
	speed: 0.0290s/iter; left time: 315.8451s
Epoch: 15 cost time: 3.5233852863311768
Epoch: 15, Steps: 128 Train Loss: 3.1428 (Forecasting Loss:0.2131 + XiCon Loss:2.9297 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1407111
	speed: 0.0241s/iter; left time: 259.8541s
Epoch: 16 cost time: 2.938925266265869
Epoch: 16, Steps: 128 Train Loss: 3.1473 (Forecasting Loss:0.2131 + XiCon Loss:2.9342 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
Validation loss decreased (0.163492 --> 0.163469).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1625080
	speed: 0.0228s/iter; left time: 242.6312s
Epoch: 17 cost time: 2.9031107425689697
Epoch: 17, Steps: 128 Train Loss: 3.1404 (Forecasting Loss:0.2129 + XiCon Loss:2.9275 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.2726116
	speed: 0.0286s/iter; left time: 301.2917s
Epoch: 18 cost time: 3.601372003555298
Epoch: 18, Steps: 128 Train Loss: 3.1403 (Forecasting Loss:0.2130 + XiCon Loss:2.9273 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1017156
	speed: 0.0251s/iter; left time: 260.4692s
Epoch: 19 cost time: 3.2150189876556396
Epoch: 19, Steps: 128 Train Loss: 3.1365 (Forecasting Loss:0.2130 + XiCon Loss:2.9234 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0959322
	speed: 0.0279s/iter; left time: 286.7772s
Epoch: 20 cost time: 3.656712770462036
Epoch: 20, Steps: 128 Train Loss: 3.1398 (Forecasting Loss:0.2131 + XiCon Loss:2.9267 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1157
Validation loss decreased (0.163469 --> 0.163435).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0695956
	speed: 0.0313s/iter; left time: 317.7194s
Epoch: 21 cost time: 3.6867494583129883
Epoch: 21, Steps: 128 Train Loss: 3.1378 (Forecasting Loss:0.2130 + XiCon Loss:2.9248 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0882270
	speed: 0.0191s/iter; left time: 191.6261s
Epoch: 22 cost time: 2.3981828689575195
Epoch: 22, Steps: 128 Train Loss: 3.1432 (Forecasting Loss:0.2130 + XiCon Loss:2.9302 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.3171480
	speed: 0.0248s/iter; left time: 245.0855s
Epoch: 23 cost time: 3.1331822872161865
Epoch: 23, Steps: 128 Train Loss: 3.1407 (Forecasting Loss:0.2130 + XiCon Loss:2.9276 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0840468
	speed: 0.0268s/iter; left time: 261.3772s
Epoch: 24 cost time: 3.36568021774292
Epoch: 24, Steps: 128 Train Loss: 3.1445 (Forecasting Loss:0.2130 + XiCon Loss:2.9316 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0764267
	speed: 0.0267s/iter; left time: 257.0636s
Epoch: 25 cost time: 3.3661041259765625
Epoch: 25, Steps: 128 Train Loss: 3.1465 (Forecasting Loss:0.2131 + XiCon Loss:2.9334 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0615451
	speed: 0.0251s/iter; left time: 238.3853s
Epoch: 26 cost time: 3.1539804935455322
Epoch: 26, Steps: 128 Train Loss: 3.1426 (Forecasting Loss:0.2131 + XiCon Loss:2.9295 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1046360
	speed: 0.0252s/iter; left time: 236.5645s
Epoch: 27 cost time: 2.9712460041046143
Epoch: 27, Steps: 128 Train Loss: 3.1495 (Forecasting Loss:0.2131 + XiCon Loss:2.9364 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0846198
	speed: 0.0211s/iter; left time: 195.4636s
Epoch: 28 cost time: 2.774993896484375
Epoch: 28, Steps: 128 Train Loss: 3.1427 (Forecasting Loss:0.2129 + XiCon Loss:2.9298 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1157
Validation loss decreased (0.163435 --> 0.163209).  Saving model ...
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0849712
	speed: 0.0286s/iter; left time: 260.6722s
Epoch: 29 cost time: 3.550976514816284
Epoch: 29, Steps: 128 Train Loss: 3.1389 (Forecasting Loss:0.2130 + XiCon Loss:2.9259 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1507168
	speed: 0.0256s/iter; left time: 229.9129s
Epoch: 30 cost time: 3.3114309310913086
Epoch: 30, Steps: 128 Train Loss: 3.1404 (Forecasting Loss:0.2131 + XiCon Loss:2.9273 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0814836
	speed: 0.0253s/iter; left time: 224.0026s
Epoch: 31 cost time: 3.1605186462402344
Epoch: 31, Steps: 128 Train Loss: 3.1417 (Forecasting Loss:0.2130 + XiCon Loss:2.9287 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.1083641
	speed: 0.0251s/iter; left time: 218.9250s
Epoch: 32 cost time: 3.3091914653778076
Epoch: 32, Steps: 128 Train Loss: 3.1380 (Forecasting Loss:0.2130 + XiCon Loss:2.9250 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.1557336
	speed: 0.0228s/iter; left time: 196.2497s
Epoch: 33 cost time: 2.8600704669952393
Epoch: 33, Steps: 128 Train Loss: 3.1451 (Forecasting Loss:0.2127 + XiCon Loss:2.9324 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.1620693
	speed: 0.0211s/iter; left time: 178.7110s
Epoch: 34 cost time: 2.7916674613952637
Epoch: 34, Steps: 128 Train Loss: 3.1409 (Forecasting Loss:0.2131 + XiCon Loss:2.9278 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.0949659
	speed: 0.0260s/iter; left time: 217.0247s
Epoch: 35 cost time: 3.3869638442993164
Epoch: 35, Steps: 128 Train Loss: 3.1467 (Forecasting Loss:0.2130 + XiCon Loss:2.9337 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.1921737
	speed: 0.0270s/iter; left time: 222.0487s
Epoch: 36 cost time: 3.260981798171997
Epoch: 36, Steps: 128 Train Loss: 3.1395 (Forecasting Loss:0.2131 + XiCon Loss:2.9264 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.2138758
	speed: 0.0254s/iter; left time: 205.6530s
Epoch: 37 cost time: 3.180640697479248
Epoch: 37, Steps: 128 Train Loss: 3.1357 (Forecasting Loss:0.2129 + XiCon Loss:2.9228 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.1324916
	speed: 0.0257s/iter; left time: 204.5303s
Epoch: 38 cost time: 3.296085834503174
Epoch: 38, Steps: 128 Train Loss: 3.1380 (Forecasting Loss:0.2130 + XiCon Loss:2.9250 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05418793857097626, mae:0.1773080676794052, mape:0.14088523387908936, mspe:0.03714945167303085 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6571
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.4160013
	speed: 0.0236s/iter; left time: 299.1539s
Epoch: 1 cost time: 3.005418062210083
Epoch: 1, Steps: 128 Train Loss: 3.4174 (Forecasting Loss:0.2453 + XiCon Loss:3.1722 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1240
Validation loss decreased (inf --> 0.175442).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2252960
	speed: 0.0260s/iter; left time: 327.0257s
Epoch: 2 cost time: 3.3197309970855713
Epoch: 2, Steps: 128 Train Loss: 3.2527 (Forecasting Loss:0.2501 + XiCon Loss:3.0026 x Lambda(1.0)), Vali MSE Loss: 0.1760 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.4587920
	speed: 0.0245s/iter; left time: 305.0112s
Epoch: 3 cost time: 3.0840375423431396
Epoch: 3, Steps: 128 Train Loss: 3.3337 (Forecasting Loss:0.2293 + XiCon Loss:3.1044 x Lambda(1.0)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1205
Validation loss decreased (0.175442 --> 0.168032).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2778616
	speed: 0.0241s/iter; left time: 296.7051s
Epoch: 4 cost time: 3.056215763092041
Epoch: 4, Steps: 128 Train Loss: 3.3500 (Forecasting Loss:0.2214 + XiCon Loss:3.1285 x Lambda(1.0)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1177
Validation loss decreased (0.168032 --> 0.167818).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.4191029
	speed: 0.0270s/iter; left time: 329.6554s
Epoch: 5 cost time: 3.523463726043701
Epoch: 5, Steps: 128 Train Loss: 3.3174 (Forecasting Loss:0.2178 + XiCon Loss:3.0997 x Lambda(1.0)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1189
Validation loss decreased (0.167818 --> 0.165800).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.3805468
	speed: 0.0215s/iter; left time: 259.7962s
Epoch: 6 cost time: 2.5840795040130615
Epoch: 6, Steps: 128 Train Loss: 3.2890 (Forecasting Loss:0.2155 + XiCon Loss:3.0735 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
Validation loss decreased (0.165800 --> 0.163786).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2887931
	speed: 0.0278s/iter; left time: 331.3530s
Epoch: 7 cost time: 3.3977458477020264
Epoch: 7, Steps: 128 Train Loss: 3.2854 (Forecasting Loss:0.2144 + XiCon Loss:3.0710 x Lambda(1.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.3114643
	speed: 0.0286s/iter; left time: 337.4591s
Epoch: 8 cost time: 3.489394426345825
Epoch: 8, Steps: 128 Train Loss: 3.2921 (Forecasting Loss:0.2138 + XiCon Loss:3.0783 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1162
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.3649449
	speed: 0.0256s/iter; left time: 298.9384s
Epoch: 9 cost time: 3.2562096118927
Epoch: 9, Steps: 128 Train Loss: 3.2765 (Forecasting Loss:0.2136 + XiCon Loss:3.0628 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2038486
	speed: 0.0262s/iter; left time: 302.9870s
Epoch: 10 cost time: 3.3098363876342773
Epoch: 10, Steps: 128 Train Loss: 3.2784 (Forecasting Loss:0.2135 + XiCon Loss:3.0649 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1160
Validation loss decreased (0.163786 --> 0.163709).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2371676
	speed: 0.0251s/iter; left time: 287.1469s
Epoch: 11 cost time: 2.937739610671997
Epoch: 11, Steps: 128 Train Loss: 3.2815 (Forecasting Loss:0.2135 + XiCon Loss:3.0680 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2906363
	speed: 0.0221s/iter; left time: 249.8268s
Epoch: 12 cost time: 2.7707138061523438
Epoch: 12, Steps: 128 Train Loss: 3.2806 (Forecasting Loss:0.2132 + XiCon Loss:3.0674 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.2550139
	speed: 0.0272s/iter; left time: 303.1397s
Epoch: 13 cost time: 3.416830539703369
Epoch: 13, Steps: 128 Train Loss: 3.2771 (Forecasting Loss:0.2133 + XiCon Loss:3.0638 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.2670565
	speed: 0.0261s/iter; left time: 288.1361s
Epoch: 14 cost time: 3.303901433944702
Epoch: 14, Steps: 128 Train Loss: 3.2844 (Forecasting Loss:0.2132 + XiCon Loss:3.0712 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
Validation loss decreased (0.163709 --> 0.163589).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.2814300
	speed: 0.0270s/iter; left time: 294.1906s
Epoch: 15 cost time: 3.372421979904175
Epoch: 15, Steps: 128 Train Loss: 3.2844 (Forecasting Loss:0.2133 + XiCon Loss:3.0711 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.3105295
	speed: 0.0258s/iter; left time: 278.1770s
Epoch: 16 cost time: 3.258331537246704
Epoch: 16, Steps: 128 Train Loss: 3.2858 (Forecasting Loss:0.2133 + XiCon Loss:3.0726 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1159
Validation loss decreased (0.163589 --> 0.163478).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.3035102
	speed: 0.0231s/iter; left time: 246.0237s
Epoch: 17 cost time: 2.906270742416382
Epoch: 17, Steps: 128 Train Loss: 3.2820 (Forecasting Loss:0.2132 + XiCon Loss:3.0688 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.2870872
	speed: 0.0218s/iter; left time: 228.9329s
Epoch: 18 cost time: 2.8118677139282227
Epoch: 18, Steps: 128 Train Loss: 3.2849 (Forecasting Loss:0.2133 + XiCon Loss:3.0715 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2453828
	speed: 0.0289s/iter; left time: 300.5638s
Epoch: 19 cost time: 3.487053632736206
Epoch: 19, Steps: 128 Train Loss: 3.2782 (Forecasting Loss:0.2132 + XiCon Loss:3.0650 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.3498321
	speed: 0.0258s/iter; left time: 265.3374s
Epoch: 20 cost time: 3.2124571800231934
Epoch: 20, Steps: 128 Train Loss: 3.2766 (Forecasting Loss:0.2133 + XiCon Loss:3.0633 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.3134830
	speed: 0.0251s/iter; left time: 254.2329s
Epoch: 21 cost time: 3.2561421394348145
Epoch: 21, Steps: 128 Train Loss: 3.2787 (Forecasting Loss:0.2133 + XiCon Loss:3.0654 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.2711380
	speed: 0.0246s/iter; left time: 246.2201s
Epoch: 22 cost time: 3.14667010307312
Epoch: 22, Steps: 128 Train Loss: 3.2858 (Forecasting Loss:0.2133 + XiCon Loss:3.0724 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2547362
	speed: 0.0215s/iter; left time: 212.8810s
Epoch: 23 cost time: 2.6701149940490723
Epoch: 23, Steps: 128 Train Loss: 3.2834 (Forecasting Loss:0.2134 + XiCon Loss:3.0701 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1915865
	speed: 0.0247s/iter; left time: 240.7219s
Epoch: 24 cost time: 3.193821907043457
Epoch: 24, Steps: 128 Train Loss: 3.2796 (Forecasting Loss:0.2132 + XiCon Loss:3.0664 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1159
Validation loss decreased (0.163478 --> 0.163361).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.2324114
	speed: 0.0298s/iter; left time: 286.8422s
Epoch: 25 cost time: 3.679433822631836
Epoch: 25, Steps: 128 Train Loss: 3.2764 (Forecasting Loss:0.2133 + XiCon Loss:3.0631 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2614198
	speed: 0.0276s/iter; left time: 262.4248s
Epoch: 26 cost time: 3.3991360664367676
Epoch: 26, Steps: 128 Train Loss: 3.2853 (Forecasting Loss:0.2133 + XiCon Loss:3.0720 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.2725630
	speed: 0.0259s/iter; left time: 242.8410s
Epoch: 27 cost time: 3.312739849090576
Epoch: 27, Steps: 128 Train Loss: 3.2860 (Forecasting Loss:0.2133 + XiCon Loss:3.0727 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.3205929
	speed: 0.0243s/iter; left time: 225.0252s
Epoch: 28 cost time: 2.9043562412261963
Epoch: 28, Steps: 128 Train Loss: 3.2816 (Forecasting Loss:0.2132 + XiCon Loss:3.0684 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.2268105
	speed: 0.0209s/iter; left time: 190.8809s
Epoch: 29 cost time: 2.77127742767334
Epoch: 29, Steps: 128 Train Loss: 3.2770 (Forecasting Loss:0.2134 + XiCon Loss:3.0637 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.3133178
	speed: 0.0242s/iter; left time: 217.3903s
Epoch: 30 cost time: 3.0975935459136963
Epoch: 30, Steps: 128 Train Loss: 3.2788 (Forecasting Loss:0.2132 + XiCon Loss:3.0656 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.3415167
	speed: 0.0256s/iter; left time: 226.6948s
Epoch: 31 cost time: 3.1858835220336914
Epoch: 31, Steps: 128 Train Loss: 3.2833 (Forecasting Loss:0.2133 + XiCon Loss:3.0700 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.2414913
	speed: 0.0251s/iter; left time: 219.4580s
Epoch: 32 cost time: 3.154934883117676
Epoch: 32, Steps: 128 Train Loss: 3.2762 (Forecasting Loss:0.2132 + XiCon Loss:3.0630 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2196817
	speed: 0.0274s/iter; left time: 235.9552s
Epoch: 33 cost time: 3.4562160968780518
Epoch: 33, Steps: 128 Train Loss: 3.2801 (Forecasting Loss:0.2133 + XiCon Loss:3.0668 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1159
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.3978975
	speed: 0.0220s/iter; left time: 186.8316s
Epoch: 34 cost time: 2.6810450553894043
Epoch: 34, Steps: 128 Train Loss: 3.2781 (Forecasting Loss:0.2132 + XiCon Loss:3.0649 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05426670238375664, mae:0.17757412791252136, mape:0.1411300152540207, mspe:0.03728211671113968 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0553+-0.00253, MAE:0.1796+-0.00513, MAPE:0.1431+-0.00392, MSPE:0.0386+-0.00223, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3435
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 32.1225739
	speed: 0.0445s/iter; left time: 520.1742s
Epoch: 1 cost time: 5.166375160217285
Epoch: 1, Steps: 118 Train Loss: 32.4712 (Forecasting Loss:0.3698 + XiCon Loss:3.2101 x Lambda(10.0)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.1790
Validation loss decreased (inf --> 0.273545).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.5355892
	speed: 0.0488s/iter; left time: 564.6804s
Epoch: 2 cost time: 5.7434563636779785
Epoch: 2, Steps: 118 Train Loss: 30.6332 (Forecasting Loss:0.3290 + XiCon Loss:3.0304 x Lambda(10.0)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1593
Validation loss decreased (0.273545 --> 0.240794).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2539845
	speed: 0.0476s/iter; left time: 546.1381s
Epoch: 3 cost time: 5.45135235786438
Epoch: 3, Steps: 118 Train Loss: 30.9758 (Forecasting Loss:0.2937 + XiCon Loss:3.0682 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1564
Validation loss decreased (0.240794 --> 0.232397).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2472286
	speed: 0.0355s/iter; left time: 402.7031s
Epoch: 4 cost time: 4.587053060531616
Epoch: 4, Steps: 118 Train Loss: 30.3207 (Forecasting Loss:0.2844 + XiCon Loss:3.0036 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1477
Validation loss decreased (0.232397 --> 0.232307).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6432247
	speed: 0.0567s/iter; left time: 636.2865s
Epoch: 5 cost time: 6.1507439613342285
Epoch: 5, Steps: 118 Train Loss: 30.0611 (Forecasting Loss:0.2688 + XiCon Loss:2.9792 x Lambda(10.0)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.1499
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6017056
	speed: 0.0259s/iter; left time: 287.4357s
Epoch: 6 cost time: 3.0357165336608887
Epoch: 6, Steps: 118 Train Loss: 29.9361 (Forecasting Loss:0.2647 + XiCon Loss:2.9671 x Lambda(10.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.1451
Validation loss decreased (0.232307 --> 0.230017).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.5981979
	speed: 0.0291s/iter; left time: 319.5500s
Epoch: 7 cost time: 3.785364866256714
Epoch: 7, Steps: 118 Train Loss: 29.9068 (Forecasting Loss:0.2621 + XiCon Loss:2.9645 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.7450886
	speed: 0.0518s/iter; left time: 563.5312s
Epoch: 8 cost time: 6.076840400695801
Epoch: 8, Steps: 118 Train Loss: 29.8874 (Forecasting Loss:0.2617 + XiCon Loss:2.9626 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1441
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.7496834
	speed: 0.0521s/iter; left time: 560.5751s
Epoch: 9 cost time: 6.127710819244385
Epoch: 9, Steps: 118 Train Loss: 29.8868 (Forecasting Loss:0.2610 + XiCon Loss:2.9626 x Lambda(10.0)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1448
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5262070
	speed: 0.0514s/iter; left time: 546.9497s
Epoch: 10 cost time: 6.157941818237305
Epoch: 10, Steps: 118 Train Loss: 29.9463 (Forecasting Loss:0.2603 + XiCon Loss:2.9686 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1439
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.3692627
	speed: 0.0441s/iter; left time: 464.0545s
Epoch: 11 cost time: 5.320136785507202
Epoch: 11, Steps: 118 Train Loss: 29.9215 (Forecasting Loss:0.2611 + XiCon Loss:2.9660 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1436
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3076553
	speed: 0.0495s/iter; left time: 515.1085s
Epoch: 12 cost time: 5.836855411529541
Epoch: 12, Steps: 118 Train Loss: 29.9506 (Forecasting Loss:0.2614 + XiCon Loss:2.9689 x Lambda(10.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1438
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7805977
	speed: 0.0504s/iter; left time: 517.9665s
Epoch: 13 cost time: 6.002942323684692
Epoch: 13, Steps: 118 Train Loss: 29.9410 (Forecasting Loss:0.2606 + XiCon Loss:2.9680 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1437
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1971493
	speed: 0.0495s/iter; left time: 503.2885s
Epoch: 14 cost time: 5.914271116256714
Epoch: 14, Steps: 118 Train Loss: 29.9468 (Forecasting Loss:0.2604 + XiCon Loss:2.9686 x Lambda(10.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1437
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5907364
	speed: 0.0448s/iter; left time: 450.1249s
Epoch: 15 cost time: 5.484454870223999
Epoch: 15, Steps: 118 Train Loss: 29.9483 (Forecasting Loss:0.2606 + XiCon Loss:2.9688 x Lambda(10.0)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1436
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.9886246
	speed: 0.0498s/iter; left time: 494.4256s
Epoch: 16 cost time: 6.021986961364746
Epoch: 16, Steps: 118 Train Loss: 29.9041 (Forecasting Loss:0.2604 + XiCon Loss:2.9644 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1436
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07471900433301926, mae:0.2155766785144806, mape:0.1582442671060562, mspe:0.04096273332834244 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3696
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 32.1879692
	speed: 0.0428s/iter; left time: 500.9146s
Epoch: 1 cost time: 5.137805938720703
Epoch: 1, Steps: 118 Train Loss: 32.4910 (Forecasting Loss:0.3526 + XiCon Loss:3.2138 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1625
Validation loss decreased (inf --> 0.252712).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.7993641
	speed: 0.0441s/iter; left time: 510.9365s
Epoch: 2 cost time: 5.219762563705444
Epoch: 2, Steps: 118 Train Loss: 30.3143 (Forecasting Loss:0.3311 + XiCon Loss:2.9983 x Lambda(10.0)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.1560
Validation loss decreased (0.252712 --> 0.246596).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1457710
	speed: 0.0428s/iter; left time: 491.1334s
Epoch: 3 cost time: 5.153817892074585
Epoch: 3, Steps: 118 Train Loss: 30.6579 (Forecasting Loss:0.2912 + XiCon Loss:3.0367 x Lambda(10.0)), Vali MSE Loss: 0.2379 Test MSE Loss: 0.1527
Validation loss decreased (0.246596 --> 0.237931).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.0982647
	speed: 0.0502s/iter; left time: 570.0926s
Epoch: 4 cost time: 5.920764923095703
Epoch: 4, Steps: 118 Train Loss: 30.4796 (Forecasting Loss:0.2730 + XiCon Loss:3.0207 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.1473
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.8089905
	speed: 0.0501s/iter; left time: 562.0798s
Epoch: 5 cost time: 5.981555461883545
Epoch: 5, Steps: 118 Train Loss: 30.2863 (Forecasting Loss:0.2660 + XiCon Loss:3.0020 x Lambda(10.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1485
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.2422485
	speed: 0.0497s/iter; left time: 551.8889s
Epoch: 6 cost time: 5.894070386886597
Epoch: 6, Steps: 118 Train Loss: 30.1462 (Forecasting Loss:0.2600 + XiCon Loss:2.9886 x Lambda(10.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1479
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8452148
	speed: 0.0438s/iter; left time: 481.0970s
Epoch: 7 cost time: 5.278363943099976
Epoch: 7, Steps: 118 Train Loss: 30.1057 (Forecasting Loss:0.2587 + XiCon Loss:2.9847 x Lambda(10.0)), Vali MSE Loss: 0.2419 Test MSE Loss: 0.1481
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0100975
	speed: 0.0475s/iter; left time: 516.2095s
Epoch: 8 cost time: 5.637607574462891
Epoch: 8, Steps: 118 Train Loss: 30.1168 (Forecasting Loss:0.2582 + XiCon Loss:2.9859 x Lambda(10.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1472
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.6377258
	speed: 0.0489s/iter; left time: 526.2927s
Epoch: 9 cost time: 5.703953504562378
Epoch: 9, Steps: 118 Train Loss: 30.0310 (Forecasting Loss:0.2575 + XiCon Loss:2.9774 x Lambda(10.0)), Vali MSE Loss: 0.2429 Test MSE Loss: 0.1472
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9502563
	speed: 0.0526s/iter; left time: 559.7494s
Epoch: 10 cost time: 6.186404228210449
Epoch: 10, Steps: 118 Train Loss: 30.0192 (Forecasting Loss:0.2572 + XiCon Loss:2.9762 x Lambda(10.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1471
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1815205
	speed: 0.0432s/iter; left time: 454.3424s
Epoch: 11 cost time: 5.09014892578125
Epoch: 11, Steps: 118 Train Loss: 30.0489 (Forecasting Loss:0.2563 + XiCon Loss:2.9793 x Lambda(10.0)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1471
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9215794
	speed: 0.0501s/iter; left time: 521.6656s
Epoch: 12 cost time: 5.932682037353516
Epoch: 12, Steps: 118 Train Loss: 30.0648 (Forecasting Loss:0.2571 + XiCon Loss:2.9808 x Lambda(10.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1473
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6355495
	speed: 0.0504s/iter; left time: 518.8382s
Epoch: 13 cost time: 5.959827661514282
Epoch: 13, Steps: 118 Train Loss: 30.0927 (Forecasting Loss:0.2569 + XiCon Loss:2.9836 x Lambda(10.0)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.1473
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08116842806339264, mae:0.22423873841762543, mape:0.16211242973804474, mspe:0.04176631197333336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3552
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 32.0809746
	speed: 0.0449s/iter; left time: 525.2271s
Epoch: 1 cost time: 5.1278440952301025
Epoch: 1, Steps: 118 Train Loss: 32.2690 (Forecasting Loss:0.3613 + XiCon Loss:3.1908 x Lambda(10.0)), Vali MSE Loss: 0.2566 Test MSE Loss: 0.1663
Validation loss decreased (inf --> 0.256603).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1074333
	speed: 0.0499s/iter; left time: 577.5509s
Epoch: 2 cost time: 5.921467542648315
Epoch: 2, Steps: 118 Train Loss: 30.8606 (Forecasting Loss:0.3420 + XiCon Loss:3.0519 x Lambda(10.0)), Vali MSE Loss: 0.2793 Test MSE Loss: 0.1686
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6329842
	speed: 0.0517s/iter; left time: 593.1785s
Epoch: 3 cost time: 6.052878379821777
Epoch: 3, Steps: 118 Train Loss: 30.7827 (Forecasting Loss:0.3059 + XiCon Loss:3.0477 x Lambda(10.0)), Vali MSE Loss: 0.2403 Test MSE Loss: 0.1612
Validation loss decreased (0.256603 --> 0.240348).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6057892
	speed: 0.0516s/iter; left time: 585.7419s
Epoch: 4 cost time: 6.041730165481567
Epoch: 4, Steps: 118 Train Loss: 30.2895 (Forecasting Loss:0.2867 + XiCon Loss:3.0003 x Lambda(10.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 0.1546
Validation loss decreased (0.240348 --> 0.235124).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1750889
	speed: 0.0508s/iter; left time: 570.4125s
Epoch: 5 cost time: 6.078968048095703
Epoch: 5, Steps: 118 Train Loss: 29.9885 (Forecasting Loss:0.2797 + XiCon Loss:2.9709 x Lambda(10.0)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.1525
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6675301
	speed: 0.0484s/iter; left time: 538.3136s
Epoch: 6 cost time: 5.766394853591919
Epoch: 6, Steps: 118 Train Loss: 29.8469 (Forecasting Loss:0.2787 + XiCon Loss:2.9568 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.1517
Validation loss decreased (0.235124 --> 0.233040).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.7922440
	speed: 0.0572s/iter; left time: 628.9858s
Epoch: 7 cost time: 6.6751015186309814
Epoch: 7, Steps: 118 Train Loss: 29.8150 (Forecasting Loss:0.2765 + XiCon Loss:2.9538 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1523
Validation loss decreased (0.233040 --> 0.232434).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3819542
	speed: 0.0535s/iter; left time: 582.0266s
Epoch: 8 cost time: 6.373836278915405
Epoch: 8, Steps: 118 Train Loss: 29.8446 (Forecasting Loss:0.2748 + XiCon Loss:2.9570 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1525
Validation loss decreased (0.232434 --> 0.232095).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.2339039
	speed: 0.0532s/iter; left time: 572.6017s
Epoch: 9 cost time: 6.326063394546509
Epoch: 9, Steps: 118 Train Loss: 29.7283 (Forecasting Loss:0.2745 + XiCon Loss:2.9454 x Lambda(10.0)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.1530
Validation loss decreased (0.232095 --> 0.231933).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.3365231
	speed: 0.0501s/iter; left time: 532.9123s
Epoch: 10 cost time: 5.899837970733643
Epoch: 10, Steps: 118 Train Loss: 29.7554 (Forecasting Loss:0.2748 + XiCon Loss:2.9481 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1527
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.4471073
	speed: 0.0529s/iter; left time: 556.0704s
Epoch: 11 cost time: 6.178764581680298
Epoch: 11, Steps: 118 Train Loss: 29.7735 (Forecasting Loss:0.2745 + XiCon Loss:2.9499 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3536968
	speed: 0.0521s/iter; left time: 542.3887s
Epoch: 12 cost time: 6.249539136886597
Epoch: 12, Steps: 118 Train Loss: 29.7287 (Forecasting Loss:0.2744 + XiCon Loss:2.9454 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.5291348
	speed: 0.0498s/iter; left time: 512.1289s
Epoch: 13 cost time: 5.777181625366211
Epoch: 13, Steps: 118 Train Loss: 29.7682 (Forecasting Loss:0.2756 + XiCon Loss:2.9493 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1528
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4146214
	speed: 0.0494s/iter; left time: 502.5690s
Epoch: 14 cost time: 5.935940265655518
Epoch: 14, Steps: 118 Train Loss: 29.7189 (Forecasting Loss:0.2739 + XiCon Loss:2.9445 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.9671707
	speed: 0.0527s/iter; left time: 529.5216s
Epoch: 15 cost time: 6.178160190582275
Epoch: 15, Steps: 118 Train Loss: 29.7338 (Forecasting Loss:0.2741 + XiCon Loss:2.9460 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6317120
	speed: 0.0514s/iter; left time: 509.9695s
Epoch: 16 cost time: 5.972420692443848
Epoch: 16, Steps: 118 Train Loss: 29.7538 (Forecasting Loss:0.2742 + XiCon Loss:2.9480 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1528
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.1427135
	speed: 0.0492s/iter; left time: 482.8682s
Epoch: 17 cost time: 5.822720050811768
Epoch: 17, Steps: 118 Train Loss: 29.7927 (Forecasting Loss:0.2747 + XiCon Loss:2.9518 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1528
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6714001
	speed: 0.0524s/iter; left time: 508.4076s
Epoch: 18 cost time: 6.168704509735107
Epoch: 18, Steps: 118 Train Loss: 29.8003 (Forecasting Loss:0.2734 + XiCon Loss:2.9527 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.0752239
	speed: 0.0529s/iter; left time: 507.0792s
Epoch: 19 cost time: 6.229954719543457
Epoch: 19, Steps: 118 Train Loss: 29.7508 (Forecasting Loss:0.2743 + XiCon Loss:2.9476 x Lambda(10.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.1528
Validation loss decreased (0.231933 --> 0.231797).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.2135105
	speed: 0.0536s/iter; left time: 506.8216s
Epoch: 20 cost time: 6.364356517791748
Epoch: 20, Steps: 118 Train Loss: 29.7315 (Forecasting Loss:0.2738 + XiCon Loss:2.9458 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.5999012
	speed: 0.0489s/iter; left time: 456.7125s
Epoch: 21 cost time: 5.745063781738281
Epoch: 21, Steps: 118 Train Loss: 29.7667 (Forecasting Loss:0.2738 + XiCon Loss:2.9493 x Lambda(10.0)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.1528
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.7011261
	speed: 0.0525s/iter; left time: 483.9294s
Epoch: 22 cost time: 6.23773193359375
Epoch: 22, Steps: 118 Train Loss: 29.7913 (Forecasting Loss:0.2737 + XiCon Loss:2.9518 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1528
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.4980068
	speed: 0.0549s/iter; left time: 500.0035s
Epoch: 23 cost time: 6.611663579940796
Epoch: 23, Steps: 118 Train Loss: 29.8200 (Forecasting Loss:0.2748 + XiCon Loss:2.9545 x Lambda(10.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.1528
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.4625530
	speed: 0.0524s/iter; left time: 471.1581s
Epoch: 24 cost time: 6.19360613822937
Epoch: 24, Steps: 118 Train Loss: 29.8173 (Forecasting Loss:0.2743 + XiCon Loss:2.9543 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1528
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.7967644
	speed: 0.0487s/iter; left time: 431.5699s
Epoch: 25 cost time: 5.891517162322998
Epoch: 25, Steps: 118 Train Loss: 29.7516 (Forecasting Loss:0.2734 + XiCon Loss:2.9478 x Lambda(10.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.1528
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.9880772
	speed: 0.0544s/iter; left time: 475.7756s
Epoch: 26 cost time: 6.45336127281189
Epoch: 26, Steps: 118 Train Loss: 29.8051 (Forecasting Loss:0.2736 + XiCon Loss:2.9532 x Lambda(10.0)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.1528
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.3483715
	speed: 0.0528s/iter; left time: 456.1897s
Epoch: 27 cost time: 6.348225355148315
Epoch: 27, Steps: 118 Train Loss: 29.7615 (Forecasting Loss:0.2752 + XiCon Loss:2.9486 x Lambda(10.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.1528
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.4928970
	speed: 0.0542s/iter; left time: 461.7695s
Epoch: 28 cost time: 6.461930990219116
Epoch: 28, Steps: 118 Train Loss: 29.7908 (Forecasting Loss:0.2740 + XiCon Loss:2.9517 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 29.4767933
	speed: 0.0478s/iter; left time: 401.3600s
Epoch: 29 cost time: 5.502326488494873
Epoch: 29, Steps: 118 Train Loss: 29.8125 (Forecasting Loss:0.2734 + XiCon Loss:2.9539 x Lambda(10.0)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1528
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0809335932135582, mae:0.22467133402824402, mape:0.16334035992622375, mspe:0.042611900717020035 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4289
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.9599323
	speed: 0.0430s/iter; left time: 503.1622s
Epoch: 1 cost time: 5.074723720550537
Epoch: 1, Steps: 118 Train Loss: 32.2247 (Forecasting Loss:0.3533 + XiCon Loss:3.1871 x Lambda(10.0)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.1646
Validation loss decreased (inf --> 0.253920).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.3814049
	speed: 0.0495s/iter; left time: 573.0694s
Epoch: 2 cost time: 5.989065885543823
Epoch: 2, Steps: 118 Train Loss: 30.4037 (Forecasting Loss:0.3427 + XiCon Loss:3.0061 x Lambda(10.0)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1662
Validation loss decreased (0.253920 --> 0.246300).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.9114494
	speed: 0.0538s/iter; left time: 616.9069s
Epoch: 3 cost time: 6.248477220535278
Epoch: 3, Steps: 118 Train Loss: 30.9896 (Forecasting Loss:0.2907 + XiCon Loss:3.0699 x Lambda(10.0)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.1638
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.3293839
	speed: 0.0473s/iter; left time: 536.7900s
Epoch: 4 cost time: 5.63941502571106
Epoch: 4, Steps: 118 Train Loss: 31.3266 (Forecasting Loss:0.2671 + XiCon Loss:3.1060 x Lambda(10.0)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1655
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7420559
	speed: 0.0523s/iter; left time: 587.0983s
Epoch: 5 cost time: 6.192500829696655
Epoch: 5, Steps: 118 Train Loss: 31.1520 (Forecasting Loss:0.2584 + XiCon Loss:3.0894 x Lambda(10.0)), Vali MSE Loss: 0.2707 Test MSE Loss: 0.1595
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.8502235
	speed: 0.0531s/iter; left time: 589.5896s
Epoch: 6 cost time: 6.350017309188843
Epoch: 6, Steps: 118 Train Loss: 31.0145 (Forecasting Loss:0.2552 + XiCon Loss:3.0759 x Lambda(10.0)), Vali MSE Loss: 0.2701 Test MSE Loss: 0.1602
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9011860
	speed: 0.0501s/iter; left time: 550.5048s
Epoch: 7 cost time: 5.693329811096191
Epoch: 7, Steps: 118 Train Loss: 30.9682 (Forecasting Loss:0.2531 + XiCon Loss:3.0715 x Lambda(10.0)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.1592
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1339340
	speed: 0.0464s/iter; left time: 504.6738s
Epoch: 8 cost time: 5.5381386280059814
Epoch: 8, Steps: 118 Train Loss: 30.8854 (Forecasting Loss:0.2522 + XiCon Loss:3.0633 x Lambda(10.0)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1604
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.2127514
	speed: 0.0519s/iter; left time: 558.0512s
Epoch: 9 cost time: 6.08446741104126
Epoch: 9, Steps: 118 Train Loss: 30.8745 (Forecasting Loss:0.2525 + XiCon Loss:3.0622 x Lambda(10.0)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.1595
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5873299
	speed: 0.0539s/iter; left time: 573.1556s
Epoch: 10 cost time: 6.256230115890503
Epoch: 10, Steps: 118 Train Loss: 30.8952 (Forecasting Loss:0.2520 + XiCon Loss:3.0643 x Lambda(10.0)), Vali MSE Loss: 0.2636 Test MSE Loss: 0.1590
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4985542
	speed: 0.0523s/iter; left time: 549.8936s
Epoch: 11 cost time: 5.958502292633057
Epoch: 11, Steps: 118 Train Loss: 30.8488 (Forecasting Loss:0.2515 + XiCon Loss:3.0597 x Lambda(10.0)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.1590
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3742237
	speed: 0.0479s/iter; left time: 498.5707s
Epoch: 12 cost time: 5.766762971878052
Epoch: 12, Steps: 118 Train Loss: 30.8330 (Forecasting Loss:0.2517 + XiCon Loss:3.0581 x Lambda(10.0)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.1590
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09220913052558899, mae:0.24027639627456665, mape:0.17528285086154938, mspe:0.04892943054437637 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3495
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 32.0727196
	speed: 0.0435s/iter; left time: 508.6614s
Epoch: 1 cost time: 5.0875630378723145
Epoch: 1, Steps: 118 Train Loss: 32.3626 (Forecasting Loss:0.3556 + XiCon Loss:3.2007 x Lambda(10.0)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.1657
Validation loss decreased (inf --> 0.254934).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.1480312
	speed: 0.0531s/iter; left time: 615.0081s
Epoch: 2 cost time: 6.280272722244263
Epoch: 2, Steps: 118 Train Loss: 30.5549 (Forecasting Loss:0.3451 + XiCon Loss:3.0210 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1676
Validation loss decreased (0.254934 --> 0.250697).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.8273106
	speed: 0.0517s/iter; left time: 593.2483s
Epoch: 3 cost time: 5.940187692642212
Epoch: 3, Steps: 118 Train Loss: 29.9714 (Forecasting Loss:0.3339 + XiCon Loss:2.9637 x Lambda(10.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.1656
Validation loss decreased (0.250697 --> 0.247813).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.6956043
	speed: 0.0559s/iter; left time: 634.5389s
Epoch: 4 cost time: 6.6129584312438965
Epoch: 4, Steps: 118 Train Loss: 29.6339 (Forecasting Loss:0.3279 + XiCon Loss:2.9306 x Lambda(10.0)), Vali MSE Loss: 0.2445 Test MSE Loss: 0.1611
Validation loss decreased (0.247813 --> 0.244485).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.6967449
	speed: 0.0575s/iter; left time: 645.1994s
Epoch: 5 cost time: 6.694612264633179
Epoch: 5, Steps: 118 Train Loss: 29.4437 (Forecasting Loss:0.3267 + XiCon Loss:2.9117 x Lambda(10.0)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1638
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3072414
	speed: 0.0594s/iter; left time: 659.9266s
Epoch: 6 cost time: 7.074148893356323
Epoch: 6, Steps: 118 Train Loss: 29.4184 (Forecasting Loss:0.3246 + XiCon Loss:2.9094 x Lambda(10.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1632
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.4544182
	speed: 0.0533s/iter; left time: 585.7173s
Epoch: 7 cost time: 6.36659574508667
Epoch: 7, Steps: 118 Train Loss: 29.4039 (Forecasting Loss:0.3236 + XiCon Loss:2.9080 x Lambda(10.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1628
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.5541992
	speed: 0.0567s/iter; left time: 616.7324s
Epoch: 8 cost time: 6.679898023605347
Epoch: 8, Steps: 118 Train Loss: 29.4452 (Forecasting Loss:0.3234 + XiCon Loss:2.9122 x Lambda(10.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1629
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4112034
	speed: 0.0565s/iter; left time: 607.5992s
Epoch: 9 cost time: 6.581884145736694
Epoch: 9, Steps: 118 Train Loss: 29.4350 (Forecasting Loss:0.3230 + XiCon Loss:2.9112 x Lambda(10.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1632
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.2743301
	speed: 0.0582s/iter; left time: 618.7292s
Epoch: 10 cost time: 6.641170024871826
Epoch: 10, Steps: 118 Train Loss: 29.4488 (Forecasting Loss:0.3231 + XiCon Loss:2.9126 x Lambda(10.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1632
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.1888485
	speed: 0.0540s/iter; left time: 567.6687s
Epoch: 11 cost time: 6.334259986877441
Epoch: 11, Steps: 118 Train Loss: 29.4526 (Forecasting Loss:0.3231 + XiCon Loss:2.9130 x Lambda(10.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1632
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.1497211
	speed: 0.0578s/iter; left time: 600.8264s
Epoch: 12 cost time: 6.808775186538696
Epoch: 12, Steps: 118 Train Loss: 29.4602 (Forecasting Loss:0.3230 + XiCon Loss:2.9137 x Lambda(10.0)), Vali MSE Loss: 0.2465 Test MSE Loss: 0.1632
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.4862766
	speed: 0.0567s/iter; left time: 582.9031s
Epoch: 13 cost time: 6.7098212242126465
Epoch: 13, Steps: 118 Train Loss: 29.4639 (Forecasting Loss:0.3229 + XiCon Loss:2.9141 x Lambda(10.0)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1632
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1538582
	speed: 0.0564s/iter; left time: 573.1063s
Epoch: 14 cost time: 6.503561973571777
Epoch: 14, Steps: 118 Train Loss: 29.4770 (Forecasting Loss:0.3231 + XiCon Loss:2.9154 x Lambda(10.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08784042298793793, mae:0.23428194224834442, mape:0.17067959904670715, mspe:0.04602174460887909 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0834+-0.00842, MAE:0.2278+-0.01193, MAPE:0.1659+-0.00857, MSPE:0.0441+-0.00414, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3848
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8131663
	speed: 0.0808s/iter; left time: 856.0545s
Epoch: 1 cost time: 8.600704193115234
Epoch: 1, Steps: 107 Train Loss: 0.8543 (Forecasting Loss:0.5323 + XiCon Loss:3.2196 x Lambda(0.1)), Vali MSE Loss: 0.3458 Test MSE Loss: 0.1971
Validation loss decreased (inf --> 0.345812).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5912520
	speed: 0.0747s/iter; left time: 783.4475s
Epoch: 2 cost time: 8.040782451629639
Epoch: 2, Steps: 107 Train Loss: 0.6937 (Forecasting Loss:0.3780 + XiCon Loss:3.1569 x Lambda(0.1)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1393
Validation loss decreased (0.345812 --> 0.251799).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5692945
	speed: 0.0732s/iter; left time: 760.5058s
Epoch: 3 cost time: 7.936472177505493
Epoch: 3, Steps: 107 Train Loss: 0.5769 (Forecasting Loss:0.2684 + XiCon Loss:3.0849 x Lambda(0.1)), Vali MSE Loss: 0.2579 Test MSE Loss: 0.1355
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5652903
	speed: 0.0955s/iter; left time: 982.1761s
Epoch: 4 cost time: 10.160133838653564
Epoch: 4, Steps: 107 Train Loss: 0.5592 (Forecasting Loss:0.2544 + XiCon Loss:3.0484 x Lambda(0.1)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.1483
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5430174
	speed: 0.0457s/iter; left time: 464.9864s
Epoch: 5 cost time: 4.913002252578735
Epoch: 5, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2472 + XiCon Loss:3.0228 x Lambda(0.1)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1368
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5418550
	speed: 0.0617s/iter; left time: 620.7048s
Epoch: 6 cost time: 6.8569653034210205
Epoch: 6, Steps: 107 Train Loss: 0.5453 (Forecasting Loss:0.2438 + XiCon Loss:3.0147 x Lambda(0.1)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5268803
	speed: 0.0777s/iter; left time: 773.4436s
Epoch: 7 cost time: 8.328057050704956
Epoch: 7, Steps: 107 Train Loss: 0.5448 (Forecasting Loss:0.2429 + XiCon Loss:3.0190 x Lambda(0.1)), Vali MSE Loss: 0.2605 Test MSE Loss: 0.1358
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5553186
	speed: 0.0784s/iter; left time: 772.0137s
Epoch: 8 cost time: 8.387805938720703
Epoch: 8, Steps: 107 Train Loss: 0.5444 (Forecasting Loss:0.2424 + XiCon Loss:3.0208 x Lambda(0.1)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.1378
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5585163
	speed: 0.0767s/iter; left time: 747.5399s
Epoch: 9 cost time: 8.138746738433838
Epoch: 9, Steps: 107 Train Loss: 0.5440 (Forecasting Loss:0.2417 + XiCon Loss:3.0227 x Lambda(0.1)), Vali MSE Loss: 0.2588 Test MSE Loss: 0.1378
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5531055
	speed: 0.0759s/iter; left time: 731.3651s
Epoch: 10 cost time: 8.1738600730896
Epoch: 10, Steps: 107 Train Loss: 0.5433 (Forecasting Loss:0.2414 + XiCon Loss:3.0190 x Lambda(0.1)), Vali MSE Loss: 0.2588 Test MSE Loss: 0.1376
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5445726
	speed: 0.0741s/iter; left time: 705.8469s
Epoch: 11 cost time: 7.958568096160889
Epoch: 11, Steps: 107 Train Loss: 0.5433 (Forecasting Loss:0.2411 + XiCon Loss:3.0227 x Lambda(0.1)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1371
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5477229
	speed: 0.0768s/iter; left time: 723.4714s
Epoch: 12 cost time: 8.263101577758789
Epoch: 12, Steps: 107 Train Loss: 0.5435 (Forecasting Loss:0.2411 + XiCon Loss:3.0237 x Lambda(0.1)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.1365
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06964340806007385, mae:0.20888778567314148, mape:0.15277229249477386, mspe:0.03864658996462822 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3609
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8187346
	speed: 0.0808s/iter; left time: 856.2130s
Epoch: 1 cost time: 8.723172426223755
Epoch: 1, Steps: 107 Train Loss: 0.8696 (Forecasting Loss:0.5476 + XiCon Loss:3.2201 x Lambda(0.1)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.2135
Validation loss decreased (inf --> 0.347553).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5969362
	speed: 0.0832s/iter; left time: 873.3255s
Epoch: 2 cost time: 8.97450065612793
Epoch: 2, Steps: 107 Train Loss: 0.7103 (Forecasting Loss:0.3917 + XiCon Loss:3.1858 x Lambda(0.1)), Vali MSE Loss: 0.2642 Test MSE Loss: 0.1616
Validation loss decreased (0.347553 --> 0.264167).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5705858
	speed: 0.0918s/iter; left time: 953.1951s
Epoch: 3 cost time: 9.868574619293213
Epoch: 3, Steps: 107 Train Loss: 0.5806 (Forecasting Loss:0.2635 + XiCon Loss:3.1714 x Lambda(0.1)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.1539
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5790501
	speed: 0.0863s/iter; left time: 886.7442s
Epoch: 4 cost time: 9.235448122024536
Epoch: 4, Steps: 107 Train Loss: 0.5691 (Forecasting Loss:0.2507 + XiCon Loss:3.1841 x Lambda(0.1)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.1515
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5682117
	speed: 0.0860s/iter; left time: 874.8125s
Epoch: 5 cost time: 9.238999843597412
Epoch: 5, Steps: 107 Train Loss: 0.5626 (Forecasting Loss:0.2431 + XiCon Loss:3.1951 x Lambda(0.1)), Vali MSE Loss: 0.2682 Test MSE Loss: 0.1549
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5633085
	speed: 0.0866s/iter; left time: 871.8964s
Epoch: 6 cost time: 9.298260927200317
Epoch: 6, Steps: 107 Train Loss: 0.5600 (Forecasting Loss:0.2399 + XiCon Loss:3.2012 x Lambda(0.1)), Vali MSE Loss: 0.2647 Test MSE Loss: 0.1566
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5563946
	speed: 0.0864s/iter; left time: 860.4011s
Epoch: 7 cost time: 9.316228151321411
Epoch: 7, Steps: 107 Train Loss: 0.5590 (Forecasting Loss:0.2387 + XiCon Loss:3.2026 x Lambda(0.1)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.1541
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5493827
	speed: 0.0860s/iter; left time: 847.4841s
Epoch: 8 cost time: 9.220895051956177
Epoch: 8, Steps: 107 Train Loss: 0.5582 (Forecasting Loss:0.2377 + XiCon Loss:3.2045 x Lambda(0.1)), Vali MSE Loss: 0.2706 Test MSE Loss: 0.1540
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5452865
	speed: 0.0890s/iter; left time: 866.8951s
Epoch: 9 cost time: 9.570327043533325
Epoch: 9, Steps: 107 Train Loss: 0.5583 (Forecasting Loss:0.2373 + XiCon Loss:3.2096 x Lambda(0.1)), Vali MSE Loss: 0.2694 Test MSE Loss: 0.1541
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5454855
	speed: 0.0831s/iter; left time: 800.5941s
Epoch: 10 cost time: 8.951616287231445
Epoch: 10, Steps: 107 Train Loss: 0.5570 (Forecasting Loss:0.2365 + XiCon Loss:3.2042 x Lambda(0.1)), Vali MSE Loss: 0.2677 Test MSE Loss: 0.1548
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5522802
	speed: 0.0863s/iter; left time: 822.1261s
Epoch: 11 cost time: 9.207594871520996
Epoch: 11, Steps: 107 Train Loss: 0.5576 (Forecasting Loss:0.2367 + XiCon Loss:3.2090 x Lambda(0.1)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.1535
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5657667
	speed: 0.0872s/iter; left time: 821.9792s
Epoch: 12 cost time: 9.379230260848999
Epoch: 12, Steps: 107 Train Loss: 0.5575 (Forecasting Loss:0.2370 + XiCon Loss:3.2043 x Lambda(0.1)), Vali MSE Loss: 0.2678 Test MSE Loss: 0.1542
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08789635449647903, mae:0.2352159321308136, mape:0.1686723679304123, mspe:0.0456615574657917 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4106
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.9024558
	speed: 0.0749s/iter; left time: 794.1726s
Epoch: 1 cost time: 8.066998958587646
Epoch: 1, Steps: 107 Train Loss: 0.8645 (Forecasting Loss:0.5414 + XiCon Loss:3.2307 x Lambda(0.1)), Vali MSE Loss: 0.3730 Test MSE Loss: 0.2208
Validation loss decreased (inf --> 0.372989).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5730931
	speed: 0.0984s/iter; left time: 1032.7594s
Epoch: 2 cost time: 10.727251529693604
Epoch: 2, Steps: 107 Train Loss: 0.6423 (Forecasting Loss:0.3329 + XiCon Loss:3.0931 x Lambda(0.1)), Vali MSE Loss: 0.3843 Test MSE Loss: 0.1598
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5544677
	speed: 0.1084s/iter; left time: 1125.7918s
Epoch: 3 cost time: 11.666447877883911
Epoch: 3, Steps: 107 Train Loss: 0.5489 (Forecasting Loss:0.2531 + XiCon Loss:2.9580 x Lambda(0.1)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.1611
Validation loss decreased (0.372989 --> 0.336326).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5561953
	speed: 0.1083s/iter; left time: 1113.7433s
Epoch: 4 cost time: 11.688846588134766
Epoch: 4, Steps: 107 Train Loss: 0.5401 (Forecasting Loss:0.2433 + XiCon Loss:2.9679 x Lambda(0.1)), Vali MSE Loss: 0.3418 Test MSE Loss: 0.1511
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5374030
	speed: 0.1102s/iter; left time: 1120.5682s
Epoch: 5 cost time: 11.80532431602478
Epoch: 5, Steps: 107 Train Loss: 0.5385 (Forecasting Loss:0.2389 + XiCon Loss:2.9967 x Lambda(0.1)), Vali MSE Loss: 0.3416 Test MSE Loss: 0.1431
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5402378
	speed: 0.1040s/iter; left time: 1046.5752s
Epoch: 6 cost time: 11.022114038467407
Epoch: 6, Steps: 107 Train Loss: 0.5379 (Forecasting Loss:0.2364 + XiCon Loss:3.0154 x Lambda(0.1)), Vali MSE Loss: 0.3457 Test MSE Loss: 0.1469
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5418972
	speed: 0.1041s/iter; left time: 1036.6153s
Epoch: 7 cost time: 11.208311080932617
Epoch: 7, Steps: 107 Train Loss: 0.5371 (Forecasting Loss:0.2348 + XiCon Loss:3.0227 x Lambda(0.1)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.1463
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5393586
	speed: 0.1030s/iter; left time: 1015.0571s
Epoch: 8 cost time: 11.113009452819824
Epoch: 8, Steps: 107 Train Loss: 0.5373 (Forecasting Loss:0.2343 + XiCon Loss:3.0295 x Lambda(0.1)), Vali MSE Loss: 0.3413 Test MSE Loss: 0.1458
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5301697
	speed: 0.1100s/iter; left time: 1072.0437s
Epoch: 9 cost time: 11.729875087738037
Epoch: 9, Steps: 107 Train Loss: 0.5376 (Forecasting Loss:0.2343 + XiCon Loss:3.0334 x Lambda(0.1)), Vali MSE Loss: 0.3415 Test MSE Loss: 0.1451
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5378828
	speed: 0.1050s/iter; left time: 1012.0457s
Epoch: 10 cost time: 11.299745082855225
Epoch: 10, Steps: 107 Train Loss: 0.5376 (Forecasting Loss:0.2346 + XiCon Loss:3.0305 x Lambda(0.1)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.1454
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5372788
	speed: 0.1008s/iter; left time: 960.3874s
Epoch: 11 cost time: 10.933534383773804
Epoch: 11, Steps: 107 Train Loss: 0.5371 (Forecasting Loss:0.2337 + XiCon Loss:3.0341 x Lambda(0.1)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.1458
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5357766
	speed: 0.1042s/iter; left time: 982.3761s
Epoch: 12 cost time: 11.022989273071289
Epoch: 12, Steps: 107 Train Loss: 0.5369 (Forecasting Loss:0.2337 + XiCon Loss:3.0322 x Lambda(0.1)), Vali MSE Loss: 0.3400 Test MSE Loss: 0.1457
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5442312
	speed: 0.1067s/iter; left time: 993.6922s
Epoch: 13 cost time: 11.420588254928589
Epoch: 13, Steps: 107 Train Loss: 0.5372 (Forecasting Loss:0.2338 + XiCon Loss:3.0344 x Lambda(0.1)), Vali MSE Loss: 0.3397 Test MSE Loss: 0.1457
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08797737210988998, mae:0.23429517447948456, mape:0.16820329427719116, mspe:0.046889614313840866 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3451
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8041233
	speed: 0.0756s/iter; left time: 801.2189s
Epoch: 1 cost time: 8.16032886505127
Epoch: 1, Steps: 107 Train Loss: 0.8540 (Forecasting Loss:0.5308 + XiCon Loss:3.2320 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.1932
Validation loss decreased (inf --> 0.326016).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6828718
	speed: 0.0768s/iter; left time: 805.9795s
Epoch: 2 cost time: 8.243957757949829
Epoch: 2, Steps: 107 Train Loss: 0.7409 (Forecasting Loss:0.4221 + XiCon Loss:3.1878 x Lambda(0.1)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.1640
Validation loss decreased (0.326016 --> 0.265148).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5924398
	speed: 0.0762s/iter; left time: 791.8163s
Epoch: 3 cost time: 8.15620231628418
Epoch: 3, Steps: 107 Train Loss: 0.6044 (Forecasting Loss:0.2924 + XiCon Loss:3.1198 x Lambda(0.1)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1517
Validation loss decreased (0.265148 --> 0.253664).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5604008
	speed: 0.0758s/iter; left time: 779.6338s
Epoch: 4 cost time: 8.150216102600098
Epoch: 4, Steps: 107 Train Loss: 0.5738 (Forecasting Loss:0.2617 + XiCon Loss:3.1214 x Lambda(0.1)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.1420
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5661130
	speed: 0.0811s/iter; left time: 824.6199s
Epoch: 5 cost time: 8.747527360916138
Epoch: 5, Steps: 107 Train Loss: 0.5630 (Forecasting Loss:0.2504 + XiCon Loss:3.1265 x Lambda(0.1)), Vali MSE Loss: 0.2631 Test MSE Loss: 0.1416
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5663646
	speed: 0.0760s/iter; left time: 765.4330s
Epoch: 6 cost time: 8.148948431015015
Epoch: 6, Steps: 107 Train Loss: 0.5601 (Forecasting Loss:0.2467 + XiCon Loss:3.1343 x Lambda(0.1)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1488
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5616840
	speed: 0.0740s/iter; left time: 737.0734s
Epoch: 7 cost time: 7.926380157470703
Epoch: 7, Steps: 107 Train Loss: 0.5589 (Forecasting Loss:0.2453 + XiCon Loss:3.1363 x Lambda(0.1)), Vali MSE Loss: 0.2588 Test MSE Loss: 0.1427
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5537368
	speed: 0.0788s/iter; left time: 776.4950s
Epoch: 8 cost time: 8.510072231292725
Epoch: 8, Steps: 107 Train Loss: 0.5583 (Forecasting Loss:0.2446 + XiCon Loss:3.1369 x Lambda(0.1)), Vali MSE Loss: 0.2557 Test MSE Loss: 0.1462
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5634332
	speed: 0.0756s/iter; left time: 736.8709s
Epoch: 9 cost time: 8.1609365940094
Epoch: 9, Steps: 107 Train Loss: 0.5579 (Forecasting Loss:0.2443 + XiCon Loss:3.1359 x Lambda(0.1)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1444
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5529498
	speed: 0.0784s/iter; left time: 755.4352s
Epoch: 10 cost time: 8.46086573600769
Epoch: 10, Steps: 107 Train Loss: 0.5577 (Forecasting Loss:0.2438 + XiCon Loss:3.1390 x Lambda(0.1)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1454
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5701946
	speed: 0.0776s/iter; left time: 739.9491s
Epoch: 11 cost time: 8.34337568283081
Epoch: 11, Steps: 107 Train Loss: 0.5572 (Forecasting Loss:0.2434 + XiCon Loss:3.1378 x Lambda(0.1)), Vali MSE Loss: 0.2563 Test MSE Loss: 0.1454
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5514693
	speed: 0.0795s/iter; left time: 749.1120s
Epoch: 12 cost time: 8.409415483474731
Epoch: 12, Steps: 107 Train Loss: 0.5574 (Forecasting Loss:0.2434 + XiCon Loss:3.1404 x Lambda(0.1)), Vali MSE Loss: 0.2566 Test MSE Loss: 0.1450
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5633525
	speed: 0.0838s/iter; left time: 780.3929s
Epoch: 13 cost time: 8.952520608901978
Epoch: 13, Steps: 107 Train Loss: 0.5572 (Forecasting Loss:0.2435 + XiCon Loss:3.1371 x Lambda(0.1)), Vali MSE Loss: 0.2569 Test MSE Loss: 0.1450
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08029942959547043, mae:0.22302354872226715, mape:0.15836720168590546, mspe:0.039483100175857544 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3994
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8454301
	speed: 0.0797s/iter; left time: 844.9640s
Epoch: 1 cost time: 8.572324752807617
Epoch: 1, Steps: 107 Train Loss: 0.8648 (Forecasting Loss:0.5419 + XiCon Loss:3.2282 x Lambda(0.1)), Vali MSE Loss: 0.3777 Test MSE Loss: 0.2232
Validation loss decreased (inf --> 0.377653).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5756198
	speed: 0.0962s/iter; left time: 1009.2240s
Epoch: 2 cost time: 10.393208503723145
Epoch: 2, Steps: 107 Train Loss: 0.6642 (Forecasting Loss:0.3506 + XiCon Loss:3.1366 x Lambda(0.1)), Vali MSE Loss: 0.3024 Test MSE Loss: 0.1420
Validation loss decreased (0.377653 --> 0.302372).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5751098
	speed: 0.0997s/iter; left time: 1035.4653s
Epoch: 3 cost time: 10.664684057235718
Epoch: 3, Steps: 107 Train Loss: 0.5747 (Forecasting Loss:0.2606 + XiCon Loss:3.1412 x Lambda(0.1)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.1439
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5628760
	speed: 0.0987s/iter; left time: 1014.6098s
Epoch: 4 cost time: 10.602455139160156
Epoch: 4, Steps: 107 Train Loss: 0.5628 (Forecasting Loss:0.2473 + XiCon Loss:3.1549 x Lambda(0.1)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.1382
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5609650
	speed: 0.1065s/iter; left time: 1083.7513s
Epoch: 5 cost time: 11.424731254577637
Epoch: 5, Steps: 107 Train Loss: 0.5567 (Forecasting Loss:0.2410 + XiCon Loss:3.1570 x Lambda(0.1)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.1387
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5434034
	speed: 0.1035s/iter; left time: 1041.8739s
Epoch: 6 cost time: 11.089580297470093
Epoch: 6, Steps: 107 Train Loss: 0.5545 (Forecasting Loss:0.2386 + XiCon Loss:3.1584 x Lambda(0.1)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.1417
Validation loss decreased (0.302372 --> 0.294120).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5547863
	speed: 0.1058s/iter; left time: 1053.5084s
Epoch: 7 cost time: 11.341752290725708
Epoch: 7, Steps: 107 Train Loss: 0.5530 (Forecasting Loss:0.2373 + XiCon Loss:3.1569 x Lambda(0.1)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.1378
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5594146
	speed: 0.1017s/iter; left time: 1001.9762s
Epoch: 8 cost time: 10.981213808059692
Epoch: 8, Steps: 107 Train Loss: 0.5525 (Forecasting Loss:0.2363 + XiCon Loss:3.1624 x Lambda(0.1)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.1408
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5546623
	speed: 0.1044s/iter; left time: 1017.2516s
Epoch: 9 cost time: 11.221569538116455
Epoch: 9, Steps: 107 Train Loss: 0.5520 (Forecasting Loss:0.2359 + XiCon Loss:3.1606 x Lambda(0.1)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.1363
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5693108
	speed: 0.1064s/iter; left time: 1025.4311s
Epoch: 10 cost time: 11.465296506881714
Epoch: 10, Steps: 107 Train Loss: 0.5515 (Forecasting Loss:0.2357 + XiCon Loss:3.1578 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.1363
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5580935
	speed: 0.1056s/iter; left time: 1006.2275s
Epoch: 11 cost time: 11.350233793258667
Epoch: 11, Steps: 107 Train Loss: 0.5517 (Forecasting Loss:0.2357 + XiCon Loss:3.1599 x Lambda(0.1)), Vali MSE Loss: 0.2974 Test MSE Loss: 0.1365
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5485758
	speed: 0.1036s/iter; left time: 976.0951s
Epoch: 12 cost time: 11.149120092391968
Epoch: 12, Steps: 107 Train Loss: 0.5512 (Forecasting Loss:0.2355 + XiCon Loss:3.1567 x Lambda(0.1)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.1361
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5577554
	speed: 0.1023s/iter; left time: 953.4250s
Epoch: 13 cost time: 11.11017894744873
Epoch: 13, Steps: 107 Train Loss: 0.5517 (Forecasting Loss:0.2358 + XiCon Loss:3.1583 x Lambda(0.1)), Vali MSE Loss: 0.2995 Test MSE Loss: 0.1361
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5619414
	speed: 0.1042s/iter; left time: 960.0905s
Epoch: 14 cost time: 11.201292037963867
Epoch: 14, Steps: 107 Train Loss: 0.5518 (Forecasting Loss:0.2360 + XiCon Loss:3.1573 x Lambda(0.1)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.1361
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5431985
	speed: 0.1003s/iter; left time: 913.0467s
Epoch: 15 cost time: 10.835666179656982
Epoch: 15, Steps: 107 Train Loss: 0.5514 (Forecasting Loss:0.2356 + XiCon Loss:3.1588 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.1362
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5615116
	speed: 0.1076s/iter; left time: 968.0630s
Epoch: 16 cost time: 11.53757381439209
Epoch: 16, Steps: 107 Train Loss: 0.5515 (Forecasting Loss:0.2355 + XiCon Loss:3.1594 x Lambda(0.1)), Vali MSE Loss: 0.2991 Test MSE Loss: 0.1362
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.0727054700255394, mae:0.21066385507583618, mape:0.15070295333862305, mspe:0.037232156842947006 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0797+-0.01050, MAE:0.2224+-0.01554, MAPE:0.1597+-0.01045, MSPE:0.0416+-0.00544, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4534
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 14.974654912948608
Epoch: 1, Steps: 96 Train Loss: 1.0667 (Forecasting Loss:0.7437 + XiCon Loss:3.2300 x Lambda(0.1)), Vali MSE Loss: 0.4371 Test MSE Loss: 0.2930
Validation loss decreased (inf --> 0.437094).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.696117639541626
Epoch: 2, Steps: 96 Train Loss: 0.8684 (Forecasting Loss:0.5505 + XiCon Loss:3.1792 x Lambda(0.1)), Vali MSE Loss: 0.2698 Test MSE Loss: 0.1691
Validation loss decreased (0.437094 --> 0.269769).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 14.093093395233154
Epoch: 3, Steps: 96 Train Loss: 0.6093 (Forecasting Loss:0.2962 + XiCon Loss:3.1313 x Lambda(0.1)), Vali MSE Loss: 0.2932 Test MSE Loss: 0.1579
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 14.026187419891357
Epoch: 4, Steps: 96 Train Loss: 0.5677 (Forecasting Loss:0.2575 + XiCon Loss:3.1019 x Lambda(0.1)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1692
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.658103466033936
Epoch: 5, Steps: 96 Train Loss: 0.5606 (Forecasting Loss:0.2494 + XiCon Loss:3.1117 x Lambda(0.1)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.1696
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.763887166976929
Epoch: 6, Steps: 96 Train Loss: 0.5585 (Forecasting Loss:0.2461 + XiCon Loss:3.1243 x Lambda(0.1)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.1674
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 15.928047895431519
Epoch: 7, Steps: 96 Train Loss: 0.5575 (Forecasting Loss:0.2444 + XiCon Loss:3.1305 x Lambda(0.1)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.1714
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.693156719207764
Epoch: 8, Steps: 96 Train Loss: 0.5562 (Forecasting Loss:0.2434 + XiCon Loss:3.1277 x Lambda(0.1)), Vali MSE Loss: 0.2912 Test MSE Loss: 0.1663
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 14.505144596099854
Epoch: 9, Steps: 96 Train Loss: 0.5565 (Forecasting Loss:0.2433 + XiCon Loss:3.1318 x Lambda(0.1)), Vali MSE Loss: 0.2918 Test MSE Loss: 0.1707
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.761230945587158
Epoch: 10, Steps: 96 Train Loss: 0.5557 (Forecasting Loss:0.2429 + XiCon Loss:3.1274 x Lambda(0.1)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.1705
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 15.640751361846924
Epoch: 11, Steps: 96 Train Loss: 0.5561 (Forecasting Loss:0.2427 + XiCon Loss:3.1341 x Lambda(0.1)), Vali MSE Loss: 0.2918 Test MSE Loss: 0.1697
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 13.734468221664429
Epoch: 12, Steps: 96 Train Loss: 0.5557 (Forecasting Loss:0.2426 + XiCon Loss:3.1315 x Lambda(0.1)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.1702
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.09469521045684814, mae:0.24348929524421692, mape:0.1724642515182495, mspe:0.04501132667064667 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4509
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.639955520629883
Epoch: 1, Steps: 96 Train Loss: 1.0440 (Forecasting Loss:0.7214 + XiCon Loss:3.2260 x Lambda(0.1)), Vali MSE Loss: 0.4323 Test MSE Loss: 0.2619
Validation loss decreased (inf --> 0.432291).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.050623416900635
Epoch: 2, Steps: 96 Train Loss: 0.7882 (Forecasting Loss:0.4726 + XiCon Loss:3.1566 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.1484
Validation loss decreased (0.432291 --> 0.319489).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 14.823702812194824
Epoch: 3, Steps: 96 Train Loss: 0.5907 (Forecasting Loss:0.2782 + XiCon Loss:3.1247 x Lambda(0.1)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.1402
Validation loss decreased (0.319489 --> 0.281654).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.692475318908691
Epoch: 4, Steps: 96 Train Loss: 0.5726 (Forecasting Loss:0.2583 + XiCon Loss:3.1437 x Lambda(0.1)), Vali MSE Loss: 0.2723 Test MSE Loss: 0.1453
Validation loss decreased (0.281654 --> 0.272349).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.13243556022644
Epoch: 5, Steps: 96 Train Loss: 0.5671 (Forecasting Loss:0.2507 + XiCon Loss:3.1634 x Lambda(0.1)), Vali MSE Loss: 0.2684 Test MSE Loss: 0.1492
Validation loss decreased (0.272349 --> 0.268353).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.92756962776184
Epoch: 6, Steps: 96 Train Loss: 0.5643 (Forecasting Loss:0.2474 + XiCon Loss:3.1693 x Lambda(0.1)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.1451
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 15.768314599990845
Epoch: 7, Steps: 96 Train Loss: 0.5627 (Forecasting Loss:0.2458 + XiCon Loss:3.1692 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
Validation loss decreased (0.268353 --> 0.265751).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 12.983237266540527
Epoch: 8, Steps: 96 Train Loss: 0.5618 (Forecasting Loss:0.2445 + XiCon Loss:3.1730 x Lambda(0.1)), Vali MSE Loss: 0.2685 Test MSE Loss: 0.1433
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 15.786543846130371
Epoch: 9, Steps: 96 Train Loss: 0.5617 (Forecasting Loss:0.2445 + XiCon Loss:3.1714 x Lambda(0.1)), Vali MSE Loss: 0.2689 Test MSE Loss: 0.1452
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 16.16741180419922
Epoch: 10, Steps: 96 Train Loss: 0.5616 (Forecasting Loss:0.2443 + XiCon Loss:3.1724 x Lambda(0.1)), Vali MSE Loss: 0.2675 Test MSE Loss: 0.1438
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 13.065480947494507
Epoch: 11, Steps: 96 Train Loss: 0.5621 (Forecasting Loss:0.2443 + XiCon Loss:3.1777 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1440
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.867601871490479
Epoch: 12, Steps: 96 Train Loss: 0.5615 (Forecasting Loss:0.2439 + XiCon Loss:3.1757 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.1442
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 15.6061692237854
Epoch: 13, Steps: 96 Train Loss: 0.5610 (Forecasting Loss:0.2441 + XiCon Loss:3.1697 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1441
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 16.048201322555542
Epoch: 14, Steps: 96 Train Loss: 0.5608 (Forecasting Loss:0.2437 + XiCon Loss:3.1716 x Lambda(0.1)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1441
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 16.18644404411316
Epoch: 15, Steps: 96 Train Loss: 0.5616 (Forecasting Loss:0.2438 + XiCon Loss:3.1787 x Lambda(0.1)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.1441
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 15.966520547866821
Epoch: 16, Steps: 96 Train Loss: 0.5607 (Forecasting Loss:0.2435 + XiCon Loss:3.1727 x Lambda(0.1)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.1441
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 16.032949924468994
Epoch: 17, Steps: 96 Train Loss: 0.5614 (Forecasting Loss:0.2435 + XiCon Loss:3.1784 x Lambda(0.1)), Vali MSE Loss: 0.2660 Test MSE Loss: 0.1441
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07390271872282028, mae:0.21285681426525116, mape:0.1556437611579895, mspe:0.040785569697618484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3580
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.63070034980774
Epoch: 1, Steps: 96 Train Loss: 1.0423 (Forecasting Loss:0.7198 + XiCon Loss:3.2251 x Lambda(0.1)), Vali MSE Loss: 0.4130 Test MSE Loss: 0.2473
Validation loss decreased (inf --> 0.412973).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.807368516921997
Epoch: 2, Steps: 96 Train Loss: 0.7987 (Forecasting Loss:0.4812 + XiCon Loss:3.1749 x Lambda(0.1)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.1592
Validation loss decreased (0.412973 --> 0.342144).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 15.73200011253357
Epoch: 3, Steps: 96 Train Loss: 0.6310 (Forecasting Loss:0.3178 + XiCon Loss:3.1324 x Lambda(0.1)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1373
Validation loss decreased (0.342144 --> 0.261070).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.914596557617188
Epoch: 4, Steps: 96 Train Loss: 0.5932 (Forecasting Loss:0.2828 + XiCon Loss:3.1037 x Lambda(0.1)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1399
Validation loss decreased (0.261070 --> 0.247643).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.555749416351318
Epoch: 5, Steps: 96 Train Loss: 0.5789 (Forecasting Loss:0.2682 + XiCon Loss:3.1068 x Lambda(0.1)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1388
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.728044033050537
Epoch: 6, Steps: 96 Train Loss: 0.5725 (Forecasting Loss:0.2611 + XiCon Loss:3.1142 x Lambda(0.1)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.1403
Validation loss decreased (0.247643 --> 0.245022).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 16.4628005027771
Epoch: 7, Steps: 96 Train Loss: 0.5698 (Forecasting Loss:0.2575 + XiCon Loss:3.1227 x Lambda(0.1)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.1414
Validation loss decreased (0.245022 --> 0.244715).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 16.4137704372406
Epoch: 8, Steps: 96 Train Loss: 0.5689 (Forecasting Loss:0.2565 + XiCon Loss:3.1248 x Lambda(0.1)), Vali MSE Loss: 0.2443 Test MSE Loss: 0.1439
Validation loss decreased (0.244715 --> 0.244328).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.044670581817627
Epoch: 9, Steps: 96 Train Loss: 0.5686 (Forecasting Loss:0.2556 + XiCon Loss:3.1299 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1423
Validation loss decreased (0.244328 --> 0.243660).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.82582688331604
Epoch: 10, Steps: 96 Train Loss: 0.5677 (Forecasting Loss:0.2547 + XiCon Loss:3.1294 x Lambda(0.1)), Vali MSE Loss: 0.2443 Test MSE Loss: 0.1430
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.18483066558838
Epoch: 11, Steps: 96 Train Loss: 0.5682 (Forecasting Loss:0.2550 + XiCon Loss:3.1321 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1426
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.923037052154541
Epoch: 12, Steps: 96 Train Loss: 0.5683 (Forecasting Loss:0.2551 + XiCon Loss:3.1312 x Lambda(0.1)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1429
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 15.968844413757324
Epoch: 13, Steps: 96 Train Loss: 0.5675 (Forecasting Loss:0.2541 + XiCon Loss:3.1342 x Lambda(0.1)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1429
Validation loss decreased (0.243660 --> 0.243640).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 15.89096999168396
Epoch: 14, Steps: 96 Train Loss: 0.5675 (Forecasting Loss:0.2541 + XiCon Loss:3.1342 x Lambda(0.1)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 15.708401679992676
Epoch: 15, Steps: 96 Train Loss: 0.5681 (Forecasting Loss:0.2547 + XiCon Loss:3.1334 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1429
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 15.822094440460205
Epoch: 16, Steps: 96 Train Loss: 0.5676 (Forecasting Loss:0.2544 + XiCon Loss:3.1316 x Lambda(0.1)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1429
Validation loss decreased (0.243640 --> 0.243539).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 15.901903629302979
Epoch: 17, Steps: 96 Train Loss: 0.5674 (Forecasting Loss:0.2541 + XiCon Loss:3.1327 x Lambda(0.1)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1429
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 16.058506965637207
Epoch: 18, Steps: 96 Train Loss: 0.5674 (Forecasting Loss:0.2541 + XiCon Loss:3.1324 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1429
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 15.946592569351196
Epoch: 19, Steps: 96 Train Loss: 0.5677 (Forecasting Loss:0.2544 + XiCon Loss:3.1330 x Lambda(0.1)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1429
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 15.571274518966675
Epoch: 20, Steps: 96 Train Loss: 0.5678 (Forecasting Loss:0.2546 + XiCon Loss:3.1316 x Lambda(0.1)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1429
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 15.797437906265259
Epoch: 21, Steps: 96 Train Loss: 0.5676 (Forecasting Loss:0.2547 + XiCon Loss:3.1294 x Lambda(0.1)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1429
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 15.698532104492188
Epoch: 22, Steps: 96 Train Loss: 0.5681 (Forecasting Loss:0.2551 + XiCon Loss:3.1302 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1429
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 15.795080423355103
Epoch: 23, Steps: 96 Train Loss: 0.5677 (Forecasting Loss:0.2544 + XiCon Loss:3.1327 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1429
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 15.824405193328857
Epoch: 24, Steps: 96 Train Loss: 0.5673 (Forecasting Loss:0.2545 + XiCon Loss:3.1287 x Lambda(0.1)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1429
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 15.68374228477478
Epoch: 25, Steps: 96 Train Loss: 0.5667 (Forecasting Loss:0.2540 + XiCon Loss:3.1276 x Lambda(0.1)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1429
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 16.07995080947876
Epoch: 26, Steps: 96 Train Loss: 0.5678 (Forecasting Loss:0.2546 + XiCon Loss:3.1319 x Lambda(0.1)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1429
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07365629822015762, mae:0.21221114695072174, mape:0.15291254222393036, mspe:0.037996966391801834 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4770
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.62262487411499
Epoch: 1, Steps: 96 Train Loss: 1.0911 (Forecasting Loss:0.7683 + XiCon Loss:3.2273 x Lambda(0.1)), Vali MSE Loss: 0.5525 Test MSE Loss: 0.3520
Validation loss decreased (inf --> 0.552523).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 26.16075301170349
Epoch: 2, Steps: 96 Train Loss: 0.6734 (Forecasting Loss:0.3604 + XiCon Loss:3.1299 x Lambda(0.1)), Vali MSE Loss: 0.3028 Test MSE Loss: 0.1665
Validation loss decreased (0.552523 --> 0.302753).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 27.19944715499878
Epoch: 3, Steps: 96 Train Loss: 0.5619 (Forecasting Loss:0.2497 + XiCon Loss:3.1215 x Lambda(0.1)), Vali MSE Loss: 0.3075 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 26.969210147857666
Epoch: 4, Steps: 96 Train Loss: 0.5544 (Forecasting Loss:0.2387 + XiCon Loss:3.1573 x Lambda(0.1)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.1657
Validation loss decreased (0.302753 --> 0.285195).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 26.665862798690796
Epoch: 5, Steps: 96 Train Loss: 0.5507 (Forecasting Loss:0.2337 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.2834 Test MSE Loss: 0.1554
Validation loss decreased (0.285195 --> 0.283424).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 26.818485736846924
Epoch: 6, Steps: 96 Train Loss: 0.5502 (Forecasting Loss:0.2320 + XiCon Loss:3.1823 x Lambda(0.1)), Vali MSE Loss: 0.2794 Test MSE Loss: 0.1565
Validation loss decreased (0.283424 --> 0.279394).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 26.621581077575684
Epoch: 7, Steps: 96 Train Loss: 0.5492 (Forecasting Loss:0.2304 + XiCon Loss:3.1880 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1515
Validation loss decreased (0.279394 --> 0.261233).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 26.305423974990845
Epoch: 8, Steps: 96 Train Loss: 0.5485 (Forecasting Loss:0.2297 + XiCon Loss:3.1883 x Lambda(0.1)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1520
Validation loss decreased (0.261233 --> 0.258715).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 26.919507265090942
Epoch: 9, Steps: 96 Train Loss: 0.5481 (Forecasting Loss:0.2292 + XiCon Loss:3.1891 x Lambda(0.1)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1522
Validation loss decreased (0.258715 --> 0.258617).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 26.978090286254883
Epoch: 10, Steps: 96 Train Loss: 0.5481 (Forecasting Loss:0.2296 + XiCon Loss:3.1851 x Lambda(0.1)), Vali MSE Loss: 0.2588 Test MSE Loss: 0.1508
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 26.67680311203003
Epoch: 11, Steps: 96 Train Loss: 0.5490 (Forecasting Loss:0.2291 + XiCon Loss:3.1991 x Lambda(0.1)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1516
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 26.96012783050537
Epoch: 12, Steps: 96 Train Loss: 0.5481 (Forecasting Loss:0.2291 + XiCon Loss:3.1899 x Lambda(0.1)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1521
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 26.676705598831177
Epoch: 13, Steps: 96 Train Loss: 0.5487 (Forecasting Loss:0.2292 + XiCon Loss:3.1949 x Lambda(0.1)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.1522
Validation loss decreased (0.258617 --> 0.258483).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 26.95824360847473
Epoch: 14, Steps: 96 Train Loss: 0.5486 (Forecasting Loss:0.2292 + XiCon Loss:3.1946 x Lambda(0.1)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.1521
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 26.424227952957153
Epoch: 15, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2290 + XiCon Loss:3.1930 x Lambda(0.1)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.1521
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 27.516113758087158
Epoch: 16, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2288 + XiCon Loss:3.1898 x Lambda(0.1)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.1521
Validation loss decreased (0.258483 --> 0.258108).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 26.889391660690308
Epoch: 17, Steps: 96 Train Loss: 0.5481 (Forecasting Loss:0.2291 + XiCon Loss:3.1901 x Lambda(0.1)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.1521
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 22.102838277816772
Epoch: 18, Steps: 96 Train Loss: 0.5482 (Forecasting Loss:0.2292 + XiCon Loss:3.1903 x Lambda(0.1)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1521
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 25.18120265007019
Epoch: 19, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2287 + XiCon Loss:3.1962 x Lambda(0.1)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.1521
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 26.973936557769775
Epoch: 20, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2292 + XiCon Loss:3.1908 x Lambda(0.1)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1521
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 27.331650018692017
Epoch: 21, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2289 + XiCon Loss:3.1942 x Lambda(0.1)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.1521
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 24.946455717086792
Epoch: 22, Steps: 96 Train Loss: 0.5488 (Forecasting Loss:0.2292 + XiCon Loss:3.1956 x Lambda(0.1)), Vali MSE Loss: 0.2588 Test MSE Loss: 0.1521
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 26.925959587097168
Epoch: 23, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2287 + XiCon Loss:3.1902 x Lambda(0.1)), Vali MSE Loss: 0.2591 Test MSE Loss: 0.1521
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 24.703702926635742
Epoch: 24, Steps: 96 Train Loss: 0.5489 (Forecasting Loss:0.2291 + XiCon Loss:3.1974 x Lambda(0.1)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1521
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 27.10158109664917
Epoch: 25, Steps: 96 Train Loss: 0.5482 (Forecasting Loss:0.2293 + XiCon Loss:3.1896 x Lambda(0.1)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.1521
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 25.290616512298584
Epoch: 26, Steps: 96 Train Loss: 0.5484 (Forecasting Loss:0.2291 + XiCon Loss:3.1931 x Lambda(0.1)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.1521
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08132289350032806, mae:0.22296808660030365, mape:0.16634894907474518, mspe:0.05104545131325722 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5186
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.788496732711792
Epoch: 1, Steps: 96 Train Loss: 1.0573 (Forecasting Loss:0.7339 + XiCon Loss:3.2343 x Lambda(0.1)), Vali MSE Loss: 0.4344 Test MSE Loss: 0.2754
Validation loss decreased (inf --> 0.434382).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 15.761410474777222
Epoch: 2, Steps: 96 Train Loss: 0.8422 (Forecasting Loss:0.5251 + XiCon Loss:3.1710 x Lambda(0.1)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.1695
Validation loss decreased (0.434382 --> 0.308986).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 15.89880895614624
Epoch: 3, Steps: 96 Train Loss: 0.5931 (Forecasting Loss:0.2819 + XiCon Loss:3.1122 x Lambda(0.1)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1790
Validation loss decreased (0.308986 --> 0.290702).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.40876030921936
Epoch: 4, Steps: 96 Train Loss: 0.5693 (Forecasting Loss:0.2555 + XiCon Loss:3.1383 x Lambda(0.1)), Vali MSE Loss: 0.3455 Test MSE Loss: 0.1764
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.424058198928833
Epoch: 5, Steps: 96 Train Loss: 0.5641 (Forecasting Loss:0.2476 + XiCon Loss:3.1643 x Lambda(0.1)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.1878
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.649030208587646
Epoch: 6, Steps: 96 Train Loss: 0.5623 (Forecasting Loss:0.2449 + XiCon Loss:3.1732 x Lambda(0.1)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.1876
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.360488414764404
Epoch: 7, Steps: 96 Train Loss: 0.5613 (Forecasting Loss:0.2434 + XiCon Loss:3.1788 x Lambda(0.1)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.1818
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.172162055969238
Epoch: 8, Steps: 96 Train Loss: 0.5610 (Forecasting Loss:0.2424 + XiCon Loss:3.1867 x Lambda(0.1)), Vali MSE Loss: 0.3468 Test MSE Loss: 0.1818
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 15.744104623794556
Epoch: 9, Steps: 96 Train Loss: 0.5608 (Forecasting Loss:0.2418 + XiCon Loss:3.1902 x Lambda(0.1)), Vali MSE Loss: 0.3642 Test MSE Loss: 0.1821
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.663708686828613
Epoch: 10, Steps: 96 Train Loss: 0.5599 (Forecasting Loss:0.2413 + XiCon Loss:3.1856 x Lambda(0.1)), Vali MSE Loss: 0.3634 Test MSE Loss: 0.1811
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 15.950602769851685
Epoch: 11, Steps: 96 Train Loss: 0.5599 (Forecasting Loss:0.2413 + XiCon Loss:3.1858 x Lambda(0.1)), Vali MSE Loss: 0.3594 Test MSE Loss: 0.1821
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.832936763763428
Epoch: 12, Steps: 96 Train Loss: 0.5601 (Forecasting Loss:0.2415 + XiCon Loss:3.1862 x Lambda(0.1)), Vali MSE Loss: 0.3659 Test MSE Loss: 0.1818
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 15.626869678497314
Epoch: 13, Steps: 96 Train Loss: 0.5593 (Forecasting Loss:0.2412 + XiCon Loss:3.1813 x Lambda(0.1)), Vali MSE Loss: 0.3659 Test MSE Loss: 0.1817
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.10364506393671036, mae:0.2542854845523834, mape:0.17796006798744202, mspe:0.048185452818870544 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0854+-0.01650, MAE:0.2292+-0.02346, MAPE:0.1651+-0.01330, MSPE:0.0446+-0.00659, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3213
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.4933300
	speed: 0.0345s/iter; left time: 438.6946s
Epoch: 1 cost time: 4.2627339363098145
Epoch: 1, Steps: 128 Train Loss: 31.8412 (Forecasting Loss:0.2931 + XiCon Loss:3.1548 x Lambda(10.0)), Vali MSE Loss: 0.2773 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.277316).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4070587
	speed: 0.0269s/iter; left time: 338.7556s
Epoch: 2 cost time: 3.4213943481445312
Epoch: 2, Steps: 128 Train Loss: 29.9493 (Forecasting Loss:0.2576 + XiCon Loss:2.9692 x Lambda(10.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2211
Validation loss decreased (0.277316 --> 0.258221).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8563480
	speed: 0.0245s/iter; left time: 304.9728s
Epoch: 3 cost time: 3.24774432182312
Epoch: 3, Steps: 128 Train Loss: 30.2660 (Forecasting Loss:0.2435 + XiCon Loss:3.0023 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.2206
Validation loss decreased (0.258221 --> 0.252733).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.5111580
	speed: 0.0315s/iter; left time: 387.7687s
Epoch: 4 cost time: 3.978868007659912
Epoch: 4, Steps: 128 Train Loss: 31.4813 (Forecasting Loss:0.2378 + XiCon Loss:3.1244 x Lambda(10.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.2057
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.8495998
	speed: 0.0302s/iter; left time: 368.3774s
Epoch: 5 cost time: 3.8360211849212646
Epoch: 5, Steps: 128 Train Loss: 31.5440 (Forecasting Loss:0.2346 + XiCon Loss:3.1309 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2079
Validation loss decreased (0.252733 --> 0.250789).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.2377167
	speed: 0.0296s/iter; left time: 356.9287s
Epoch: 6 cost time: 3.7465951442718506
Epoch: 6, Steps: 128 Train Loss: 31.5599 (Forecasting Loss:0.2325 + XiCon Loss:3.1327 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2063
Validation loss decreased (0.250789 --> 0.249632).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.8979607
	speed: 0.0325s/iter; left time: 387.4436s
Epoch: 7 cost time: 4.0331361293792725
Epoch: 7, Steps: 128 Train Loss: 31.5926 (Forecasting Loss:0.2313 + XiCon Loss:3.1361 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2070
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0878792
	speed: 0.0254s/iter; left time: 300.4252s
Epoch: 8 cost time: 3.265430212020874
Epoch: 8, Steps: 128 Train Loss: 31.5363 (Forecasting Loss:0.2310 + XiCon Loss:3.1305 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2067
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.0047379
	speed: 0.0251s/iter; left time: 292.9426s
Epoch: 9 cost time: 3.3366081714630127
Epoch: 9, Steps: 128 Train Loss: 31.5600 (Forecasting Loss:0.2310 + XiCon Loss:3.1329 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.8697987
	speed: 0.0309s/iter; left time: 357.4199s
Epoch: 10 cost time: 3.9327964782714844
Epoch: 10, Steps: 128 Train Loss: 31.5129 (Forecasting Loss:0.2308 + XiCon Loss:3.1282 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.5842628
	speed: 0.0324s/iter; left time: 369.5456s
Epoch: 11 cost time: 4.035501480102539
Epoch: 11, Steps: 128 Train Loss: 31.5349 (Forecasting Loss:0.2306 + XiCon Loss:3.1304 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2060
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.8858013
	speed: 0.0318s/iter; left time: 358.7848s
Epoch: 12 cost time: 3.947599411010742
Epoch: 12, Steps: 128 Train Loss: 31.5852 (Forecasting Loss:0.2307 + XiCon Loss:3.1355 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2060
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2433033
	speed: 0.0304s/iter; left time: 338.8927s
Epoch: 13 cost time: 3.756638765335083
Epoch: 13, Steps: 128 Train Loss: 31.6810 (Forecasting Loss:0.2306 + XiCon Loss:3.1450 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2060
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2370415
	speed: 0.0262s/iter; left time: 289.0142s
Epoch: 14 cost time: 3.3795814514160156
Epoch: 14, Steps: 128 Train Loss: 31.6380 (Forecasting Loss:0.2304 + XiCon Loss:3.1408 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.5097675
	speed: 0.0247s/iter; left time: 269.8130s
Epoch: 15 cost time: 3.224138021469116
Epoch: 15, Steps: 128 Train Loss: 31.5940 (Forecasting Loss:0.2304 + XiCon Loss:3.1364 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2060
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.1369629
	speed: 0.0326s/iter; left time: 351.5775s
Epoch: 16 cost time: 4.111891031265259
Epoch: 16, Steps: 128 Train Loss: 31.6081 (Forecasting Loss:0.2307 + XiCon Loss:3.1377 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2060
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13212789595127106, mae:0.28054505586624146, mape:0.664027214050293, mspe:19.6600284576416 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3896
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.5354233
	speed: 0.0310s/iter; left time: 393.5899s
Epoch: 1 cost time: 3.9224679470062256
Epoch: 1, Steps: 128 Train Loss: 31.6838 (Forecasting Loss:0.2941 + XiCon Loss:3.1390 x Lambda(10.0)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.2310
Validation loss decreased (inf --> 0.274166).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.9137211
	speed: 0.0293s/iter; left time: 368.5693s
Epoch: 2 cost time: 3.7049551010131836
Epoch: 2, Steps: 128 Train Loss: 30.4906 (Forecasting Loss:0.2580 + XiCon Loss:3.0233 x Lambda(10.0)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.2176
Validation loss decreased (0.274166 --> 0.264266).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.2124100
	speed: 0.0292s/iter; left time: 363.7452s
Epoch: 3 cost time: 3.7258617877960205
Epoch: 3, Steps: 128 Train Loss: 32.1194 (Forecasting Loss:0.2426 + XiCon Loss:3.1877 x Lambda(10.0)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.2086
Validation loss decreased (0.264266 --> 0.254761).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.5068703
	speed: 0.0255s/iter; left time: 313.8255s
Epoch: 4 cost time: 3.0851356983184814
Epoch: 4, Steps: 128 Train Loss: 32.3193 (Forecasting Loss:0.2377 + XiCon Loss:3.2082 x Lambda(10.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.2073
Validation loss decreased (0.254761 --> 0.248229).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.6947365
	speed: 0.0267s/iter; left time: 325.0837s
Epoch: 5 cost time: 3.429471731185913
Epoch: 5, Steps: 128 Train Loss: 32.5472 (Forecasting Loss:0.2345 + XiCon Loss:3.2313 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2097
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.1359901
	speed: 0.0312s/iter; left time: 376.8491s
Epoch: 6 cost time: 3.933640480041504
Epoch: 6, Steps: 128 Train Loss: 32.7445 (Forecasting Loss:0.2328 + XiCon Loss:3.2512 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2062
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.8150673
	speed: 0.0324s/iter; left time: 387.1937s
Epoch: 7 cost time: 4.143006086349487
Epoch: 7, Steps: 128 Train Loss: 32.5502 (Forecasting Loss:0.2319 + XiCon Loss:3.2318 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2057
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.8130646
	speed: 0.0314s/iter; left time: 370.2278s
Epoch: 8 cost time: 3.963310718536377
Epoch: 8, Steps: 128 Train Loss: 32.5714 (Forecasting Loss:0.2314 + XiCon Loss:3.2340 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2056
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.8875580
	speed: 0.0306s/iter; left time: 357.7431s
Epoch: 9 cost time: 3.8152220249176025
Epoch: 9, Steps: 128 Train Loss: 32.7698 (Forecasting Loss:0.2312 + XiCon Loss:3.2539 x Lambda(10.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2057
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.0470047
	speed: 0.0249s/iter; left time: 287.6691s
Epoch: 10 cost time: 2.9963595867156982
Epoch: 10, Steps: 128 Train Loss: 32.5728 (Forecasting Loss:0.2312 + XiCon Loss:3.2342 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2057
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.2963257
	speed: 0.0282s/iter; left time: 322.0974s
Epoch: 11 cost time: 3.6193344593048096
Epoch: 11, Steps: 128 Train Loss: 32.5326 (Forecasting Loss:0.2311 + XiCon Loss:3.2302 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2056
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.3798370
	speed: 0.0326s/iter; left time: 368.3346s
Epoch: 12 cost time: 4.130198955535889
Epoch: 12, Steps: 128 Train Loss: 32.5514 (Forecasting Loss:0.2311 + XiCon Loss:3.2320 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2055
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.7623997
	speed: 0.0311s/iter; left time: 346.6776s
Epoch: 13 cost time: 3.8957014083862305
Epoch: 13, Steps: 128 Train Loss: 32.6202 (Forecasting Loss:0.2310 + XiCon Loss:3.2389 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2055
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.3006706
	speed: 0.0318s/iter; left time: 350.5302s
Epoch: 14 cost time: 3.9171035289764404
Epoch: 14, Steps: 128 Train Loss: 32.6105 (Forecasting Loss:0.2309 + XiCon Loss:3.2380 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13283410668373108, mae:0.28166964650154114, mape:0.6763295531272888, mspe:20.67252540588379 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3190
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.4197559
	speed: 0.0285s/iter; left time: 362.5090s
Epoch: 1 cost time: 3.5194756984710693
Epoch: 1, Steps: 128 Train Loss: 31.6695 (Forecasting Loss:0.2955 + XiCon Loss:3.1374 x Lambda(10.0)), Vali MSE Loss: 0.2736 Test MSE Loss: 0.2305
Validation loss decreased (inf --> 0.273602).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.5958805
	speed: 0.0256s/iter; left time: 321.4846s
Epoch: 2 cost time: 3.1065855026245117
Epoch: 2, Steps: 128 Train Loss: 30.2094 (Forecasting Loss:0.2582 + XiCon Loss:2.9951 x Lambda(10.0)), Vali MSE Loss: 0.2732 Test MSE Loss: 0.2139
Validation loss decreased (0.273602 --> 0.273199).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6629543
	speed: 0.0300s/iter; left time: 373.6648s
Epoch: 3 cost time: 3.7546732425689697
Epoch: 3, Steps: 128 Train Loss: 30.5541 (Forecasting Loss:0.2426 + XiCon Loss:3.0312 x Lambda(10.0)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.2138
Validation loss decreased (0.273199 --> 0.256522).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2434254
	speed: 0.0326s/iter; left time: 401.5395s
Epoch: 4 cost time: 4.149275779724121
Epoch: 4, Steps: 128 Train Loss: 30.3206 (Forecasting Loss:0.2377 + XiCon Loss:3.0083 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2018
Validation loss decreased (0.256522 --> 0.250779).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3855991
	speed: 0.0304s/iter; left time: 370.8530s
Epoch: 5 cost time: 3.847445487976074
Epoch: 5, Steps: 128 Train Loss: 30.1971 (Forecasting Loss:0.2349 + XiCon Loss:2.9962 x Lambda(10.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2042
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.1170006
	speed: 0.0310s/iter; left time: 374.2669s
Epoch: 6 cost time: 3.8295340538024902
Epoch: 6, Steps: 128 Train Loss: 30.0971 (Forecasting Loss:0.2332 + XiCon Loss:2.9864 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2066
Validation loss decreased (0.250779 --> 0.250419).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0311089
	speed: 0.0313s/iter; left time: 373.1971s
Epoch: 7 cost time: 3.8346102237701416
Epoch: 7, Steps: 128 Train Loss: 30.0881 (Forecasting Loss:0.2324 + XiCon Loss:2.9856 x Lambda(10.0)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.2050
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.4489765
	speed: 0.0255s/iter; left time: 300.8830s
Epoch: 8 cost time: 3.038391351699829
Epoch: 8, Steps: 128 Train Loss: 30.0720 (Forecasting Loss:0.2319 + XiCon Loss:2.9840 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2063
Validation loss decreased (0.250419 --> 0.249979).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7294235
	speed: 0.0307s/iter; left time: 358.3914s
Epoch: 9 cost time: 3.890181064605713
Epoch: 9, Steps: 128 Train Loss: 30.0035 (Forecasting Loss:0.2318 + XiCon Loss:2.9772 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7141838
	speed: 0.0296s/iter; left time: 341.4717s
Epoch: 10 cost time: 3.8117756843566895
Epoch: 10, Steps: 128 Train Loss: 30.0061 (Forecasting Loss:0.2315 + XiCon Loss:2.9775 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2058
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.3640766
	speed: 0.0291s/iter; left time: 332.8123s
Epoch: 11 cost time: 3.6777327060699463
Epoch: 11, Steps: 128 Train Loss: 30.0734 (Forecasting Loss:0.2312 + XiCon Loss:2.9842 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5570965
	speed: 0.0310s/iter; left time: 350.4375s
Epoch: 12 cost time: 3.833817481994629
Epoch: 12, Steps: 128 Train Loss: 29.9913 (Forecasting Loss:0.2315 + XiCon Loss:2.9760 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.1604099
	speed: 0.0314s/iter; left time: 350.7791s
Epoch: 13 cost time: 3.8548688888549805
Epoch: 13, Steps: 128 Train Loss: 30.0023 (Forecasting Loss:0.2315 + XiCon Loss:2.9771 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2057
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4352188
	speed: 0.0239s/iter; left time: 264.2756s
Epoch: 14 cost time: 3.1394355297088623
Epoch: 14, Steps: 128 Train Loss: 30.0051 (Forecasting Loss:0.2314 + XiCon Loss:2.9774 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2057
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.2849998
	speed: 0.0297s/iter; left time: 323.6214s
Epoch: 15 cost time: 3.7019615173339844
Epoch: 15, Steps: 128 Train Loss: 30.0213 (Forecasting Loss:0.2314 + XiCon Loss:2.9790 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2057
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6495514
	speed: 0.0315s/iter; left time: 339.9034s
Epoch: 16 cost time: 3.942364454269409
Epoch: 16, Steps: 128 Train Loss: 30.0006 (Forecasting Loss:0.2314 + XiCon Loss:2.9769 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2057
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.0330963
	speed: 0.0321s/iter; left time: 342.2812s
Epoch: 17 cost time: 4.001288652420044
Epoch: 17, Steps: 128 Train Loss: 30.0379 (Forecasting Loss:0.2313 + XiCon Loss:2.9807 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2057
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.9058952
	speed: 0.0313s/iter; left time: 329.6001s
Epoch: 18 cost time: 3.9424047470092773
Epoch: 18, Steps: 128 Train Loss: 30.0454 (Forecasting Loss:0.2314 + XiCon Loss:2.9814 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2057
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1320430189371109, mae:0.28052350878715515, mape:0.663496732711792, mspe:19.64226531982422 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3614
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.5793629
	speed: 0.0295s/iter; left time: 375.1838s
Epoch: 1 cost time: 3.6701672077178955
Epoch: 1, Steps: 128 Train Loss: 31.7398 (Forecasting Loss:0.2933 + XiCon Loss:3.1446 x Lambda(10.0)), Vali MSE Loss: 0.2761 Test MSE Loss: 0.2312
Validation loss decreased (inf --> 0.276055).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.2225361
	speed: 0.0233s/iter; left time: 292.7688s
Epoch: 2 cost time: 3.110029458999634
Epoch: 2, Steps: 128 Train Loss: 29.8283 (Forecasting Loss:0.2571 + XiCon Loss:2.9571 x Lambda(10.0)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.2216
Validation loss decreased (0.276055 --> 0.265948).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.1977825
	speed: 0.0322s/iter; left time: 400.4400s
Epoch: 3 cost time: 3.9181411266326904
Epoch: 3, Steps: 128 Train Loss: 30.1663 (Forecasting Loss:0.2427 + XiCon Loss:2.9924 x Lambda(10.0)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.2136
Validation loss decreased (0.265948 --> 0.262682).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0767479
	speed: 0.0315s/iter; left time: 388.2232s
Epoch: 4 cost time: 3.99788761138916
Epoch: 4, Steps: 128 Train Loss: 30.9361 (Forecasting Loss:0.2373 + XiCon Loss:3.0699 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2063
Validation loss decreased (0.262682 --> 0.252636).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1493530
	speed: 0.0303s/iter; left time: 368.7482s
Epoch: 5 cost time: 3.8600645065307617
Epoch: 5, Steps: 128 Train Loss: 30.5047 (Forecasting Loss:0.2343 + XiCon Loss:3.0270 x Lambda(10.0)), Vali MSE Loss: 0.2544 Test MSE Loss: 0.2081
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9047012
	speed: 0.0321s/iter; left time: 387.7561s
Epoch: 6 cost time: 4.067788124084473
Epoch: 6, Steps: 128 Train Loss: 30.3149 (Forecasting Loss:0.2330 + XiCon Loss:3.0082 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2063
Validation loss decreased (0.252636 --> 0.250688).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.3072853
	speed: 0.0268s/iter; left time: 319.9902s
Epoch: 7 cost time: 3.4225716590881348
Epoch: 7, Steps: 128 Train Loss: 30.3684 (Forecasting Loss:0.2322 + XiCon Loss:3.0136 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2041
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.4178104
	speed: 0.0255s/iter; left time: 301.1761s
Epoch: 8 cost time: 3.269054651260376
Epoch: 8, Steps: 128 Train Loss: 30.3451 (Forecasting Loss:0.2319 + XiCon Loss:3.0113 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2058
Validation loss decreased (0.250688 --> 0.249976).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0424366
	speed: 0.0313s/iter; left time: 365.0297s
Epoch: 9 cost time: 3.974517583847046
Epoch: 9, Steps: 128 Train Loss: 30.2635 (Forecasting Loss:0.2318 + XiCon Loss:3.0032 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6932354
	speed: 0.0293s/iter; left time: 338.5268s
Epoch: 10 cost time: 3.6703848838806152
Epoch: 10, Steps: 128 Train Loss: 30.3255 (Forecasting Loss:0.2315 + XiCon Loss:3.0094 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2059
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.0374851
	speed: 0.0296s/iter; left time: 337.8176s
Epoch: 11 cost time: 3.8390092849731445
Epoch: 11, Steps: 128 Train Loss: 30.3163 (Forecasting Loss:0.2316 + XiCon Loss:3.0085 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1148643
	speed: 0.0315s/iter; left time: 355.6457s
Epoch: 12 cost time: 3.9995038509368896
Epoch: 12, Steps: 128 Train Loss: 30.1974 (Forecasting Loss:0.2314 + XiCon Loss:2.9966 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2058
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6334133
	speed: 0.0272s/iter; left time: 303.3837s
Epoch: 13 cost time: 3.42755389213562
Epoch: 13, Steps: 128 Train Loss: 30.2644 (Forecasting Loss:0.2316 + XiCon Loss:3.0033 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2058
Validation loss decreased (0.249976 --> 0.249803).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4482822
	speed: 0.0254s/iter; left time: 280.3295s
Epoch: 14 cost time: 3.352454662322998
Epoch: 14, Steps: 128 Train Loss: 30.2255 (Forecasting Loss:0.2315 + XiCon Loss:2.9994 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.0445385
	speed: 0.0319s/iter; left time: 348.4128s
Epoch: 15 cost time: 3.969695568084717
Epoch: 15, Steps: 128 Train Loss: 30.3019 (Forecasting Loss:0.2313 + XiCon Loss:3.0071 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2058
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.2175865
	speed: 0.0316s/iter; left time: 341.0206s
Epoch: 16 cost time: 4.031338930130005
Epoch: 16, Steps: 128 Train Loss: 30.2483 (Forecasting Loss:0.2314 + XiCon Loss:3.0017 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.0172825
	speed: 0.0316s/iter; left time: 336.8983s
Epoch: 17 cost time: 3.983278512954712
Epoch: 17, Steps: 128 Train Loss: 30.3099 (Forecasting Loss:0.2313 + XiCon Loss:3.0079 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2058
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.7707233
	speed: 0.0305s/iter; left time: 320.5545s
Epoch: 18 cost time: 3.8213298320770264
Epoch: 18, Steps: 128 Train Loss: 30.2428 (Forecasting Loss:0.2313 + XiCon Loss:3.0011 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2058
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.1589565
	speed: 0.0269s/iter; left time: 279.6228s
Epoch: 19 cost time: 3.4421253204345703
Epoch: 19, Steps: 128 Train Loss: 30.2658 (Forecasting Loss:0.2315 + XiCon Loss:3.0034 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2058
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.6040955
	speed: 0.0262s/iter; left time: 269.2487s
Epoch: 20 cost time: 3.394394636154175
Epoch: 20, Steps: 128 Train Loss: 30.2872 (Forecasting Loss:0.2313 + XiCon Loss:3.0056 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2058
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.6323147
	speed: 0.0321s/iter; left time: 325.7617s
Epoch: 21 cost time: 3.9950873851776123
Epoch: 21, Steps: 128 Train Loss: 30.2884 (Forecasting Loss:0.2314 + XiCon Loss:3.0057 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2058
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.7048740
	speed: 0.0311s/iter; left time: 311.1218s
Epoch: 22 cost time: 3.969322681427002
Epoch: 22, Steps: 128 Train Loss: 30.2855 (Forecasting Loss:0.2315 + XiCon Loss:3.0054 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2058
Validation loss decreased (0.249803 --> 0.249685).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.6388245
	speed: 0.0305s/iter; left time: 301.1706s
Epoch: 23 cost time: 3.839768409729004
Epoch: 23, Steps: 128 Train Loss: 30.2699 (Forecasting Loss:0.2315 + XiCon Loss:3.0038 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.7632427
	speed: 0.0298s/iter; left time: 290.8371s
Epoch: 24 cost time: 3.7013518810272217
Epoch: 24, Steps: 128 Train Loss: 30.2907 (Forecasting Loss:0.2315 + XiCon Loss:3.0059 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2058
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.5354881
	speed: 0.0265s/iter; left time: 255.6026s
Epoch: 25 cost time: 3.2588064670562744
Epoch: 25, Steps: 128 Train Loss: 30.2448 (Forecasting Loss:0.2314 + XiCon Loss:3.0013 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.6196766
	speed: 0.0261s/iter; left time: 248.3335s
Epoch: 26 cost time: 3.480781316757202
Epoch: 26, Steps: 128 Train Loss: 30.3012 (Forecasting Loss:0.2315 + XiCon Loss:3.0070 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2058
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.6612148
	speed: 0.0297s/iter; left time: 278.0313s
Epoch: 27 cost time: 3.86023211479187
Epoch: 27, Steps: 128 Train Loss: 30.2262 (Forecasting Loss:0.2316 + XiCon Loss:2.9995 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2058
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.8736286
	speed: 0.0307s/iter; left time: 284.1007s
Epoch: 28 cost time: 3.898693799972534
Epoch: 28, Steps: 128 Train Loss: 30.2296 (Forecasting Loss:0.2316 + XiCon Loss:2.9998 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2058
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.5208321
	speed: 0.0311s/iter; left time: 283.8597s
Epoch: 29 cost time: 3.8877086639404297
Epoch: 29, Steps: 128 Train Loss: 30.3098 (Forecasting Loss:0.2314 + XiCon Loss:3.0078 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2058
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 30.0653782
	speed: 0.0314s/iter; left time: 282.2833s
Epoch: 30 cost time: 4.020347595214844
Epoch: 30, Steps: 128 Train Loss: 30.3234 (Forecasting Loss:0.2316 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2058
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 29.9273777
	speed: 0.0239s/iter; left time: 212.0446s
Epoch: 31 cost time: 3.062303066253662
Epoch: 31, Steps: 128 Train Loss: 30.3441 (Forecasting Loss:0.2313 + XiCon Loss:3.0113 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2058
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 31.2919159
	speed: 0.0244s/iter; left time: 212.6692s
Epoch: 32 cost time: 3.103545665740967
Epoch: 32, Steps: 128 Train Loss: 30.2701 (Forecasting Loss:0.2315 + XiCon Loss:3.0039 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2058
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13162003457546234, mae:0.2800472676753998, mape:0.6627505421638489, mspe:19.56523895263672 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4217
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.7231750
	speed: 0.0306s/iter; left time: 388.3794s
Epoch: 1 cost time: 3.9121851921081543
Epoch: 1, Steps: 128 Train Loss: 31.9162 (Forecasting Loss:0.2924 + XiCon Loss:3.1624 x Lambda(10.0)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.2334
Validation loss decreased (inf --> 0.276539).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.1876411
	speed: 0.0308s/iter; left time: 387.3476s
Epoch: 2 cost time: 3.96777081489563
Epoch: 2, Steps: 128 Train Loss: 30.0408 (Forecasting Loss:0.2572 + XiCon Loss:2.9784 x Lambda(10.0)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.2205
Validation loss decreased (0.276539 --> 0.258430).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.8139515
	speed: 0.0321s/iter; left time: 399.0324s
Epoch: 3 cost time: 3.9574131965637207
Epoch: 3, Steps: 128 Train Loss: 30.2420 (Forecasting Loss:0.2427 + XiCon Loss:2.9999 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2129
Validation loss decreased (0.258430 --> 0.250615).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.8294563
	speed: 0.0302s/iter; left time: 371.6505s
Epoch: 4 cost time: 3.848874568939209
Epoch: 4, Steps: 128 Train Loss: 31.2440 (Forecasting Loss:0.2378 + XiCon Loss:3.1006 x Lambda(10.0)), Vali MSE Loss: 0.2546 Test MSE Loss: 0.2093
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8114948
	speed: 0.0257s/iter; left time: 313.7659s
Epoch: 5 cost time: 3.2526063919067383
Epoch: 5, Steps: 128 Train Loss: 30.7523 (Forecasting Loss:0.2346 + XiCon Loss:3.0518 x Lambda(10.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2057
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.7619057
	speed: 0.0277s/iter; left time: 333.6683s
Epoch: 6 cost time: 3.5732333660125732
Epoch: 6, Steps: 128 Train Loss: 30.4648 (Forecasting Loss:0.2328 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2055
Validation loss decreased (0.250615 --> 0.249956).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.3516407
	speed: 0.0284s/iter; left time: 338.5602s
Epoch: 7 cost time: 3.6079838275909424
Epoch: 7, Steps: 128 Train Loss: 30.2872 (Forecasting Loss:0.2323 + XiCon Loss:3.0055 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.3748856
	speed: 0.0313s/iter; left time: 369.0985s
Epoch: 8 cost time: 3.9641151428222656
Epoch: 8, Steps: 128 Train Loss: 30.2666 (Forecasting Loss:0.2319 + XiCon Loss:3.0035 x Lambda(10.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2061
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4588356
	speed: 0.0310s/iter; left time: 362.3935s
Epoch: 9 cost time: 3.86476469039917
Epoch: 9, Steps: 128 Train Loss: 30.2297 (Forecasting Loss:0.2316 + XiCon Loss:2.9998 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9183960
	speed: 0.0291s/iter; left time: 336.6178s
Epoch: 10 cost time: 3.6694517135620117
Epoch: 10, Steps: 128 Train Loss: 30.2283 (Forecasting Loss:0.2315 + XiCon Loss:2.9997 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
Validation loss decreased (0.249956 --> 0.249892).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.9720097
	speed: 0.0245s/iter; left time: 279.6813s
Epoch: 11 cost time: 3.0262961387634277
Epoch: 11, Steps: 128 Train Loss: 30.1951 (Forecasting Loss:0.2314 + XiCon Loss:2.9964 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.7453213
	speed: 0.0264s/iter; left time: 298.4354s
Epoch: 12 cost time: 3.449195146560669
Epoch: 12, Steps: 128 Train Loss: 30.2254 (Forecasting Loss:0.2316 + XiCon Loss:2.9994 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.2725563
	speed: 0.0315s/iter; left time: 351.5774s
Epoch: 13 cost time: 4.026007652282715
Epoch: 13, Steps: 128 Train Loss: 30.2375 (Forecasting Loss:0.2315 + XiCon Loss:3.0006 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.7806511
	speed: 0.0305s/iter; left time: 336.0803s
Epoch: 14 cost time: 3.8479490280151367
Epoch: 14, Steps: 128 Train Loss: 30.1834 (Forecasting Loss:0.2314 + XiCon Loss:2.9952 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2059
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2219830
	speed: 0.0312s/iter; left time: 340.4958s
Epoch: 15 cost time: 3.9901440143585205
Epoch: 15, Steps: 128 Train Loss: 30.2338 (Forecasting Loss:0.2313 + XiCon Loss:3.0002 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
Validation loss decreased (0.249892 --> 0.249858).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1805935
	speed: 0.0307s/iter; left time: 331.0073s
Epoch: 16 cost time: 3.968869924545288
Epoch: 16, Steps: 128 Train Loss: 30.1926 (Forecasting Loss:0.2314 + XiCon Loss:2.9961 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2059
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.7396851
	speed: 0.0257s/iter; left time: 274.0598s
Epoch: 17 cost time: 3.147444486618042
Epoch: 17, Steps: 128 Train Loss: 30.1870 (Forecasting Loss:0.2315 + XiCon Loss:2.9955 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2059
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.2013855
	speed: 0.0291s/iter; left time: 305.7664s
Epoch: 18 cost time: 3.7170393466949463
Epoch: 18, Steps: 128 Train Loss: 30.2431 (Forecasting Loss:0.2315 + XiCon Loss:3.0012 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.7991123
	speed: 0.0309s/iter; left time: 321.6801s
Epoch: 19 cost time: 3.8858039379119873
Epoch: 19, Steps: 128 Train Loss: 30.1634 (Forecasting Loss:0.2314 + XiCon Loss:2.9932 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2059
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.8566704
	speed: 0.0297s/iter; left time: 304.7704s
Epoch: 20 cost time: 3.8369100093841553
Epoch: 20, Steps: 128 Train Loss: 30.2443 (Forecasting Loss:0.2314 + XiCon Loss:3.0013 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.4843521
	speed: 0.0329s/iter; left time: 333.6788s
Epoch: 21 cost time: 4.1034557819366455
Epoch: 21, Steps: 128 Train Loss: 30.2165 (Forecasting Loss:0.2314 + XiCon Loss:2.9985 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.8887081
	speed: 0.0318s/iter; left time: 318.4984s
Epoch: 22 cost time: 4.088819265365601
Epoch: 22, Steps: 128 Train Loss: 30.2607 (Forecasting Loss:0.2314 + XiCon Loss:3.0029 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2059
Validation loss decreased (0.249858 --> 0.249687).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.1780224
	speed: 0.0261s/iter; left time: 257.5869s
Epoch: 23 cost time: 3.1479527950286865
Epoch: 23, Steps: 128 Train Loss: 30.2274 (Forecasting Loss:0.2313 + XiCon Loss:2.9996 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2059
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.6196747
	speed: 0.0201s/iter; left time: 196.0019s
Epoch: 24 cost time: 2.547638177871704
Epoch: 24, Steps: 128 Train Loss: 30.2287 (Forecasting Loss:0.2314 + XiCon Loss:2.9997 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.1577587
	speed: 0.0145s/iter; left time: 139.2037s
Epoch: 25 cost time: 1.8539457321166992
Epoch: 25, Steps: 128 Train Loss: 30.2579 (Forecasting Loss:0.2312 + XiCon Loss:3.0027 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.0811024
	speed: 0.0592s/iter; left time: 562.1207s
Epoch: 26 cost time: 7.021546125411987
Epoch: 26, Steps: 128 Train Loss: 30.1779 (Forecasting Loss:0.2314 + XiCon Loss:2.9947 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2059
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.0750313
	speed: 0.0181s/iter; left time: 169.7136s
Epoch: 27 cost time: 2.2323977947235107
Epoch: 27, Steps: 128 Train Loss: 30.2357 (Forecasting Loss:0.2314 + XiCon Loss:3.0004 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2059
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.9881382
	speed: 0.0157s/iter; left time: 145.2345s
Epoch: 28 cost time: 1.9479351043701172
Epoch: 28, Steps: 128 Train Loss: 30.1526 (Forecasting Loss:0.2314 + XiCon Loss:2.9921 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.0427685
	speed: 0.0137s/iter; left time: 124.9735s
Epoch: 29 cost time: 1.7118661403656006
Epoch: 29, Steps: 128 Train Loss: 30.1880 (Forecasting Loss:0.2314 + XiCon Loss:2.9957 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 31.2161884
	speed: 0.0305s/iter; left time: 274.4851s
Epoch: 30 cost time: 3.928614377975464
Epoch: 30, Steps: 128 Train Loss: 30.1734 (Forecasting Loss:0.2314 + XiCon Loss:2.9942 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2059
Validation loss decreased (0.249687 --> 0.249648).  Saving model ...
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.3374233
	speed: 0.0295s/iter; left time: 261.3664s
Epoch: 31 cost time: 3.7612740993499756
Epoch: 31, Steps: 128 Train Loss: 30.2178 (Forecasting Loss:0.2315 + XiCon Loss:2.9986 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2059
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 30.8285675
	speed: 0.0312s/iter; left time: 272.4870s
Epoch: 32 cost time: 3.9672391414642334
Epoch: 32, Steps: 128 Train Loss: 30.2196 (Forecasting Loss:0.2315 + XiCon Loss:2.9988 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2059
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 29.7410393
	speed: 0.0305s/iter; left time: 262.4934s
Epoch: 33 cost time: 3.8423798084259033
Epoch: 33, Steps: 128 Train Loss: 30.2348 (Forecasting Loss:0.2314 + XiCon Loss:3.0003 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 29.6731834
	speed: 0.0308s/iter; left time: 260.7719s
Epoch: 34 cost time: 3.813086748123169
Epoch: 34, Steps: 128 Train Loss: 30.2211 (Forecasting Loss:0.2314 + XiCon Loss:2.9990 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2059
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 29.8205719
	speed: 0.0255s/iter; left time: 212.9182s
Epoch: 35 cost time: 3.2239232063293457
Epoch: 35, Steps: 128 Train Loss: 30.2231 (Forecasting Loss:0.2314 + XiCon Loss:2.9992 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 30.0758705
	speed: 0.0310s/iter; left time: 254.8792s
Epoch: 36 cost time: 3.931490182876587
Epoch: 36, Steps: 128 Train Loss: 30.2056 (Forecasting Loss:0.2315 + XiCon Loss:2.9974 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2059
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 29.7296810
	speed: 0.0317s/iter; left time: 256.3399s
Epoch: 37 cost time: 3.960399866104126
Epoch: 37, Steps: 128 Train Loss: 30.2586 (Forecasting Loss:0.2314 + XiCon Loss:3.0027 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2059
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 30.0373573
	speed: 0.0323s/iter; left time: 257.5338s
Epoch: 38 cost time: 4.003255844116211
Epoch: 38, Steps: 128 Train Loss: 30.2078 (Forecasting Loss:0.2314 + XiCon Loss:2.9976 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2059
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 30.0567627
	speed: 0.0322s/iter; left time: 252.0615s
Epoch: 39 cost time: 4.0725743770599365
Epoch: 39, Steps: 128 Train Loss: 30.2729 (Forecasting Loss:0.2314 + XiCon Loss:3.0041 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2059
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 29.7799988
	speed: 0.0292s/iter; left time: 225.2938s
Epoch: 40 cost time: 3.7724947929382324
Epoch: 40, Steps: 128 Train Loss: 30.2935 (Forecasting Loss:0.2315 + XiCon Loss:3.0062 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13174834847450256, mae:0.280047744512558, mape:0.6625213027000427, mspe:19.659177780151367 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1321+-0.00059, MAE:0.2806+-0.00082, MAPE:0.6658+-0.00733, MSPE:19.8398+-0.58000, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1262
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4412984
	speed: 0.0239s/iter; left time: 279.2496s
Epoch: 1 cost time: 2.8625364303588867
Epoch: 1, Steps: 118 Train Loss: 0.4460 (Forecasting Loss:0.4140 + XiCon Loss:3.1979 x Lambda(0.01)), Vali MSE Loss: 0.4299 Test MSE Loss: 0.3241
Validation loss decreased (inf --> 0.429949).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3050256
	speed: 0.0577s/iter; left time: 668.3905s
Epoch: 2 cost time: 6.827629804611206
Epoch: 2, Steps: 118 Train Loss: 0.3328 (Forecasting Loss:0.3007 + XiCon Loss:3.2108 x Lambda(0.01)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2711
Validation loss decreased (0.429949 --> 0.363949).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3018940
	speed: 0.0598s/iter; left time: 685.7567s
Epoch: 3 cost time: 6.964492559432983
Epoch: 3, Steps: 118 Train Loss: 0.2896 (Forecasting Loss:0.2581 + XiCon Loss:3.1577 x Lambda(0.01)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2633
Validation loss decreased (0.363949 --> 0.322374).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2945407
	speed: 0.0587s/iter; left time: 666.3187s
Epoch: 4 cost time: 6.971272230148315
Epoch: 4, Steps: 118 Train Loss: 0.2757 (Forecasting Loss:0.2443 + XiCon Loss:3.1367 x Lambda(0.01)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2540
Validation loss decreased (0.322374 --> 0.318091).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2579552
	speed: 0.0502s/iter; left time: 563.4587s
Epoch: 5 cost time: 6.153627157211304
Epoch: 5, Steps: 118 Train Loss: 0.2698 (Forecasting Loss:0.2385 + XiCon Loss:3.1284 x Lambda(0.01)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2563
Validation loss decreased (0.318091 --> 0.316050).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2557519
	speed: 0.0279s/iter; left time: 309.8734s
Epoch: 6 cost time: 3.2668545246124268
Epoch: 6, Steps: 118 Train Loss: 0.2672 (Forecasting Loss:0.2360 + XiCon Loss:3.1222 x Lambda(0.01)), Vali MSE Loss: 0.3032 Test MSE Loss: 0.2528
Validation loss decreased (0.316050 --> 0.303215).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2724923
	speed: 0.0580s/iter; left time: 637.4962s
Epoch: 7 cost time: 6.802973985671997
Epoch: 7, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2345 + XiCon Loss:3.1189 x Lambda(0.01)), Vali MSE Loss: 0.3104 Test MSE Loss: 0.2551
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2453628
	speed: 0.0571s/iter; left time: 621.0605s
Epoch: 8 cost time: 6.8317039012908936
Epoch: 8, Steps: 118 Train Loss: 0.2650 (Forecasting Loss:0.2338 + XiCon Loss:3.1167 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.2559
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2574254
	speed: 0.0595s/iter; left time: 639.7758s
Epoch: 9 cost time: 7.030458211898804
Epoch: 9, Steps: 118 Train Loss: 0.2646 (Forecasting Loss:0.2334 + XiCon Loss:3.1174 x Lambda(0.01)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.2543
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2610086
	speed: 0.0550s/iter; left time: 585.3861s
Epoch: 10 cost time: 6.463943004608154
Epoch: 10, Steps: 118 Train Loss: 0.2644 (Forecasting Loss:0.2333 + XiCon Loss:3.1152 x Lambda(0.01)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2548
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2621101
	speed: 0.0368s/iter; left time: 387.3450s
Epoch: 11 cost time: 4.173800230026245
Epoch: 11, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2330 + XiCon Loss:3.1160 x Lambda(0.01)), Vali MSE Loss: 0.3087 Test MSE Loss: 0.2544
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2636967
	speed: 0.0416s/iter; left time: 432.4867s
Epoch: 12 cost time: 5.329621315002441
Epoch: 12, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2329 + XiCon Loss:3.1153 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.2546
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2633713
	speed: 0.0566s/iter; left time: 582.0743s
Epoch: 13 cost time: 6.707937479019165
Epoch: 13, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2329 + XiCon Loss:3.1167 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.2544
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2684475
	speed: 0.0578s/iter; left time: 587.2860s
Epoch: 14 cost time: 6.890730619430542
Epoch: 14, Steps: 118 Train Loss: 0.2640 (Forecasting Loss:0.2329 + XiCon Loss:3.1154 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.2544
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2426653
	speed: 0.0594s/iter; left time: 597.1283s
Epoch: 15 cost time: 6.868286371231079
Epoch: 15, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2329 + XiCon Loss:3.1152 x Lambda(0.01)), Vali MSE Loss: 0.3099 Test MSE Loss: 0.2544
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2740979
	speed: 0.0469s/iter; left time: 465.3847s
Epoch: 16 cost time: 5.1915881633758545
Epoch: 16, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2330 + XiCon Loss:3.1145 x Lambda(0.01)), Vali MSE Loss: 0.3089 Test MSE Loss: 0.2544
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1708611249923706, mae:0.33468109369277954, mape:0.6985403895378113, mspe:21.659259796142578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2638
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4141048
	speed: 0.0349s/iter; left time: 408.7294s
Epoch: 1 cost time: 4.333580017089844
Epoch: 1, Steps: 118 Train Loss: 0.4400 (Forecasting Loss:0.4081 + XiCon Loss:3.1870 x Lambda(0.01)), Vali MSE Loss: 0.4202 Test MSE Loss: 0.3056
Validation loss decreased (inf --> 0.420223).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3360814
	speed: 0.0487s/iter; left time: 564.2082s
Epoch: 2 cost time: 5.756747722625732
Epoch: 2, Steps: 118 Train Loss: 0.3632 (Forecasting Loss:0.3313 + XiCon Loss:3.1910 x Lambda(0.01)), Vali MSE Loss: 0.3665 Test MSE Loss: 0.2796
Validation loss decreased (0.420223 --> 0.366468).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2888763
	speed: 0.0469s/iter; left time: 537.9434s
Epoch: 3 cost time: 5.509315729141235
Epoch: 3, Steps: 118 Train Loss: 0.3114 (Forecasting Loss:0.2798 + XiCon Loss:3.1643 x Lambda(0.01)), Vali MSE Loss: 0.3734 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2779878
	speed: 0.0478s/iter; left time: 542.3549s
Epoch: 4 cost time: 5.685927629470825
Epoch: 4, Steps: 118 Train Loss: 0.2884 (Forecasting Loss:0.2570 + XiCon Loss:3.1372 x Lambda(0.01)), Vali MSE Loss: 0.3324 Test MSE Loss: 0.2546
Validation loss decreased (0.366468 --> 0.332435).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2830139
	speed: 0.0445s/iter; left time: 499.3036s
Epoch: 5 cost time: 5.1769349575042725
Epoch: 5, Steps: 118 Train Loss: 0.2788 (Forecasting Loss:0.2475 + XiCon Loss:3.1224 x Lambda(0.01)), Vali MSE Loss: 0.3427 Test MSE Loss: 0.2643
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3049175
	speed: 0.0220s/iter; left time: 244.8397s
Epoch: 6 cost time: 2.585421323776245
Epoch: 6, Steps: 118 Train Loss: 0.2743 (Forecasting Loss:0.2431 + XiCon Loss:3.1153 x Lambda(0.01)), Vali MSE Loss: 0.3517 Test MSE Loss: 0.2622
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2652242
	speed: 0.0213s/iter; left time: 233.7733s
Epoch: 7 cost time: 3.0180823802948
Epoch: 7, Steps: 118 Train Loss: 0.2723 (Forecasting Loss:0.2413 + XiCon Loss:3.1093 x Lambda(0.01)), Vali MSE Loss: 0.3489 Test MSE Loss: 0.2704
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2728635
	speed: 0.0479s/iter; left time: 520.5178s
Epoch: 8 cost time: 5.666666269302368
Epoch: 8, Steps: 118 Train Loss: 0.2715 (Forecasting Loss:0.2404 + XiCon Loss:3.1071 x Lambda(0.01)), Vali MSE Loss: 0.3445 Test MSE Loss: 0.2675
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2754408
	speed: 0.0478s/iter; left time: 514.2219s
Epoch: 9 cost time: 5.628436088562012
Epoch: 9, Steps: 118 Train Loss: 0.2709 (Forecasting Loss:0.2398 + XiCon Loss:3.1055 x Lambda(0.01)), Vali MSE Loss: 0.3443 Test MSE Loss: 0.2617
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2692295
	speed: 0.0522s/iter; left time: 555.3359s
Epoch: 10 cost time: 6.063479423522949
Epoch: 10, Steps: 118 Train Loss: 0.2702 (Forecasting Loss:0.2392 + XiCon Loss:3.1033 x Lambda(0.01)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.2605
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2763732
	speed: 0.0449s/iter; left time: 472.4270s
Epoch: 11 cost time: 5.420184850692749
Epoch: 11, Steps: 118 Train Loss: 0.2699 (Forecasting Loss:0.2389 + XiCon Loss:3.1045 x Lambda(0.01)), Vali MSE Loss: 0.3460 Test MSE Loss: 0.2641
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2678642
	speed: 0.0438s/iter; left time: 455.3738s
Epoch: 12 cost time: 5.269367694854736
Epoch: 12, Steps: 118 Train Loss: 0.2703 (Forecasting Loss:0.2393 + XiCon Loss:3.1028 x Lambda(0.01)), Vali MSE Loss: 0.3460 Test MSE Loss: 0.2635
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2750379
	speed: 0.0470s/iter; left time: 483.5429s
Epoch: 13 cost time: 5.539438247680664
Epoch: 13, Steps: 118 Train Loss: 0.2699 (Forecasting Loss:0.2389 + XiCon Loss:3.1026 x Lambda(0.01)), Vali MSE Loss: 0.3473 Test MSE Loss: 0.2633
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2678712
	speed: 0.0476s/iter; left time: 483.8197s
Epoch: 14 cost time: 5.620720624923706
Epoch: 14, Steps: 118 Train Loss: 0.2700 (Forecasting Loss:0.2390 + XiCon Loss:3.1018 x Lambda(0.01)), Vali MSE Loss: 0.3472 Test MSE Loss: 0.2628
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17309674620628357, mae:0.3361797332763672, mape:0.6298720240592957, mspe:16.018896102905273 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3830
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3552097
	speed: 0.0467s/iter; left time: 546.1904s
Epoch: 1 cost time: 5.50321364402771
Epoch: 1, Steps: 118 Train Loss: 0.4194 (Forecasting Loss:0.3874 + XiCon Loss:3.2035 x Lambda(0.01)), Vali MSE Loss: 0.3863 Test MSE Loss: 0.2897
Validation loss decreased (inf --> 0.386279).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3301869
	speed: 0.0395s/iter; left time: 457.3184s
Epoch: 2 cost time: 4.760287046432495
Epoch: 2, Steps: 118 Train Loss: 0.3574 (Forecasting Loss:0.3257 + XiCon Loss:3.1652 x Lambda(0.01)), Vali MSE Loss: 0.3426 Test MSE Loss: 0.2900
Validation loss decreased (0.386279 --> 0.342562).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3071283
	speed: 0.0481s/iter; left time: 551.8517s
Epoch: 3 cost time: 5.6819658279418945
Epoch: 3, Steps: 118 Train Loss: 0.3015 (Forecasting Loss:0.2705 + XiCon Loss:3.1045 x Lambda(0.01)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2834
Validation loss decreased (0.342562 --> 0.323467).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2626694
	speed: 0.0467s/iter; left time: 530.2127s
Epoch: 4 cost time: 5.503524303436279
Epoch: 4, Steps: 118 Train Loss: 0.2834 (Forecasting Loss:0.2526 + XiCon Loss:3.0827 x Lambda(0.01)), Vali MSE Loss: 0.3299 Test MSE Loss: 0.2721
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2592556
	speed: 0.0482s/iter; left time: 541.7385s
Epoch: 5 cost time: 5.713019371032715
Epoch: 5, Steps: 118 Train Loss: 0.2762 (Forecasting Loss:0.2454 + XiCon Loss:3.0753 x Lambda(0.01)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.2666
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2758453
	speed: 0.0488s/iter; left time: 541.6641s
Epoch: 6 cost time: 5.7418458461761475
Epoch: 6, Steps: 118 Train Loss: 0.2727 (Forecasting Loss:0.2419 + XiCon Loss:3.0737 x Lambda(0.01)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2757
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2600314
	speed: 0.0436s/iter; left time: 479.3183s
Epoch: 7 cost time: 4.938589811325073
Epoch: 7, Steps: 118 Train Loss: 0.2704 (Forecasting Loss:0.2397 + XiCon Loss:3.0725 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2795
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2739170
	speed: 0.0465s/iter; left time: 505.8621s
Epoch: 8 cost time: 5.5075483322143555
Epoch: 8, Steps: 118 Train Loss: 0.2696 (Forecasting Loss:0.2389 + XiCon Loss:3.0745 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2759
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2835833
	speed: 0.0471s/iter; left time: 506.2810s
Epoch: 9 cost time: 5.572297811508179
Epoch: 9, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2383 + XiCon Loss:3.0753 x Lambda(0.01)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2772
Validation loss decreased (0.323467 --> 0.323442).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2498759
	speed: 0.0464s/iter; left time: 493.4287s
Epoch: 10 cost time: 5.501478433609009
Epoch: 10, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2383 + XiCon Loss:3.0729 x Lambda(0.01)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2757
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2741824
	speed: 0.0491s/iter; left time: 516.5399s
Epoch: 11 cost time: 5.520766019821167
Epoch: 11, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2381 + XiCon Loss:3.0740 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2762
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2585665
	speed: 0.0350s/iter; left time: 363.6314s
Epoch: 12 cost time: 3.8869411945343018
Epoch: 12, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2382 + XiCon Loss:3.0744 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2769
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2671429
	speed: 0.0208s/iter; left time: 213.4945s
Epoch: 13 cost time: 2.45939302444458
Epoch: 13, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2382 + XiCon Loss:3.0737 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2765
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2635019
	speed: 0.0493s/iter; left time: 501.1796s
Epoch: 14 cost time: 5.777710437774658
Epoch: 14, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2380 + XiCon Loss:3.0750 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2763
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2590919
	speed: 0.0462s/iter; left time: 464.7485s
Epoch: 15 cost time: 5.398244619369507
Epoch: 15, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2379 + XiCon Loss:3.0738 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2766
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2727907
	speed: 0.0477s/iter; left time: 473.8234s
Epoch: 16 cost time: 5.648264646530151
Epoch: 16, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2382 + XiCon Loss:3.0748 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2766
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2657832
	speed: 0.0479s/iter; left time: 469.8946s
Epoch: 17 cost time: 5.629040002822876
Epoch: 17, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2380 + XiCon Loss:3.0743 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2766
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2612879
	speed: 0.0439s/iter; left time: 425.8385s
Epoch: 18 cost time: 4.901889324188232
Epoch: 18, Steps: 118 Train Loss: 0.2686 (Forecasting Loss:0.2379 + XiCon Loss:3.0712 x Lambda(0.01)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.2766
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2724193
	speed: 0.0480s/iter; left time: 459.3155s
Epoch: 19 cost time: 5.692075729370117
Epoch: 19, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2381 + XiCon Loss:3.0728 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2766
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1986204981803894, mae:0.35579994320869446, mape:0.6020961999893188, mspe:13.767438888549805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3874
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4113514
	speed: 0.0484s/iter; left time: 566.8081s
Epoch: 1 cost time: 5.717859745025635
Epoch: 1, Steps: 118 Train Loss: 0.4395 (Forecasting Loss:0.4076 + XiCon Loss:3.1902 x Lambda(0.01)), Vali MSE Loss: 0.4288 Test MSE Loss: 0.3195
Validation loss decreased (inf --> 0.428773).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3143024
	speed: 0.0477s/iter; left time: 552.3369s
Epoch: 2 cost time: 5.627336740493774
Epoch: 2, Steps: 118 Train Loss: 0.3499 (Forecasting Loss:0.3183 + XiCon Loss:3.1574 x Lambda(0.01)), Vali MSE Loss: 0.3418 Test MSE Loss: 0.2727
Validation loss decreased (0.428773 --> 0.341809).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2840714
	speed: 0.0448s/iter; left time: 513.9471s
Epoch: 3 cost time: 5.121051549911499
Epoch: 3, Steps: 118 Train Loss: 0.2926 (Forecasting Loss:0.2616 + XiCon Loss:3.1006 x Lambda(0.01)), Vali MSE Loss: 0.3585 Test MSE Loss: 0.2814
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2805465
	speed: 0.0471s/iter; left time: 534.1949s
Epoch: 4 cost time: 5.528801918029785
Epoch: 4, Steps: 118 Train Loss: 0.2755 (Forecasting Loss:0.2448 + XiCon Loss:3.0773 x Lambda(0.01)), Vali MSE Loss: 0.3281 Test MSE Loss: 0.2726
Validation loss decreased (0.341809 --> 0.328127).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2598401
	speed: 0.0480s/iter; left time: 539.0393s
Epoch: 5 cost time: 5.745702505111694
Epoch: 5, Steps: 118 Train Loss: 0.2683 (Forecasting Loss:0.2376 + XiCon Loss:3.0728 x Lambda(0.01)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2586
Validation loss decreased (0.328127 --> 0.320856).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2497385
	speed: 0.0491s/iter; left time: 546.0491s
Epoch: 6 cost time: 5.762197494506836
Epoch: 6, Steps: 118 Train Loss: 0.2649 (Forecasting Loss:0.2342 + XiCon Loss:3.0754 x Lambda(0.01)), Vali MSE Loss: 0.3439 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2550774
	speed: 0.0471s/iter; left time: 518.1201s
Epoch: 7 cost time: 5.6292102336883545
Epoch: 7, Steps: 118 Train Loss: 0.2632 (Forecasting Loss:0.2325 + XiCon Loss:3.0751 x Lambda(0.01)), Vali MSE Loss: 0.3357 Test MSE Loss: 0.2645
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2696203
	speed: 0.0423s/iter; left time: 459.6113s
Epoch: 8 cost time: 4.906335115432739
Epoch: 8, Steps: 118 Train Loss: 0.2623 (Forecasting Loss:0.2315 + XiCon Loss:3.0738 x Lambda(0.01)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.2668
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2529641
	speed: 0.0485s/iter; left time: 521.3832s
Epoch: 9 cost time: 5.679689168930054
Epoch: 9, Steps: 118 Train Loss: 0.2618 (Forecasting Loss:0.2311 + XiCon Loss:3.0763 x Lambda(0.01)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.2680
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2587023
	speed: 0.0480s/iter; left time: 510.2748s
Epoch: 10 cost time: 5.711004257202148
Epoch: 10, Steps: 118 Train Loss: 0.2614 (Forecasting Loss:0.2307 + XiCon Loss:3.0736 x Lambda(0.01)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.2688
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2626437
	speed: 0.0471s/iter; left time: 495.3725s
Epoch: 11 cost time: 5.533695459365845
Epoch: 11, Steps: 118 Train Loss: 0.2614 (Forecasting Loss:0.2307 + XiCon Loss:3.0748 x Lambda(0.01)), Vali MSE Loss: 0.3394 Test MSE Loss: 0.2682
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2576505
	speed: 0.0477s/iter; left time: 496.6249s
Epoch: 12 cost time: 5.629649639129639
Epoch: 12, Steps: 118 Train Loss: 0.2614 (Forecasting Loss:0.2307 + XiCon Loss:3.0766 x Lambda(0.01)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.2691
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2609514
	speed: 0.0389s/iter; left time: 400.3624s
Epoch: 13 cost time: 4.674215078353882
Epoch: 13, Steps: 118 Train Loss: 0.2615 (Forecasting Loss:0.2307 + XiCon Loss:3.0764 x Lambda(0.01)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.2683
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2754965
	speed: 0.0504s/iter; left time: 512.2614s
Epoch: 14 cost time: 5.854046821594238
Epoch: 14, Steps: 118 Train Loss: 0.2613 (Forecasting Loss:0.2305 + XiCon Loss:3.0756 x Lambda(0.01)), Vali MSE Loss: 0.3397 Test MSE Loss: 0.2684
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2612818
	speed: 0.0489s/iter; left time: 491.5469s
Epoch: 15 cost time: 5.7430644035339355
Epoch: 15, Steps: 118 Train Loss: 0.2612 (Forecasting Loss:0.2304 + XiCon Loss:3.0769 x Lambda(0.01)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.2685
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17686805129051208, mae:0.3402355909347534, mape:0.6286329030990601, mspe:17.11587142944336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4142
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3772520
	speed: 0.0464s/iter; left time: 543.1038s
Epoch: 1 cost time: 5.482814788818359
Epoch: 1, Steps: 118 Train Loss: 0.4387 (Forecasting Loss:0.4068 + XiCon Loss:3.1868 x Lambda(0.01)), Vali MSE Loss: 0.4334 Test MSE Loss: 0.3192
Validation loss decreased (inf --> 0.433362).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3051060
	speed: 0.0430s/iter; left time: 497.5830s
Epoch: 2 cost time: 4.902323007583618
Epoch: 2, Steps: 118 Train Loss: 0.3496 (Forecasting Loss:0.3182 + XiCon Loss:3.1434 x Lambda(0.01)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.2678
Validation loss decreased (0.433362 --> 0.337948).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2833401
	speed: 0.0479s/iter; left time: 549.3883s
Epoch: 3 cost time: 5.654769420623779
Epoch: 3, Steps: 118 Train Loss: 0.2907 (Forecasting Loss:0.2595 + XiCon Loss:3.1154 x Lambda(0.01)), Vali MSE Loss: 0.3474 Test MSE Loss: 0.2619
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2838787
	speed: 0.0488s/iter; left time: 554.1601s
Epoch: 4 cost time: 5.746733903884888
Epoch: 4, Steps: 118 Train Loss: 0.2729 (Forecasting Loss:0.2417 + XiCon Loss:3.1110 x Lambda(0.01)), Vali MSE Loss: 0.3473 Test MSE Loss: 0.2708
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2514836
	speed: 0.0498s/iter; left time: 559.4607s
Epoch: 5 cost time: 5.862238168716431
Epoch: 5, Steps: 118 Train Loss: 0.2660 (Forecasting Loss:0.2349 + XiCon Loss:3.1150 x Lambda(0.01)), Vali MSE Loss: 0.3403 Test MSE Loss: 0.2770
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2699094
	speed: 0.0506s/iter; left time: 562.0219s
Epoch: 6 cost time: 5.948969125747681
Epoch: 6, Steps: 118 Train Loss: 0.2631 (Forecasting Loss:0.2319 + XiCon Loss:3.1175 x Lambda(0.01)), Vali MSE Loss: 0.3410 Test MSE Loss: 0.2727
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2536761
	speed: 0.0471s/iter; left time: 517.8063s
Epoch: 7 cost time: 5.381645679473877
Epoch: 7, Steps: 118 Train Loss: 0.2620 (Forecasting Loss:0.2308 + XiCon Loss:3.1205 x Lambda(0.01)), Vali MSE Loss: 0.3437 Test MSE Loss: 0.2730
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2572678
	speed: 0.0491s/iter; left time: 533.9481s
Epoch: 8 cost time: 5.829407691955566
Epoch: 8, Steps: 118 Train Loss: 0.2611 (Forecasting Loss:0.2299 + XiCon Loss:3.1206 x Lambda(0.01)), Vali MSE Loss: 0.3429 Test MSE Loss: 0.2719
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2556846
	speed: 0.0501s/iter; left time: 538.7147s
Epoch: 9 cost time: 5.863172292709351
Epoch: 9, Steps: 118 Train Loss: 0.2606 (Forecasting Loss:0.2294 + XiCon Loss:3.1170 x Lambda(0.01)), Vali MSE Loss: 0.3425 Test MSE Loss: 0.2730
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2528946
	speed: 0.0484s/iter; left time: 515.4024s
Epoch: 10 cost time: 5.695133209228516
Epoch: 10, Steps: 118 Train Loss: 0.2606 (Forecasting Loss:0.2294 + XiCon Loss:3.1240 x Lambda(0.01)), Vali MSE Loss: 0.3416 Test MSE Loss: 0.2730
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2744489
	speed: 0.0509s/iter; left time: 535.5047s
Epoch: 11 cost time: 5.8022544384002686
Epoch: 11, Steps: 118 Train Loss: 0.2604 (Forecasting Loss:0.2291 + XiCon Loss:3.1228 x Lambda(0.01)), Vali MSE Loss: 0.3429 Test MSE Loss: 0.2731
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2444460
	speed: 0.0440s/iter; left time: 457.5528s
Epoch: 12 cost time: 5.268239498138428
Epoch: 12, Steps: 118 Train Loss: 0.2601 (Forecasting Loss:0.2288 + XiCon Loss:3.1211 x Lambda(0.01)), Vali MSE Loss: 0.3429 Test MSE Loss: 0.2725
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1854356974363327, mae:0.3501774072647095, mape:0.6557601094245911, mspe:19.167572021484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1810+-0.01405, MAE:0.3434+-0.01141, MAPE:0.6430+-0.04519, MSPE:17.5458+-3.74269, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3761
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5831676
	speed: 0.0632s/iter; left time: 670.4482s
Epoch: 1 cost time: 6.790846586227417
Epoch: 1, Steps: 107 Train Loss: 0.6372 (Forecasting Loss:0.6340 + XiCon Loss:3.2158 x Lambda(0.001)), Vali MSE Loss: 0.5962 Test MSE Loss: 0.4668
Validation loss decreased (inf --> 0.596243).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3099761
	speed: 0.0843s/iter; left time: 884.4349s
Epoch: 2 cost time: 9.04619312286377
Epoch: 2, Steps: 107 Train Loss: 0.3626 (Forecasting Loss:0.3594 + XiCon Loss:3.2592 x Lambda(0.001)), Vali MSE Loss: 0.3786 Test MSE Loss: 0.2525
Validation loss decreased (0.596243 --> 0.378585).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2633366
	speed: 0.0713s/iter; left time: 740.8532s
Epoch: 3 cost time: 7.751340627670288
Epoch: 3, Steps: 107 Train Loss: 0.2776 (Forecasting Loss:0.2744 + XiCon Loss:3.2368 x Lambda(0.001)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.2607
Validation loss decreased (0.378585 --> 0.354448).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2621636
	speed: 0.0810s/iter; left time: 832.7743s
Epoch: 4 cost time: 8.682902336120605
Epoch: 4, Steps: 107 Train Loss: 0.2630 (Forecasting Loss:0.2598 + XiCon Loss:3.2198 x Lambda(0.001)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2400
Validation loss decreased (0.354448 --> 0.322254).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2700873
	speed: 0.0851s/iter; left time: 865.3395s
Epoch: 5 cost time: 9.119623184204102
Epoch: 5, Steps: 107 Train Loss: 0.2579 (Forecasting Loss:0.2547 + XiCon Loss:3.2122 x Lambda(0.001)), Vali MSE Loss: 0.3320 Test MSE Loss: 0.2406
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2452846
	speed: 0.0816s/iter; left time: 821.1597s
Epoch: 6 cost time: 8.84238600730896
Epoch: 6, Steps: 107 Train Loss: 0.2552 (Forecasting Loss:0.2520 + XiCon Loss:3.2065 x Lambda(0.001)), Vali MSE Loss: 0.3237 Test MSE Loss: 0.2434
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2607927
	speed: 0.0823s/iter; left time: 819.3512s
Epoch: 7 cost time: 8.819888591766357
Epoch: 7, Steps: 107 Train Loss: 0.2538 (Forecasting Loss:0.2506 + XiCon Loss:3.2036 x Lambda(0.001)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2424
Validation loss decreased (0.322254 --> 0.320576).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2522963
	speed: 0.0811s/iter; left time: 799.1829s
Epoch: 8 cost time: 8.676412343978882
Epoch: 8, Steps: 107 Train Loss: 0.2532 (Forecasting Loss:0.2500 + XiCon Loss:3.2026 x Lambda(0.001)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2431
Validation loss decreased (0.320576 --> 0.320449).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2570315
	speed: 0.0851s/iter; left time: 829.4930s
Epoch: 9 cost time: 9.215013980865479
Epoch: 9, Steps: 107 Train Loss: 0.2527 (Forecasting Loss:0.2495 + XiCon Loss:3.2008 x Lambda(0.001)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2418
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2485089
	speed: 0.0803s/iter; left time: 773.4933s
Epoch: 10 cost time: 8.67024564743042
Epoch: 10, Steps: 107 Train Loss: 0.2527 (Forecasting Loss:0.2495 + XiCon Loss:3.1999 x Lambda(0.001)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2426
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2525557
	speed: 0.0780s/iter; left time: 743.3780s
Epoch: 11 cost time: 8.441319942474365
Epoch: 11, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2492 + XiCon Loss:3.2003 x Lambda(0.001)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2417
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2442835
	speed: 0.0823s/iter; left time: 775.5301s
Epoch: 12 cost time: 8.812313079833984
Epoch: 12, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.2008 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2417
Validation loss decreased (0.320449 --> 0.320092).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2542471
	speed: 0.0832s/iter; left time: 774.8825s
Epoch: 13 cost time: 8.887050867080688
Epoch: 13, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.2009 x Lambda(0.001)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2419
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2503159
	speed: 0.0794s/iter; left time: 731.1412s
Epoch: 14 cost time: 8.484498262405396
Epoch: 14, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2492 + XiCon Loss:3.2006 x Lambda(0.001)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2420
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2628960
	speed: 0.0813s/iter; left time: 740.3785s
Epoch: 15 cost time: 8.721109628677368
Epoch: 15, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2492 + XiCon Loss:3.2000 x Lambda(0.001)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2420
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2560565
	speed: 0.0821s/iter; left time: 738.5229s
Epoch: 16 cost time: 8.873881340026855
Epoch: 16, Steps: 107 Train Loss: 0.2522 (Forecasting Loss:0.2490 + XiCon Loss:3.2006 x Lambda(0.001)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2420
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2526453
	speed: 0.0806s/iter; left time: 716.6106s
Epoch: 17 cost time: 8.707207679748535
Epoch: 17, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.2002 x Lambda(0.001)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2420
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2468823
	speed: 0.0787s/iter; left time: 690.9294s
Epoch: 18 cost time: 8.475569486618042
Epoch: 18, Steps: 107 Train Loss: 0.2525 (Forecasting Loss:0.2493 + XiCon Loss:3.2000 x Lambda(0.001)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2420
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2641206
	speed: 0.0854s/iter; left time: 741.1599s
Epoch: 19 cost time: 9.138854265213013
Epoch: 19, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2492 + XiCon Loss:3.2001 x Lambda(0.001)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2420
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.2472709
	speed: 0.0836s/iter; left time: 716.1837s
Epoch: 20 cost time: 9.040424823760986
Epoch: 20, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.2005 x Lambda(0.001)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2420
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.2529677
	speed: 0.0825s/iter; left time: 697.6385s
Epoch: 21 cost time: 8.887034893035889
Epoch: 21, Steps: 107 Train Loss: 0.2522 (Forecasting Loss:0.2490 + XiCon Loss:3.2018 x Lambda(0.001)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2420
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.2580053
	speed: 0.0720s/iter; left time: 601.4781s
Epoch: 22 cost time: 7.846416234970093
Epoch: 22, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.1998 x Lambda(0.001)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2420
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.15936772525310516, mae:0.3240565061569214, mape:0.6514052748680115, mspe:17.463979721069336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4410
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5939701
	speed: 0.0609s/iter; left time: 645.9934s
Epoch: 1 cost time: 6.591560363769531
Epoch: 1, Steps: 107 Train Loss: 0.6186 (Forecasting Loss:0.6154 + XiCon Loss:3.1986 x Lambda(0.001)), Vali MSE Loss: 0.5483 Test MSE Loss: 0.4029
Validation loss decreased (inf --> 0.548323).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2932201
	speed: 0.0639s/iter; left time: 670.8972s
Epoch: 2 cost time: 6.881615400314331
Epoch: 2, Steps: 107 Train Loss: 0.4359 (Forecasting Loss:0.4327 + XiCon Loss:3.2041 x Lambda(0.001)), Vali MSE Loss: 0.3829 Test MSE Loss: 0.2806
Validation loss decreased (0.548323 --> 0.382917).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2838135
	speed: 0.0622s/iter; left time: 645.6139s
Epoch: 3 cost time: 6.698126554489136
Epoch: 3, Steps: 107 Train Loss: 0.3028 (Forecasting Loss:0.2997 + XiCon Loss:3.1683 x Lambda(0.001)), Vali MSE Loss: 0.3645 Test MSE Loss: 0.2525
Validation loss decreased (0.382917 --> 0.364537).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2816098
	speed: 0.0543s/iter; left time: 558.4850s
Epoch: 4 cost time: 5.756072521209717
Epoch: 4, Steps: 107 Train Loss: 0.2772 (Forecasting Loss:0.2740 + XiCon Loss:3.1587 x Lambda(0.001)), Vali MSE Loss: 0.3710 Test MSE Loss: 0.2499
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2534430
	speed: 0.0652s/iter; left time: 662.8012s
Epoch: 5 cost time: 7.005730867385864
Epoch: 5, Steps: 107 Train Loss: 0.2672 (Forecasting Loss:0.2641 + XiCon Loss:3.1549 x Lambda(0.001)), Vali MSE Loss: 0.3898 Test MSE Loss: 0.2620
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2510238
	speed: 0.0645s/iter; left time: 649.4222s
Epoch: 6 cost time: 6.977983236312866
Epoch: 6, Steps: 107 Train Loss: 0.2633 (Forecasting Loss:0.2601 + XiCon Loss:3.1543 x Lambda(0.001)), Vali MSE Loss: 0.3861 Test MSE Loss: 0.2810
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2607692
	speed: 0.0629s/iter; left time: 626.0234s
Epoch: 7 cost time: 6.760104179382324
Epoch: 7, Steps: 107 Train Loss: 0.2611 (Forecasting Loss:0.2580 + XiCon Loss:3.1541 x Lambda(0.001)), Vali MSE Loss: 0.3922 Test MSE Loss: 0.2795
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2578429
	speed: 0.0584s/iter; left time: 575.3633s
Epoch: 8 cost time: 6.254776477813721
Epoch: 8, Steps: 107 Train Loss: 0.2601 (Forecasting Loss:0.2569 + XiCon Loss:3.1537 x Lambda(0.001)), Vali MSE Loss: 0.3927 Test MSE Loss: 0.2739
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2638412
	speed: 0.0600s/iter; left time: 585.0469s
Epoch: 9 cost time: 6.4887449741363525
Epoch: 9, Steps: 107 Train Loss: 0.2594 (Forecasting Loss:0.2562 + XiCon Loss:3.1530 x Lambda(0.001)), Vali MSE Loss: 0.3956 Test MSE Loss: 0.2706
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2599235
	speed: 0.0642s/iter; left time: 618.7149s
Epoch: 10 cost time: 6.94131326675415
Epoch: 10, Steps: 107 Train Loss: 0.2589 (Forecasting Loss:0.2557 + XiCon Loss:3.1540 x Lambda(0.001)), Vali MSE Loss: 0.3977 Test MSE Loss: 0.2714
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2586619
	speed: 0.0644s/iter; left time: 613.3643s
Epoch: 11 cost time: 6.954455137252808
Epoch: 11, Steps: 107 Train Loss: 0.2591 (Forecasting Loss:0.2559 + XiCon Loss:3.1534 x Lambda(0.001)), Vali MSE Loss: 0.3964 Test MSE Loss: 0.2771
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2530008
	speed: 0.0629s/iter; left time: 592.9839s
Epoch: 12 cost time: 6.8157734870910645
Epoch: 12, Steps: 107 Train Loss: 0.2589 (Forecasting Loss:0.2558 + XiCon Loss:3.1518 x Lambda(0.001)), Vali MSE Loss: 0.3968 Test MSE Loss: 0.2741
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2597644
	speed: 0.0562s/iter; left time: 523.6788s
Epoch: 13 cost time: 6.119540214538574
Epoch: 13, Steps: 107 Train Loss: 0.2590 (Forecasting Loss:0.2558 + XiCon Loss:3.1510 x Lambda(0.001)), Vali MSE Loss: 0.3969 Test MSE Loss: 0.2754
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1702793836593628, mae:0.33473628759384155, mape:0.6002511978149414, mspe:14.827356338500977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3938
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5521466
	speed: 0.0614s/iter; left time: 650.8122s
Epoch: 1 cost time: 6.612912654876709
Epoch: 1, Steps: 107 Train Loss: 0.6304 (Forecasting Loss:0.6272 + XiCon Loss:3.2057 x Lambda(0.001)), Vali MSE Loss: 0.5767 Test MSE Loss: 0.4445
Validation loss decreased (inf --> 0.576656).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3198967
	speed: 0.0653s/iter; left time: 685.7278s
Epoch: 2 cost time: 7.1188881397247314
Epoch: 2, Steps: 107 Train Loss: 0.4104 (Forecasting Loss:0.4071 + XiCon Loss:3.2375 x Lambda(0.001)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2716
Validation loss decreased (0.576656 --> 0.489616).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2766180
	speed: 0.0757s/iter; left time: 786.7953s
Epoch: 3 cost time: 8.119757890701294
Epoch: 3, Steps: 107 Train Loss: 0.2852 (Forecasting Loss:0.2820 + XiCon Loss:3.2336 x Lambda(0.001)), Vali MSE Loss: 0.3507 Test MSE Loss: 0.2524
Validation loss decreased (0.489616 --> 0.350676).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2627106
	speed: 0.0673s/iter; left time: 691.7008s
Epoch: 4 cost time: 7.297577619552612
Epoch: 4, Steps: 107 Train Loss: 0.2684 (Forecasting Loss:0.2652 + XiCon Loss:3.2283 x Lambda(0.001)), Vali MSE Loss: 0.3395 Test MSE Loss: 0.2363
Validation loss decreased (0.350676 --> 0.339456).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2620663
	speed: 0.0756s/iter; left time: 769.0715s
Epoch: 5 cost time: 8.167382717132568
Epoch: 5, Steps: 107 Train Loss: 0.2625 (Forecasting Loss:0.2593 + XiCon Loss:3.2243 x Lambda(0.001)), Vali MSE Loss: 0.3523 Test MSE Loss: 0.2390
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2598242
	speed: 0.0794s/iter; left time: 799.2610s
Epoch: 6 cost time: 8.58190655708313
Epoch: 6, Steps: 107 Train Loss: 0.2594 (Forecasting Loss:0.2562 + XiCon Loss:3.2254 x Lambda(0.001)), Vali MSE Loss: 0.3508 Test MSE Loss: 0.2379
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2498860
	speed: 0.0773s/iter; left time: 769.6104s
Epoch: 7 cost time: 8.277796745300293
Epoch: 7, Steps: 107 Train Loss: 0.2576 (Forecasting Loss:0.2544 + XiCon Loss:3.2238 x Lambda(0.001)), Vali MSE Loss: 0.3491 Test MSE Loss: 0.2370
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2582361
	speed: 0.0713s/iter; left time: 702.8721s
Epoch: 8 cost time: 7.742643594741821
Epoch: 8, Steps: 107 Train Loss: 0.2564 (Forecasting Loss:0.2531 + XiCon Loss:3.2246 x Lambda(0.001)), Vali MSE Loss: 0.3466 Test MSE Loss: 0.2369
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2485178
	speed: 0.0796s/iter; left time: 775.3908s
Epoch: 9 cost time: 8.524704694747925
Epoch: 9, Steps: 107 Train Loss: 0.2561 (Forecasting Loss:0.2529 + XiCon Loss:3.2240 x Lambda(0.001)), Vali MSE Loss: 0.3447 Test MSE Loss: 0.2373
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2536454
	speed: 0.0780s/iter; left time: 751.7599s
Epoch: 10 cost time: 8.422165155410767
Epoch: 10, Steps: 107 Train Loss: 0.2559 (Forecasting Loss:0.2526 + XiCon Loss:3.2236 x Lambda(0.001)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2375
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2529775
	speed: 0.0778s/iter; left time: 741.2203s
Epoch: 11 cost time: 8.381213426589966
Epoch: 11, Steps: 107 Train Loss: 0.2555 (Forecasting Loss:0.2523 + XiCon Loss:3.2235 x Lambda(0.001)), Vali MSE Loss: 0.3457 Test MSE Loss: 0.2371
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2482520
	speed: 0.0756s/iter; left time: 712.7724s
Epoch: 12 cost time: 8.175732851028442
Epoch: 12, Steps: 107 Train Loss: 0.2558 (Forecasting Loss:0.2525 + XiCon Loss:3.2243 x Lambda(0.001)), Vali MSE Loss: 0.3460 Test MSE Loss: 0.2374
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2516057
	speed: 0.0779s/iter; left time: 726.0963s
Epoch: 13 cost time: 8.400393009185791
Epoch: 13, Steps: 107 Train Loss: 0.2556 (Forecasting Loss:0.2524 + XiCon Loss:3.2245 x Lambda(0.001)), Vali MSE Loss: 0.3464 Test MSE Loss: 0.2374
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2594212
	speed: 0.0780s/iter; left time: 718.7465s
Epoch: 14 cost time: 8.427547693252563
Epoch: 14, Steps: 107 Train Loss: 0.2557 (Forecasting Loss:0.2524 + XiCon Loss:3.2245 x Lambda(0.001)), Vali MSE Loss: 0.3470 Test MSE Loss: 0.2374
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1536296159029007, mae:0.3189125061035156, mape:0.6730878353118896, mspe:20.172677993774414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5159
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5800329
	speed: 0.0545s/iter; left time: 578.0634s
Epoch: 1 cost time: 5.899385690689087
Epoch: 1, Steps: 107 Train Loss: 0.6204 (Forecasting Loss:0.6172 + XiCon Loss:3.1947 x Lambda(0.001)), Vali MSE Loss: 0.5706 Test MSE Loss: 0.4298
Validation loss decreased (inf --> 0.570577).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3250100
	speed: 0.0471s/iter; left time: 494.4644s
Epoch: 2 cost time: 5.470269441604614
Epoch: 2, Steps: 107 Train Loss: 0.4219 (Forecasting Loss:0.4187 + XiCon Loss:3.2386 x Lambda(0.001)), Vali MSE Loss: 0.3693 Test MSE Loss: 0.2594
Validation loss decreased (0.570577 --> 0.369279).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2779891
	speed: 0.0750s/iter; left time: 778.6317s
Epoch: 3 cost time: 7.819631814956665
Epoch: 3, Steps: 107 Train Loss: 0.2842 (Forecasting Loss:0.2810 + XiCon Loss:3.2296 x Lambda(0.001)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.2469
Validation loss decreased (0.369279 --> 0.342068).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2793601
	speed: 0.0374s/iter; left time: 384.6308s
Epoch: 4 cost time: 4.040750026702881
Epoch: 4, Steps: 107 Train Loss: 0.2671 (Forecasting Loss:0.2639 + XiCon Loss:3.2238 x Lambda(0.001)), Vali MSE Loss: 0.3395 Test MSE Loss: 0.2582
Validation loss decreased (0.342068 --> 0.339527).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2565023
	speed: 0.0670s/iter; left time: 681.7447s
Epoch: 5 cost time: 7.322322130203247
Epoch: 5, Steps: 107 Train Loss: 0.2598 (Forecasting Loss:0.2565 + XiCon Loss:3.2216 x Lambda(0.001)), Vali MSE Loss: 0.3442 Test MSE Loss: 0.2690
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2652166
	speed: 0.0748s/iter; left time: 753.1831s
Epoch: 6 cost time: 8.05374002456665
Epoch: 6, Steps: 107 Train Loss: 0.2569 (Forecasting Loss:0.2536 + XiCon Loss:3.2208 x Lambda(0.001)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2789
Validation loss decreased (0.339527 --> 0.337436).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2574613
	speed: 0.0756s/iter; left time: 752.5968s
Epoch: 7 cost time: 8.195785522460938
Epoch: 7, Steps: 107 Train Loss: 0.2550 (Forecasting Loss:0.2518 + XiCon Loss:3.2205 x Lambda(0.001)), Vali MSE Loss: 0.3428 Test MSE Loss: 0.2752
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2467488
	speed: 0.0702s/iter; left time: 691.9037s
Epoch: 8 cost time: 7.631899118423462
Epoch: 8, Steps: 107 Train Loss: 0.2543 (Forecasting Loss:0.2511 + XiCon Loss:3.2207 x Lambda(0.001)), Vali MSE Loss: 0.3438 Test MSE Loss: 0.2726
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2465893
	speed: 0.0705s/iter; left time: 687.1376s
Epoch: 9 cost time: 7.627668142318726
Epoch: 9, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2505 + XiCon Loss:3.2215 x Lambda(0.001)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.2786
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2568872
	speed: 0.0783s/iter; left time: 754.2895s
Epoch: 10 cost time: 8.403183937072754
Epoch: 10, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2505 + XiCon Loss:3.2210 x Lambda(0.001)), Vali MSE Loss: 0.3431 Test MSE Loss: 0.2747
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2539453
	speed: 0.0767s/iter; left time: 730.9102s
Epoch: 11 cost time: 8.253487586975098
Epoch: 11, Steps: 107 Train Loss: 0.2532 (Forecasting Loss:0.2500 + XiCon Loss:3.2209 x Lambda(0.001)), Vali MSE Loss: 0.3434 Test MSE Loss: 0.2747
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2417569
	speed: 0.0736s/iter; left time: 693.4351s
Epoch: 12 cost time: 7.748591184616089
Epoch: 12, Steps: 107 Train Loss: 0.2531 (Forecasting Loss:0.2499 + XiCon Loss:3.2207 x Lambda(0.001)), Vali MSE Loss: 0.3433 Test MSE Loss: 0.2757
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2412967
	speed: 0.0401s/iter; left time: 374.0697s
Epoch: 13 cost time: 4.315170526504517
Epoch: 13, Steps: 107 Train Loss: 0.2534 (Forecasting Loss:0.2502 + XiCon Loss:3.2209 x Lambda(0.001)), Vali MSE Loss: 0.3438 Test MSE Loss: 0.2749
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2545063
	speed: 0.0732s/iter; left time: 674.2182s
Epoch: 14 cost time: 7.873255491256714
Epoch: 14, Steps: 107 Train Loss: 0.2535 (Forecasting Loss:0.2503 + XiCon Loss:3.2205 x Lambda(0.001)), Vali MSE Loss: 0.3434 Test MSE Loss: 0.2749
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2593155
	speed: 0.0740s/iter; left time: 673.9357s
Epoch: 15 cost time: 7.98554253578186
Epoch: 15, Steps: 107 Train Loss: 0.2538 (Forecasting Loss:0.2505 + XiCon Loss:3.2213 x Lambda(0.001)), Vali MSE Loss: 0.3432 Test MSE Loss: 0.2749
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2628406
	speed: 0.0750s/iter; left time: 674.4984s
Epoch: 16 cost time: 8.08156943321228
Epoch: 16, Steps: 107 Train Loss: 0.2535 (Forecasting Loss:0.2502 + XiCon Loss:3.2210 x Lambda(0.001)), Vali MSE Loss: 0.3433 Test MSE Loss: 0.2749
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1969899833202362, mae:0.3607300817966461, mape:0.6069802045822144, mspe:13.121988296508789 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4847
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5387215
	speed: 0.0523s/iter; left time: 554.6780s
Epoch: 1 cost time: 5.6900763511657715
Epoch: 1, Steps: 107 Train Loss: 0.6202 (Forecasting Loss:0.6170 + XiCon Loss:3.2094 x Lambda(0.001)), Vali MSE Loss: 0.5716 Test MSE Loss: 0.4330
Validation loss decreased (inf --> 0.571577).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2809460
	speed: 0.0414s/iter; left time: 434.0423s
Epoch: 2 cost time: 4.5113255977630615
Epoch: 2, Steps: 107 Train Loss: 0.3454 (Forecasting Loss:0.3422 + XiCon Loss:3.1990 x Lambda(0.001)), Vali MSE Loss: 0.3897 Test MSE Loss: 0.2620
Validation loss decreased (0.571577 --> 0.389652).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2624699
	speed: 0.0815s/iter; left time: 846.8069s
Epoch: 3 cost time: 8.80873727798462
Epoch: 3, Steps: 107 Train Loss: 0.2681 (Forecasting Loss:0.2650 + XiCon Loss:3.1662 x Lambda(0.001)), Vali MSE Loss: 0.3655 Test MSE Loss: 0.2780
Validation loss decreased (0.389652 --> 0.365461).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2600128
	speed: 0.0819s/iter; left time: 842.1071s
Epoch: 4 cost time: 8.771229028701782
Epoch: 4, Steps: 107 Train Loss: 0.2559 (Forecasting Loss:0.2528 + XiCon Loss:3.1523 x Lambda(0.001)), Vali MSE Loss: 0.3548 Test MSE Loss: 0.2674
Validation loss decreased (0.365461 --> 0.354788).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2467293
	speed: 0.0814s/iter; left time: 828.0948s
Epoch: 5 cost time: 8.730448246002197
Epoch: 5, Steps: 107 Train Loss: 0.2508 (Forecasting Loss:0.2476 + XiCon Loss:3.1473 x Lambda(0.001)), Vali MSE Loss: 0.3630 Test MSE Loss: 0.2575
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2486831
	speed: 0.0671s/iter; left time: 675.2129s
Epoch: 6 cost time: 7.03401780128479
Epoch: 6, Steps: 107 Train Loss: 0.2484 (Forecasting Loss:0.2452 + XiCon Loss:3.1448 x Lambda(0.001)), Vali MSE Loss: 0.3504 Test MSE Loss: 0.2621
Validation loss decreased (0.354788 --> 0.350424).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2577179
	speed: 0.0513s/iter; left time: 510.8119s
Epoch: 7 cost time: 5.7239930629730225
Epoch: 7, Steps: 107 Train Loss: 0.2469 (Forecasting Loss:0.2438 + XiCon Loss:3.1441 x Lambda(0.001)), Vali MSE Loss: 0.3516 Test MSE Loss: 0.2566
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2361633
	speed: 0.0800s/iter; left time: 788.2223s
Epoch: 8 cost time: 8.654226541519165
Epoch: 8, Steps: 107 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.1431 x Lambda(0.001)), Vali MSE Loss: 0.3525 Test MSE Loss: 0.2594
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2365414
	speed: 0.0818s/iter; left time: 797.3363s
Epoch: 9 cost time: 8.803894758224487
Epoch: 9, Steps: 107 Train Loss: 0.2460 (Forecasting Loss:0.2429 + XiCon Loss:3.1448 x Lambda(0.001)), Vali MSE Loss: 0.3506 Test MSE Loss: 0.2625
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2319890
	speed: 0.0805s/iter; left time: 775.5174s
Epoch: 10 cost time: 8.561457395553589
Epoch: 10, Steps: 107 Train Loss: 0.2459 (Forecasting Loss:0.2428 + XiCon Loss:3.1425 x Lambda(0.001)), Vali MSE Loss: 0.3500 Test MSE Loss: 0.2607
Validation loss decreased (0.350424 --> 0.350044).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2468741
	speed: 0.0560s/iter; left time: 533.7306s
Epoch: 11 cost time: 5.935250282287598
Epoch: 11, Steps: 107 Train Loss: 0.2458 (Forecasting Loss:0.2427 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.3492 Test MSE Loss: 0.2605
Validation loss decreased (0.350044 --> 0.349152).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2400789
	speed: 0.0755s/iter; left time: 711.9012s
Epoch: 12 cost time: 8.2143075466156
Epoch: 12, Steps: 107 Train Loss: 0.2458 (Forecasting Loss:0.2426 + XiCon Loss:3.1422 x Lambda(0.001)), Vali MSE Loss: 0.3495 Test MSE Loss: 0.2608
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2563872
	speed: 0.0795s/iter; left time: 740.5446s
Epoch: 13 cost time: 8.556223630905151
Epoch: 13, Steps: 107 Train Loss: 0.2456 (Forecasting Loss:0.2425 + XiCon Loss:3.1434 x Lambda(0.001)), Vali MSE Loss: 0.3496 Test MSE Loss: 0.2608
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2510550
	speed: 0.0836s/iter; left time: 769.8609s
Epoch: 14 cost time: 8.912677764892578
Epoch: 14, Steps: 107 Train Loss: 0.2457 (Forecasting Loss:0.2426 + XiCon Loss:3.1419 x Lambda(0.001)), Vali MSE Loss: 0.3495 Test MSE Loss: 0.2607
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2488780
	speed: 0.0766s/iter; left time: 697.5687s
Epoch: 15 cost time: 8.240846395492554
Epoch: 15, Steps: 107 Train Loss: 0.2458 (Forecasting Loss:0.2426 + XiCon Loss:3.1423 x Lambda(0.001)), Vali MSE Loss: 0.3497 Test MSE Loss: 0.2606
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2546275
	speed: 0.0443s/iter; left time: 398.7504s
Epoch: 16 cost time: 4.830969572067261
Epoch: 16, Steps: 107 Train Loss: 0.2457 (Forecasting Loss:0.2425 + XiCon Loss:3.1432 x Lambda(0.001)), Vali MSE Loss: 0.3501 Test MSE Loss: 0.2606
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2552312
	speed: 0.0839s/iter; left time: 745.4737s
Epoch: 17 cost time: 8.988813877105713
Epoch: 17, Steps: 107 Train Loss: 0.2457 (Forecasting Loss:0.2425 + XiCon Loss:3.1424 x Lambda(0.001)), Vali MSE Loss: 0.3499 Test MSE Loss: 0.2607
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2317732
	speed: 0.0810s/iter; left time: 711.2218s
Epoch: 18 cost time: 8.692964315414429
Epoch: 18, Steps: 107 Train Loss: 0.2456 (Forecasting Loss:0.2425 + XiCon Loss:3.1420 x Lambda(0.001)), Vali MSE Loss: 0.3497 Test MSE Loss: 0.2607
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2408789
	speed: 0.0785s/iter; left time: 681.0815s
Epoch: 19 cost time: 8.466719150543213
Epoch: 19, Steps: 107 Train Loss: 0.2456 (Forecasting Loss:0.2424 + XiCon Loss:3.1419 x Lambda(0.001)), Vali MSE Loss: 0.3494 Test MSE Loss: 0.2607
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.2420138
	speed: 0.0653s/iter; left time: 559.8948s
Epoch: 20 cost time: 6.882223606109619
Epoch: 20, Steps: 107 Train Loss: 0.2457 (Forecasting Loss:0.2425 + XiCon Loss:3.1429 x Lambda(0.001)), Vali MSE Loss: 0.3494 Test MSE Loss: 0.2607
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.2543995
	speed: 0.0639s/iter; left time: 540.5142s
Epoch: 21 cost time: 7.0182740688323975
Epoch: 21, Steps: 107 Train Loss: 0.2457 (Forecasting Loss:0.2426 + XiCon Loss:3.1433 x Lambda(0.001)), Vali MSE Loss: 0.3494 Test MSE Loss: 0.2607
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17875544726848602, mae:0.34230759739875793, mape:0.6087542176246643, mspe:14.978363990783691 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1718+-0.02124, MAE:0.3361+-0.02047, MAPE:0.6281+-0.04006, MSPE:16.1129+-3.41133, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3877
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.595279216766357
Epoch: 1, Steps: 96 Train Loss: 1.2979 (Forecasting Loss:0.9746 + XiCon Loss:3.2321 x Lambda(0.1)), Vali MSE Loss: 0.6605 Test MSE Loss: 0.9194
Validation loss decreased (inf --> 0.660522).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.416111707687378
Epoch: 2, Steps: 96 Train Loss: 1.0689 (Forecasting Loss:0.7475 + XiCon Loss:3.2136 x Lambda(0.1)), Vali MSE Loss: 0.6159 Test MSE Loss: 0.2712
Validation loss decreased (0.660522 --> 0.615938).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.067763805389404
Epoch: 3, Steps: 96 Train Loss: 0.8783 (Forecasting Loss:0.5570 + XiCon Loss:3.2134 x Lambda(0.1)), Vali MSE Loss: 0.5599 Test MSE Loss: 0.2551
Validation loss decreased (0.615938 --> 0.559863).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.890332460403442
Epoch: 4, Steps: 96 Train Loss: 0.8425 (Forecasting Loss:0.5220 + XiCon Loss:3.2048 x Lambda(0.1)), Vali MSE Loss: 0.5160 Test MSE Loss: 0.2578
Validation loss decreased (0.559863 --> 0.516012).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.221187591552734
Epoch: 5, Steps: 96 Train Loss: 0.8272 (Forecasting Loss:0.5072 + XiCon Loss:3.2004 x Lambda(0.1)), Vali MSE Loss: 0.5022 Test MSE Loss: 0.2571
Validation loss decreased (0.516012 --> 0.502247).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.51045823097229
Epoch: 6, Steps: 96 Train Loss: 0.8199 (Forecasting Loss:0.4999 + XiCon Loss:3.1995 x Lambda(0.1)), Vali MSE Loss: 0.4909 Test MSE Loss: 0.2639
Validation loss decreased (0.502247 --> 0.490904).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.228169679641724
Epoch: 7, Steps: 96 Train Loss: 0.8165 (Forecasting Loss:0.4968 + XiCon Loss:3.1972 x Lambda(0.1)), Vali MSE Loss: 0.4953 Test MSE Loss: 0.2591
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.292280912399292
Epoch: 8, Steps: 96 Train Loss: 0.8138 (Forecasting Loss:0.4942 + XiCon Loss:3.1964 x Lambda(0.1)), Vali MSE Loss: 0.4901 Test MSE Loss: 0.2616
Validation loss decreased (0.490904 --> 0.490081).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.414271831512451
Epoch: 9, Steps: 96 Train Loss: 0.8129 (Forecasting Loss:0.4933 + XiCon Loss:3.1957 x Lambda(0.1)), Vali MSE Loss: 0.4908 Test MSE Loss: 0.2611
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.293673038482666
Epoch: 10, Steps: 96 Train Loss: 0.8130 (Forecasting Loss:0.4935 + XiCon Loss:3.1950 x Lambda(0.1)), Vali MSE Loss: 0.4905 Test MSE Loss: 0.2610
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.359333038330078
Epoch: 11, Steps: 96 Train Loss: 0.8129 (Forecasting Loss:0.4933 + XiCon Loss:3.1960 x Lambda(0.1)), Vali MSE Loss: 0.4899 Test MSE Loss: 0.2611
Validation loss decreased (0.490081 --> 0.489883).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.575561285018921
Epoch: 12, Steps: 96 Train Loss: 0.8124 (Forecasting Loss:0.4929 + XiCon Loss:3.1956 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2613
Validation loss decreased (0.489883 --> 0.489651).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.285797595977783
Epoch: 13, Steps: 96 Train Loss: 0.8119 (Forecasting Loss:0.4924 + XiCon Loss:3.1957 x Lambda(0.1)), Vali MSE Loss: 0.4899 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.792435646057129
Epoch: 14, Steps: 96 Train Loss: 0.8118 (Forecasting Loss:0.4923 + XiCon Loss:3.1956 x Lambda(0.1)), Vali MSE Loss: 0.4894 Test MSE Loss: 0.2614
Validation loss decreased (0.489651 --> 0.489409).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.077885627746582
Epoch: 15, Steps: 96 Train Loss: 0.8118 (Forecasting Loss:0.4922 + XiCon Loss:3.1955 x Lambda(0.1)), Vali MSE Loss: 0.4892 Test MSE Loss: 0.2614
Validation loss decreased (0.489409 --> 0.489244).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 5.495923042297363
Epoch: 16, Steps: 96 Train Loss: 0.8115 (Forecasting Loss:0.4919 + XiCon Loss:3.1956 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 5.452438592910767
Epoch: 17, Steps: 96 Train Loss: 0.8123 (Forecasting Loss:0.4928 + XiCon Loss:3.1958 x Lambda(0.1)), Vali MSE Loss: 0.4892 Test MSE Loss: 0.2614
Validation loss decreased (0.489244 --> 0.489209).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 5.549861192703247
Epoch: 18, Steps: 96 Train Loss: 0.8112 (Forecasting Loss:0.4915 + XiCon Loss:3.1964 x Lambda(0.1)), Vali MSE Loss: 0.4894 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 5.265595197677612
Epoch: 19, Steps: 96 Train Loss: 0.8119 (Forecasting Loss:0.4923 + XiCon Loss:3.1960 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2614
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.920371055603027
Epoch: 20, Steps: 96 Train Loss: 0.8114 (Forecasting Loss:0.4918 + XiCon Loss:3.1959 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2614
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 5.308214426040649
Epoch: 21, Steps: 96 Train Loss: 0.8115 (Forecasting Loss:0.4919 + XiCon Loss:3.1952 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2614
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 5.335598468780518
Epoch: 22, Steps: 96 Train Loss: 0.8125 (Forecasting Loss:0.4929 + XiCon Loss:3.1961 x Lambda(0.1)), Vali MSE Loss: 0.4891 Test MSE Loss: 0.2614
Validation loss decreased (0.489209 --> 0.489130).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 5.289336442947388
Epoch: 23, Steps: 96 Train Loss: 0.8122 (Forecasting Loss:0.4926 + XiCon Loss:3.1962 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 5.464111328125
Epoch: 24, Steps: 96 Train Loss: 0.8126 (Forecasting Loss:0.4931 + XiCon Loss:3.1958 x Lambda(0.1)), Vali MSE Loss: 0.4899 Test MSE Loss: 0.2614
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.666991710662842
Epoch: 25, Steps: 96 Train Loss: 0.8116 (Forecasting Loss:0.4919 + XiCon Loss:3.1969 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2614
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 5.441668272018433
Epoch: 26, Steps: 96 Train Loss: 0.8112 (Forecasting Loss:0.4917 + XiCon Loss:3.1951 x Lambda(0.1)), Vali MSE Loss: 0.4894 Test MSE Loss: 0.2614
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 5.4648191928863525
Epoch: 27, Steps: 96 Train Loss: 0.8108 (Forecasting Loss:0.4913 + XiCon Loss:3.1955 x Lambda(0.1)), Vali MSE Loss: 0.4900 Test MSE Loss: 0.2614
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 5.64259147644043
Epoch: 28, Steps: 96 Train Loss: 0.8128 (Forecasting Loss:0.4932 + XiCon Loss:3.1955 x Lambda(0.1)), Vali MSE Loss: 0.4894 Test MSE Loss: 0.2614
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 5.559430837631226
Epoch: 29, Steps: 96 Train Loss: 0.8117 (Forecasting Loss:0.4922 + XiCon Loss:3.1950 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2614
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.8088297843933105
Epoch: 30, Steps: 96 Train Loss: 0.8109 (Forecasting Loss:0.4913 + XiCon Loss:3.1960 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2614
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 5.340949535369873
Epoch: 31, Steps: 96 Train Loss: 0.8122 (Forecasting Loss:0.4927 + XiCon Loss:3.1954 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2614
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 5.499432802200317
Epoch: 32, Steps: 96 Train Loss: 0.8115 (Forecasting Loss:0.4919 + XiCon Loss:3.1960 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2614
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.18331259489059448, mae:0.3394155204296112, mape:0.6758632063865662, mspe:20.979881286621094 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3941
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.2697062492370605
Epoch: 1, Steps: 96 Train Loss: 1.2947 (Forecasting Loss:0.9712 + XiCon Loss:3.2343 x Lambda(0.1)), Vali MSE Loss: 0.6861 Test MSE Loss: 0.9599
Validation loss decreased (inf --> 0.686148).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.582784175872803
Epoch: 2, Steps: 96 Train Loss: 1.1216 (Forecasting Loss:0.8000 + XiCon Loss:3.2156 x Lambda(0.1)), Vali MSE Loss: 0.5787 Test MSE Loss: 0.4626
Validation loss decreased (0.686148 --> 0.578729).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.613145589828491
Epoch: 3, Steps: 96 Train Loss: 0.9167 (Forecasting Loss:0.5970 + XiCon Loss:3.1967 x Lambda(0.1)), Vali MSE Loss: 0.4857 Test MSE Loss: 0.3096
Validation loss decreased (0.578729 --> 0.485659).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.441712379455566
Epoch: 4, Steps: 96 Train Loss: 0.8237 (Forecasting Loss:0.5052 + XiCon Loss:3.1851 x Lambda(0.1)), Vali MSE Loss: 0.4863 Test MSE Loss: 0.3182
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.595804691314697
Epoch: 5, Steps: 96 Train Loss: 0.8018 (Forecasting Loss:0.4841 + XiCon Loss:3.1775 x Lambda(0.1)), Vali MSE Loss: 0.4883 Test MSE Loss: 0.3247
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.393687725067139
Epoch: 6, Steps: 96 Train Loss: 0.7932 (Forecasting Loss:0.4758 + XiCon Loss:3.1744 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3372
Validation loss decreased (0.485659 --> 0.481707).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.736920595169067
Epoch: 7, Steps: 96 Train Loss: 0.7908 (Forecasting Loss:0.4737 + XiCon Loss:3.1708 x Lambda(0.1)), Vali MSE Loss: 0.4830 Test MSE Loss: 0.3320
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.655633926391602
Epoch: 8, Steps: 96 Train Loss: 0.7875 (Forecasting Loss:0.4704 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3365
Validation loss decreased (0.481707 --> 0.480786).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.1272923946380615
Epoch: 9, Steps: 96 Train Loss: 0.7859 (Forecasting Loss:0.4688 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3402
Validation loss decreased (0.480786 --> 0.480732).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.517122268676758
Epoch: 10, Steps: 96 Train Loss: 0.7862 (Forecasting Loss:0.4691 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.4809 Test MSE Loss: 0.3333
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.540213584899902
Epoch: 11, Steps: 96 Train Loss: 0.7835 (Forecasting Loss:0.4664 + XiCon Loss:3.1711 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3352
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.206565856933594
Epoch: 12, Steps: 96 Train Loss: 0.7868 (Forecasting Loss:0.4696 + XiCon Loss:3.1718 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3356
Validation loss decreased (0.480732 --> 0.480503).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.34298849105835
Epoch: 13, Steps: 96 Train Loss: 0.7860 (Forecasting Loss:0.4689 + XiCon Loss:3.1707 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3360
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.755564212799072
Epoch: 14, Steps: 96 Train Loss: 0.7847 (Forecasting Loss:0.4677 + XiCon Loss:3.1701 x Lambda(0.1)), Vali MSE Loss: 0.4819 Test MSE Loss: 0.3360
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.6529741287231445
Epoch: 15, Steps: 96 Train Loss: 0.7855 (Forecasting Loss:0.4684 + XiCon Loss:3.1717 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3362
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 5.684996128082275
Epoch: 16, Steps: 96 Train Loss: 0.7851 (Forecasting Loss:0.4680 + XiCon Loss:3.1708 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3362
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 5.284467458724976
Epoch: 17, Steps: 96 Train Loss: 0.7861 (Forecasting Loss:0.4690 + XiCon Loss:3.1712 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3362
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 5.431623220443726
Epoch: 18, Steps: 96 Train Loss: 0.7858 (Forecasting Loss:0.4688 + XiCon Loss:3.1702 x Lambda(0.1)), Vali MSE Loss: 0.4814 Test MSE Loss: 0.3362
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.886593341827393
Epoch: 19, Steps: 96 Train Loss: 0.7876 (Forecasting Loss:0.4704 + XiCon Loss:3.1725 x Lambda(0.1)), Vali MSE Loss: 0.4804 Test MSE Loss: 0.3362
Validation loss decreased (0.480503 --> 0.480429).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 5.301129579544067
Epoch: 20, Steps: 96 Train Loss: 0.7854 (Forecasting Loss:0.4681 + XiCon Loss:3.1727 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3362
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 5.686910390853882
Epoch: 21, Steps: 96 Train Loss: 0.7843 (Forecasting Loss:0.4672 + XiCon Loss:3.1714 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3362
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 5.322565078735352
Epoch: 22, Steps: 96 Train Loss: 0.7873 (Forecasting Loss:0.4701 + XiCon Loss:3.1718 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3362
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 5.318991422653198
Epoch: 23, Steps: 96 Train Loss: 0.7848 (Forecasting Loss:0.4679 + XiCon Loss:3.1698 x Lambda(0.1)), Vali MSE Loss: 0.4806 Test MSE Loss: 0.3362
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.846558094024658
Epoch: 24, Steps: 96 Train Loss: 0.7858 (Forecasting Loss:0.4687 + XiCon Loss:3.1714 x Lambda(0.1)), Vali MSE Loss: 0.4795 Test MSE Loss: 0.3362
Validation loss decreased (0.480429 --> 0.479524).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 5.259762525558472
Epoch: 25, Steps: 96 Train Loss: 0.7859 (Forecasting Loss:0.4689 + XiCon Loss:3.1700 x Lambda(0.1)), Vali MSE Loss: 0.4798 Test MSE Loss: 0.3362
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 5.397019624710083
Epoch: 26, Steps: 96 Train Loss: 0.7858 (Forecasting Loss:0.4686 + XiCon Loss:3.1720 x Lambda(0.1)), Vali MSE Loss: 0.4809 Test MSE Loss: 0.3362
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 5.440721035003662
Epoch: 27, Steps: 96 Train Loss: 0.7868 (Forecasting Loss:0.4697 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3362
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 5.317781209945679
Epoch: 28, Steps: 96 Train Loss: 0.7868 (Forecasting Loss:0.4698 + XiCon Loss:3.1705 x Lambda(0.1)), Vali MSE Loss: 0.4801 Test MSE Loss: 0.3362
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 4.919475555419922
Epoch: 29, Steps: 96 Train Loss: 0.7857 (Forecasting Loss:0.4685 + XiCon Loss:3.1719 x Lambda(0.1)), Vali MSE Loss: 0.4815 Test MSE Loss: 0.3362
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.649751663208008
Epoch: 30, Steps: 96 Train Loss: 0.7849 (Forecasting Loss:0.4678 + XiCon Loss:3.1708 x Lambda(0.1)), Vali MSE Loss: 0.4793 Test MSE Loss: 0.3362
Validation loss decreased (0.479524 --> 0.479262).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 5.354310035705566
Epoch: 31, Steps: 96 Train Loss: 0.7867 (Forecasting Loss:0.4696 + XiCon Loss:3.1710 x Lambda(0.1)), Vali MSE Loss: 0.4795 Test MSE Loss: 0.3362
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 5.556139707565308
Epoch: 32, Steps: 96 Train Loss: 0.7837 (Forecasting Loss:0.4667 + XiCon Loss:3.1707 x Lambda(0.1)), Vali MSE Loss: 0.4819 Test MSE Loss: 0.3362
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 5.22697114944458
Epoch: 33, Steps: 96 Train Loss: 0.7845 (Forecasting Loss:0.4672 + XiCon Loss:3.1724 x Lambda(0.1)), Vali MSE Loss: 0.4827 Test MSE Loss: 0.3362
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 5.212124347686768
Epoch: 34, Steps: 96 Train Loss: 0.7843 (Forecasting Loss:0.4671 + XiCon Loss:3.1719 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3362
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 4.80362343788147
Epoch: 35, Steps: 96 Train Loss: 0.7857 (Forecasting Loss:0.4687 + XiCon Loss:3.1702 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3362
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 5.5508034229278564
Epoch: 36, Steps: 96 Train Loss: 0.7860 (Forecasting Loss:0.4690 + XiCon Loss:3.1703 x Lambda(0.1)), Vali MSE Loss: 0.4812 Test MSE Loss: 0.3362
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 5.35590934753418
Epoch: 37, Steps: 96 Train Loss: 0.7853 (Forecasting Loss:0.4682 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3362
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 5.347963094711304
Epoch: 38, Steps: 96 Train Loss: 0.7855 (Forecasting Loss:0.4683 + XiCon Loss:3.1712 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3362
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 5.233771800994873
Epoch: 39, Steps: 96 Train Loss: 0.7855 (Forecasting Loss:0.4685 + XiCon Loss:3.1709 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3362
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 5.064363241195679
Epoch: 40, Steps: 96 Train Loss: 0.7853 (Forecasting Loss:0.4682 + XiCon Loss:3.1712 x Lambda(0.1)), Vali MSE Loss: 0.4828 Test MSE Loss: 0.3362
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2678911089897156, mae:0.40454772114753723, mape:0.7778903245925903, mspe:28.280227661132812 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3805
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.590168237686157
Epoch: 1, Steps: 96 Train Loss: 1.2594 (Forecasting Loss:0.9379 + XiCon Loss:3.2150 x Lambda(0.1)), Vali MSE Loss: 0.6600 Test MSE Loss: 0.8493
Validation loss decreased (inf --> 0.659952).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.482434988021851
Epoch: 2, Steps: 96 Train Loss: 1.0630 (Forecasting Loss:0.7436 + XiCon Loss:3.1941 x Lambda(0.1)), Vali MSE Loss: 0.5991 Test MSE Loss: 0.3514
Validation loss decreased (0.659952 --> 0.599091).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.3991522789001465
Epoch: 3, Steps: 96 Train Loss: 0.8759 (Forecasting Loss:0.5576 + XiCon Loss:3.1830 x Lambda(0.1)), Vali MSE Loss: 0.5629 Test MSE Loss: 0.2607
Validation loss decreased (0.599091 --> 0.562892).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.3835272789001465
Epoch: 4, Steps: 96 Train Loss: 0.8342 (Forecasting Loss:0.5161 + XiCon Loss:3.1809 x Lambda(0.1)), Vali MSE Loss: 0.6200 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.660549640655518
Epoch: 5, Steps: 96 Train Loss: 0.8206 (Forecasting Loss:0.5027 + XiCon Loss:3.1790 x Lambda(0.1)), Vali MSE Loss: 0.5316 Test MSE Loss: 0.2853
Validation loss decreased (0.562892 --> 0.531553).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.913381576538086
Epoch: 6, Steps: 96 Train Loss: 0.8123 (Forecasting Loss:0.4944 + XiCon Loss:3.1792 x Lambda(0.1)), Vali MSE Loss: 0.5269 Test MSE Loss: 0.2916
Validation loss decreased (0.531553 --> 0.526927).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.480651378631592
Epoch: 7, Steps: 96 Train Loss: 0.8088 (Forecasting Loss:0.4910 + XiCon Loss:3.1779 x Lambda(0.1)), Vali MSE Loss: 0.5319 Test MSE Loss: 0.2861
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.446274280548096
Epoch: 8, Steps: 96 Train Loss: 0.8080 (Forecasting Loss:0.4901 + XiCon Loss:3.1785 x Lambda(0.1)), Vali MSE Loss: 0.5340 Test MSE Loss: 0.2841
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.15418004989624
Epoch: 9, Steps: 96 Train Loss: 0.8054 (Forecasting Loss:0.4875 + XiCon Loss:3.1785 x Lambda(0.1)), Vali MSE Loss: 0.5344 Test MSE Loss: 0.2846
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.937894105911255
Epoch: 10, Steps: 96 Train Loss: 0.8053 (Forecasting Loss:0.4874 + XiCon Loss:3.1783 x Lambda(0.1)), Vali MSE Loss: 0.5369 Test MSE Loss: 0.2844
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.519871711730957
Epoch: 11, Steps: 96 Train Loss: 0.8052 (Forecasting Loss:0.4874 + XiCon Loss:3.1786 x Lambda(0.1)), Vali MSE Loss: 0.5342 Test MSE Loss: 0.2850
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.405934572219849
Epoch: 12, Steps: 96 Train Loss: 0.8044 (Forecasting Loss:0.4866 + XiCon Loss:3.1781 x Lambda(0.1)), Vali MSE Loss: 0.5328 Test MSE Loss: 0.2858
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.333666086196899
Epoch: 13, Steps: 96 Train Loss: 0.8049 (Forecasting Loss:0.4870 + XiCon Loss:3.1785 x Lambda(0.1)), Vali MSE Loss: 0.5337 Test MSE Loss: 0.2858
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.299484968185425
Epoch: 14, Steps: 96 Train Loss: 0.8043 (Forecasting Loss:0.4865 + XiCon Loss:3.1788 x Lambda(0.1)), Vali MSE Loss: 0.5333 Test MSE Loss: 0.2858
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.728756904602051
Epoch: 15, Steps: 96 Train Loss: 0.8055 (Forecasting Loss:0.4876 + XiCon Loss:3.1793 x Lambda(0.1)), Vali MSE Loss: 0.5337 Test MSE Loss: 0.2858
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.686461448669434
Epoch: 16, Steps: 96 Train Loss: 0.8053 (Forecasting Loss:0.4876 + XiCon Loss:3.1776 x Lambda(0.1)), Vali MSE Loss: 0.5349 Test MSE Loss: 0.2858
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.21684448421001434, mae:0.36644455790519714, mape:0.7308550477027893, mspe:24.55910873413086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4480
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.354971885681152
Epoch: 1, Steps: 96 Train Loss: 1.2456 (Forecasting Loss:0.9244 + XiCon Loss:3.2123 x Lambda(0.1)), Vali MSE Loss: 0.6505 Test MSE Loss: 0.8092
Validation loss decreased (inf --> 0.650496).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 5.377564430236816
Epoch: 2, Steps: 96 Train Loss: 1.1221 (Forecasting Loss:0.8014 + XiCon Loss:3.2069 x Lambda(0.1)), Vali MSE Loss: 0.5669 Test MSE Loss: 0.4015
Validation loss decreased (0.650496 --> 0.566864).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.423290491104126
Epoch: 3, Steps: 96 Train Loss: 0.8815 (Forecasting Loss:0.5609 + XiCon Loss:3.2064 x Lambda(0.1)), Vali MSE Loss: 0.6605 Test MSE Loss: 0.2759
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.427556037902832
Epoch: 4, Steps: 96 Train Loss: 0.8163 (Forecasting Loss:0.4963 + XiCon Loss:3.1999 x Lambda(0.1)), Vali MSE Loss: 0.5492 Test MSE Loss: 0.2849
Validation loss decreased (0.566864 --> 0.549189).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.5300726890563965
Epoch: 5, Steps: 96 Train Loss: 0.7964 (Forecasting Loss:0.4767 + XiCon Loss:3.1971 x Lambda(0.1)), Vali MSE Loss: 0.5665 Test MSE Loss: 0.2828
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.302679061889648
Epoch: 6, Steps: 96 Train Loss: 0.7890 (Forecasting Loss:0.4694 + XiCon Loss:3.1961 x Lambda(0.1)), Vali MSE Loss: 0.5702 Test MSE Loss: 0.2822
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.602644205093384
Epoch: 7, Steps: 96 Train Loss: 0.7834 (Forecasting Loss:0.4638 + XiCon Loss:3.1955 x Lambda(0.1)), Vali MSE Loss: 0.5578 Test MSE Loss: 0.2858
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.400833606719971
Epoch: 8, Steps: 96 Train Loss: 0.7813 (Forecasting Loss:0.4619 + XiCon Loss:3.1937 x Lambda(0.1)), Vali MSE Loss: 0.5590 Test MSE Loss: 0.2859
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.352945804595947
Epoch: 9, Steps: 96 Train Loss: 0.7808 (Forecasting Loss:0.4614 + XiCon Loss:3.1941 x Lambda(0.1)), Vali MSE Loss: 0.5551 Test MSE Loss: 0.2876
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.982518911361694
Epoch: 10, Steps: 96 Train Loss: 0.7813 (Forecasting Loss:0.4618 + XiCon Loss:3.1952 x Lambda(0.1)), Vali MSE Loss: 0.5543 Test MSE Loss: 0.2881
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.243314504623413
Epoch: 11, Steps: 96 Train Loss: 0.7819 (Forecasting Loss:0.4625 + XiCon Loss:3.1947 x Lambda(0.1)), Vali MSE Loss: 0.5555 Test MSE Loss: 0.2876
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.272623300552368
Epoch: 12, Steps: 96 Train Loss: 0.7808 (Forecasting Loss:0.4614 + XiCon Loss:3.1940 x Lambda(0.1)), Vali MSE Loss: 0.5560 Test MSE Loss: 0.2875
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.252288103103638
Epoch: 13, Steps: 96 Train Loss: 0.7804 (Forecasting Loss:0.4609 + XiCon Loss:3.1948 x Lambda(0.1)), Vali MSE Loss: 0.5550 Test MSE Loss: 0.2874
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.3589513301849365
Epoch: 14, Steps: 96 Train Loss: 0.7792 (Forecasting Loss:0.4597 + XiCon Loss:3.1950 x Lambda(0.1)), Vali MSE Loss: 0.5549 Test MSE Loss: 0.2875
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2080511748790741, mae:0.36165305972099304, mape:0.683010995388031, mspe:21.016372680664062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3901
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.066030263900757
Epoch: 1, Steps: 96 Train Loss: 1.2352 (Forecasting Loss:0.9104 + XiCon Loss:3.2488 x Lambda(0.1)), Vali MSE Loss: 0.6232 Test MSE Loss: 0.7929
Validation loss decreased (inf --> 0.623234).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.18615198135376
Epoch: 2, Steps: 96 Train Loss: 1.0503 (Forecasting Loss:0.7322 + XiCon Loss:3.1806 x Lambda(0.1)), Vali MSE Loss: 0.5156 Test MSE Loss: 0.2711
Validation loss decreased (0.623234 --> 0.515569).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.759185075759888
Epoch: 3, Steps: 96 Train Loss: 0.8419 (Forecasting Loss:0.5277 + XiCon Loss:3.1424 x Lambda(0.1)), Vali MSE Loss: 0.5523 Test MSE Loss: 0.2849
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.945838689804077
Epoch: 4, Steps: 96 Train Loss: 0.8057 (Forecasting Loss:0.4930 + XiCon Loss:3.1267 x Lambda(0.1)), Vali MSE Loss: 0.5276 Test MSE Loss: 0.3221
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 2.7793872356414795
Epoch: 5, Steps: 96 Train Loss: 0.7905 (Forecasting Loss:0.4784 + XiCon Loss:3.1215 x Lambda(0.1)), Vali MSE Loss: 0.5571 Test MSE Loss: 0.2949
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 2.5765035152435303
Epoch: 6, Steps: 96 Train Loss: 0.7844 (Forecasting Loss:0.4724 + XiCon Loss:3.1207 x Lambda(0.1)), Vali MSE Loss: 0.5302 Test MSE Loss: 0.3110
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 5.4287378787994385
Epoch: 7, Steps: 96 Train Loss: 0.7788 (Forecasting Loss:0.4668 + XiCon Loss:3.1196 x Lambda(0.1)), Vali MSE Loss: 0.5261 Test MSE Loss: 0.3212
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.231890678405762
Epoch: 8, Steps: 96 Train Loss: 0.7784 (Forecasting Loss:0.4665 + XiCon Loss:3.1183 x Lambda(0.1)), Vali MSE Loss: 0.5263 Test MSE Loss: 0.3180
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.147761106491089
Epoch: 9, Steps: 96 Train Loss: 0.7778 (Forecasting Loss:0.4660 + XiCon Loss:3.1175 x Lambda(0.1)), Vali MSE Loss: 0.5279 Test MSE Loss: 0.3174
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.405883312225342
Epoch: 10, Steps: 96 Train Loss: 0.7766 (Forecasting Loss:0.4647 + XiCon Loss:3.1189 x Lambda(0.1)), Vali MSE Loss: 0.5258 Test MSE Loss: 0.3188
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.108623266220093
Epoch: 11, Steps: 96 Train Loss: 0.7773 (Forecasting Loss:0.4655 + XiCon Loss:3.1188 x Lambda(0.1)), Vali MSE Loss: 0.5256 Test MSE Loss: 0.3198
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 3.949246644973755
Epoch: 12, Steps: 96 Train Loss: 0.7782 (Forecasting Loss:0.4665 + XiCon Loss:3.1177 x Lambda(0.1)), Vali MSE Loss: 0.5255 Test MSE Loss: 0.3199
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.19307473301887512, mae:0.3491102457046509, mape:0.6878136992454529, mspe:21.00591278076172 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2138+-0.04084, MAE:0.3642+-0.03093, MAPE:0.7111+-0.05349, MSPE:23.1683+-4.03121, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9106
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.0360184
	speed: 0.0634s/iter; left time: 1674.5849s
	iters: 200, epoch: 1 | loss: 33.4087791
	speed: 0.0488s/iter; left time: 1284.2826s
Epoch: 1 cost time: 13.565056085586548
Epoch: 1, Steps: 265 Train Loss: 34.1300 (Forecasting Loss:0.2124 + XiCon Loss:3.3918 x Lambda(10.0)), Vali MSE Loss: 0.1458 Test MSE Loss: 0.0981
Validation loss decreased (inf --> 0.145790).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.1306915
	speed: 0.0643s/iter; left time: 1679.7149s
	iters: 200, epoch: 2 | loss: 33.8834343
	speed: 0.0667s/iter; left time: 1736.7158s
Epoch: 2 cost time: 17.358422994613647
Epoch: 2, Steps: 265 Train Loss: 33.8688 (Forecasting Loss:0.1980 + XiCon Loss:3.3671 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0957
Validation loss decreased (0.145790 --> 0.144243).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.0280190
	speed: 0.0690s/iter; left time: 1786.1059s
	iters: 200, epoch: 3 | loss: 31.7656174
	speed: 0.0627s/iter; left time: 1615.4061s
Epoch: 3 cost time: 16.087714195251465
Epoch: 3, Steps: 265 Train Loss: 32.1628 (Forecasting Loss:0.1937 + XiCon Loss:3.1969 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0955
Validation loss decreased (0.144243 --> 0.143305).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.6175308
	speed: 0.0583s/iter; left time: 1492.8050s
	iters: 200, epoch: 4 | loss: 34.4521675
	speed: 0.0659s/iter; left time: 1680.9862s
Epoch: 4 cost time: 16.62224507331848
Epoch: 4, Steps: 265 Train Loss: 32.5113 (Forecasting Loss:0.1914 + XiCon Loss:3.2320 x Lambda(10.0)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0955
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.4061050
	speed: 0.0672s/iter; left time: 1703.7516s
	iters: 200, epoch: 5 | loss: 32.0718727
	speed: 0.0624s/iter; left time: 1575.2452s
Epoch: 5 cost time: 17.065155506134033
Epoch: 5, Steps: 265 Train Loss: 32.8477 (Forecasting Loss:0.1903 + XiCon Loss:3.2657 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0950
Validation loss decreased (0.143305 --> 0.142381).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.3384361
	speed: 0.0412s/iter; left time: 1033.0017s
	iters: 200, epoch: 6 | loss: 32.6945152
	speed: 0.0633s/iter; left time: 1582.1763s
Epoch: 6 cost time: 14.559253215789795
Epoch: 6, Steps: 265 Train Loss: 32.7302 (Forecasting Loss:0.1898 + XiCon Loss:3.2540 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
Validation loss decreased (0.142381 --> 0.141939).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.1753502
	speed: 0.0673s/iter; left time: 1670.3336s
	iters: 200, epoch: 7 | loss: 32.7265472
	speed: 0.0636s/iter; left time: 1570.4017s
Epoch: 7 cost time: 17.366223573684692
Epoch: 7, Steps: 265 Train Loss: 32.6775 (Forecasting Loss:0.1895 + XiCon Loss:3.2488 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 34.1626167
	speed: 0.0658s/iter; left time: 1614.6037s
	iters: 200, epoch: 8 | loss: 32.9164429
	speed: 0.0643s/iter; left time: 1572.4219s
Epoch: 8 cost time: 17.160303115844727
Epoch: 8, Steps: 265 Train Loss: 32.6427 (Forecasting Loss:0.1893 + XiCon Loss:3.2453 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.1011200
	speed: 0.0685s/iter; left time: 1664.1048s
	iters: 200, epoch: 9 | loss: 32.9365959
	speed: 0.0620s/iter; left time: 1499.0369s
Epoch: 9 cost time: 17.264132976531982
Epoch: 9, Steps: 265 Train Loss: 32.5984 (Forecasting Loss:0.1893 + XiCon Loss:3.2409 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.7184334
	speed: 0.0475s/iter; left time: 1140.2317s
	iters: 200, epoch: 10 | loss: 32.1033249
	speed: 0.0649s/iter; left time: 1551.8100s
Epoch: 10 cost time: 15.469769477844238
Epoch: 10, Steps: 265 Train Loss: 32.5911 (Forecasting Loss:0.1892 + XiCon Loss:3.2402 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.8454590
	speed: 0.0680s/iter; left time: 1615.6092s
	iters: 200, epoch: 11 | loss: 33.0718307
	speed: 0.0633s/iter; left time: 1496.8410s
Epoch: 11 cost time: 17.230780124664307
Epoch: 11, Steps: 265 Train Loss: 32.6815 (Forecasting Loss:0.1893 + XiCon Loss:3.2492 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.3514290
	speed: 0.0418s/iter; left time: 981.1910s
	iters: 200, epoch: 12 | loss: 32.9301147
	speed: 0.0497s/iter; left time: 1161.3590s
Epoch: 12 cost time: 13.282126188278198
Epoch: 12, Steps: 265 Train Loss: 32.6144 (Forecasting Loss:0.1892 + XiCon Loss:3.2425 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.0644379
	speed: 0.0676s/iter; left time: 1570.5038s
	iters: 200, epoch: 13 | loss: 34.2304878
	speed: 0.0638s/iter; left time: 1475.5817s
Epoch: 13 cost time: 17.290857553482056
Epoch: 13, Steps: 265 Train Loss: 32.6231 (Forecasting Loss:0.1892 + XiCon Loss:3.2434 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
Validation loss decreased (0.141939 --> 0.141864).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.8867683
	speed: 0.0603s/iter; left time: 1385.3159s
	iters: 200, epoch: 14 | loss: 32.5392990
	speed: 0.0381s/iter; left time: 869.7808s
Epoch: 14 cost time: 13.36644721031189
Epoch: 14, Steps: 265 Train Loss: 32.5817 (Forecasting Loss:0.1892 + XiCon Loss:3.2393 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.1382484
	speed: 0.0668s/iter; left time: 1515.6595s
	iters: 200, epoch: 15 | loss: 32.0857735
	speed: 0.0643s/iter; left time: 1453.5607s
Epoch: 15 cost time: 17.40136432647705
Epoch: 15, Steps: 265 Train Loss: 32.6449 (Forecasting Loss:0.1892 + XiCon Loss:3.2456 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4558449
	speed: 0.0668s/iter; left time: 1497.6289s
	iters: 200, epoch: 16 | loss: 32.6243515
	speed: 0.0533s/iter; left time: 1189.1218s
Epoch: 16 cost time: 14.489534139633179
Epoch: 16, Steps: 265 Train Loss: 32.5683 (Forecasting Loss:0.1891 + XiCon Loss:3.2379 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.3972397
	speed: 0.0657s/iter; left time: 1455.3086s
	iters: 200, epoch: 17 | loss: 32.6216393
	speed: 0.0612s/iter; left time: 1349.6671s
Epoch: 17 cost time: 16.84853982925415
Epoch: 17, Steps: 265 Train Loss: 32.5921 (Forecasting Loss:0.1891 + XiCon Loss:3.2403 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.7599869
	speed: 0.0687s/iter; left time: 1504.0898s
	iters: 200, epoch: 18 | loss: 33.0862045
	speed: 0.0609s/iter; left time: 1328.0269s
Epoch: 18 cost time: 16.098399877548218
Epoch: 18, Steps: 265 Train Loss: 32.6149 (Forecasting Loss:0.1891 + XiCon Loss:3.2426 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.9314079
	speed: 0.0507s/iter; left time: 1095.8232s
	iters: 200, epoch: 19 | loss: 33.3597450
	speed: 0.0627s/iter; left time: 1350.2157s
Epoch: 19 cost time: 15.474411725997925
Epoch: 19, Steps: 265 Train Loss: 32.6206 (Forecasting Loss:0.1892 + XiCon Loss:3.2431 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 34.1381989
	speed: 0.0667s/iter; left time: 1424.5691s
	iters: 200, epoch: 20 | loss: 31.7910748
	speed: 0.0619s/iter; left time: 1315.8386s
Epoch: 20 cost time: 16.79012441635132
Epoch: 20, Steps: 265 Train Loss: 32.6240 (Forecasting Loss:0.1891 + XiCon Loss:3.2435 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.2094765
	speed: 0.0417s/iter; left time: 879.7042s
	iters: 200, epoch: 21 | loss: 32.4819107
	speed: 0.0607s/iter; left time: 1275.3717s
Epoch: 21 cost time: 14.46058464050293
Epoch: 21, Steps: 265 Train Loss: 32.6221 (Forecasting Loss:0.1892 + XiCon Loss:3.2433 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.7326202
	speed: 0.0669s/iter; left time: 1393.3418s
	iters: 200, epoch: 22 | loss: 32.2552643
	speed: 0.0650s/iter; left time: 1348.0658s
Epoch: 22 cost time: 17.273509740829468
Epoch: 22, Steps: 265 Train Loss: 32.6170 (Forecasting Loss:0.1891 + XiCon Loss:3.2428 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.2000465
	speed: 0.0643s/iter; left time: 1321.7002s
	iters: 200, epoch: 23 | loss: 32.5153542
	speed: 0.0633s/iter; left time: 1295.3616s
Epoch: 23 cost time: 16.913217306137085
Epoch: 23, Steps: 265 Train Loss: 32.6594 (Forecasting Loss:0.1892 + XiCon Loss:3.2470 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039354439824819565, mae:0.14953452348709106, mape:0.11872539669275284, mspe:0.026369139552116394 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9699
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.1908989
	speed: 0.0608s/iter; left time: 1606.1348s
	iters: 200, epoch: 1 | loss: 33.1706390
	speed: 0.0613s/iter; left time: 1612.1292s
Epoch: 1 cost time: 16.025856256484985
Epoch: 1, Steps: 265 Train Loss: 34.0401 (Forecasting Loss:0.2101 + XiCon Loss:3.3830 x Lambda(10.0)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.0981
Validation loss decreased (inf --> 0.147526).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.0284767
	speed: 0.0690s/iter; left time: 1804.3397s
	iters: 200, epoch: 2 | loss: 34.0321617
	speed: 0.0605s/iter; left time: 1575.4263s
Epoch: 2 cost time: 16.90306329727173
Epoch: 2, Steps: 265 Train Loss: 33.6279 (Forecasting Loss:0.1982 + XiCon Loss:3.3430 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0980
Validation loss decreased (0.147526 --> 0.146464).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.7601662
	speed: 0.0646s/iter; left time: 1670.0530s
	iters: 200, epoch: 3 | loss: 33.3049393
	speed: 0.0618s/iter; left time: 1592.8846s
Epoch: 3 cost time: 16.79565978050232
Epoch: 3, Steps: 265 Train Loss: 33.2634 (Forecasting Loss:0.1936 + XiCon Loss:3.3070 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0956
Validation loss decreased (0.146464 --> 0.143358).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.6602478
	speed: 0.0658s/iter; left time: 1684.6201s
	iters: 200, epoch: 4 | loss: 33.1719551
	speed: 0.0602s/iter; left time: 1536.1876s
Epoch: 4 cost time: 16.497711181640625
Epoch: 4, Steps: 265 Train Loss: 33.0593 (Forecasting Loss:0.1912 + XiCon Loss:3.2868 x Lambda(10.0)), Vali MSE Loss: 0.1429 Test MSE Loss: 0.0954
Validation loss decreased (0.143358 --> 0.142938).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.0115967
	speed: 0.0656s/iter; left time: 1662.1312s
	iters: 200, epoch: 5 | loss: 32.4178810
	speed: 0.0657s/iter; left time: 1659.1868s
Epoch: 5 cost time: 17.483590364456177
Epoch: 5, Steps: 265 Train Loss: 32.9848 (Forecasting Loss:0.1902 + XiCon Loss:3.2795 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
Validation loss decreased (0.142938 --> 0.141903).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.6726112
	speed: 0.0642s/iter; left time: 1610.3443s
	iters: 200, epoch: 6 | loss: 32.2885666
	speed: 0.0594s/iter; left time: 1483.7392s
Epoch: 6 cost time: 16.30948829650879
Epoch: 6, Steps: 265 Train Loss: 32.9387 (Forecasting Loss:0.1898 + XiCon Loss:3.2749 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.5912056
	speed: 0.0668s/iter; left time: 1658.2602s
	iters: 200, epoch: 7 | loss: 33.4393768
	speed: 0.0641s/iter; left time: 1584.9789s
Epoch: 7 cost time: 17.291117191314697
Epoch: 7, Steps: 265 Train Loss: 32.9207 (Forecasting Loss:0.1895 + XiCon Loss:3.2731 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.141903 --> 0.141812).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.6756783
	speed: 0.0631s/iter; left time: 1549.4109s
	iters: 200, epoch: 8 | loss: 33.5317307
	speed: 0.0638s/iter; left time: 1558.9561s
Epoch: 8 cost time: 17.09295892715454
Epoch: 8, Steps: 265 Train Loss: 33.0042 (Forecasting Loss:0.1894 + XiCon Loss:3.2815 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.141812 --> 0.141802).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.9839592
	speed: 0.0647s/iter; left time: 1570.0443s
	iters: 200, epoch: 9 | loss: 33.1064606
	speed: 0.0614s/iter; left time: 1484.0295s
Epoch: 9 cost time: 16.35633373260498
Epoch: 9, Steps: 265 Train Loss: 32.8666 (Forecasting Loss:0.1893 + XiCon Loss:3.2677 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
Validation loss decreased (0.141802 --> 0.141536).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.5483932
	speed: 0.0623s/iter; left time: 1496.5299s
	iters: 200, epoch: 10 | loss: 32.3772316
	speed: 0.0636s/iter; left time: 1521.8568s
Epoch: 10 cost time: 16.534594774246216
Epoch: 10, Steps: 265 Train Loss: 32.9514 (Forecasting Loss:0.1891 + XiCon Loss:3.2762 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.6687431
	speed: 0.0665s/iter; left time: 1580.3664s
	iters: 200, epoch: 11 | loss: 33.2416573
	speed: 0.0617s/iter; left time: 1460.1391s
Epoch: 11 cost time: 16.757815837860107
Epoch: 11, Steps: 265 Train Loss: 32.9276 (Forecasting Loss:0.1892 + XiCon Loss:3.2738 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.8335838
	speed: 0.0657s/iter; left time: 1544.0883s
	iters: 200, epoch: 12 | loss: 33.2835503
	speed: 0.0619s/iter; left time: 1447.2280s
Epoch: 12 cost time: 16.748404502868652
Epoch: 12, Steps: 265 Train Loss: 32.9069 (Forecasting Loss:0.1892 + XiCon Loss:3.2718 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.3448334
	speed: 0.0632s/iter; left time: 1467.8174s
	iters: 200, epoch: 13 | loss: 32.3229446
	speed: 0.0601s/iter; left time: 1390.3919s
Epoch: 13 cost time: 16.372689247131348
Epoch: 13, Steps: 265 Train Loss: 32.9408 (Forecasting Loss:0.1893 + XiCon Loss:3.2752 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.4698601
	speed: 0.0636s/iter; left time: 1460.3936s
	iters: 200, epoch: 14 | loss: 33.2786255
	speed: 0.0641s/iter; left time: 1465.1660s
Epoch: 14 cost time: 17.009043216705322
Epoch: 14, Steps: 265 Train Loss: 32.9086 (Forecasting Loss:0.1892 + XiCon Loss:3.2719 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.9191055
	speed: 0.0612s/iter; left time: 1387.8576s
	iters: 200, epoch: 15 | loss: 33.8030548
	speed: 0.0601s/iter; left time: 1357.7438s
Epoch: 15 cost time: 16.046269178390503
Epoch: 15, Steps: 265 Train Loss: 32.8753 (Forecasting Loss:0.1892 + XiCon Loss:3.2686 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.3462639
	speed: 0.0633s/iter; left time: 1419.4570s
	iters: 200, epoch: 16 | loss: 32.5266418
	speed: 0.0609s/iter; left time: 1360.4593s
Epoch: 16 cost time: 16.43697690963745
Epoch: 16, Steps: 265 Train Loss: 32.9389 (Forecasting Loss:0.1891 + XiCon Loss:3.2750 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.8120155
	speed: 0.0653s/iter; left time: 1447.9268s
	iters: 200, epoch: 17 | loss: 33.3659897
	speed: 0.0626s/iter; left time: 1380.5366s
Epoch: 17 cost time: 16.81951069831848
Epoch: 17, Steps: 265 Train Loss: 32.9499 (Forecasting Loss:0.1892 + XiCon Loss:3.2761 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.4925346
	speed: 0.0658s/iter; left time: 1440.0139s
	iters: 200, epoch: 18 | loss: 33.4340744
	speed: 0.0624s/iter; left time: 1359.7342s
Epoch: 18 cost time: 16.76206088066101
Epoch: 18, Steps: 265 Train Loss: 32.9297 (Forecasting Loss:0.1892 + XiCon Loss:3.2740 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.2085533
	speed: 0.0642s/iter; left time: 1389.5045s
	iters: 200, epoch: 19 | loss: 33.2605400
	speed: 0.0635s/iter; left time: 1366.7976s
Epoch: 19 cost time: 16.715160131454468
Epoch: 19, Steps: 265 Train Loss: 32.8949 (Forecasting Loss:0.1892 + XiCon Loss:3.2706 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03935738652944565, mae:0.14952227473258972, mape:0.11866120994091034, mspe:0.02631787210702896 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.3832
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.9530411
	speed: 0.0636s/iter; left time: 1680.1459s
	iters: 200, epoch: 1 | loss: 33.2425690
	speed: 0.0593s/iter; left time: 1559.5040s
Epoch: 1 cost time: 16.325021028518677
Epoch: 1, Steps: 265 Train Loss: 33.9279 (Forecasting Loss:0.2113 + XiCon Loss:3.3717 x Lambda(10.0)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.146317).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 37.1717720
	speed: 0.0670s/iter; left time: 1751.2198s
	iters: 200, epoch: 2 | loss: 35.7444420
	speed: 0.0621s/iter; left time: 1617.9069s
Epoch: 2 cost time: 16.817586183547974
Epoch: 2, Steps: 265 Train Loss: 34.9199 (Forecasting Loss:0.1982 + XiCon Loss:3.4722 x Lambda(10.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.0977
Validation loss decreased (0.146317 --> 0.146053).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 35.3261299
	speed: 0.0634s/iter; left time: 1639.6542s
	iters: 200, epoch: 3 | loss: 34.1092987
	speed: 0.0655s/iter; left time: 1688.4236s
Epoch: 3 cost time: 16.94144296646118
Epoch: 3, Steps: 265 Train Loss: 34.1522 (Forecasting Loss:0.1935 + XiCon Loss:3.3959 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0961
Validation loss decreased (0.146053 --> 0.143618).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.7643356
	speed: 0.0632s/iter; left time: 1619.0160s
	iters: 200, epoch: 4 | loss: 32.4006233
	speed: 0.0606s/iter; left time: 1546.5047s
Epoch: 4 cost time: 16.610036849975586
Epoch: 4, Steps: 265 Train Loss: 33.8038 (Forecasting Loss:0.1911 + XiCon Loss:3.3613 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0953
Validation loss decreased (0.143618 --> 0.142169).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.3942261
	speed: 0.0663s/iter; left time: 1679.5154s
	iters: 200, epoch: 5 | loss: 33.4598351
	speed: 0.0612s/iter; left time: 1545.6297s
Epoch: 5 cost time: 16.78885054588318
Epoch: 5, Steps: 265 Train Loss: 32.7336 (Forecasting Loss:0.1898 + XiCon Loss:3.2544 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0952
Validation loss decreased (0.142169 --> 0.142106).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.7635670
	speed: 0.0612s/iter; left time: 1535.3436s
	iters: 200, epoch: 6 | loss: 32.8364754
	speed: 0.0629s/iter; left time: 1571.0203s
Epoch: 6 cost time: 16.510570287704468
Epoch: 6, Steps: 265 Train Loss: 32.5338 (Forecasting Loss:0.1890 + XiCon Loss:3.2345 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0951
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.9080410
	speed: 0.0640s/iter; left time: 1587.1498s
	iters: 200, epoch: 7 | loss: 34.3899727
	speed: 0.0614s/iter; left time: 1517.7311s
Epoch: 7 cost time: 16.613807678222656
Epoch: 7, Steps: 265 Train Loss: 32.5440 (Forecasting Loss:0.1888 + XiCon Loss:3.2355 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0950
Validation loss decreased (0.142106 --> 0.141592).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.7736397
	speed: 0.0621s/iter; left time: 1523.1524s
	iters: 200, epoch: 8 | loss: 33.4789543
	speed: 0.0637s/iter; left time: 1557.3133s
Epoch: 8 cost time: 16.48643684387207
Epoch: 8, Steps: 265 Train Loss: 32.4854 (Forecasting Loss:0.1891 + XiCon Loss:3.2296 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.6244049
	speed: 0.0643s/iter; left time: 1560.8844s
	iters: 200, epoch: 9 | loss: 31.8296585
	speed: 0.0615s/iter; left time: 1486.1366s
Epoch: 9 cost time: 16.33500051498413
Epoch: 9, Steps: 265 Train Loss: 32.3606 (Forecasting Loss:0.1892 + XiCon Loss:3.2171 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.8384647
	speed: 0.0647s/iter; left time: 1552.8141s
	iters: 200, epoch: 10 | loss: 32.2274475
	speed: 0.0616s/iter; left time: 1472.9524s
Epoch: 10 cost time: 16.69113063812256
Epoch: 10, Steps: 265 Train Loss: 32.2986 (Forecasting Loss:0.1892 + XiCon Loss:3.2109 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0947
Validation loss decreased (0.141592 --> 0.141550).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.8316994
	speed: 0.0641s/iter; left time: 1521.3958s
	iters: 200, epoch: 11 | loss: 31.8552780
	speed: 0.0600s/iter; left time: 1418.0138s
Epoch: 11 cost time: 16.102755546569824
Epoch: 11, Steps: 265 Train Loss: 32.2254 (Forecasting Loss:0.1891 + XiCon Loss:3.2036 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0946
Validation loss decreased (0.141550 --> 0.141513).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.8017502
	speed: 0.0650s/iter; left time: 1525.4403s
	iters: 200, epoch: 12 | loss: 32.7305527
	speed: 0.0594s/iter; left time: 1390.0919s
Epoch: 12 cost time: 16.50423765182495
Epoch: 12, Steps: 265 Train Loss: 32.2963 (Forecasting Loss:0.1890 + XiCon Loss:3.2107 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.7814140
	speed: 0.0649s/iter; left time: 1506.4621s
	iters: 200, epoch: 13 | loss: 33.2471237
	speed: 0.0596s/iter; left time: 1377.3677s
Epoch: 13 cost time: 15.860457420349121
Epoch: 13, Steps: 265 Train Loss: 32.2963 (Forecasting Loss:0.1890 + XiCon Loss:3.2107 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0946
Validation loss decreased (0.141513 --> 0.141457).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.6502342
	speed: 0.0447s/iter; left time: 1026.0034s
	iters: 200, epoch: 14 | loss: 33.1130104
	speed: 0.0931s/iter; left time: 2126.9134s
Epoch: 14 cost time: 16.61004376411438
Epoch: 14, Steps: 265 Train Loss: 32.2653 (Forecasting Loss:0.1891 + XiCon Loss:3.2076 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.4041443
	speed: 0.0419s/iter; left time: 950.6920s
	iters: 200, epoch: 15 | loss: 32.7589417
	speed: 0.0581s/iter; left time: 1313.4495s
Epoch: 15 cost time: 14.255971670150757
Epoch: 15, Steps: 265 Train Loss: 32.2421 (Forecasting Loss:0.1890 + XiCon Loss:3.2053 x Lambda(10.0)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0946
Validation loss decreased (0.141457 --> 0.141428).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.5667419
	speed: 0.0685s/iter; left time: 1536.5055s
	iters: 200, epoch: 16 | loss: 31.9150658
	speed: 0.0672s/iter; left time: 1499.8297s
Epoch: 16 cost time: 17.893686771392822
Epoch: 16, Steps: 265 Train Loss: 32.2907 (Forecasting Loss:0.1891 + XiCon Loss:3.2102 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.6689930
	speed: 0.0693s/iter; left time: 1535.4300s
	iters: 200, epoch: 17 | loss: 32.4357910
	speed: 0.0600s/iter; left time: 1323.5582s
Epoch: 17 cost time: 16.351828575134277
Epoch: 17, Steps: 265 Train Loss: 32.2372 (Forecasting Loss:0.1889 + XiCon Loss:3.2048 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.1129189
	speed: 0.0683s/iter; left time: 1494.9498s
	iters: 200, epoch: 18 | loss: 31.8692112
	speed: 0.0663s/iter; left time: 1444.3693s
Epoch: 18 cost time: 17.738296270370483
Epoch: 18, Steps: 265 Train Loss: 32.2643 (Forecasting Loss:0.1890 + XiCon Loss:3.2075 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.7470779
	speed: 0.0693s/iter; left time: 1499.8372s
	iters: 200, epoch: 19 | loss: 31.9876919
	speed: 0.0679s/iter; left time: 1461.6983s
Epoch: 19 cost time: 17.827286958694458
Epoch: 19, Steps: 265 Train Loss: 32.2534 (Forecasting Loss:0.1891 + XiCon Loss:3.2064 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.8788490
	speed: 0.0673s/iter; left time: 1437.2308s
	iters: 200, epoch: 20 | loss: 32.9321632
	speed: 0.0657s/iter; left time: 1397.7748s
Epoch: 20 cost time: 17.72059965133667
Epoch: 20, Steps: 265 Train Loss: 32.2348 (Forecasting Loss:0.1889 + XiCon Loss:3.2046 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.7392998
	speed: 0.0693s/iter; left time: 1462.4232s
	iters: 200, epoch: 21 | loss: 33.1877518
	speed: 0.0668s/iter; left time: 1402.7395s
Epoch: 21 cost time: 18.001708984375
Epoch: 21, Steps: 265 Train Loss: 32.2699 (Forecasting Loss:0.1891 + XiCon Loss:3.2081 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.7865143
	speed: 0.0678s/iter; left time: 1413.1323s
	iters: 200, epoch: 22 | loss: 32.5274544
	speed: 0.0454s/iter; left time: 942.1994s
Epoch: 22 cost time: 13.787227869033813
Epoch: 22, Steps: 265 Train Loss: 32.2380 (Forecasting Loss:0.1891 + XiCon Loss:3.2049 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 33.1355247
	speed: 0.0578s/iter; left time: 1189.9712s
	iters: 200, epoch: 23 | loss: 32.6820755
	speed: 0.0672s/iter; left time: 1374.9071s
Epoch: 23 cost time: 16.925463438034058
Epoch: 23, Steps: 265 Train Loss: 32.3178 (Forecasting Loss:0.1890 + XiCon Loss:3.2129 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.8577003
	speed: 0.0661s/iter; left time: 1342.8161s
	iters: 200, epoch: 24 | loss: 32.0717468
	speed: 0.0671s/iter; left time: 1355.2732s
Epoch: 24 cost time: 17.83098292350769
Epoch: 24, Steps: 265 Train Loss: 32.2414 (Forecasting Loss:0.1891 + XiCon Loss:3.2052 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 33.1664314
	speed: 0.0639s/iter; left time: 1280.4681s
	iters: 200, epoch: 25 | loss: 31.9231052
	speed: 0.0430s/iter; left time: 857.6236s
Epoch: 25 cost time: 13.108378887176514
Epoch: 25, Steps: 265 Train Loss: 32.2436 (Forecasting Loss:0.1892 + XiCon Loss:3.2054 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03949218988418579, mae:0.14979252219200134, mape:0.11913961917161942, mspe:0.02658429741859436 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.0394
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.4295692
	speed: 0.0687s/iter; left time: 1814.6767s
	iters: 200, epoch: 1 | loss: 33.2667885
	speed: 0.0649s/iter; left time: 1707.7730s
Epoch: 1 cost time: 17.520567417144775
Epoch: 1, Steps: 265 Train Loss: 34.3656 (Forecasting Loss:0.2108 + XiCon Loss:3.4155 x Lambda(10.0)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.148035).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.4989166
	speed: 0.0618s/iter; left time: 1614.5287s
	iters: 200, epoch: 2 | loss: 33.5394974
	speed: 0.0395s/iter; left time: 1029.1516s
Epoch: 2 cost time: 12.630650520324707
Epoch: 2, Steps: 265 Train Loss: 34.4902 (Forecasting Loss:0.1984 + XiCon Loss:3.4292 x Lambda(10.0)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.0968
Validation loss decreased (0.148035 --> 0.146802).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.3369446
	speed: 0.0711s/iter; left time: 1838.8749s
	iters: 200, epoch: 3 | loss: 32.2234573
	speed: 0.0677s/iter; left time: 1744.8884s
Epoch: 3 cost time: 18.2513644695282
Epoch: 3, Steps: 265 Train Loss: 32.8788 (Forecasting Loss:0.1932 + XiCon Loss:3.2686 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0969
Validation loss decreased (0.146802 --> 0.144073).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.4477921
	speed: 0.0710s/iter; left time: 1818.7006s
	iters: 200, epoch: 4 | loss: 32.7106361
	speed: 0.0682s/iter; left time: 1740.3364s
Epoch: 4 cost time: 18.262903928756714
Epoch: 4, Steps: 265 Train Loss: 32.5358 (Forecasting Loss:0.1909 + XiCon Loss:3.2345 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0962
Validation loss decreased (0.144073 --> 0.142647).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.6990128
	speed: 0.0609s/iter; left time: 1543.0444s
	iters: 200, epoch: 5 | loss: 31.8410778
	speed: 0.0389s/iter; left time: 982.1295s
Epoch: 5 cost time: 12.64872670173645
Epoch: 5, Steps: 265 Train Loss: 32.5850 (Forecasting Loss:0.1896 + XiCon Loss:3.2395 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0957
Validation loss decreased (0.142647 --> 0.142339).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.8826160
	speed: 0.0709s/iter; left time: 1777.6304s
	iters: 200, epoch: 6 | loss: 31.9719524
	speed: 0.0695s/iter; left time: 1736.3585s
Epoch: 6 cost time: 18.429315090179443
Epoch: 6, Steps: 265 Train Loss: 32.4569 (Forecasting Loss:0.1889 + XiCon Loss:3.2268 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0959
Validation loss decreased (0.142339 --> 0.142093).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.2541580
	speed: 0.0715s/iter; left time: 1775.1426s
	iters: 200, epoch: 7 | loss: 31.8265438
	speed: 0.0687s/iter; left time: 1697.4983s
Epoch: 7 cost time: 18.43247079849243
Epoch: 7, Steps: 265 Train Loss: 32.4985 (Forecasting Loss:0.1889 + XiCon Loss:3.2310 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
Validation loss decreased (0.142093 --> 0.141793).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.8003006
	speed: 0.0545s/iter; left time: 1338.5369s
	iters: 200, epoch: 8 | loss: 33.2670135
	speed: 0.0390s/iter; left time: 952.7670s
Epoch: 8 cost time: 11.824552536010742
Epoch: 8, Steps: 265 Train Loss: 32.4933 (Forecasting Loss:0.1886 + XiCon Loss:3.2305 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.1506462
	speed: 0.0705s/iter; left time: 1712.0499s
	iters: 200, epoch: 9 | loss: 31.8527431
	speed: 0.0682s/iter; left time: 1647.9491s
Epoch: 9 cost time: 18.18765091896057
Epoch: 9, Steps: 265 Train Loss: 32.4514 (Forecasting Loss:0.1885 + XiCon Loss:3.2263 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.2626419
	speed: 0.0708s/iter; left time: 1701.1384s
	iters: 200, epoch: 10 | loss: 32.1230965
	speed: 0.0692s/iter; left time: 1656.1625s
Epoch: 10 cost time: 18.445985555648804
Epoch: 10, Steps: 265 Train Loss: 32.4534 (Forecasting Loss:0.1884 + XiCon Loss:3.2265 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0957
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.1115646
	speed: 0.0687s/iter; left time: 1630.9552s
	iters: 200, epoch: 11 | loss: 31.8864346
	speed: 0.0683s/iter; left time: 1616.4525s
Epoch: 11 cost time: 18.236323595046997
Epoch: 11, Steps: 265 Train Loss: 32.4909 (Forecasting Loss:0.1884 + XiCon Loss:3.2302 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.3229218
	speed: 0.0702s/iter; left time: 1648.0180s
	iters: 200, epoch: 12 | loss: 31.9782467
	speed: 0.0689s/iter; left time: 1612.3566s
Epoch: 12 cost time: 18.400596380233765
Epoch: 12, Steps: 265 Train Loss: 32.4645 (Forecasting Loss:0.1884 + XiCon Loss:3.2276 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
Validation loss decreased (0.141793 --> 0.141751).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.1259727
	speed: 0.0679s/iter; left time: 1576.5346s
	iters: 200, epoch: 13 | loss: 33.0792465
	speed: 0.0696s/iter; left time: 1609.2792s
Epoch: 13 cost time: 18.32352328300476
Epoch: 13, Steps: 265 Train Loss: 32.4338 (Forecasting Loss:0.1884 + XiCon Loss:3.2245 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.0575218
	speed: 0.0700s/iter; left time: 1606.8204s
	iters: 200, epoch: 14 | loss: 32.1185722
	speed: 0.0673s/iter; left time: 1538.0140s
Epoch: 14 cost time: 18.29762291908264
Epoch: 14, Steps: 265 Train Loss: 32.4017 (Forecasting Loss:0.1884 + XiCon Loss:3.2213 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.0300255
	speed: 0.0688s/iter; left time: 1561.1072s
	iters: 200, epoch: 15 | loss: 32.7825317
	speed: 0.0641s/iter; left time: 1449.0713s
Epoch: 15 cost time: 17.680779218673706
Epoch: 15, Steps: 265 Train Loss: 32.5058 (Forecasting Loss:0.1883 + XiCon Loss:3.2317 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0958
Validation loss decreased (0.141751 --> 0.141740).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.8460579
	speed: 0.0714s/iter; left time: 1601.5828s
	iters: 200, epoch: 16 | loss: 32.0107841
	speed: 0.0703s/iter; left time: 1569.0870s
Epoch: 16 cost time: 18.645287036895752
Epoch: 16, Steps: 265 Train Loss: 32.4865 (Forecasting Loss:0.1884 + XiCon Loss:3.2298 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0958
Validation loss decreased (0.141740 --> 0.141691).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.7039070
	speed: 0.0715s/iter; left time: 1584.0040s
	iters: 200, epoch: 17 | loss: 32.2571754
	speed: 0.0651s/iter; left time: 1435.4479s
Epoch: 17 cost time: 17.947321891784668
Epoch: 17, Steps: 265 Train Loss: 32.4411 (Forecasting Loss:0.1885 + XiCon Loss:3.2253 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.0212135
	speed: 0.0713s/iter; left time: 1560.8671s
	iters: 200, epoch: 18 | loss: 32.8837967
	speed: 0.0681s/iter; left time: 1484.6764s
Epoch: 18 cost time: 18.44349193572998
Epoch: 18, Steps: 265 Train Loss: 32.5196 (Forecasting Loss:0.1883 + XiCon Loss:3.2331 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 34.1149597
	speed: 0.0677s/iter; left time: 1465.2986s
	iters: 200, epoch: 19 | loss: 33.8598900
	speed: 0.0682s/iter; left time: 1469.0182s
Epoch: 19 cost time: 17.83519458770752
Epoch: 19, Steps: 265 Train Loss: 32.4745 (Forecasting Loss:0.1884 + XiCon Loss:3.2286 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.3075256
	speed: 0.0694s/iter; left time: 1482.0584s
	iters: 200, epoch: 20 | loss: 33.1975174
	speed: 0.0690s/iter; left time: 1466.5444s
Epoch: 20 cost time: 18.272151947021484
Epoch: 20, Steps: 265 Train Loss: 32.4908 (Forecasting Loss:0.1885 + XiCon Loss:3.2302 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.3768234
	speed: 0.0719s/iter; left time: 1516.6900s
	iters: 200, epoch: 21 | loss: 32.1243744
	speed: 0.0685s/iter; left time: 1439.2148s
Epoch: 21 cost time: 18.545767307281494
Epoch: 21, Steps: 265 Train Loss: 32.4632 (Forecasting Loss:0.1884 + XiCon Loss:3.2275 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.1407700
	speed: 0.0665s/iter; left time: 1384.6379s
	iters: 200, epoch: 22 | loss: 31.9651337
	speed: 0.0695s/iter; left time: 1441.9716s
Epoch: 22 cost time: 17.880929231643677
Epoch: 22, Steps: 265 Train Loss: 32.4424 (Forecasting Loss:0.1883 + XiCon Loss:3.2254 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.0151024
	speed: 0.0722s/iter; left time: 1484.8071s
	iters: 200, epoch: 23 | loss: 32.0270844
	speed: 0.0680s/iter; left time: 1392.2319s
Epoch: 23 cost time: 18.518874883651733
Epoch: 23, Steps: 265 Train Loss: 32.4960 (Forecasting Loss:0.1885 + XiCon Loss:3.2308 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.2990265
	speed: 0.0715s/iter; left time: 1451.4828s
	iters: 200, epoch: 24 | loss: 32.6407242
	speed: 0.0671s/iter; left time: 1355.4233s
Epoch: 24 cost time: 18.224292755126953
Epoch: 24, Steps: 265 Train Loss: 32.4912 (Forecasting Loss:0.1885 + XiCon Loss:3.2303 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.4929695
	speed: 0.0711s/iter; left time: 1424.2781s
	iters: 200, epoch: 25 | loss: 33.1746292
	speed: 0.0684s/iter; left time: 1363.5761s
Epoch: 25 cost time: 18.330333471298218
Epoch: 25, Steps: 265 Train Loss: 32.4914 (Forecasting Loss:0.1885 + XiCon Loss:3.2303 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.8514366
	speed: 0.0706s/iter; left time: 1397.1696s
	iters: 200, epoch: 26 | loss: 31.9586601
	speed: 0.0649s/iter; left time: 1276.9533s
Epoch: 26 cost time: 17.85399627685547
Epoch: 26, Steps: 265 Train Loss: 32.4510 (Forecasting Loss:0.1884 + XiCon Loss:3.2263 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04007032513618469, mae:0.15145111083984375, mape:0.12003709375858307, mspe:0.02667977102100849 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1676
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.4256363
	speed: 0.0667s/iter; left time: 1759.9152s
	iters: 200, epoch: 1 | loss: 33.4654541
	speed: 0.0636s/iter; left time: 1671.5797s
Epoch: 1 cost time: 16.87265157699585
Epoch: 1, Steps: 265 Train Loss: 34.1932 (Forecasting Loss:0.2108 + XiCon Loss:3.3982 x Lambda(10.0)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.148214).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 35.7870941
	speed: 0.0691s/iter; left time: 1806.9240s
	iters: 200, epoch: 2 | loss: 35.1471024
	speed: 0.0667s/iter; left time: 1736.6370s
Epoch: 2 cost time: 17.90726375579834
Epoch: 2, Steps: 265 Train Loss: 35.5288 (Forecasting Loss:0.1981 + XiCon Loss:3.5331 x Lambda(10.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0964
Validation loss decreased (0.148214 --> 0.145571).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 35.0255928
	speed: 0.0714s/iter; left time: 1846.1577s
	iters: 200, epoch: 3 | loss: 33.1883812
	speed: 0.0662s/iter; left time: 1704.8330s
Epoch: 3 cost time: 18.079966068267822
Epoch: 3, Steps: 265 Train Loss: 34.5461 (Forecasting Loss:0.1935 + XiCon Loss:3.4353 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0958
Validation loss decreased (0.145571 --> 0.143639).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 34.1676216
	speed: 0.0646s/iter; left time: 1653.9595s
	iters: 200, epoch: 4 | loss: 35.5258789
	speed: 0.0656s/iter; left time: 1673.4867s
Epoch: 4 cost time: 17.366514205932617
Epoch: 4, Steps: 265 Train Loss: 34.4852 (Forecasting Loss:0.1913 + XiCon Loss:3.4294 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0951
Validation loss decreased (0.143639 --> 0.142298).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.9354591
	speed: 0.0678s/iter; left time: 1718.9306s
	iters: 200, epoch: 5 | loss: 33.4387321
	speed: 0.0666s/iter; left time: 1681.6527s
Epoch: 5 cost time: 17.7024028301239
Epoch: 5, Steps: 265 Train Loss: 34.0732 (Forecasting Loss:0.1903 + XiCon Loss:3.3883 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
Validation loss decreased (0.142298 --> 0.141959).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.7398872
	speed: 0.0676s/iter; left time: 1696.2857s
	iters: 200, epoch: 6 | loss: 34.1778755
	speed: 0.0638s/iter; left time: 1593.3416s
Epoch: 6 cost time: 17.51780390739441
Epoch: 6, Steps: 265 Train Loss: 34.0220 (Forecasting Loss:0.1898 + XiCon Loss:3.3832 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141959 --> 0.141751).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 34.2815552
	speed: 0.0683s/iter; left time: 1695.1720s
	iters: 200, epoch: 7 | loss: 34.7024155
	speed: 0.0686s/iter; left time: 1694.7519s
Epoch: 7 cost time: 18.11723232269287
Epoch: 7, Steps: 265 Train Loss: 33.9771 (Forecasting Loss:0.1895 + XiCon Loss:3.3788 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141751 --> 0.141658).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 34.7708664
	speed: 0.0691s/iter; left time: 1697.0872s
	iters: 200, epoch: 8 | loss: 34.5493431
	speed: 0.0652s/iter; left time: 1593.0542s
Epoch: 8 cost time: 17.69701075553894
Epoch: 8, Steps: 265 Train Loss: 34.0278 (Forecasting Loss:0.1893 + XiCon Loss:3.3838 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 34.4086609
	speed: 0.0693s/iter; left time: 1681.5852s
	iters: 200, epoch: 9 | loss: 35.2672043
	speed: 0.0678s/iter; left time: 1639.9929s
Epoch: 9 cost time: 17.93287706375122
Epoch: 9, Steps: 265 Train Loss: 34.0150 (Forecasting Loss:0.1893 + XiCon Loss:3.3826 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.3819275
	speed: 0.0684s/iter; left time: 1641.8226s
	iters: 200, epoch: 10 | loss: 35.7819786
	speed: 0.0679s/iter; left time: 1624.5953s
Epoch: 10 cost time: 17.765604257583618
Epoch: 10, Steps: 265 Train Loss: 33.9939 (Forecasting Loss:0.1893 + XiCon Loss:3.3805 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.7891769
	speed: 0.0643s/iter; left time: 1527.9822s
	iters: 200, epoch: 11 | loss: 34.0684624
	speed: 0.0660s/iter; left time: 1561.5908s
Epoch: 11 cost time: 17.176530838012695
Epoch: 11, Steps: 265 Train Loss: 33.9671 (Forecasting Loss:0.1892 + XiCon Loss:3.3778 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.5555687
	speed: 0.0695s/iter; left time: 1631.1720s
	iters: 200, epoch: 12 | loss: 35.4375877
	speed: 0.0670s/iter; left time: 1566.1039s
Epoch: 12 cost time: 17.968156814575195
Epoch: 12, Steps: 265 Train Loss: 34.0287 (Forecasting Loss:0.1891 + XiCon Loss:3.3840 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.6457863
	speed: 0.0647s/iter; left time: 1503.1420s
	iters: 200, epoch: 13 | loss: 34.6416931
	speed: 0.0633s/iter; left time: 1463.2541s
Epoch: 13 cost time: 17.240468978881836
Epoch: 13, Steps: 265 Train Loss: 34.0997 (Forecasting Loss:0.1891 + XiCon Loss:3.3911 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.0413589
	speed: 0.0693s/iter; left time: 1591.5074s
	iters: 200, epoch: 14 | loss: 35.2365913
	speed: 0.0667s/iter; left time: 1525.5646s
Epoch: 14 cost time: 17.922173738479614
Epoch: 14, Steps: 265 Train Loss: 34.0325 (Forecasting Loss:0.1892 + XiCon Loss:3.3843 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 34.7915802
	speed: 0.0678s/iter; left time: 1538.7722s
	iters: 200, epoch: 15 | loss: 34.0522614
	speed: 0.0635s/iter; left time: 1435.2006s
Epoch: 15 cost time: 17.266113758087158
Epoch: 15, Steps: 265 Train Loss: 34.0851 (Forecasting Loss:0.1891 + XiCon Loss:3.3896 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141658 --> 0.141608).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.0749474
	speed: 0.0687s/iter; left time: 1541.2082s
	iters: 200, epoch: 16 | loss: 33.4949646
	speed: 0.0657s/iter; left time: 1467.8729s
Epoch: 16 cost time: 17.80025839805603
Epoch: 16, Steps: 265 Train Loss: 33.9776 (Forecasting Loss:0.1892 + XiCon Loss:3.3788 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141608 --> 0.141601).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 34.0770607
	speed: 0.0687s/iter; left time: 1523.0589s
	iters: 200, epoch: 17 | loss: 34.5937080
	speed: 0.0661s/iter; left time: 1457.8318s
Epoch: 17 cost time: 17.74693989753723
Epoch: 17, Steps: 265 Train Loss: 33.9925 (Forecasting Loss:0.1891 + XiCon Loss:3.3803 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.9820099
	speed: 0.0653s/iter; left time: 1429.5009s
	iters: 200, epoch: 18 | loss: 36.1072502
	speed: 0.0678s/iter; left time: 1478.0308s
Epoch: 18 cost time: 17.759713888168335
Epoch: 18, Steps: 265 Train Loss: 34.0617 (Forecasting Loss:0.1892 + XiCon Loss:3.3872 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.6965790
	speed: 0.0692s/iter; left time: 1496.5582s
	iters: 200, epoch: 19 | loss: 33.6242599
	speed: 0.0681s/iter; left time: 1466.8244s
Epoch: 19 cost time: 18.04346990585327
Epoch: 19, Steps: 265 Train Loss: 33.9705 (Forecasting Loss:0.1892 + XiCon Loss:3.3781 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0945
Validation loss decreased (0.141601 --> 0.141537).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.4536781
	speed: 0.0641s/iter; left time: 1369.7803s
	iters: 200, epoch: 20 | loss: 32.0263557
	speed: 0.0659s/iter; left time: 1402.2996s
Epoch: 20 cost time: 17.364153385162354
Epoch: 20, Steps: 265 Train Loss: 33.9575 (Forecasting Loss:0.1892 + XiCon Loss:3.3768 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 35.8841667
	speed: 0.0695s/iter; left time: 1466.8268s
	iters: 200, epoch: 21 | loss: 33.4074211
	speed: 0.0672s/iter; left time: 1411.5426s
Epoch: 21 cost time: 18.234110355377197
Epoch: 21, Steps: 265 Train Loss: 33.9387 (Forecasting Loss:0.1892 + XiCon Loss:3.3750 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.7586174
	speed: 0.0662s/iter; left time: 1379.9130s
	iters: 200, epoch: 22 | loss: 33.5382156
	speed: 0.0622s/iter; left time: 1289.3244s
Epoch: 22 cost time: 16.988157033920288
Epoch: 22, Steps: 265 Train Loss: 33.9707 (Forecasting Loss:0.1892 + XiCon Loss:3.3781 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 34.6512222
	speed: 0.0694s/iter; left time: 1427.8601s
	iters: 200, epoch: 23 | loss: 34.7804871
	speed: 0.0651s/iter; left time: 1331.7651s
Epoch: 23 cost time: 17.738173961639404
Epoch: 23, Steps: 265 Train Loss: 33.9563 (Forecasting Loss:0.1890 + XiCon Loss:3.3767 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.9380531
	speed: 0.0685s/iter; left time: 1390.7569s
	iters: 200, epoch: 24 | loss: 35.3352470
	speed: 0.0646s/iter; left time: 1306.2965s
Epoch: 24 cost time: 17.63548493385315
Epoch: 24, Steps: 265 Train Loss: 34.1265 (Forecasting Loss:0.1893 + XiCon Loss:3.3937 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 34.1381569
	speed: 0.0402s/iter; left time: 804.8292s
	iters: 200, epoch: 25 | loss: 33.1827431
	speed: 0.0485s/iter; left time: 967.9175s
Epoch: 25 cost time: 13.282476663589478
Epoch: 25, Steps: 265 Train Loss: 33.9181 (Forecasting Loss:0.1892 + XiCon Loss:3.3729 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 34.4977493
	speed: 0.0699s/iter; left time: 1383.2570s
	iters: 200, epoch: 26 | loss: 32.3792381
	speed: 0.0681s/iter; left time: 1339.7183s
Epoch: 26 cost time: 18.243220806121826
Epoch: 26, Steps: 265 Train Loss: 33.9832 (Forecasting Loss:0.1891 + XiCon Loss:3.3794 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 34.7346039
	speed: 0.0694s/iter; left time: 1353.4128s
	iters: 200, epoch: 27 | loss: 34.1937523
	speed: 0.0628s/iter; left time: 1219.5905s
Epoch: 27 cost time: 17.38138222694397
Epoch: 27, Steps: 265 Train Loss: 34.0284 (Forecasting Loss:0.1891 + XiCon Loss:3.3839 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 35.7404633
	speed: 0.0681s/iter; left time: 1310.0574s
	iters: 200, epoch: 28 | loss: 36.4917870
	speed: 0.0686s/iter; left time: 1314.1228s
Epoch: 28 cost time: 18.05727767944336
Epoch: 28, Steps: 265 Train Loss: 33.9876 (Forecasting Loss:0.1891 + XiCon Loss:3.3798 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 34.4037285
	speed: 0.0689s/iter; left time: 1308.0824s
	iters: 200, epoch: 29 | loss: 32.8712425
	speed: 0.0675s/iter; left time: 1274.3916s
Epoch: 29 cost time: 17.88863778114319
Epoch: 29, Steps: 265 Train Loss: 34.0177 (Forecasting Loss:0.1890 + XiCon Loss:3.3829 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03939618542790413, mae:0.1495639681816101, mape:0.1186906024813652, mspe:0.026332419365644455 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0395+-0.00038, MAE:0.1500+-0.00104, MAPE:0.1191+-0.00073, MSPE:0.0265+-0.00020, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5222
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3475940
	speed: 0.1340s/iter; left time: 3415.9568s
	iters: 200, epoch: 1 | loss: 0.3133371
	speed: 0.1247s/iter; left time: 3166.5720s
Epoch: 1 cost time: 33.038538694381714
Epoch: 1, Steps: 256 Train Loss: 0.3332 (Forecasting Loss:0.2981 + XiCon Loss:3.5087 x Lambda(0.01)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1593
Validation loss decreased (inf --> 0.209115).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2743700
	speed: 0.1676s/iter; left time: 4232.1116s
	iters: 200, epoch: 2 | loss: 0.2506673
	speed: 0.1728s/iter; left time: 4345.6159s
Epoch: 2 cost time: 44.24433159828186
Epoch: 2, Steps: 256 Train Loss: 0.2738 (Forecasting Loss:0.2394 + XiCon Loss:3.4438 x Lambda(0.01)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1862
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2275961
	speed: 0.1818s/iter; left time: 4543.1012s
	iters: 200, epoch: 3 | loss: 0.2183451
	speed: 0.1753s/iter; left time: 4362.8871s
Epoch: 3 cost time: 45.87102293968201
Epoch: 3, Steps: 256 Train Loss: 0.2218 (Forecasting Loss:0.1878 + XiCon Loss:3.4022 x Lambda(0.01)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1859
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2082132
	speed: 0.1792s/iter; left time: 4431.7177s
	iters: 200, epoch: 4 | loss: 0.1945544
	speed: 0.1778s/iter; left time: 4380.3383s
Epoch: 4 cost time: 45.29137921333313
Epoch: 4, Steps: 256 Train Loss: 0.2003 (Forecasting Loss:0.1662 + XiCon Loss:3.4085 x Lambda(0.01)), Vali MSE Loss: 0.2236 Test MSE Loss: 0.1906
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1844983
	speed: 0.1764s/iter; left time: 4318.3194s
	iters: 200, epoch: 5 | loss: 0.1860268
	speed: 0.1811s/iter; left time: 4415.4842s
Epoch: 5 cost time: 45.696537256240845
Epoch: 5, Steps: 256 Train Loss: 0.1889 (Forecasting Loss:0.1547 + XiCon Loss:3.4173 x Lambda(0.01)), Vali MSE Loss: 0.2325 Test MSE Loss: 0.1861
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1921369
	speed: 0.1758s/iter; left time: 4257.8387s
	iters: 200, epoch: 6 | loss: 0.1806814
	speed: 0.1760s/iter; left time: 4244.6619s
Epoch: 6 cost time: 44.95560026168823
Epoch: 6, Steps: 256 Train Loss: 0.1833 (Forecasting Loss:0.1491 + XiCon Loss:3.4248 x Lambda(0.01)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1866
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1849147
	speed: 0.1757s/iter; left time: 4210.5087s
	iters: 200, epoch: 7 | loss: 0.1769310
	speed: 0.1756s/iter; left time: 4191.4580s
Epoch: 7 cost time: 44.98336839675903
Epoch: 7, Steps: 256 Train Loss: 0.1807 (Forecasting Loss:0.1464 + XiCon Loss:3.4272 x Lambda(0.01)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1885
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1867039
	speed: 0.1739s/iter; left time: 4124.0899s
	iters: 200, epoch: 8 | loss: 0.1789974
	speed: 0.1771s/iter; left time: 4180.4950s
Epoch: 8 cost time: 44.80876445770264
Epoch: 8, Steps: 256 Train Loss: 0.1794 (Forecasting Loss:0.1451 + XiCon Loss:3.4293 x Lambda(0.01)), Vali MSE Loss: 0.2347 Test MSE Loss: 0.1887
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1851013
	speed: 0.1747s/iter; left time: 4096.4788s
	iters: 200, epoch: 9 | loss: 0.1719857
	speed: 0.1744s/iter; left time: 4073.9129s
Epoch: 9 cost time: 44.673774003982544
Epoch: 9, Steps: 256 Train Loss: 0.1786 (Forecasting Loss:0.1444 + XiCon Loss:3.4286 x Lambda(0.01)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1893
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1753762
	speed: 0.1745s/iter; left time: 4047.5429s
	iters: 200, epoch: 10 | loss: 0.1809651
	speed: 0.1728s/iter; left time: 3990.2573s
Epoch: 10 cost time: 44.441925048828125
Epoch: 10, Steps: 256 Train Loss: 0.1783 (Forecasting Loss:0.1440 + XiCon Loss:3.4326 x Lambda(0.01)), Vali MSE Loss: 0.2344 Test MSE Loss: 0.1890
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1803653
	speed: 0.1774s/iter; left time: 4069.8733s
	iters: 200, epoch: 11 | loss: 0.1728005
	speed: 0.1754s/iter; left time: 4005.4512s
Epoch: 11 cost time: 44.874606132507324
Epoch: 11, Steps: 256 Train Loss: 0.1783 (Forecasting Loss:0.1440 + XiCon Loss:3.4325 x Lambda(0.01)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1894
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08756373077630997, mae:0.23112839460372925, mape:0.17007561028003693, mspe:0.04572566598653793 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.4251
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3416965
	speed: 0.1080s/iter; left time: 2755.3550s
	iters: 200, epoch: 1 | loss: 0.3081965
	speed: 0.0961s/iter; left time: 2440.0546s
Epoch: 1 cost time: 27.882773637771606
Epoch: 1, Steps: 256 Train Loss: 0.3242 (Forecasting Loss:0.2889 + XiCon Loss:3.5320 x Lambda(0.01)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1548
Validation loss decreased (inf --> 0.204326).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3192837
	speed: 0.1300s/iter; left time: 3281.4125s
	iters: 200, epoch: 2 | loss: 0.2705335
	speed: 0.1374s/iter; left time: 3454.7906s
Epoch: 2 cost time: 34.21276783943176
Epoch: 2, Steps: 256 Train Loss: 0.2962 (Forecasting Loss:0.2617 + XiCon Loss:3.4436 x Lambda(0.01)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1756
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2301832
	speed: 0.1397s/iter; left time: 3492.0170s
	iters: 200, epoch: 3 | loss: 0.2220217
	speed: 0.1352s/iter; left time: 3366.1893s
Epoch: 3 cost time: 35.18142104148865
Epoch: 3, Steps: 256 Train Loss: 0.2334 (Forecasting Loss:0.1987 + XiCon Loss:3.4723 x Lambda(0.01)), Vali MSE Loss: 0.2234 Test MSE Loss: 0.1964
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2121617
	speed: 0.1367s/iter; left time: 3381.2040s
	iters: 200, epoch: 4 | loss: 0.2026413
	speed: 0.1332s/iter; left time: 3281.4705s
Epoch: 4 cost time: 34.52080941200256
Epoch: 4, Steps: 256 Train Loss: 0.2121 (Forecasting Loss:0.1767 + XiCon Loss:3.5343 x Lambda(0.01)), Vali MSE Loss: 0.2238 Test MSE Loss: 0.1854
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2049006
	speed: 0.1396s/iter; left time: 3417.8323s
	iters: 200, epoch: 5 | loss: 0.1890551
	speed: 0.1345s/iter; left time: 3279.3125s
Epoch: 5 cost time: 35.26295852661133
Epoch: 5, Steps: 256 Train Loss: 0.2014 (Forecasting Loss:0.1658 + XiCon Loss:3.5648 x Lambda(0.01)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1949
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1930741
	speed: 0.1425s/iter; left time: 3451.8038s
	iters: 200, epoch: 6 | loss: 0.1960037
	speed: 0.1401s/iter; left time: 3378.2900s
Epoch: 6 cost time: 35.906466245651245
Epoch: 6, Steps: 256 Train Loss: 0.1956 (Forecasting Loss:0.1598 + XiCon Loss:3.5815 x Lambda(0.01)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.1960
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1953131
	speed: 0.1410s/iter; left time: 3378.2028s
	iters: 200, epoch: 7 | loss: 0.1889262
	speed: 0.1389s/iter; left time: 3315.4477s
Epoch: 7 cost time: 36.00650429725647
Epoch: 7, Steps: 256 Train Loss: 0.1927 (Forecasting Loss:0.1568 + XiCon Loss:3.5823 x Lambda(0.01)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.2004
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1880744
	speed: 0.1420s/iter; left time: 3367.7672s
	iters: 200, epoch: 8 | loss: 0.1872517
	speed: 0.1418s/iter; left time: 3346.6767s
Epoch: 8 cost time: 36.26560115814209
Epoch: 8, Steps: 256 Train Loss: 0.1912 (Forecasting Loss:0.1553 + XiCon Loss:3.5905 x Lambda(0.01)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.1993
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1899784
	speed: 0.1407s/iter; left time: 3300.4569s
	iters: 200, epoch: 9 | loss: 0.1900503
	speed: 0.1382s/iter; left time: 3226.4294s
Epoch: 9 cost time: 35.704397439956665
Epoch: 9, Steps: 256 Train Loss: 0.1904 (Forecasting Loss:0.1545 + XiCon Loss:3.5933 x Lambda(0.01)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.2011
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1929858
	speed: 0.1420s/iter; left time: 3293.5822s
	iters: 200, epoch: 10 | loss: 0.1876841
	speed: 0.1387s/iter; left time: 3204.3414s
Epoch: 10 cost time: 35.73304295539856
Epoch: 10, Steps: 256 Train Loss: 0.1900 (Forecasting Loss:0.1541 + XiCon Loss:3.5947 x Lambda(0.01)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.2026
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1975208
	speed: 0.1415s/iter; left time: 3246.3614s
	iters: 200, epoch: 11 | loss: 0.1936197
	speed: 0.1355s/iter; left time: 3094.3726s
Epoch: 11 cost time: 35.61637496948242
Epoch: 11, Steps: 256 Train Loss: 0.1898 (Forecasting Loss:0.1539 + XiCon Loss:3.5929 x Lambda(0.01)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.2015
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08447305858135223, mae:0.2252030223608017, mape:0.16653065383434296, mspe:0.04498155787587166 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9629
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3158112
	speed: 0.1267s/iter; left time: 3231.8915s
	iters: 200, epoch: 1 | loss: 0.3344537
	speed: 0.1237s/iter; left time: 3142.0011s
Epoch: 1 cost time: 32.32819628715515
Epoch: 1, Steps: 256 Train Loss: 0.3224 (Forecasting Loss:0.2872 + XiCon Loss:3.5136 x Lambda(0.01)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1527
Validation loss decreased (inf --> 0.198390).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2953615
	speed: 0.1800s/iter; left time: 4545.2678s
	iters: 200, epoch: 2 | loss: 0.3097288
	speed: 0.1894s/iter; left time: 4761.4815s
Epoch: 2 cost time: 47.16913652420044
Epoch: 2, Steps: 256 Train Loss: 0.3141 (Forecasting Loss:0.2792 + XiCon Loss:3.4878 x Lambda(0.01)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1644
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2457494
	speed: 0.1843s/iter; left time: 4605.6469s
	iters: 200, epoch: 3 | loss: 0.2525167
	speed: 0.1803s/iter; left time: 4487.8608s
Epoch: 3 cost time: 46.87889647483826
Epoch: 3, Steps: 256 Train Loss: 0.2573 (Forecasting Loss:0.2230 + XiCon Loss:3.4292 x Lambda(0.01)), Vali MSE Loss: 0.2251 Test MSE Loss: 0.1798
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2390200
	speed: 0.1798s/iter; left time: 4447.5800s
	iters: 200, epoch: 4 | loss: 0.2434400
	speed: 0.1848s/iter; left time: 4551.7876s
Epoch: 4 cost time: 46.66919207572937
Epoch: 4, Steps: 256 Train Loss: 0.2413 (Forecasting Loss:0.2069 + XiCon Loss:3.4334 x Lambda(0.01)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1808
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2302486
	speed: 0.1839s/iter; left time: 4501.3341s
	iters: 200, epoch: 5 | loss: 0.2441595
	speed: 0.1796s/iter; left time: 4377.3203s
Epoch: 5 cost time: 46.9474995136261
Epoch: 5, Steps: 256 Train Loss: 0.2355 (Forecasting Loss:0.2010 + XiCon Loss:3.4511 x Lambda(0.01)), Vali MSE Loss: 0.2175 Test MSE Loss: 0.1838
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2386553
	speed: 0.1801s/iter; left time: 4363.2885s
	iters: 200, epoch: 6 | loss: 0.2293697
	speed: 0.1873s/iter; left time: 4518.1377s
Epoch: 6 cost time: 46.947731494903564
Epoch: 6, Steps: 256 Train Loss: 0.2328 (Forecasting Loss:0.1981 + XiCon Loss:3.4631 x Lambda(0.01)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1827
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2354671
	speed: 0.1833s/iter; left time: 4392.5233s
	iters: 200, epoch: 7 | loss: 0.2355898
	speed: 0.1829s/iter; left time: 4365.3819s
Epoch: 7 cost time: 47.00287699699402
Epoch: 7, Steps: 256 Train Loss: 0.2311 (Forecasting Loss:0.1964 + XiCon Loss:3.4675 x Lambda(0.01)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1829
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2348287
	speed: 0.1824s/iter; left time: 4325.1002s
	iters: 200, epoch: 8 | loss: 0.2368854
	speed: 0.1880s/iter; left time: 4438.9496s
Epoch: 8 cost time: 47.33463191986084
Epoch: 8, Steps: 256 Train Loss: 0.2303 (Forecasting Loss:0.1955 + XiCon Loss:3.4732 x Lambda(0.01)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1842
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2350046
	speed: 0.1835s/iter; left time: 4303.4862s
	iters: 200, epoch: 9 | loss: 0.2253228
	speed: 0.1822s/iter; left time: 4255.6459s
Epoch: 9 cost time: 46.53882932662964
Epoch: 9, Steps: 256 Train Loss: 0.2299 (Forecasting Loss:0.1951 + XiCon Loss:3.4753 x Lambda(0.01)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.1843
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2319069
	speed: 0.1846s/iter; left time: 4281.1645s
	iters: 200, epoch: 10 | loss: 0.2231205
	speed: 0.1779s/iter; left time: 4109.5566s
Epoch: 10 cost time: 46.33537220954895
Epoch: 10, Steps: 256 Train Loss: 0.2295 (Forecasting Loss:0.1948 + XiCon Loss:3.4755 x Lambda(0.01)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1849
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2277721
	speed: 0.1792s/iter; left time: 4110.6275s
	iters: 200, epoch: 11 | loss: 0.2271914
	speed: 0.1855s/iter; left time: 4237.7488s
Epoch: 11 cost time: 46.74331855773926
Epoch: 11, Steps: 256 Train Loss: 0.2295 (Forecasting Loss:0.1947 + XiCon Loss:3.4777 x Lambda(0.01)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.1850
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08260771632194519, mae:0.2227211445569992, mape:0.16563192009925842, mspe:0.04481656476855278 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6686
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3170085
	speed: 0.1254s/iter; left time: 3197.0839s
	iters: 200, epoch: 1 | loss: 0.3116919
	speed: 0.1300s/iter; left time: 3301.4443s
Epoch: 1 cost time: 32.68190145492554
Epoch: 1, Steps: 256 Train Loss: 0.3290 (Forecasting Loss:0.2939 + XiCon Loss:3.5089 x Lambda(0.01)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1599
Validation loss decreased (inf --> 0.205819).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2709552
	speed: 0.1451s/iter; left time: 3662.2146s
	iters: 200, epoch: 2 | loss: 0.2539718
	speed: 0.1231s/iter; left time: 3094.7178s
Epoch: 2 cost time: 34.745901346206665
Epoch: 2, Steps: 256 Train Loss: 0.2768 (Forecasting Loss:0.2425 + XiCon Loss:3.4355 x Lambda(0.01)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1751
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2254361
	speed: 0.1341s/iter; left time: 3349.8506s
	iters: 200, epoch: 3 | loss: 0.2138517
	speed: 0.1627s/iter; left time: 4048.8887s
Epoch: 3 cost time: 39.17694091796875
Epoch: 3, Steps: 256 Train Loss: 0.2230 (Forecasting Loss:0.1879 + XiCon Loss:3.5177 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1818
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1938927
	speed: 0.1487s/iter; left time: 3677.9156s
	iters: 200, epoch: 4 | loss: 0.1927449
	speed: 0.1705s/iter; left time: 4200.0366s
Epoch: 4 cost time: 41.20841121673584
Epoch: 4, Steps: 256 Train Loss: 0.1999 (Forecasting Loss:0.1641 + XiCon Loss:3.5781 x Lambda(0.01)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1956
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1871773
	speed: 0.1710s/iter; left time: 4185.4586s
	iters: 200, epoch: 5 | loss: 0.1862285
	speed: 0.1233s/iter; left time: 3006.5961s
Epoch: 5 cost time: 38.851189613342285
Epoch: 5, Steps: 256 Train Loss: 0.1893 (Forecasting Loss:0.1533 + XiCon Loss:3.5985 x Lambda(0.01)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.1923
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1922160
	speed: 0.1730s/iter; left time: 4189.8423s
	iters: 200, epoch: 6 | loss: 0.1822215
	speed: 0.1563s/iter; left time: 3769.8761s
Epoch: 6 cost time: 39.30085062980652
Epoch: 6, Steps: 256 Train Loss: 0.1846 (Forecasting Loss:0.1486 + XiCon Loss:3.6002 x Lambda(0.01)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1953
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1776233
	speed: 0.1754s/iter; left time: 4203.5740s
	iters: 200, epoch: 7 | loss: 0.1839416
	speed: 0.1729s/iter; left time: 4126.0232s
Epoch: 7 cost time: 44.07508134841919
Epoch: 7, Steps: 256 Train Loss: 0.1822 (Forecasting Loss:0.1462 + XiCon Loss:3.6023 x Lambda(0.01)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1949
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1838751
	speed: 0.1532s/iter; left time: 3633.0108s
	iters: 200, epoch: 8 | loss: 0.1774574
	speed: 0.1682s/iter; left time: 3970.5100s
Epoch: 8 cost time: 41.672163009643555
Epoch: 8, Steps: 256 Train Loss: 0.1811 (Forecasting Loss:0.1450 + XiCon Loss:3.6037 x Lambda(0.01)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.1938
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1825888
	speed: 0.1298s/iter; left time: 3043.4198s
	iters: 200, epoch: 9 | loss: 0.1802280
	speed: 0.1562s/iter; left time: 3648.8639s
Epoch: 9 cost time: 38.439539432525635
Epoch: 9, Steps: 256 Train Loss: 0.1805 (Forecasting Loss:0.1444 + XiCon Loss:3.6040 x Lambda(0.01)), Vali MSE Loss: 0.2172 Test MSE Loss: 0.1948
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1703088
	speed: 0.1738s/iter; left time: 4031.2545s
	iters: 200, epoch: 10 | loss: 0.1842265
	speed: 0.1206s/iter; left time: 2786.4922s
Epoch: 10 cost time: 38.561490058898926
Epoch: 10, Steps: 256 Train Loss: 0.1801 (Forecasting Loss:0.1441 + XiCon Loss:3.5994 x Lambda(0.01)), Vali MSE Loss: 0.2172 Test MSE Loss: 0.1951
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1798159
	speed: 0.1742s/iter; left time: 3996.4359s
	iters: 200, epoch: 11 | loss: 0.1753838
	speed: 0.1669s/iter; left time: 3812.3113s
Epoch: 11 cost time: 41.12278127670288
Epoch: 11, Steps: 256 Train Loss: 0.1799 (Forecasting Loss:0.1439 + XiCon Loss:3.6023 x Lambda(0.01)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.1952
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08764845877885818, mae:0.23205804824829102, mape:0.17225858569145203, mspe:0.047600895166397095 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1605
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3214679
	speed: 0.1306s/iter; left time: 3330.4247s
	iters: 200, epoch: 1 | loss: 0.3138367
	speed: 0.1084s/iter; left time: 2752.9944s
Epoch: 1 cost time: 28.39837908744812
Epoch: 1, Steps: 256 Train Loss: 0.3228 (Forecasting Loss:0.2875 + XiCon Loss:3.5276 x Lambda(0.01)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1517
Validation loss decreased (inf --> 0.200605).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3056847
	speed: 0.1563s/iter; left time: 3945.7568s
	iters: 200, epoch: 2 | loss: 0.2756942
	speed: 0.1709s/iter; left time: 4296.5496s
Epoch: 2 cost time: 42.498008251190186
Epoch: 2, Steps: 256 Train Loss: 0.2980 (Forecasting Loss:0.2629 + XiCon Loss:3.5026 x Lambda(0.01)), Vali MSE Loss: 0.2334 Test MSE Loss: 0.1713
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2440980
	speed: 0.1467s/iter; left time: 3666.1178s
	iters: 200, epoch: 3 | loss: 0.2300260
	speed: 0.1815s/iter; left time: 4517.4009s
Epoch: 3 cost time: 43.11679697036743
Epoch: 3, Steps: 256 Train Loss: 0.2403 (Forecasting Loss:0.2052 + XiCon Loss:3.5127 x Lambda(0.01)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.1676
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2161628
	speed: 0.1367s/iter; left time: 3380.8347s
	iters: 200, epoch: 4 | loss: 0.2182410
	speed: 0.1791s/iter; left time: 4412.7984s
Epoch: 4 cost time: 42.007787227630615
Epoch: 4, Steps: 256 Train Loss: 0.2212 (Forecasting Loss:0.1857 + XiCon Loss:3.5493 x Lambda(0.01)), Vali MSE Loss: 0.2333 Test MSE Loss: 0.1833
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2035195
	speed: 0.1764s/iter; left time: 4318.0175s
	iters: 200, epoch: 5 | loss: 0.2136859
	speed: 0.1738s/iter; left time: 4237.8887s
Epoch: 5 cost time: 45.04588294029236
Epoch: 5, Steps: 256 Train Loss: 0.2110 (Forecasting Loss:0.1752 + XiCon Loss:3.5780 x Lambda(0.01)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.1872
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2056213
	speed: 0.1754s/iter; left time: 4248.4723s
	iters: 200, epoch: 6 | loss: 0.2062905
	speed: 0.1761s/iter; left time: 4248.7040s
Epoch: 6 cost time: 45.19740700721741
Epoch: 6, Steps: 256 Train Loss: 0.2056 (Forecasting Loss:0.1697 + XiCon Loss:3.5908 x Lambda(0.01)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1879
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1974619
	speed: 0.1741s/iter; left time: 4172.0450s
	iters: 200, epoch: 7 | loss: 0.2078165
	speed: 0.1767s/iter; left time: 4215.8201s
Epoch: 7 cost time: 45.26088237762451
Epoch: 7, Steps: 256 Train Loss: 0.2029 (Forecasting Loss:0.1669 + XiCon Loss:3.5975 x Lambda(0.01)), Vali MSE Loss: 0.2340 Test MSE Loss: 0.1874
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2102993
	speed: 0.1758s/iter; left time: 4167.8292s
	iters: 200, epoch: 8 | loss: 0.1983821
	speed: 0.1761s/iter; left time: 4158.2399s
Epoch: 8 cost time: 45.23180031776428
Epoch: 8, Steps: 256 Train Loss: 0.2015 (Forecasting Loss:0.1654 + XiCon Loss:3.6054 x Lambda(0.01)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.1894
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1994877
	speed: 0.1778s/iter; left time: 4170.6656s
	iters: 200, epoch: 9 | loss: 0.2030404
	speed: 0.1727s/iter; left time: 4032.8505s
Epoch: 9 cost time: 45.253233909606934
Epoch: 9, Steps: 256 Train Loss: 0.2005 (Forecasting Loss:0.1645 + XiCon Loss:3.6019 x Lambda(0.01)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.1889
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1910236
	speed: 0.1780s/iter; left time: 4129.6096s
	iters: 200, epoch: 10 | loss: 0.2016905
	speed: 0.1719s/iter; left time: 3971.5176s
Epoch: 10 cost time: 45.316118001937866
Epoch: 10, Steps: 256 Train Loss: 0.2002 (Forecasting Loss:0.1642 + XiCon Loss:3.5994 x Lambda(0.01)), Vali MSE Loss: 0.2340 Test MSE Loss: 0.1879
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2039189
	speed: 0.1812s/iter; left time: 4156.7984s
	iters: 200, epoch: 11 | loss: 0.1994101
	speed: 0.1734s/iter; left time: 3960.9587s
Epoch: 11 cost time: 45.64766049385071
Epoch: 11, Steps: 256 Train Loss: 0.1999 (Forecasting Loss:0.1639 + XiCon Loss:3.6023 x Lambda(0.01)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1879
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08145192265510559, mae:0.22190164029598236, mape:0.16585248708724976, mspe:0.045178573578596115 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0847+-0.00350, MAE:0.2266+-0.00587, MAPE:0.1681+-0.00366, MSPE:0.0457+-0.00141, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9099
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3435363
	speed: 0.1767s/iter; left time: 4294.8609s
	iters: 200, epoch: 1 | loss: 0.3184089
	speed: 0.1969s/iter; left time: 4766.3741s
Epoch: 1 cost time: 47.60590076446533
Epoch: 1, Steps: 244 Train Loss: 0.3528 (Forecasting Loss:0.3492 + XiCon Loss:3.5880 x Lambda(0.001)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1565
Validation loss decreased (inf --> 0.228261).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3093123
	speed: 0.2415s/iter; left time: 5810.4391s
	iters: 200, epoch: 2 | loss: 0.2722028
	speed: 0.2317s/iter; left time: 5551.4078s
Epoch: 2 cost time: 57.69621539115906
Epoch: 2, Steps: 244 Train Loss: 0.3003 (Forecasting Loss:0.2968 + XiCon Loss:3.5367 x Lambda(0.001)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.1581
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2555562
	speed: 0.2285s/iter; left time: 5440.6298s
	iters: 200, epoch: 3 | loss: 0.2439757
	speed: 0.2211s/iter; left time: 5243.9170s
Epoch: 3 cost time: 55.15745806694031
Epoch: 3, Steps: 244 Train Loss: 0.2540 (Forecasting Loss:0.2505 + XiCon Loss:3.4885 x Lambda(0.001)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.1534
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2286588
	speed: 0.2300s/iter; left time: 5421.3137s
	iters: 200, epoch: 4 | loss: 0.2342544
	speed: 0.2233s/iter; left time: 5240.5380s
Epoch: 4 cost time: 55.23435878753662
Epoch: 4, Steps: 244 Train Loss: 0.2342 (Forecasting Loss:0.2307 + XiCon Loss:3.4719 x Lambda(0.001)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.1578
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2301937
	speed: 0.2318s/iter; left time: 5406.6556s
	iters: 200, epoch: 5 | loss: 0.2283893
	speed: 0.2229s/iter; left time: 5176.2558s
Epoch: 5 cost time: 56.041250228881836
Epoch: 5, Steps: 244 Train Loss: 0.2267 (Forecasting Loss:0.2233 + XiCon Loss:3.4648 x Lambda(0.001)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.1597
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2209039
	speed: 0.2296s/iter; left time: 5299.2188s
	iters: 200, epoch: 6 | loss: 0.2255308
	speed: 0.2250s/iter; left time: 5171.3548s
Epoch: 6 cost time: 56.038063764572144
Epoch: 6, Steps: 244 Train Loss: 0.2229 (Forecasting Loss:0.2194 + XiCon Loss:3.4637 x Lambda(0.001)), Vali MSE Loss: 0.3170 Test MSE Loss: 0.1607
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2132259
	speed: 0.2270s/iter; left time: 5183.1591s
	iters: 200, epoch: 7 | loss: 0.2197877
	speed: 0.2250s/iter; left time: 5116.8715s
Epoch: 7 cost time: 55.12653875350952
Epoch: 7, Steps: 244 Train Loss: 0.2212 (Forecasting Loss:0.2177 + XiCon Loss:3.4625 x Lambda(0.001)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.1642
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2288008
	speed: 0.2221s/iter; left time: 5016.7847s
	iters: 200, epoch: 8 | loss: 0.2186570
	speed: 0.2299s/iter; left time: 5170.9437s
Epoch: 8 cost time: 55.78827404975891
Epoch: 8, Steps: 244 Train Loss: 0.2204 (Forecasting Loss:0.2169 + XiCon Loss:3.4614 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.1657
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2094978
	speed: 0.2285s/iter; left time: 5106.0835s
	iters: 200, epoch: 9 | loss: 0.2160964
	speed: 0.2309s/iter; left time: 5138.3731s
Epoch: 9 cost time: 56.21894097328186
Epoch: 9, Steps: 244 Train Loss: 0.2199 (Forecasting Loss:0.2164 + XiCon Loss:3.4611 x Lambda(0.001)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.1645
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2174034
	speed: 0.2316s/iter; left time: 5120.3340s
	iters: 200, epoch: 10 | loss: 0.2151129
	speed: 0.2200s/iter; left time: 4840.7406s
Epoch: 10 cost time: 55.781171798706055
Epoch: 10, Steps: 244 Train Loss: 0.2198 (Forecasting Loss:0.2163 + XiCon Loss:3.4607 x Lambda(0.001)), Vali MSE Loss: 0.3300 Test MSE Loss: 0.1646
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2050626
	speed: 0.2293s/iter; left time: 5012.4142s
	iters: 200, epoch: 11 | loss: 0.2130629
	speed: 0.2230s/iter; left time: 4853.0049s
Epoch: 11 cost time: 55.47084164619446
Epoch: 11, Steps: 244 Train Loss: 0.2197 (Forecasting Loss:0.2162 + XiCon Loss:3.4611 x Lambda(0.001)), Vali MSE Loss: 0.3254 Test MSE Loss: 0.1641
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08478239923715591, mae:0.22814592719078064, mape:0.16172584891319275, mspe:0.039977796375751495 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 24.8672
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3345911
	speed: 0.1407s/iter; left time: 3418.9602s
	iters: 200, epoch: 1 | loss: 0.3397067
	speed: 0.1601s/iter; left time: 3874.7616s
Epoch: 1 cost time: 37.520105600357056
Epoch: 1, Steps: 244 Train Loss: 0.3422 (Forecasting Loss:0.3386 + XiCon Loss:3.5763 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1588
Validation loss decreased (inf --> 0.221885).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3085136
	speed: 0.2358s/iter; left time: 5673.6038s
	iters: 200, epoch: 2 | loss: 0.2885893
	speed: 0.2495s/iter; left time: 5976.5146s
Epoch: 2 cost time: 59.51661467552185
Epoch: 2, Steps: 244 Train Loss: 0.3205 (Forecasting Loss:0.3169 + XiCon Loss:3.5192 x Lambda(0.001)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2589155
	speed: 0.2069s/iter; left time: 4926.0152s
	iters: 200, epoch: 3 | loss: 0.2525565
	speed: 0.2564s/iter; left time: 6079.2838s
Epoch: 3 cost time: 57.15867853164673
Epoch: 3, Steps: 244 Train Loss: 0.2613 (Forecasting Loss:0.2578 + XiCon Loss:3.4954 x Lambda(0.001)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1550
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2357195
	speed: 0.2110s/iter; left time: 4973.3578s
	iters: 200, epoch: 4 | loss: 0.2272021
	speed: 0.2479s/iter; left time: 5818.7787s
Epoch: 4 cost time: 56.73558735847473
Epoch: 4, Steps: 244 Train Loss: 0.2432 (Forecasting Loss:0.2397 + XiCon Loss:3.4824 x Lambda(0.001)), Vali MSE Loss: 0.2753 Test MSE Loss: 0.1560
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2497023
	speed: 0.2076s/iter; left time: 4843.0037s
	iters: 200, epoch: 5 | loss: 0.2373883
	speed: 0.2392s/iter; left time: 5554.3703s
Epoch: 5 cost time: 55.04027199745178
Epoch: 5, Steps: 244 Train Loss: 0.2348 (Forecasting Loss:0.2313 + XiCon Loss:3.4788 x Lambda(0.001)), Vali MSE Loss: 0.2791 Test MSE Loss: 0.1628
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2283122
	speed: 0.2428s/iter; left time: 5603.6907s
	iters: 200, epoch: 6 | loss: 0.2361136
	speed: 0.2393s/iter; left time: 5499.9711s
Epoch: 6 cost time: 58.86954879760742
Epoch: 6, Steps: 244 Train Loss: 0.2311 (Forecasting Loss:0.2276 + XiCon Loss:3.4763 x Lambda(0.001)), Vali MSE Loss: 0.2772 Test MSE Loss: 0.1604
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2319787
	speed: 0.2364s/iter; left time: 5398.1158s
	iters: 200, epoch: 7 | loss: 0.2305599
	speed: 0.2423s/iter; left time: 5508.8697s
Epoch: 7 cost time: 59.19070863723755
Epoch: 7, Steps: 244 Train Loss: 0.2291 (Forecasting Loss:0.2256 + XiCon Loss:3.4748 x Lambda(0.001)), Vali MSE Loss: 0.2834 Test MSE Loss: 0.1608
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2275633
	speed: 0.2274s/iter; left time: 5137.4493s
	iters: 200, epoch: 8 | loss: 0.2177589
	speed: 0.2386s/iter; left time: 5366.7558s
Epoch: 8 cost time: 57.71003723144531
Epoch: 8, Steps: 244 Train Loss: 0.2281 (Forecasting Loss:0.2246 + XiCon Loss:3.4751 x Lambda(0.001)), Vali MSE Loss: 0.2805 Test MSE Loss: 0.1595
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2260079
	speed: 0.2163s/iter; left time: 4833.9294s
	iters: 200, epoch: 9 | loss: 0.2317743
	speed: 0.2381s/iter; left time: 5297.7703s
Epoch: 9 cost time: 56.43656301498413
Epoch: 9, Steps: 244 Train Loss: 0.2275 (Forecasting Loss:0.2241 + XiCon Loss:3.4741 x Lambda(0.001)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.1607
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2383718
	speed: 0.2123s/iter; left time: 4693.8018s
	iters: 200, epoch: 10 | loss: 0.2256163
	speed: 0.2315s/iter; left time: 5095.1991s
Epoch: 10 cost time: 55.67670392990112
Epoch: 10, Steps: 244 Train Loss: 0.2273 (Forecasting Loss:0.2238 + XiCon Loss:3.4737 x Lambda(0.001)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.1608
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2247621
	speed: 0.1953s/iter; left time: 4270.1968s
	iters: 200, epoch: 11 | loss: 0.2303960
	speed: 0.2390s/iter; left time: 5200.3216s
Epoch: 11 cost time: 53.990601778030396
Epoch: 11, Steps: 244 Train Loss: 0.2272 (Forecasting Loss:0.2237 + XiCon Loss:3.4738 x Lambda(0.001)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.1609
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08615794777870178, mae:0.23149865865707397, mape:0.16736146807670593, mspe:0.0436602383852005 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7254
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3780313
	speed: 0.1683s/iter; left time: 4089.9512s
	iters: 200, epoch: 1 | loss: 0.3456207
	speed: 0.1550s/iter; left time: 3750.8340s
Epoch: 1 cost time: 40.93786549568176
Epoch: 1, Steps: 244 Train Loss: 0.3564 (Forecasting Loss:0.3528 + XiCon Loss:3.5659 x Lambda(0.001)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1521
Validation loss decreased (inf --> 0.235646).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3017606
	speed: 0.2087s/iter; left time: 5019.7138s
	iters: 200, epoch: 2 | loss: 0.2909361
	speed: 0.1992s/iter; left time: 4773.0883s
Epoch: 2 cost time: 49.8400719165802
Epoch: 2, Steps: 244 Train Loss: 0.3151 (Forecasting Loss:0.3116 + XiCon Loss:3.5508 x Lambda(0.001)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2704597
	speed: 0.2037s/iter; left time: 4850.3400s
	iters: 200, epoch: 3 | loss: 0.2559348
	speed: 0.2003s/iter; left time: 4750.6267s
Epoch: 3 cost time: 49.45759439468384
Epoch: 3, Steps: 244 Train Loss: 0.2690 (Forecasting Loss:0.2655 + XiCon Loss:3.5420 x Lambda(0.001)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.1513
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2506041
	speed: 0.2038s/iter; left time: 4804.4439s
	iters: 200, epoch: 4 | loss: 0.2543442
	speed: 0.2045s/iter; left time: 4799.3059s
Epoch: 4 cost time: 49.97547364234924
Epoch: 4, Steps: 244 Train Loss: 0.2530 (Forecasting Loss:0.2495 + XiCon Loss:3.5193 x Lambda(0.001)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.1532
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2418342
	speed: 0.2071s/iter; left time: 4829.6716s
	iters: 200, epoch: 5 | loss: 0.2439409
	speed: 0.2037s/iter; left time: 4731.5886s
Epoch: 5 cost time: 50.162415981292725
Epoch: 5, Steps: 244 Train Loss: 0.2447 (Forecasting Loss:0.2412 + XiCon Loss:3.5088 x Lambda(0.001)), Vali MSE Loss: 0.3039 Test MSE Loss: 0.1513
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2427789
	speed: 0.2099s/iter; left time: 4844.4109s
	iters: 200, epoch: 6 | loss: 0.2259959
	speed: 0.2024s/iter; left time: 4652.3744s
Epoch: 6 cost time: 50.34964680671692
Epoch: 6, Steps: 244 Train Loss: 0.2403 (Forecasting Loss:0.2368 + XiCon Loss:3.5039 x Lambda(0.001)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.1536
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2556652
	speed: 0.2079s/iter; left time: 4747.4179s
	iters: 200, epoch: 7 | loss: 0.2378224
	speed: 0.2038s/iter; left time: 4633.8625s
Epoch: 7 cost time: 50.232160568237305
Epoch: 7, Steps: 244 Train Loss: 0.2377 (Forecasting Loss:0.2342 + XiCon Loss:3.4995 x Lambda(0.001)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1543
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2352592
	speed: 0.2042s/iter; left time: 4614.2235s
	iters: 200, epoch: 8 | loss: 0.2307214
	speed: 0.2045s/iter; left time: 4600.4323s
Epoch: 8 cost time: 50.24983072280884
Epoch: 8, Steps: 244 Train Loss: 0.2367 (Forecasting Loss:0.2332 + XiCon Loss:3.4988 x Lambda(0.001)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.1568
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2312075
	speed: 0.2068s/iter; left time: 4620.6861s
	iters: 200, epoch: 9 | loss: 0.2335485
	speed: 0.2054s/iter; left time: 4569.6194s
Epoch: 9 cost time: 50.34040117263794
Epoch: 9, Steps: 244 Train Loss: 0.2359 (Forecasting Loss:0.2324 + XiCon Loss:3.4975 x Lambda(0.001)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.1551
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2403453
	speed: 0.2086s/iter; left time: 4610.1301s
	iters: 200, epoch: 10 | loss: 0.2397711
	speed: 0.2045s/iter; left time: 4499.1423s
Epoch: 10 cost time: 50.30697703361511
Epoch: 10, Steps: 244 Train Loss: 0.2357 (Forecasting Loss:0.2322 + XiCon Loss:3.4966 x Lambda(0.001)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.1547
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2435236
	speed: 0.2091s/iter; left time: 4570.9006s
	iters: 200, epoch: 11 | loss: 0.2344515
	speed: 0.2034s/iter; left time: 4427.2059s
Epoch: 11 cost time: 50.48744249343872
Epoch: 11, Steps: 244 Train Loss: 0.2354 (Forecasting Loss:0.2319 + XiCon Loss:3.4968 x Lambda(0.001)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.1553
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08023922145366669, mae:0.2239588052034378, mape:0.16083547472953796, mspe:0.03969426080584526 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8164
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3649276
	speed: 0.1677s/iter; left time: 4076.1793s
	iters: 200, epoch: 1 | loss: 0.3297414
	speed: 0.1642s/iter; left time: 3974.5008s
Epoch: 1 cost time: 40.96287655830383
Epoch: 1, Steps: 244 Train Loss: 0.3495 (Forecasting Loss:0.3460 + XiCon Loss:3.5642 x Lambda(0.001)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1486
Validation loss decreased (inf --> 0.240119).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2921579
	speed: 0.2250s/iter; left time: 5412.7248s
	iters: 200, epoch: 2 | loss: 0.2701982
	speed: 0.2153s/iter; left time: 5157.3862s
Epoch: 2 cost time: 54.170881032943726
Epoch: 2, Steps: 244 Train Loss: 0.2980 (Forecasting Loss:0.2945 + XiCon Loss:3.5121 x Lambda(0.001)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1646
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2736402
	speed: 0.2079s/iter; left time: 4949.7629s
	iters: 200, epoch: 3 | loss: 0.2628790
	speed: 0.2066s/iter; left time: 4899.2027s
Epoch: 3 cost time: 50.67449069023132
Epoch: 3, Steps: 244 Train Loss: 0.2612 (Forecasting Loss:0.2577 + XiCon Loss:3.5144 x Lambda(0.001)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.1615
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2399198
	speed: 0.2127s/iter; left time: 5012.3144s
	iters: 200, epoch: 4 | loss: 0.2412450
	speed: 0.2070s/iter; left time: 4859.0122s
Epoch: 4 cost time: 51.14826035499573
Epoch: 4, Steps: 244 Train Loss: 0.2419 (Forecasting Loss:0.2383 + XiCon Loss:3.5133 x Lambda(0.001)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.1705
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2335137
	speed: 0.2075s/iter; left time: 4840.5425s
	iters: 200, epoch: 5 | loss: 0.2374256
	speed: 0.1712s/iter; left time: 3976.4104s
Epoch: 5 cost time: 45.38695526123047
Epoch: 5, Steps: 244 Train Loss: 0.2335 (Forecasting Loss:0.2300 + XiCon Loss:3.5108 x Lambda(0.001)), Vali MSE Loss: 0.2975 Test MSE Loss: 0.1634
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2313742
	speed: 0.2088s/iter; left time: 4820.3200s
	iters: 200, epoch: 6 | loss: 0.2258924
	speed: 0.2097s/iter; left time: 4819.0110s
Epoch: 6 cost time: 50.88196682929993
Epoch: 6, Steps: 244 Train Loss: 0.2295 (Forecasting Loss:0.2260 + XiCon Loss:3.5085 x Lambda(0.001)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.1701
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2230275
	speed: 0.2094s/iter; left time: 4782.4940s
	iters: 200, epoch: 7 | loss: 0.2256324
	speed: 0.2047s/iter; left time: 4654.7376s
Epoch: 7 cost time: 50.63872408866882
Epoch: 7, Steps: 244 Train Loss: 0.2272 (Forecasting Loss:0.2237 + XiCon Loss:3.5069 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.1679
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2244586
	speed: 0.2076s/iter; left time: 4689.6124s
	iters: 200, epoch: 8 | loss: 0.2296699
	speed: 0.2090s/iter; left time: 4701.3470s
Epoch: 8 cost time: 50.80780649185181
Epoch: 8, Steps: 244 Train Loss: 0.2259 (Forecasting Loss:0.2224 + XiCon Loss:3.5054 x Lambda(0.001)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.1695
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2215685
	speed: 0.2129s/iter; left time: 4757.2225s
	iters: 200, epoch: 9 | loss: 0.2241816
	speed: 0.2075s/iter; left time: 4616.9148s
Epoch: 9 cost time: 51.18983197212219
Epoch: 9, Steps: 244 Train Loss: 0.2255 (Forecasting Loss:0.2220 + XiCon Loss:3.5052 x Lambda(0.001)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.1694
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2219300
	speed: 0.2071s/iter; left time: 4577.5432s
	iters: 200, epoch: 10 | loss: 0.2309074
	speed: 0.2111s/iter; left time: 4645.2687s
Epoch: 10 cost time: 50.95922493934631
Epoch: 10, Steps: 244 Train Loss: 0.2252 (Forecasting Loss:0.2217 + XiCon Loss:3.5045 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.1699
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2347232
	speed: 0.2090s/iter; left time: 4568.6267s
	iters: 200, epoch: 11 | loss: 0.2278030
	speed: 0.2079s/iter; left time: 4523.9951s
Epoch: 11 cost time: 50.956249713897705
Epoch: 11, Steps: 244 Train Loss: 0.2250 (Forecasting Loss:0.2215 + XiCon Loss:3.5049 x Lambda(0.001)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.1702
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.07752027362585068, mae:0.2196982204914093, mape:0.1578778326511383, mspe:0.038473840802907944 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6680
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3529765
	speed: 0.1612s/iter; left time: 3916.7586s
	iters: 200, epoch: 1 | loss: 0.2788807
	speed: 0.1707s/iter; left time: 4130.7876s
Epoch: 1 cost time: 40.82670474052429
Epoch: 1, Steps: 244 Train Loss: 0.3456 (Forecasting Loss:0.3420 + XiCon Loss:3.5688 x Lambda(0.001)), Vali MSE Loss: 0.2347 Test MSE Loss: 0.1629
Validation loss decreased (inf --> 0.234740).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3228284
	speed: 0.2267s/iter; left time: 5454.1193s
	iters: 200, epoch: 2 | loss: 0.2920310
	speed: 0.2393s/iter; left time: 5733.6870s
Epoch: 2 cost time: 57.16379952430725
Epoch: 2, Steps: 244 Train Loss: 0.3331 (Forecasting Loss:0.3296 + XiCon Loss:3.5225 x Lambda(0.001)), Vali MSE Loss: 0.2372 Test MSE Loss: 0.1608
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2507354
	speed: 0.2365s/iter; left time: 5632.4240s
	iters: 200, epoch: 3 | loss: 0.2784022
	speed: 0.2380s/iter; left time: 5642.5812s
Epoch: 3 cost time: 57.993173122406006
Epoch: 3, Steps: 244 Train Loss: 0.2689 (Forecasting Loss:0.2654 + XiCon Loss:3.4958 x Lambda(0.001)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.1506
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2460427
	speed: 0.2388s/iter; left time: 5628.5777s
	iters: 200, epoch: 4 | loss: 0.2493585
	speed: 0.2369s/iter; left time: 5560.4932s
Epoch: 4 cost time: 57.94867944717407
Epoch: 4, Steps: 244 Train Loss: 0.2497 (Forecasting Loss:0.2462 + XiCon Loss:3.4929 x Lambda(0.001)), Vali MSE Loss: 0.2673 Test MSE Loss: 0.1579
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2458693
	speed: 0.2356s/iter; left time: 5495.8980s
	iters: 200, epoch: 5 | loss: 0.2400233
	speed: 0.2314s/iter; left time: 5373.2948s
Epoch: 5 cost time: 57.0657856464386
Epoch: 5, Steps: 244 Train Loss: 0.2392 (Forecasting Loss:0.2357 + XiCon Loss:3.4915 x Lambda(0.001)), Vali MSE Loss: 0.2714 Test MSE Loss: 0.1592
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2410397
	speed: 0.2300s/iter; left time: 5309.0029s
	iters: 200, epoch: 6 | loss: 0.2337701
	speed: 0.2286s/iter; left time: 5252.6648s
Epoch: 6 cost time: 56.02126359939575
Epoch: 6, Steps: 244 Train Loss: 0.2344 (Forecasting Loss:0.2309 + XiCon Loss:3.4888 x Lambda(0.001)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.1579
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2281228
	speed: 0.2321s/iter; left time: 5299.7840s
	iters: 200, epoch: 7 | loss: 0.2276146
	speed: 0.2297s/iter; left time: 5223.1709s
Epoch: 7 cost time: 56.38246750831604
Epoch: 7, Steps: 244 Train Loss: 0.2319 (Forecasting Loss:0.2284 + XiCon Loss:3.4871 x Lambda(0.001)), Vali MSE Loss: 0.2769 Test MSE Loss: 0.1580
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2333707
	speed: 0.2292s/iter; left time: 5178.4877s
	iters: 200, epoch: 8 | loss: 0.2221137
	speed: 0.2279s/iter; left time: 5125.4798s
Epoch: 8 cost time: 55.89678931236267
Epoch: 8, Steps: 244 Train Loss: 0.2305 (Forecasting Loss:0.2270 + XiCon Loss:3.4873 x Lambda(0.001)), Vali MSE Loss: 0.2724 Test MSE Loss: 0.1585
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2333043
	speed: 0.2396s/iter; left time: 5355.2972s
	iters: 200, epoch: 9 | loss: 0.2363936
	speed: 0.2235s/iter; left time: 4971.8654s
Epoch: 9 cost time: 56.19121599197388
Epoch: 9, Steps: 244 Train Loss: 0.2298 (Forecasting Loss:0.2263 + XiCon Loss:3.4863 x Lambda(0.001)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.1575
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2360942
	speed: 0.2282s/iter; left time: 5045.4119s
	iters: 200, epoch: 10 | loss: 0.2226356
	speed: 0.2284s/iter; left time: 5026.7697s
Epoch: 10 cost time: 55.86532425880432
Epoch: 10, Steps: 244 Train Loss: 0.2293 (Forecasting Loss:0.2258 + XiCon Loss:3.4859 x Lambda(0.001)), Vali MSE Loss: 0.2753 Test MSE Loss: 0.1579
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2398870
	speed: 0.2276s/iter; left time: 4976.0410s
	iters: 200, epoch: 11 | loss: 0.2312320
	speed: 0.2308s/iter; left time: 5023.1137s
Epoch: 11 cost time: 56.01048159599304
Epoch: 11, Steps: 244 Train Loss: 0.2291 (Forecasting Loss:0.2256 + XiCon Loss:3.4864 x Lambda(0.001)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.1579
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08993428200483322, mae:0.23590901494026184, mape:0.16951414942741394, mspe:0.04447413608431816 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0837+-0.00609, MAE:0.2278+-0.00785, MAPE:0.1635+-0.00598, MSPE:0.0413+-0.00328, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7210
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7867293
	speed: 0.1571s/iter; left time: 3644.1178s
	iters: 200, epoch: 1 | loss: 0.7660443
	speed: 0.1402s/iter; left time: 3239.3335s
Epoch: 1 cost time: 32.94463610649109
Epoch: 1, Steps: 233 Train Loss: 0.7872 (Forecasting Loss:0.4293 + XiCon Loss:3.5795 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.1704
Validation loss decreased (inf --> 0.299219).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6923640
	speed: 0.0925s/iter; left time: 2124.9322s
	iters: 200, epoch: 2 | loss: 0.6349850
	speed: 0.1545s/iter; left time: 3533.7784s
Epoch: 2 cost time: 30.044183015823364
Epoch: 2, Steps: 233 Train Loss: 0.6797 (Forecasting Loss:0.3344 + XiCon Loss:3.4526 x Lambda(0.1)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1612
Validation loss decreased (0.299219 --> 0.241015).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6296437
	speed: 0.1585s/iter; left time: 3603.0534s
	iters: 200, epoch: 3 | loss: 0.6224692
	speed: 0.1455s/iter; left time: 3293.3959s
Epoch: 3 cost time: 35.632599115371704
Epoch: 3, Steps: 233 Train Loss: 0.6245 (Forecasting Loss:0.2853 + XiCon Loss:3.3923 x Lambda(0.1)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1543
Validation loss decreased (0.241015 --> 0.240557).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6179436
	speed: 0.1577s/iter; left time: 3549.3408s
	iters: 200, epoch: 4 | loss: 0.6100289
	speed: 0.1424s/iter; left time: 3191.1123s
Epoch: 4 cost time: 32.669081926345825
Epoch: 4, Steps: 233 Train Loss: 0.6145 (Forecasting Loss:0.2771 + XiCon Loss:3.3745 x Lambda(0.1)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1607
Validation loss decreased (0.240557 --> 0.230451).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6088772
	speed: 0.1629s/iter; left time: 3626.5091s
	iters: 200, epoch: 5 | loss: 0.6049508
	speed: 0.1575s/iter; left time: 3492.0909s
Epoch: 5 cost time: 37.424789905548096
Epoch: 5, Steps: 233 Train Loss: 0.6096 (Forecasting Loss:0.2730 + XiCon Loss:3.3652 x Lambda(0.1)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.1525
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6175681
	speed: 0.0989s/iter; left time: 2179.5855s
	iters: 200, epoch: 6 | loss: 0.6045795
	speed: 0.1570s/iter; left time: 3443.9852s
Epoch: 6 cost time: 30.915855407714844
Epoch: 6, Steps: 233 Train Loss: 0.6071 (Forecasting Loss:0.2710 + XiCon Loss:3.3614 x Lambda(0.1)), Vali MSE Loss: 0.2339 Test MSE Loss: 0.1564
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6207139
	speed: 0.1564s/iter; left time: 3410.4501s
	iters: 200, epoch: 7 | loss: 0.6185093
	speed: 0.1120s/iter; left time: 2429.6871s
Epoch: 7 cost time: 29.90888023376465
Epoch: 7, Steps: 233 Train Loss: 0.6057 (Forecasting Loss:0.2698 + XiCon Loss:3.3586 x Lambda(0.1)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1555
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5885173
	speed: 0.1602s/iter; left time: 3456.2516s
	iters: 200, epoch: 8 | loss: 0.6172359
	speed: 0.1564s/iter; left time: 3356.9921s
Epoch: 8 cost time: 36.55039978027344
Epoch: 8, Steps: 233 Train Loss: 0.6049 (Forecasting Loss:0.2692 + XiCon Loss:3.3573 x Lambda(0.1)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.1561
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5916081
	speed: 0.1045s/iter; left time: 2229.5750s
	iters: 200, epoch: 9 | loss: 0.6132745
	speed: 0.1596s/iter; left time: 3390.4586s
Epoch: 9 cost time: 31.70443344116211
Epoch: 9, Steps: 233 Train Loss: 0.6046 (Forecasting Loss:0.2689 + XiCon Loss:3.3570 x Lambda(0.1)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1568
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5979394
	speed: 0.1564s/iter; left time: 3300.9022s
	iters: 200, epoch: 10 | loss: 0.6025716
	speed: 0.0926s/iter; left time: 1945.8370s
Epoch: 10 cost time: 30.234639644622803
Epoch: 10, Steps: 233 Train Loss: 0.6042 (Forecasting Loss:0.2685 + XiCon Loss:3.3564 x Lambda(0.1)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1554
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.6156902
	speed: 0.1597s/iter; left time: 3332.9165s
	iters: 200, epoch: 11 | loss: 0.6091406
	speed: 0.1527s/iter; left time: 3170.8375s
Epoch: 11 cost time: 36.221755027770996
Epoch: 11, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.2686 + XiCon Loss:3.3567 x Lambda(0.1)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.1564
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.6087887
	speed: 0.1298s/iter; left time: 2678.2388s
	iters: 200, epoch: 12 | loss: 0.5831591
	speed: 0.1554s/iter; left time: 3191.2409s
Epoch: 12 cost time: 33.80812120437622
Epoch: 12, Steps: 233 Train Loss: 0.6041 (Forecasting Loss:0.2684 + XiCon Loss:3.3568 x Lambda(0.1)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1565
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.6116520
	speed: 0.1512s/iter; left time: 3084.4566s
	iters: 200, epoch: 13 | loss: 0.6067362
	speed: 0.1611s/iter; left time: 3270.8945s
Epoch: 13 cost time: 36.31814980506897
Epoch: 13, Steps: 233 Train Loss: 0.6039 (Forecasting Loss:0.2683 + XiCon Loss:3.3557 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1560
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5997355
	speed: 0.1568s/iter; left time: 3163.6701s
	iters: 200, epoch: 14 | loss: 0.5902218
	speed: 0.1511s/iter; left time: 3031.9735s
Epoch: 14 cost time: 36.034287214279175
Epoch: 14, Steps: 233 Train Loss: 0.6043 (Forecasting Loss:0.2686 + XiCon Loss:3.3575 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1562
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08698119968175888, mae:0.2343282401561737, mape:0.1670929342508316, mspe:0.04267379641532898 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.6035
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7983278
	speed: 0.1423s/iter; left time: 3301.1833s
	iters: 200, epoch: 1 | loss: 0.7488220
	speed: 0.1443s/iter; left time: 3332.5751s
Epoch: 1 cost time: 33.3607292175293
Epoch: 1, Steps: 233 Train Loss: 0.7843 (Forecasting Loss:0.4272 + XiCon Loss:3.5706 x Lambda(0.1)), Vali MSE Loss: 0.3015 Test MSE Loss: 0.1701
Validation loss decreased (inf --> 0.301525).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6773366
	speed: 0.1370s/iter; left time: 3145.6705s
	iters: 200, epoch: 2 | loss: 0.6515558
	speed: 0.1397s/iter; left time: 3195.1078s
Epoch: 2 cost time: 32.75853681564331
Epoch: 2, Steps: 233 Train Loss: 0.6770 (Forecasting Loss:0.3325 + XiCon Loss:3.4450 x Lambda(0.1)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1650
Validation loss decreased (0.301525 --> 0.234555).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6274703
	speed: 0.1416s/iter; left time: 3219.1437s
	iters: 200, epoch: 3 | loss: 0.6272632
	speed: 0.1412s/iter; left time: 3196.9748s
Epoch: 3 cost time: 33.13290190696716
Epoch: 3, Steps: 233 Train Loss: 0.6278 (Forecasting Loss:0.2868 + XiCon Loss:3.4099 x Lambda(0.1)), Vali MSE Loss: 0.2451 Test MSE Loss: 0.1512
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6175277
	speed: 0.1463s/iter; left time: 3292.3957s
	iters: 200, epoch: 4 | loss: 0.6145465
	speed: 0.1404s/iter; left time: 3145.4342s
Epoch: 4 cost time: 33.181647539138794
Epoch: 4, Steps: 233 Train Loss: 0.6154 (Forecasting Loss:0.2753 + XiCon Loss:3.4008 x Lambda(0.1)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1497
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6088002
	speed: 0.1468s/iter; left time: 3269.7620s
	iters: 200, epoch: 5 | loss: 0.5959541
	speed: 0.1438s/iter; left time: 3187.9865s
Epoch: 5 cost time: 33.67134475708008
Epoch: 5, Steps: 233 Train Loss: 0.6090 (Forecasting Loss:0.2695 + XiCon Loss:3.3946 x Lambda(0.1)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1477
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6093182
	speed: 0.1175s/iter; left time: 2588.8220s
	iters: 200, epoch: 6 | loss: 0.5970325
	speed: 0.0970s/iter; left time: 2127.1490s
Epoch: 6 cost time: 26.14926290512085
Epoch: 6, Steps: 233 Train Loss: 0.6059 (Forecasting Loss:0.2668 + XiCon Loss:3.3906 x Lambda(0.1)), Vali MSE Loss: 0.2442 Test MSE Loss: 0.1458
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5865089
	speed: 0.1441s/iter; left time: 3142.4745s
	iters: 200, epoch: 7 | loss: 0.6113955
	speed: 0.1383s/iter; left time: 3002.2265s
Epoch: 7 cost time: 32.860381841659546
Epoch: 7, Steps: 233 Train Loss: 0.6044 (Forecasting Loss:0.2655 + XiCon Loss:3.3892 x Lambda(0.1)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1453
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.6046912
	speed: 0.1104s/iter; left time: 2380.4434s
	iters: 200, epoch: 8 | loss: 0.5940444
	speed: 0.1471s/iter; left time: 3157.4019s
Epoch: 8 cost time: 30.575100898742676
Epoch: 8, Steps: 233 Train Loss: 0.6036 (Forecasting Loss:0.2648 + XiCon Loss:3.3888 x Lambda(0.1)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1447
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.6122262
	speed: 0.1413s/iter; left time: 3015.2201s
	iters: 200, epoch: 9 | loss: 0.6095008
	speed: 0.1346s/iter; left time: 2857.8128s
Epoch: 9 cost time: 32.512922525405884
Epoch: 9, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.2643 + XiCon Loss:3.3868 x Lambda(0.1)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1451
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.6177856
	speed: 0.1456s/iter; left time: 3071.8834s
	iters: 200, epoch: 10 | loss: 0.5952988
	speed: 0.1374s/iter; left time: 2885.6984s
Epoch: 10 cost time: 33.12733721733093
Epoch: 10, Steps: 233 Train Loss: 0.6032 (Forecasting Loss:0.2645 + XiCon Loss:3.3873 x Lambda(0.1)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1450
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.6068001
	speed: 0.1492s/iter; left time: 3114.0930s
	iters: 200, epoch: 11 | loss: 0.5975156
	speed: 0.1438s/iter; left time: 2987.7740s
Epoch: 11 cost time: 34.0089647769928
Epoch: 11, Steps: 233 Train Loss: 0.6028 (Forecasting Loss:0.2641 + XiCon Loss:3.3866 x Lambda(0.1)), Vali MSE Loss: 0.2465 Test MSE Loss: 0.1450
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.6085053
	speed: 0.1422s/iter; left time: 2934.7990s
	iters: 200, epoch: 12 | loss: 0.6073878
	speed: 0.1438s/iter; left time: 2952.5091s
Epoch: 12 cost time: 33.20369529724121
Epoch: 12, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.2640 + XiCon Loss:3.3870 x Lambda(0.1)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1452
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09079503268003464, mae:0.23921284079551697, mape:0.16966010630130768, mspe:0.04384591802954674 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.1391
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7872436
	speed: 0.1516s/iter; left time: 3517.6919s
	iters: 200, epoch: 1 | loss: 0.7906773
	speed: 0.1476s/iter; left time: 3409.7722s
Epoch: 1 cost time: 34.53849411010742
Epoch: 1, Steps: 233 Train Loss: 0.7996 (Forecasting Loss:0.4434 + XiCon Loss:3.5620 x Lambda(0.1)), Vali MSE Loss: 0.3003 Test MSE Loss: 0.1962
Validation loss decreased (inf --> 0.300262).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6470279
	speed: 0.1710s/iter; left time: 3927.3983s
	iters: 200, epoch: 2 | loss: 0.6168208
	speed: 0.1856s/iter; left time: 4244.3348s
Epoch: 2 cost time: 41.82094097137451
Epoch: 2, Steps: 233 Train Loss: 0.6676 (Forecasting Loss:0.3261 + XiCon Loss:3.4149 x Lambda(0.1)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.1449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6063266
	speed: 0.1841s/iter; left time: 4185.0030s
	iters: 200, epoch: 3 | loss: 0.6092995
	speed: 0.1902s/iter; left time: 4304.9815s
Epoch: 3 cost time: 43.658674240112305
Epoch: 3, Steps: 233 Train Loss: 0.6117 (Forecasting Loss:0.2788 + XiCon Loss:3.3293 x Lambda(0.1)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.1376
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5939941
	speed: 0.1835s/iter; left time: 4128.9822s
	iters: 200, epoch: 4 | loss: 0.5929635
	speed: 0.1838s/iter; left time: 4116.9615s
Epoch: 4 cost time: 42.80562400817871
Epoch: 4, Steps: 233 Train Loss: 0.6000 (Forecasting Loss:0.2720 + XiCon Loss:3.2804 x Lambda(0.1)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.1376
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5825993
	speed: 0.1528s/iter; left time: 3402.4495s
	iters: 200, epoch: 5 | loss: 0.5930151
	speed: 0.1632s/iter; left time: 3618.5880s
Epoch: 5 cost time: 37.66210103034973
Epoch: 5, Steps: 233 Train Loss: 0.5939 (Forecasting Loss:0.2677 + XiCon Loss:3.2619 x Lambda(0.1)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.1383
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5928100
	speed: 0.1901s/iter; left time: 4189.1203s
	iters: 200, epoch: 6 | loss: 0.6177138
	speed: 0.1796s/iter; left time: 3940.7214s
Epoch: 6 cost time: 43.23117637634277
Epoch: 6, Steps: 233 Train Loss: 0.5905 (Forecasting Loss:0.2653 + XiCon Loss:3.2522 x Lambda(0.1)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.1377
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5912968
	speed: 0.1856s/iter; left time: 4045.9968s
	iters: 200, epoch: 7 | loss: 0.6046355
	speed: 0.1584s/iter; left time: 3438.4609s
Epoch: 7 cost time: 38.04380655288696
Epoch: 7, Steps: 233 Train Loss: 0.5894 (Forecasting Loss:0.2646 + XiCon Loss:3.2485 x Lambda(0.1)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.1371
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5864345
	speed: 0.1862s/iter; left time: 4016.6426s
	iters: 200, epoch: 8 | loss: 0.5888286
	speed: 0.1849s/iter; left time: 3970.4624s
Epoch: 8 cost time: 43.59659028053284
Epoch: 8, Steps: 233 Train Loss: 0.5886 (Forecasting Loss:0.2638 + XiCon Loss:3.2481 x Lambda(0.1)), Vali MSE Loss: 0.3140 Test MSE Loss: 0.1379
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5966848
	speed: 0.1894s/iter; left time: 4040.6133s
	iters: 200, epoch: 9 | loss: 0.5772537
	speed: 0.1875s/iter; left time: 3981.5472s
Epoch: 9 cost time: 43.59574508666992
Epoch: 9, Steps: 233 Train Loss: 0.5882 (Forecasting Loss:0.2635 + XiCon Loss:3.2475 x Lambda(0.1)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.1382
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.6052103
	speed: 0.1805s/iter; left time: 3810.0806s
	iters: 200, epoch: 10 | loss: 0.5901229
	speed: 0.1873s/iter; left time: 3934.0510s
Epoch: 10 cost time: 42.99592208862305
Epoch: 10, Steps: 233 Train Loss: 0.5879 (Forecasting Loss:0.2633 + XiCon Loss:3.2461 x Lambda(0.1)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.1380
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5732231
	speed: 0.1863s/iter; left time: 3887.9926s
	iters: 200, epoch: 11 | loss: 0.5788070
	speed: 0.1853s/iter; left time: 3848.3231s
Epoch: 11 cost time: 43.38928270339966
Epoch: 11, Steps: 233 Train Loss: 0.5879 (Forecasting Loss:0.2632 + XiCon Loss:3.2467 x Lambda(0.1)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.1378
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11809878796339035, mae:0.2743421494960785, mape:0.1928982138633728, mspe:0.05537954345345497 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.3468
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8265056
	speed: 0.1404s/iter; left time: 3258.1699s
	iters: 200, epoch: 1 | loss: 0.8033235
	speed: 0.1405s/iter; left time: 3246.4871s
Epoch: 1 cost time: 32.54206895828247
Epoch: 1, Steps: 233 Train Loss: 0.7971 (Forecasting Loss:0.4393 + XiCon Loss:3.5779 x Lambda(0.1)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.1739
Validation loss decreased (inf --> 0.278233).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.7136183
	speed: 0.1496s/iter; left time: 3436.0573s
	iters: 200, epoch: 2 | loss: 0.6789300
	speed: 0.1468s/iter; left time: 3356.9278s
Epoch: 2 cost time: 34.469489097595215
Epoch: 2, Steps: 233 Train Loss: 0.7217 (Forecasting Loss:0.3769 + XiCon Loss:3.4483 x Lambda(0.1)), Vali MSE Loss: 0.2437 Test MSE Loss: 0.1593
Validation loss decreased (0.278233 --> 0.243675).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6249757
	speed: 0.1383s/iter; left time: 3143.5718s
	iters: 200, epoch: 3 | loss: 0.6086342
	speed: 0.1410s/iter; left time: 3191.8600s
Epoch: 3 cost time: 33.20726180076599
Epoch: 3, Steps: 233 Train Loss: 0.6342 (Forecasting Loss:0.3024 + XiCon Loss:3.3187 x Lambda(0.1)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1513
Validation loss decreased (0.243675 --> 0.236337).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6024041
	speed: 0.1406s/iter; left time: 3162.7845s
	iters: 200, epoch: 4 | loss: 0.6147056
	speed: 0.1408s/iter; left time: 3153.4785s
Epoch: 4 cost time: 32.93821048736572
Epoch: 4, Steps: 233 Train Loss: 0.6093 (Forecasting Loss:0.2830 + XiCon Loss:3.2629 x Lambda(0.1)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.1521
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.6098101
	speed: 0.1483s/iter; left time: 3302.8175s
	iters: 200, epoch: 5 | loss: 0.5991398
	speed: 0.1432s/iter; left time: 3174.3738s
Epoch: 5 cost time: 33.468170166015625
Epoch: 5, Steps: 233 Train Loss: 0.6060 (Forecasting Loss:0.2771 + XiCon Loss:3.2890 x Lambda(0.1)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.1646
Validation loss decreased (0.236337 --> 0.234241).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6125959
	speed: 0.1484s/iter; left time: 3270.0731s
	iters: 200, epoch: 6 | loss: 0.6021104
	speed: 0.1383s/iter; left time: 3033.6081s
Epoch: 6 cost time: 33.38811731338501
Epoch: 6, Steps: 233 Train Loss: 0.6055 (Forecasting Loss:0.2741 + XiCon Loss:3.3141 x Lambda(0.1)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.1628
Validation loss decreased (0.234241 --> 0.231891).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6092638
	speed: 0.1446s/iter; left time: 3153.0470s
	iters: 200, epoch: 7 | loss: 0.6087578
	speed: 0.1408s/iter; left time: 3056.6471s
Epoch: 7 cost time: 33.30035138130188
Epoch: 7, Steps: 233 Train Loss: 0.6047 (Forecasting Loss:0.2720 + XiCon Loss:3.3269 x Lambda(0.1)), Vali MSE Loss: 0.2336 Test MSE Loss: 0.1644
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.6265097
	speed: 0.1393s/iter; left time: 3004.2170s
	iters: 200, epoch: 8 | loss: 0.6065840
	speed: 0.1418s/iter; left time: 3045.4059s
Epoch: 8 cost time: 32.945595264434814
Epoch: 8, Steps: 233 Train Loss: 0.6038 (Forecasting Loss:0.2713 + XiCon Loss:3.3252 x Lambda(0.1)), Vali MSE Loss: 0.2335 Test MSE Loss: 0.1651
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5956684
	speed: 0.1513s/iter; left time: 3228.3482s
	iters: 200, epoch: 9 | loss: 0.6115704
	speed: 0.1364s/iter; left time: 2897.6547s
Epoch: 9 cost time: 33.29713821411133
Epoch: 9, Steps: 233 Train Loss: 0.6035 (Forecasting Loss:0.2709 + XiCon Loss:3.3262 x Lambda(0.1)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1666
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.6143396
	speed: 0.1460s/iter; left time: 3080.4358s
	iters: 200, epoch: 10 | loss: 0.6039418
	speed: 0.1418s/iter; left time: 2979.3857s
Epoch: 10 cost time: 33.23230338096619
Epoch: 10, Steps: 233 Train Loss: 0.6032 (Forecasting Loss:0.2708 + XiCon Loss:3.3241 x Lambda(0.1)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1651
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5937970
	speed: 0.1429s/iter; left time: 2982.4451s
	iters: 200, epoch: 11 | loss: 0.6054295
	speed: 0.1457s/iter; left time: 3026.1336s
Epoch: 11 cost time: 33.6295325756073
Epoch: 11, Steps: 233 Train Loss: 0.6031 (Forecasting Loss:0.2705 + XiCon Loss:3.3253 x Lambda(0.1)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1660
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5972476
	speed: 0.1367s/iter; left time: 2820.1983s
	iters: 200, epoch: 12 | loss: 0.5877680
	speed: 0.1378s/iter; left time: 2831.0069s
Epoch: 12 cost time: 32.16030788421631
Epoch: 12, Steps: 233 Train Loss: 0.6027 (Forecasting Loss:0.2704 + XiCon Loss:3.3235 x Lambda(0.1)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1657
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.6099924
	speed: 0.1435s/iter; left time: 2928.5737s
	iters: 200, epoch: 13 | loss: 0.5929503
	speed: 0.1362s/iter; left time: 2766.4203s
Epoch: 13 cost time: 32.80034327507019
Epoch: 13, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.2704 + XiCon Loss:3.3257 x Lambda(0.1)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1662
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5927503
	speed: 0.1508s/iter; left time: 3042.4405s
	iters: 200, epoch: 14 | loss: 0.5970125
	speed: 0.1424s/iter; left time: 2857.9043s
Epoch: 14 cost time: 34.122562646865845
Epoch: 14, Steps: 233 Train Loss: 0.6031 (Forecasting Loss:0.2706 + XiCon Loss:3.3244 x Lambda(0.1)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1659
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.6051376
	speed: 0.1400s/iter; left time: 2791.8644s
	iters: 200, epoch: 15 | loss: 0.6144143
	speed: 0.1422s/iter; left time: 2821.7480s
Epoch: 15 cost time: 32.973804235458374
Epoch: 15, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.2706 + XiCon Loss:3.3247 x Lambda(0.1)), Vali MSE Loss: 0.2347 Test MSE Loss: 0.1655
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5852973
	speed: 0.1463s/iter; left time: 2882.9716s
	iters: 200, epoch: 16 | loss: 0.5885152
	speed: 0.1437s/iter; left time: 2816.8001s
Epoch: 16 cost time: 33.97863459587097
Epoch: 16, Steps: 233 Train Loss: 0.6030 (Forecasting Loss:0.2705 + XiCon Loss:3.3247 x Lambda(0.1)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1654
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08885855972766876, mae:0.23671069741249084, mape:0.16691163182258606, mspe:0.04192977026104927 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.4207
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7916034
	speed: 0.1400s/iter; left time: 3249.2873s
	iters: 200, epoch: 1 | loss: 0.7447116
	speed: 0.1451s/iter; left time: 3351.3634s
Epoch: 1 cost time: 33.287391662597656
Epoch: 1, Steps: 233 Train Loss: 0.7844 (Forecasting Loss:0.4261 + XiCon Loss:3.5823 x Lambda(0.1)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.1696
Validation loss decreased (inf --> 0.289385).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6798965
	speed: 0.0943s/iter; left time: 2166.5582s
	iters: 200, epoch: 2 | loss: 0.6586702
	speed: 0.1287s/iter; left time: 2943.1344s
Epoch: 2 cost time: 26.899428129196167
Epoch: 2, Steps: 233 Train Loss: 0.6782 (Forecasting Loss:0.3359 + XiCon Loss:3.4226 x Lambda(0.1)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.1560
Validation loss decreased (0.289385 --> 0.255104).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6247172
	speed: 0.1513s/iter; left time: 3439.5901s
	iters: 200, epoch: 3 | loss: 0.6039387
	speed: 0.1398s/iter; left time: 3164.5746s
Epoch: 3 cost time: 33.41164517402649
Epoch: 3, Steps: 233 Train Loss: 0.6200 (Forecasting Loss:0.2825 + XiCon Loss:3.3750 x Lambda(0.1)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1579
Validation loss decreased (0.255104 --> 0.244145).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6236229
	speed: 0.1474s/iter; left time: 3317.3240s
	iters: 200, epoch: 4 | loss: 0.5895829
	speed: 0.1465s/iter; left time: 3282.6686s
Epoch: 4 cost time: 34.0103325843811
Epoch: 4, Steps: 233 Train Loss: 0.6074 (Forecasting Loss:0.2715 + XiCon Loss:3.3585 x Lambda(0.1)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1543
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5967673
	speed: 0.1447s/iter; left time: 3221.3114s
	iters: 200, epoch: 5 | loss: 0.6047288
	speed: 0.1466s/iter; left time: 3250.3423s
Epoch: 5 cost time: 33.8946647644043
Epoch: 5, Steps: 233 Train Loss: 0.6013 (Forecasting Loss:0.2664 + XiCon Loss:3.3492 x Lambda(0.1)), Vali MSE Loss: 0.2714 Test MSE Loss: 0.1560
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.6097991
	speed: 0.1374s/iter; left time: 3027.1267s
	iters: 200, epoch: 6 | loss: 0.6125923
	speed: 0.1475s/iter; left time: 3235.0802s
Epoch: 6 cost time: 33.026339292526245
Epoch: 6, Steps: 233 Train Loss: 0.5987 (Forecasting Loss:0.2642 + XiCon Loss:3.3450 x Lambda(0.1)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.1583
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6045462
	speed: 0.1456s/iter; left time: 3174.9344s
	iters: 200, epoch: 7 | loss: 0.5777137
	speed: 0.1366s/iter; left time: 2964.5305s
Epoch: 7 cost time: 33.061564207077026
Epoch: 7, Steps: 233 Train Loss: 0.5971 (Forecasting Loss:0.2629 + XiCon Loss:3.3418 x Lambda(0.1)), Vali MSE Loss: 0.2637 Test MSE Loss: 0.1582
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5950869
	speed: 0.1469s/iter; left time: 3168.5997s
	iters: 200, epoch: 8 | loss: 0.6086736
	speed: 0.1375s/iter; left time: 2951.7189s
Epoch: 8 cost time: 33.40915131568909
Epoch: 8, Steps: 233 Train Loss: 0.5962 (Forecasting Loss:0.2620 + XiCon Loss:3.3421 x Lambda(0.1)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.1622
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.6032395
	speed: 0.1458s/iter; left time: 3111.6126s
	iters: 200, epoch: 9 | loss: 0.5928508
	speed: 0.1445s/iter; left time: 3068.8135s
Epoch: 9 cost time: 33.735963582992554
Epoch: 9, Steps: 233 Train Loss: 0.5959 (Forecasting Loss:0.2619 + XiCon Loss:3.3403 x Lambda(0.1)), Vali MSE Loss: 0.2678 Test MSE Loss: 0.1555
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5959482
	speed: 0.1480s/iter; left time: 3123.8035s
	iters: 200, epoch: 10 | loss: 0.5882019
	speed: 0.1446s/iter; left time: 3036.8934s
Epoch: 10 cost time: 34.149672508239746
Epoch: 10, Steps: 233 Train Loss: 0.5958 (Forecasting Loss:0.2616 + XiCon Loss:3.3420 x Lambda(0.1)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1576
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5951319
	speed: 0.1448s/iter; left time: 3022.1524s
	iters: 200, epoch: 11 | loss: 0.5909350
	speed: 0.1348s/iter; left time: 2800.1987s
Epoch: 11 cost time: 32.64712643623352
Epoch: 11, Steps: 233 Train Loss: 0.5953 (Forecasting Loss:0.2613 + XiCon Loss:3.3394 x Lambda(0.1)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.1562
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.6002140
	speed: 0.1426s/iter; left time: 2943.8411s
	iters: 200, epoch: 12 | loss: 0.5919138
	speed: 0.1389s/iter; left time: 2853.1639s
Epoch: 12 cost time: 32.734755992889404
Epoch: 12, Steps: 233 Train Loss: 0.5955 (Forecasting Loss:0.2615 + XiCon Loss:3.3398 x Lambda(0.1)), Vali MSE Loss: 0.2665 Test MSE Loss: 0.1562
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5959178
	speed: 0.1436s/iter; left time: 2930.3851s
	iters: 200, epoch: 13 | loss: 0.6006027
	speed: 0.1501s/iter; left time: 3046.8663s
Epoch: 13 cost time: 34.02851223945618
Epoch: 13, Steps: 233 Train Loss: 0.5955 (Forecasting Loss:0.2614 + XiCon Loss:3.3411 x Lambda(0.1)), Vali MSE Loss: 0.2665 Test MSE Loss: 0.1565
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08471107482910156, mae:0.2310001254081726, mape:0.1638064980506897, mspe:0.04089677333831787 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0939+-0.01704, MAE:0.2431+-0.02200, MAPE:0.1721+-0.01468, MSPE:0.0449+-0.00736, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2159
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.7719383
	speed: 0.0632s/iter; left time: 1669.0224s
	iters: 200, epoch: 1 | loss: 33.9868546
	speed: 0.0537s/iter; left time: 1411.6293s
Epoch: 1 cost time: 14.499753952026367
Epoch: 1, Steps: 265 Train Loss: 34.4738 (Forecasting Loss:0.2280 + XiCon Loss:3.4246 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.210059).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.2775421
	speed: 0.0353s/iter; left time: 921.7021s
	iters: 200, epoch: 2 | loss: 34.3790703
	speed: 0.0288s/iter; left time: 749.9566s
Epoch: 2 cost time: 8.686472177505493
Epoch: 2, Steps: 265 Train Loss: 33.4839 (Forecasting Loss:0.2091 + XiCon Loss:3.3275 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1667
Validation loss decreased (0.210059 --> 0.206478).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7755795
	speed: 0.0598s/iter; left time: 1546.0785s
	iters: 200, epoch: 3 | loss: 31.8102551
	speed: 0.0575s/iter; left time: 1481.1404s
Epoch: 3 cost time: 15.315629005432129
Epoch: 3, Steps: 265 Train Loss: 32.0820 (Forecasting Loss:0.2012 + XiCon Loss:3.1881 x Lambda(10.0)), Vali MSE Loss: 0.2039 Test MSE Loss: 0.1621
Validation loss decreased (0.206478 --> 0.203874).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.6328049
	speed: 0.0605s/iter; left time: 1548.7626s
	iters: 200, epoch: 4 | loss: 32.2742844
	speed: 0.0576s/iter; left time: 1468.1236s
Epoch: 4 cost time: 15.35141110420227
Epoch: 4, Steps: 265 Train Loss: 31.8806 (Forecasting Loss:0.1991 + XiCon Loss:3.1682 x Lambda(10.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1606
Validation loss decreased (0.203874 --> 0.200764).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.9711113
	speed: 0.0455s/iter; left time: 1154.2276s
	iters: 200, epoch: 5 | loss: 31.7140713
	speed: 0.0552s/iter; left time: 1392.1760s
Epoch: 5 cost time: 13.742786169052124
Epoch: 5, Steps: 265 Train Loss: 31.8628 (Forecasting Loss:0.1972 + XiCon Loss:3.1666 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1594
Validation loss decreased (0.200764 --> 0.199018).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.2045212
	speed: 0.0615s/iter; left time: 1542.7858s
	iters: 200, epoch: 6 | loss: 32.6790161
	speed: 0.0579s/iter; left time: 1446.7612s
Epoch: 6 cost time: 15.7791428565979
Epoch: 6, Steps: 265 Train Loss: 31.8428 (Forecasting Loss:0.1965 + XiCon Loss:3.1646 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.7227211
	speed: 0.0601s/iter; left time: 1490.6005s
	iters: 200, epoch: 7 | loss: 31.6346607
	speed: 0.0428s/iter; left time: 1056.7969s
Epoch: 7 cost time: 13.203867435455322
Epoch: 7, Steps: 265 Train Loss: 31.8574 (Forecasting Loss:0.1963 + XiCon Loss:3.1661 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1585
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.9923153
	speed: 0.0615s/iter; left time: 1510.4570s
	iters: 200, epoch: 8 | loss: 32.0873299
	speed: 0.0575s/iter; left time: 1405.5298s
Epoch: 8 cost time: 15.68144154548645
Epoch: 8, Steps: 265 Train Loss: 31.8259 (Forecasting Loss:0.1960 + XiCon Loss:3.1630 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1588
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.1331406
	speed: 0.0598s/iter; left time: 1451.1555s
	iters: 200, epoch: 9 | loss: 32.1112976
	speed: 0.0593s/iter; left time: 1433.2963s
Epoch: 9 cost time: 15.427260160446167
Epoch: 9, Steps: 265 Train Loss: 31.8502 (Forecasting Loss:0.1959 + XiCon Loss:3.1654 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1585
Validation loss decreased (0.199018 --> 0.198912).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.0834808
	speed: 0.0463s/iter; left time: 1111.2837s
	iters: 200, epoch: 10 | loss: 32.6554184
	speed: 0.0592s/iter; left time: 1415.0685s
Epoch: 10 cost time: 14.557464122772217
Epoch: 10, Steps: 265 Train Loss: 31.8080 (Forecasting Loss:0.1959 + XiCon Loss:3.1612 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.6921749
	speed: 0.0615s/iter; left time: 1461.7783s
	iters: 200, epoch: 11 | loss: 31.5736237
	speed: 0.0585s/iter; left time: 1383.2809s
Epoch: 11 cost time: 15.826685428619385
Epoch: 11, Steps: 265 Train Loss: 31.8231 (Forecasting Loss:0.1959 + XiCon Loss:3.1627 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.7632942
	speed: 0.0575s/iter; left time: 1351.3606s
	iters: 200, epoch: 12 | loss: 31.9031219
	speed: 0.0448s/iter; left time: 1046.8701s
Epoch: 12 cost time: 13.574022769927979
Epoch: 12, Steps: 265 Train Loss: 31.8764 (Forecasting Loss:0.1958 + XiCon Loss:3.1681 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1586
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.9740467
	speed: 0.0597s/iter; left time: 1386.4494s
	iters: 200, epoch: 13 | loss: 31.5374756
	speed: 0.0564s/iter; left time: 1304.6909s
Epoch: 13 cost time: 15.520225286483765
Epoch: 13, Steps: 265 Train Loss: 31.8213 (Forecasting Loss:0.1958 + XiCon Loss:3.1626 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.5138435
	speed: 0.0609s/iter; left time: 1398.1468s
	iters: 200, epoch: 14 | loss: 32.1197433
	speed: 0.0581s/iter; left time: 1327.5736s
Epoch: 14 cost time: 15.015507221221924
Epoch: 14, Steps: 265 Train Loss: 31.8333 (Forecasting Loss:0.1958 + XiCon Loss:3.1638 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.5488739
	speed: 0.0522s/iter; left time: 1185.1745s
	iters: 200, epoch: 15 | loss: 31.6334095
	speed: 0.0590s/iter; left time: 1333.3411s
Epoch: 15 cost time: 14.760728359222412
Epoch: 15, Steps: 265 Train Loss: 31.8368 (Forecasting Loss:0.1958 + XiCon Loss:3.1641 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1586
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.6288395
	speed: 0.0599s/iter; left time: 1343.6054s
	iters: 200, epoch: 16 | loss: 31.6656933
	speed: 0.0551s/iter; left time: 1229.3658s
Epoch: 16 cost time: 15.342552900314331
Epoch: 16, Steps: 265 Train Loss: 31.8316 (Forecasting Loss:0.1958 + XiCon Loss:3.1636 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1586
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.4532852
	speed: 0.0517s/iter; left time: 1146.3089s
	iters: 200, epoch: 17 | loss: 31.5837727
	speed: 0.0435s/iter; left time: 959.7584s
Epoch: 17 cost time: 13.18778657913208
Epoch: 17, Steps: 265 Train Loss: 31.8281 (Forecasting Loss:0.1958 + XiCon Loss:3.1632 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.0184326
	speed: 0.0611s/iter; left time: 1337.3701s
	iters: 200, epoch: 18 | loss: 31.6293926
	speed: 0.0586s/iter; left time: 1276.2635s
Epoch: 18 cost time: 15.746330738067627
Epoch: 18, Steps: 265 Train Loss: 31.8190 (Forecasting Loss:0.1958 + XiCon Loss:3.1623 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1586
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.2142296
	speed: 0.0600s/iter; left time: 1298.0380s
	iters: 200, epoch: 19 | loss: 31.4860134
	speed: 0.0553s/iter; left time: 1190.8465s
Epoch: 19 cost time: 14.438929319381714
Epoch: 19, Steps: 265 Train Loss: 31.8073 (Forecasting Loss:0.1958 + XiCon Loss:3.1612 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1586
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09166663140058517, mae:0.2253514677286148, mape:0.542493999004364, mspe:11.268904685974121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2380
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.5015144
	speed: 0.0588s/iter; left time: 1553.4792s
	iters: 200, epoch: 1 | loss: 33.6287918
	speed: 0.0576s/iter; left time: 1513.6674s
Epoch: 1 cost time: 15.206142663955688
Epoch: 1, Steps: 265 Train Loss: 34.3199 (Forecasting Loss:0.2276 + XiCon Loss:3.4092 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1674
Validation loss decreased (inf --> 0.210259).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.9784355
	speed: 0.0450s/iter; left time: 1177.1367s
	iters: 200, epoch: 2 | loss: 34.3710899
	speed: 0.0572s/iter; left time: 1489.6981s
Epoch: 2 cost time: 13.975644588470459
Epoch: 2, Steps: 265 Train Loss: 33.5679 (Forecasting Loss:0.2075 + XiCon Loss:3.3360 x Lambda(10.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1683
Validation loss decreased (0.210259 --> 0.207117).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.6167908
	speed: 0.0588s/iter; left time: 1520.0904s
	iters: 200, epoch: 3 | loss: 32.1130447
	speed: 0.0546s/iter; left time: 1407.5845s
Epoch: 3 cost time: 15.084899663925171
Epoch: 3, Steps: 265 Train Loss: 32.4988 (Forecasting Loss:0.2007 + XiCon Loss:3.2298 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1622
Validation loss decreased (0.207117 --> 0.202729).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.8619251
	speed: 0.0591s/iter; left time: 1513.1995s
	iters: 200, epoch: 4 | loss: 31.9816170
	speed: 0.0431s/iter; left time: 1098.6576s
Epoch: 4 cost time: 13.117338180541992
Epoch: 4, Steps: 265 Train Loss: 31.8958 (Forecasting Loss:0.1987 + XiCon Loss:3.1697 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1603
Validation loss decreased (0.202729 --> 0.200308).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.0883522
	speed: 0.0604s/iter; left time: 1530.0765s
	iters: 200, epoch: 5 | loss: 31.9976768
	speed: 0.0573s/iter; left time: 1446.8154s
Epoch: 5 cost time: 15.481771230697632
Epoch: 5, Steps: 265 Train Loss: 31.8477 (Forecasting Loss:0.1971 + XiCon Loss:3.1651 x Lambda(10.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1599
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.9755898
	speed: 0.0620s/iter; left time: 1555.8887s
	iters: 200, epoch: 6 | loss: 32.1197777
	speed: 0.0566s/iter; left time: 1413.5192s
Epoch: 6 cost time: 15.44586992263794
Epoch: 6, Steps: 265 Train Loss: 31.8040 (Forecasting Loss:0.1963 + XiCon Loss:3.1608 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1589
Validation loss decreased (0.200308 --> 0.198723).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.6062584
	speed: 0.0474s/iter; left time: 1175.3611s
	iters: 200, epoch: 7 | loss: 31.6189842
	speed: 0.0552s/iter; left time: 1363.7510s
Epoch: 7 cost time: 14.005923748016357
Epoch: 7, Steps: 265 Train Loss: 31.7892 (Forecasting Loss:0.1961 + XiCon Loss:3.1593 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.1737823
	speed: 0.0615s/iter; left time: 1508.5094s
	iters: 200, epoch: 8 | loss: 31.9306984
	speed: 0.0567s/iter; left time: 1385.1716s
Epoch: 8 cost time: 15.627660751342773
Epoch: 8, Steps: 265 Train Loss: 31.7818 (Forecasting Loss:0.1959 + XiCon Loss:3.1586 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.3735695
	speed: 0.0592s/iter; left time: 1436.8730s
	iters: 200, epoch: 9 | loss: 31.5658436
	speed: 0.0427s/iter; left time: 1033.5226s
Epoch: 9 cost time: 13.3540620803833
Epoch: 9, Steps: 265 Train Loss: 31.7919 (Forecasting Loss:0.1958 + XiCon Loss:3.1596 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1589
Validation loss decreased (0.198723 --> 0.198689).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.4480324
	speed: 0.0619s/iter; left time: 1487.1471s
	iters: 200, epoch: 10 | loss: 32.3688622
	speed: 0.0565s/iter; left time: 1350.0644s
Epoch: 10 cost time: 15.672319889068604
Epoch: 10, Steps: 265 Train Loss: 31.7875 (Forecasting Loss:0.1957 + XiCon Loss:3.1592 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.9014168
	speed: 0.0612s/iter; left time: 1452.8092s
	iters: 200, epoch: 11 | loss: 31.7311001
	speed: 0.0588s/iter; left time: 1389.6230s
Epoch: 11 cost time: 15.059093713760376
Epoch: 11, Steps: 265 Train Loss: 31.8107 (Forecasting Loss:0.1957 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.1253471
	speed: 0.0523s/iter; left time: 1227.6850s
	iters: 200, epoch: 12 | loss: 31.6791286
	speed: 0.0573s/iter; left time: 1341.1575s
Epoch: 12 cost time: 14.64931845664978
Epoch: 12, Steps: 265 Train Loss: 31.7845 (Forecasting Loss:0.1957 + XiCon Loss:3.1589 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.1869736
	speed: 0.0602s/iter; left time: 1398.5657s
	iters: 200, epoch: 13 | loss: 31.7982960
	speed: 0.0591s/iter; left time: 1367.0339s
Epoch: 13 cost time: 15.65804409980774
Epoch: 13, Steps: 265 Train Loss: 31.8040 (Forecasting Loss:0.1957 + XiCon Loss:3.1608 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.8260593
	speed: 0.0529s/iter; left time: 1214.9450s
	iters: 200, epoch: 14 | loss: 31.7221680
	speed: 0.0428s/iter; left time: 977.7867s
Epoch: 14 cost time: 13.006147861480713
Epoch: 14, Steps: 265 Train Loss: 31.7877 (Forecasting Loss:0.1957 + XiCon Loss:3.1592 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.8459778
	speed: 0.0604s/iter; left time: 1371.5714s
	iters: 200, epoch: 15 | loss: 31.2869549
	speed: 0.0585s/iter; left time: 1321.6481s
Epoch: 15 cost time: 15.577178716659546
Epoch: 15, Steps: 265 Train Loss: 31.7788 (Forecasting Loss:0.1957 + XiCon Loss:3.1583 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1587
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.4313850
	speed: 0.0622s/iter; left time: 1394.0868s
	iters: 200, epoch: 16 | loss: 31.7073765
	speed: 0.0573s/iter; left time: 1279.7350s
Epoch: 16 cost time: 14.873167991638184
Epoch: 16, Steps: 265 Train Loss: 31.8044 (Forecasting Loss:0.1956 + XiCon Loss:3.1609 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.6076698
	speed: 0.0531s/iter; left time: 1177.4226s
	iters: 200, epoch: 17 | loss: 31.7720547
	speed: 0.0584s/iter; left time: 1289.4481s
Epoch: 17 cost time: 14.915742874145508
Epoch: 17, Steps: 265 Train Loss: 31.7868 (Forecasting Loss:0.1956 + XiCon Loss:3.1591 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.0636559
	speed: 0.0606s/iter; left time: 1327.7635s
	iters: 200, epoch: 18 | loss: 31.6189785
	speed: 0.0575s/iter; left time: 1252.7881s
Epoch: 18 cost time: 15.614085674285889
Epoch: 18, Steps: 265 Train Loss: 31.7736 (Forecasting Loss:0.1956 + XiCon Loss:3.1578 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.4291401
	speed: 0.0503s/iter; left time: 1089.0954s
	iters: 200, epoch: 19 | loss: 31.7212181
	speed: 0.0467s/iter; left time: 1005.1159s
Epoch: 19 cost time: 13.379314661026001
Epoch: 19, Steps: 265 Train Loss: 31.7776 (Forecasting Loss:0.1957 + XiCon Loss:3.1582 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
Validation loss decreased (0.198689 --> 0.198658).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.7511406
	speed: 0.0592s/iter; left time: 1265.7712s
	iters: 200, epoch: 20 | loss: 32.0203323
	speed: 0.0584s/iter; left time: 1241.8543s
Epoch: 20 cost time: 15.47029185295105
Epoch: 20, Steps: 265 Train Loss: 31.7772 (Forecasting Loss:0.1957 + XiCon Loss:3.1582 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.1768723
	speed: 0.0621s/iter; left time: 1309.3448s
	iters: 200, epoch: 21 | loss: 31.9948692
	speed: 0.0518s/iter; left time: 1088.6088s
Epoch: 21 cost time: 14.229495286941528
Epoch: 21, Steps: 265 Train Loss: 31.8118 (Forecasting Loss:0.1956 + XiCon Loss:3.1616 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.6234417
	speed: 0.0583s/iter; left time: 1214.1281s
	iters: 200, epoch: 22 | loss: 32.5145607
	speed: 0.0580s/iter; left time: 1202.0538s
Epoch: 22 cost time: 15.564526081085205
Epoch: 22, Steps: 265 Train Loss: 31.8158 (Forecasting Loss:0.1956 + XiCon Loss:3.1620 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.5408726
	speed: 0.0608s/iter; left time: 1250.2034s
	iters: 200, epoch: 23 | loss: 31.5044994
	speed: 0.0590s/iter; left time: 1208.5754s
Epoch: 23 cost time: 15.838815212249756
Epoch: 23, Steps: 265 Train Loss: 31.8011 (Forecasting Loss:0.1957 + XiCon Loss:3.1605 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.5347672
	speed: 0.0470s/iter; left time: 955.1955s
	iters: 200, epoch: 24 | loss: 32.2275696
	speed: 0.0480s/iter; left time: 970.4154s
Epoch: 24 cost time: 13.263465166091919
Epoch: 24, Steps: 265 Train Loss: 31.8134 (Forecasting Loss:0.1957 + XiCon Loss:3.1618 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.5268898
	speed: 0.0603s/iter; left time: 1207.4970s
	iters: 200, epoch: 25 | loss: 31.4853687
	speed: 0.0576s/iter; left time: 1147.9572s
Epoch: 25 cost time: 15.455599784851074
Epoch: 25, Steps: 265 Train Loss: 31.8104 (Forecasting Loss:0.1957 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.4383678
	speed: 0.0597s/iter; left time: 1180.4875s
	iters: 200, epoch: 26 | loss: 31.6395950
	speed: 0.0489s/iter; left time: 961.7040s
Epoch: 26 cost time: 13.803645610809326
Epoch: 26, Steps: 265 Train Loss: 31.8046 (Forecasting Loss:0.1957 + XiCon Loss:3.1609 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.4442978
	speed: 0.0615s/iter; left time: 1199.9663s
	iters: 200, epoch: 27 | loss: 32.3004150
	speed: 0.0579s/iter; left time: 1124.6726s
Epoch: 27 cost time: 15.691188097000122
Epoch: 27, Steps: 265 Train Loss: 31.8064 (Forecasting Loss:0.1956 + XiCon Loss:3.1611 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 32.0018272
	speed: 0.0578s/iter; left time: 1113.3461s
	iters: 200, epoch: 28 | loss: 31.8877449
	speed: 0.0584s/iter; left time: 1118.3299s
Epoch: 28 cost time: 15.360887050628662
Epoch: 28, Steps: 265 Train Loss: 31.7845 (Forecasting Loss:0.1957 + XiCon Loss:3.1589 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 31.4411201
	speed: 0.0467s/iter; left time: 886.7810s
	iters: 200, epoch: 29 | loss: 32.0607224
	speed: 0.0526s/iter; left time: 993.1307s
Epoch: 29 cost time: 13.861114501953125
Epoch: 29, Steps: 265 Train Loss: 31.7839 (Forecasting Loss:0.1956 + XiCon Loss:3.1588 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09188482910394669, mae:0.2255702167749405, mape:0.5444998145103455, mspe:11.36922550201416 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9604
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 35.0302010
	speed: 0.0493s/iter; left time: 1302.1857s
	iters: 200, epoch: 1 | loss: 33.9561043
	speed: 0.0406s/iter; left time: 1066.8975s
Epoch: 1 cost time: 11.863084316253662
Epoch: 1, Steps: 265 Train Loss: 34.5403 (Forecasting Loss:0.2264 + XiCon Loss:3.4314 x Lambda(10.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1671
Validation loss decreased (inf --> 0.211052).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.6995506
	speed: 0.0636s/iter; left time: 1662.4422s
	iters: 200, epoch: 2 | loss: 34.6236725
	speed: 0.0755s/iter; left time: 1964.9019s
Epoch: 2 cost time: 16.226074695587158
Epoch: 2, Steps: 265 Train Loss: 33.9704 (Forecasting Loss:0.2075 + XiCon Loss:3.3763 x Lambda(10.0)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1647
Validation loss decreased (0.211052 --> 0.205087).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.2776566
	speed: 0.0320s/iter; left time: 828.5578s
	iters: 200, epoch: 3 | loss: 32.2348747
	speed: 0.0517s/iter; left time: 1333.4507s
Epoch: 3 cost time: 12.018268346786499
Epoch: 3, Steps: 265 Train Loss: 33.2550 (Forecasting Loss:0.2014 + XiCon Loss:3.3054 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1630
Validation loss decreased (0.205087 --> 0.203607).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.6605110
	speed: 0.0609s/iter; left time: 1559.9920s
	iters: 200, epoch: 4 | loss: 31.9687042
	speed: 0.0586s/iter; left time: 1494.8701s
Epoch: 4 cost time: 15.846896886825562
Epoch: 4, Steps: 265 Train Loss: 32.9966 (Forecasting Loss:0.1985 + XiCon Loss:3.2798 x Lambda(10.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1634
Validation loss decreased (0.203607 --> 0.202975).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.3960152
	speed: 0.0590s/iter; left time: 1495.9383s
	iters: 200, epoch: 5 | loss: 32.7903175
	speed: 0.0448s/iter; left time: 1131.7097s
Epoch: 5 cost time: 12.8011794090271
Epoch: 5, Steps: 265 Train Loss: 32.8150 (Forecasting Loss:0.1972 + XiCon Loss:3.2618 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1600
Validation loss decreased (0.202975 --> 0.200090).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.3581696
	speed: 0.0598s/iter; left time: 1500.3737s
	iters: 200, epoch: 6 | loss: 33.7735863
	speed: 0.0566s/iter; left time: 1413.9288s
Epoch: 6 cost time: 15.346389532089233
Epoch: 6, Steps: 265 Train Loss: 32.8096 (Forecasting Loss:0.1965 + XiCon Loss:3.2613 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1596
Validation loss decreased (0.200090 --> 0.199999).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.3038673
	speed: 0.0599s/iter; left time: 1485.8454s
	iters: 200, epoch: 7 | loss: 32.9668579
	speed: 0.0568s/iter; left time: 1404.2553s
Epoch: 7 cost time: 15.401020526885986
Epoch: 7, Steps: 265 Train Loss: 32.7689 (Forecasting Loss:0.1960 + XiCon Loss:3.2573 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1595
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.8676872
	speed: 0.0470s/iter; left time: 1152.4674s
	iters: 200, epoch: 8 | loss: 32.4635391
	speed: 0.0534s/iter; left time: 1304.9922s
Epoch: 8 cost time: 13.718420505523682
Epoch: 8, Steps: 265 Train Loss: 32.7123 (Forecasting Loss:0.1957 + XiCon Loss:3.2517 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1590
Validation loss decreased (0.199999 --> 0.199832).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.4257774
	speed: 0.0603s/iter; left time: 1465.2197s
	iters: 200, epoch: 9 | loss: 33.5083504
	speed: 0.0582s/iter; left time: 1407.6919s
Epoch: 9 cost time: 15.768846988677979
Epoch: 9, Steps: 265 Train Loss: 32.7920 (Forecasting Loss:0.1958 + XiCon Loss:3.2596 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1593
Validation loss decreased (0.199832 --> 0.199741).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.1768303
	speed: 0.0577s/iter; left time: 1384.5837s
	iters: 200, epoch: 10 | loss: 32.6784592
	speed: 0.0442s/iter; left time: 1056.0567s
Epoch: 10 cost time: 12.4320809841156
Epoch: 10, Steps: 265 Train Loss: 32.7399 (Forecasting Loss:0.1956 + XiCon Loss:3.2544 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1591
Validation loss decreased (0.199741 --> 0.199547).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.6039009
	speed: 0.0314s/iter; left time: 745.8127s
	iters: 200, epoch: 11 | loss: 33.4976578
	speed: 0.0454s/iter; left time: 1074.5021s
Epoch: 11 cost time: 11.366893291473389
Epoch: 11, Steps: 265 Train Loss: 32.6505 (Forecasting Loss:0.1955 + XiCon Loss:3.2455 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1591
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.1140099
	speed: 0.0602s/iter; left time: 1413.0874s
	iters: 200, epoch: 12 | loss: 32.3065605
	speed: 0.0566s/iter; left time: 1322.5748s
Epoch: 12 cost time: 15.350122451782227
Epoch: 12, Steps: 265 Train Loss: 32.7071 (Forecasting Loss:0.1956 + XiCon Loss:3.2511 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1591
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.6929398
	speed: 0.0606s/iter; left time: 1406.3831s
	iters: 200, epoch: 13 | loss: 32.2333755
	speed: 0.0460s/iter; left time: 1062.9267s
Epoch: 13 cost time: 13.501354694366455
Epoch: 13, Steps: 265 Train Loss: 32.7585 (Forecasting Loss:0.1957 + XiCon Loss:3.2563 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.4095802
	speed: 0.0317s/iter; left time: 726.8376s
	iters: 200, epoch: 14 | loss: 32.2865067
	speed: 0.0376s/iter; left time: 859.1723s
Epoch: 14 cost time: 10.654052734375
Epoch: 14, Steps: 265 Train Loss: 32.7444 (Forecasting Loss:0.1955 + XiCon Loss:3.2549 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.0755501
	speed: 0.0586s/iter; left time: 1328.7173s
	iters: 200, epoch: 15 | loss: 32.1318588
	speed: 0.0565s/iter; left time: 1277.4694s
Epoch: 15 cost time: 15.249285697937012
Epoch: 15, Steps: 265 Train Loss: 32.6614 (Forecasting Loss:0.1955 + XiCon Loss:3.2466 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.5707512
	speed: 0.0620s/iter; left time: 1390.6013s
	iters: 200, epoch: 16 | loss: 33.4260559
	speed: 0.0518s/iter; left time: 1156.9685s
Epoch: 16 cost time: 14.326232671737671
Epoch: 16, Steps: 265 Train Loss: 32.6787 (Forecasting Loss:0.1955 + XiCon Loss:3.2483 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1591
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.3936806
	speed: 0.0312s/iter; left time: 691.1840s
	iters: 200, epoch: 17 | loss: 32.2285271
	speed: 0.0293s/iter; left time: 646.1974s
Epoch: 17 cost time: 9.330054759979248
Epoch: 17, Steps: 265 Train Loss: 32.6769 (Forecasting Loss:0.1955 + XiCon Loss:3.2481 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1591
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.4294739
	speed: 0.0596s/iter; left time: 1304.4524s
	iters: 200, epoch: 18 | loss: 32.6529198
	speed: 0.0580s/iter; left time: 1263.5108s
Epoch: 18 cost time: 15.517867088317871
Epoch: 18, Steps: 265 Train Loss: 32.7219 (Forecasting Loss:0.1955 + XiCon Loss:3.2526 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1591
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.8694191
	speed: 0.0610s/iter; left time: 1319.2071s
	iters: 200, epoch: 19 | loss: 32.3984489
	speed: 0.0576s/iter; left time: 1240.2333s
Epoch: 19 cost time: 14.849744081497192
Epoch: 19, Steps: 265 Train Loss: 32.6698 (Forecasting Loss:0.1956 + XiCon Loss:3.2474 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1591
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.5182304
	speed: 0.0361s/iter; left time: 771.5702s
	iters: 200, epoch: 20 | loss: 33.6989250
	speed: 0.0291s/iter; left time: 618.7991s
Epoch: 20 cost time: 8.421679496765137
Epoch: 20, Steps: 265 Train Loss: 32.6993 (Forecasting Loss:0.1956 + XiCon Loss:3.2504 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1591
Validation loss decreased (0.199547 --> 0.199545).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.4875259
	speed: 0.0600s/iter; left time: 1265.7272s
	iters: 200, epoch: 21 | loss: 32.3854561
	speed: 0.0555s/iter; left time: 1165.4475s
Epoch: 21 cost time: 15.328591108322144
Epoch: 21, Steps: 265 Train Loss: 32.7294 (Forecasting Loss:0.1956 + XiCon Loss:3.2534 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1591
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.3135605
	speed: 0.0597s/iter; left time: 1244.5528s
	iters: 200, epoch: 22 | loss: 32.5945892
	speed: 0.0573s/iter; left time: 1187.5121s
Epoch: 22 cost time: 15.323394060134888
Epoch: 22, Steps: 265 Train Loss: 32.7296 (Forecasting Loss:0.1955 + XiCon Loss:3.2534 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1591
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.3564758
	speed: 0.0421s/iter; left time: 866.3399s
	iters: 200, epoch: 23 | loss: 33.0841141
	speed: 0.0291s/iter; left time: 596.3416s
Epoch: 23 cost time: 9.043471097946167
Epoch: 23, Steps: 265 Train Loss: 32.7229 (Forecasting Loss:0.1955 + XiCon Loss:3.2527 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.7674580
	speed: 0.0594s/iter; left time: 1205.2038s
	iters: 200, epoch: 24 | loss: 32.7525406
	speed: 0.0587s/iter; left time: 1185.9564s
Epoch: 24 cost time: 15.504496812820435
Epoch: 24, Steps: 265 Train Loss: 32.7029 (Forecasting Loss:0.1955 + XiCon Loss:3.2507 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1591
Validation loss decreased (0.199545 --> 0.199342).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.7425880
	speed: 0.0581s/iter; left time: 1163.7072s
	iters: 200, epoch: 25 | loss: 32.5760880
	speed: 0.0553s/iter; left time: 1103.4383s
Epoch: 25 cost time: 15.165730476379395
Epoch: 25, Steps: 265 Train Loss: 32.7249 (Forecasting Loss:0.1956 + XiCon Loss:3.2529 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1591
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.9103432
	speed: 0.0466s/iter; left time: 920.8641s
	iters: 200, epoch: 26 | loss: 32.3270416
	speed: 0.0311s/iter; left time: 611.4584s
Epoch: 26 cost time: 9.716904878616333
Epoch: 26, Steps: 265 Train Loss: 32.7502 (Forecasting Loss:0.1955 + XiCon Loss:3.2555 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 33.6253471
	speed: 0.0575s/iter; left time: 1121.7244s
	iters: 200, epoch: 27 | loss: 32.6097183
	speed: 0.0575s/iter; left time: 1116.2678s
Epoch: 27 cost time: 15.076006174087524
Epoch: 27, Steps: 265 Train Loss: 32.7478 (Forecasting Loss:0.1956 + XiCon Loss:3.2552 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 32.3978043
	speed: 0.0609s/iter; left time: 1172.5062s
	iters: 200, epoch: 28 | loss: 32.3051338
	speed: 0.0577s/iter; left time: 1104.2247s
Epoch: 28 cost time: 15.506849527359009
Epoch: 28, Steps: 265 Train Loss: 32.6834 (Forecasting Loss:0.1955 + XiCon Loss:3.2488 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 32.4969940
	speed: 0.0480s/iter; left time: 910.3617s
	iters: 200, epoch: 29 | loss: 34.1680183
	speed: 0.0524s/iter; left time: 988.9761s
Epoch: 29 cost time: 13.883704900741577
Epoch: 29, Steps: 265 Train Loss: 32.7023 (Forecasting Loss:0.1955 + XiCon Loss:3.2507 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 31.8742390
	speed: 0.0596s/iter; left time: 1116.3263s
	iters: 200, epoch: 30 | loss: 33.4685936
	speed: 0.0584s/iter; left time: 1087.4658s
Epoch: 30 cost time: 15.683186292648315
Epoch: 30, Steps: 265 Train Loss: 32.7207 (Forecasting Loss:0.1956 + XiCon Loss:3.2525 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 32.8616295
	speed: 0.0605s/iter; left time: 1116.3484s
	iters: 200, epoch: 31 | loss: 32.4317970
	speed: 0.0464s/iter; left time: 852.0324s
Epoch: 31 cost time: 13.50034761428833
Epoch: 31, Steps: 265 Train Loss: 32.7344 (Forecasting Loss:0.1955 + XiCon Loss:3.2539 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1591
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 32.0475998
	speed: 0.0598s/iter; left time: 1087.4853s
	iters: 200, epoch: 32 | loss: 32.3116913
	speed: 0.0558s/iter; left time: 1009.1883s
Epoch: 32 cost time: 15.314013481140137
Epoch: 32, Steps: 265 Train Loss: 32.6682 (Forecasting Loss:0.1956 + XiCon Loss:3.2473 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1591
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 32.2322311
	speed: 0.0589s/iter; left time: 1054.9194s
	iters: 200, epoch: 33 | loss: 33.5053329
	speed: 0.0561s/iter; left time: 1000.3147s
Epoch: 33 cost time: 15.037570238113403
Epoch: 33, Steps: 265 Train Loss: 32.7023 (Forecasting Loss:0.1955 + XiCon Loss:3.2507 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1591
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 32.0439835
	speed: 0.0438s/iter; left time: 772.4926s
	iters: 200, epoch: 34 | loss: 33.2219543
	speed: 0.0284s/iter; left time: 498.3133s
Epoch: 34 cost time: 9.091359376907349
Epoch: 34, Steps: 265 Train Loss: 32.7008 (Forecasting Loss:0.1956 + XiCon Loss:3.2505 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1591
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09221892058849335, mae:0.22590646147727966, mape:0.5445465445518494, mspe:11.361347198486328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.7859
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.6193161
	speed: 0.0598s/iter; left time: 1579.7845s
	iters: 200, epoch: 1 | loss: 33.7243881
	speed: 0.0562s/iter; left time: 1478.5554s
Epoch: 1 cost time: 14.412779092788696
Epoch: 1, Steps: 265 Train Loss: 34.3314 (Forecasting Loss:0.2276 + XiCon Loss:3.4104 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1681
Validation loss decreased (inf --> 0.210585).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.2188988
	speed: 0.0551s/iter; left time: 1439.5899s
	iters: 200, epoch: 2 | loss: 33.9743919
	speed: 0.0564s/iter; left time: 1468.9254s
Epoch: 2 cost time: 14.845784425735474
Epoch: 2, Steps: 265 Train Loss: 33.6893 (Forecasting Loss:0.2081 + XiCon Loss:3.3481 x Lambda(10.0)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1683
Validation loss decreased (0.210585 --> 0.207729).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.8685799
	speed: 0.0598s/iter; left time: 1548.3210s
	iters: 200, epoch: 3 | loss: 32.9980965
	speed: 0.0598s/iter; left time: 1542.0931s
Epoch: 3 cost time: 15.623633861541748
Epoch: 3, Steps: 265 Train Loss: 33.1155 (Forecasting Loss:0.2010 + XiCon Loss:3.2915 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1636
Validation loss decreased (0.207729 --> 0.202448).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.5480003
	speed: 0.0486s/iter; left time: 1243.8285s
	iters: 200, epoch: 4 | loss: 33.0467262
	speed: 0.0490s/iter; left time: 1250.4149s
Epoch: 4 cost time: 13.544967889785767
Epoch: 4, Steps: 265 Train Loss: 32.8701 (Forecasting Loss:0.1986 + XiCon Loss:3.2671 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1606
Validation loss decreased (0.202448 --> 0.199701).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.9015083
	speed: 0.0585s/iter; left time: 1482.3817s
	iters: 200, epoch: 5 | loss: 33.1530685
	speed: 0.0574s/iter; left time: 1449.3095s
Epoch: 5 cost time: 15.195455551147461
Epoch: 5, Steps: 265 Train Loss: 32.6440 (Forecasting Loss:0.1974 + XiCon Loss:3.2447 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1595
Validation loss decreased (0.199701 --> 0.198906).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.8250008
	speed: 0.0613s/iter; left time: 1536.4275s
	iters: 200, epoch: 6 | loss: 33.7318764
	speed: 0.0510s/iter; left time: 1274.7980s
Epoch: 6 cost time: 14.152532815933228
Epoch: 6, Steps: 265 Train Loss: 32.6775 (Forecasting Loss:0.1966 + XiCon Loss:3.2481 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1598
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.2812958
	speed: 0.0621s/iter; left time: 1539.5484s
	iters: 200, epoch: 7 | loss: 32.3027840
	speed: 0.0565s/iter; left time: 1396.5613s
Epoch: 7 cost time: 15.553056240081787
Epoch: 7, Steps: 265 Train Loss: 32.7246 (Forecasting Loss:0.1961 + XiCon Loss:3.2529 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.3968964
	speed: 0.0626s/iter; left time: 1537.5202s
	iters: 200, epoch: 8 | loss: 32.5183907
	speed: 0.0578s/iter; left time: 1413.5059s
Epoch: 8 cost time: 15.564181089401245
Epoch: 8, Steps: 265 Train Loss: 32.5980 (Forecasting Loss:0.1961 + XiCon Loss:3.2402 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1589
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0192375
	speed: 0.0468s/iter; left time: 1136.8797s
	iters: 200, epoch: 9 | loss: 32.5836296
	speed: 0.0572s/iter; left time: 1383.5931s
Epoch: 9 cost time: 14.046885251998901
Epoch: 9, Steps: 265 Train Loss: 32.6631 (Forecasting Loss:0.1958 + XiCon Loss:3.2467 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.6614571
	speed: 0.0617s/iter; left time: 1480.7654s
	iters: 200, epoch: 10 | loss: 32.2283745
	speed: 0.0574s/iter; left time: 1373.0656s
Epoch: 10 cost time: 15.569298028945923
Epoch: 10, Steps: 265 Train Loss: 32.5702 (Forecasting Loss:0.1958 + XiCon Loss:3.2374 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1589
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.7102203
	speed: 0.0561s/iter; left time: 1332.7461s
	iters: 200, epoch: 11 | loss: 32.5347252
	speed: 0.0461s/iter; left time: 1091.3521s
Epoch: 11 cost time: 13.485733270645142
Epoch: 11, Steps: 265 Train Loss: 32.6856 (Forecasting Loss:0.1957 + XiCon Loss:3.2490 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1589
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.9149036
	speed: 0.0626s/iter; left time: 1471.1179s
	iters: 200, epoch: 12 | loss: 32.6002235
	speed: 0.0564s/iter; left time: 1319.7705s
Epoch: 12 cost time: 15.871367931365967
Epoch: 12, Steps: 265 Train Loss: 32.6037 (Forecasting Loss:0.1957 + XiCon Loss:3.2408 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1589
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.2239723
	speed: 0.0599s/iter; left time: 1390.9636s
	iters: 200, epoch: 13 | loss: 31.8576946
	speed: 0.0594s/iter; left time: 1373.4953s
Epoch: 13 cost time: 14.86510968208313
Epoch: 13, Steps: 265 Train Loss: 32.6097 (Forecasting Loss:0.1957 + XiCon Loss:3.2414 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1589
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2302780
	speed: 0.0524s/iter; left time: 1202.5012s
	iters: 200, epoch: 14 | loss: 32.0522652
	speed: 0.0589s/iter; left time: 1346.3936s
Epoch: 14 cost time: 14.650946140289307
Epoch: 14, Steps: 265 Train Loss: 32.6509 (Forecasting Loss:0.1957 + XiCon Loss:3.2455 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1589
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.7615623
	speed: 0.0572s/iter; left time: 1298.0431s
	iters: 200, epoch: 15 | loss: 33.0597916
	speed: 0.0587s/iter; left time: 1326.5127s
Epoch: 15 cost time: 15.440926551818848
Epoch: 15, Steps: 265 Train Loss: 32.7120 (Forecasting Loss:0.1957 + XiCon Loss:3.2516 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1589
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09232130646705627, mae:0.22662347555160522, mape:0.546978235244751, mspe:11.185629844665527 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.4155
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 35.0295296
	speed: 0.0584s/iter; left time: 1542.6242s
	iters: 200, epoch: 1 | loss: 33.9491196
	speed: 0.0577s/iter; left time: 1517.7450s
Epoch: 1 cost time: 15.34155559539795
Epoch: 1, Steps: 265 Train Loss: 34.6189 (Forecasting Loss:0.2284 + XiCon Loss:3.4391 x Lambda(10.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1673
Validation loss decreased (inf --> 0.211390).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 35.6046181
	speed: 0.0586s/iter; left time: 1530.6916s
	iters: 200, epoch: 2 | loss: 37.5242310
	speed: 0.0449s/iter; left time: 1167.8355s
Epoch: 2 cost time: 13.426058530807495
Epoch: 2, Steps: 265 Train Loss: 35.6040 (Forecasting Loss:0.2067 + XiCon Loss:3.5397 x Lambda(10.0)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1670
Validation loss decreased (0.211390 --> 0.205252).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 37.4713326
	speed: 0.0612s/iter; left time: 1582.1704s
	iters: 200, epoch: 3 | loss: 35.5443878
	speed: 0.0572s/iter; left time: 1475.3843s
Epoch: 3 cost time: 15.753859043121338
Epoch: 3, Steps: 265 Train Loss: 36.3781 (Forecasting Loss:0.2004 + XiCon Loss:3.6178 x Lambda(10.0)), Vali MSE Loss: 0.2094 Test MSE Loss: 0.1650
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 35.3969917
	speed: 0.0614s/iter; left time: 1573.2856s
	iters: 200, epoch: 4 | loss: 34.9006844
	speed: 0.0585s/iter; left time: 1492.8139s
Epoch: 4 cost time: 15.257954597473145
Epoch: 4, Steps: 265 Train Loss: 35.7474 (Forecasting Loss:0.1984 + XiCon Loss:3.5549 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1617
Validation loss decreased (0.205252 --> 0.199134).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 34.1838837
	speed: 0.0420s/iter; left time: 1063.1384s
	iters: 200, epoch: 5 | loss: 36.2393951
	speed: 0.0296s/iter; left time: 746.1781s
Epoch: 5 cost time: 9.196401834487915
Epoch: 5, Steps: 265 Train Loss: 35.8930 (Forecasting Loss:0.1967 + XiCon Loss:3.5696 x Lambda(10.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.1609
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 36.4464035
	speed: 0.0587s/iter; left time: 1471.7588s
	iters: 200, epoch: 6 | loss: 35.4746399
	speed: 0.0548s/iter; left time: 1367.6490s
Epoch: 6 cost time: 15.108818531036377
Epoch: 6, Steps: 265 Train Loss: 35.4741 (Forecasting Loss:0.1961 + XiCon Loss:3.5278 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1605
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 35.9890633
	speed: 0.0604s/iter; left time: 1497.9373s
	iters: 200, epoch: 7 | loss: 35.3600311
	speed: 0.0566s/iter; left time: 1397.4210s
Epoch: 7 cost time: 15.080622673034668
Epoch: 7, Steps: 265 Train Loss: 35.3424 (Forecasting Loss:0.1955 + XiCon Loss:3.5147 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1608
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 35.4813805
	speed: 0.0449s/iter; left time: 1102.0071s
	iters: 200, epoch: 8 | loss: 35.8949013
	speed: 0.0581s/iter; left time: 1421.4906s
Epoch: 8 cost time: 14.277772188186646
Epoch: 8, Steps: 265 Train Loss: 35.3520 (Forecasting Loss:0.1954 + XiCon Loss:3.5157 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1607
Validation loss decreased (0.199134 --> 0.199132).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 35.4676437
	speed: 0.0599s/iter; left time: 1454.9329s
	iters: 200, epoch: 9 | loss: 35.4355583
	speed: 0.0598s/iter; left time: 1445.0493s
Epoch: 9 cost time: 15.680415868759155
Epoch: 9, Steps: 265 Train Loss: 35.4040 (Forecasting Loss:0.1953 + XiCon Loss:3.5209 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1605
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 35.3969536
	speed: 0.0560s/iter; left time: 1346.0695s
	iters: 200, epoch: 10 | loss: 35.9351044
	speed: 0.0453s/iter; left time: 1083.4016s
Epoch: 10 cost time: 13.614188432693481
Epoch: 10, Steps: 265 Train Loss: 35.3367 (Forecasting Loss:0.1952 + XiCon Loss:3.5141 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1605
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 34.8600731
	speed: 0.0593s/iter; left time: 1407.4380s
	iters: 200, epoch: 11 | loss: 37.0623703
	speed: 0.0569s/iter; left time: 1345.8152s
Epoch: 11 cost time: 15.403319835662842
Epoch: 11, Steps: 265 Train Loss: 35.4773 (Forecasting Loss:0.1952 + XiCon Loss:3.5282 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1605
Validation loss decreased (0.199132 --> 0.199010).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.3421135
	speed: 0.0615s/iter; left time: 1445.4136s
	iters: 200, epoch: 12 | loss: 35.2748528
	speed: 0.0558s/iter; left time: 1305.0443s
Epoch: 12 cost time: 14.634769678115845
Epoch: 12, Steps: 265 Train Loss: 35.3836 (Forecasting Loss:0.1951 + XiCon Loss:3.5188 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1605
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.7617149
	speed: 0.0539s/iter; left time: 1252.3378s
	iters: 200, epoch: 13 | loss: 36.2959328
	speed: 0.0582s/iter; left time: 1344.7913s
Epoch: 13 cost time: 14.975416421890259
Epoch: 13, Steps: 265 Train Loss: 35.3582 (Forecasting Loss:0.1952 + XiCon Loss:3.5163 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1605
Validation loss decreased (0.199010 --> 0.198597).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 34.9867325
	speed: 0.0619s/iter; left time: 1420.2715s
	iters: 200, epoch: 14 | loss: 35.5094986
	speed: 0.0571s/iter; left time: 1305.3756s
Epoch: 14 cost time: 15.584134578704834
Epoch: 14, Steps: 265 Train Loss: 35.3964 (Forecasting Loss:0.1951 + XiCon Loss:3.5201 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1605
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 35.9293251
	speed: 0.0480s/iter; left time: 1090.0204s
	iters: 200, epoch: 15 | loss: 35.1736069
	speed: 0.0491s/iter; left time: 1109.5392s
Epoch: 15 cost time: 13.510807752609253
Epoch: 15, Steps: 265 Train Loss: 35.4211 (Forecasting Loss:0.1953 + XiCon Loss:3.5226 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1605
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 34.1791878
	speed: 0.0608s/iter; left time: 1364.5432s
	iters: 200, epoch: 16 | loss: 34.5208473
	speed: 0.0580s/iter; left time: 1294.7030s
Epoch: 16 cost time: 15.569388151168823
Epoch: 16, Steps: 265 Train Loss: 35.5018 (Forecasting Loss:0.1952 + XiCon Loss:3.5307 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1605
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 34.2458992
	speed: 0.0577s/iter; left time: 1278.0115s
	iters: 200, epoch: 17 | loss: 34.5659218
	speed: 0.0498s/iter; left time: 1097.7169s
Epoch: 17 cost time: 13.58318018913269
Epoch: 17, Steps: 265 Train Loss: 35.4439 (Forecasting Loss:0.1952 + XiCon Loss:3.5249 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1605
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 34.4263306
	speed: 0.0325s/iter; left time: 711.1159s
	iters: 200, epoch: 18 | loss: 34.7371445
	speed: 0.0445s/iter; left time: 968.9112s
Epoch: 18 cost time: 11.453474044799805
Epoch: 18, Steps: 265 Train Loss: 35.3267 (Forecasting Loss:0.1950 + XiCon Loss:3.5132 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1605
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 34.4445686
	speed: 0.0590s/iter; left time: 1276.1934s
	iters: 200, epoch: 19 | loss: 35.2087288
	speed: 0.0562s/iter; left time: 1209.2976s
Epoch: 19 cost time: 15.208756923675537
Epoch: 19, Steps: 265 Train Loss: 35.4266 (Forecasting Loss:0.1951 + XiCon Loss:3.5231 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1605
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 34.9002876
	speed: 0.0623s/iter; left time: 1332.1213s
	iters: 200, epoch: 20 | loss: 35.7753181
	speed: 0.0487s/iter; left time: 1036.4765s
Epoch: 20 cost time: 14.10515022277832
Epoch: 20, Steps: 265 Train Loss: 35.4106 (Forecasting Loss:0.1951 + XiCon Loss:3.5216 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1605
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 36.3688126
	speed: 0.0601s/iter; left time: 1269.1050s
	iters: 200, epoch: 21 | loss: 35.8098450
	speed: 0.0593s/iter; left time: 1246.2907s
Epoch: 21 cost time: 15.723613977432251
Epoch: 21, Steps: 265 Train Loss: 35.4850 (Forecasting Loss:0.1951 + XiCon Loss:3.5290 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1605
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 35.9945068
	speed: 0.0615s/iter; left time: 1280.4467s
	iters: 200, epoch: 22 | loss: 35.1091156
	speed: 0.0587s/iter; left time: 1217.6357s
Epoch: 22 cost time: 15.634782791137695
Epoch: 22, Steps: 265 Train Loss: 35.3604 (Forecasting Loss:0.1952 + XiCon Loss:3.5165 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1605
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 34.3360291
	speed: 0.0461s/iter; left time: 947.6209s
	iters: 200, epoch: 23 | loss: 35.7251320
	speed: 0.0601s/iter; left time: 1229.8393s
Epoch: 23 cost time: 14.55764651298523
Epoch: 23, Steps: 265 Train Loss: 35.3875 (Forecasting Loss:0.1951 + XiCon Loss:3.5192 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1605
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09347348660230637, mae:0.22760352492332458, mape:0.5468835830688477, mspe:11.361784934997559 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0923+-0.00087, MAE:0.2262+-0.00114, MAPE:0.5451+-0.00234, MSPE:11.3094+-0.10007, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8697
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4614161
	speed: 0.0595s/iter; left time: 1516.3581s
	iters: 200, epoch: 1 | loss: 0.4958267
	speed: 0.0466s/iter; left time: 1183.3998s
Epoch: 1 cost time: 15.016522645950317
Epoch: 1, Steps: 256 Train Loss: 0.4697 (Forecasting Loss:0.4343 + XiCon Loss:3.5366 x Lambda(0.01)), Vali MSE Loss: 0.4131 Test MSE Loss: 0.3831
Validation loss decreased (inf --> 0.413086).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3612708
	speed: 0.0802s/iter; left time: 2023.5044s
	iters: 200, epoch: 2 | loss: 0.3680863
	speed: 0.0780s/iter; left time: 1960.7463s
Epoch: 2 cost time: 20.269123077392578
Epoch: 2, Steps: 256 Train Loss: 0.3747 (Forecasting Loss:0.3394 + XiCon Loss:3.5247 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3039
Validation loss decreased (0.413086 --> 0.327794).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3512641
	speed: 0.0752s/iter; left time: 1878.7780s
	iters: 200, epoch: 3 | loss: 0.3573428
	speed: 0.0794s/iter; left time: 1976.1170s
Epoch: 3 cost time: 20.068410396575928
Epoch: 3, Steps: 256 Train Loss: 0.3507 (Forecasting Loss:0.3156 + XiCon Loss:3.5118 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.3006
Validation loss decreased (0.327794 --> 0.320461).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3562713
	speed: 0.0802s/iter; left time: 1984.1407s
	iters: 200, epoch: 4 | loss: 0.3505147
	speed: 0.0778s/iter; left time: 1917.5472s
Epoch: 4 cost time: 20.097668170928955
Epoch: 4, Steps: 256 Train Loss: 0.3481 (Forecasting Loss:0.3130 + XiCon Loss:3.5108 x Lambda(0.01)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.3001
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3582997
	speed: 0.0783s/iter; left time: 1917.1236s
	iters: 200, epoch: 5 | loss: 0.3682902
	speed: 0.0779s/iter; left time: 1897.8600s
Epoch: 5 cost time: 20.262248277664185
Epoch: 5, Steps: 256 Train Loss: 0.3471 (Forecasting Loss:0.3120 + XiCon Loss:3.5095 x Lambda(0.01)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.3000
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3369442
	speed: 0.0830s/iter; left time: 2009.6079s
	iters: 200, epoch: 6 | loss: 0.3213712
	speed: 0.0771s/iter; left time: 1859.9556s
Epoch: 6 cost time: 20.07355523109436
Epoch: 6, Steps: 256 Train Loss: 0.3466 (Forecasting Loss:0.3115 + XiCon Loss:3.5089 x Lambda(0.01)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2996
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3648786
	speed: 0.0766s/iter; left time: 1836.4116s
	iters: 200, epoch: 7 | loss: 0.3354340
	speed: 0.0789s/iter; left time: 1883.4826s
Epoch: 7 cost time: 20.200356006622314
Epoch: 7, Steps: 256 Train Loss: 0.3464 (Forecasting Loss:0.3113 + XiCon Loss:3.5090 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3438461
	speed: 0.0810s/iter; left time: 1919.7045s
	iters: 200, epoch: 8 | loss: 0.3286679
	speed: 0.0762s/iter; left time: 1798.5603s
Epoch: 8 cost time: 20.09212303161621
Epoch: 8, Steps: 256 Train Loss: 0.3463 (Forecasting Loss:0.3113 + XiCon Loss:3.5090 x Lambda(0.01)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2996
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3760610
	speed: 0.0811s/iter; left time: 1902.8320s
	iters: 200, epoch: 9 | loss: 0.3478576
	speed: 0.0768s/iter; left time: 1794.2348s
Epoch: 9 cost time: 20.213860750198364
Epoch: 9, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3111 + XiCon Loss:3.5096 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3507361
	speed: 0.0794s/iter; left time: 1841.1324s
	iters: 200, epoch: 10 | loss: 0.3576219
	speed: 0.0765s/iter; left time: 1766.4081s
Epoch: 10 cost time: 20.033599376678467
Epoch: 10, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3111 + XiCon Loss:3.5086 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3564322
	speed: 0.0787s/iter; left time: 1805.1491s
	iters: 200, epoch: 11 | loss: 0.3633023
	speed: 0.0800s/iter; left time: 1828.1854s
Epoch: 11 cost time: 20.312514781951904
Epoch: 11, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3111 + XiCon Loss:3.5093 x Lambda(0.01)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2996
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3525176
	speed: 0.0772s/iter; left time: 1751.2430s
	iters: 200, epoch: 12 | loss: 0.3360929
	speed: 0.0772s/iter; left time: 1743.0074s
Epoch: 12 cost time: 19.899853229522705
Epoch: 12, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3111 + XiCon Loss:3.5090 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3539691
	speed: 0.0818s/iter; left time: 1834.7989s
	iters: 200, epoch: 13 | loss: 0.3445216
	speed: 0.0815s/iter; left time: 1818.7126s
Epoch: 13 cost time: 20.691728830337524
Epoch: 13, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3111 + XiCon Loss:3.5096 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22695331275463104, mae:0.3742707669734955, mape:0.7468517422676086, mspe:18.98126983642578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9269
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.5341287
	speed: 0.0762s/iter; left time: 1942.3616s
	iters: 200, epoch: 1 | loss: 0.4566968
	speed: 0.0721s/iter; left time: 1832.2431s
Epoch: 1 cost time: 18.89465069770813
Epoch: 1, Steps: 256 Train Loss: 0.4707 (Forecasting Loss:0.4349 + XiCon Loss:3.5796 x Lambda(0.01)), Vali MSE Loss: 0.4158 Test MSE Loss: 0.3855
Validation loss decreased (inf --> 0.415779).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3565605
	speed: 0.0715s/iter; left time: 1804.6173s
	iters: 200, epoch: 2 | loss: 0.3425853
	speed: 0.0774s/iter; left time: 1946.3732s
Epoch: 2 cost time: 19.119526863098145
Epoch: 2, Steps: 256 Train Loss: 0.3814 (Forecasting Loss:0.3461 + XiCon Loss:3.5334 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2976
Validation loss decreased (0.415779 --> 0.316157).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3603631
	speed: 0.0788s/iter; left time: 1970.2936s
	iters: 200, epoch: 3 | loss: 0.3520440
	speed: 0.0753s/iter; left time: 1873.7684s
Epoch: 3 cost time: 19.47835397720337
Epoch: 3, Steps: 256 Train Loss: 0.3525 (Forecasting Loss:0.3174 + XiCon Loss:3.5090 x Lambda(0.01)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2951
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3501256
	speed: 0.0772s/iter; left time: 1908.6624s
	iters: 200, epoch: 4 | loss: 0.3525837
	speed: 0.0765s/iter; left time: 1884.4384s
Epoch: 4 cost time: 19.545762062072754
Epoch: 4, Steps: 256 Train Loss: 0.3495 (Forecasting Loss:0.3145 + XiCon Loss:3.5067 x Lambda(0.01)), Vali MSE Loss: 0.3156 Test MSE Loss: 0.2944
Validation loss decreased (0.316157 --> 0.315593).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3918175
	speed: 0.0810s/iter; left time: 1983.0598s
	iters: 200, epoch: 5 | loss: 0.3621716
	speed: 0.0747s/iter; left time: 1822.1575s
Epoch: 5 cost time: 19.72088074684143
Epoch: 5, Steps: 256 Train Loss: 0.3485 (Forecasting Loss:0.3134 + XiCon Loss:3.5062 x Lambda(0.01)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3556365
	speed: 0.0790s/iter; left time: 1914.6345s
	iters: 200, epoch: 6 | loss: 0.3366575
	speed: 0.0718s/iter; left time: 1732.4358s
Epoch: 6 cost time: 19.238218784332275
Epoch: 6, Steps: 256 Train Loss: 0.3480 (Forecasting Loss:0.3129 + XiCon Loss:3.5052 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2940
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3398136
	speed: 0.0787s/iter; left time: 1887.0662s
	iters: 200, epoch: 7 | loss: 0.3512621
	speed: 0.0714s/iter; left time: 1703.5072s
Epoch: 7 cost time: 18.95342183113098
Epoch: 7, Steps: 256 Train Loss: 0.3477 (Forecasting Loss:0.3126 + XiCon Loss:3.5056 x Lambda(0.01)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2940
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3697141
	speed: 0.0782s/iter; left time: 1854.3198s
	iters: 200, epoch: 8 | loss: 0.3413361
	speed: 0.0749s/iter; left time: 1769.3118s
Epoch: 8 cost time: 19.495571851730347
Epoch: 8, Steps: 256 Train Loss: 0.3476 (Forecasting Loss:0.3126 + XiCon Loss:3.5049 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3284897
	speed: 0.0789s/iter; left time: 1849.7821s
	iters: 200, epoch: 9 | loss: 0.3687202
	speed: 0.0704s/iter; left time: 1643.1331s
Epoch: 9 cost time: 18.694096088409424
Epoch: 9, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3125 + XiCon Loss:3.5048 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3777167
	speed: 0.0770s/iter; left time: 1786.3348s
	iters: 200, epoch: 10 | loss: 0.3391597
	speed: 0.0746s/iter; left time: 1723.8240s
Epoch: 10 cost time: 19.337875366210938
Epoch: 10, Steps: 256 Train Loss: 0.3474 (Forecasting Loss:0.3124 + XiCon Loss:3.5053 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3645586
	speed: 0.0770s/iter; left time: 1766.4838s
	iters: 200, epoch: 11 | loss: 0.3494779
	speed: 0.0720s/iter; left time: 1645.0538s
Epoch: 11 cost time: 18.911406755447388
Epoch: 11, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3124 + XiCon Loss:3.5045 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3291294
	speed: 0.0772s/iter; left time: 1751.5142s
	iters: 200, epoch: 12 | loss: 0.3391163
	speed: 0.0754s/iter; left time: 1702.3013s
Epoch: 12 cost time: 19.384358882904053
Epoch: 12, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3124 + XiCon Loss:3.5050 x Lambda(0.01)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.2939
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3420916
	speed: 0.0780s/iter; left time: 1748.8048s
	iters: 200, epoch: 13 | loss: 0.3822883
	speed: 0.0703s/iter; left time: 1570.5559s
Epoch: 13 cost time: 18.979775190353394
Epoch: 13, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3124 + XiCon Loss:3.5050 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3489278
	speed: 0.0778s/iter; left time: 1724.7936s
	iters: 200, epoch: 14 | loss: 0.3419011
	speed: 0.0741s/iter; left time: 1635.0555s
Epoch: 14 cost time: 19.497244119644165
Epoch: 14, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3124 + XiCon Loss:3.5057 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2939
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2201147824525833, mae:0.3687824606895447, mape:0.749603271484375, mspe:19.596614837646484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.3123
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4404274
	speed: 0.0734s/iter; left time: 1872.3076s
	iters: 200, epoch: 1 | loss: 0.4412971
	speed: 0.0758s/iter; left time: 1925.6707s
Epoch: 1 cost time: 19.04338240623474
Epoch: 1, Steps: 256 Train Loss: 0.4673 (Forecasting Loss:0.4320 + XiCon Loss:3.5344 x Lambda(0.01)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3812
Validation loss decreased (inf --> 0.411460).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3680875
	speed: 0.0721s/iter; left time: 1820.8356s
	iters: 200, epoch: 2 | loss: 0.3557529
	speed: 0.0717s/iter; left time: 1803.1534s
Epoch: 2 cost time: 18.650643348693848
Epoch: 2, Steps: 256 Train Loss: 0.3788 (Forecasting Loss:0.3436 + XiCon Loss:3.5145 x Lambda(0.01)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.3001
Validation loss decreased (0.411460 --> 0.330530).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3488962
	speed: 0.0761s/iter; left time: 1900.7116s
	iters: 200, epoch: 3 | loss: 0.3384731
	speed: 0.0734s/iter; left time: 1827.2639s
Epoch: 3 cost time: 19.439417600631714
Epoch: 3, Steps: 256 Train Loss: 0.3521 (Forecasting Loss:0.3171 + XiCon Loss:3.5017 x Lambda(0.01)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2960
Validation loss decreased (0.330530 --> 0.321158).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3324523
	speed: 0.0742s/iter; left time: 1834.0358s
	iters: 200, epoch: 4 | loss: 0.3618571
	speed: 0.0713s/iter; left time: 1755.5380s
Epoch: 4 cost time: 18.59500551223755
Epoch: 4, Steps: 256 Train Loss: 0.3495 (Forecasting Loss:0.3145 + XiCon Loss:3.5001 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2968
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3756030
	speed: 0.0772s/iter; left time: 1889.0062s
	iters: 200, epoch: 5 | loss: 0.3546192
	speed: 0.0772s/iter; left time: 1881.8168s
Epoch: 5 cost time: 19.49144721031189
Epoch: 5, Steps: 256 Train Loss: 0.3485 (Forecasting Loss:0.3135 + XiCon Loss:3.5001 x Lambda(0.01)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2963
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3259562
	speed: 0.0784s/iter; left time: 1898.7769s
	iters: 200, epoch: 6 | loss: 0.3465926
	speed: 0.0770s/iter; left time: 1858.4353s
Epoch: 6 cost time: 19.870177268981934
Epoch: 6, Steps: 256 Train Loss: 0.3480 (Forecasting Loss:0.3130 + XiCon Loss:3.4983 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2965
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3398668
	speed: 0.0782s/iter; left time: 1875.2205s
	iters: 200, epoch: 7 | loss: 0.3536282
	speed: 0.0763s/iter; left time: 1821.2650s
Epoch: 7 cost time: 19.402061700820923
Epoch: 7, Steps: 256 Train Loss: 0.3478 (Forecasting Loss:0.3128 + XiCon Loss:3.4992 x Lambda(0.01)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.2967
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3440861
	speed: 0.0739s/iter; left time: 1751.4587s
	iters: 200, epoch: 8 | loss: 0.3422400
	speed: 0.0737s/iter; left time: 1740.1717s
Epoch: 8 cost time: 18.842853307724
Epoch: 8, Steps: 256 Train Loss: 0.3476 (Forecasting Loss:0.3127 + XiCon Loss:3.4984 x Lambda(0.01)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2964
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3370997
	speed: 0.0780s/iter; left time: 1828.3677s
	iters: 200, epoch: 9 | loss: 0.3374210
	speed: 0.0748s/iter; left time: 1747.0563s
Epoch: 9 cost time: 19.342844486236572
Epoch: 9, Steps: 256 Train Loss: 0.3476 (Forecasting Loss:0.3126 + XiCon Loss:3.4989 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3782563
	speed: 0.0658s/iter; left time: 1525.2466s
	iters: 200, epoch: 10 | loss: 0.3609311
	speed: 0.0402s/iter; left time: 928.5669s
Epoch: 10 cost time: 13.214724779129028
Epoch: 10, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3125 + XiCon Loss:3.4987 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2965
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3763947
	speed: 0.0536s/iter; left time: 1228.5984s
	iters: 200, epoch: 11 | loss: 0.3637811
	speed: 0.0454s/iter; left time: 1037.9129s
Epoch: 11 cost time: 12.574808835983276
Epoch: 11, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3125 + XiCon Loss:3.4990 x Lambda(0.01)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2965
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3207645
	speed: 0.0498s/iter; left time: 1130.3297s
	iters: 200, epoch: 12 | loss: 0.3377590
	speed: 0.0470s/iter; left time: 1062.3460s
Epoch: 12 cost time: 12.362399578094482
Epoch: 12, Steps: 256 Train Loss: 0.3475 (Forecasting Loss:0.3125 + XiCon Loss:3.4993 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3656994
	speed: 0.0522s/iter; left time: 1170.1515s
	iters: 200, epoch: 13 | loss: 0.3609290
	speed: 0.0467s/iter; left time: 1042.9258s
Epoch: 13 cost time: 12.523170948028564
Epoch: 13, Steps: 256 Train Loss: 0.3476 (Forecasting Loss:0.3126 + XiCon Loss:3.4988 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22186338901519775, mae:0.37004801630973816, mape:0.7376999258995056, mspe:18.824583053588867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.6213
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4674730
	speed: 0.0512s/iter; left time: 1305.4690s
	iters: 200, epoch: 1 | loss: 0.4512575
	speed: 0.0470s/iter; left time: 1193.8324s
Epoch: 1 cost time: 12.324007987976074
Epoch: 1, Steps: 256 Train Loss: 0.4673 (Forecasting Loss:0.4319 + XiCon Loss:3.5418 x Lambda(0.01)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3766
Validation loss decreased (inf --> 0.405968).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3636813
	speed: 0.0507s/iter; left time: 1281.1009s
	iters: 200, epoch: 2 | loss: 0.3743157
	speed: 0.0515s/iter; left time: 1295.1030s
Epoch: 2 cost time: 12.729778528213501
Epoch: 2, Steps: 256 Train Loss: 0.3801 (Forecasting Loss:0.3450 + XiCon Loss:3.5134 x Lambda(0.01)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3029
Validation loss decreased (0.405968 --> 0.338523).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3545930
	speed: 0.0510s/iter; left time: 1273.9310s
	iters: 200, epoch: 3 | loss: 0.3498501
	speed: 0.0496s/iter; left time: 1235.2777s
Epoch: 3 cost time: 13.142219305038452
Epoch: 3, Steps: 256 Train Loss: 0.3580 (Forecasting Loss:0.3231 + XiCon Loss:3.4965 x Lambda(0.01)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.2995
Validation loss decreased (0.338523 --> 0.334849).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3672918
	speed: 0.0540s/iter; left time: 1334.6217s
	iters: 200, epoch: 4 | loss: 0.3610053
	speed: 0.0483s/iter; left time: 1188.8671s
Epoch: 4 cost time: 13.000751256942749
Epoch: 4, Steps: 256 Train Loss: 0.3544 (Forecasting Loss:0.3195 + XiCon Loss:3.4889 x Lambda(0.01)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.2985
Validation loss decreased (0.334849 --> 0.332079).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3519374
	speed: 0.0534s/iter; left time: 1308.2431s
	iters: 200, epoch: 5 | loss: 0.3569617
	speed: 0.0501s/iter; left time: 1220.1431s
Epoch: 5 cost time: 13.305039405822754
Epoch: 5, Steps: 256 Train Loss: 0.3530 (Forecasting Loss:0.3181 + XiCon Loss:3.4856 x Lambda(0.01)), Vali MSE Loss: 0.3302 Test MSE Loss: 0.2977
Validation loss decreased (0.332079 --> 0.330213).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3416490
	speed: 0.0559s/iter; left time: 1354.2148s
	iters: 200, epoch: 6 | loss: 0.3646027
	speed: 0.0505s/iter; left time: 1217.0681s
Epoch: 6 cost time: 12.99070692062378
Epoch: 6, Steps: 256 Train Loss: 0.3523 (Forecasting Loss:0.3175 + XiCon Loss:3.4834 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2976
Validation loss decreased (0.330213 --> 0.329505).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3219815
	speed: 0.0535s/iter; left time: 1281.7433s
	iters: 200, epoch: 7 | loss: 0.3419397
	speed: 0.0473s/iter; left time: 1128.5154s
Epoch: 7 cost time: 12.57703185081482
Epoch: 7, Steps: 256 Train Loss: 0.3521 (Forecasting Loss:0.3172 + XiCon Loss:3.4828 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2975
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3589316
	speed: 0.0539s/iter; left time: 1278.1334s
	iters: 200, epoch: 8 | loss: 0.3513586
	speed: 0.0485s/iter; left time: 1144.8628s
Epoch: 8 cost time: 12.725948810577393
Epoch: 8, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4825 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2974
Validation loss decreased (0.329505 --> 0.329278).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3376742
	speed: 0.0489s/iter; left time: 1146.8096s
	iters: 200, epoch: 9 | loss: 0.3417851
	speed: 0.0463s/iter; left time: 1082.2438s
Epoch: 9 cost time: 12.107990026473999
Epoch: 9, Steps: 256 Train Loss: 0.3518 (Forecasting Loss:0.3169 + XiCon Loss:3.4824 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
Validation loss decreased (0.329278 --> 0.329168).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3733150
	speed: 0.0549s/iter; left time: 1273.2709s
	iters: 200, epoch: 10 | loss: 0.3391699
	speed: 0.0504s/iter; left time: 1164.1908s
Epoch: 10 cost time: 13.121270656585693
Epoch: 10, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4820 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3556503
	speed: 0.0549s/iter; left time: 1260.3589s
	iters: 200, epoch: 11 | loss: 0.3587384
	speed: 0.0457s/iter; left time: 1043.7874s
Epoch: 11 cost time: 12.556015014648438
Epoch: 11, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4817 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329168 --> 0.328999).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3306879
	speed: 0.0548s/iter; left time: 1243.2231s
	iters: 200, epoch: 12 | loss: 0.3481046
	speed: 0.0501s/iter; left time: 1132.5256s
Epoch: 12 cost time: 13.212416410446167
Epoch: 12, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4814 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3423909
	speed: 0.0527s/iter; left time: 1181.5470s
	iters: 200, epoch: 13 | loss: 0.3689104
	speed: 0.0472s/iter; left time: 1053.4815s
Epoch: 13 cost time: 12.743140697479248
Epoch: 13, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4817 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3579696
	speed: 0.0550s/iter; left time: 1219.2356s
	iters: 200, epoch: 14 | loss: 0.3422503
	speed: 0.0471s/iter; left time: 1038.7828s
Epoch: 14 cost time: 12.825311422348022
Epoch: 14, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4819 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.3505566
	speed: 0.0551s/iter; left time: 1207.0807s
	iters: 200, epoch: 15 | loss: 0.3465043
	speed: 0.0482s/iter; left time: 1051.9241s
Epoch: 15 cost time: 12.763051271438599
Epoch: 15, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4816 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.328999 --> 0.328992).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.3468637
	speed: 0.0559s/iter; left time: 1210.1680s
	iters: 200, epoch: 16 | loss: 0.3277413
	speed: 0.0478s/iter; left time: 1029.7925s
Epoch: 16 cost time: 12.851813793182373
Epoch: 16, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4819 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.328992 --> 0.328955).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.3640516
	speed: 0.0495s/iter; left time: 1059.4913s
	iters: 200, epoch: 17 | loss: 0.3519281
	speed: 0.0461s/iter; left time: 981.9339s
Epoch: 17 cost time: 12.239941358566284
Epoch: 17, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4821 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.3380710
	speed: 0.0541s/iter; left time: 1143.3351s
	iters: 200, epoch: 18 | loss: 0.3319894
	speed: 0.0484s/iter; left time: 1018.7415s
Epoch: 18 cost time: 12.850302696228027
Epoch: 18, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4821 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328955 --> 0.328937).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.3564085
	speed: 0.0533s/iter; left time: 1112.7665s
	iters: 200, epoch: 19 | loss: 0.3431531
	speed: 0.0505s/iter; left time: 1050.7917s
Epoch: 19 cost time: 13.339908599853516
Epoch: 19, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4820 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.3406413
	speed: 0.0550s/iter; left time: 1135.1537s
	iters: 200, epoch: 20 | loss: 0.3424320
	speed: 0.0487s/iter; left time: 1000.4896s
Epoch: 20 cost time: 12.793689250946045
Epoch: 20, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4821 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.3604870
	speed: 0.0532s/iter; left time: 1083.5888s
	iters: 200, epoch: 21 | loss: 0.3554849
	speed: 0.0455s/iter; left time: 923.5513s
Epoch: 21 cost time: 12.328810691833496
Epoch: 21, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4819 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328937 --> 0.328891).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.3574468
	speed: 0.0539s/iter; left time: 1085.3842s
	iters: 200, epoch: 22 | loss: 0.3576773
	speed: 0.0510s/iter; left time: 1022.0944s
Epoch: 22 cost time: 13.418741941452026
Epoch: 22, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3167 + XiCon Loss:3.4824 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.3408740
	speed: 0.0559s/iter; left time: 1110.6865s
	iters: 200, epoch: 23 | loss: 0.3538416
	speed: 0.0471s/iter; left time: 930.4059s
Epoch: 23 cost time: 12.836633920669556
Epoch: 23, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3168 + XiCon Loss:3.4813 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.3620054
	speed: 0.0530s/iter; left time: 1039.0816s
	iters: 200, epoch: 24 | loss: 0.3384845
	speed: 0.0506s/iter; left time: 987.8129s
Epoch: 24 cost time: 13.167885303497314
Epoch: 24, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4820 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.3577054
	speed: 0.0558s/iter; left time: 1079.3944s
	iters: 200, epoch: 25 | loss: 0.3865727
	speed: 0.0505s/iter; left time: 972.5823s
Epoch: 25 cost time: 13.442235469818115
Epoch: 25, Steps: 256 Train Loss: 0.3518 (Forecasting Loss:0.3169 + XiCon Loss:3.4820 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.3569142
	speed: 0.0538s/iter; left time: 1026.8406s
	iters: 200, epoch: 26 | loss: 0.3442590
	speed: 0.0461s/iter; left time: 875.3112s
Epoch: 26 cost time: 12.666106224060059
Epoch: 26, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3168 + XiCon Loss:3.4819 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328891 --> 0.328869).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.3664718
	speed: 0.0514s/iter; left time: 968.5678s
	iters: 200, epoch: 27 | loss: 0.3453896
	speed: 0.0483s/iter; left time: 906.1230s
Epoch: 27 cost time: 12.469356775283813
Epoch: 27, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3168 + XiCon Loss:3.4826 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.3475367
	speed: 0.0510s/iter; left time: 948.4561s
	iters: 200, epoch: 28 | loss: 0.3602175
	speed: 0.0497s/iter; left time: 918.2241s
Epoch: 28 cost time: 13.021982908248901
Epoch: 28, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4819 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.3490661
	speed: 0.0501s/iter; left time: 918.4266s
	iters: 200, epoch: 29 | loss: 0.3584134
	speed: 0.0466s/iter; left time: 850.2112s
Epoch: 29 cost time: 12.456262111663818
Epoch: 29, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4814 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.3829976
	speed: 0.0560s/iter; left time: 1012.0660s
	iters: 200, epoch: 30 | loss: 0.3572400
	speed: 0.0474s/iter; left time: 852.1692s
Epoch: 30 cost time: 12.922920942306519
Epoch: 30, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4815 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.3451149
	speed: 0.0523s/iter; left time: 931.4741s
	iters: 200, epoch: 31 | loss: 0.3431174
	speed: 0.0499s/iter; left time: 884.8703s
Epoch: 31 cost time: 12.884978532791138
Epoch: 31, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4818 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.3481923
	speed: 0.0523s/iter; left time: 919.4876s
	iters: 200, epoch: 32 | loss: 0.3488846
	speed: 0.0466s/iter; left time: 813.0377s
Epoch: 32 cost time: 12.579575300216675
Epoch: 32, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4823 x Lambda(0.01)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2974
Validation loss decreased (0.328869 --> 0.328774).  Saving model ...
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.3453041
	speed: 0.0502s/iter; left time: 869.5740s
	iters: 200, epoch: 33 | loss: 0.3447386
	speed: 0.0461s/iter; left time: 793.3833s
Epoch: 33 cost time: 12.584995746612549
Epoch: 33, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4820 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.3404082
	speed: 0.0541s/iter; left time: 923.3788s
	iters: 200, epoch: 34 | loss: 0.3224280
	speed: 0.0481s/iter; left time: 816.2768s
Epoch: 34 cost time: 12.976992130279541
Epoch: 34, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4817 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.3454369
	speed: 0.0513s/iter; left time: 861.7513s
	iters: 200, epoch: 35 | loss: 0.3452075
	speed: 0.0463s/iter; left time: 772.3177s
Epoch: 35 cost time: 12.55613923072815
Epoch: 35, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4823 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.3389052
	speed: 0.0510s/iter; left time: 843.0382s
	iters: 200, epoch: 36 | loss: 0.3309000
	speed: 0.0464s/iter; left time: 763.5019s
Epoch: 36 cost time: 12.357067584991455
Epoch: 36, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4813 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.3333721
	speed: 0.0495s/iter; left time: 806.8718s
	iters: 200, epoch: 37 | loss: 0.3314672
	speed: 0.0466s/iter; left time: 754.3776s
Epoch: 37 cost time: 12.505175590515137
Epoch: 37, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3167 + XiCon Loss:3.4819 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.3440879
	speed: 0.0526s/iter; left time: 843.2069s
	iters: 200, epoch: 38 | loss: 0.3579917
	speed: 0.0466s/iter; left time: 742.4130s
Epoch: 38 cost time: 12.587566137313843
Epoch: 38, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4818 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.3458675
	speed: 0.0511s/iter; left time: 806.0122s
	iters: 200, epoch: 39 | loss: 0.3326156
	speed: 0.0468s/iter; left time: 733.3489s
Epoch: 39 cost time: 12.597610235214233
Epoch: 39, Steps: 256 Train Loss: 0.3516 (Forecasting Loss:0.3168 + XiCon Loss:3.4814 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.3768723
	speed: 0.0543s/iter; left time: 843.0823s
	iters: 200, epoch: 40 | loss: 0.3854662
	speed: 0.0478s/iter; left time: 737.3806s
Epoch: 40 cost time: 12.820686340332031
Epoch: 40, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3168 + XiCon Loss:3.4821 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.3652488
	speed: 0.0505s/iter; left time: 770.6373s
	iters: 200, epoch: 41 | loss: 0.3549864
	speed: 0.0458s/iter; left time: 694.6999s
Epoch: 41 cost time: 12.559127569198608
Epoch: 41, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3168 + XiCon Loss:3.4826 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.3844541
	speed: 0.0548s/iter; left time: 822.4488s
	iters: 200, epoch: 42 | loss: 0.3375237
	speed: 0.0466s/iter; left time: 694.0353s
Epoch: 42 cost time: 12.752588510513306
Epoch: 42, Steps: 256 Train Loss: 0.3517 (Forecasting Loss:0.3169 + XiCon Loss:3.4823 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2205611914396286, mae:0.37420234084129333, mape:0.727612316608429, mspe:18.853761672973633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8539
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4375169
	speed: 0.0543s/iter; left time: 1383.4381s
	iters: 200, epoch: 1 | loss: 0.4924550
	speed: 0.0478s/iter; left time: 1215.0139s
Epoch: 1 cost time: 12.962396383285522
Epoch: 1, Steps: 256 Train Loss: 0.4735 (Forecasting Loss:0.4381 + XiCon Loss:3.5490 x Lambda(0.01)), Vali MSE Loss: 0.3983 Test MSE Loss: 0.3709
Validation loss decreased (inf --> 0.398277).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3858855
	speed: 0.0571s/iter; left time: 1440.5362s
	iters: 200, epoch: 2 | loss: 0.4073693
	speed: 0.0508s/iter; left time: 1276.5698s
Epoch: 2 cost time: 13.565730333328247
Epoch: 2, Steps: 256 Train Loss: 0.3861 (Forecasting Loss:0.3509 + XiCon Loss:3.5250 x Lambda(0.01)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.3010
Validation loss decreased (0.398277 --> 0.330390).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3549128
	speed: 0.0540s/iter; left time: 1348.5867s
	iters: 200, epoch: 3 | loss: 0.3583297
	speed: 0.0488s/iter; left time: 1213.7001s
Epoch: 3 cost time: 13.127351999282837
Epoch: 3, Steps: 256 Train Loss: 0.3572 (Forecasting Loss:0.3223 + XiCon Loss:3.4903 x Lambda(0.01)), Vali MSE Loss: 0.3114 Test MSE Loss: 0.3015
Validation loss decreased (0.330390 --> 0.311422).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3318043
	speed: 0.0563s/iter; left time: 1391.2623s
	iters: 200, epoch: 4 | loss: 0.3439785
	speed: 0.0546s/iter; left time: 1344.8411s
Epoch: 4 cost time: 14.032416343688965
Epoch: 4, Steps: 256 Train Loss: 0.3492 (Forecasting Loss:0.3144 + XiCon Loss:3.4812 x Lambda(0.01)), Vali MSE Loss: 0.3087 Test MSE Loss: 0.3031
Validation loss decreased (0.311422 --> 0.308652).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3284321
	speed: 0.0529s/iter; left time: 1294.6595s
	iters: 200, epoch: 5 | loss: 0.3318778
	speed: 0.0486s/iter; left time: 1185.2972s
Epoch: 5 cost time: 13.307761192321777
Epoch: 5, Steps: 256 Train Loss: 0.3468 (Forecasting Loss:0.3120 + XiCon Loss:3.4777 x Lambda(0.01)), Vali MSE Loss: 0.3088 Test MSE Loss: 0.3035
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3428183
	speed: 0.0552s/iter; left time: 1337.7365s
	iters: 200, epoch: 6 | loss: 0.3435760
	speed: 0.0540s/iter; left time: 1301.7218s
Epoch: 6 cost time: 13.758031368255615
Epoch: 6, Steps: 256 Train Loss: 0.3457 (Forecasting Loss:0.3109 + XiCon Loss:3.4763 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3039
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3440851
	speed: 0.0524s/iter; left time: 1255.7477s
	iters: 200, epoch: 7 | loss: 0.3721613
	speed: 0.0491s/iter; left time: 1171.5747s
Epoch: 7 cost time: 13.088257789611816
Epoch: 7, Steps: 256 Train Loss: 0.3451 (Forecasting Loss:0.3104 + XiCon Loss:3.4751 x Lambda(0.01)), Vali MSE Loss: 0.3094 Test MSE Loss: 0.3040
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3432509
	speed: 0.0546s/iter; left time: 1293.6676s
	iters: 200, epoch: 8 | loss: 0.3562906
	speed: 0.0489s/iter; left time: 1155.5980s
Epoch: 8 cost time: 13.31598949432373
Epoch: 8, Steps: 256 Train Loss: 0.3450 (Forecasting Loss:0.3103 + XiCon Loss:3.4755 x Lambda(0.01)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3345110
	speed: 0.0538s/iter; left time: 1260.8538s
	iters: 200, epoch: 9 | loss: 0.3500419
	speed: 0.0504s/iter; left time: 1176.5218s
Epoch: 9 cost time: 13.385159969329834
Epoch: 9, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3100 + XiCon Loss:3.4745 x Lambda(0.01)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.3041
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3334690
	speed: 0.0569s/iter; left time: 1320.5324s
	iters: 200, epoch: 10 | loss: 0.3364884
	speed: 0.0505s/iter; left time: 1166.4118s
Epoch: 10 cost time: 13.680795192718506
Epoch: 10, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3100 + XiCon Loss:3.4741 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3041
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3489244
	speed: 0.0573s/iter; left time: 1313.4427s
	iters: 200, epoch: 11 | loss: 0.3352180
	speed: 0.0549s/iter; left time: 1253.8085s
Epoch: 11 cost time: 14.371584177017212
Epoch: 11, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3100 + XiCon Loss:3.4745 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3518287
	speed: 0.0516s/iter; left time: 1169.5564s
	iters: 200, epoch: 12 | loss: 0.3542706
	speed: 0.0500s/iter; left time: 1128.1897s
Epoch: 12 cost time: 12.771182775497437
Epoch: 12, Steps: 256 Train Loss: 0.3447 (Forecasting Loss:0.3100 + XiCon Loss:3.4745 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3166330
	speed: 0.0584s/iter; left time: 1309.5123s
	iters: 200, epoch: 13 | loss: 0.3632158
	speed: 0.0560s/iter; left time: 1250.3759s
Epoch: 13 cost time: 14.338773965835571
Epoch: 13, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3100 + XiCon Loss:3.4743 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3579071
	speed: 0.0528s/iter; left time: 1171.2144s
	iters: 200, epoch: 14 | loss: 0.3389442
	speed: 0.0507s/iter; left time: 1119.1126s
Epoch: 14 cost time: 13.132580757141113
Epoch: 14, Steps: 256 Train Loss: 0.3447 (Forecasting Loss:0.3100 + XiCon Loss:3.4751 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22968770563602448, mae:0.37648239731788635, mape:0.7645583152770996, mspe:20.691030502319336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2238+-0.00528, MAE:0.3728+-0.00399, MAPE:0.7453+-0.01714, MSPE:19.3895+-0.98352, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.4592
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.9631748
	speed: 0.0895s/iter; left time: 2175.8801s
	iters: 200, epoch: 1 | loss: 3.9400821
	speed: 0.0856s/iter; left time: 2071.6776s
Epoch: 1 cost time: 21.205535173416138
Epoch: 1, Steps: 244 Train Loss: 3.9859 (Forecasting Loss:0.4576 + XiCon Loss:3.5283 x Lambda(1.0)), Vali MSE Loss: 0.4554 Test MSE Loss: 0.3567
Validation loss decreased (inf --> 0.455366).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.7211862
	speed: 0.0820s/iter; left time: 1972.7151s
	iters: 200, epoch: 2 | loss: 3.7521107
	speed: 0.0809s/iter; left time: 1939.0263s
Epoch: 2 cost time: 20.200281143188477
Epoch: 2, Steps: 244 Train Loss: 3.7618 (Forecasting Loss:0.3662 + XiCon Loss:3.3956 x Lambda(1.0)), Vali MSE Loss: 0.3810 Test MSE Loss: 0.2909
Validation loss decreased (0.455366 --> 0.380980).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.7332821
	speed: 0.0839s/iter; left time: 1997.0688s
	iters: 200, epoch: 3 | loss: 3.7934897
	speed: 0.0810s/iter; left time: 1920.1501s
Epoch: 3 cost time: 19.936696767807007
Epoch: 3, Steps: 244 Train Loss: 3.7592 (Forecasting Loss:0.3469 + XiCon Loss:3.4123 x Lambda(1.0)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.2902
Validation loss decreased (0.380980 --> 0.367558).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7185628
	speed: 0.0851s/iter; left time: 2004.6827s
	iters: 200, epoch: 4 | loss: 3.6966207
	speed: 0.0824s/iter; left time: 1933.9517s
Epoch: 4 cost time: 20.31511688232422
Epoch: 4, Steps: 244 Train Loss: 3.7337 (Forecasting Loss:0.3425 + XiCon Loss:3.3911 x Lambda(1.0)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2984
Validation loss decreased (0.367558 --> 0.346542).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.7399657
	speed: 0.0872s/iter; left time: 2033.6460s
	iters: 200, epoch: 5 | loss: 3.7861853
	speed: 0.0822s/iter; left time: 1909.4996s
Epoch: 5 cost time: 20.665517568588257
Epoch: 5, Steps: 244 Train Loss: 3.7187 (Forecasting Loss:0.3410 + XiCon Loss:3.3778 x Lambda(1.0)), Vali MSE Loss: 0.3493 Test MSE Loss: 0.2929
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.7254267
	speed: 0.0844s/iter; left time: 1948.8089s
	iters: 200, epoch: 6 | loss: 3.7136834
	speed: 0.0862s/iter; left time: 1980.5517s
Epoch: 6 cost time: 20.668107271194458
Epoch: 6, Steps: 244 Train Loss: 3.7119 (Forecasting Loss:0.3393 + XiCon Loss:3.3726 x Lambda(1.0)), Vali MSE Loss: 0.3585 Test MSE Loss: 0.2926
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6829197
	speed: 0.0845s/iter; left time: 1928.7206s
	iters: 200, epoch: 7 | loss: 3.7087209
	speed: 0.0815s/iter; left time: 1853.5644s
Epoch: 7 cost time: 20.260167837142944
Epoch: 7, Steps: 244 Train Loss: 3.7084 (Forecasting Loss:0.3390 + XiCon Loss:3.3694 x Lambda(1.0)), Vali MSE Loss: 0.3511 Test MSE Loss: 0.2923
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6671576
	speed: 0.0858s/iter; left time: 1938.6731s
	iters: 200, epoch: 8 | loss: 3.7549474
	speed: 0.0808s/iter; left time: 1818.2997s
Epoch: 8 cost time: 20.151233911514282
Epoch: 8, Steps: 244 Train Loss: 3.7068 (Forecasting Loss:0.3394 + XiCon Loss:3.3674 x Lambda(1.0)), Vali MSE Loss: 0.3551 Test MSE Loss: 0.2925
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6746566
	speed: 0.0843s/iter; left time: 1883.9762s
	iters: 200, epoch: 9 | loss: 3.6642678
	speed: 0.0858s/iter; left time: 1909.7154s
Epoch: 9 cost time: 20.75861954689026
Epoch: 9, Steps: 244 Train Loss: 3.7039 (Forecasting Loss:0.3390 + XiCon Loss:3.3649 x Lambda(1.0)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.2924
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6749389
	speed: 0.0874s/iter; left time: 1932.7937s
	iters: 200, epoch: 10 | loss: 3.6825306
	speed: 0.0821s/iter; left time: 1807.3550s
Epoch: 10 cost time: 20.70449733734131
Epoch: 10, Steps: 244 Train Loss: 3.7048 (Forecasting Loss:0.3387 + XiCon Loss:3.3661 x Lambda(1.0)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2924
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.7611413
	speed: 0.0833s/iter; left time: 1820.7227s
	iters: 200, epoch: 11 | loss: 3.6941133
	speed: 0.0853s/iter; left time: 1856.7529s
Epoch: 11 cost time: 20.480862617492676
Epoch: 11, Steps: 244 Train Loss: 3.7053 (Forecasting Loss:0.3391 + XiCon Loss:3.3662 x Lambda(1.0)), Vali MSE Loss: 0.3524 Test MSE Loss: 0.2924
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.7149005
	speed: 0.0838s/iter; left time: 1812.2945s
	iters: 200, epoch: 12 | loss: 3.6874490
	speed: 0.0830s/iter; left time: 1785.2946s
Epoch: 12 cost time: 20.28523087501526
Epoch: 12, Steps: 244 Train Loss: 3.7032 (Forecasting Loss:0.3389 + XiCon Loss:3.3643 x Lambda(1.0)), Vali MSE Loss: 0.3522 Test MSE Loss: 0.2924
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.7498832
	speed: 0.0870s/iter; left time: 1860.3485s
	iters: 200, epoch: 13 | loss: 3.6858718
	speed: 0.0858s/iter; left time: 1825.5673s
Epoch: 13 cost time: 21.002327919006348
Epoch: 13, Steps: 244 Train Loss: 3.7055 (Forecasting Loss:0.3384 + XiCon Loss:3.3671 x Lambda(1.0)), Vali MSE Loss: 0.3522 Test MSE Loss: 0.2924
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6888580
	speed: 0.0838s/iter; left time: 1770.3673s
	iters: 200, epoch: 14 | loss: 3.7468956
	speed: 0.0817s/iter; left time: 1718.9111s
Epoch: 14 cost time: 20.15881586074829
Epoch: 14, Steps: 244 Train Loss: 3.7001 (Forecasting Loss:0.3385 + XiCon Loss:3.3616 x Lambda(1.0)), Vali MSE Loss: 0.3522 Test MSE Loss: 0.2924
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.21988831460475922, mae:0.3768171966075897, mape:0.758393406867981, mspe:22.69002914428711 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.8134
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 4.0127583
	speed: 0.0727s/iter; left time: 1767.8585s
	iters: 200, epoch: 1 | loss: 3.9542384
	speed: 0.0724s/iter; left time: 1752.7226s
Epoch: 1 cost time: 17.908527851104736
Epoch: 1, Steps: 244 Train Loss: 3.9893 (Forecasting Loss:0.4584 + XiCon Loss:3.5309 x Lambda(1.0)), Vali MSE Loss: 0.4584 Test MSE Loss: 0.3615
Validation loss decreased (inf --> 0.458372).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6938653
	speed: 0.0756s/iter; left time: 1819.3563s
	iters: 200, epoch: 2 | loss: 3.7054238
	speed: 0.0818s/iter; left time: 1960.0076s
Epoch: 2 cost time: 20.162895441055298
Epoch: 2, Steps: 244 Train Loss: 3.7517 (Forecasting Loss:0.3926 + XiCon Loss:3.3591 x Lambda(1.0)), Vali MSE Loss: 0.4151 Test MSE Loss: 0.3286
Validation loss decreased (0.458372 --> 0.415076).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.7548015
	speed: 0.1002s/iter; left time: 2385.7444s
	iters: 200, epoch: 3 | loss: 3.7771366
	speed: 0.0946s/iter; left time: 2243.5665s
Epoch: 3 cost time: 24.10494828224182
Epoch: 3, Steps: 244 Train Loss: 3.7707 (Forecasting Loss:0.3863 + XiCon Loss:3.3844 x Lambda(1.0)), Vali MSE Loss: 0.4192 Test MSE Loss: 0.3280
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7879415
	speed: 0.1022s/iter; left time: 2407.9134s
	iters: 200, epoch: 4 | loss: 3.8882079
	speed: 0.1000s/iter; left time: 2345.8705s
Epoch: 4 cost time: 24.418089628219604
Epoch: 4, Steps: 244 Train Loss: 3.8302 (Forecasting Loss:0.3845 + XiCon Loss:3.4456 x Lambda(1.0)), Vali MSE Loss: 0.4200 Test MSE Loss: 0.3281
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.8521900
	speed: 0.1009s/iter; left time: 2352.4498s
	iters: 200, epoch: 5 | loss: 3.8853281
	speed: 0.0982s/iter; left time: 2281.5672s
Epoch: 5 cost time: 24.176716089248657
Epoch: 5, Steps: 244 Train Loss: 3.8569 (Forecasting Loss:0.3833 + XiCon Loss:3.4736 x Lambda(1.0)), Vali MSE Loss: 0.4203 Test MSE Loss: 0.3285
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.9724755
	speed: 0.1060s/iter; left time: 2446.6318s
	iters: 200, epoch: 6 | loss: 3.8689599
	speed: 0.0998s/iter; left time: 2293.7416s
Epoch: 6 cost time: 24.786667346954346
Epoch: 6, Steps: 244 Train Loss: 3.8724 (Forecasting Loss:0.3825 + XiCon Loss:3.4899 x Lambda(1.0)), Vali MSE Loss: 0.4212 Test MSE Loss: 0.3296
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.8717098
	speed: 0.1017s/iter; left time: 2321.8510s
	iters: 200, epoch: 7 | loss: 3.9149969
	speed: 0.0986s/iter; left time: 2241.3722s
Epoch: 7 cost time: 24.4027898311615
Epoch: 7, Steps: 244 Train Loss: 3.8800 (Forecasting Loss:0.3825 + XiCon Loss:3.4975 x Lambda(1.0)), Vali MSE Loss: 0.4211 Test MSE Loss: 0.3293
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.8467250
	speed: 0.1010s/iter; left time: 2282.2491s
	iters: 200, epoch: 8 | loss: 3.9297843
	speed: 0.0985s/iter; left time: 2215.8464s
Epoch: 8 cost time: 24.109159231185913
Epoch: 8, Steps: 244 Train Loss: 3.8895 (Forecasting Loss:0.3825 + XiCon Loss:3.5070 x Lambda(1.0)), Vali MSE Loss: 0.4220 Test MSE Loss: 0.3301
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.9033625
	speed: 0.1012s/iter; left time: 2261.0795s
	iters: 200, epoch: 9 | loss: 3.7996564
	speed: 0.1019s/iter; left time: 2268.2764s
Epoch: 9 cost time: 24.720244646072388
Epoch: 9, Steps: 244 Train Loss: 3.8964 (Forecasting Loss:0.3821 + XiCon Loss:3.5143 x Lambda(1.0)), Vali MSE Loss: 0.4219 Test MSE Loss: 0.3301
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.8075538
	speed: 0.1009s/iter; left time: 2229.5479s
	iters: 200, epoch: 10 | loss: 3.9167497
	speed: 0.0964s/iter; left time: 2120.9156s
Epoch: 10 cost time: 23.846379280090332
Epoch: 10, Steps: 244 Train Loss: 3.8890 (Forecasting Loss:0.3821 + XiCon Loss:3.5069 x Lambda(1.0)), Vali MSE Loss: 0.4215 Test MSE Loss: 0.3299
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.9165678
	speed: 0.0982s/iter; left time: 2146.1046s
	iters: 200, epoch: 11 | loss: 3.8822057
	speed: 0.0986s/iter; left time: 2144.8753s
Epoch: 11 cost time: 23.808154106140137
Epoch: 11, Steps: 244 Train Loss: 3.8906 (Forecasting Loss:0.3822 + XiCon Loss:3.5084 x Lambda(1.0)), Vali MSE Loss: 0.4211 Test MSE Loss: 0.3299
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.9532702
	speed: 0.0957s/iter; left time: 2067.8610s
	iters: 200, epoch: 12 | loss: 3.9429121
	speed: 0.0988s/iter; left time: 2125.6144s
Epoch: 12 cost time: 23.715933084487915
Epoch: 12, Steps: 244 Train Loss: 3.8892 (Forecasting Loss:0.3823 + XiCon Loss:3.5069 x Lambda(1.0)), Vali MSE Loss: 0.4216 Test MSE Loss: 0.3300
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.25343212485313416, mae:0.40375789999961853, mape:0.6634635925292969, mspe:14.445294380187988 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9843
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.9769416
	speed: 0.0756s/iter; left time: 1836.8014s
	iters: 200, epoch: 1 | loss: 3.9574189
	speed: 0.0711s/iter; left time: 1719.9468s
Epoch: 1 cost time: 17.83746647834778
Epoch: 1, Steps: 244 Train Loss: 3.9754 (Forecasting Loss:0.4635 + XiCon Loss:3.5119 x Lambda(1.0)), Vali MSE Loss: 0.4394 Test MSE Loss: 0.3381
Validation loss decreased (inf --> 0.439444).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6861188
	speed: 0.0796s/iter; left time: 1913.8373s
	iters: 200, epoch: 2 | loss: 3.7239375
	speed: 0.0738s/iter; left time: 1769.1704s
Epoch: 2 cost time: 18.420893669128418
Epoch: 2, Steps: 244 Train Loss: 3.7284 (Forecasting Loss:0.3801 + XiCon Loss:3.3483 x Lambda(1.0)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.2879
Validation loss decreased (0.439444 --> 0.353511).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.7001958
	speed: 0.0747s/iter; left time: 1777.9298s
	iters: 200, epoch: 3 | loss: 3.7502666
	speed: 0.0767s/iter; left time: 1819.0029s
Epoch: 3 cost time: 18.57329225540161
Epoch: 3, Steps: 244 Train Loss: 3.7191 (Forecasting Loss:0.3489 + XiCon Loss:3.3702 x Lambda(1.0)), Vali MSE Loss: 0.3504 Test MSE Loss: 0.2851
Validation loss decreased (0.353511 --> 0.350387).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7165203
	speed: 0.0790s/iter; left time: 1861.4965s
	iters: 200, epoch: 4 | loss: 3.6912172
	speed: 0.0717s/iter; left time: 1682.7236s
Epoch: 4 cost time: 18.565197944641113
Epoch: 4, Steps: 244 Train Loss: 3.6931 (Forecasting Loss:0.3429 + XiCon Loss:3.3502 x Lambda(1.0)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2871
Validation loss decreased (0.350387 --> 0.328919).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6662397
	speed: 0.0788s/iter; left time: 1837.0466s
	iters: 200, epoch: 5 | loss: 3.6302190
	speed: 0.0738s/iter; left time: 1715.0857s
Epoch: 5 cost time: 18.445293426513672
Epoch: 5, Steps: 244 Train Loss: 3.6770 (Forecasting Loss:0.3394 + XiCon Loss:3.3376 x Lambda(1.0)), Vali MSE Loss: 0.3303 Test MSE Loss: 0.2871
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6872838
	speed: 0.0832s/iter; left time: 1919.5124s
	iters: 200, epoch: 6 | loss: 3.7472227
	speed: 0.0764s/iter; left time: 1755.6461s
Epoch: 6 cost time: 19.286805152893066
Epoch: 6, Steps: 244 Train Loss: 3.6607 (Forecasting Loss:0.3373 + XiCon Loss:3.3234 x Lambda(1.0)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.2874
Validation loss decreased (0.328919 --> 0.327766).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6342206
	speed: 0.0797s/iter; left time: 1821.0298s
	iters: 200, epoch: 7 | loss: 3.6323500
	speed: 0.0767s/iter; left time: 1744.2206s
Epoch: 7 cost time: 19.151854515075684
Epoch: 7, Steps: 244 Train Loss: 3.6572 (Forecasting Loss:0.3358 + XiCon Loss:3.3214 x Lambda(1.0)), Vali MSE Loss: 0.3268 Test MSE Loss: 0.2872
Validation loss decreased (0.327766 --> 0.326799).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.7468655
	speed: 0.0795s/iter; left time: 1795.6279s
	iters: 200, epoch: 8 | loss: 3.6217427
	speed: 0.0810s/iter; left time: 1823.0009s
Epoch: 8 cost time: 19.71170425415039
Epoch: 8, Steps: 244 Train Loss: 3.6574 (Forecasting Loss:0.3358 + XiCon Loss:3.3216 x Lambda(1.0)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.2873
Validation loss decreased (0.326799 --> 0.326612).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.7065580
	speed: 0.0778s/iter; left time: 1739.3870s
	iters: 200, epoch: 9 | loss: 3.6146076
	speed: 0.0770s/iter; left time: 1712.7851s
Epoch: 9 cost time: 18.9290030002594
Epoch: 9, Steps: 244 Train Loss: 3.6536 (Forecasting Loss:0.3352 + XiCon Loss:3.3184 x Lambda(1.0)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.2872
Validation loss decreased (0.326612 --> 0.326358).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6837046
	speed: 0.0789s/iter; left time: 1744.8617s
	iters: 200, epoch: 10 | loss: 3.6658697
	speed: 0.0749s/iter; left time: 1647.9255s
Epoch: 10 cost time: 18.8378746509552
Epoch: 10, Steps: 244 Train Loss: 3.6560 (Forecasting Loss:0.3357 + XiCon Loss:3.3203 x Lambda(1.0)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2873
Validation loss decreased (0.326358 --> 0.325991).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6182532
	speed: 0.0772s/iter; left time: 1687.4981s
	iters: 200, epoch: 11 | loss: 3.6505024
	speed: 0.0802s/iter; left time: 1744.2830s
Epoch: 11 cost time: 19.21685004234314
Epoch: 11, Steps: 244 Train Loss: 3.6533 (Forecasting Loss:0.3356 + XiCon Loss:3.3177 x Lambda(1.0)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.2873
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6242566
	speed: 0.0799s/iter; left time: 1726.6067s
	iters: 200, epoch: 12 | loss: 3.7311389
	speed: 0.0766s/iter; left time: 1647.9154s
Epoch: 12 cost time: 19.30817723274231
Epoch: 12, Steps: 244 Train Loss: 3.6541 (Forecasting Loss:0.3354 + XiCon Loss:3.3187 x Lambda(1.0)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2873
Validation loss decreased (0.325991 --> 0.325984).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.7133765
	speed: 0.0799s/iter; left time: 1706.9305s
	iters: 200, epoch: 13 | loss: 3.6634693
	speed: 0.0740s/iter; left time: 1573.8339s
Epoch: 13 cost time: 18.86915159225464
Epoch: 13, Steps: 244 Train Loss: 3.6521 (Forecasting Loss:0.3352 + XiCon Loss:3.3168 x Lambda(1.0)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.2873
Validation loss decreased (0.325984 --> 0.325757).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5962329
	speed: 0.0828s/iter; left time: 1748.4302s
	iters: 200, epoch: 14 | loss: 3.6532688
	speed: 0.0770s/iter; left time: 1620.1299s
Epoch: 14 cost time: 19.473946809768677
Epoch: 14, Steps: 244 Train Loss: 3.6530 (Forecasting Loss:0.3353 + XiCon Loss:3.3177 x Lambda(1.0)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.2873
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6653342
	speed: 0.0787s/iter; left time: 1643.3334s
	iters: 200, epoch: 15 | loss: 3.6461666
	speed: 0.0801s/iter; left time: 1664.2821s
Epoch: 15 cost time: 19.074898719787598
Epoch: 15, Steps: 244 Train Loss: 3.6563 (Forecasting Loss:0.3352 + XiCon Loss:3.3211 x Lambda(1.0)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.2873
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6566825
	speed: 0.0817s/iter; left time: 1686.7841s
	iters: 200, epoch: 16 | loss: 3.6776366
	speed: 0.0765s/iter; left time: 1572.1758s
Epoch: 16 cost time: 19.29406976699829
Epoch: 16, Steps: 244 Train Loss: 3.6520 (Forecasting Loss:0.3356 + XiCon Loss:3.3165 x Lambda(1.0)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.2873
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6031284
	speed: 0.0792s/iter; left time: 1614.6036s
	iters: 200, epoch: 17 | loss: 3.6564744
	speed: 0.0631s/iter; left time: 1280.9322s
Epoch: 17 cost time: 17.535834550857544
Epoch: 17, Steps: 244 Train Loss: 3.6564 (Forecasting Loss:0.3353 + XiCon Loss:3.3211 x Lambda(1.0)), Vali MSE Loss: 0.3262 Test MSE Loss: 0.2873
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6795936
	speed: 0.0852s/iter; left time: 1716.7422s
	iters: 200, epoch: 18 | loss: 3.6941855
	speed: 0.0748s/iter; left time: 1499.7616s
Epoch: 18 cost time: 19.57140827178955
Epoch: 18, Steps: 244 Train Loss: 3.6513 (Forecasting Loss:0.3351 + XiCon Loss:3.3163 x Lambda(1.0)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2873
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6460118
	speed: 0.0833s/iter; left time: 1657.6325s
	iters: 200, epoch: 19 | loss: 3.6458876
	speed: 0.0798s/iter; left time: 1580.7855s
Epoch: 19 cost time: 19.664632320404053
Epoch: 19, Steps: 244 Train Loss: 3.6531 (Forecasting Loss:0.3355 + XiCon Loss:3.3176 x Lambda(1.0)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.2873
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.7129424
	speed: 0.0811s/iter; left time: 1594.2652s
	iters: 200, epoch: 20 | loss: 3.6115670
	speed: 0.0804s/iter; left time: 1573.1617s
Epoch: 20 cost time: 19.862755060195923
Epoch: 20, Steps: 244 Train Loss: 3.6526 (Forecasting Loss:0.3355 + XiCon Loss:3.3171 x Lambda(1.0)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.2873
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6207237
	speed: 0.0826s/iter; left time: 1605.1054s
	iters: 200, epoch: 21 | loss: 3.6685286
	speed: 0.0821s/iter; left time: 1585.6192s
Epoch: 21 cost time: 19.997347831726074
Epoch: 21, Steps: 244 Train Loss: 3.6519 (Forecasting Loss:0.3355 + XiCon Loss:3.3164 x Lambda(1.0)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2873
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.6848433
	speed: 0.0814s/iter; left time: 1561.4611s
	iters: 200, epoch: 22 | loss: 3.7049665
	speed: 0.0810s/iter; left time: 1544.3372s
Epoch: 22 cost time: 19.507171154022217
Epoch: 22, Steps: 244 Train Loss: 3.6566 (Forecasting Loss:0.3351 + XiCon Loss:3.3215 x Lambda(1.0)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.2873
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.6498258
	speed: 0.0829s/iter; left time: 1570.0476s
	iters: 200, epoch: 23 | loss: 3.6021104
	speed: 0.0826s/iter; left time: 1555.8898s
Epoch: 23 cost time: 20.08599829673767
Epoch: 23, Steps: 244 Train Loss: 3.6535 (Forecasting Loss:0.3357 + XiCon Loss:3.3178 x Lambda(1.0)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.2873
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2082972228527069, mae:0.36630603671073914, mape:0.6876775026321411, mspe:18.527896881103516 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.3355
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 4.0462275
	speed: 0.0758s/iter; left time: 1841.4541s
	iters: 200, epoch: 1 | loss: 3.9583750
	speed: 0.0727s/iter; left time: 1758.7933s
Epoch: 1 cost time: 18.35704779624939
Epoch: 1, Steps: 244 Train Loss: 4.0029 (Forecasting Loss:0.4645 + XiCon Loss:3.5384 x Lambda(1.0)), Vali MSE Loss: 0.4771 Test MSE Loss: 0.3826
Validation loss decreased (inf --> 0.477079).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6904848
	speed: 0.0771s/iter; left time: 1853.7801s
	iters: 200, epoch: 2 | loss: 3.6684885
	speed: 0.0765s/iter; left time: 1833.8057s
Epoch: 2 cost time: 18.581637382507324
Epoch: 2, Steps: 244 Train Loss: 3.7246 (Forecasting Loss:0.3749 + XiCon Loss:3.3497 x Lambda(1.0)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.3288
Validation loss decreased (0.477079 --> 0.363938).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6878428
	speed: 0.0794s/iter; left time: 1891.8574s
	iters: 200, epoch: 3 | loss: 3.7583344
	speed: 0.0758s/iter; left time: 1798.4356s
Epoch: 3 cost time: 18.956050395965576
Epoch: 3, Steps: 244 Train Loss: 3.6820 (Forecasting Loss:0.3514 + XiCon Loss:3.3306 x Lambda(1.0)), Vali MSE Loss: 0.3590 Test MSE Loss: 0.3129
Validation loss decreased (0.363938 --> 0.359008).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.8316143
	speed: 0.0798s/iter; left time: 1881.4862s
	iters: 200, epoch: 4 | loss: 3.8004301
	speed: 0.0809s/iter; left time: 1897.9609s
Epoch: 4 cost time: 19.432700395584106
Epoch: 4, Steps: 244 Train Loss: 3.7567 (Forecasting Loss:0.3430 + XiCon Loss:3.4137 x Lambda(1.0)), Vali MSE Loss: 0.3563 Test MSE Loss: 0.3196
Validation loss decreased (0.359008 --> 0.356341).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.7762208
	speed: 0.0759s/iter; left time: 1770.0648s
	iters: 200, epoch: 5 | loss: 3.7424033
	speed: 0.0808s/iter; left time: 1877.1317s
Epoch: 5 cost time: 19.123197555541992
Epoch: 5, Steps: 244 Train Loss: 3.7561 (Forecasting Loss:0.3395 + XiCon Loss:3.4165 x Lambda(1.0)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.3363
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.7326345
	speed: 0.0792s/iter; left time: 1828.8704s
	iters: 200, epoch: 6 | loss: 3.7486742
	speed: 0.0735s/iter; left time: 1689.5671s
Epoch: 6 cost time: 18.6361141204834
Epoch: 6, Steps: 244 Train Loss: 3.7570 (Forecasting Loss:0.3376 + XiCon Loss:3.4194 x Lambda(1.0)), Vali MSE Loss: 0.3564 Test MSE Loss: 0.3303
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.7646334
	speed: 0.0818s/iter; left time: 1868.2450s
	iters: 200, epoch: 7 | loss: 3.7800777
	speed: 0.0765s/iter; left time: 1739.0114s
Epoch: 7 cost time: 19.197269439697266
Epoch: 7, Steps: 244 Train Loss: 3.7514 (Forecasting Loss:0.3364 + XiCon Loss:3.4149 x Lambda(1.0)), Vali MSE Loss: 0.3562 Test MSE Loss: 0.3259
Validation loss decreased (0.356341 --> 0.356169).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.7763858
	speed: 0.0819s/iter; left time: 1849.2649s
	iters: 200, epoch: 8 | loss: 3.7601573
	speed: 0.0802s/iter; left time: 1804.9379s
Epoch: 8 cost time: 19.462039470672607
Epoch: 8, Steps: 244 Train Loss: 3.7560 (Forecasting Loss:0.3359 + XiCon Loss:3.4201 x Lambda(1.0)), Vali MSE Loss: 0.3560 Test MSE Loss: 0.3279
Validation loss decreased (0.356169 --> 0.356036).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.7556803
	speed: 0.0801s/iter; left time: 1790.0056s
	iters: 200, epoch: 9 | loss: 3.6623569
	speed: 0.0787s/iter; left time: 1750.0037s
Epoch: 9 cost time: 19.272297143936157
Epoch: 9, Steps: 244 Train Loss: 3.7491 (Forecasting Loss:0.3359 + XiCon Loss:3.4132 x Lambda(1.0)), Vali MSE Loss: 0.3558 Test MSE Loss: 0.3278
Validation loss decreased (0.356036 --> 0.355824).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.7513962
	speed: 0.0808s/iter; left time: 1786.2537s
	iters: 200, epoch: 10 | loss: 3.7536705
	speed: 0.0759s/iter; left time: 1670.4660s
Epoch: 10 cost time: 18.848538398742676
Epoch: 10, Steps: 244 Train Loss: 3.7454 (Forecasting Loss:0.3360 + XiCon Loss:3.4094 x Lambda(1.0)), Vali MSE Loss: 0.3558 Test MSE Loss: 0.3276
Validation loss decreased (0.355824 --> 0.355791).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.7745342
	speed: 0.0829s/iter; left time: 1811.9659s
	iters: 200, epoch: 11 | loss: 3.8942041
	speed: 0.0747s/iter; left time: 1625.3311s
Epoch: 11 cost time: 18.843428373336792
Epoch: 11, Steps: 244 Train Loss: 3.7503 (Forecasting Loss:0.3357 + XiCon Loss:3.4146 x Lambda(1.0)), Vali MSE Loss: 0.3551 Test MSE Loss: 0.3271
Validation loss decreased (0.355791 --> 0.355112).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.7527478
	speed: 0.0817s/iter; left time: 1765.4093s
	iters: 200, epoch: 12 | loss: 3.7155845
	speed: 0.0796s/iter; left time: 1712.7720s
Epoch: 12 cost time: 19.445279836654663
Epoch: 12, Steps: 244 Train Loss: 3.7522 (Forecasting Loss:0.3359 + XiCon Loss:3.4163 x Lambda(1.0)), Vali MSE Loss: 0.3557 Test MSE Loss: 0.3270
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.7587752
	speed: 0.0781s/iter; left time: 1669.2881s
	iters: 200, epoch: 13 | loss: 3.7279096
	speed: 0.0759s/iter; left time: 1613.6776s
Epoch: 13 cost time: 18.815176486968994
Epoch: 13, Steps: 244 Train Loss: 3.7532 (Forecasting Loss:0.3355 + XiCon Loss:3.4178 x Lambda(1.0)), Vali MSE Loss: 0.3551 Test MSE Loss: 0.3268
Validation loss decreased (0.355112 --> 0.355084).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.8677773
	speed: 0.0788s/iter; left time: 1664.5673s
	iters: 200, epoch: 14 | loss: 3.7279859
	speed: 0.0749s/iter; left time: 1574.9407s
Epoch: 14 cost time: 18.841173887252808
Epoch: 14, Steps: 244 Train Loss: 3.7496 (Forecasting Loss:0.3356 + XiCon Loss:3.4141 x Lambda(1.0)), Vali MSE Loss: 0.3555 Test MSE Loss: 0.3268
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.7696967
	speed: 0.0822s/iter; left time: 1716.6444s
	iters: 200, epoch: 15 | loss: 3.6788559
	speed: 0.0775s/iter; left time: 1611.0988s
Epoch: 15 cost time: 19.15441083908081
Epoch: 15, Steps: 244 Train Loss: 3.7553 (Forecasting Loss:0.3359 + XiCon Loss:3.4194 x Lambda(1.0)), Vali MSE Loss: 0.3554 Test MSE Loss: 0.3269
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.7399793
	speed: 0.0794s/iter; left time: 1637.9999s
	iters: 200, epoch: 16 | loss: 3.7726369
	speed: 0.0762s/iter; left time: 1565.6005s
Epoch: 16 cost time: 18.94199013710022
Epoch: 16, Steps: 244 Train Loss: 3.7478 (Forecasting Loss:0.3353 + XiCon Loss:3.4125 x Lambda(1.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.3269
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.8177888
	speed: 0.0772s/iter; left time: 1574.2615s
	iters: 200, epoch: 17 | loss: 3.6958144
	speed: 0.0763s/iter; left time: 1549.3638s
Epoch: 17 cost time: 18.886571168899536
Epoch: 17, Steps: 244 Train Loss: 3.7466 (Forecasting Loss:0.3357 + XiCon Loss:3.4109 x Lambda(1.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.3269
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.7613966
	speed: 0.0778s/iter; left time: 1568.8033s
	iters: 200, epoch: 18 | loss: 3.7261038
	speed: 0.0741s/iter; left time: 1485.8867s
Epoch: 18 cost time: 18.433619260787964
Epoch: 18, Steps: 244 Train Loss: 3.7555 (Forecasting Loss:0.3355 + XiCon Loss:3.4200 x Lambda(1.0)), Vali MSE Loss: 0.3557 Test MSE Loss: 0.3270
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.8051219
	speed: 0.0764s/iter; left time: 1521.9433s
	iters: 200, epoch: 19 | loss: 3.8345575
	speed: 0.0749s/iter; left time: 1483.3266s
Epoch: 19 cost time: 18.481565475463867
Epoch: 19, Steps: 244 Train Loss: 3.7465 (Forecasting Loss:0.3358 + XiCon Loss:3.4107 x Lambda(1.0)), Vali MSE Loss: 0.3554 Test MSE Loss: 0.3270
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.6571038
	speed: 0.0828s/iter; left time: 1627.5299s
	iters: 200, epoch: 20 | loss: 3.7196782
	speed: 0.0742s/iter; left time: 1452.1613s
Epoch: 20 cost time: 19.16861867904663
Epoch: 20, Steps: 244 Train Loss: 3.7474 (Forecasting Loss:0.3355 + XiCon Loss:3.4120 x Lambda(1.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.3270
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.8368163
	speed: 0.0779s/iter; left time: 1512.5352s
	iters: 200, epoch: 21 | loss: 3.6844964
	speed: 0.0761s/iter; left time: 1470.7115s
Epoch: 21 cost time: 18.656589031219482
Epoch: 21, Steps: 244 Train Loss: 3.7481 (Forecasting Loss:0.3355 + XiCon Loss:3.4126 x Lambda(1.0)), Vali MSE Loss: 0.3555 Test MSE Loss: 0.3270
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.7543344
	speed: 0.0783s/iter; left time: 1502.3635s
	iters: 200, epoch: 22 | loss: 3.7584810
	speed: 0.0755s/iter; left time: 1440.3141s
Epoch: 22 cost time: 18.902238607406616
Epoch: 22, Steps: 244 Train Loss: 3.7485 (Forecasting Loss:0.3357 + XiCon Loss:3.4129 x Lambda(1.0)), Vali MSE Loss: 0.3555 Test MSE Loss: 0.3270
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.8036299
	speed: 0.0805s/iter; left time: 1524.5299s
	iters: 200, epoch: 23 | loss: 3.7368250
	speed: 0.0748s/iter; left time: 1407.8884s
Epoch: 23 cost time: 18.693737268447876
Epoch: 23, Steps: 244 Train Loss: 3.7467 (Forecasting Loss:0.3355 + XiCon Loss:3.4112 x Lambda(1.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.3270
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2526792287826538, mae:0.4008901119232178, mape:0.6969566941261292, mspe:17.361963272094727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.9996
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 4.0001197
	speed: 0.0790s/iter; left time: 1919.4993s
	iters: 200, epoch: 1 | loss: 3.9702961
	speed: 0.0749s/iter; left time: 1811.7754s
Epoch: 1 cost time: 18.820131540298462
Epoch: 1, Steps: 244 Train Loss: 3.9866 (Forecasting Loss:0.4593 + XiCon Loss:3.5272 x Lambda(1.0)), Vali MSE Loss: 0.4651 Test MSE Loss: 0.3694
Validation loss decreased (inf --> 0.465089).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6884840
	speed: 0.0775s/iter; left time: 1863.6831s
	iters: 200, epoch: 2 | loss: 3.7843621
	speed: 0.0725s/iter; left time: 1737.9427s
Epoch: 2 cost time: 18.332777738571167
Epoch: 2, Steps: 244 Train Loss: 3.7457 (Forecasting Loss:0.3776 + XiCon Loss:3.3681 x Lambda(1.0)), Vali MSE Loss: 0.3643 Test MSE Loss: 0.3004
Validation loss decreased (0.465089 --> 0.364294).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6625109
	speed: 0.0774s/iter; left time: 1843.5269s
	iters: 200, epoch: 3 | loss: 3.7194803
	speed: 0.0760s/iter; left time: 1802.5935s
Epoch: 3 cost time: 18.56198477745056
Epoch: 3, Steps: 244 Train Loss: 3.7056 (Forecasting Loss:0.3473 + XiCon Loss:3.3583 x Lambda(1.0)), Vali MSE Loss: 0.3626 Test MSE Loss: 0.2902
Validation loss decreased (0.364294 --> 0.362618).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7262852
	speed: 0.0808s/iter; left time: 1903.8658s
	iters: 200, epoch: 4 | loss: 3.7009037
	speed: 0.0770s/iter; left time: 1806.4940s
Epoch: 4 cost time: 19.34863829612732
Epoch: 4, Steps: 244 Train Loss: 3.7038 (Forecasting Loss:0.3449 + XiCon Loss:3.3589 x Lambda(1.0)), Vali MSE Loss: 0.3558 Test MSE Loss: 0.2900
Validation loss decreased (0.362618 --> 0.355810).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6585548
	speed: 0.0784s/iter; left time: 1828.5930s
	iters: 200, epoch: 5 | loss: 3.6205540
	speed: 0.0778s/iter; left time: 1805.8292s
Epoch: 5 cost time: 19.058497667312622
Epoch: 5, Steps: 244 Train Loss: 3.6945 (Forecasting Loss:0.3435 + XiCon Loss:3.3510 x Lambda(1.0)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.2903
Validation loss decreased (0.355810 --> 0.353543).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6802099
	speed: 0.0795s/iter; left time: 1834.6840s
	iters: 200, epoch: 6 | loss: 3.7148919
	speed: 0.0756s/iter; left time: 1736.5555s
Epoch: 6 cost time: 18.774393796920776
Epoch: 6, Steps: 244 Train Loss: 3.6890 (Forecasting Loss:0.3429 + XiCon Loss:3.3460 x Lambda(1.0)), Vali MSE Loss: 0.3542 Test MSE Loss: 0.2901
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6980119
	speed: 0.0789s/iter; left time: 1801.7077s
	iters: 200, epoch: 7 | loss: 3.6866300
	speed: 0.0736s/iter; left time: 1674.2288s
Epoch: 7 cost time: 18.62769603729248
Epoch: 7, Steps: 244 Train Loss: 3.6842 (Forecasting Loss:0.3430 + XiCon Loss:3.3412 x Lambda(1.0)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.7173104
	speed: 0.0790s/iter; left time: 1784.8708s
	iters: 200, epoch: 8 | loss: 3.6630430
	speed: 0.0727s/iter; left time: 1634.9716s
Epoch: 8 cost time: 18.620373487472534
Epoch: 8, Steps: 244 Train Loss: 3.6874 (Forecasting Loss:0.3427 + XiCon Loss:3.3447 x Lambda(1.0)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.2905
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6505563
	speed: 0.0805s/iter; left time: 1798.9947s
	iters: 200, epoch: 9 | loss: 3.6963623
	speed: 0.0782s/iter; left time: 1739.6527s
Epoch: 9 cost time: 19.242729425430298
Epoch: 9, Steps: 244 Train Loss: 3.6815 (Forecasting Loss:0.3423 + XiCon Loss:3.3392 x Lambda(1.0)), Vali MSE Loss: 0.3533 Test MSE Loss: 0.2905
Validation loss decreased (0.353543 --> 0.353338).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6302431
	speed: 0.0781s/iter; left time: 1726.5614s
	iters: 200, epoch: 10 | loss: 3.6759410
	speed: 0.0755s/iter; left time: 1660.9429s
Epoch: 10 cost time: 18.7067551612854
Epoch: 10, Steps: 244 Train Loss: 3.6812 (Forecasting Loss:0.3423 + XiCon Loss:3.3389 x Lambda(1.0)), Vali MSE Loss: 0.3527 Test MSE Loss: 0.2905
Validation loss decreased (0.353338 --> 0.352656).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.7075038
	speed: 0.0788s/iter; left time: 1721.6552s
	iters: 200, epoch: 11 | loss: 3.6815200
	speed: 0.0768s/iter; left time: 1670.2907s
Epoch: 11 cost time: 18.657773971557617
Epoch: 11, Steps: 244 Train Loss: 3.6822 (Forecasting Loss:0.3424 + XiCon Loss:3.3399 x Lambda(1.0)), Vali MSE Loss: 0.3532 Test MSE Loss: 0.2904
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6328554
	speed: 0.0813s/iter; left time: 1757.1275s
	iters: 200, epoch: 12 | loss: 3.7132297
	speed: 0.0763s/iter; left time: 1641.7186s
Epoch: 12 cost time: 18.86677360534668
Epoch: 12, Steps: 244 Train Loss: 3.6825 (Forecasting Loss:0.3426 + XiCon Loss:3.3399 x Lambda(1.0)), Vali MSE Loss: 0.3529 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.7505655
	speed: 0.0786s/iter; left time: 1679.5257s
	iters: 200, epoch: 13 | loss: 3.7313447
	speed: 0.0757s/iter; left time: 1611.0990s
Epoch: 13 cost time: 18.984682083129883
Epoch: 13, Steps: 244 Train Loss: 3.6823 (Forecasting Loss:0.3424 + XiCon Loss:3.3399 x Lambda(1.0)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2904
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6935933
	speed: 0.0822s/iter; left time: 1737.8470s
	iters: 200, epoch: 14 | loss: 3.6597781
	speed: 0.0769s/iter; left time: 1617.1627s
Epoch: 14 cost time: 19.47047233581543
Epoch: 14, Steps: 244 Train Loss: 3.6801 (Forecasting Loss:0.3425 + XiCon Loss:3.3376 x Lambda(1.0)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2904
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6059535
	speed: 0.0782s/iter; left time: 1633.2547s
	iters: 200, epoch: 15 | loss: 3.6872675
	speed: 0.0783s/iter; left time: 1628.2603s
Epoch: 15 cost time: 19.04838490486145
Epoch: 15, Steps: 244 Train Loss: 3.6834 (Forecasting Loss:0.3423 + XiCon Loss:3.3411 x Lambda(1.0)), Vali MSE Loss: 0.3529 Test MSE Loss: 0.2904
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6414700
	speed: 0.0840s/iter; left time: 1734.1194s
	iters: 200, epoch: 16 | loss: 3.7359447
	speed: 0.0767s/iter; left time: 1576.4322s
Epoch: 16 cost time: 19.223119974136353
Epoch: 16, Steps: 244 Train Loss: 3.6828 (Forecasting Loss:0.3426 + XiCon Loss:3.3402 x Lambda(1.0)), Vali MSE Loss: 0.3526 Test MSE Loss: 0.2904
Validation loss decreased (0.352656 --> 0.352578).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.7042799
	speed: 0.0756s/iter; left time: 1541.8268s
	iters: 200, epoch: 17 | loss: 3.6536429
	speed: 0.0787s/iter; left time: 1596.7924s
Epoch: 17 cost time: 18.949172258377075
Epoch: 17, Steps: 244 Train Loss: 3.6796 (Forecasting Loss:0.3423 + XiCon Loss:3.3373 x Lambda(1.0)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.2904
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6777403
	speed: 0.0782s/iter; left time: 1576.0580s
	iters: 200, epoch: 18 | loss: 3.7040348
	speed: 0.0752s/iter; left time: 1507.3448s
Epoch: 18 cost time: 18.754968404769897
Epoch: 18, Steps: 244 Train Loss: 3.6837 (Forecasting Loss:0.3428 + XiCon Loss:3.3409 x Lambda(1.0)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6266532
	speed: 0.0779s/iter; left time: 1549.9680s
	iters: 200, epoch: 19 | loss: 3.6882653
	speed: 0.0780s/iter; left time: 1544.8161s
Epoch: 19 cost time: 18.78307795524597
Epoch: 19, Steps: 244 Train Loss: 3.6804 (Forecasting Loss:0.3425 + XiCon Loss:3.3379 x Lambda(1.0)), Vali MSE Loss: 0.3531 Test MSE Loss: 0.2904
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.6758263
	speed: 0.0794s/iter; left time: 1561.4677s
	iters: 200, epoch: 20 | loss: 3.6884401
	speed: 0.0770s/iter; left time: 1506.1236s
Epoch: 20 cost time: 18.91749620437622
Epoch: 20, Steps: 244 Train Loss: 3.6819 (Forecasting Loss:0.3423 + XiCon Loss:3.3396 x Lambda(1.0)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.2904
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6940584
	speed: 0.0766s/iter; left time: 1487.7827s
	iters: 200, epoch: 21 | loss: 3.6112089
	speed: 0.0799s/iter; left time: 1543.3590s
Epoch: 21 cost time: 19.072458267211914
Epoch: 21, Steps: 244 Train Loss: 3.6829 (Forecasting Loss:0.3422 + XiCon Loss:3.3407 x Lambda(1.0)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2904
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.7238586
	speed: 0.0786s/iter; left time: 1507.3797s
	iters: 200, epoch: 22 | loss: 3.6592078
	speed: 0.0743s/iter; left time: 1416.8180s
Epoch: 22 cost time: 18.757060766220093
Epoch: 22, Steps: 244 Train Loss: 3.6841 (Forecasting Loss:0.3424 + XiCon Loss:3.3417 x Lambda(1.0)), Vali MSE Loss: 0.3527 Test MSE Loss: 0.2904
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.6312425
	speed: 0.0788s/iter; left time: 1491.1034s
	iters: 200, epoch: 23 | loss: 3.6137943
	speed: 0.0763s/iter; left time: 1437.4927s
Epoch: 23 cost time: 18.783885717391968
Epoch: 23, Steps: 244 Train Loss: 3.6831 (Forecasting Loss:0.3424 + XiCon Loss:3.3407 x Lambda(1.0)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.2904
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.7036209
	speed: 0.0817s/iter; left time: 1526.1877s
	iters: 200, epoch: 24 | loss: 3.6896977
	speed: 0.0760s/iter; left time: 1412.7656s
Epoch: 24 cost time: 19.370702505111694
Epoch: 24, Steps: 244 Train Loss: 3.6830 (Forecasting Loss:0.3422 + XiCon Loss:3.3408 x Lambda(1.0)), Vali MSE Loss: 0.3527 Test MSE Loss: 0.2904
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.6688612
	speed: 0.0778s/iter; left time: 1434.5042s
	iters: 200, epoch: 25 | loss: 3.6595764
	speed: 0.0756s/iter; left time: 1386.5499s
Epoch: 25 cost time: 18.66382360458374
Epoch: 25, Steps: 244 Train Loss: 3.6843 (Forecasting Loss:0.3426 + XiCon Loss:3.3417 x Lambda(1.0)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.2904
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.7149427
	speed: 0.0780s/iter; left time: 1420.3656s
	iters: 200, epoch: 26 | loss: 3.6833184
	speed: 0.0759s/iter; left time: 1373.7954s
Epoch: 26 cost time: 18.93544602394104
Epoch: 26, Steps: 244 Train Loss: 3.6807 (Forecasting Loss:0.3423 + XiCon Loss:3.3384 x Lambda(1.0)), Vali MSE Loss: 0.3529 Test MSE Loss: 0.2904
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.21222126483917236, mae:0.3686457574367523, mape:0.6746864914894104, mspe:18.033716201782227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2293+-0.02742, MAE:0.3833+-0.02216, MAPE:0.6962+-0.04594, MSPE:18.2118+-3.67787, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.0095
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8722420
	speed: 0.1625s/iter; left time: 3769.3224s
	iters: 200, epoch: 1 | loss: 0.8973823
	speed: 0.1594s/iter; left time: 3682.5574s
Epoch: 1 cost time: 37.418501138687134
Epoch: 1, Steps: 233 Train Loss: 0.8993 (Forecasting Loss:0.5456 + XiCon Loss:3.5367 x Lambda(0.1)), Vali MSE Loss: 0.4977 Test MSE Loss: 0.3896
Validation loss decreased (inf --> 0.497673).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7331654
	speed: 0.1645s/iter; left time: 3779.0302s
	iters: 200, epoch: 2 | loss: 0.7202723
	speed: 0.1640s/iter; left time: 3751.0227s
Epoch: 2 cost time: 38.26597213745117
Epoch: 2, Steps: 233 Train Loss: 0.7449 (Forecasting Loss:0.3959 + XiCon Loss:3.4897 x Lambda(0.1)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3439
Validation loss decreased (0.497673 --> 0.377055).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7243112
	speed: 0.1702s/iter; left time: 3869.7872s
	iters: 200, epoch: 3 | loss: 0.7145497
	speed: 0.1684s/iter; left time: 3810.8986s
Epoch: 3 cost time: 39.487194538116455
Epoch: 3, Steps: 233 Train Loss: 0.7195 (Forecasting Loss:0.3755 + XiCon Loss:3.4406 x Lambda(0.1)), Vali MSE Loss: 0.3775 Test MSE Loss: 0.3370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.7017846
	speed: 0.1675s/iter; left time: 3768.6576s
	iters: 200, epoch: 4 | loss: 0.6925154
	speed: 0.1674s/iter; left time: 3751.1084s
Epoch: 4 cost time: 38.81545877456665
Epoch: 4, Steps: 233 Train Loss: 0.7108 (Forecasting Loss:0.3689 + XiCon Loss:3.4198 x Lambda(0.1)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3244
Validation loss decreased (0.377055 --> 0.374729).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.7195566
	speed: 0.1681s/iter; left time: 3743.4107s
	iters: 200, epoch: 5 | loss: 0.7092488
	speed: 0.1616s/iter; left time: 3581.6723s
Epoch: 5 cost time: 38.67236804962158
Epoch: 5, Steps: 233 Train Loss: 0.7062 (Forecasting Loss:0.3654 + XiCon Loss:3.4081 x Lambda(0.1)), Vali MSE Loss: 0.3713 Test MSE Loss: 0.3195
Validation loss decreased (0.374729 --> 0.371348).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.7034724
	speed: 0.1690s/iter; left time: 3723.5198s
	iters: 200, epoch: 6 | loss: 0.7109705
	speed: 0.1689s/iter; left time: 3705.6398s
Epoch: 6 cost time: 38.9680335521698
Epoch: 6, Steps: 233 Train Loss: 0.7034 (Forecasting Loss:0.3631 + XiCon Loss:3.4029 x Lambda(0.1)), Vali MSE Loss: 0.3736 Test MSE Loss: 0.3225
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.7052994
	speed: 0.1666s/iter; left time: 3631.4140s
	iters: 200, epoch: 7 | loss: 0.7165632
	speed: 0.1601s/iter; left time: 3473.7744s
Epoch: 7 cost time: 38.01143479347229
Epoch: 7, Steps: 233 Train Loss: 0.7019 (Forecasting Loss:0.3619 + XiCon Loss:3.3993 x Lambda(0.1)), Vali MSE Loss: 0.3709 Test MSE Loss: 0.3210
Validation loss decreased (0.371348 --> 0.370890).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6888722
	speed: 0.1707s/iter; left time: 3681.4853s
	iters: 200, epoch: 8 | loss: 0.6832213
	speed: 0.1633s/iter; left time: 3506.7328s
Epoch: 8 cost time: 38.82689309120178
Epoch: 8, Steps: 233 Train Loss: 0.7013 (Forecasting Loss:0.3615 + XiCon Loss:3.3985 x Lambda(0.1)), Vali MSE Loss: 0.3702 Test MSE Loss: 0.3213
Validation loss decreased (0.370890 --> 0.370174).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6890333
	speed: 0.1634s/iter; left time: 3486.4916s
	iters: 200, epoch: 9 | loss: 0.7012756
	speed: 0.1590s/iter; left time: 3375.7996s
Epoch: 9 cost time: 38.28114128112793
Epoch: 9, Steps: 233 Train Loss: 0.7007 (Forecasting Loss:0.3611 + XiCon Loss:3.3965 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
Validation loss decreased (0.370174 --> 0.368108).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.7155025
	speed: 0.1671s/iter; left time: 3527.1759s
	iters: 200, epoch: 10 | loss: 0.7088622
	speed: 0.1709s/iter; left time: 3590.1817s
Epoch: 10 cost time: 39.51563835144043
Epoch: 10, Steps: 233 Train Loss: 0.7005 (Forecasting Loss:0.3608 + XiCon Loss:3.3969 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3208
Validation loss decreased (0.368108 --> 0.368092).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.7013245
	speed: 0.1685s/iter; left time: 3517.1619s
	iters: 200, epoch: 11 | loss: 0.6878775
	speed: 0.1616s/iter; left time: 3357.2437s
Epoch: 11 cost time: 38.2850079536438
Epoch: 11, Steps: 233 Train Loss: 0.7004 (Forecasting Loss:0.3608 + XiCon Loss:3.3965 x Lambda(0.1)), Vali MSE Loss: 0.3679 Test MSE Loss: 0.3207
Validation loss decreased (0.368092 --> 0.367933).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.7061230
	speed: 0.1643s/iter; left time: 3390.2219s
	iters: 200, epoch: 12 | loss: 0.6895062
	speed: 0.1670s/iter; left time: 3430.5911s
Epoch: 12 cost time: 38.508233308792114
Epoch: 12, Steps: 233 Train Loss: 0.7002 (Forecasting Loss:0.3607 + XiCon Loss:3.3958 x Lambda(0.1)), Vali MSE Loss: 0.3680 Test MSE Loss: 0.3207
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6664608
	speed: 0.1678s/iter; left time: 3424.4310s
	iters: 200, epoch: 13 | loss: 0.7015334
	speed: 0.1632s/iter; left time: 3314.6813s
Epoch: 13 cost time: 38.272316455841064
Epoch: 13, Steps: 233 Train Loss: 0.7003 (Forecasting Loss:0.3608 + XiCon Loss:3.3953 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3207
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.7080413
	speed: 0.1676s/iter; left time: 3380.1652s
	iters: 200, epoch: 14 | loss: 0.6935160
	speed: 0.1681s/iter; left time: 3373.5644s
Epoch: 14 cost time: 39.411508083343506
Epoch: 14, Steps: 233 Train Loss: 0.7005 (Forecasting Loss:0.3609 + XiCon Loss:3.3959 x Lambda(0.1)), Vali MSE Loss: 0.3680 Test MSE Loss: 0.3207
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.7063359
	speed: 0.1623s/iter; left time: 3236.4856s
	iters: 200, epoch: 15 | loss: 0.6959499
	speed: 0.1498s/iter; left time: 2972.5808s
Epoch: 15 cost time: 36.61151075363159
Epoch: 15, Steps: 233 Train Loss: 0.7004 (Forecasting Loss:0.3609 + XiCon Loss:3.3957 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.7061058
	speed: 0.1640s/iter; left time: 3231.8550s
	iters: 200, epoch: 16 | loss: 0.6947696
	speed: 0.1597s/iter; left time: 3131.2500s
Epoch: 16 cost time: 37.851890087127686
Epoch: 16, Steps: 233 Train Loss: 0.7005 (Forecasting Loss:0.3609 + XiCon Loss:3.3959 x Lambda(0.1)), Vali MSE Loss: 0.3680 Test MSE Loss: 0.3207
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.7181699
	speed: 0.1662s/iter; left time: 3236.4455s
	iters: 200, epoch: 17 | loss: 0.7260998
	speed: 0.1635s/iter; left time: 3167.1020s
Epoch: 17 cost time: 38.45454216003418
Epoch: 17, Steps: 233 Train Loss: 0.7003 (Forecasting Loss:0.3607 + XiCon Loss:3.3965 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6929153
	speed: 0.1654s/iter; left time: 3182.0256s
	iters: 200, epoch: 18 | loss: 0.6881059
	speed: 0.1609s/iter; left time: 3079.3950s
Epoch: 18 cost time: 37.85723304748535
Epoch: 18, Steps: 233 Train Loss: 0.7003 (Forecasting Loss:0.3607 + XiCon Loss:3.3960 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.7192206
	speed: 0.1667s/iter; left time: 3167.6756s
	iters: 200, epoch: 19 | loss: 0.7032235
	speed: 0.1797s/iter; left time: 3397.7433s
Epoch: 19 cost time: 40.6833291053772
Epoch: 19, Steps: 233 Train Loss: 0.7003 (Forecasting Loss:0.3607 + XiCon Loss:3.3962 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.7030063
	speed: 0.1725s/iter; left time: 3239.0594s
	iters: 200, epoch: 20 | loss: 0.7019109
	speed: 0.1742s/iter; left time: 3253.6053s
Epoch: 20 cost time: 40.66811156272888
Epoch: 20, Steps: 233 Train Loss: 0.7004 (Forecasting Loss:0.3608 + XiCon Loss:3.3957 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6956329
	speed: 0.1735s/iter; left time: 3217.3247s
	iters: 200, epoch: 21 | loss: 0.6803203
	speed: 0.1811s/iter; left time: 3339.6154s
Epoch: 21 cost time: 41.55223989486694
Epoch: 21, Steps: 233 Train Loss: 0.7004 (Forecasting Loss:0.3608 + XiCon Loss:3.3957 x Lambda(0.1)), Vali MSE Loss: 0.3681 Test MSE Loss: 0.3207
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.25060543417930603, mae:0.39079657196998596, mape:0.6844218373298645, mspe:18.960763931274414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.1834
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.9215720
	speed: 0.1656s/iter; left time: 3843.1208s
	iters: 200, epoch: 1 | loss: 0.8589337
	speed: 0.1608s/iter; left time: 3715.7786s
Epoch: 1 cost time: 38.07165598869324
Epoch: 1, Steps: 233 Train Loss: 0.9043 (Forecasting Loss:0.5509 + XiCon Loss:3.5343 x Lambda(0.1)), Vali MSE Loss: 0.5003 Test MSE Loss: 0.4025
Validation loss decreased (inf --> 0.500261).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7541325
	speed: 0.1706s/iter; left time: 3918.4994s
	iters: 200, epoch: 2 | loss: 0.7135329
	speed: 0.1708s/iter; left time: 3906.1671s
Epoch: 2 cost time: 39.92335820198059
Epoch: 2, Steps: 233 Train Loss: 0.7447 (Forecasting Loss:0.4015 + XiCon Loss:3.4326 x Lambda(0.1)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3166
Validation loss decreased (0.500261 --> 0.370418).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7034152
	speed: 0.1733s/iter; left time: 3941.0686s
	iters: 200, epoch: 3 | loss: 0.6913207
	speed: 0.1723s/iter; left time: 3900.2283s
Epoch: 3 cost time: 40.11003851890564
Epoch: 3, Steps: 233 Train Loss: 0.6984 (Forecasting Loss:0.3620 + XiCon Loss:3.3637 x Lambda(0.1)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.3064
Validation loss decreased (0.370418 --> 0.347571).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6851982
	speed: 0.1716s/iter; left time: 3861.7494s
	iters: 200, epoch: 4 | loss: 0.6721235
	speed: 0.1714s/iter; left time: 3838.9052s
Epoch: 4 cost time: 40.325403451919556
Epoch: 4, Steps: 233 Train Loss: 0.6794 (Forecasting Loss:0.3387 + XiCon Loss:3.4070 x Lambda(0.1)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.3161
Validation loss decreased (0.347571 --> 0.323124).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6819473
	speed: 0.1737s/iter; left time: 3867.6977s
	iters: 200, epoch: 5 | loss: 0.6979631
	speed: 0.1717s/iter; left time: 3806.4737s
Epoch: 5 cost time: 40.16410255432129
Epoch: 5, Steps: 233 Train Loss: 0.6742 (Forecasting Loss:0.3326 + XiCon Loss:3.4160 x Lambda(0.1)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.3327
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6627060
	speed: 0.1772s/iter; left time: 3905.6668s
	iters: 200, epoch: 6 | loss: 0.6805215
	speed: 0.1656s/iter; left time: 3631.5637s
Epoch: 6 cost time: 39.8302366733551
Epoch: 6, Steps: 233 Train Loss: 0.6723 (Forecasting Loss:0.3305 + XiCon Loss:3.4175 x Lambda(0.1)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.3161
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6690760
	speed: 0.1720s/iter; left time: 3750.9273s
	iters: 200, epoch: 7 | loss: 0.6801510
	speed: 0.1722s/iter; left time: 3738.0627s
Epoch: 7 cost time: 40.17628622055054
Epoch: 7, Steps: 233 Train Loss: 0.6713 (Forecasting Loss:0.3294 + XiCon Loss:3.4189 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.3187
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6691934
	speed: 0.1770s/iter; left time: 3817.6107s
	iters: 200, epoch: 8 | loss: 0.6687349
	speed: 0.1726s/iter; left time: 3706.5996s
Epoch: 8 cost time: 40.85056185722351
Epoch: 8, Steps: 233 Train Loss: 0.6707 (Forecasting Loss:0.3288 + XiCon Loss:3.4197 x Lambda(0.1)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.3180
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6726974
	speed: 0.1744s/iter; left time: 3721.8504s
	iters: 200, epoch: 9 | loss: 0.6650254
	speed: 0.1671s/iter; left time: 3548.9414s
Epoch: 9 cost time: 39.72626852989197
Epoch: 9, Steps: 233 Train Loss: 0.6707 (Forecasting Loss:0.3288 + XiCon Loss:3.4196 x Lambda(0.1)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.3186
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6674612
	speed: 0.1776s/iter; left time: 3747.7510s
	iters: 200, epoch: 10 | loss: 0.6492813
	speed: 0.1696s/iter; left time: 3562.0441s
Epoch: 10 cost time: 40.42301797866821
Epoch: 10, Steps: 233 Train Loss: 0.6707 (Forecasting Loss:0.3288 + XiCon Loss:3.4186 x Lambda(0.1)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3161
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6546701
	speed: 0.1743s/iter; left time: 3636.8992s
	iters: 200, epoch: 11 | loss: 0.6727501
	speed: 0.1728s/iter; left time: 3589.6252s
Epoch: 11 cost time: 40.10667014122009
Epoch: 11, Steps: 233 Train Loss: 0.6706 (Forecasting Loss:0.3287 + XiCon Loss:3.4198 x Lambda(0.1)), Vali MSE Loss: 0.3274 Test MSE Loss: 0.3178
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6819295
	speed: 0.1734s/iter; left time: 3578.1868s
	iters: 200, epoch: 12 | loss: 0.6921265
	speed: 0.1747s/iter; left time: 3587.0543s
Epoch: 12 cost time: 40.667500257492065
Epoch: 12, Steps: 233 Train Loss: 0.6707 (Forecasting Loss:0.3288 + XiCon Loss:3.4193 x Lambda(0.1)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3175
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6815850
	speed: 0.1745s/iter; left time: 3559.7648s
	iters: 200, epoch: 13 | loss: 0.6851256
	speed: 0.1713s/iter; left time: 3477.3759s
Epoch: 13 cost time: 40.311686754226685
Epoch: 13, Steps: 233 Train Loss: 0.6709 (Forecasting Loss:0.3289 + XiCon Loss:3.4203 x Lambda(0.1)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.3172
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6768098
	speed: 0.1666s/iter; left time: 3360.2454s
	iters: 200, epoch: 14 | loss: 0.6676767
	speed: 0.1741s/iter; left time: 3495.2043s
Epoch: 14 cost time: 39.77042078971863
Epoch: 14, Steps: 233 Train Loss: 0.6704 (Forecasting Loss:0.3285 + XiCon Loss:3.4187 x Lambda(0.1)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.3173
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2375059276819229, mae:0.3946078419685364, mape:0.6251474022865295, mspe:13.616122245788574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.4976
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8802451
	speed: 0.1663s/iter; left time: 3858.4028s
	iters: 200, epoch: 1 | loss: 0.9181206
	speed: 0.1649s/iter; left time: 3808.4327s
Epoch: 1 cost time: 38.96174168586731
Epoch: 1, Steps: 233 Train Loss: 0.9081 (Forecasting Loss:0.5542 + XiCon Loss:3.5387 x Lambda(0.1)), Vali MSE Loss: 0.5435 Test MSE Loss: 0.4562
Validation loss decreased (inf --> 0.543535).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6968962
	speed: 0.1812s/iter; left time: 4162.7706s
	iters: 200, epoch: 2 | loss: 0.6739246
	speed: 0.1760s/iter; left time: 4025.2780s
Epoch: 2 cost time: 41.628464221954346
Epoch: 2, Steps: 233 Train Loss: 0.7407 (Forecasting Loss:0.3985 + XiCon Loss:3.4216 x Lambda(0.1)), Vali MSE Loss: 0.3731 Test MSE Loss: 0.3148
Validation loss decreased (0.543535 --> 0.373068).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7289248
	speed: 0.1784s/iter; left time: 4055.3450s
	iters: 200, epoch: 3 | loss: 0.6701111
	speed: 0.1732s/iter; left time: 3921.4715s
Epoch: 3 cost time: 40.62524914741516
Epoch: 3, Steps: 233 Train Loss: 0.6789 (Forecasting Loss:0.3355 + XiCon Loss:3.4332 x Lambda(0.1)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2965
Validation loss decreased (0.373068 --> 0.311513).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6662806
	speed: 0.1749s/iter; left time: 3935.8237s
	iters: 200, epoch: 4 | loss: 0.6607022
	speed: 0.1744s/iter; left time: 3907.3339s
Epoch: 4 cost time: 40.86990833282471
Epoch: 4, Steps: 233 Train Loss: 0.6736 (Forecasting Loss:0.3304 + XiCon Loss:3.4310 x Lambda(0.1)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2981
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6697434
	speed: 0.1755s/iter; left time: 3908.5745s
	iters: 200, epoch: 5 | loss: 0.6421503
	speed: 0.1755s/iter; left time: 3890.7926s
Epoch: 5 cost time: 40.77080798149109
Epoch: 5, Steps: 233 Train Loss: 0.6705 (Forecasting Loss:0.3283 + XiCon Loss:3.4221 x Lambda(0.1)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.2959
Validation loss decreased (0.311513 --> 0.308603).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6768790
	speed: 0.1800s/iter; left time: 3967.3573s
	iters: 200, epoch: 6 | loss: 0.6651608
	speed: 0.1762s/iter; left time: 3866.0263s
Epoch: 6 cost time: 41.133078813552856
Epoch: 6, Steps: 233 Train Loss: 0.6693 (Forecasting Loss:0.3276 + XiCon Loss:3.4176 x Lambda(0.1)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.2955
Validation loss decreased (0.308603 --> 0.306526).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6682975
	speed: 0.1766s/iter; left time: 3850.9013s
	iters: 200, epoch: 7 | loss: 0.6886774
	speed: 0.1662s/iter; left time: 3606.9085s
Epoch: 7 cost time: 40.063770055770874
Epoch: 7, Steps: 233 Train Loss: 0.6681 (Forecasting Loss:0.3267 + XiCon Loss:3.4147 x Lambda(0.1)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.2922
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6676301
	speed: 0.1666s/iter; left time: 3592.7708s
	iters: 200, epoch: 8 | loss: 0.6567707
	speed: 0.1719s/iter; left time: 3690.9717s
Epoch: 8 cost time: 39.1307692527771
Epoch: 8, Steps: 233 Train Loss: 0.6678 (Forecasting Loss:0.3265 + XiCon Loss:3.4136 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2944
Validation loss decreased (0.306526 --> 0.305961).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6997503
	speed: 0.1764s/iter; left time: 3762.9475s
	iters: 200, epoch: 9 | loss: 0.6849310
	speed: 0.1716s/iter; left time: 3643.7707s
Epoch: 9 cost time: 40.35199189186096
Epoch: 9, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3261 + XiCon Loss:3.4162 x Lambda(0.1)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.2946
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6768212
	speed: 0.1750s/iter; left time: 3694.0469s
	iters: 200, epoch: 10 | loss: 0.6665556
	speed: 0.1723s/iter; left time: 3619.1929s
Epoch: 10 cost time: 40.45599699020386
Epoch: 10, Steps: 233 Train Loss: 0.6676 (Forecasting Loss:0.3263 + XiCon Loss:3.4130 x Lambda(0.1)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2952
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6580507
	speed: 0.1756s/iter; left time: 3665.8848s
	iters: 200, epoch: 11 | loss: 0.6525061
	speed: 0.1738s/iter; left time: 3610.3564s
Epoch: 11 cost time: 40.764711141586304
Epoch: 11, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3265 + XiCon Loss:3.4123 x Lambda(0.1)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.2949
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6875910
	speed: 0.1810s/iter; left time: 3734.7045s
	iters: 200, epoch: 12 | loss: 0.6560045
	speed: 0.1689s/iter; left time: 3469.7757s
Epoch: 12 cost time: 41.10873818397522
Epoch: 12, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3263 + XiCon Loss:3.4136 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6676028
	speed: 0.1754s/iter; left time: 3578.0458s
	iters: 200, epoch: 13 | loss: 0.6765861
	speed: 0.1774s/iter; left time: 3602.8131s
Epoch: 13 cost time: 41.212031841278076
Epoch: 13, Steps: 233 Train Loss: 0.6676 (Forecasting Loss:0.3261 + XiCon Loss:3.4145 x Lambda(0.1)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.2950
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6792940
	speed: 0.1730s/iter; left time: 3489.1543s
	iters: 200, epoch: 14 | loss: 0.6632202
	speed: 0.1787s/iter; left time: 3586.2199s
Epoch: 14 cost time: 41.10798001289368
Epoch: 14, Steps: 233 Train Loss: 0.6675 (Forecasting Loss:0.3258 + XiCon Loss:3.4165 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2951
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6482007
	speed: 0.1723s/iter; left time: 3435.3011s
	iters: 200, epoch: 15 | loss: 0.6804588
	speed: 0.1697s/iter; left time: 3366.5166s
Epoch: 15 cost time: 39.65687704086304
Epoch: 15, Steps: 233 Train Loss: 0.6676 (Forecasting Loss:0.3264 + XiCon Loss:3.4120 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6607182
	speed: 0.1724s/iter; left time: 3398.2495s
	iters: 200, epoch: 16 | loss: 0.6633435
	speed: 0.1797s/iter; left time: 3523.4099s
Epoch: 16 cost time: 40.745830059051514
Epoch: 16, Steps: 233 Train Loss: 0.6678 (Forecasting Loss:0.3263 + XiCon Loss:3.4158 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6704904
	speed: 0.1793s/iter; left time: 3491.7502s
	iters: 200, epoch: 17 | loss: 0.6823621
	speed: 0.1747s/iter; left time: 3384.7952s
Epoch: 17 cost time: 40.69058179855347
Epoch: 17, Steps: 233 Train Loss: 0.6673 (Forecasting Loss:0.3260 + XiCon Loss:3.4136 x Lambda(0.1)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.2950
Validation loss decreased (0.305961 --> 0.305941).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6705602
	speed: 0.1744s/iter; left time: 3356.0526s
	iters: 200, epoch: 18 | loss: 0.6833202
	speed: 0.1777s/iter; left time: 3401.8916s
Epoch: 18 cost time: 41.23057413101196
Epoch: 18, Steps: 233 Train Loss: 0.6676 (Forecasting Loss:0.3264 + XiCon Loss:3.4129 x Lambda(0.1)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.2950
Validation loss decreased (0.305941 --> 0.305926).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.6730106
	speed: 0.1717s/iter; left time: 3263.0729s
	iters: 200, epoch: 19 | loss: 0.6525658
	speed: 0.1715s/iter; left time: 3243.3470s
Epoch: 19 cost time: 40.282217502593994
Epoch: 19, Steps: 233 Train Loss: 0.6678 (Forecasting Loss:0.3262 + XiCon Loss:3.4152 x Lambda(0.1)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.2950
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.6799760
	speed: 0.1755s/iter; left time: 3294.4468s
	iters: 200, epoch: 20 | loss: 0.6683426
	speed: 0.1772s/iter; left time: 3308.5038s
Epoch: 20 cost time: 40.97774338722229
Epoch: 20, Steps: 233 Train Loss: 0.6675 (Forecasting Loss:0.3261 + XiCon Loss:3.4142 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6588343
	speed: 0.1762s/iter; left time: 3266.7617s
	iters: 200, epoch: 21 | loss: 0.6829394
	speed: 0.1674s/iter; left time: 3087.4381s
Epoch: 21 cost time: 40.3056845664978
Epoch: 21, Steps: 233 Train Loss: 0.6672 (Forecasting Loss:0.3260 + XiCon Loss:3.4118 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 0.6674820
	speed: 0.1747s/iter; left time: 3198.6194s
	iters: 200, epoch: 22 | loss: 0.6588705
	speed: 0.1791s/iter; left time: 3260.6581s
Epoch: 22 cost time: 41.26028227806091
Epoch: 22, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3264 + XiCon Loss:3.4137 x Lambda(0.1)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2950
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 0.6759527
	speed: 0.1784s/iter; left time: 3225.2500s
	iters: 200, epoch: 23 | loss: 0.6653908
	speed: 0.1780s/iter; left time: 3199.2964s
Epoch: 23 cost time: 41.39045238494873
Epoch: 23, Steps: 233 Train Loss: 0.6678 (Forecasting Loss:0.3264 + XiCon Loss:3.4145 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 0.6917312
	speed: 0.1711s/iter; left time: 3053.3958s
	iters: 200, epoch: 24 | loss: 0.6834260
	speed: 0.1732s/iter; left time: 3072.7768s
Epoch: 24 cost time: 40.76771283149719
Epoch: 24, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3263 + XiCon Loss:3.4140 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 0.6767682
	speed: 0.1753s/iter; left time: 3086.3209s
	iters: 200, epoch: 25 | loss: 0.6639588
	speed: 0.1782s/iter; left time: 3119.9171s
Epoch: 25 cost time: 41.21756649017334
Epoch: 25, Steps: 233 Train Loss: 0.6674 (Forecasting Loss:0.3260 + XiCon Loss:3.4145 x Lambda(0.1)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.2950
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 0.6915398
	speed: 0.1748s/iter; left time: 3037.4430s
	iters: 200, epoch: 26 | loss: 0.6610172
	speed: 0.1712s/iter; left time: 2958.1742s
Epoch: 26 cost time: 40.490163803100586
Epoch: 26, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3263 + XiCon Loss:3.4136 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 0.6813967
	speed: 0.1733s/iter; left time: 2971.6245s
	iters: 200, epoch: 27 | loss: 0.6934949
	speed: 0.1685s/iter; left time: 2872.4411s
Epoch: 27 cost time: 40.137799978256226
Epoch: 27, Steps: 233 Train Loss: 0.6680 (Forecasting Loss:0.3263 + XiCon Loss:3.4168 x Lambda(0.1)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2950
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 0.6718256
	speed: 0.1806s/iter; left time: 3054.0787s
	iters: 200, epoch: 28 | loss: 0.6497707
	speed: 0.1781s/iter; left time: 2993.0908s
Epoch: 28 cost time: 41.60184574127197
Epoch: 28, Steps: 233 Train Loss: 0.6677 (Forecasting Loss:0.3266 + XiCon Loss:3.4117 x Lambda(0.1)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.2950
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21501965820789337, mae:0.3750433325767517, mape:0.628031849861145, mspe:14.590531349182129 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.6577
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8546895
	speed: 0.1672s/iter; left time: 3878.1533s
	iters: 200, epoch: 1 | loss: 0.8668135
	speed: 0.1635s/iter; left time: 3776.7139s
Epoch: 1 cost time: 38.85610342025757
Epoch: 1, Steps: 233 Train Loss: 0.9049 (Forecasting Loss:0.5506 + XiCon Loss:3.5422 x Lambda(0.1)), Vali MSE Loss: 0.5321 Test MSE Loss: 0.4415
Validation loss decreased (inf --> 0.532073).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6785505
	speed: 0.1758s/iter; left time: 4037.9245s
	iters: 200, epoch: 2 | loss: 0.6733868
	speed: 0.1919s/iter; left time: 4388.5608s
Epoch: 2 cost time: 43.605013370513916
Epoch: 2, Steps: 233 Train Loss: 0.7301 (Forecasting Loss:0.3843 + XiCon Loss:3.4588 x Lambda(0.1)), Vali MSE Loss: 0.3489 Test MSE Loss: 0.2894
Validation loss decreased (0.532073 --> 0.348901).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6683912
	speed: 0.2192s/iter; left time: 4983.4270s
	iters: 200, epoch: 3 | loss: 0.6820318
	speed: 0.2247s/iter; left time: 5085.1939s
Epoch: 3 cost time: 51.17908477783203
Epoch: 3, Steps: 233 Train Loss: 0.6694 (Forecasting Loss:0.3234 + XiCon Loss:3.4598 x Lambda(0.1)), Vali MSE Loss: 0.3856 Test MSE Loss: 0.2874
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6608557
	speed: 0.2328s/iter; left time: 5238.8773s
	iters: 200, epoch: 4 | loss: 0.6662683
	speed: 0.2412s/iter; left time: 5403.3392s
Epoch: 4 cost time: 55.54973125457764
Epoch: 4, Steps: 233 Train Loss: 0.6621 (Forecasting Loss:0.3165 + XiCon Loss:3.4560 x Lambda(0.1)), Vali MSE Loss: 0.4185 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6466589
	speed: 0.2503s/iter; left time: 5573.4130s
	iters: 200, epoch: 5 | loss: 0.6515930
	speed: 0.2445s/iter; left time: 5419.4779s
Epoch: 5 cost time: 57.6879301071167
Epoch: 5, Steps: 233 Train Loss: 0.6593 (Forecasting Loss:0.3139 + XiCon Loss:3.4540 x Lambda(0.1)), Vali MSE Loss: 0.3882 Test MSE Loss: 0.2922
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6700581
	speed: 0.2528s/iter; left time: 5570.5248s
	iters: 200, epoch: 6 | loss: 0.6445771
	speed: 0.2491s/iter; left time: 5464.8872s
Epoch: 6 cost time: 58.583783864974976
Epoch: 6, Steps: 233 Train Loss: 0.6578 (Forecasting Loss:0.3127 + XiCon Loss:3.4510 x Lambda(0.1)), Vali MSE Loss: 0.3936 Test MSE Loss: 0.2930
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6856067
	speed: 0.2461s/iter; left time: 5365.6678s
	iters: 200, epoch: 7 | loss: 0.6276531
	speed: 0.2524s/iter; left time: 5477.6581s
Epoch: 7 cost time: 58.133591651916504
Epoch: 7, Steps: 233 Train Loss: 0.6570 (Forecasting Loss:0.3121 + XiCon Loss:3.4493 x Lambda(0.1)), Vali MSE Loss: 0.3818 Test MSE Loss: 0.2907
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6537087
	speed: 0.2461s/iter; left time: 5307.4349s
	iters: 200, epoch: 8 | loss: 0.6415024
	speed: 0.2425s/iter; left time: 5205.5802s
Epoch: 8 cost time: 57.02459692955017
Epoch: 8, Steps: 233 Train Loss: 0.6568 (Forecasting Loss:0.3118 + XiCon Loss:3.4501 x Lambda(0.1)), Vali MSE Loss: 0.3826 Test MSE Loss: 0.2906
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6418338
	speed: 0.2395s/iter; left time: 5109.4999s
	iters: 200, epoch: 9 | loss: 0.6679626
	speed: 0.2472s/iter; left time: 5248.8238s
Epoch: 9 cost time: 57.284284591674805
Epoch: 9, Steps: 233 Train Loss: 0.6565 (Forecasting Loss:0.3115 + XiCon Loss:3.4503 x Lambda(0.1)), Vali MSE Loss: 0.3830 Test MSE Loss: 0.2914
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6596226
	speed: 0.2495s/iter; left time: 5264.4557s
	iters: 200, epoch: 10 | loss: 0.6609713
	speed: 0.2471s/iter; left time: 5190.5852s
Epoch: 10 cost time: 58.05151414871216
Epoch: 10, Steps: 233 Train Loss: 0.6561 (Forecasting Loss:0.3113 + XiCon Loss:3.4481 x Lambda(0.1)), Vali MSE Loss: 0.3840 Test MSE Loss: 0.2912
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6516933
	speed: 0.2463s/iter; left time: 5140.5264s
	iters: 200, epoch: 11 | loss: 0.6661515
	speed: 0.2458s/iter; left time: 5105.1668s
Epoch: 11 cost time: 57.436410665512085
Epoch: 11, Steps: 233 Train Loss: 0.6563 (Forecasting Loss:0.3114 + XiCon Loss:3.4487 x Lambda(0.1)), Vali MSE Loss: 0.3844 Test MSE Loss: 0.2913
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6513948
	speed: 0.2509s/iter; left time: 5177.3791s
	iters: 200, epoch: 12 | loss: 0.6499275
	speed: 0.2460s/iter; left time: 5051.9729s
Epoch: 12 cost time: 58.21759819984436
Epoch: 12, Steps: 233 Train Loss: 0.6560 (Forecasting Loss:0.3113 + XiCon Loss:3.4474 x Lambda(0.1)), Vali MSE Loss: 0.3844 Test MSE Loss: 0.2913
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2104921191930771, mae:0.36836495995521545, mape:0.6636996865272522, mspe:16.95187759399414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.1519
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.9071440
	speed: 0.1604s/iter; left time: 3721.9060s
	iters: 200, epoch: 1 | loss: 0.8992233
	speed: 0.1615s/iter; left time: 3730.2539s
Epoch: 1 cost time: 37.95702528953552
Epoch: 1, Steps: 233 Train Loss: 0.9134 (Forecasting Loss:0.5587 + XiCon Loss:3.5464 x Lambda(0.1)), Vali MSE Loss: 0.5596 Test MSE Loss: 0.4756
Validation loss decreased (inf --> 0.559625).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6948258
	speed: 0.1717s/iter; left time: 3943.5903s
	iters: 200, epoch: 2 | loss: 0.6567036
	speed: 0.1887s/iter; left time: 4314.9026s
Epoch: 2 cost time: 42.59430503845215
Epoch: 2, Steps: 233 Train Loss: 0.7202 (Forecasting Loss:0.3777 + XiCon Loss:3.4259 x Lambda(0.1)), Vali MSE Loss: 0.3893 Test MSE Loss: 0.2954
Validation loss decreased (0.559625 --> 0.389275).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6798097
	speed: 0.1954s/iter; left time: 4443.3181s
	iters: 200, epoch: 3 | loss: 0.6602129
	speed: 0.1997s/iter; left time: 4520.8713s
Epoch: 3 cost time: 45.74263262748718
Epoch: 3, Steps: 233 Train Loss: 0.6708 (Forecasting Loss:0.3262 + XiCon Loss:3.4454 x Lambda(0.1)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.3025
Validation loss decreased (0.389275 --> 0.360467).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6568472
	speed: 0.1989s/iter; left time: 4475.5964s
	iters: 200, epoch: 4 | loss: 0.6636029
	speed: 0.1985s/iter; left time: 4447.2113s
Epoch: 4 cost time: 46.56059408187866
Epoch: 4, Steps: 233 Train Loss: 0.6679 (Forecasting Loss:0.3212 + XiCon Loss:3.4674 x Lambda(0.1)), Vali MSE Loss: 0.3495 Test MSE Loss: 0.2986
Validation loss decreased (0.360467 --> 0.349506).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6460915
	speed: 0.2006s/iter; left time: 4466.7615s
	iters: 200, epoch: 5 | loss: 0.6843953
	speed: 0.2012s/iter; left time: 4459.5190s
Epoch: 5 cost time: 46.90045380592346
Epoch: 5, Steps: 233 Train Loss: 0.6662 (Forecasting Loss:0.3190 + XiCon Loss:3.4721 x Lambda(0.1)), Vali MSE Loss: 0.3433 Test MSE Loss: 0.2967
Validation loss decreased (0.349506 --> 0.343258).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6472378
	speed: 0.2070s/iter; left time: 4561.7031s
	iters: 200, epoch: 6 | loss: 0.6735730
	speed: 0.2049s/iter; left time: 4495.4992s
Epoch: 6 cost time: 47.63263773918152
Epoch: 6, Steps: 233 Train Loss: 0.6653 (Forecasting Loss:0.3180 + XiCon Loss:3.4729 x Lambda(0.1)), Vali MSE Loss: 0.3412 Test MSE Loss: 0.2963
Validation loss decreased (0.343258 --> 0.341235).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6554438
	speed: 0.2061s/iter; left time: 4494.5118s
	iters: 200, epoch: 7 | loss: 0.6798104
	speed: 0.1999s/iter; left time: 4338.6081s
Epoch: 7 cost time: 47.570719957351685
Epoch: 7, Steps: 233 Train Loss: 0.6644 (Forecasting Loss:0.3172 + XiCon Loss:3.4726 x Lambda(0.1)), Vali MSE Loss: 0.3478 Test MSE Loss: 0.2962
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6888285
	speed: 0.2073s/iter; left time: 4472.4888s
	iters: 200, epoch: 8 | loss: 0.6525337
	speed: 0.2000s/iter; left time: 4292.9455s
Epoch: 8 cost time: 47.57304286956787
Epoch: 8, Steps: 233 Train Loss: 0.6644 (Forecasting Loss:0.3170 + XiCon Loss:3.4733 x Lambda(0.1)), Vali MSE Loss: 0.3470 Test MSE Loss: 0.2969
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6679872
	speed: 0.2042s/iter; left time: 4357.7890s
	iters: 200, epoch: 9 | loss: 0.6609678
	speed: 0.2068s/iter; left time: 4391.9657s
Epoch: 9 cost time: 48.006783962249756
Epoch: 9, Steps: 233 Train Loss: 0.6642 (Forecasting Loss:0.3168 + XiCon Loss:3.4738 x Lambda(0.1)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2965
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6507771
	speed: 0.2038s/iter; left time: 4300.9855s
	iters: 200, epoch: 10 | loss: 0.6764773
	speed: 0.1986s/iter; left time: 4171.2208s
Epoch: 10 cost time: 47.13331079483032
Epoch: 10, Steps: 233 Train Loss: 0.6640 (Forecasting Loss:0.3167 + XiCon Loss:3.4729 x Lambda(0.1)), Vali MSE Loss: 0.3452 Test MSE Loss: 0.2977
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6730810
	speed: 0.2048s/iter; left time: 4274.7867s
	iters: 200, epoch: 11 | loss: 0.6749778
	speed: 0.1966s/iter; left time: 4084.3444s
Epoch: 11 cost time: 46.73068332672119
Epoch: 11, Steps: 233 Train Loss: 0.6642 (Forecasting Loss:0.3169 + XiCon Loss:3.4728 x Lambda(0.1)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2967
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6531569
	speed: 0.2012s/iter; left time: 4152.1531s
	iters: 200, epoch: 12 | loss: 0.6897917
	speed: 0.2030s/iter; left time: 4169.6952s
Epoch: 12 cost time: 47.41328191757202
Epoch: 12, Steps: 233 Train Loss: 0.6637 (Forecasting Loss:0.3163 + XiCon Loss:3.4739 x Lambda(0.1)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2967
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6592488
	speed: 0.2079s/iter; left time: 4241.1942s
	iters: 200, epoch: 13 | loss: 0.6482654
	speed: 0.2016s/iter; left time: 4093.6637s
Epoch: 13 cost time: 48.04548001289368
Epoch: 13, Steps: 233 Train Loss: 0.6638 (Forecasting Loss:0.3165 + XiCon Loss:3.4736 x Lambda(0.1)), Vali MSE Loss: 0.3464 Test MSE Loss: 0.2967
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6569555
	speed: 0.2049s/iter; left time: 4132.5614s
	iters: 200, epoch: 14 | loss: 0.6573325
	speed: 0.1989s/iter; left time: 3992.2817s
Epoch: 14 cost time: 47.221758127212524
Epoch: 14, Steps: 233 Train Loss: 0.6637 (Forecasting Loss:0.3166 + XiCon Loss:3.4711 x Lambda(0.1)), Vali MSE Loss: 0.3464 Test MSE Loss: 0.2968
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6862523
	speed: 0.2053s/iter; left time: 4093.9799s
	iters: 200, epoch: 15 | loss: 0.6506457
	speed: 0.2072s/iter; left time: 4111.3311s
Epoch: 15 cost time: 48.228243589401245
Epoch: 15, Steps: 233 Train Loss: 0.6640 (Forecasting Loss:0.3166 + XiCon Loss:3.4738 x Lambda(0.1)), Vali MSE Loss: 0.3462 Test MSE Loss: 0.2968
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6656177
	speed: 0.2096s/iter; left time: 4130.0128s
	iters: 200, epoch: 16 | loss: 0.6709967
	speed: 0.1974s/iter; left time: 3870.5630s
Epoch: 16 cost time: 47.410069704055786
Epoch: 16, Steps: 233 Train Loss: 0.6643 (Forecasting Loss:0.3168 + XiCon Loss:3.4753 x Lambda(0.1)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2968
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2181645929813385, mae:0.3744717836380005, mape:0.6623722910881042, mspe:16.426204681396484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2264+-0.02114, MAE:0.3807+-0.01413, MAPE:0.6527+-0.03159, MSPE:16.1091+-2.59444, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
