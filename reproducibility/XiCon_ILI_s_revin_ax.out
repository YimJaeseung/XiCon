Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[14], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=14, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3200
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 1.055955171585083
Epoch: 1, Steps: 38 Train Loss: 2.0690 (Forecasting Loss:0.4217 + XiCon Loss:1.6472 x Lambda(1.0)), Vali MSE Loss: 0.2644 Test MSE Loss: 1.0792
Validation loss decreased (inf --> 0.264424).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7453691959381104
Epoch: 2, Steps: 38 Train Loss: 1.8668 (Forecasting Loss:0.2624 + XiCon Loss:1.6044 x Lambda(1.0)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.5682
Validation loss decreased (0.264424 --> 0.169232).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7339863777160645
Epoch: 3, Steps: 38 Train Loss: 1.6937 (Forecasting Loss:0.1660 + XiCon Loss:1.5278 x Lambda(1.0)), Vali MSE Loss: 0.1255 Test MSE Loss: 0.6017
Validation loss decreased (0.169232 --> 0.125525).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7484405040740967
Epoch: 4, Steps: 38 Train Loss: 1.6568 (Forecasting Loss:0.1334 + XiCon Loss:1.5235 x Lambda(1.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.6083
Validation loss decreased (0.125525 --> 0.108753).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.77815842628479
Epoch: 5, Steps: 38 Train Loss: 1.6477 (Forecasting Loss:0.1287 + XiCon Loss:1.5191 x Lambda(1.0)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.6015
Validation loss decreased (0.108753 --> 0.106238).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7558412551879883
Epoch: 6, Steps: 38 Train Loss: 1.6552 (Forecasting Loss:0.1250 + XiCon Loss:1.5302 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5981
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7721643447875977
Epoch: 7, Steps: 38 Train Loss: 1.6629 (Forecasting Loss:0.1244 + XiCon Loss:1.5385 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.5968
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7439141273498535
Epoch: 8, Steps: 38 Train Loss: 1.6495 (Forecasting Loss:0.1228 + XiCon Loss:1.5267 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.5967
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7092142105102539
Epoch: 9, Steps: 38 Train Loss: 1.6558 (Forecasting Loss:0.1234 + XiCon Loss:1.5324 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.5964
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7599763870239258
Epoch: 10, Steps: 38 Train Loss: 1.6247 (Forecasting Loss:0.1232 + XiCon Loss:1.5015 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.5961
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7474675178527832
Epoch: 11, Steps: 38 Train Loss: 1.6488 (Forecasting Loss:0.1226 + XiCon Loss:1.5262 x Lambda(1.0)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.5956
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7466814517974854
Epoch: 12, Steps: 38 Train Loss: 1.6590 (Forecasting Loss:0.1221 + XiCon Loss:1.5369 x Lambda(1.0)), Vali MSE Loss: 0.1068 Test MSE Loss: 0.5955
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7384822368621826
Epoch: 13, Steps: 38 Train Loss: 1.6327 (Forecasting Loss:0.1226 + XiCon Loss:1.5101 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.5955
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7474052906036377
Epoch: 14, Steps: 38 Train Loss: 1.6567 (Forecasting Loss:0.1226 + XiCon Loss:1.5341 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5954
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7300400733947754
Epoch: 15, Steps: 38 Train Loss: 1.6589 (Forecasting Loss:0.1230 + XiCon Loss:1.5360 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.5954
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6473795771598816, mae:0.5556558966636658, mape:0.21567581593990326, mspe:0.17507705092430115 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3729
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.714632511138916
Epoch: 1, Steps: 38 Train Loss: 2.0956 (Forecasting Loss:0.4498 + XiCon Loss:1.6458 x Lambda(1.0)), Vali MSE Loss: 0.3012 Test MSE Loss: 1.0631
Validation loss decreased (inf --> 0.301161).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7481920719146729
Epoch: 2, Steps: 38 Train Loss: 1.8858 (Forecasting Loss:0.2874 + XiCon Loss:1.5984 x Lambda(1.0)), Vali MSE Loss: 0.1555 Test MSE Loss: 0.6276
Validation loss decreased (0.301161 --> 0.155471).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7335226535797119
Epoch: 3, Steps: 38 Train Loss: 1.6945 (Forecasting Loss:0.1600 + XiCon Loss:1.5345 x Lambda(1.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6405
Validation loss decreased (0.155471 --> 0.117924).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7025299072265625
Epoch: 4, Steps: 38 Train Loss: 1.6386 (Forecasting Loss:0.1335 + XiCon Loss:1.5051 x Lambda(1.0)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.6145
Validation loss decreased (0.117924 --> 0.111747).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7161498069763184
Epoch: 5, Steps: 38 Train Loss: 1.6349 (Forecasting Loss:0.1259 + XiCon Loss:1.5090 x Lambda(1.0)), Vali MSE Loss: 0.1112 Test MSE Loss: 0.6420
Validation loss decreased (0.111747 --> 0.111202).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7429237365722656
Epoch: 6, Steps: 38 Train Loss: 1.6192 (Forecasting Loss:0.1224 + XiCon Loss:1.4968 x Lambda(1.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6489
Validation loss decreased (0.111202 --> 0.110669).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7322626113891602
Epoch: 7, Steps: 38 Train Loss: 1.6314 (Forecasting Loss:0.1210 + XiCon Loss:1.5104 x Lambda(1.0)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6521
Validation loss decreased (0.110669 --> 0.110199).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7672662734985352
Epoch: 8, Steps: 38 Train Loss: 1.6137 (Forecasting Loss:0.1206 + XiCon Loss:1.4931 x Lambda(1.0)), Vali MSE Loss: 0.1093 Test MSE Loss: 0.6541
Validation loss decreased (0.110199 --> 0.109251).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7419283390045166
Epoch: 9, Steps: 38 Train Loss: 1.6189 (Forecasting Loss:0.1185 + XiCon Loss:1.5004 x Lambda(1.0)), Vali MSE Loss: 0.1092 Test MSE Loss: 0.6551
Validation loss decreased (0.109251 --> 0.109235).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6829855442047119
Epoch: 10, Steps: 38 Train Loss: 1.6278 (Forecasting Loss:0.1184 + XiCon Loss:1.5094 x Lambda(1.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.6553
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7543182373046875
Epoch: 11, Steps: 38 Train Loss: 1.6225 (Forecasting Loss:0.1184 + XiCon Loss:1.5042 x Lambda(1.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.6552
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7402949333190918
Epoch: 12, Steps: 38 Train Loss: 1.6182 (Forecasting Loss:0.1193 + XiCon Loss:1.4990 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.6551
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7406594753265381
Epoch: 13, Steps: 38 Train Loss: 1.6254 (Forecasting Loss:0.1192 + XiCon Loss:1.5061 x Lambda(1.0)), Vali MSE Loss: 0.1101 Test MSE Loss: 0.6551
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7722988128662109
Epoch: 14, Steps: 38 Train Loss: 1.6090 (Forecasting Loss:0.1204 + XiCon Loss:1.4886 x Lambda(1.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.6551
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7717349529266357
Epoch: 15, Steps: 38 Train Loss: 1.6182 (Forecasting Loss:0.1178 + XiCon Loss:1.5004 x Lambda(1.0)), Vali MSE Loss: 0.1095 Test MSE Loss: 0.6551
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7222833633422852
Epoch: 16, Steps: 38 Train Loss: 1.6129 (Forecasting Loss:0.1186 + XiCon Loss:1.4943 x Lambda(1.0)), Vali MSE Loss: 0.1101 Test MSE Loss: 0.6551
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.75360107421875
Epoch: 17, Steps: 38 Train Loss: 1.6087 (Forecasting Loss:0.1192 + XiCon Loss:1.4896 x Lambda(1.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.6551
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6843774318695068
Epoch: 18, Steps: 38 Train Loss: 1.6159 (Forecasting Loss:0.1193 + XiCon Loss:1.4966 x Lambda(1.0)), Vali MSE Loss: 0.1093 Test MSE Loss: 0.6551
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7286090850830078
Epoch: 19, Steps: 38 Train Loss: 1.6146 (Forecasting Loss:0.1196 + XiCon Loss:1.4950 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.6551
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.7304108142852783, mae:0.5797913670539856, mape:0.22653460502624512, mspe:0.19726121425628662 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4341
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7321078777313232
Epoch: 1, Steps: 38 Train Loss: 2.1515 (Forecasting Loss:0.5112 + XiCon Loss:1.6403 x Lambda(1.0)), Vali MSE Loss: 0.3109 Test MSE Loss: 1.3943
Validation loss decreased (inf --> 0.310858).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7558071613311768
Epoch: 2, Steps: 38 Train Loss: 1.8643 (Forecasting Loss:0.2690 + XiCon Loss:1.5954 x Lambda(1.0)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.6505
Validation loss decreased (0.310858 --> 0.160955).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7547438144683838
Epoch: 3, Steps: 38 Train Loss: 1.6865 (Forecasting Loss:0.1661 + XiCon Loss:1.5204 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6203
Validation loss decreased (0.160955 --> 0.115105).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7390003204345703
Epoch: 4, Steps: 38 Train Loss: 1.6588 (Forecasting Loss:0.1351 + XiCon Loss:1.5237 x Lambda(1.0)), Vali MSE Loss: 0.1106 Test MSE Loss: 0.5921
Validation loss decreased (0.115105 --> 0.110644).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7812597751617432
Epoch: 5, Steps: 38 Train Loss: 1.6605 (Forecasting Loss:0.1271 + XiCon Loss:1.5334 x Lambda(1.0)), Vali MSE Loss: 0.1094 Test MSE Loss: 0.5951
Validation loss decreased (0.110644 --> 0.109375).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7543609142303467
Epoch: 6, Steps: 38 Train Loss: 1.6555 (Forecasting Loss:0.1241 + XiCon Loss:1.5315 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.6153
Validation loss decreased (0.109375 --> 0.108638).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6799914836883545
Epoch: 7, Steps: 38 Train Loss: 1.6559 (Forecasting Loss:0.1230 + XiCon Loss:1.5329 x Lambda(1.0)), Vali MSE Loss: 0.1104 Test MSE Loss: 0.5998
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.8260583877563477
Epoch: 8, Steps: 38 Train Loss: 1.6685 (Forecasting Loss:0.1220 + XiCon Loss:1.5465 x Lambda(1.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.5969
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7452154159545898
Epoch: 9, Steps: 38 Train Loss: 1.6730 (Forecasting Loss:0.1203 + XiCon Loss:1.5527 x Lambda(1.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.5981
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7468869686126709
Epoch: 10, Steps: 38 Train Loss: 1.6773 (Forecasting Loss:0.1204 + XiCon Loss:1.5569 x Lambda(1.0)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.5994
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.749887228012085
Epoch: 11, Steps: 38 Train Loss: 1.6719 (Forecasting Loss:0.1205 + XiCon Loss:1.5514 x Lambda(1.0)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6001
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7491135597229004
Epoch: 12, Steps: 38 Train Loss: 1.6610 (Forecasting Loss:0.1208 + XiCon Loss:1.5402 x Lambda(1.0)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.6003
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7411839962005615
Epoch: 13, Steps: 38 Train Loss: 1.6789 (Forecasting Loss:0.1201 + XiCon Loss:1.5588 x Lambda(1.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.6006
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7483541965484619
Epoch: 14, Steps: 38 Train Loss: 1.6478 (Forecasting Loss:0.1208 + XiCon Loss:1.5270 x Lambda(1.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.6006
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6981310844421387
Epoch: 15, Steps: 38 Train Loss: 1.6547 (Forecasting Loss:0.1193 + XiCon Loss:1.5354 x Lambda(1.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6006
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7070355415344238
Epoch: 16, Steps: 38 Train Loss: 1.6762 (Forecasting Loss:0.1211 + XiCon Loss:1.5551 x Lambda(1.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6007
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6724080443382263, mae:0.5581082105636597, mape:0.21676446497440338, mspe:0.1861116737127304 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4314
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7838695049285889
Epoch: 1, Steps: 38 Train Loss: 2.1586 (Forecasting Loss:0.5238 + XiCon Loss:1.6348 x Lambda(1.0)), Vali MSE Loss: 0.3157 Test MSE Loss: 1.3949
Validation loss decreased (inf --> 0.315745).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7652766704559326
Epoch: 2, Steps: 38 Train Loss: 1.8738 (Forecasting Loss:0.2762 + XiCon Loss:1.5976 x Lambda(1.0)), Vali MSE Loss: 0.1770 Test MSE Loss: 0.5977
Validation loss decreased (0.315745 --> 0.177031).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.756061315536499
Epoch: 3, Steps: 38 Train Loss: 1.7025 (Forecasting Loss:0.1688 + XiCon Loss:1.5337 x Lambda(1.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.5985
Validation loss decreased (0.177031 --> 0.115726).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7475647926330566
Epoch: 4, Steps: 38 Train Loss: 1.6732 (Forecasting Loss:0.1349 + XiCon Loss:1.5382 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.5966
Validation loss decreased (0.115726 --> 0.109729).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7507758140563965
Epoch: 5, Steps: 38 Train Loss: 1.7043 (Forecasting Loss:0.1264 + XiCon Loss:1.5779 x Lambda(1.0)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.6324
Validation loss decreased (0.109729 --> 0.105813).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7389359474182129
Epoch: 6, Steps: 38 Train Loss: 1.6877 (Forecasting Loss:0.1223 + XiCon Loss:1.5655 x Lambda(1.0)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6296
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6639761924743652
Epoch: 7, Steps: 38 Train Loss: 1.7054 (Forecasting Loss:0.1204 + XiCon Loss:1.5851 x Lambda(1.0)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.6348
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7843358516693115
Epoch: 8, Steps: 38 Train Loss: 1.7333 (Forecasting Loss:0.1207 + XiCon Loss:1.6126 x Lambda(1.0)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6345
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.785879373550415
Epoch: 9, Steps: 38 Train Loss: 1.7132 (Forecasting Loss:0.1194 + XiCon Loss:1.5939 x Lambda(1.0)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6315
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7286403179168701
Epoch: 10, Steps: 38 Train Loss: 1.6766 (Forecasting Loss:0.1200 + XiCon Loss:1.5566 x Lambda(1.0)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.6310
Validation loss decreased (0.105813 --> 0.105810).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7564966678619385
Epoch: 11, Steps: 38 Train Loss: 1.7306 (Forecasting Loss:0.1198 + XiCon Loss:1.6108 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6311
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7393050193786621
Epoch: 12, Steps: 38 Train Loss: 1.6999 (Forecasting Loss:0.1202 + XiCon Loss:1.5796 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6310
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7696845531463623
Epoch: 13, Steps: 38 Train Loss: 1.7040 (Forecasting Loss:0.1182 + XiCon Loss:1.5858 x Lambda(1.0)), Vali MSE Loss: 0.1066 Test MSE Loss: 0.6309
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7398886680603027
Epoch: 14, Steps: 38 Train Loss: 1.7098 (Forecasting Loss:0.1168 + XiCon Loss:1.5930 x Lambda(1.0)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.6309
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6971709728240967
Epoch: 15, Steps: 38 Train Loss: 1.7044 (Forecasting Loss:0.1191 + XiCon Loss:1.5853 x Lambda(1.0)), Vali MSE Loss: 0.1057 Test MSE Loss: 0.6309
Validation loss decreased (0.105810 --> 0.105748).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7088582515716553
Epoch: 16, Steps: 38 Train Loss: 1.7434 (Forecasting Loss:0.1195 + XiCon Loss:1.6239 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.733269214630127
Epoch: 17, Steps: 38 Train Loss: 1.7211 (Forecasting Loss:0.1189 + XiCon Loss:1.6022 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6309
Validation loss decreased (0.105748 --> 0.105463).  Saving model ...
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6857402324676514
Epoch: 18, Steps: 38 Train Loss: 1.7291 (Forecasting Loss:0.1197 + XiCon Loss:1.6095 x Lambda(1.0)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.6309
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7803397178649902
Epoch: 19, Steps: 38 Train Loss: 1.7168 (Forecasting Loss:0.1199 + XiCon Loss:1.5969 x Lambda(1.0)), Vali MSE Loss: 0.1056 Test MSE Loss: 0.6309
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7897725105285645
Epoch: 20, Steps: 38 Train Loss: 1.7158 (Forecasting Loss:0.1180 + XiCon Loss:1.5979 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7300090789794922
Epoch: 21, Steps: 38 Train Loss: 1.7227 (Forecasting Loss:0.1196 + XiCon Loss:1.6031 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7686862945556641
Epoch: 22, Steps: 38 Train Loss: 1.7121 (Forecasting Loss:0.1188 + XiCon Loss:1.5933 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6309
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7474994659423828
Epoch: 23, Steps: 38 Train Loss: 1.7350 (Forecasting Loss:0.1191 + XiCon Loss:1.6159 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7206885814666748
Epoch: 24, Steps: 38 Train Loss: 1.7122 (Forecasting Loss:0.1206 + XiCon Loss:1.5916 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6309
Validation loss decreased (0.105463 --> 0.105463).  Saving model ...
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7378220558166504
Epoch: 25, Steps: 38 Train Loss: 1.7065 (Forecasting Loss:0.1199 + XiCon Loss:1.5865 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6309
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7211117744445801
Epoch: 26, Steps: 38 Train Loss: 1.7040 (Forecasting Loss:0.1188 + XiCon Loss:1.5852 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6309
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7204363346099854
Epoch: 27, Steps: 38 Train Loss: 1.7133 (Forecasting Loss:0.1196 + XiCon Loss:1.5937 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7782323360443115
Epoch: 28, Steps: 38 Train Loss: 1.7071 (Forecasting Loss:0.1197 + XiCon Loss:1.5874 x Lambda(1.0)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.6309
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7574594020843506
Epoch: 29, Steps: 38 Train Loss: 1.7262 (Forecasting Loss:0.1204 + XiCon Loss:1.6057 x Lambda(1.0)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.6309
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7689838409423828
Epoch: 30, Steps: 38 Train Loss: 1.7148 (Forecasting Loss:0.1191 + XiCon Loss:1.5956 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7535495758056641
Epoch: 31, Steps: 38 Train Loss: 1.6834 (Forecasting Loss:0.1187 + XiCon Loss:1.5647 x Lambda(1.0)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.6309
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.7216465473175049
Epoch: 32, Steps: 38 Train Loss: 1.7271 (Forecasting Loss:0.1196 + XiCon Loss:1.6074 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6309
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.761481761932373
Epoch: 33, Steps: 38 Train Loss: 1.7201 (Forecasting Loss:0.1201 + XiCon Loss:1.6000 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6309
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.7794623374938965
Epoch: 34, Steps: 38 Train Loss: 1.7170 (Forecasting Loss:0.1202 + XiCon Loss:1.5968 x Lambda(1.0)), Vali MSE Loss: 0.1057 Test MSE Loss: 0.6309
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.7068975567817688, mae:0.5548227429389954, mape:0.2202458530664444, mspe:0.19557607173919678 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4565
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.714118242263794
Epoch: 1, Steps: 38 Train Loss: 2.1549 (Forecasting Loss:0.5123 + XiCon Loss:1.6426 x Lambda(1.0)), Vali MSE Loss: 0.3143 Test MSE Loss: 1.4143
Validation loss decreased (inf --> 0.314257).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7039806842803955
Epoch: 2, Steps: 38 Train Loss: 1.8505 (Forecasting Loss:0.2743 + XiCon Loss:1.5762 x Lambda(1.0)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.6333
Validation loss decreased (0.314257 --> 0.165360).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7590851783752441
Epoch: 3, Steps: 38 Train Loss: 1.6919 (Forecasting Loss:0.1742 + XiCon Loss:1.5177 x Lambda(1.0)), Vali MSE Loss: 0.1238 Test MSE Loss: 0.6664
Validation loss decreased (0.165360 --> 0.123757).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7308826446533203
Epoch: 4, Steps: 38 Train Loss: 1.6483 (Forecasting Loss:0.1320 + XiCon Loss:1.5163 x Lambda(1.0)), Vali MSE Loss: 0.1221 Test MSE Loss: 0.6115
Validation loss decreased (0.123757 --> 0.122069).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7124161720275879
Epoch: 5, Steps: 38 Train Loss: 1.6772 (Forecasting Loss:0.1220 + XiCon Loss:1.5552 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6171
Validation loss decreased (0.122069 --> 0.115234).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6737053394317627
Epoch: 6, Steps: 38 Train Loss: 1.6753 (Forecasting Loss:0.1209 + XiCon Loss:1.5544 x Lambda(1.0)), Vali MSE Loss: 0.1188 Test MSE Loss: 0.6133
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7589538097381592
Epoch: 7, Steps: 38 Train Loss: 1.6807 (Forecasting Loss:0.1156 + XiCon Loss:1.5650 x Lambda(1.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6543
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7335226535797119
Epoch: 8, Steps: 38 Train Loss: 1.6644 (Forecasting Loss:0.1157 + XiCon Loss:1.5487 x Lambda(1.0)), Vali MSE Loss: 0.1189 Test MSE Loss: 0.6222
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7769227027893066
Epoch: 9, Steps: 38 Train Loss: 1.7061 (Forecasting Loss:0.1151 + XiCon Loss:1.5910 x Lambda(1.0)), Vali MSE Loss: 0.1177 Test MSE Loss: 0.6331
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.734464168548584
Epoch: 10, Steps: 38 Train Loss: 1.6996 (Forecasting Loss:0.1151 + XiCon Loss:1.5845 x Lambda(1.0)), Vali MSE Loss: 0.1172 Test MSE Loss: 0.6375
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.735912561416626
Epoch: 11, Steps: 38 Train Loss: 1.6815 (Forecasting Loss:0.1143 + XiCon Loss:1.5672 x Lambda(1.0)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6378
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.74595046043396
Epoch: 12, Steps: 38 Train Loss: 1.6765 (Forecasting Loss:0.1146 + XiCon Loss:1.5619 x Lambda(1.0)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6375
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7649712562561035
Epoch: 13, Steps: 38 Train Loss: 1.6984 (Forecasting Loss:0.1129 + XiCon Loss:1.5855 x Lambda(1.0)), Vali MSE Loss: 0.1175 Test MSE Loss: 0.6375
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7374327182769775
Epoch: 14, Steps: 38 Train Loss: 1.7064 (Forecasting Loss:0.1145 + XiCon Loss:1.5918 x Lambda(1.0)), Vali MSE Loss: 0.1175 Test MSE Loss: 0.6376
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7134127616882324
Epoch: 15, Steps: 38 Train Loss: 1.6664 (Forecasting Loss:0.1158 + XiCon Loss:1.5506 x Lambda(1.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6375
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6861322522163391, mae:0.5481348633766174, mape:0.21425636112689972, mspe:0.191025972366333 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6886+-0.03951, MAE:0.5593+-0.01494, MAPE:0.2187+-0.00610, MSPE:0.1890+-0.01107, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[28], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=28, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3731
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 1.0272307395935059
Epoch: 1, Steps: 37 Train Loss: 16.9562 (Forecasting Loss:0.4947 + XiCon Loss:1.6462 x Lambda(10.0)), Vali MSE Loss: 0.3102 Test MSE Loss: 1.2574
Validation loss decreased (inf --> 0.310159).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7345709800720215
Epoch: 2, Steps: 37 Train Loss: 16.1878 (Forecasting Loss:0.3055 + XiCon Loss:1.5882 x Lambda(10.0)), Vali MSE Loss: 0.1885 Test MSE Loss: 0.6870
Validation loss decreased (0.310159 --> 0.188510).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.774829626083374
Epoch: 3, Steps: 37 Train Loss: 15.3305 (Forecasting Loss:0.1918 + XiCon Loss:1.5139 x Lambda(10.0)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.7194
Validation loss decreased (0.188510 --> 0.123363).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7025799751281738
Epoch: 4, Steps: 37 Train Loss: 15.1466 (Forecasting Loss:0.1541 + XiCon Loss:1.4993 x Lambda(10.0)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6560
Validation loss decreased (0.123363 --> 0.117810).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7093465328216553
Epoch: 5, Steps: 37 Train Loss: 15.2331 (Forecasting Loss:0.1486 + XiCon Loss:1.5085 x Lambda(10.0)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.6792
Validation loss decreased (0.117810 --> 0.114261).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7398285865783691
Epoch: 6, Steps: 37 Train Loss: 15.0829 (Forecasting Loss:0.1460 + XiCon Loss:1.4937 x Lambda(10.0)), Vali MSE Loss: 0.1160 Test MSE Loss: 0.6676
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7366149425506592
Epoch: 7, Steps: 37 Train Loss: 15.0422 (Forecasting Loss:0.1439 + XiCon Loss:1.4898 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6684
Validation loss decreased (0.114261 --> 0.113177).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7298154830932617
Epoch: 8, Steps: 37 Train Loss: 15.1057 (Forecasting Loss:0.1448 + XiCon Loss:1.4961 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6689
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7333230972290039
Epoch: 9, Steps: 37 Train Loss: 15.0648 (Forecasting Loss:0.1431 + XiCon Loss:1.4922 x Lambda(10.0)), Vali MSE Loss: 0.1135 Test MSE Loss: 0.6692
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7265620231628418
Epoch: 10, Steps: 37 Train Loss: 15.1207 (Forecasting Loss:0.1441 + XiCon Loss:1.4977 x Lambda(10.0)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6695
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7372753620147705
Epoch: 11, Steps: 37 Train Loss: 15.1826 (Forecasting Loss:0.1433 + XiCon Loss:1.5039 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6697
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7767899036407471
Epoch: 12, Steps: 37 Train Loss: 15.0471 (Forecasting Loss:0.1438 + XiCon Loss:1.4903 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6698
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6713178157806396
Epoch: 13, Steps: 37 Train Loss: 15.0531 (Forecasting Loss:0.1426 + XiCon Loss:1.4910 x Lambda(10.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6699
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.715151309967041
Epoch: 14, Steps: 37 Train Loss: 15.2615 (Forecasting Loss:0.1432 + XiCon Loss:1.5118 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6700
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7822122573852539
Epoch: 15, Steps: 37 Train Loss: 15.1228 (Forecasting Loss:0.1438 + XiCon Loss:1.4979 x Lambda(10.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6701
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7553465366363525
Epoch: 16, Steps: 37 Train Loss: 15.1622 (Forecasting Loss:0.1420 + XiCon Loss:1.5020 x Lambda(10.0)), Vali MSE Loss: 0.1138 Test MSE Loss: 0.6701
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.8157901763916016
Epoch: 17, Steps: 37 Train Loss: 15.0746 (Forecasting Loss:0.1423 + XiCon Loss:1.4932 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.723067045211792, mae:0.6136666536331177, mape:0.2431146502494812, mspe:0.205479234457016 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4736
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7499504089355469
Epoch: 1, Steps: 37 Train Loss: 16.9287 (Forecasting Loss:0.5467 + XiCon Loss:1.6382 x Lambda(10.0)), Vali MSE Loss: 0.3280 Test MSE Loss: 1.4432
Validation loss decreased (inf --> 0.327996).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7284166812896729
Epoch: 2, Steps: 37 Train Loss: 16.2721 (Forecasting Loss:0.3301 + XiCon Loss:1.5942 x Lambda(10.0)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.7316
Validation loss decreased (0.327996 --> 0.165689).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7158961296081543
Epoch: 3, Steps: 37 Train Loss: 15.4424 (Forecasting Loss:0.1896 + XiCon Loss:1.5253 x Lambda(10.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.6000
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7461259365081787
Epoch: 4, Steps: 37 Train Loss: 15.3391 (Forecasting Loss:0.1668 + XiCon Loss:1.5172 x Lambda(10.0)), Vali MSE Loss: 0.1215 Test MSE Loss: 0.7026
Validation loss decreased (0.165689 --> 0.121489).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7514712810516357
Epoch: 5, Steps: 37 Train Loss: 15.3101 (Forecasting Loss:0.1566 + XiCon Loss:1.5154 x Lambda(10.0)), Vali MSE Loss: 0.1199 Test MSE Loss: 0.6688
Validation loss decreased (0.121489 --> 0.119858).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7637131214141846
Epoch: 6, Steps: 37 Train Loss: 15.2547 (Forecasting Loss:0.1498 + XiCon Loss:1.5105 x Lambda(10.0)), Vali MSE Loss: 0.1113 Test MSE Loss: 0.7097
Validation loss decreased (0.119858 --> 0.111260).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7280631065368652
Epoch: 7, Steps: 37 Train Loss: 15.5544 (Forecasting Loss:0.1513 + XiCon Loss:1.5403 x Lambda(10.0)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6953
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7471938133239746
Epoch: 8, Steps: 37 Train Loss: 15.6071 (Forecasting Loss:0.1510 + XiCon Loss:1.5456 x Lambda(10.0)), Vali MSE Loss: 0.1123 Test MSE Loss: 0.6875
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7356059551239014
Epoch: 9, Steps: 37 Train Loss: 15.4089 (Forecasting Loss:0.1515 + XiCon Loss:1.5257 x Lambda(10.0)), Vali MSE Loss: 0.1111 Test MSE Loss: 0.6876
Validation loss decreased (0.111260 --> 0.111115).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7451057434082031
Epoch: 10, Steps: 37 Train Loss: 15.5342 (Forecasting Loss:0.1515 + XiCon Loss:1.5383 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6889
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7507920265197754
Epoch: 11, Steps: 37 Train Loss: 15.6106 (Forecasting Loss:0.1509 + XiCon Loss:1.5460 x Lambda(10.0)), Vali MSE Loss: 0.1128 Test MSE Loss: 0.6891
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7889447212219238
Epoch: 12, Steps: 37 Train Loss: 15.4090 (Forecasting Loss:0.1484 + XiCon Loss:1.5261 x Lambda(10.0)), Vali MSE Loss: 0.1126 Test MSE Loss: 0.6892
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7293014526367188
Epoch: 13, Steps: 37 Train Loss: 15.5892 (Forecasting Loss:0.1503 + XiCon Loss:1.5439 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6893
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7526717185974121
Epoch: 14, Steps: 37 Train Loss: 15.4890 (Forecasting Loss:0.1517 + XiCon Loss:1.5337 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6896
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7666163444519043
Epoch: 15, Steps: 37 Train Loss: 15.6154 (Forecasting Loss:0.1482 + XiCon Loss:1.5467 x Lambda(10.0)), Vali MSE Loss: 0.1131 Test MSE Loss: 0.6896
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7799649238586426
Epoch: 16, Steps: 37 Train Loss: 15.4626 (Forecasting Loss:0.1488 + XiCon Loss:1.5314 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6897
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7360789775848389
Epoch: 17, Steps: 37 Train Loss: 15.4848 (Forecasting Loss:0.1504 + XiCon Loss:1.5334 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6897
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.687875509262085
Epoch: 18, Steps: 37 Train Loss: 15.4041 (Forecasting Loss:0.1510 + XiCon Loss:1.5253 x Lambda(10.0)), Vali MSE Loss: 0.1127 Test MSE Loss: 0.6897
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7228374481201172
Epoch: 19, Steps: 37 Train Loss: 15.5900 (Forecasting Loss:0.1517 + XiCon Loss:1.5438 x Lambda(10.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6897
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.749732494354248, mae:0.6254292130470276, mape:0.2438012659549713, mspe:0.19632068276405334 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4058
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.6796894073486328
Epoch: 1, Steps: 37 Train Loss: 16.8957 (Forecasting Loss:0.4576 + XiCon Loss:1.6438 x Lambda(10.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 1.2041
Validation loss decreased (inf --> 0.289107).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7622709274291992
Epoch: 2, Steps: 37 Train Loss: 16.1992 (Forecasting Loss:0.3087 + XiCon Loss:1.5891 x Lambda(10.0)), Vali MSE Loss: 0.1907 Test MSE Loss: 0.7062
Validation loss decreased (0.289107 --> 0.190669).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.770824670791626
Epoch: 3, Steps: 37 Train Loss: 15.3060 (Forecasting Loss:0.1923 + XiCon Loss:1.5114 x Lambda(10.0)), Vali MSE Loss: 0.1291 Test MSE Loss: 0.6963
Validation loss decreased (0.190669 --> 0.129116).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7351808547973633
Epoch: 4, Steps: 37 Train Loss: 15.2154 (Forecasting Loss:0.1582 + XiCon Loss:1.5057 x Lambda(10.0)), Vali MSE Loss: 0.1175 Test MSE Loss: 0.6721
Validation loss decreased (0.129116 --> 0.117519).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7422285079956055
Epoch: 5, Steps: 37 Train Loss: 15.1341 (Forecasting Loss:0.1490 + XiCon Loss:1.4985 x Lambda(10.0)), Vali MSE Loss: 0.1166 Test MSE Loss: 0.6629
Validation loss decreased (0.117519 --> 0.116552).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7536158561706543
Epoch: 6, Steps: 37 Train Loss: 15.0985 (Forecasting Loss:0.1460 + XiCon Loss:1.4952 x Lambda(10.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6636
Validation loss decreased (0.116552 --> 0.114762).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7014954090118408
Epoch: 7, Steps: 37 Train Loss: 15.1510 (Forecasting Loss:0.1425 + XiCon Loss:1.5009 x Lambda(10.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6652
Validation loss decreased (0.114762 --> 0.114486).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7586779594421387
Epoch: 8, Steps: 37 Train Loss: 15.1156 (Forecasting Loss:0.1437 + XiCon Loss:1.4972 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6654
Validation loss decreased (0.114486 --> 0.113682).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7161991596221924
Epoch: 9, Steps: 37 Train Loss: 15.0219 (Forecasting Loss:0.1427 + XiCon Loss:1.4879 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6651
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7242515087127686
Epoch: 10, Steps: 37 Train Loss: 15.0347 (Forecasting Loss:0.1425 + XiCon Loss:1.4892 x Lambda(10.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6645
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7187714576721191
Epoch: 11, Steps: 37 Train Loss: 15.1234 (Forecasting Loss:0.1427 + XiCon Loss:1.4981 x Lambda(10.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6645
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7780592441558838
Epoch: 12, Steps: 37 Train Loss: 15.1902 (Forecasting Loss:0.1416 + XiCon Loss:1.5049 x Lambda(10.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.6644
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7664036750793457
Epoch: 13, Steps: 37 Train Loss: 15.0965 (Forecasting Loss:0.1429 + XiCon Loss:1.4954 x Lambda(10.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6643
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7402446269989014
Epoch: 14, Steps: 37 Train Loss: 15.2073 (Forecasting Loss:0.1429 + XiCon Loss:1.5064 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6644
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7165977954864502
Epoch: 15, Steps: 37 Train Loss: 15.1987 (Forecasting Loss:0.1428 + XiCon Loss:1.5056 x Lambda(10.0)), Vali MSE Loss: 0.1163 Test MSE Loss: 0.6643
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7597606182098389
Epoch: 16, Steps: 37 Train Loss: 15.0994 (Forecasting Loss:0.1427 + XiCon Loss:1.4957 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6643
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7020161151885986
Epoch: 17, Steps: 37 Train Loss: 15.1906 (Forecasting Loss:0.1424 + XiCon Loss:1.5048 x Lambda(10.0)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.6643
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7114126682281494
Epoch: 18, Steps: 37 Train Loss: 15.0775 (Forecasting Loss:0.1422 + XiCon Loss:1.4935 x Lambda(10.0)), Vali MSE Loss: 0.1143 Test MSE Loss: 0.6643
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7134374380111694, mae:0.6173449158668518, mape:0.24519532918930054, mspe:0.20620596408843994 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4397
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7084436416625977
Epoch: 1, Steps: 37 Train Loss: 16.9390 (Forecasting Loss:0.4628 + XiCon Loss:1.6476 x Lambda(10.0)), Vali MSE Loss: 0.3013 Test MSE Loss: 1.2145
Validation loss decreased (inf --> 0.301281).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7283260822296143
Epoch: 2, Steps: 37 Train Loss: 16.2940 (Forecasting Loss:0.3123 + XiCon Loss:1.5982 x Lambda(10.0)), Vali MSE Loss: 0.1814 Test MSE Loss: 0.6277
Validation loss decreased (0.301281 --> 0.181425).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7736387252807617
Epoch: 3, Steps: 37 Train Loss: 15.3995 (Forecasting Loss:0.1842 + XiCon Loss:1.5215 x Lambda(10.0)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.6897
Validation loss decreased (0.181425 --> 0.125677).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7177121639251709
Epoch: 4, Steps: 37 Train Loss: 15.0318 (Forecasting Loss:0.1559 + XiCon Loss:1.4876 x Lambda(10.0)), Vali MSE Loss: 0.1293 Test MSE Loss: 0.6663
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.728856086730957
Epoch: 5, Steps: 37 Train Loss: 15.1941 (Forecasting Loss:0.1503 + XiCon Loss:1.5044 x Lambda(10.0)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.6812
Validation loss decreased (0.125677 --> 0.116653).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7526936531066895
Epoch: 6, Steps: 37 Train Loss: 15.0407 (Forecasting Loss:0.1466 + XiCon Loss:1.4894 x Lambda(10.0)), Vali MSE Loss: 0.1196 Test MSE Loss: 0.6624
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6742753982543945
Epoch: 7, Steps: 37 Train Loss: 15.0133 (Forecasting Loss:0.1454 + XiCon Loss:1.4868 x Lambda(10.0)), Vali MSE Loss: 0.1191 Test MSE Loss: 0.6618
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7078986167907715
Epoch: 8, Steps: 37 Train Loss: 15.0840 (Forecasting Loss:0.1453 + XiCon Loss:1.4939 x Lambda(10.0)), Vali MSE Loss: 0.1183 Test MSE Loss: 0.6647
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7273201942443848
Epoch: 9, Steps: 37 Train Loss: 15.0590 (Forecasting Loss:0.1452 + XiCon Loss:1.4914 x Lambda(10.0)), Vali MSE Loss: 0.1194 Test MSE Loss: 0.6682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7366816997528076
Epoch: 10, Steps: 37 Train Loss: 14.9650 (Forecasting Loss:0.1448 + XiCon Loss:1.4820 x Lambda(10.0)), Vali MSE Loss: 0.1178 Test MSE Loss: 0.6688
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7421488761901855
Epoch: 11, Steps: 37 Train Loss: 14.9223 (Forecasting Loss:0.1434 + XiCon Loss:1.4779 x Lambda(10.0)), Vali MSE Loss: 0.1177 Test MSE Loss: 0.6694
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7726128101348877
Epoch: 12, Steps: 37 Train Loss: 15.0223 (Forecasting Loss:0.1447 + XiCon Loss:1.4878 x Lambda(10.0)), Vali MSE Loss: 0.1189 Test MSE Loss: 0.6699
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7458329200744629
Epoch: 13, Steps: 37 Train Loss: 15.1593 (Forecasting Loss:0.1444 + XiCon Loss:1.5015 x Lambda(10.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6699
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7365899085998535
Epoch: 14, Steps: 37 Train Loss: 14.9197 (Forecasting Loss:0.1431 + XiCon Loss:1.4777 x Lambda(10.0)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.6700
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6682274341583252
Epoch: 15, Steps: 37 Train Loss: 15.1084 (Forecasting Loss:0.1434 + XiCon Loss:1.4965 x Lambda(10.0)), Vali MSE Loss: 0.1198 Test MSE Loss: 0.6701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7316081523895264, mae:0.6308897733688354, mape:0.24664463102817535, mspe:0.20212000608444214 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4301
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7734084129333496
Epoch: 1, Steps: 37 Train Loss: 16.8829 (Forecasting Loss:0.4964 + XiCon Loss:1.6386 x Lambda(10.0)), Vali MSE Loss: 0.3011 Test MSE Loss: 1.3905
Validation loss decreased (inf --> 0.301148).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7666652202606201
Epoch: 2, Steps: 37 Train Loss: 16.0288 (Forecasting Loss:0.2790 + XiCon Loss:1.5750 x Lambda(10.0)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.7151
Validation loss decreased (0.301148 --> 0.235990).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7418155670166016
Epoch: 3, Steps: 37 Train Loss: 15.3312 (Forecasting Loss:0.1894 + XiCon Loss:1.5142 x Lambda(10.0)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.7015
Validation loss decreased (0.235990 --> 0.171900).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7639636993408203
Epoch: 4, Steps: 37 Train Loss: 15.1599 (Forecasting Loss:0.1555 + XiCon Loss:1.5004 x Lambda(10.0)), Vali MSE Loss: 0.1341 Test MSE Loss: 0.7088
Validation loss decreased (0.171900 --> 0.134085).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7556412220001221
Epoch: 5, Steps: 37 Train Loss: 15.2304 (Forecasting Loss:0.1396 + XiCon Loss:1.5091 x Lambda(10.0)), Vali MSE Loss: 0.1384 Test MSE Loss: 0.7225
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7688908576965332
Epoch: 6, Steps: 37 Train Loss: 15.1265 (Forecasting Loss:0.1345 + XiCon Loss:1.4992 x Lambda(10.0)), Vali MSE Loss: 0.1342 Test MSE Loss: 0.7198
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7626771926879883
Epoch: 7, Steps: 37 Train Loss: 15.2346 (Forecasting Loss:0.1341 + XiCon Loss:1.5100 x Lambda(10.0)), Vali MSE Loss: 0.1322 Test MSE Loss: 0.7231
Validation loss decreased (0.134085 --> 0.132190).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7011239528656006
Epoch: 8, Steps: 37 Train Loss: 15.1757 (Forecasting Loss:0.1311 + XiCon Loss:1.5045 x Lambda(10.0)), Vali MSE Loss: 0.1339 Test MSE Loss: 0.7258
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.708021879196167
Epoch: 9, Steps: 37 Train Loss: 15.1386 (Forecasting Loss:0.1336 + XiCon Loss:1.5005 x Lambda(10.0)), Vali MSE Loss: 0.1331 Test MSE Loss: 0.7166
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.8047313690185547
Epoch: 10, Steps: 37 Train Loss: 15.2091 (Forecasting Loss:0.1314 + XiCon Loss:1.5078 x Lambda(10.0)), Vali MSE Loss: 0.1342 Test MSE Loss: 0.7156
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7378661632537842
Epoch: 11, Steps: 37 Train Loss: 15.2496 (Forecasting Loss:0.1309 + XiCon Loss:1.5119 x Lambda(10.0)), Vali MSE Loss: 0.1334 Test MSE Loss: 0.7143
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7724201679229736
Epoch: 12, Steps: 37 Train Loss: 15.1880 (Forecasting Loss:0.1310 + XiCon Loss:1.5057 x Lambda(10.0)), Vali MSE Loss: 0.1322 Test MSE Loss: 0.7144
Validation loss decreased (0.132190 --> 0.132158).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7984912395477295
Epoch: 13, Steps: 37 Train Loss: 15.2551 (Forecasting Loss:0.1309 + XiCon Loss:1.5124 x Lambda(10.0)), Vali MSE Loss: 0.1339 Test MSE Loss: 0.7142
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7165789604187012
Epoch: 14, Steps: 37 Train Loss: 15.1165 (Forecasting Loss:0.1310 + XiCon Loss:1.4985 x Lambda(10.0)), Vali MSE Loss: 0.1350 Test MSE Loss: 0.7141
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7482414245605469
Epoch: 15, Steps: 37 Train Loss: 15.1132 (Forecasting Loss:0.1310 + XiCon Loss:1.4982 x Lambda(10.0)), Vali MSE Loss: 0.1352 Test MSE Loss: 0.7140
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7219293117523193
Epoch: 16, Steps: 37 Train Loss: 15.2295 (Forecasting Loss:0.1318 + XiCon Loss:1.5098 x Lambda(10.0)), Vali MSE Loss: 0.1329 Test MSE Loss: 0.7140
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.661475658416748
Epoch: 17, Steps: 37 Train Loss: 15.2623 (Forecasting Loss:0.1305 + XiCon Loss:1.5132 x Lambda(10.0)), Vali MSE Loss: 0.1330 Test MSE Loss: 0.7139
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7792785167694092
Epoch: 18, Steps: 37 Train Loss: 15.1522 (Forecasting Loss:0.1303 + XiCon Loss:1.5022 x Lambda(10.0)), Vali MSE Loss: 0.1328 Test MSE Loss: 0.7139
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7672157287597656
Epoch: 19, Steps: 37 Train Loss: 15.2228 (Forecasting Loss:0.1317 + XiCon Loss:1.5091 x Lambda(10.0)), Vali MSE Loss: 0.1330 Test MSE Loss: 0.7139
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7423768043518066
Epoch: 20, Steps: 37 Train Loss: 15.1586 (Forecasting Loss:0.1298 + XiCon Loss:1.5029 x Lambda(10.0)), Vali MSE Loss: 0.1331 Test MSE Loss: 0.7139
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7485897541046143
Epoch: 21, Steps: 37 Train Loss: 15.2299 (Forecasting Loss:0.1307 + XiCon Loss:1.5099 x Lambda(10.0)), Vali MSE Loss: 0.1315 Test MSE Loss: 0.7139
Validation loss decreased (0.132158 --> 0.131508).  Saving model ...
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.745628833770752
Epoch: 22, Steps: 37 Train Loss: 15.1899 (Forecasting Loss:0.1303 + XiCon Loss:1.5060 x Lambda(10.0)), Vali MSE Loss: 0.1345 Test MSE Loss: 0.7139
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.775853157043457
Epoch: 23, Steps: 37 Train Loss: 15.2264 (Forecasting Loss:0.1301 + XiCon Loss:1.5096 x Lambda(10.0)), Vali MSE Loss: 0.1353 Test MSE Loss: 0.7139
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7703559398651123
Epoch: 24, Steps: 37 Train Loss: 15.2581 (Forecasting Loss:0.1310 + XiCon Loss:1.5127 x Lambda(10.0)), Vali MSE Loss: 0.1324 Test MSE Loss: 0.7139
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6908340454101562
Epoch: 25, Steps: 37 Train Loss: 15.2953 (Forecasting Loss:0.1298 + XiCon Loss:1.5165 x Lambda(10.0)), Vali MSE Loss: 0.1333 Test MSE Loss: 0.7139
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7106447219848633
Epoch: 26, Steps: 37 Train Loss: 15.1844 (Forecasting Loss:0.1305 + XiCon Loss:1.5054 x Lambda(10.0)), Vali MSE Loss: 0.1340 Test MSE Loss: 0.7139
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7574009895324707
Epoch: 27, Steps: 37 Train Loss: 15.1029 (Forecasting Loss:0.1293 + XiCon Loss:1.4974 x Lambda(10.0)), Vali MSE Loss: 0.1335 Test MSE Loss: 0.7139
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7111055850982666
Epoch: 28, Steps: 37 Train Loss: 15.1335 (Forecasting Loss:0.1307 + XiCon Loss:1.5003 x Lambda(10.0)), Vali MSE Loss: 0.1343 Test MSE Loss: 0.7139
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7808811664581299
Epoch: 29, Steps: 37 Train Loss: 15.1760 (Forecasting Loss:0.1302 + XiCon Loss:1.5046 x Lambda(10.0)), Vali MSE Loss: 0.1328 Test MSE Loss: 0.7139
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7246582508087158
Epoch: 30, Steps: 37 Train Loss: 15.1874 (Forecasting Loss:0.1307 + XiCon Loss:1.5057 x Lambda(10.0)), Vali MSE Loss: 0.1335 Test MSE Loss: 0.7139
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7476780414581299
Epoch: 31, Steps: 37 Train Loss: 15.1000 (Forecasting Loss:0.1307 + XiCon Loss:1.4969 x Lambda(10.0)), Vali MSE Loss: 0.1348 Test MSE Loss: 0.7139
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.783112108707428, mae:0.6447429060935974, mape:0.2515478730201721, mspe:0.21504755318164825 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7402+-0.03409, MAE:0.6264+-0.01523, MAPE:0.2461+-0.00416, MSPE:0.2050+-0.00847, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[56], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=56, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3605
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.9961137771606445
Epoch: 1, Steps: 35 Train Loss: 0.4884 (Forecasting Loss:0.4719 + XiCon Loss:1.6493 x Lambda(0.01)), Vali MSE Loss: 0.3099 Test MSE Loss: 1.1657
Validation loss decreased (inf --> 0.309899).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.679210901260376
Epoch: 2, Steps: 35 Train Loss: 0.3397 (Forecasting Loss:0.3231 + XiCon Loss:1.6529 x Lambda(0.01)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.7019
Validation loss decreased (0.309899 --> 0.195587).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6908187866210938
Epoch: 3, Steps: 35 Train Loss: 0.2232 (Forecasting Loss:0.2065 + XiCon Loss:1.6688 x Lambda(0.01)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.6318
Validation loss decreased (0.195587 --> 0.165198).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7275786399841309
Epoch: 4, Steps: 35 Train Loss: 0.1846 (Forecasting Loss:0.1679 + XiCon Loss:1.6719 x Lambda(0.01)), Vali MSE Loss: 0.1503 Test MSE Loss: 0.6840
Validation loss decreased (0.165198 --> 0.150314).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7077984809875488
Epoch: 5, Steps: 35 Train Loss: 0.1702 (Forecasting Loss:0.1535 + XiCon Loss:1.6726 x Lambda(0.01)), Vali MSE Loss: 0.1572 Test MSE Loss: 0.6733
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7272288799285889
Epoch: 6, Steps: 35 Train Loss: 0.1640 (Forecasting Loss:0.1473 + XiCon Loss:1.6715 x Lambda(0.01)), Vali MSE Loss: 0.1557 Test MSE Loss: 0.7178
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6645393371582031
Epoch: 7, Steps: 35 Train Loss: 0.1592 (Forecasting Loss:0.1425 + XiCon Loss:1.6702 x Lambda(0.01)), Vali MSE Loss: 0.1600 Test MSE Loss: 0.7025
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7606608867645264
Epoch: 8, Steps: 35 Train Loss: 0.1560 (Forecasting Loss:0.1393 + XiCon Loss:1.6705 x Lambda(0.01)), Vali MSE Loss: 0.1570 Test MSE Loss: 0.7089
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.9019360542297363
Epoch: 9, Steps: 35 Train Loss: 0.1566 (Forecasting Loss:0.1399 + XiCon Loss:1.6692 x Lambda(0.01)), Vali MSE Loss: 0.1594 Test MSE Loss: 0.7128
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.8375270366668701
Epoch: 10, Steps: 35 Train Loss: 0.1545 (Forecasting Loss:0.1378 + XiCon Loss:1.6686 x Lambda(0.01)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.7117
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6391856670379639
Epoch: 11, Steps: 35 Train Loss: 0.1523 (Forecasting Loss:0.1356 + XiCon Loss:1.6692 x Lambda(0.01)), Vali MSE Loss: 0.1602 Test MSE Loss: 0.7105
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 1.2118511199951172
Epoch: 12, Steps: 35 Train Loss: 0.1539 (Forecasting Loss:0.1372 + XiCon Loss:1.6707 x Lambda(0.01)), Vali MSE Loss: 0.1610 Test MSE Loss: 0.7107
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.915020227432251
Epoch: 13, Steps: 35 Train Loss: 0.1529 (Forecasting Loss:0.1363 + XiCon Loss:1.6687 x Lambda(0.01)), Vali MSE Loss: 0.1591 Test MSE Loss: 0.7110
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.8717172145843506
Epoch: 14, Steps: 35 Train Loss: 0.1521 (Forecasting Loss:0.1354 + XiCon Loss:1.6695 x Lambda(0.01)), Vali MSE Loss: 0.1593 Test MSE Loss: 0.7112
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6997620463371277, mae:0.6682707667350769, mape:0.25495097041130066, mspe:0.18116000294685364 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4637
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.8314497470855713
Epoch: 1, Steps: 35 Train Loss: 0.4713 (Forecasting Loss:0.4548 + XiCon Loss:1.6454 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 1.0039
Validation loss decreased (inf --> 0.324540).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.8283460140228271
Epoch: 2, Steps: 35 Train Loss: 0.3503 (Forecasting Loss:0.3336 + XiCon Loss:1.6725 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.7277
Validation loss decreased (0.324540 --> 0.192298).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6807498931884766
Epoch: 3, Steps: 35 Train Loss: 0.2380 (Forecasting Loss:0.2211 + XiCon Loss:1.6814 x Lambda(0.01)), Vali MSE Loss: 0.1412 Test MSE Loss: 0.7214
Validation loss decreased (0.192298 --> 0.141196).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8602495193481445
Epoch: 4, Steps: 35 Train Loss: 0.2025 (Forecasting Loss:0.1857 + XiCon Loss:1.6836 x Lambda(0.01)), Vali MSE Loss: 0.1351 Test MSE Loss: 0.6818
Validation loss decreased (0.141196 --> 0.135118).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.873680591583252
Epoch: 5, Steps: 35 Train Loss: 0.1941 (Forecasting Loss:0.1773 + XiCon Loss:1.6824 x Lambda(0.01)), Vali MSE Loss: 0.1331 Test MSE Loss: 0.6657
Validation loss decreased (0.135118 --> 0.133125).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.634279727935791
Epoch: 6, Steps: 35 Train Loss: 0.1909 (Forecasting Loss:0.1740 + XiCon Loss:1.6834 x Lambda(0.01)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6762
Validation loss decreased (0.133125 --> 0.130711).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.8046183586120605
Epoch: 7, Steps: 35 Train Loss: 0.1898 (Forecasting Loss:0.1729 + XiCon Loss:1.6840 x Lambda(0.01)), Vali MSE Loss: 0.1315 Test MSE Loss: 0.6760
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.691887617111206
Epoch: 8, Steps: 35 Train Loss: 0.1895 (Forecasting Loss:0.1727 + XiCon Loss:1.6839 x Lambda(0.01)), Vali MSE Loss: 0.1298 Test MSE Loss: 0.6753
Validation loss decreased (0.130711 --> 0.129774).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6945784091949463
Epoch: 9, Steps: 35 Train Loss: 0.1881 (Forecasting Loss:0.1713 + XiCon Loss:1.6834 x Lambda(0.01)), Vali MSE Loss: 0.1317 Test MSE Loss: 0.6763
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7297966480255127
Epoch: 10, Steps: 35 Train Loss: 0.1877 (Forecasting Loss:0.1709 + XiCon Loss:1.6829 x Lambda(0.01)), Vali MSE Loss: 0.1321 Test MSE Loss: 0.6750
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7159903049468994
Epoch: 11, Steps: 35 Train Loss: 0.1881 (Forecasting Loss:0.1713 + XiCon Loss:1.6837 x Lambda(0.01)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6749
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7197291851043701
Epoch: 12, Steps: 35 Train Loss: 0.1875 (Forecasting Loss:0.1707 + XiCon Loss:1.6827 x Lambda(0.01)), Vali MSE Loss: 0.1312 Test MSE Loss: 0.6747
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7371859550476074
Epoch: 13, Steps: 35 Train Loss: 0.1877 (Forecasting Loss:0.1709 + XiCon Loss:1.6828 x Lambda(0.01)), Vali MSE Loss: 0.1313 Test MSE Loss: 0.6747
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7062532901763916
Epoch: 14, Steps: 35 Train Loss: 0.1878 (Forecasting Loss:0.1709 + XiCon Loss:1.6840 x Lambda(0.01)), Vali MSE Loss: 0.1326 Test MSE Loss: 0.6746
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7149920463562012
Epoch: 15, Steps: 35 Train Loss: 0.1878 (Forecasting Loss:0.1710 + XiCon Loss:1.6838 x Lambda(0.01)), Vali MSE Loss: 0.1308 Test MSE Loss: 0.6746
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7029902935028076
Epoch: 16, Steps: 35 Train Loss: 0.1877 (Forecasting Loss:0.1708 + XiCon Loss:1.6838 x Lambda(0.01)), Vali MSE Loss: 0.1312 Test MSE Loss: 0.6746
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6595015525817871
Epoch: 17, Steps: 35 Train Loss: 0.1881 (Forecasting Loss:0.1713 + XiCon Loss:1.6831 x Lambda(0.01)), Vali MSE Loss: 0.1321 Test MSE Loss: 0.6746
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7309360504150391
Epoch: 18, Steps: 35 Train Loss: 0.1874 (Forecasting Loss:0.1706 + XiCon Loss:1.6826 x Lambda(0.01)), Vali MSE Loss: 0.1323 Test MSE Loss: 0.6746
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6882267594337463, mae:0.6623976230621338, mape:0.25715070962905884, mspe:0.18454347550868988 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4408
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7167503833770752
Epoch: 1, Steps: 35 Train Loss: 0.4911 (Forecasting Loss:0.4746 + XiCon Loss:1.6502 x Lambda(0.01)), Vali MSE Loss: 0.3309 Test MSE Loss: 1.0402
Validation loss decreased (inf --> 0.330949).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.67826247215271
Epoch: 2, Steps: 35 Train Loss: 0.3504 (Forecasting Loss:0.3336 + XiCon Loss:1.6734 x Lambda(0.01)), Vali MSE Loss: 0.1971 Test MSE Loss: 0.7454
Validation loss decreased (0.330949 --> 0.197124).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6939437389373779
Epoch: 3, Steps: 35 Train Loss: 0.2328 (Forecasting Loss:0.2160 + XiCon Loss:1.6822 x Lambda(0.01)), Vali MSE Loss: 0.1399 Test MSE Loss: 0.7000
Validation loss decreased (0.197124 --> 0.139906).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7077755928039551
Epoch: 4, Steps: 35 Train Loss: 0.2035 (Forecasting Loss:0.1867 + XiCon Loss:1.6818 x Lambda(0.01)), Vali MSE Loss: 0.1328 Test MSE Loss: 0.6926
Validation loss decreased (0.139906 --> 0.132795).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7147114276885986
Epoch: 5, Steps: 35 Train Loss: 0.1957 (Forecasting Loss:0.1789 + XiCon Loss:1.6818 x Lambda(0.01)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.6939
Validation loss decreased (0.132795 --> 0.130134).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6785686016082764
Epoch: 6, Steps: 35 Train Loss: 0.1933 (Forecasting Loss:0.1765 + XiCon Loss:1.6820 x Lambda(0.01)), Vali MSE Loss: 0.1312 Test MSE Loss: 0.6906
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7165818214416504
Epoch: 7, Steps: 35 Train Loss: 0.1922 (Forecasting Loss:0.1754 + XiCon Loss:1.6825 x Lambda(0.01)), Vali MSE Loss: 0.1313 Test MSE Loss: 0.6898
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7202122211456299
Epoch: 8, Steps: 35 Train Loss: 0.1916 (Forecasting Loss:0.1748 + XiCon Loss:1.6830 x Lambda(0.01)), Vali MSE Loss: 0.1285 Test MSE Loss: 0.6883
Validation loss decreased (0.130134 --> 0.128498).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7165110111236572
Epoch: 9, Steps: 35 Train Loss: 0.1913 (Forecasting Loss:0.1745 + XiCon Loss:1.6819 x Lambda(0.01)), Vali MSE Loss: 0.1305 Test MSE Loss: 0.6883
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6978580951690674
Epoch: 10, Steps: 35 Train Loss: 0.1912 (Forecasting Loss:0.1744 + XiCon Loss:1.6833 x Lambda(0.01)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6876
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7308223247528076
Epoch: 11, Steps: 35 Train Loss: 0.1911 (Forecasting Loss:0.1743 + XiCon Loss:1.6831 x Lambda(0.01)), Vali MSE Loss: 0.1312 Test MSE Loss: 0.6877
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6946539878845215
Epoch: 12, Steps: 35 Train Loss: 0.1911 (Forecasting Loss:0.1742 + XiCon Loss:1.6836 x Lambda(0.01)), Vali MSE Loss: 0.1305 Test MSE Loss: 0.6878
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6965305805206299
Epoch: 13, Steps: 35 Train Loss: 0.1910 (Forecasting Loss:0.1742 + XiCon Loss:1.6823 x Lambda(0.01)), Vali MSE Loss: 0.1297 Test MSE Loss: 0.6878
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6672756671905518
Epoch: 14, Steps: 35 Train Loss: 0.1910 (Forecasting Loss:0.1742 + XiCon Loss:1.6824 x Lambda(0.01)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6878
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6228106021881104
Epoch: 15, Steps: 35 Train Loss: 0.1910 (Forecasting Loss:0.1742 + XiCon Loss:1.6826 x Lambda(0.01)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6877
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6957859992980957
Epoch: 16, Steps: 35 Train Loss: 0.1910 (Forecasting Loss:0.1742 + XiCon Loss:1.6834 x Lambda(0.01)), Vali MSE Loss: 0.1299 Test MSE Loss: 0.6877
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6705460548400879
Epoch: 17, Steps: 35 Train Loss: 0.1910 (Forecasting Loss:0.1742 + XiCon Loss:1.6816 x Lambda(0.01)), Vali MSE Loss: 0.1311 Test MSE Loss: 0.6877
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7137892246246338
Epoch: 18, Steps: 35 Train Loss: 0.1910 (Forecasting Loss:0.1742 + XiCon Loss:1.6826 x Lambda(0.01)), Vali MSE Loss: 0.1296 Test MSE Loss: 0.6877
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7052050828933716, mae:0.671459972858429, mape:0.26000237464904785, mspe:0.1864038109779358 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4517
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7055554389953613
Epoch: 1, Steps: 35 Train Loss: 0.4927 (Forecasting Loss:0.4763 + XiCon Loss:1.6478 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 1.2037
Validation loss decreased (inf --> 0.316183).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7310934066772461
Epoch: 2, Steps: 35 Train Loss: 0.3396 (Forecasting Loss:0.3233 + XiCon Loss:1.6294 x Lambda(0.01)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.7893
Validation loss decreased (0.316183 --> 0.227372).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7076036930084229
Epoch: 3, Steps: 35 Train Loss: 0.2100 (Forecasting Loss:0.1935 + XiCon Loss:1.6428 x Lambda(0.01)), Vali MSE Loss: 0.1888 Test MSE Loss: 0.7301
Validation loss decreased (0.227372 --> 0.188799).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7006940841674805
Epoch: 4, Steps: 35 Train Loss: 0.1637 (Forecasting Loss:0.1474 + XiCon Loss:1.6363 x Lambda(0.01)), Vali MSE Loss: 0.1540 Test MSE Loss: 0.7338
Validation loss decreased (0.188799 --> 0.154039).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7206683158874512
Epoch: 5, Steps: 35 Train Loss: 0.1464 (Forecasting Loss:0.1302 + XiCon Loss:1.6231 x Lambda(0.01)), Vali MSE Loss: 0.1345 Test MSE Loss: 0.6881
Validation loss decreased (0.154039 --> 0.134541).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6949434280395508
Epoch: 6, Steps: 35 Train Loss: 0.1397 (Forecasting Loss:0.1233 + XiCon Loss:1.6406 x Lambda(0.01)), Vali MSE Loss: 0.1347 Test MSE Loss: 0.6462
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6909158229827881
Epoch: 7, Steps: 35 Train Loss: 0.1367 (Forecasting Loss:0.1204 + XiCon Loss:1.6316 x Lambda(0.01)), Vali MSE Loss: 0.1315 Test MSE Loss: 0.6589
Validation loss decreased (0.134541 --> 0.131518).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7010905742645264
Epoch: 8, Steps: 35 Train Loss: 0.1347 (Forecasting Loss:0.1183 + XiCon Loss:1.6372 x Lambda(0.01)), Vali MSE Loss: 0.1302 Test MSE Loss: 0.6584
Validation loss decreased (0.131518 --> 0.130202).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6958348751068115
Epoch: 9, Steps: 35 Train Loss: 0.1344 (Forecasting Loss:0.1182 + XiCon Loss:1.6215 x Lambda(0.01)), Vali MSE Loss: 0.1310 Test MSE Loss: 0.6564
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7106096744537354
Epoch: 10, Steps: 35 Train Loss: 0.1335 (Forecasting Loss:0.1172 + XiCon Loss:1.6290 x Lambda(0.01)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6562
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6694858074188232
Epoch: 11, Steps: 35 Train Loss: 0.1339 (Forecasting Loss:0.1175 + XiCon Loss:1.6353 x Lambda(0.01)), Vali MSE Loss: 0.1317 Test MSE Loss: 0.6570
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7196049690246582
Epoch: 12, Steps: 35 Train Loss: 0.1333 (Forecasting Loss:0.1169 + XiCon Loss:1.6369 x Lambda(0.01)), Vali MSE Loss: 0.1303 Test MSE Loss: 0.6574
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6444883346557617
Epoch: 13, Steps: 35 Train Loss: 0.1333 (Forecasting Loss:0.1170 + XiCon Loss:1.6306 x Lambda(0.01)), Vali MSE Loss: 0.1298 Test MSE Loss: 0.6576
Validation loss decreased (0.130202 --> 0.129796).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6541898250579834
Epoch: 14, Steps: 35 Train Loss: 0.1337 (Forecasting Loss:0.1174 + XiCon Loss:1.6307 x Lambda(0.01)), Vali MSE Loss: 0.1304 Test MSE Loss: 0.6576
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7100303173065186
Epoch: 15, Steps: 35 Train Loss: 0.1334 (Forecasting Loss:0.1171 + XiCon Loss:1.6303 x Lambda(0.01)), Vali MSE Loss: 0.1277 Test MSE Loss: 0.6575
Validation loss decreased (0.129796 --> 0.127710).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6809017658233643
Epoch: 16, Steps: 35 Train Loss: 0.1331 (Forecasting Loss:0.1167 + XiCon Loss:1.6356 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6575
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6974923610687256
Epoch: 17, Steps: 35 Train Loss: 0.1336 (Forecasting Loss:0.1172 + XiCon Loss:1.6360 x Lambda(0.01)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.6575
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7033629417419434
Epoch: 18, Steps: 35 Train Loss: 0.1329 (Forecasting Loss:0.1166 + XiCon Loss:1.6349 x Lambda(0.01)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6575
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6850922107696533
Epoch: 19, Steps: 35 Train Loss: 0.1334 (Forecasting Loss:0.1171 + XiCon Loss:1.6366 x Lambda(0.01)), Vali MSE Loss: 0.1295 Test MSE Loss: 0.6575
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7094736099243164
Epoch: 20, Steps: 35 Train Loss: 0.1334 (Forecasting Loss:0.1170 + XiCon Loss:1.6342 x Lambda(0.01)), Vali MSE Loss: 0.1305 Test MSE Loss: 0.6575
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7064497470855713
Epoch: 21, Steps: 35 Train Loss: 0.1333 (Forecasting Loss:0.1171 + XiCon Loss:1.6277 x Lambda(0.01)), Vali MSE Loss: 0.1314 Test MSE Loss: 0.6575
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.656050443649292
Epoch: 22, Steps: 35 Train Loss: 0.1332 (Forecasting Loss:0.1169 + XiCon Loss:1.6314 x Lambda(0.01)), Vali MSE Loss: 0.1294 Test MSE Loss: 0.6575
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7143363952636719
Epoch: 23, Steps: 35 Train Loss: 0.1333 (Forecasting Loss:0.1170 + XiCon Loss:1.6302 x Lambda(0.01)), Vali MSE Loss: 0.1303 Test MSE Loss: 0.6575
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7116029262542725
Epoch: 24, Steps: 35 Train Loss: 0.1333 (Forecasting Loss:0.1169 + XiCon Loss:1.6347 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6575
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7029578685760498
Epoch: 25, Steps: 35 Train Loss: 0.1333 (Forecasting Loss:0.1170 + XiCon Loss:1.6281 x Lambda(0.01)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6575
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6693726778030396, mae:0.6456719040870667, mape:0.2450520247220993, mspe:0.1702926903963089 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4257
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.704174280166626
Epoch: 1, Steps: 35 Train Loss: 0.4982 (Forecasting Loss:0.4816 + XiCon Loss:1.6525 x Lambda(0.01)), Vali MSE Loss: 0.3479 Test MSE Loss: 1.1382
Validation loss decreased (inf --> 0.347892).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6645603179931641
Epoch: 2, Steps: 35 Train Loss: 0.3579 (Forecasting Loss:0.3413 + XiCon Loss:1.6602 x Lambda(0.01)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.7235
Validation loss decreased (0.347892 --> 0.200660).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7386713027954102
Epoch: 3, Steps: 35 Train Loss: 0.2317 (Forecasting Loss:0.2150 + XiCon Loss:1.6711 x Lambda(0.01)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.6895
Validation loss decreased (0.200660 --> 0.162762).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6963541507720947
Epoch: 4, Steps: 35 Train Loss: 0.1909 (Forecasting Loss:0.1743 + XiCon Loss:1.6634 x Lambda(0.01)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.7157
Validation loss decreased (0.162762 --> 0.143618).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6195039749145508
Epoch: 5, Steps: 35 Train Loss: 0.1820 (Forecasting Loss:0.1654 + XiCon Loss:1.6643 x Lambda(0.01)), Vali MSE Loss: 0.1398 Test MSE Loss: 0.7094
Validation loss decreased (0.143618 --> 0.139769).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7123303413391113
Epoch: 6, Steps: 35 Train Loss: 0.1713 (Forecasting Loss:0.1547 + XiCon Loss:1.6665 x Lambda(0.01)), Vali MSE Loss: 0.1518 Test MSE Loss: 0.6853
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6825194358825684
Epoch: 7, Steps: 35 Train Loss: 0.1642 (Forecasting Loss:0.1475 + XiCon Loss:1.6662 x Lambda(0.01)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.7088
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6918187141418457
Epoch: 8, Steps: 35 Train Loss: 0.1608 (Forecasting Loss:0.1442 + XiCon Loss:1.6653 x Lambda(0.01)), Vali MSE Loss: 0.1452 Test MSE Loss: 0.7015
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7385485172271729
Epoch: 9, Steps: 35 Train Loss: 0.1596 (Forecasting Loss:0.1429 + XiCon Loss:1.6607 x Lambda(0.01)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.7057
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6756157875061035
Epoch: 10, Steps: 35 Train Loss: 0.1588 (Forecasting Loss:0.1422 + XiCon Loss:1.6601 x Lambda(0.01)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.7088
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.745002269744873
Epoch: 11, Steps: 35 Train Loss: 0.1574 (Forecasting Loss:0.1408 + XiCon Loss:1.6613 x Lambda(0.01)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.7100
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7300527095794678
Epoch: 12, Steps: 35 Train Loss: 0.1578 (Forecasting Loss:0.1412 + XiCon Loss:1.6597 x Lambda(0.01)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.7106
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6904735565185547
Epoch: 13, Steps: 35 Train Loss: 0.1574 (Forecasting Loss:0.1408 + XiCon Loss:1.6589 x Lambda(0.01)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.7107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7188975811004639
Epoch: 14, Steps: 35 Train Loss: 0.1570 (Forecasting Loss:0.1403 + XiCon Loss:1.6645 x Lambda(0.01)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.7107
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6880970001220703
Epoch: 15, Steps: 35 Train Loss: 0.1574 (Forecasting Loss:0.1408 + XiCon Loss:1.6655 x Lambda(0.01)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.7109
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7298860549926758, mae:0.6888379454612732, mape:0.2599942684173584, mspe:0.17702773213386536 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6985+-0.02766, MAE:0.6673+-0.01937, MAPE:0.2554+-0.00767, MSPE:0.1799+-0.00800, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[112], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=112, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3555
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.9446554183959961
Epoch: 1, Steps: 30 Train Loss: 0.7997 (Forecasting Loss:0.6351 + XiCon Loss:1.6459 x Lambda(0.1)), Vali MSE Loss: 0.4249 Test MSE Loss: 1.5909
Validation loss decreased (inf --> 0.424901).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6580691337585449
Epoch: 2, Steps: 30 Train Loss: 0.5869 (Forecasting Loss:0.4266 + XiCon Loss:1.6023 x Lambda(0.1)), Vali MSE Loss: 0.3498 Test MSE Loss: 1.0731
Validation loss decreased (0.424901 --> 0.349813).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6522824764251709
Epoch: 3, Steps: 30 Train Loss: 0.4215 (Forecasting Loss:0.2660 + XiCon Loss:1.5552 x Lambda(0.1)), Vali MSE Loss: 0.2900 Test MSE Loss: 1.1280
Validation loss decreased (0.349813 --> 0.290012).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5419352054595947
Epoch: 4, Steps: 30 Train Loss: 0.3827 (Forecasting Loss:0.2276 + XiCon Loss:1.5511 x Lambda(0.1)), Vali MSE Loss: 0.3284 Test MSE Loss: 1.1381
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.638404130935669
Epoch: 5, Steps: 30 Train Loss: 0.3542 (Forecasting Loss:0.2020 + XiCon Loss:1.5217 x Lambda(0.1)), Vali MSE Loss: 0.4011 Test MSE Loss: 0.9537
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6174402236938477
Epoch: 6, Steps: 30 Train Loss: 0.3457 (Forecasting Loss:0.1928 + XiCon Loss:1.5292 x Lambda(0.1)), Vali MSE Loss: 0.4210 Test MSE Loss: 0.9214
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6712162494659424
Epoch: 7, Steps: 30 Train Loss: 0.3397 (Forecasting Loss:0.1881 + XiCon Loss:1.5159 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 1.0673
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6545138359069824
Epoch: 8, Steps: 30 Train Loss: 0.3355 (Forecasting Loss:0.1834 + XiCon Loss:1.5210 x Lambda(0.1)), Vali MSE Loss: 0.3691 Test MSE Loss: 1.0144
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6275379657745361
Epoch: 9, Steps: 30 Train Loss: 0.3345 (Forecasting Loss:0.1822 + XiCon Loss:1.5232 x Lambda(0.1)), Vali MSE Loss: 0.3680 Test MSE Loss: 1.0057
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6227636337280273
Epoch: 10, Steps: 30 Train Loss: 0.3331 (Forecasting Loss:0.1811 + XiCon Loss:1.5198 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 1.0136
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6875402927398682
Epoch: 11, Steps: 30 Train Loss: 0.3332 (Forecasting Loss:0.1812 + XiCon Loss:1.5193 x Lambda(0.1)), Vali MSE Loss: 0.3591 Test MSE Loss: 1.0242
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6087753772735596
Epoch: 12, Steps: 30 Train Loss: 0.3326 (Forecasting Loss:0.1803 + XiCon Loss:1.5233 x Lambda(0.1)), Vali MSE Loss: 0.3581 Test MSE Loss: 1.0214
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5542619228363037
Epoch: 13, Steps: 30 Train Loss: 0.3322 (Forecasting Loss:0.1806 + XiCon Loss:1.5161 x Lambda(0.1)), Vali MSE Loss: 0.3564 Test MSE Loss: 1.0211
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.2680554389953613, mae:0.9879503846168518, mape:0.31946009397506714, mspe:0.14167505502700806 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4530
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6327285766601562
Epoch: 1, Steps: 30 Train Loss: 0.7373 (Forecasting Loss:0.5727 + XiCon Loss:1.6466 x Lambda(0.1)), Vali MSE Loss: 0.3363 Test MSE Loss: 1.7675
Validation loss decreased (inf --> 0.336290).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6157686710357666
Epoch: 2, Steps: 30 Train Loss: 0.5761 (Forecasting Loss:0.4144 + XiCon Loss:1.6170 x Lambda(0.1)), Vali MSE Loss: 0.3676 Test MSE Loss: 1.0971
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6432907581329346
Epoch: 3, Steps: 30 Train Loss: 0.3868 (Forecasting Loss:0.2289 + XiCon Loss:1.5786 x Lambda(0.1)), Vali MSE Loss: 0.3151 Test MSE Loss: 1.0359
Validation loss decreased (0.336290 --> 0.315094).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6302950382232666
Epoch: 4, Steps: 30 Train Loss: 0.3385 (Forecasting Loss:0.1854 + XiCon Loss:1.5308 x Lambda(0.1)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.9783
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6246819496154785
Epoch: 5, Steps: 30 Train Loss: 0.3156 (Forecasting Loss:0.1633 + XiCon Loss:1.5232 x Lambda(0.1)), Vali MSE Loss: 0.2343 Test MSE Loss: 1.0126
Validation loss decreased (0.315094 --> 0.234252).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6391167640686035
Epoch: 6, Steps: 30 Train Loss: 0.3040 (Forecasting Loss:0.1524 + XiCon Loss:1.5156 x Lambda(0.1)), Vali MSE Loss: 0.2753 Test MSE Loss: 0.9548
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6546401977539062
Epoch: 7, Steps: 30 Train Loss: 0.2984 (Forecasting Loss:0.1470 + XiCon Loss:1.5133 x Lambda(0.1)), Vali MSE Loss: 0.2671 Test MSE Loss: 0.9418
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6047956943511963
Epoch: 8, Steps: 30 Train Loss: 0.2934 (Forecasting Loss:0.1432 + XiCon Loss:1.5018 x Lambda(0.1)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.9570
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5822386741638184
Epoch: 9, Steps: 30 Train Loss: 0.2929 (Forecasting Loss:0.1425 + XiCon Loss:1.5041 x Lambda(0.1)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.9233
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6486876010894775
Epoch: 10, Steps: 30 Train Loss: 0.2914 (Forecasting Loss:0.1411 + XiCon Loss:1.5034 x Lambda(0.1)), Vali MSE Loss: 0.2639 Test MSE Loss: 0.9332
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6485519409179688
Epoch: 11, Steps: 30 Train Loss: 0.2914 (Forecasting Loss:0.1408 + XiCon Loss:1.5056 x Lambda(0.1)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.9391
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6442651748657227
Epoch: 12, Steps: 30 Train Loss: 0.2913 (Forecasting Loss:0.1410 + XiCon Loss:1.5033 x Lambda(0.1)), Vali MSE Loss: 0.2688 Test MSE Loss: 0.9340
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6302132606506348
Epoch: 13, Steps: 30 Train Loss: 0.2907 (Forecasting Loss:0.1408 + XiCon Loss:1.4983 x Lambda(0.1)), Vali MSE Loss: 0.2630 Test MSE Loss: 0.9341
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6897008419036865
Epoch: 14, Steps: 30 Train Loss: 0.2911 (Forecasting Loss:0.1411 + XiCon Loss:1.4992 x Lambda(0.1)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.9339
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6744675636291504
Epoch: 15, Steps: 30 Train Loss: 0.2933 (Forecasting Loss:0.1417 + XiCon Loss:1.5159 x Lambda(0.1)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.9340
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.1081444025039673, mae:0.9170222282409668, mape:0.2996579110622406, mspe:0.13652604818344116 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4394
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6599380970001221
Epoch: 1, Steps: 30 Train Loss: 0.7718 (Forecasting Loss:0.6078 + XiCon Loss:1.6406 x Lambda(0.1)), Vali MSE Loss: 0.3569 Test MSE Loss: 1.7841
Validation loss decreased (inf --> 0.356883).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6248941421508789
Epoch: 2, Steps: 30 Train Loss: 0.5780 (Forecasting Loss:0.4123 + XiCon Loss:1.6576 x Lambda(0.1)), Vali MSE Loss: 0.2676 Test MSE Loss: 1.2373
Validation loss decreased (0.356883 --> 0.267592).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6344289779663086
Epoch: 3, Steps: 30 Train Loss: 0.4034 (Forecasting Loss:0.2366 + XiCon Loss:1.6674 x Lambda(0.1)), Vali MSE Loss: 0.4024 Test MSE Loss: 0.9528
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6223561763763428
Epoch: 4, Steps: 30 Train Loss: 0.3705 (Forecasting Loss:0.2044 + XiCon Loss:1.6605 x Lambda(0.1)), Vali MSE Loss: 0.2761 Test MSE Loss: 1.0766
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6177847385406494
Epoch: 5, Steps: 30 Train Loss: 0.3490 (Forecasting Loss:0.1841 + XiCon Loss:1.6493 x Lambda(0.1)), Vali MSE Loss: 0.3295 Test MSE Loss: 1.0107
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6481859683990479
Epoch: 6, Steps: 30 Train Loss: 0.3391 (Forecasting Loss:0.1750 + XiCon Loss:1.6405 x Lambda(0.1)), Vali MSE Loss: 0.3432 Test MSE Loss: 1.0413
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6226415634155273
Epoch: 7, Steps: 30 Train Loss: 0.3301 (Forecasting Loss:0.1677 + XiCon Loss:1.6245 x Lambda(0.1)), Vali MSE Loss: 0.3403 Test MSE Loss: 1.0065
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6609632968902588
Epoch: 8, Steps: 30 Train Loss: 0.3251 (Forecasting Loss:0.1625 + XiCon Loss:1.6254 x Lambda(0.1)), Vali MSE Loss: 0.3594 Test MSE Loss: 0.9677
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6677963733673096
Epoch: 9, Steps: 30 Train Loss: 0.3219 (Forecasting Loss:0.1582 + XiCon Loss:1.6371 x Lambda(0.1)), Vali MSE Loss: 0.3827 Test MSE Loss: 0.9663
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6302216053009033
Epoch: 10, Steps: 30 Train Loss: 0.3211 (Forecasting Loss:0.1576 + XiCon Loss:1.6353 x Lambda(0.1)), Vali MSE Loss: 0.3618 Test MSE Loss: 0.9823
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6376845836639404
Epoch: 11, Steps: 30 Train Loss: 0.3207 (Forecasting Loss:0.1563 + XiCon Loss:1.6440 x Lambda(0.1)), Vali MSE Loss: 0.3668 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6673233509063721
Epoch: 12, Steps: 30 Train Loss: 0.3211 (Forecasting Loss:0.1573 + XiCon Loss:1.6374 x Lambda(0.1)), Vali MSE Loss: 0.3803 Test MSE Loss: 0.9777
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.456840991973877, mae:1.0178542137145996, mape:0.3264903128147125, mspe:0.1593342423439026 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4470
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6532571315765381
Epoch: 1, Steps: 30 Train Loss: 0.7422 (Forecasting Loss:0.5777 + XiCon Loss:1.6455 x Lambda(0.1)), Vali MSE Loss: 0.4625 Test MSE Loss: 1.5571
Validation loss decreased (inf --> 0.462534).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6574718952178955
Epoch: 2, Steps: 30 Train Loss: 0.6595 (Forecasting Loss:0.4969 + XiCon Loss:1.6263 x Lambda(0.1)), Vali MSE Loss: 0.2894 Test MSE Loss: 1.0259
Validation loss decreased (0.462534 --> 0.289375).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.65708327293396
Epoch: 3, Steps: 30 Train Loss: 0.4632 (Forecasting Loss:0.3027 + XiCon Loss:1.6048 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.9938
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.654170036315918
Epoch: 4, Steps: 30 Train Loss: 0.4096 (Forecasting Loss:0.2510 + XiCon Loss:1.5857 x Lambda(0.1)), Vali MSE Loss: 0.2552 Test MSE Loss: 1.1177
Validation loss decreased (0.289375 --> 0.255227).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6296899318695068
Epoch: 5, Steps: 30 Train Loss: 0.3861 (Forecasting Loss:0.2281 + XiCon Loss:1.5803 x Lambda(0.1)), Vali MSE Loss: 0.3262 Test MSE Loss: 1.0251
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6390724182128906
Epoch: 6, Steps: 30 Train Loss: 0.3778 (Forecasting Loss:0.2217 + XiCon Loss:1.5614 x Lambda(0.1)), Vali MSE Loss: 0.2631 Test MSE Loss: 1.1443
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6493737697601318
Epoch: 7, Steps: 30 Train Loss: 0.3709 (Forecasting Loss:0.2155 + XiCon Loss:1.5542 x Lambda(0.1)), Vali MSE Loss: 0.3052 Test MSE Loss: 1.0721
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6862874031066895
Epoch: 8, Steps: 30 Train Loss: 0.3687 (Forecasting Loss:0.2140 + XiCon Loss:1.5472 x Lambda(0.1)), Vali MSE Loss: 0.2993 Test MSE Loss: 1.0845
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6971480846405029
Epoch: 9, Steps: 30 Train Loss: 0.3675 (Forecasting Loss:0.2127 + XiCon Loss:1.5488 x Lambda(0.1)), Vali MSE Loss: 0.3104 Test MSE Loss: 1.0874
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6393308639526367
Epoch: 10, Steps: 30 Train Loss: 0.3644 (Forecasting Loss:0.2098 + XiCon Loss:1.5462 x Lambda(0.1)), Vali MSE Loss: 0.3087 Test MSE Loss: 1.0849
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6455168724060059
Epoch: 11, Steps: 30 Train Loss: 0.3647 (Forecasting Loss:0.2103 + XiCon Loss:1.5434 x Lambda(0.1)), Vali MSE Loss: 0.3046 Test MSE Loss: 1.0856
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6229791641235352
Epoch: 12, Steps: 30 Train Loss: 0.3650 (Forecasting Loss:0.2099 + XiCon Loss:1.5507 x Lambda(0.1)), Vali MSE Loss: 0.2984 Test MSE Loss: 1.0853
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.635655403137207
Epoch: 13, Steps: 30 Train Loss: 0.3642 (Forecasting Loss:0.2093 + XiCon Loss:1.5486 x Lambda(0.1)), Vali MSE Loss: 0.3043 Test MSE Loss: 1.0850
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6719715595245361
Epoch: 14, Steps: 30 Train Loss: 0.3638 (Forecasting Loss:0.2097 + XiCon Loss:1.5407 x Lambda(0.1)), Vali MSE Loss: 0.2959 Test MSE Loss: 1.0849
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.252297282218933, mae:0.983132004737854, mape:0.3190805912017822, mspe:0.1436053365468979 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4527
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6267619132995605
Epoch: 1, Steps: 30 Train Loss: 0.7906 (Forecasting Loss:0.6268 + XiCon Loss:1.6378 x Lambda(0.1)), Vali MSE Loss: 0.3906 Test MSE Loss: 1.6310
Validation loss decreased (inf --> 0.390563).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6301229000091553
Epoch: 2, Steps: 30 Train Loss: 0.5767 (Forecasting Loss:0.4152 + XiCon Loss:1.6146 x Lambda(0.1)), Vali MSE Loss: 0.3710 Test MSE Loss: 1.0536
Validation loss decreased (0.390563 --> 0.370984).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6914677619934082
Epoch: 3, Steps: 30 Train Loss: 0.4145 (Forecasting Loss:0.2576 + XiCon Loss:1.5688 x Lambda(0.1)), Vali MSE Loss: 0.3891 Test MSE Loss: 1.0478
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6008615493774414
Epoch: 4, Steps: 30 Train Loss: 0.3591 (Forecasting Loss:0.2062 + XiCon Loss:1.5290 x Lambda(0.1)), Vali MSE Loss: 0.2529 Test MSE Loss: 1.1766
Validation loss decreased (0.370984 --> 0.252851).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6482057571411133
Epoch: 5, Steps: 30 Train Loss: 0.3345 (Forecasting Loss:0.1834 + XiCon Loss:1.5110 x Lambda(0.1)), Vali MSE Loss: 0.2416 Test MSE Loss: 1.1317
Validation loss decreased (0.252851 --> 0.241646).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6465532779693604
Epoch: 6, Steps: 30 Train Loss: 0.3238 (Forecasting Loss:0.1722 + XiCon Loss:1.5157 x Lambda(0.1)), Vali MSE Loss: 0.2665 Test MSE Loss: 1.0771
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6219110488891602
Epoch: 7, Steps: 30 Train Loss: 0.3170 (Forecasting Loss:0.1664 + XiCon Loss:1.5067 x Lambda(0.1)), Vali MSE Loss: 0.2568 Test MSE Loss: 1.0598
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6303596496582031
Epoch: 8, Steps: 30 Train Loss: 0.3129 (Forecasting Loss:0.1621 + XiCon Loss:1.5075 x Lambda(0.1)), Vali MSE Loss: 0.2633 Test MSE Loss: 1.0314
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6589572429656982
Epoch: 9, Steps: 30 Train Loss: 0.3125 (Forecasting Loss:0.1614 + XiCon Loss:1.5102 x Lambda(0.1)), Vali MSE Loss: 0.2537 Test MSE Loss: 1.0641
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.633638858795166
Epoch: 10, Steps: 30 Train Loss: 0.3128 (Forecasting Loss:0.1613 + XiCon Loss:1.5148 x Lambda(0.1)), Vali MSE Loss: 0.2621 Test MSE Loss: 1.0472
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6479897499084473
Epoch: 11, Steps: 30 Train Loss: 0.3104 (Forecasting Loss:0.1594 + XiCon Loss:1.5101 x Lambda(0.1)), Vali MSE Loss: 0.2631 Test MSE Loss: 1.0471
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6313927173614502
Epoch: 12, Steps: 30 Train Loss: 0.3108 (Forecasting Loss:0.1594 + XiCon Loss:1.5147 x Lambda(0.1)), Vali MSE Loss: 0.2687 Test MSE Loss: 1.0477
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6135509014129639
Epoch: 13, Steps: 30 Train Loss: 0.3100 (Forecasting Loss:0.1600 + XiCon Loss:1.5000 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 1.0478
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6080377101898193
Epoch: 14, Steps: 30 Train Loss: 0.3101 (Forecasting Loss:0.1588 + XiCon Loss:1.5131 x Lambda(0.1)), Vali MSE Loss: 0.2562 Test MSE Loss: 1.0474
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6220765113830566
Epoch: 15, Steps: 30 Train Loss: 0.3108 (Forecasting Loss:0.1587 + XiCon Loss:1.5216 x Lambda(0.1)), Vali MSE Loss: 0.2560 Test MSE Loss: 1.0482
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.2755711078643799, mae:0.9878767728805542, mape:0.317501962184906, mspe:0.14048327505588531 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.2722+-0.15388, MAE:0.9788+-0.04615, MAPE:0.3164+-0.01241, MSPE:0.1443+-0.01090, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
