Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7967
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3180280
	speed: 0.0357s/iter; left time: 453.7097s
Epoch: 1 cost time: 4.317825078964233
Epoch: 1, Steps: 128 Train Loss: 3.3407 (Forecasting Loss:0.2444 + XiCon Loss:3.0963 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173681).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1650846
	speed: 0.0268s/iter; left time: 336.9752s
Epoch: 2 cost time: 3.2963180541992188
Epoch: 2, Steps: 128 Train Loss: 3.1645 (Forecasting Loss:0.2459 + XiCon Loss:2.9186 x Lambda(1.0)), Vali MSE Loss: 0.1763 Test MSE Loss: 0.1328
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0447204
	speed: 0.0247s/iter; left time: 307.9177s
Epoch: 3 cost time: 3.280562400817871
Epoch: 3, Steps: 128 Train Loss: 3.1557 (Forecasting Loss:0.2315 + XiCon Loss:2.9242 x Lambda(1.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1234
Validation loss decreased (0.173681 --> 0.168800).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0424340
	speed: 0.0246s/iter; left time: 302.5608s
Epoch: 4 cost time: 3.1447882652282715
Epoch: 4, Steps: 128 Train Loss: 3.0958 (Forecasting Loss:0.2223 + XiCon Loss:2.8736 x Lambda(1.0)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1159
Validation loss decreased (0.168800 --> 0.168300).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0649469
	speed: 0.0296s/iter; left time: 361.1539s
Epoch: 5 cost time: 3.452263832092285
Epoch: 5, Steps: 128 Train Loss: 3.0878 (Forecasting Loss:0.2171 + XiCon Loss:2.8707 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1164
Validation loss decreased (0.168300 --> 0.165616).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0661869
	speed: 0.0326s/iter; left time: 392.9492s
Epoch: 6 cost time: 3.896522045135498
Epoch: 6, Steps: 128 Train Loss: 3.0781 (Forecasting Loss:0.2155 + XiCon Loss:2.8626 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1152
Validation loss decreased (0.165616 --> 0.164502).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0734613
	speed: 0.0286s/iter; left time: 341.4056s
Epoch: 7 cost time: 3.6547200679779053
Epoch: 7, Steps: 128 Train Loss: 3.0665 (Forecasting Loss:0.2143 + XiCon Loss:2.8522 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1165
Validation loss decreased (0.164502 --> 0.163121).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0991349
	speed: 0.0282s/iter; left time: 333.2789s
Epoch: 8 cost time: 3.8564605712890625
Epoch: 8, Steps: 128 Train Loss: 3.0711 (Forecasting Loss:0.2140 + XiCon Loss:2.8571 x Lambda(1.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1160
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.2303095
	speed: 0.0243s/iter; left time: 283.9442s
Epoch: 9 cost time: 2.964290142059326
Epoch: 9, Steps: 128 Train Loss: 3.0643 (Forecasting Loss:0.2136 + XiCon Loss:2.8507 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0555234
	speed: 0.0220s/iter; left time: 253.8570s
Epoch: 10 cost time: 3.136230230331421
Epoch: 10, Steps: 128 Train Loss: 3.0667 (Forecasting Loss:0.2134 + XiCon Loss:2.8534 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0049913
	speed: 0.0254s/iter; left time: 290.2783s
Epoch: 11 cost time: 3.3058767318725586
Epoch: 11, Steps: 128 Train Loss: 3.0714 (Forecasting Loss:0.2133 + XiCon Loss:2.8582 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1156
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0392511
	speed: 0.0295s/iter; left time: 333.4511s
Epoch: 12 cost time: 3.5680625438690186
Epoch: 12, Steps: 128 Train Loss: 3.0602 (Forecasting Loss:0.2131 + XiCon Loss:2.8471 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1156
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1328528
	speed: 0.0313s/iter; left time: 349.8759s
Epoch: 13 cost time: 3.729588508605957
Epoch: 13, Steps: 128 Train Loss: 3.0668 (Forecasting Loss:0.2130 + XiCon Loss:2.8538 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1156
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0589502
	speed: 0.0297s/iter; left time: 327.7341s
Epoch: 14 cost time: 3.707343578338623
Epoch: 14, Steps: 128 Train Loss: 3.0626 (Forecasting Loss:0.2132 + XiCon Loss:2.8494 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1156
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0684700
	speed: 0.0268s/iter; left time: 292.0886s
Epoch: 15 cost time: 3.357964277267456
Epoch: 15, Steps: 128 Train Loss: 3.0667 (Forecasting Loss:0.2132 + XiCon Loss:2.8536 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1156
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0158985
	speed: 0.0223s/iter; left time: 240.4224s
Epoch: 16 cost time: 2.7648849487304688
Epoch: 16, Steps: 128 Train Loss: 3.0750 (Forecasting Loss:0.2132 + XiCon Loss:2.8618 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1156
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0068843
	speed: 0.0293s/iter; left time: 312.2948s
Epoch: 17 cost time: 3.6426706314086914
Epoch: 17, Steps: 128 Train Loss: 3.0592 (Forecasting Loss:0.2132 + XiCon Loss:2.8460 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1156
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05471761152148247, mae:0.17827840149402618, mape:0.14168128371238708, mspe:0.03753267973661423 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6986
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2712445
	speed: 0.0253s/iter; left time: 320.8877s
Epoch: 1 cost time: 3.115314483642578
Epoch: 1, Steps: 128 Train Loss: 3.3167 (Forecasting Loss:0.2417 + XiCon Loss:3.0751 x Lambda(1.0)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1215
Validation loss decreased (inf --> 0.173852).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1653695
	speed: 0.0422s/iter; left time: 530.0086s
Epoch: 2 cost time: 5.053129196166992
Epoch: 2, Steps: 128 Train Loss: 3.1310 (Forecasting Loss:0.2445 + XiCon Loss:2.8865 x Lambda(1.0)), Vali MSE Loss: 0.1793 Test MSE Loss: 0.1219
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2383914
	speed: 0.0369s/iter; left time: 459.6637s
Epoch: 3 cost time: 4.689065456390381
Epoch: 3, Steps: 128 Train Loss: 3.1629 (Forecasting Loss:0.2321 + XiCon Loss:2.9308 x Lambda(1.0)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1206
Validation loss decreased (0.173852 --> 0.168266).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1119909
	speed: 0.0375s/iter; left time: 462.4339s
Epoch: 4 cost time: 4.909626483917236
Epoch: 4, Steps: 128 Train Loss: 3.1389 (Forecasting Loss:0.2224 + XiCon Loss:2.9165 x Lambda(1.0)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0450170
	speed: 0.0286s/iter; left time: 348.4544s
Epoch: 5 cost time: 3.8692378997802734
Epoch: 5, Steps: 128 Train Loss: 3.0821 (Forecasting Loss:0.2167 + XiCon Loss:2.8654 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1151
Validation loss decreased (0.168266 --> 0.166600).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0330644
	speed: 0.0341s/iter; left time: 411.3422s
Epoch: 6 cost time: 4.374619007110596
Epoch: 6, Steps: 128 Train Loss: 3.0726 (Forecasting Loss:0.2131 + XiCon Loss:2.8595 x Lambda(1.0)), Vali MSE Loss: 0.1664 Test MSE Loss: 0.1156
Validation loss decreased (0.166600 --> 0.166414).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1074679
	speed: 0.0230s/iter; left time: 274.0062s
Epoch: 7 cost time: 2.7331221103668213
Epoch: 7, Steps: 128 Train Loss: 3.0615 (Forecasting Loss:0.2113 + XiCon Loss:2.8502 x Lambda(1.0)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1133
Validation loss decreased (0.166414 --> 0.165926).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1273775
	speed: 0.0191s/iter; left time: 226.0191s
Epoch: 8 cost time: 2.5157785415649414
Epoch: 8, Steps: 128 Train Loss: 3.0613 (Forecasting Loss:0.2101 + XiCon Loss:2.8512 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1138
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1221499
	speed: 0.0198s/iter; left time: 231.4540s
Epoch: 9 cost time: 2.456197500228882
Epoch: 9, Steps: 128 Train Loss: 3.0616 (Forecasting Loss:0.2096 + XiCon Loss:2.8520 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1137
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0547800
	speed: 0.0176s/iter; left time: 202.7650s
Epoch: 10 cost time: 2.3665220737457275
Epoch: 10, Steps: 128 Train Loss: 3.0585 (Forecasting Loss:0.2097 + XiCon Loss:2.8487 x Lambda(1.0)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1138
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1014142
	speed: 0.0271s/iter; left time: 309.6503s
Epoch: 11 cost time: 3.4180469512939453
Epoch: 11, Steps: 128 Train Loss: 3.0576 (Forecasting Loss:0.2096 + XiCon Loss:2.8479 x Lambda(1.0)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1138
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 2.9830542
	speed: 0.0293s/iter; left time: 331.4022s
Epoch: 12 cost time: 3.531888008117676
Epoch: 12, Steps: 128 Train Loss: 3.0595 (Forecasting Loss:0.2093 + XiCon Loss:2.8502 x Lambda(1.0)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1137
Validation loss decreased (0.165926 --> 0.165894).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0023866
	speed: 0.0312s/iter; left time: 348.3780s
Epoch: 13 cost time: 3.915712356567383
Epoch: 13, Steps: 128 Train Loss: 3.0605 (Forecasting Loss:0.2095 + XiCon Loss:2.8510 x Lambda(1.0)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1137
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 2.9979427
	speed: 0.0295s/iter; left time: 325.1811s
Epoch: 14 cost time: 3.7137186527252197
Epoch: 14, Steps: 128 Train Loss: 3.0493 (Forecasting Loss:0.2097 + XiCon Loss:2.8397 x Lambda(1.0)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1137
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0445039
	speed: 0.0296s/iter; left time: 322.7214s
Epoch: 15 cost time: 3.6018166542053223
Epoch: 15, Steps: 128 Train Loss: 3.0596 (Forecasting Loss:0.2093 + XiCon Loss:2.8503 x Lambda(1.0)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1137
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0963778
	speed: 0.0229s/iter; left time: 246.6957s
Epoch: 16 cost time: 2.937270164489746
Epoch: 16, Steps: 128 Train Loss: 3.0587 (Forecasting Loss:0.2093 + XiCon Loss:2.8493 x Lambda(1.0)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1137
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0653434
	speed: 0.0295s/iter; left time: 314.5623s
Epoch: 17 cost time: 3.606769561767578
Epoch: 17, Steps: 128 Train Loss: 3.0673 (Forecasting Loss:0.2094 + XiCon Loss:2.8579 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1137
Validation loss decreased (0.165894 --> 0.165621).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.0659680
	speed: 0.0289s/iter; left time: 303.7814s
Epoch: 18 cost time: 3.4758424758911133
Epoch: 18, Steps: 128 Train Loss: 3.0563 (Forecasting Loss:0.2096 + XiCon Loss:2.8467 x Lambda(1.0)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1137
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0105090
	speed: 0.0313s/iter; left time: 325.6983s
Epoch: 19 cost time: 3.7088329792022705
Epoch: 19, Steps: 128 Train Loss: 3.0530 (Forecasting Loss:0.2093 + XiCon Loss:2.8437 x Lambda(1.0)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1137
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1256189
	speed: 0.0275s/iter; left time: 281.9528s
Epoch: 20 cost time: 3.4240658283233643
Epoch: 20, Steps: 128 Train Loss: 3.0539 (Forecasting Loss:0.2093 + XiCon Loss:2.8446 x Lambda(1.0)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1137
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0311062
	speed: 0.0238s/iter; left time: 241.7505s
Epoch: 21 cost time: 3.0453600883483887
Epoch: 21, Steps: 128 Train Loss: 3.0603 (Forecasting Loss:0.2096 + XiCon Loss:2.8507 x Lambda(1.0)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1137
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1337817
	speed: 0.0266s/iter; left time: 266.5930s
Epoch: 22 cost time: 3.277341365814209
Epoch: 22, Steps: 128 Train Loss: 3.0597 (Forecasting Loss:0.2095 + XiCon Loss:2.8502 x Lambda(1.0)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1137
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0123348
	speed: 0.0338s/iter; left time: 334.4483s
Epoch: 23 cost time: 4.092768669128418
Epoch: 23, Steps: 128 Train Loss: 3.0571 (Forecasting Loss:0.2095 + XiCon Loss:2.8476 x Lambda(1.0)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1137
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0104945
	speed: 0.0295s/iter; left time: 287.4224s
Epoch: 24 cost time: 3.631925582885742
Epoch: 24, Steps: 128 Train Loss: 3.0510 (Forecasting Loss:0.2094 + XiCon Loss:2.8415 x Lambda(1.0)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1137
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0156505
	speed: 0.0273s/iter; left time: 263.1629s
Epoch: 25 cost time: 3.417379856109619
Epoch: 25, Steps: 128 Train Loss: 3.0605 (Forecasting Loss:0.2096 + XiCon Loss:2.8509 x Lambda(1.0)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1137
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0798907
	speed: 0.0235s/iter; left time: 223.3709s
Epoch: 26 cost time: 2.977222442626953
Epoch: 26, Steps: 128 Train Loss: 3.0593 (Forecasting Loss:0.2096 + XiCon Loss:2.8497 x Lambda(1.0)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1137
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0136859
	speed: 0.0267s/iter; left time: 250.3852s
Epoch: 27 cost time: 3.433347463607788
Epoch: 27, Steps: 128 Train Loss: 3.0585 (Forecasting Loss:0.2093 + XiCon Loss:2.8492 x Lambda(1.0)), Vali MSE Loss: 0.1658 Test MSE Loss: 0.1137
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05239889770746231, mae:0.1750316321849823, mape:0.14062969386577606, mspe:0.03828876465559006 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7698
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3114510
	speed: 0.0245s/iter; left time: 310.7775s
Epoch: 1 cost time: 3.220794916152954
Epoch: 1, Steps: 128 Train Loss: 3.3284 (Forecasting Loss:0.2455 + XiCon Loss:3.0829 x Lambda(1.0)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1235
Validation loss decreased (inf --> 0.173090).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1008844
	speed: 0.0295s/iter; left time: 370.5132s
Epoch: 2 cost time: 3.51991605758667
Epoch: 2, Steps: 128 Train Loss: 3.1480 (Forecasting Loss:0.2417 + XiCon Loss:2.9063 x Lambda(1.0)), Vali MSE Loss: 0.1769 Test MSE Loss: 0.1297
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1055727
	speed: 0.0322s/iter; left time: 401.0114s
Epoch: 3 cost time: 3.81086802482605
Epoch: 3, Steps: 128 Train Loss: 3.1090 (Forecasting Loss:0.2300 + XiCon Loss:2.8790 x Lambda(1.0)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1171
Validation loss decreased (0.173090 --> 0.171622).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0436506
	speed: 0.0308s/iter; left time: 379.2648s
Epoch: 4 cost time: 4.026697874069214
Epoch: 4, Steps: 128 Train Loss: 3.0834 (Forecasting Loss:0.2223 + XiCon Loss:2.8611 x Lambda(1.0)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1186
Validation loss decreased (0.171622 --> 0.167729).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1216590
	speed: 0.0266s/iter; left time: 324.0457s
Epoch: 5 cost time: 3.143470525741577
Epoch: 5, Steps: 128 Train Loss: 3.1045 (Forecasting Loss:0.2174 + XiCon Loss:2.8871 x Lambda(1.0)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1188
Validation loss decreased (0.167729 --> 0.165290).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2703929
	speed: 0.0236s/iter; left time: 284.3718s
Epoch: 6 cost time: 3.0962095260620117
Epoch: 6, Steps: 128 Train Loss: 3.2427 (Forecasting Loss:0.2156 + XiCon Loss:3.0271 x Lambda(1.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1167
Validation loss decreased (0.165290 --> 0.164373).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1693313
	speed: 0.0279s/iter; left time: 333.1059s
Epoch: 7 cost time: 3.2324154376983643
Epoch: 7, Steps: 128 Train Loss: 3.2176 (Forecasting Loss:0.2138 + XiCon Loss:3.0038 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1169
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1831148
	speed: 0.0351s/iter; left time: 414.5946s
Epoch: 8 cost time: 4.287040948867798
Epoch: 8, Steps: 128 Train Loss: 3.1987 (Forecasting Loss:0.2135 + XiCon Loss:2.9852 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1163
Validation loss decreased (0.164373 --> 0.164262).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1744931
	speed: 0.0331s/iter; left time: 386.6767s
Epoch: 9 cost time: 4.2687976360321045
Epoch: 9, Steps: 128 Train Loss: 3.1881 (Forecasting Loss:0.2128 + XiCon Loss:2.9752 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1163
Validation loss decreased (0.164262 --> 0.164124).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1997993
	speed: 0.0298s/iter; left time: 344.1881s
Epoch: 10 cost time: 3.817638635635376
Epoch: 10, Steps: 128 Train Loss: 3.1807 (Forecasting Loss:0.2128 + XiCon Loss:2.9678 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1164
Validation loss decreased (0.164124 --> 0.164055).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1191766
	speed: 0.0271s/iter; left time: 309.0689s
Epoch: 11 cost time: 3.6194849014282227
Epoch: 11, Steps: 128 Train Loss: 3.1819 (Forecasting Loss:0.2127 + XiCon Loss:2.9691 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1165
Validation loss decreased (0.164055 --> 0.163941).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1850605
	speed: 0.0336s/iter; left time: 379.1800s
Epoch: 12 cost time: 4.084758281707764
Epoch: 12, Steps: 128 Train Loss: 3.1845 (Forecasting Loss:0.2126 + XiCon Loss:2.9720 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1165
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1864133
	speed: 0.0380s/iter; left time: 424.0284s
Epoch: 13 cost time: 4.7773637771606445
Epoch: 13, Steps: 128 Train Loss: 3.1802 (Forecasting Loss:0.2128 + XiCon Loss:2.9674 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1164
Validation loss decreased (0.163941 --> 0.163870).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1208231
	speed: 0.0370s/iter; left time: 408.7669s
Epoch: 14 cost time: 4.524251937866211
Epoch: 14, Steps: 128 Train Loss: 3.1849 (Forecasting Loss:0.2129 + XiCon Loss:2.9720 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1164
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1388888
	speed: 0.0347s/iter; left time: 378.5952s
Epoch: 15 cost time: 4.474776983261108
Epoch: 15, Steps: 128 Train Loss: 3.1737 (Forecasting Loss:0.2126 + XiCon Loss:2.9611 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1164
Validation loss decreased (0.163870 --> 0.163721).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1800621
	speed: 0.0299s/iter; left time: 322.8113s
Epoch: 16 cost time: 3.6726224422454834
Epoch: 16, Steps: 128 Train Loss: 3.1849 (Forecasting Loss:0.2126 + XiCon Loss:2.9723 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1164
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.2538788
	speed: 0.0273s/iter; left time: 290.6959s
Epoch: 17 cost time: 3.261183977127075
Epoch: 17, Steps: 128 Train Loss: 3.1854 (Forecasting Loss:0.2126 + XiCon Loss:2.9728 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1164
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.3142431
	speed: 0.0308s/iter; left time: 323.8722s
Epoch: 18 cost time: 3.752800941467285
Epoch: 18, Steps: 128 Train Loss: 3.1869 (Forecasting Loss:0.2125 + XiCon Loss:2.9743 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1164
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1341360
	speed: 0.0316s/iter; left time: 328.5602s
Epoch: 19 cost time: 4.029388666152954
Epoch: 19, Steps: 128 Train Loss: 3.1818 (Forecasting Loss:0.2124 + XiCon Loss:2.9693 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1164
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0711427
	speed: 0.0263s/iter; left time: 270.3678s
Epoch: 20 cost time: 3.6443309783935547
Epoch: 20, Steps: 128 Train Loss: 3.1787 (Forecasting Loss:0.2126 + XiCon Loss:2.9660 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1164
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0564063
	speed: 0.0273s/iter; left time: 276.5111s
Epoch: 21 cost time: 3.402557611465454
Epoch: 21, Steps: 128 Train Loss: 3.1776 (Forecasting Loss:0.2128 + XiCon Loss:2.9648 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1164
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.2186196
	speed: 0.0280s/iter; left time: 280.2340s
Epoch: 22 cost time: 3.358444929122925
Epoch: 22, Steps: 128 Train Loss: 3.1876 (Forecasting Loss:0.2127 + XiCon Loss:2.9749 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1164
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1415236
	speed: 0.0303s/iter; left time: 299.1199s
Epoch: 23 cost time: 3.6508991718292236
Epoch: 23, Steps: 128 Train Loss: 3.1858 (Forecasting Loss:0.2126 + XiCon Loss:2.9733 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1164
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1654534
	speed: 0.0330s/iter; left time: 321.5643s
Epoch: 24 cost time: 4.052924633026123
Epoch: 24, Steps: 128 Train Loss: 3.1894 (Forecasting Loss:0.2127 + XiCon Loss:2.9766 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1164
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1609504
	speed: 0.0293s/iter; left time: 282.2071s
Epoch: 25 cost time: 3.6339476108551025
Epoch: 25, Steps: 128 Train Loss: 3.1861 (Forecasting Loss:0.2126 + XiCon Loss:2.9736 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1164
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05470911040902138, mae:0.17812325060367584, mape:0.14180316030979156, mspe:0.03804513439536095 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6496
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3091497
	speed: 0.0263s/iter; left time: 333.7589s
Epoch: 1 cost time: 3.279984951019287
Epoch: 1, Steps: 128 Train Loss: 3.3303 (Forecasting Loss:0.2453 + XiCon Loss:3.0850 x Lambda(1.0)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1222
Validation loss decreased (inf --> 0.172661).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2824719
	speed: 0.0289s/iter; left time: 363.5253s
Epoch: 2 cost time: 3.54921555519104
Epoch: 2, Steps: 128 Train Loss: 3.2515 (Forecasting Loss:0.2494 + XiCon Loss:3.0020 x Lambda(1.0)), Vali MSE Loss: 0.1799 Test MSE Loss: 0.1318
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2080901
	speed: 0.0273s/iter; left time: 340.1775s
Epoch: 3 cost time: 3.5972156524658203
Epoch: 3, Steps: 128 Train Loss: 3.1468 (Forecasting Loss:0.2302 + XiCon Loss:2.9165 x Lambda(1.0)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1235
Validation loss decreased (0.172661 --> 0.169669).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0752423
	speed: 0.0248s/iter; left time: 305.0960s
Epoch: 4 cost time: 3.310934066772461
Epoch: 4, Steps: 128 Train Loss: 3.0889 (Forecasting Loss:0.2216 + XiCon Loss:2.8672 x Lambda(1.0)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0224025
	speed: 0.0284s/iter; left time: 346.4155s
Epoch: 5 cost time: 3.6151862144470215
Epoch: 5, Steps: 128 Train Loss: 3.0784 (Forecasting Loss:0.2177 + XiCon Loss:2.8608 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1149
Validation loss decreased (0.169669 --> 0.165558).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0506585
	speed: 0.0273s/iter; left time: 328.7317s
Epoch: 6 cost time: 3.391768455505371
Epoch: 6, Steps: 128 Train Loss: 3.0758 (Forecasting Loss:0.2151 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1165
Validation loss decreased (0.165558 --> 0.164907).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0327501
	speed: 0.0290s/iter; left time: 345.8215s
Epoch: 7 cost time: 3.547945261001587
Epoch: 7, Steps: 128 Train Loss: 3.0767 (Forecasting Loss:0.2138 + XiCon Loss:2.8629 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
Validation loss decreased (0.164907 --> 0.163855).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0339115
	speed: 0.0300s/iter; left time: 354.6689s
Epoch: 8 cost time: 3.7221031188964844
Epoch: 8, Steps: 128 Train Loss: 3.0703 (Forecasting Loss:0.2131 + XiCon Loss:2.8572 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0020854
	speed: 0.0275s/iter; left time: 320.7159s
Epoch: 9 cost time: 3.439467191696167
Epoch: 9, Steps: 128 Train Loss: 3.0681 (Forecasting Loss:0.2128 + XiCon Loss:2.8553 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
Validation loss decreased (0.163855 --> 0.163623).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0471237
	speed: 0.0206s/iter; left time: 238.2243s
Epoch: 10 cost time: 2.754192352294922
Epoch: 10, Steps: 128 Train Loss: 3.0688 (Forecasting Loss:0.2127 + XiCon Loss:2.8561 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1158
Validation loss decreased (0.163623 --> 0.163498).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0574875
	speed: 0.0264s/iter; left time: 301.2347s
Epoch: 11 cost time: 3.2568094730377197
Epoch: 11, Steps: 128 Train Loss: 3.0640 (Forecasting Loss:0.2125 + XiCon Loss:2.8515 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0668783
	speed: 0.0282s/iter; left time: 317.9778s
Epoch: 12 cost time: 3.4750261306762695
Epoch: 12, Steps: 128 Train Loss: 3.0670 (Forecasting Loss:0.2122 + XiCon Loss:2.8547 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0769238
	speed: 0.0320s/iter; left time: 357.0710s
Epoch: 13 cost time: 3.8243954181671143
Epoch: 13, Steps: 128 Train Loss: 3.0669 (Forecasting Loss:0.2124 + XiCon Loss:2.8546 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0068641
	speed: 0.0246s/iter; left time: 271.7036s
Epoch: 14 cost time: 3.1325831413269043
Epoch: 14, Steps: 128 Train Loss: 3.0727 (Forecasting Loss:0.2124 + XiCon Loss:2.8602 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0097561
	speed: 0.0256s/iter; left time: 279.7812s
Epoch: 15 cost time: 3.170419931411743
Epoch: 15, Steps: 128 Train Loss: 3.0678 (Forecasting Loss:0.2126 + XiCon Loss:2.8552 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0758216
	speed: 0.0280s/iter; left time: 301.4529s
Epoch: 16 cost time: 3.478391647338867
Epoch: 16, Steps: 128 Train Loss: 3.0722 (Forecasting Loss:0.2126 + XiCon Loss:2.8595 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1159
Validation loss decreased (0.163498 --> 0.163467).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0828481
	speed: 0.0359s/iter; left time: 382.3899s
Epoch: 17 cost time: 4.396907567977905
Epoch: 17, Steps: 128 Train Loss: 3.0657 (Forecasting Loss:0.2124 + XiCon Loss:2.8534 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.2133436
	speed: 0.0317s/iter; left time: 334.1520s
Epoch: 18 cost time: 3.8640177249908447
Epoch: 18, Steps: 128 Train Loss: 3.0669 (Forecasting Loss:0.2125 + XiCon Loss:2.8543 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0312228
	speed: 0.0408s/iter; left time: 424.2023s
Epoch: 19 cost time: 5.1802356243133545
Epoch: 19, Steps: 128 Train Loss: 3.0611 (Forecasting Loss:0.2125 + XiCon Loss:2.8487 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0330789
	speed: 0.0367s/iter; left time: 376.4558s
Epoch: 20 cost time: 4.860576152801514
Epoch: 20, Steps: 128 Train Loss: 3.0654 (Forecasting Loss:0.2125 + XiCon Loss:2.8529 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1159
Validation loss decreased (0.163467 --> 0.163434).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0246565
	speed: 0.0275s/iter; left time: 278.9571s
Epoch: 21 cost time: 3.517899751663208
Epoch: 21, Steps: 128 Train Loss: 3.0642 (Forecasting Loss:0.2126 + XiCon Loss:2.8516 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0034254
	speed: 0.0369s/iter; left time: 369.7566s
Epoch: 22 cost time: 4.634150266647339
Epoch: 22, Steps: 128 Train Loss: 3.0696 (Forecasting Loss:0.2124 + XiCon Loss:2.8572 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2250261
	speed: 0.0352s/iter; left time: 348.2083s
Epoch: 23 cost time: 4.466084003448486
Epoch: 23, Steps: 128 Train Loss: 3.0653 (Forecasting Loss:0.2125 + XiCon Loss:2.8529 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0076680
	speed: 0.0279s/iter; left time: 272.5717s
Epoch: 24 cost time: 3.6067306995391846
Epoch: 24, Steps: 128 Train Loss: 3.0699 (Forecasting Loss:0.2125 + XiCon Loss:2.8574 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0166645
	speed: 0.0276s/iter; left time: 265.5965s
Epoch: 25 cost time: 3.6143269538879395
Epoch: 25, Steps: 128 Train Loss: 3.0703 (Forecasting Loss:0.2125 + XiCon Loss:2.8578 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 2.9976213
	speed: 0.0232s/iter; left time: 220.5932s
Epoch: 26 cost time: 3.096048593521118
Epoch: 26, Steps: 128 Train Loss: 3.0684 (Forecasting Loss:0.2125 + XiCon Loss:2.8559 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0448923
	speed: 0.0252s/iter; left time: 236.0691s
Epoch: 27 cost time: 3.032634735107422
Epoch: 27, Steps: 128 Train Loss: 3.0739 (Forecasting Loss:0.2125 + XiCon Loss:2.8614 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0209703
	speed: 0.0321s/iter; left time: 296.4083s
Epoch: 28 cost time: 3.8825438022613525
Epoch: 28, Steps: 128 Train Loss: 3.0680 (Forecasting Loss:0.2123 + XiCon Loss:2.8557 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1159
Validation loss decreased (0.163434 --> 0.163207).  Saving model ...
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0072126
	speed: 0.0300s/iter; left time: 273.6904s
Epoch: 29 cost time: 3.707329273223877
Epoch: 29, Steps: 128 Train Loss: 3.0651 (Forecasting Loss:0.2122 + XiCon Loss:2.8529 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.0685506
	speed: 0.0270s/iter; left time: 242.3333s
Epoch: 30 cost time: 3.597311496734619
Epoch: 30, Steps: 128 Train Loss: 3.0660 (Forecasting Loss:0.2125 + XiCon Loss:2.8535 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.0082641
	speed: 0.0253s/iter; left time: 224.1015s
Epoch: 31 cost time: 3.158630847930908
Epoch: 31, Steps: 128 Train Loss: 3.0705 (Forecasting Loss:0.2124 + XiCon Loss:2.8581 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0375109
	speed: 0.0238s/iter; left time: 207.6161s
Epoch: 32 cost time: 2.9982521533966064
Epoch: 32, Steps: 128 Train Loss: 3.0649 (Forecasting Loss:0.2124 + XiCon Loss:2.8525 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0686750
	speed: 0.0271s/iter; left time: 233.3424s
Epoch: 33 cost time: 3.2746379375457764
Epoch: 33, Steps: 128 Train Loss: 3.0700 (Forecasting Loss:0.2122 + XiCon Loss:2.8578 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0678916
	speed: 0.0305s/iter; left time: 258.8469s
Epoch: 34 cost time: 3.756218433380127
Epoch: 34, Steps: 128 Train Loss: 3.0673 (Forecasting Loss:0.2125 + XiCon Loss:2.8548 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1159
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.0207407
	speed: 0.0327s/iter; left time: 272.7889s
Epoch: 35 cost time: 3.943669557571411
Epoch: 35, Steps: 128 Train Loss: 3.0742 (Forecasting Loss:0.2126 + XiCon Loss:2.8617 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.1124353
	speed: 0.0333s/iter; left time: 273.9675s
Epoch: 36 cost time: 4.414745807647705
Epoch: 36, Steps: 128 Train Loss: 3.0634 (Forecasting Loss:0.2126 + XiCon Loss:2.8508 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1159
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.1599486
	speed: 0.0231s/iter; left time: 187.2244s
Epoch: 37 cost time: 3.2542147636413574
Epoch: 37, Steps: 128 Train Loss: 3.0645 (Forecasting Loss:0.2124 + XiCon Loss:2.8521 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1159
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.0388117
	speed: 0.0261s/iter; left time: 207.5849s
Epoch: 38 cost time: 3.3183441162109375
Epoch: 38, Steps: 128 Train Loss: 3.0634 (Forecasting Loss:0.2124 + XiCon Loss:2.8510 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1159
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05411500483751297, mae:0.17773106694221497, mape:0.14141547679901123, mspe:0.03729446232318878 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7549
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3271246
	speed: 0.0297s/iter; left time: 376.9635s
Epoch: 1 cost time: 3.734569787979126
Epoch: 1, Steps: 128 Train Loss: 3.3322 (Forecasting Loss:0.2453 + XiCon Loss:3.0869 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1239
Validation loss decreased (inf --> 0.175428).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1247077
	speed: 0.0301s/iter; left time: 379.0639s
Epoch: 2 cost time: 3.683223009109497
Epoch: 2, Steps: 128 Train Loss: 3.1770 (Forecasting Loss:0.2503 + XiCon Loss:2.9267 x Lambda(1.0)), Vali MSE Loss: 0.1761 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2496200
	speed: 0.0291s/iter; left time: 362.4066s
Epoch: 3 cost time: 3.780479907989502
Epoch: 3, Steps: 128 Train Loss: 3.2307 (Forecasting Loss:0.2291 + XiCon Loss:3.0016 x Lambda(1.0)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1201
Validation loss decreased (0.175428 --> 0.167802).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1664851
	speed: 0.0268s/iter; left time: 329.9857s
Epoch: 4 cost time: 3.165743827819824
Epoch: 4, Steps: 128 Train Loss: 3.2058 (Forecasting Loss:0.2210 + XiCon Loss:2.9848 x Lambda(1.0)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1171
Validation loss decreased (0.167802 --> 0.167683).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1092067
	speed: 0.0306s/iter; left time: 373.3031s
Epoch: 5 cost time: 3.6475019454956055
Epoch: 5, Steps: 128 Train Loss: 3.1795 (Forecasting Loss:0.2175 + XiCon Loss:2.9620 x Lambda(1.0)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1184
Validation loss decreased (0.167683 --> 0.165329).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2984953
	speed: 0.0279s/iter; left time: 337.0508s
Epoch: 6 cost time: 3.332339286804199
Epoch: 6, Steps: 128 Train Loss: 3.1647 (Forecasting Loss:0.2153 + XiCon Loss:2.9494 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
Validation loss decreased (0.165329 --> 0.163475).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2278571
	speed: 0.0308s/iter; left time: 367.4874s
Epoch: 7 cost time: 3.809978485107422
Epoch: 7, Steps: 128 Train Loss: 3.1662 (Forecasting Loss:0.2142 + XiCon Loss:2.9519 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1159
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1599176
	speed: 0.0242s/iter; left time: 285.8048s
Epoch: 8 cost time: 3.282013177871704
Epoch: 8, Steps: 128 Train Loss: 3.1550 (Forecasting Loss:0.2137 + XiCon Loss:2.9413 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0837207
	speed: 0.0251s/iter; left time: 292.8005s
Epoch: 9 cost time: 3.0771350860595703
Epoch: 9, Steps: 128 Train Loss: 3.1552 (Forecasting Loss:0.2134 + XiCon Loss:2.9418 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
Validation loss decreased (0.163475 --> 0.163427).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0489721
	speed: 0.0296s/iter; left time: 342.2408s
Epoch: 10 cost time: 3.5017426013946533
Epoch: 10, Steps: 128 Train Loss: 3.1541 (Forecasting Loss:0.2134 + XiCon Loss:2.9407 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
Validation loss decreased (0.163427 --> 0.163302).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1166255
	speed: 0.0272s/iter; left time: 311.1135s
Epoch: 11 cost time: 3.2857203483581543
Epoch: 11, Steps: 128 Train Loss: 3.1529 (Forecasting Loss:0.2133 + XiCon Loss:2.9396 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2331066
	speed: 0.0298s/iter; left time: 336.1496s
Epoch: 12 cost time: 3.6815578937530518
Epoch: 12, Steps: 128 Train Loss: 3.1555 (Forecasting Loss:0.2131 + XiCon Loss:2.9424 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.2297485
	speed: 0.0365s/iter; left time: 407.4970s
Epoch: 13 cost time: 4.826203107833862
Epoch: 13, Steps: 128 Train Loss: 3.1554 (Forecasting Loss:0.2132 + XiCon Loss:2.9423 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1954932
	speed: 0.0310s/iter; left time: 342.1733s
Epoch: 14 cost time: 3.826709032058716
Epoch: 14, Steps: 128 Train Loss: 3.1595 (Forecasting Loss:0.2131 + XiCon Loss:2.9464 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1152
Validation loss decreased (0.163302 --> 0.163175).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1204879
	speed: 0.0314s/iter; left time: 342.2105s
Epoch: 15 cost time: 3.957041025161743
Epoch: 15, Steps: 128 Train Loss: 3.1545 (Forecasting Loss:0.2132 + XiCon Loss:2.9413 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1667159
	speed: 0.0335s/iter; left time: 361.4085s
Epoch: 16 cost time: 4.14144492149353
Epoch: 16, Steps: 128 Train Loss: 3.1491 (Forecasting Loss:0.2131 + XiCon Loss:2.9360 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1152
Validation loss decreased (0.163175 --> 0.163079).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0964680
	speed: 0.0365s/iter; left time: 389.1860s
Epoch: 17 cost time: 4.585787534713745
Epoch: 17, Steps: 128 Train Loss: 3.1531 (Forecasting Loss:0.2131 + XiCon Loss:2.9401 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1422613
	speed: 0.0409s/iter; left time: 430.1313s
Epoch: 18 cost time: 4.918504953384399
Epoch: 18, Steps: 128 Train Loss: 3.1531 (Forecasting Loss:0.2131 + XiCon Loss:2.9400 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0872068
	speed: 0.0298s/iter; left time: 309.5840s
Epoch: 19 cost time: 3.950387716293335
Epoch: 19, Steps: 128 Train Loss: 3.1513 (Forecasting Loss:0.2131 + XiCon Loss:2.9382 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0590799
	speed: 0.0276s/iter; left time: 283.8880s
Epoch: 20 cost time: 3.467275857925415
Epoch: 20, Steps: 128 Train Loss: 3.1583 (Forecasting Loss:0.2131 + XiCon Loss:2.9451 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1721649
	speed: 0.0258s/iter; left time: 261.9141s
Epoch: 21 cost time: 3.337106227874756
Epoch: 21, Steps: 128 Train Loss: 3.1576 (Forecasting Loss:0.2132 + XiCon Loss:2.9445 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.2017059
	speed: 0.0263s/iter; left time: 263.5470s
Epoch: 22 cost time: 3.3797266483306885
Epoch: 22, Steps: 128 Train Loss: 3.1531 (Forecasting Loss:0.2132 + XiCon Loss:2.9399 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2405703
	speed: 0.0288s/iter; left time: 284.2062s
Epoch: 23 cost time: 3.312300205230713
Epoch: 23, Steps: 128 Train Loss: 3.1518 (Forecasting Loss:0.2132 + XiCon Loss:2.9385 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1541798
	speed: 0.0313s/iter; left time: 305.3634s
Epoch: 24 cost time: 3.916856050491333
Epoch: 24, Steps: 128 Train Loss: 3.1577 (Forecasting Loss:0.2131 + XiCon Loss:2.9447 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1152
Validation loss decreased (0.163079 --> 0.162960).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0838807
	speed: 0.0267s/iter; left time: 256.9446s
Epoch: 25 cost time: 3.460890531539917
Epoch: 25, Steps: 128 Train Loss: 3.1481 (Forecasting Loss:0.2132 + XiCon Loss:2.9349 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2082334
	speed: 0.0266s/iter; left time: 252.9667s
Epoch: 26 cost time: 3.1995887756347656
Epoch: 26, Steps: 128 Train Loss: 3.1550 (Forecasting Loss:0.2132 + XiCon Loss:2.9418 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1372108
	speed: 0.0329s/iter; left time: 308.5263s
Epoch: 27 cost time: 3.898948907852173
Epoch: 27, Steps: 128 Train Loss: 3.1556 (Forecasting Loss:0.2132 + XiCon Loss:2.9424 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1152
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1399062
	speed: 0.0272s/iter; left time: 251.2983s
Epoch: 28 cost time: 3.4375107288360596
Epoch: 28, Steps: 128 Train Loss: 3.1585 (Forecasting Loss:0.2130 + XiCon Loss:2.9455 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.1418855
	speed: 0.0230s/iter; left time: 209.4548s
Epoch: 29 cost time: 2.9425876140594482
Epoch: 29, Steps: 128 Train Loss: 3.1517 (Forecasting Loss:0.2132 + XiCon Loss:2.9386 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1271949
	speed: 0.0295s/iter; left time: 265.1877s
Epoch: 30 cost time: 3.745137929916382
Epoch: 30, Steps: 128 Train Loss: 3.1592 (Forecasting Loss:0.2131 + XiCon Loss:2.9461 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.2269425
	speed: 0.0323s/iter; left time: 286.3241s
Epoch: 31 cost time: 4.06536865234375
Epoch: 31, Steps: 128 Train Loss: 3.1567 (Forecasting Loss:0.2131 + XiCon Loss:2.9436 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1152
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.1745262
	speed: 0.0253s/iter; left time: 220.9760s
Epoch: 32 cost time: 3.3347859382629395
Epoch: 32, Steps: 128 Train Loss: 3.1546 (Forecasting Loss:0.2130 + XiCon Loss:2.9416 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1152
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2398238
	speed: 0.0286s/iter; left time: 245.7163s
Epoch: 33 cost time: 3.618298292160034
Epoch: 33, Steps: 128 Train Loss: 3.1566 (Forecasting Loss:0.2132 + XiCon Loss:2.9435 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1152
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.1026173
	speed: 0.0305s/iter; left time: 258.9523s
Epoch: 34 cost time: 3.639073371887207
Epoch: 34, Steps: 128 Train Loss: 3.1520 (Forecasting Loss:0.2131 + XiCon Loss:2.9389 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1152
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05407387390732765, mae:0.1763715147972107, mape:0.14017243683338165, mspe:0.03716094046831131 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0540+-0.00118, MAE:0.1771+-0.00172, MAPE:0.1411+-0.00088, MSPE:0.0377+-0.00060, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6490
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3346004
	speed: 0.0452s/iter; left time: 528.3512s
Epoch: 1 cost time: 5.264228582382202
Epoch: 1, Steps: 118 Train Loss: 31.6516 (Forecasting Loss:0.3698 + XiCon Loss:3.1282 x Lambda(10.0)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.1790
Validation loss decreased (inf --> 0.273515).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4762306
	speed: 0.0455s/iter; left time: 526.7095s
Epoch: 2 cost time: 5.274580478668213
Epoch: 2, Steps: 118 Train Loss: 29.6592 (Forecasting Loss:0.3260 + XiCon Loss:2.9333 x Lambda(10.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1475
Validation loss decreased (0.273515 --> 0.245531).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1442070
	speed: 0.0470s/iter; left time: 539.2227s
Epoch: 3 cost time: 5.49278450012207
Epoch: 3, Steps: 118 Train Loss: 29.9414 (Forecasting Loss:0.2937 + XiCon Loss:2.9648 x Lambda(10.0)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1533
Validation loss decreased (0.245531 --> 0.232405).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.6148129
	speed: 0.0432s/iter; left time: 489.9672s
Epoch: 4 cost time: 5.19255518913269
Epoch: 4, Steps: 118 Train Loss: 29.5935 (Forecasting Loss:0.2814 + XiCon Loss:2.9312 x Lambda(10.0)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.1432
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.0380325
	speed: 0.0467s/iter; left time: 524.1382s
Epoch: 5 cost time: 5.649730443954468
Epoch: 5, Steps: 118 Train Loss: 29.3820 (Forecasting Loss:0.2715 + XiCon Loss:2.9111 x Lambda(10.0)), Vali MSE Loss: 0.2392 Test MSE Loss: 0.1418
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.4235554
	speed: 0.0502s/iter; left time: 557.2273s
Epoch: 6 cost time: 5.70880389213562
Epoch: 6, Steps: 118 Train Loss: 29.2829 (Forecasting Loss:0.2684 + XiCon Loss:2.9014 x Lambda(10.0)), Vali MSE Loss: 0.2339 Test MSE Loss: 0.1412
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.6532421
	speed: 0.0461s/iter; left time: 506.9011s
Epoch: 7 cost time: 5.607439756393433
Epoch: 7, Steps: 118 Train Loss: 29.2261 (Forecasting Loss:0.2658 + XiCon Loss:2.8960 x Lambda(10.0)), Vali MSE Loss: 0.2363 Test MSE Loss: 0.1402
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.3620167
	speed: 0.0500s/iter; left time: 544.1449s
Epoch: 8 cost time: 6.1205153465271
Epoch: 8, Steps: 118 Train Loss: 29.2457 (Forecasting Loss:0.2642 + XiCon Loss:2.8982 x Lambda(10.0)), Vali MSE Loss: 0.2360 Test MSE Loss: 0.1408
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1369457
	speed: 0.0574s/iter; left time: 617.2011s
Epoch: 9 cost time: 6.732132434844971
Epoch: 9, Steps: 118 Train Loss: 29.2784 (Forecasting Loss:0.2644 + XiCon Loss:2.9014 x Lambda(10.0)), Vali MSE Loss: 0.2339 Test MSE Loss: 0.1419
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4983788
	speed: 0.0544s/iter; left time: 579.1778s
Epoch: 10 cost time: 6.416682720184326
Epoch: 10, Steps: 118 Train Loss: 29.2387 (Forecasting Loss:0.2646 + XiCon Loss:2.8974 x Lambda(10.0)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1411
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.6654873
	speed: 0.0472s/iter; left time: 496.8027s
Epoch: 11 cost time: 5.402018308639526
Epoch: 11, Steps: 118 Train Loss: 29.2540 (Forecasting Loss:0.2634 + XiCon Loss:2.8991 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1409
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3905220
	speed: 0.0454s/iter; left time: 471.9494s
Epoch: 12 cost time: 5.399094820022583
Epoch: 12, Steps: 118 Train Loss: 29.2940 (Forecasting Loss:0.2642 + XiCon Loss:2.9030 x Lambda(10.0)), Vali MSE Loss: 0.2354 Test MSE Loss: 0.1409
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6307087
	speed: 0.0468s/iter; left time: 481.2525s
Epoch: 13 cost time: 5.450074672698975
Epoch: 13, Steps: 118 Train Loss: 29.2744 (Forecasting Loss:0.2639 + XiCon Loss:2.9011 x Lambda(10.0)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1410
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.081389881670475, mae:0.22522909939289093, mape:0.16374503076076508, mspe:0.04290354996919632 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5584
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.5607758
	speed: 0.0436s/iter; left time: 509.7158s
Epoch: 1 cost time: 5.033262014389038
Epoch: 1, Steps: 118 Train Loss: 31.5496 (Forecasting Loss:0.3553 + XiCon Loss:3.1194 x Lambda(10.0)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.1655
Validation loss decreased (inf --> 0.254170).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.7873173
	speed: 0.0510s/iter; left time: 590.9790s
Epoch: 2 cost time: 6.14345383644104
Epoch: 2, Steps: 118 Train Loss: 29.5511 (Forecasting Loss:0.3421 + XiCon Loss:2.9209 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1714
Validation loss decreased (0.254170 --> 0.249211).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1456184
	speed: 0.0506s/iter; left time: 580.4609s
Epoch: 3 cost time: 6.10906457901001
Epoch: 3, Steps: 118 Train Loss: 30.4481 (Forecasting Loss:0.3160 + XiCon Loss:3.0132 x Lambda(10.0)), Vali MSE Loss: 0.2349 Test MSE Loss: 0.1562
Validation loss decreased (0.249211 --> 0.234927).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.5798359
	speed: 0.0514s/iter; left time: 582.8521s
Epoch: 4 cost time: 5.81809401512146
Epoch: 4, Steps: 118 Train Loss: 30.0626 (Forecasting Loss:0.2845 + XiCon Loss:2.9778 x Lambda(10.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.1541
Validation loss decreased (0.234927 --> 0.230003).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.4963169
	speed: 0.0462s/iter; left time: 518.6078s
Epoch: 5 cost time: 5.407426595687866
Epoch: 5, Steps: 118 Train Loss: 29.8758 (Forecasting Loss:0.2778 + XiCon Loss:2.9598 x Lambda(10.0)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1561
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2561169
	speed: 0.0422s/iter; left time: 468.4580s
Epoch: 6 cost time: 5.0773162841796875
Epoch: 6, Steps: 118 Train Loss: 29.7385 (Forecasting Loss:0.2748 + XiCon Loss:2.9464 x Lambda(10.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.1560
Validation loss decreased (0.230003 --> 0.225549).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1798038
	speed: 0.0429s/iter; left time: 471.2251s
Epoch: 7 cost time: 5.162829875946045
Epoch: 7, Steps: 118 Train Loss: 29.7824 (Forecasting Loss:0.2738 + XiCon Loss:2.9509 x Lambda(10.0)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1549
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1912117
	speed: 0.0505s/iter; left time: 549.2224s
Epoch: 8 cost time: 5.720789194107056
Epoch: 8, Steps: 118 Train Loss: 29.7339 (Forecasting Loss:0.2724 + XiCon Loss:2.9462 x Lambda(10.0)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1551
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.6463680
	speed: 0.0485s/iter; left time: 521.2758s
Epoch: 9 cost time: 5.705536603927612
Epoch: 9, Steps: 118 Train Loss: 29.7060 (Forecasting Loss:0.2709 + XiCon Loss:2.9435 x Lambda(10.0)), Vali MSE Loss: 0.2281 Test MSE Loss: 0.1550
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.4238358
	speed: 0.0476s/iter; left time: 506.7768s
Epoch: 10 cost time: 5.782077074050903
Epoch: 10, Steps: 118 Train Loss: 29.7122 (Forecasting Loss:0.2711 + XiCon Loss:2.9441 x Lambda(10.0)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1556
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1859684
	speed: 0.0462s/iter; left time: 485.6580s
Epoch: 11 cost time: 5.504742622375488
Epoch: 11, Steps: 118 Train Loss: 29.7607 (Forecasting Loss:0.2713 + XiCon Loss:2.9489 x Lambda(10.0)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.1558
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.1826706
	speed: 0.0513s/iter; left time: 533.6096s
Epoch: 12 cost time: 5.8787877559661865
Epoch: 12, Steps: 118 Train Loss: 29.6923 (Forecasting Loss:0.2710 + XiCon Loss:2.9421 x Lambda(10.0)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1558
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.4556065
	speed: 0.0461s/iter; left time: 474.5173s
Epoch: 13 cost time: 5.378284454345703
Epoch: 13, Steps: 118 Train Loss: 29.6978 (Forecasting Loss:0.2710 + XiCon Loss:2.9427 x Lambda(10.0)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1558
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.9863586
	speed: 0.0449s/iter; left time: 456.2930s
Epoch: 14 cost time: 5.342648983001709
Epoch: 14, Steps: 118 Train Loss: 29.7222 (Forecasting Loss:0.2713 + XiCon Loss:2.9451 x Lambda(10.0)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.1558
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3967113
	speed: 0.0464s/iter; left time: 465.9796s
Epoch: 15 cost time: 5.721394777297974
Epoch: 15, Steps: 118 Train Loss: 29.7456 (Forecasting Loss:0.2718 + XiCon Loss:2.9474 x Lambda(10.0)), Vali MSE Loss: 0.2263 Test MSE Loss: 0.1558
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1218357
	speed: 0.0581s/iter; left time: 576.8648s
Epoch: 16 cost time: 6.7078588008880615
Epoch: 16, Steps: 118 Train Loss: 29.7674 (Forecasting Loss:0.2710 + XiCon Loss:2.9496 x Lambda(10.0)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1558
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08344674110412598, mae:0.22854410111904144, mape:0.16818098723888397, mspe:0.04636447876691818 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8025
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3359032
	speed: 0.0502s/iter; left time: 586.8861s
Epoch: 1 cost time: 5.947979211807251
Epoch: 1, Steps: 118 Train Loss: 31.4522 (Forecasting Loss:0.3613 + XiCon Loss:3.1091 x Lambda(10.0)), Vali MSE Loss: 0.2566 Test MSE Loss: 0.1662
Validation loss decreased (inf --> 0.256568).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8107815
	speed: 0.0540s/iter; left time: 625.3660s
Epoch: 2 cost time: 6.439762592315674
Epoch: 2, Steps: 118 Train Loss: 29.9240 (Forecasting Loss:0.3406 + XiCon Loss:2.9583 x Lambda(10.0)), Vali MSE Loss: 0.2767 Test MSE Loss: 0.1563
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.2413292
	speed: 0.0511s/iter; left time: 586.3997s
Epoch: 3 cost time: 6.037474632263184
Epoch: 3, Steps: 118 Train Loss: 29.9002 (Forecasting Loss:0.2977 + XiCon Loss:2.9602 x Lambda(10.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1527
Validation loss decreased (0.256568 --> 0.236795).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.5435467
	speed: 0.0485s/iter; left time: 550.3791s
Epoch: 4 cost time: 5.546978235244751
Epoch: 4, Steps: 118 Train Loss: 29.4066 (Forecasting Loss:0.2867 + XiCon Loss:2.9120 x Lambda(10.0)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.1552
Validation loss decreased (0.236795 --> 0.229130).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.0467186
	speed: 0.0450s/iter; left time: 504.7599s
Epoch: 5 cost time: 5.503077030181885
Epoch: 5, Steps: 118 Train Loss: 29.1949 (Forecasting Loss:0.2829 + XiCon Loss:2.8912 x Lambda(10.0)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1550
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.8367424
	speed: 0.0472s/iter; left time: 524.5378s
Epoch: 6 cost time: 5.59145188331604
Epoch: 6, Steps: 118 Train Loss: 29.0490 (Forecasting Loss:0.2786 + XiCon Loss:2.8770 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1542
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.0003967
	speed: 0.0507s/iter; left time: 557.5898s
Epoch: 7 cost time: 5.892224550247192
Epoch: 7, Steps: 118 Train Loss: 29.0053 (Forecasting Loss:0.2767 + XiCon Loss:2.8729 x Lambda(10.0)), Vali MSE Loss: 0.2310 Test MSE Loss: 0.1541
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.6802158
	speed: 0.0484s/iter; left time: 526.1681s
Epoch: 8 cost time: 5.8196446895599365
Epoch: 8, Steps: 118 Train Loss: 29.0532 (Forecasting Loss:0.2758 + XiCon Loss:2.8777 x Lambda(10.0)), Vali MSE Loss: 0.2315 Test MSE Loss: 0.1543
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4534187
	speed: 0.0515s/iter; left time: 554.0945s
Epoch: 9 cost time: 5.882544279098511
Epoch: 9, Steps: 118 Train Loss: 28.9642 (Forecasting Loss:0.2752 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.1541
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.4172955
	speed: 0.0461s/iter; left time: 490.7428s
Epoch: 10 cost time: 5.728537082672119
Epoch: 10, Steps: 118 Train Loss: 28.9549 (Forecasting Loss:0.2741 + XiCon Loss:2.8681 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.1543
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.6352024
	speed: 0.0496s/iter; left time: 521.3806s
Epoch: 11 cost time: 5.974679470062256
Epoch: 11, Steps: 118 Train Loss: 28.9939 (Forecasting Loss:0.2742 + XiCon Loss:2.8720 x Lambda(10.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.1543
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.4149666
	speed: 0.0511s/iter; left time: 531.5073s
Epoch: 12 cost time: 5.843749046325684
Epoch: 12, Steps: 118 Train Loss: 28.9510 (Forecasting Loss:0.2747 + XiCon Loss:2.8676 x Lambda(10.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.1543
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.7124081
	speed: 0.0481s/iter; left time: 494.8413s
Epoch: 13 cost time: 5.752561569213867
Epoch: 13, Steps: 118 Train Loss: 28.9977 (Forecasting Loss:0.2742 + XiCon Loss:2.8723 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1543
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2670174
	speed: 0.0473s/iter; left time: 481.2459s
Epoch: 14 cost time: 5.633729457855225
Epoch: 14, Steps: 118 Train Loss: 28.9401 (Forecasting Loss:0.2745 + XiCon Loss:2.8666 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.1543
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08270447701215744, mae:0.22771847248077393, mape:0.1657281368970871, mspe:0.04365195706486702 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7365
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3848743
	speed: 0.0436s/iter; left time: 509.7697s
Epoch: 1 cost time: 5.046219348907471
Epoch: 1, Steps: 118 Train Loss: 31.5783 (Forecasting Loss:0.3701 + XiCon Loss:3.1208 x Lambda(10.0)), Vali MSE Loss: 0.2741 Test MSE Loss: 0.1793
Validation loss decreased (inf --> 0.274075).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.0102367
	speed: 0.0405s/iter; left time: 469.1141s
Epoch: 2 cost time: 5.014551401138306
Epoch: 2, Steps: 118 Train Loss: 30.6881 (Forecasting Loss:0.3349 + XiCon Loss:3.0353 x Lambda(10.0)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.1560
Validation loss decreased (0.274075 --> 0.253752).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1566887
	speed: 0.0472s/iter; left time: 541.2486s
Epoch: 3 cost time: 5.6822509765625
Epoch: 3, Steps: 118 Train Loss: 29.8285 (Forecasting Loss:0.2929 + XiCon Loss:2.9536 x Lambda(10.0)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1559
Validation loss decreased (0.253752 --> 0.240566).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.6503582
	speed: 0.0461s/iter; left time: 523.5413s
Epoch: 4 cost time: 5.515949964523315
Epoch: 4, Steps: 118 Train Loss: 29.5149 (Forecasting Loss:0.2694 + XiCon Loss:2.9246 x Lambda(10.0)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1569
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.2369652
	speed: 0.0495s/iter; left time: 555.9132s
Epoch: 5 cost time: 5.804188251495361
Epoch: 5, Steps: 118 Train Loss: 29.4350 (Forecasting Loss:0.2629 + XiCon Loss:2.9172 x Lambda(10.0)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1553
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.2194557
	speed: 0.0526s/iter; left time: 584.9352s
Epoch: 6 cost time: 6.331469774246216
Epoch: 6, Steps: 118 Train Loss: 29.3008 (Forecasting Loss:0.2607 + XiCon Loss:2.9040 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1541
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.8982430
	speed: 0.0520s/iter; left time: 571.3251s
Epoch: 7 cost time: 6.162017583847046
Epoch: 7, Steps: 118 Train Loss: 29.3008 (Forecasting Loss:0.2593 + XiCon Loss:2.9041 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1539
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.2261162
	speed: 0.0561s/iter; left time: 610.0875s
Epoch: 8 cost time: 6.628490209579468
Epoch: 8, Steps: 118 Train Loss: 29.3184 (Forecasting Loss:0.2575 + XiCon Loss:2.9061 x Lambda(10.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.1540
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3890438
	speed: 0.0542s/iter; left time: 583.5428s
Epoch: 9 cost time: 6.25017523765564
Epoch: 9, Steps: 118 Train Loss: 29.2414 (Forecasting Loss:0.2564 + XiCon Loss:2.8985 x Lambda(10.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.1543
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7662582
	speed: 0.0457s/iter; left time: 486.1804s
Epoch: 10 cost time: 5.545047044754028
Epoch: 10, Steps: 118 Train Loss: 29.2537 (Forecasting Loss:0.2572 + XiCon Loss:2.8996 x Lambda(10.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1541
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.3326302
	speed: 0.0480s/iter; left time: 504.6093s
Epoch: 11 cost time: 5.705267429351807
Epoch: 11, Steps: 118 Train Loss: 29.2763 (Forecasting Loss:0.2581 + XiCon Loss:2.9018 x Lambda(10.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1541
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.0886135
	speed: 0.0477s/iter; left time: 496.0711s
Epoch: 12 cost time: 5.460835933685303
Epoch: 12, Steps: 118 Train Loss: 29.2914 (Forecasting Loss:0.2569 + XiCon Loss:2.9035 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1541
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.2653427
	speed: 0.0503s/iter; left time: 517.2238s
Epoch: 13 cost time: 5.75141167640686
Epoch: 13, Steps: 118 Train Loss: 29.2489 (Forecasting Loss:0.2562 + XiCon Loss:2.8993 x Lambda(10.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1540
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08353719115257263, mae:0.22820138931274414, mape:0.16596227884292603, mspe:0.04480976238846779 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6795
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.4289227
	speed: 0.0411s/iter; left time: 480.4109s
Epoch: 1 cost time: 4.955699443817139
Epoch: 1, Steps: 118 Train Loss: 31.5693 (Forecasting Loss:0.3571 + XiCon Loss:3.1212 x Lambda(10.0)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.257544).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4661789
	speed: 0.0464s/iter; left time: 537.2630s
Epoch: 2 cost time: 5.369362831115723
Epoch: 2, Steps: 118 Train Loss: 29.7755 (Forecasting Loss:0.3455 + XiCon Loss:2.9430 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1666
Validation loss decreased (0.257544 --> 0.249071).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4986801
	speed: 0.0475s/iter; left time: 544.7774s
Epoch: 3 cost time: 5.680818796157837
Epoch: 3, Steps: 118 Train Loss: 29.9215 (Forecasting Loss:0.3294 + XiCon Loss:2.9592 x Lambda(10.0)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1547
Validation loss decreased (0.249071 --> 0.235616).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9784050
	speed: 0.0495s/iter; left time: 561.9589s
Epoch: 4 cost time: 5.864394903182983
Epoch: 4, Steps: 118 Train Loss: 30.4971 (Forecasting Loss:0.3016 + XiCon Loss:3.0195 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1564
Validation loss decreased (0.235616 --> 0.234957).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9085312
	speed: 0.0515s/iter; left time: 578.4597s
Epoch: 5 cost time: 6.0597312450408936
Epoch: 5, Steps: 118 Train Loss: 30.1275 (Forecasting Loss:0.2960 + XiCon Loss:2.9831 x Lambda(10.0)), Vali MSE Loss: 0.2306 Test MSE Loss: 0.1540
Validation loss decreased (0.234957 --> 0.230603).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.1954651
	speed: 0.0492s/iter; left time: 546.5313s
Epoch: 6 cost time: 5.834435939788818
Epoch: 6, Steps: 118 Train Loss: 30.1527 (Forecasting Loss:0.2885 + XiCon Loss:2.9864 x Lambda(10.0)), Vali MSE Loss: 0.2279 Test MSE Loss: 0.1503
Validation loss decreased (0.230603 --> 0.227896).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.2908020
	speed: 0.0454s/iter; left time: 499.3714s
Epoch: 7 cost time: 5.421586990356445
Epoch: 7, Steps: 118 Train Loss: 29.9827 (Forecasting Loss:0.2922 + XiCon Loss:2.9691 x Lambda(10.0)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1507
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.6370544
	speed: 0.0533s/iter; left time: 579.8479s
Epoch: 8 cost time: 6.043766975402832
Epoch: 8, Steps: 118 Train Loss: 29.9695 (Forecasting Loss:0.2878 + XiCon Loss:2.9682 x Lambda(10.0)), Vali MSE Loss: 0.2294 Test MSE Loss: 0.1514
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1630917
	speed: 0.0447s/iter; left time: 480.3779s
Epoch: 9 cost time: 5.478581428527832
Epoch: 9, Steps: 118 Train Loss: 30.0423 (Forecasting Loss:0.2888 + XiCon Loss:2.9753 x Lambda(10.0)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.1512
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.3559608
	speed: 0.0465s/iter; left time: 494.6782s
Epoch: 10 cost time: 5.5908424854278564
Epoch: 10, Steps: 118 Train Loss: 29.9441 (Forecasting Loss:0.2881 + XiCon Loss:2.9656 x Lambda(10.0)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.1515
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0212326
	speed: 0.0486s/iter; left time: 511.4659s
Epoch: 11 cost time: 5.626182556152344
Epoch: 11, Steps: 118 Train Loss: 29.9017 (Forecasting Loss:0.2885 + XiCon Loss:2.9613 x Lambda(10.0)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.1514
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4333210
	speed: 0.0545s/iter; left time: 566.6974s
Epoch: 12 cost time: 6.358357667922974
Epoch: 12, Steps: 118 Train Loss: 29.9069 (Forecasting Loss:0.2882 + XiCon Loss:2.9619 x Lambda(10.0)), Vali MSE Loss: 0.2300 Test MSE Loss: 0.1515
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2357426
	speed: 0.0497s/iter; left time: 511.1109s
Epoch: 13 cost time: 5.946084976196289
Epoch: 13, Steps: 118 Train Loss: 29.9357 (Forecasting Loss:0.2886 + XiCon Loss:2.9647 x Lambda(10.0)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.1515
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4504604
	speed: 0.0575s/iter; left time: 584.3103s
Epoch: 14 cost time: 6.587568521499634
Epoch: 14, Steps: 118 Train Loss: 29.9574 (Forecasting Loss:0.2883 + XiCon Loss:2.9669 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1514
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.9863300
	speed: 0.0562s/iter; left time: 564.2674s
Epoch: 15 cost time: 6.550957918167114
Epoch: 15, Steps: 118 Train Loss: 29.9369 (Forecasting Loss:0.2880 + XiCon Loss:2.9649 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1514
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6890621
	speed: 0.0558s/iter; left time: 553.8170s
Epoch: 16 cost time: 6.472625255584717
Epoch: 16, Steps: 118 Train Loss: 29.9613 (Forecasting Loss:0.2885 + XiCon Loss:2.9673 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1514
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07810413092374802, mae:0.2223992496728897, mape:0.16411229968070984, mspe:0.04371232911944389 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0818+-0.00280, MAE:0.2264+-0.00322, MAPE:0.1655+-0.00219, MSPE:0.0443+-0.00167, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5909
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8049200
	speed: 0.0694s/iter; left time: 735.2783s
Epoch: 1 cost time: 7.438340663909912
Epoch: 1, Steps: 107 Train Loss: 0.8464 (Forecasting Loss:0.5322 + XiCon Loss:3.1420 x Lambda(0.1)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.1970
Validation loss decreased (inf --> 0.345639).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5833403
	speed: 0.0688s/iter; left time: 722.1797s
Epoch: 2 cost time: 7.390927076339722
Epoch: 2, Steps: 107 Train Loss: 0.6861 (Forecasting Loss:0.3782 + XiCon Loss:3.0796 x Lambda(0.1)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1391
Validation loss decreased (0.345639 --> 0.250608).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5623441
	speed: 0.0692s/iter; left time: 719.1529s
Epoch: 3 cost time: 7.37256646156311
Epoch: 3, Steps: 107 Train Loss: 0.5693 (Forecasting Loss:0.2684 + XiCon Loss:3.0093 x Lambda(0.1)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5566824
	speed: 0.0705s/iter; left time: 724.8508s
Epoch: 4 cost time: 7.663939476013184
Epoch: 4, Steps: 107 Train Loss: 0.5521 (Forecasting Loss:0.2546 + XiCon Loss:2.9755 x Lambda(0.1)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.1458
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5361923
	speed: 0.0641s/iter; left time: 652.0292s
Epoch: 5 cost time: 6.873213529586792
Epoch: 5, Steps: 107 Train Loss: 0.5422 (Forecasting Loss:0.2471 + XiCon Loss:2.9508 x Lambda(0.1)), Vali MSE Loss: 0.2634 Test MSE Loss: 0.1365
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5345362
	speed: 0.0680s/iter; left time: 684.9439s
Epoch: 6 cost time: 7.225414752960205
Epoch: 6, Steps: 107 Train Loss: 0.5381 (Forecasting Loss:0.2438 + XiCon Loss:2.9428 x Lambda(0.1)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.1367
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5195609
	speed: 0.0696s/iter; left time: 692.6547s
Epoch: 7 cost time: 7.465161561965942
Epoch: 7, Steps: 107 Train Loss: 0.5373 (Forecasting Loss:0.2428 + XiCon Loss:2.9453 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1354
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5461722
	speed: 0.0658s/iter; left time: 648.0790s
Epoch: 8 cost time: 7.0039167404174805
Epoch: 8, Steps: 107 Train Loss: 0.5369 (Forecasting Loss:0.2423 + XiCon Loss:2.9458 x Lambda(0.1)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1373
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5521094
	speed: 0.0707s/iter; left time: 689.3443s
Epoch: 9 cost time: 7.670849084854126
Epoch: 9, Steps: 107 Train Loss: 0.5365 (Forecasting Loss:0.2416 + XiCon Loss:2.9489 x Lambda(0.1)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5454488
	speed: 0.0718s/iter; left time: 691.5339s
Epoch: 10 cost time: 7.809896469116211
Epoch: 10, Steps: 107 Train Loss: 0.5359 (Forecasting Loss:0.2414 + XiCon Loss:2.9456 x Lambda(0.1)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.1370
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5367955
	speed: 0.0659s/iter; left time: 627.8203s
Epoch: 11 cost time: 7.108304500579834
Epoch: 11, Steps: 107 Train Loss: 0.5358 (Forecasting Loss:0.2410 + XiCon Loss:2.9484 x Lambda(0.1)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1365
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5409603
	speed: 0.0710s/iter; left time: 669.3506s
Epoch: 12 cost time: 7.750093221664429
Epoch: 12, Steps: 107 Train Loss: 0.5360 (Forecasting Loss:0.2410 + XiCon Loss:2.9496 x Lambda(0.1)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1359
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.0694696381688118, mae:0.20877526700496674, mape:0.15291860699653625, mspe:0.038816891610622406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.9248
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8111052
	speed: 0.0702s/iter; left time: 743.9879s
Epoch: 1 cost time: 7.625952243804932
Epoch: 1, Steps: 107 Train Loss: 0.8617 (Forecasting Loss:0.5476 + XiCon Loss:3.1418 x Lambda(0.1)), Vali MSE Loss: 0.3477 Test MSE Loss: 0.2136
Validation loss decreased (inf --> 0.347707).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5851230
	speed: 0.0821s/iter; left time: 862.0644s
Epoch: 2 cost time: 8.933161973953247
Epoch: 2, Steps: 107 Train Loss: 0.7012 (Forecasting Loss:0.3902 + XiCon Loss:3.1100 x Lambda(0.1)), Vali MSE Loss: 0.2632 Test MSE Loss: 0.1553
Validation loss decreased (0.347707 --> 0.263195).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5594372
	speed: 0.0824s/iter; left time: 855.6272s
Epoch: 3 cost time: 8.882753610610962
Epoch: 3, Steps: 107 Train Loss: 0.5722 (Forecasting Loss:0.2626 + XiCon Loss:3.0954 x Lambda(0.1)), Vali MSE Loss: 0.2717 Test MSE Loss: 0.1562
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5695049
	speed: 0.0746s/iter; left time: 767.0331s
Epoch: 4 cost time: 8.008586168289185
Epoch: 4, Steps: 107 Train Loss: 0.5605 (Forecasting Loss:0.2499 + XiCon Loss:3.1060 x Lambda(0.1)), Vali MSE Loss: 0.2869 Test MSE Loss: 0.1507
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5626650
	speed: 0.0748s/iter; left time: 761.2622s
Epoch: 5 cost time: 8.005430936813354
Epoch: 5, Steps: 107 Train Loss: 0.5547 (Forecasting Loss:0.2426 + XiCon Loss:3.1210 x Lambda(0.1)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.1552
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5535967
	speed: 0.0778s/iter; left time: 783.1629s
Epoch: 6 cost time: 8.390058994293213
Epoch: 6, Steps: 107 Train Loss: 0.5520 (Forecasting Loss:0.2395 + XiCon Loss:3.1250 x Lambda(0.1)), Vali MSE Loss: 0.2638 Test MSE Loss: 0.1571
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5490598
	speed: 0.0728s/iter; left time: 724.6431s
Epoch: 7 cost time: 7.9437034130096436
Epoch: 7, Steps: 107 Train Loss: 0.5511 (Forecasting Loss:0.2384 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1542
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5419264
	speed: 0.0762s/iter; left time: 750.3145s
Epoch: 8 cost time: 8.257807970046997
Epoch: 8, Steps: 107 Train Loss: 0.5501 (Forecasting Loss:0.2373 + XiCon Loss:3.1280 x Lambda(0.1)), Vali MSE Loss: 0.2676 Test MSE Loss: 0.1541
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5385745
	speed: 0.0790s/iter; left time: 770.3102s
Epoch: 9 cost time: 8.606793642044067
Epoch: 9, Steps: 107 Train Loss: 0.5495 (Forecasting Loss:0.2369 + XiCon Loss:3.1262 x Lambda(0.1)), Vali MSE Loss: 0.2668 Test MSE Loss: 0.1542
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5373805
	speed: 0.0735s/iter; left time: 707.9959s
Epoch: 10 cost time: 7.870521306991577
Epoch: 10, Steps: 107 Train Loss: 0.5485 (Forecasting Loss:0.2360 + XiCon Loss:3.1245 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1548
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5459757
	speed: 0.0763s/iter; left time: 726.8895s
Epoch: 11 cost time: 8.245682954788208
Epoch: 11, Steps: 107 Train Loss: 0.5493 (Forecasting Loss:0.2363 + XiCon Loss:3.1303 x Lambda(0.1)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1534
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5584253
	speed: 0.0782s/iter; left time: 736.8979s
Epoch: 12 cost time: 8.36404824256897
Epoch: 12, Steps: 107 Train Loss: 0.5491 (Forecasting Loss:0.2366 + XiCon Loss:3.1256 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1542
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08253799378871918, mae:0.2279779464006424, mape:0.16444101929664612, mspe:0.044037725776433945 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6813
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8945969
	speed: 0.0659s/iter; left time: 698.3317s
Epoch: 1 cost time: 7.14593768119812
Epoch: 1, Steps: 107 Train Loss: 0.8565 (Forecasting Loss:0.5414 + XiCon Loss:3.1514 x Lambda(0.1)), Vali MSE Loss: 0.3729 Test MSE Loss: 0.2208
Validation loss decreased (inf --> 0.372859).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5707532
	speed: 0.0894s/iter; left time: 938.4948s
Epoch: 2 cost time: 9.75986933708191
Epoch: 2, Steps: 107 Train Loss: 0.6343 (Forecasting Loss:0.3326 + XiCon Loss:3.0167 x Lambda(0.1)), Vali MSE Loss: 0.3633 Test MSE Loss: 0.1556
Validation loss decreased (0.372859 --> 0.363320).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5434852
	speed: 0.0965s/iter; left time: 1001.9552s
Epoch: 3 cost time: 10.493363380432129
Epoch: 3, Steps: 107 Train Loss: 0.5428 (Forecasting Loss:0.2532 + XiCon Loss:2.8952 x Lambda(0.1)), Vali MSE Loss: 0.3468 Test MSE Loss: 0.1527
Validation loss decreased (0.363320 --> 0.346822).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5469298
	speed: 0.1030s/iter; left time: 1058.6837s
Epoch: 4 cost time: 11.1372811794281
Epoch: 4, Steps: 107 Train Loss: 0.5319 (Forecasting Loss:0.2435 + XiCon Loss:2.8845 x Lambda(0.1)), Vali MSE Loss: 0.3375 Test MSE Loss: 0.1478
Validation loss decreased (0.346822 --> 0.337505).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5339961
	speed: 0.0999s/iter; left time: 1016.1934s
Epoch: 5 cost time: 10.785038948059082
Epoch: 5, Steps: 107 Train Loss: 0.5306 (Forecasting Loss:0.2391 + XiCon Loss:2.9143 x Lambda(0.1)), Vali MSE Loss: 0.3452 Test MSE Loss: 0.1477
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5320685
	speed: 0.0953s/iter; left time: 959.7230s
Epoch: 6 cost time: 10.164532899856567
Epoch: 6, Steps: 107 Train Loss: 0.5293 (Forecasting Loss:0.2360 + XiCon Loss:2.9336 x Lambda(0.1)), Vali MSE Loss: 0.3446 Test MSE Loss: 0.1486
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5334424
	speed: 0.0952s/iter; left time: 947.6980s
Epoch: 7 cost time: 10.214995384216309
Epoch: 7, Steps: 107 Train Loss: 0.5281 (Forecasting Loss:0.2345 + XiCon Loss:2.9357 x Lambda(0.1)), Vali MSE Loss: 0.3391 Test MSE Loss: 0.1467
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5304511
	speed: 0.0905s/iter; left time: 891.4504s
Epoch: 8 cost time: 9.86051058769226
Epoch: 8, Steps: 107 Train Loss: 0.5279 (Forecasting Loss:0.2340 + XiCon Loss:2.9387 x Lambda(0.1)), Vali MSE Loss: 0.3436 Test MSE Loss: 0.1460
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5230365
	speed: 0.0933s/iter; left time: 908.9959s
Epoch: 9 cost time: 10.122823476791382
Epoch: 9, Steps: 107 Train Loss: 0.5280 (Forecasting Loss:0.2340 + XiCon Loss:2.9394 x Lambda(0.1)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.1461
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5287977
	speed: 0.0937s/iter; left time: 903.4457s
Epoch: 10 cost time: 10.052800416946411
Epoch: 10, Steps: 107 Train Loss: 0.5282 (Forecasting Loss:0.2343 + XiCon Loss:2.9387 x Lambda(0.1)), Vali MSE Loss: 0.3392 Test MSE Loss: 0.1455
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5281329
	speed: 0.0923s/iter; left time: 879.9434s
Epoch: 11 cost time: 9.916995525360107
Epoch: 11, Steps: 107 Train Loss: 0.5274 (Forecasting Loss:0.2335 + XiCon Loss:2.9395 x Lambda(0.1)), Vali MSE Loss: 0.3401 Test MSE Loss: 0.1463
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5292755
	speed: 0.0945s/iter; left time: 890.6370s
Epoch: 12 cost time: 10.314777612686157
Epoch: 12, Steps: 107 Train Loss: 0.5276 (Forecasting Loss:0.2337 + XiCon Loss:2.9391 x Lambda(0.1)), Vali MSE Loss: 0.3409 Test MSE Loss: 0.1461
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5322249
	speed: 0.0944s/iter; left time: 879.9299s
Epoch: 13 cost time: 10.163501262664795
Epoch: 13, Steps: 107 Train Loss: 0.5275 (Forecasting Loss:0.2336 + XiCon Loss:2.9396 x Lambda(0.1)), Vali MSE Loss: 0.3407 Test MSE Loss: 0.1459
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5342816
	speed: 0.0997s/iter; left time: 918.0830s
Epoch: 14 cost time: 10.64458155632019
Epoch: 14, Steps: 107 Train Loss: 0.5272 (Forecasting Loss:0.2331 + XiCon Loss:2.9412 x Lambda(0.1)), Vali MSE Loss: 0.3411 Test MSE Loss: 0.1459
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07696767896413803, mae:0.21871569752693176, mape:0.1586221605539322, mspe:0.04289235174655914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7789
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8082997
	speed: 0.0682s/iter; left time: 722.6786s
Epoch: 1 cost time: 7.371977090835571
Epoch: 1, Steps: 107 Train Loss: 0.8442 (Forecasting Loss:0.5289 + XiCon Loss:3.1531 x Lambda(0.1)), Vali MSE Loss: 0.3443 Test MSE Loss: 0.2025
Validation loss decreased (inf --> 0.344307).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6567679
	speed: 0.0806s/iter; left time: 845.3591s
Epoch: 2 cost time: 8.658382177352905
Epoch: 2, Steps: 107 Train Loss: 0.7099 (Forecasting Loss:0.4037 + XiCon Loss:3.0620 x Lambda(0.1)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1374
Validation loss decreased (0.344307 --> 0.232289).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5526332
	speed: 0.0805s/iter; left time: 836.5027s
Epoch: 3 cost time: 8.743850231170654
Epoch: 3, Steps: 107 Train Loss: 0.5772 (Forecasting Loss:0.2785 + XiCon Loss:2.9871 x Lambda(0.1)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1399
Validation loss decreased (0.232289 --> 0.228436).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5616779
	speed: 0.0729s/iter; left time: 749.5466s
Epoch: 4 cost time: 7.925268650054932
Epoch: 4, Steps: 107 Train Loss: 0.5558 (Forecasting Loss:0.2549 + XiCon Loss:3.0094 x Lambda(0.1)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1343
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5577659
	speed: 0.0706s/iter; left time: 718.2603s
Epoch: 5 cost time: 7.603626489639282
Epoch: 5, Steps: 107 Train Loss: 0.5508 (Forecasting Loss:0.2460 + XiCon Loss:3.0482 x Lambda(0.1)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1371
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5556826
	speed: 0.0886s/iter; left time: 891.8887s
Epoch: 6 cost time: 9.699204206466675
Epoch: 6, Steps: 107 Train Loss: 0.5488 (Forecasting Loss:0.2427 + XiCon Loss:3.0608 x Lambda(0.1)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1366
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5468559
	speed: 0.0857s/iter; left time: 853.9429s
Epoch: 7 cost time: 9.101701498031616
Epoch: 7, Steps: 107 Train Loss: 0.5476 (Forecasting Loss:0.2407 + XiCon Loss:3.0693 x Lambda(0.1)), Vali MSE Loss: 0.2444 Test MSE Loss: 0.1359
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5475633
	speed: 0.0671s/iter; left time: 661.0993s
Epoch: 8 cost time: 7.143152713775635
Epoch: 8, Steps: 107 Train Loss: 0.5475 (Forecasting Loss:0.2403 + XiCon Loss:3.0718 x Lambda(0.1)), Vali MSE Loss: 0.2422 Test MSE Loss: 0.1364
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5463241
	speed: 0.0683s/iter; left time: 665.5779s
Epoch: 9 cost time: 7.286011219024658
Epoch: 9, Steps: 107 Train Loss: 0.5469 (Forecasting Loss:0.2396 + XiCon Loss:3.0726 x Lambda(0.1)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.1374
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5495200
	speed: 0.0671s/iter; left time: 646.8568s
Epoch: 10 cost time: 7.268251895904541
Epoch: 10, Steps: 107 Train Loss: 0.5469 (Forecasting Loss:0.2398 + XiCon Loss:3.0707 x Lambda(0.1)), Vali MSE Loss: 0.2418 Test MSE Loss: 0.1358
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5409309
	speed: 0.0637s/iter; left time: 607.3207s
Epoch: 11 cost time: 6.919610500335693
Epoch: 11, Steps: 107 Train Loss: 0.5472 (Forecasting Loss:0.2395 + XiCon Loss:3.0768 x Lambda(0.1)), Vali MSE Loss: 0.2422 Test MSE Loss: 0.1364
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5469781
	speed: 0.0688s/iter; left time: 648.7602s
Epoch: 12 cost time: 7.31849479675293
Epoch: 12, Steps: 107 Train Loss: 0.5465 (Forecasting Loss:0.2396 + XiCon Loss:3.0690 x Lambda(0.1)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.1364
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5539347
	speed: 0.0680s/iter; left time: 633.6390s
Epoch: 13 cost time: 7.271161079406738
Epoch: 13, Steps: 107 Train Loss: 0.5468 (Forecasting Loss:0.2395 + XiCon Loss:3.0732 x Lambda(0.1)), Vali MSE Loss: 0.2424 Test MSE Loss: 0.1364
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07025786489248276, mae:0.20957106351852417, mape:0.15161444246768951, mspe:0.037513189017772675 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7099
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.8881824
	speed: 0.0651s/iter; left time: 690.1819s
Epoch: 1 cost time: 7.082062482833862
Epoch: 1, Steps: 107 Train Loss: 0.8504 (Forecasting Loss:0.5360 + XiCon Loss:3.1441 x Lambda(0.1)), Vali MSE Loss: 0.3622 Test MSE Loss: 0.2145
Validation loss decreased (inf --> 0.362156).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.5708240
	speed: 0.0876s/iter; left time: 919.0587s
Epoch: 2 cost time: 9.469053030014038
Epoch: 2, Steps: 107 Train Loss: 0.6255 (Forecasting Loss:0.3206 + XiCon Loss:3.0485 x Lambda(0.1)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5532739
	speed: 0.0889s/iter; left time: 923.8761s
Epoch: 3 cost time: 9.487137794494629
Epoch: 3, Steps: 107 Train Loss: 0.5593 (Forecasting Loss:0.2532 + XiCon Loss:3.0604 x Lambda(0.1)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.1340
Validation loss decreased (0.362156 --> 0.335775).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5468107
	speed: 0.0857s/iter; left time: 880.7739s
Epoch: 4 cost time: 9.241676330566406
Epoch: 4, Steps: 107 Train Loss: 0.5519 (Forecasting Loss:0.2440 + XiCon Loss:3.0789 x Lambda(0.1)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.1312
Validation loss decreased (0.335775 --> 0.331859).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5346882
	speed: 0.0894s/iter; left time: 909.9198s
Epoch: 5 cost time: 9.681848287582397
Epoch: 5, Steps: 107 Train Loss: 0.5485 (Forecasting Loss:0.2400 + XiCon Loss:3.0855 x Lambda(0.1)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.1321
Validation loss decreased (0.331859 --> 0.306062).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5507693
	speed: 0.0900s/iter; left time: 905.4460s
Epoch: 6 cost time: 9.635804414749146
Epoch: 6, Steps: 107 Train Loss: 0.5450 (Forecasting Loss:0.2369 + XiCon Loss:3.0804 x Lambda(0.1)), Vali MSE Loss: 0.3020 Test MSE Loss: 0.1291
Validation loss decreased (0.306062 --> 0.302031).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5418635
	speed: 0.0913s/iter; left time: 908.9839s
Epoch: 7 cost time: 9.718462705612183
Epoch: 7, Steps: 107 Train Loss: 0.5435 (Forecasting Loss:0.2357 + XiCon Loss:3.0779 x Lambda(0.1)), Vali MSE Loss: 0.3038 Test MSE Loss: 0.1302
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5459535
	speed: 0.0898s/iter; left time: 885.0060s
Epoch: 8 cost time: 9.789828062057495
Epoch: 8, Steps: 107 Train Loss: 0.5428 (Forecasting Loss:0.2350 + XiCon Loss:3.0774 x Lambda(0.1)), Vali MSE Loss: 0.3053 Test MSE Loss: 0.1296
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5600773
	speed: 0.0902s/iter; left time: 878.5961s
Epoch: 9 cost time: 9.725372791290283
Epoch: 9, Steps: 107 Train Loss: 0.5416 (Forecasting Loss:0.2342 + XiCon Loss:3.0742 x Lambda(0.1)), Vali MSE Loss: 0.3028 Test MSE Loss: 0.1295
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5451728
	speed: 0.0963s/iter; left time: 928.3929s
Epoch: 10 cost time: 10.458317279815674
Epoch: 10, Steps: 107 Train Loss: 0.5417 (Forecasting Loss:0.2342 + XiCon Loss:3.0747 x Lambda(0.1)), Vali MSE Loss: 0.3019 Test MSE Loss: 0.1294
Validation loss decreased (0.302031 --> 0.301851).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5409151
	speed: 0.0990s/iter; left time: 943.5402s
Epoch: 11 cost time: 10.717694997787476
Epoch: 11, Steps: 107 Train Loss: 0.5410 (Forecasting Loss:0.2339 + XiCon Loss:3.0714 x Lambda(0.1)), Vali MSE Loss: 0.3023 Test MSE Loss: 0.1292
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5472752
	speed: 0.0857s/iter; left time: 807.8170s
Epoch: 12 cost time: 9.283636331558228
Epoch: 12, Steps: 107 Train Loss: 0.5416 (Forecasting Loss:0.2342 + XiCon Loss:3.0732 x Lambda(0.1)), Vali MSE Loss: 0.3030 Test MSE Loss: 0.1293
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5474349
	speed: 0.0832s/iter; left time: 774.8392s
Epoch: 13 cost time: 9.026909351348877
Epoch: 13, Steps: 107 Train Loss: 0.5410 (Forecasting Loss:0.2341 + XiCon Loss:3.0690 x Lambda(0.1)), Vali MSE Loss: 0.3028 Test MSE Loss: 0.1293
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5262091
	speed: 0.0900s/iter; left time: 829.1166s
Epoch: 14 cost time: 9.593560695648193
Epoch: 14, Steps: 107 Train Loss: 0.5412 (Forecasting Loss:0.2340 + XiCon Loss:3.0721 x Lambda(0.1)), Vali MSE Loss: 0.3025 Test MSE Loss: 0.1293
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5421747
	speed: 0.0902s/iter; left time: 820.7372s
Epoch: 15 cost time: 9.765630722045898
Epoch: 15, Steps: 107 Train Loss: 0.5410 (Forecasting Loss:0.2337 + XiCon Loss:3.0721 x Lambda(0.1)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.1293
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5499966
	speed: 0.0908s/iter; left time: 816.8315s
Epoch: 16 cost time: 9.865449905395508
Epoch: 16, Steps: 107 Train Loss: 0.5405 (Forecasting Loss:0.2336 + XiCon Loss:3.0686 x Lambda(0.1)), Vali MSE Loss: 0.3033 Test MSE Loss: 0.1293
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5387253
	speed: 0.0907s/iter; left time: 806.2911s
Epoch: 17 cost time: 9.78702163696289
Epoch: 17, Steps: 107 Train Loss: 0.5409 (Forecasting Loss:0.2338 + XiCon Loss:3.0709 x Lambda(0.1)), Vali MSE Loss: 0.3032 Test MSE Loss: 0.1293
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5417570
	speed: 0.0882s/iter; left time: 774.5186s
Epoch: 18 cost time: 9.59967565536499
Epoch: 18, Steps: 107 Train Loss: 0.5405 (Forecasting Loss:0.2338 + XiCon Loss:3.0675 x Lambda(0.1)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.1293
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.5469018
	speed: 0.0867s/iter; left time: 752.4946s
Epoch: 19 cost time: 9.415528297424316
Epoch: 19, Steps: 107 Train Loss: 0.5413 (Forecasting Loss:0.2342 + XiCon Loss:3.0709 x Lambda(0.1)), Vali MSE Loss: 0.3024 Test MSE Loss: 0.1293
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.5363678
	speed: 0.0916s/iter; left time: 784.5361s
Epoch: 20 cost time: 9.879401206970215
Epoch: 20, Steps: 107 Train Loss: 0.5413 (Forecasting Loss:0.2338 + XiCon Loss:3.0751 x Lambda(0.1)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1293
Validation loss decreased (0.301851 --> 0.301637).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.5477467
	speed: 0.0926s/iter; left time: 783.0850s
Epoch: 21 cost time: 10.031271934509277
Epoch: 21, Steps: 107 Train Loss: 0.5409 (Forecasting Loss:0.2339 + XiCon Loss:3.0700 x Lambda(0.1)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.1293
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.5531363
	speed: 0.0880s/iter; left time: 734.7804s
Epoch: 22 cost time: 9.533217430114746
Epoch: 22, Steps: 107 Train Loss: 0.5408 (Forecasting Loss:0.2340 + XiCon Loss:3.0681 x Lambda(0.1)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.1293
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.5344672
	speed: 0.0930s/iter; left time: 766.9355s
Epoch: 23 cost time: 9.993057250976562
Epoch: 23, Steps: 107 Train Loss: 0.5410 (Forecasting Loss:0.2340 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.3023 Test MSE Loss: 0.1293
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.5417852
	speed: 0.0931s/iter; left time: 757.5001s
Epoch: 24 cost time: 10.0738046169281
Epoch: 24, Steps: 107 Train Loss: 0.5412 (Forecasting Loss:0.2339 + XiCon Loss:3.0732 x Lambda(0.1)), Vali MSE Loss: 0.3029 Test MSE Loss: 0.1293
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.5425462
	speed: 0.0907s/iter; left time: 728.2361s
Epoch: 25 cost time: 9.745115995407104
Epoch: 25, Steps: 107 Train Loss: 0.5415 (Forecasting Loss:0.2339 + XiCon Loss:3.0760 x Lambda(0.1)), Vali MSE Loss: 0.3032 Test MSE Loss: 0.1293
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.5630084
	speed: 0.0916s/iter; left time: 725.6808s
Epoch: 26 cost time: 9.871632814407349
Epoch: 26, Steps: 107 Train Loss: 0.5408 (Forecasting Loss:0.2339 + XiCon Loss:3.0690 x Lambda(0.1)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.1293
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.5421851
	speed: 0.0937s/iter; left time: 732.7832s
Epoch: 27 cost time: 10.221894264221191
Epoch: 27, Steps: 107 Train Loss: 0.5412 (Forecasting Loss:0.2339 + XiCon Loss:3.0728 x Lambda(0.1)), Vali MSE Loss: 0.3033 Test MSE Loss: 0.1293
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.5440732
	speed: 0.0937s/iter; left time: 722.7341s
Epoch: 28 cost time: 10.05966591835022
Epoch: 28, Steps: 107 Train Loss: 0.5406 (Forecasting Loss:0.2339 + XiCon Loss:3.0670 x Lambda(0.1)), Vali MSE Loss: 0.3029 Test MSE Loss: 0.1293
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.5433649
	speed: 0.0841s/iter; left time: 639.8025s
Epoch: 29 cost time: 8.99123501777649
Epoch: 29, Steps: 107 Train Loss: 0.5413 (Forecasting Loss:0.2339 + XiCon Loss:3.0740 x Lambda(0.1)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1293
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.5429105
	speed: 0.0862s/iter; left time: 646.0457s
Epoch: 30 cost time: 9.3633553981781
Epoch: 30, Steps: 107 Train Loss: 0.5411 (Forecasting Loss:0.2341 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1293
Validation loss decreased (0.301637 --> 0.301617).  Saving model ...
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.5377550
	speed: 0.0923s/iter; left time: 682.5374s
Epoch: 31 cost time: 9.87995958328247
Epoch: 31, Steps: 107 Train Loss: 0.5413 (Forecasting Loss:0.2340 + XiCon Loss:3.0733 x Lambda(0.1)), Vali MSE Loss: 0.3028 Test MSE Loss: 0.1293
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 0.5372630
	speed: 0.0902s/iter; left time: 656.9468s
Epoch: 32 cost time: 9.70697808265686
Epoch: 32, Steps: 107 Train Loss: 0.5411 (Forecasting Loss:0.2338 + XiCon Loss:3.0723 x Lambda(0.1)), Vali MSE Loss: 0.3018 Test MSE Loss: 0.1293
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 0.5502102
	speed: 0.0932s/iter; left time: 669.1299s
Epoch: 33 cost time: 10.158431768417358
Epoch: 33, Steps: 107 Train Loss: 0.5412 (Forecasting Loss:0.2337 + XiCon Loss:3.0749 x Lambda(0.1)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.1293
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 0.5412264
	speed: 0.0902s/iter; left time: 637.8217s
Epoch: 34 cost time: 9.686384677886963
Epoch: 34, Steps: 107 Train Loss: 0.5408 (Forecasting Loss:0.2337 + XiCon Loss:3.0711 x Lambda(0.1)), Vali MSE Loss: 0.3032 Test MSE Loss: 0.1293
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 0.5356138
	speed: 0.0879s/iter; left time: 611.8334s
Epoch: 35 cost time: 9.5637366771698
Epoch: 35, Steps: 107 Train Loss: 0.5406 (Forecasting Loss:0.2339 + XiCon Loss:3.0670 x Lambda(0.1)), Vali MSE Loss: 0.3030 Test MSE Loss: 0.1293
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 0.5373079
	speed: 0.0919s/iter; left time: 629.7494s
Epoch: 36 cost time: 9.906527757644653
Epoch: 36, Steps: 107 Train Loss: 0.5410 (Forecasting Loss:0.2340 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.3028 Test MSE Loss: 0.1293
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 0.5208203
	speed: 0.0927s/iter; left time: 625.9469s
Epoch: 37 cost time: 10.034881114959717
Epoch: 37, Steps: 107 Train Loss: 0.5409 (Forecasting Loss:0.2338 + XiCon Loss:3.0718 x Lambda(0.1)), Vali MSE Loss: 0.3027 Test MSE Loss: 0.1293
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 0.5268286
	speed: 0.0880s/iter; left time: 584.2928s
Epoch: 38 cost time: 9.499266386032104
Epoch: 38, Steps: 107 Train Loss: 0.5412 (Forecasting Loss:0.2341 + XiCon Loss:3.0707 x Lambda(0.1)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.1293
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 0.5468301
	speed: 0.0922s/iter; left time: 602.3840s
Epoch: 39 cost time: 9.860342502593994
Epoch: 39, Steps: 107 Train Loss: 0.5418 (Forecasting Loss:0.2341 + XiCon Loss:3.0772 x Lambda(0.1)), Vali MSE Loss: 0.3024 Test MSE Loss: 0.1293
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 0.5561795
	speed: 0.0894s/iter; left time: 574.5869s
Epoch: 40 cost time: 9.556136846542358
Epoch: 40, Steps: 107 Train Loss: 0.5408 (Forecasting Loss:0.2338 + XiCon Loss:3.0704 x Lambda(0.1)), Vali MSE Loss: 0.3030 Test MSE Loss: 0.1293
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06268526613712311, mae:0.19588938355445862, mape:0.1450250744819641, mspe:0.03788675740361214 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0724+-0.00944, MAE:0.2122+-0.01490, MAPE:0.1545+-0.00913, MSPE:0.0402+-0.00375, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6065
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.715317726135254
Epoch: 1, Steps: 96 Train Loss: 1.0593 (Forecasting Loss:0.7436 + XiCon Loss:3.1565 x Lambda(0.1)), Vali MSE Loss: 0.4370 Test MSE Loss: 0.2930
Validation loss decreased (inf --> 0.437048).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.862140893936157
Epoch: 2, Steps: 96 Train Loss: 0.8610 (Forecasting Loss:0.5503 + XiCon Loss:3.1074 x Lambda(0.1)), Vali MSE Loss: 0.2695 Test MSE Loss: 0.1687
Validation loss decreased (0.437048 --> 0.269513).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.026114225387573
Epoch: 3, Steps: 96 Train Loss: 0.6020 (Forecasting Loss:0.2959 + XiCon Loss:3.0608 x Lambda(0.1)), Vali MSE Loss: 0.2933 Test MSE Loss: 0.1548
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 12.903060674667358
Epoch: 4, Steps: 96 Train Loss: 0.5604 (Forecasting Loss:0.2575 + XiCon Loss:3.0295 x Lambda(0.1)), Vali MSE Loss: 0.3034 Test MSE Loss: 0.1675
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.74825119972229
Epoch: 5, Steps: 96 Train Loss: 0.5529 (Forecasting Loss:0.2493 + XiCon Loss:3.0352 x Lambda(0.1)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.1675
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 14.2302405834198
Epoch: 6, Steps: 96 Train Loss: 0.5506 (Forecasting Loss:0.2459 + XiCon Loss:3.0470 x Lambda(0.1)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.1669
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.221350193023682
Epoch: 7, Steps: 96 Train Loss: 0.5496 (Forecasting Loss:0.2442 + XiCon Loss:3.0542 x Lambda(0.1)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.1704
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 14.293396711349487
Epoch: 8, Steps: 96 Train Loss: 0.5484 (Forecasting Loss:0.2432 + XiCon Loss:3.0519 x Lambda(0.1)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1654
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.647730350494385
Epoch: 9, Steps: 96 Train Loss: 0.5487 (Forecasting Loss:0.2431 + XiCon Loss:3.0558 x Lambda(0.1)), Vali MSE Loss: 0.2915 Test MSE Loss: 0.1698
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.520797967910767
Epoch: 10, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2427 + XiCon Loss:3.0509 x Lambda(0.1)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1696
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 13.484659910202026
Epoch: 11, Steps: 96 Train Loss: 0.5483 (Forecasting Loss:0.2425 + XiCon Loss:3.0577 x Lambda(0.1)), Vali MSE Loss: 0.2913 Test MSE Loss: 0.1687
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 13.408376455307007
Epoch: 12, Steps: 96 Train Loss: 0.5478 (Forecasting Loss:0.2424 + XiCon Loss:3.0540 x Lambda(0.1)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.1692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.09431882947683334, mae:0.24300166964530945, mape:0.17222432792186737, mspe:0.04493904486298561 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7502
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 14.149209260940552
Epoch: 1, Steps: 96 Train Loss: 1.0366 (Forecasting Loss:0.7214 + XiCon Loss:3.1520 x Lambda(0.1)), Vali MSE Loss: 0.4323 Test MSE Loss: 0.2619
Validation loss decreased (inf --> 0.432277).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.6814603805542
Epoch: 2, Steps: 96 Train Loss: 0.7810 (Forecasting Loss:0.4725 + XiCon Loss:3.0849 x Lambda(0.1)), Vali MSE Loss: 0.3173 Test MSE Loss: 0.1474
Validation loss decreased (0.432277 --> 0.317255).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.11384654045105
Epoch: 3, Steps: 96 Train Loss: 0.5834 (Forecasting Loss:0.2782 + XiCon Loss:3.0520 x Lambda(0.1)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.1400
Validation loss decreased (0.317255 --> 0.282080).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.55683422088623
Epoch: 4, Steps: 96 Train Loss: 0.5649 (Forecasting Loss:0.2582 + XiCon Loss:3.0668 x Lambda(0.1)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.1444
Validation loss decreased (0.282080 --> 0.271513).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.59185528755188
Epoch: 5, Steps: 96 Train Loss: 0.5594 (Forecasting Loss:0.2508 + XiCon Loss:3.0857 x Lambda(0.1)), Vali MSE Loss: 0.2685 Test MSE Loss: 0.1489
Validation loss decreased (0.271513 --> 0.268466).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.41728663444519
Epoch: 6, Steps: 96 Train Loss: 0.5567 (Forecasting Loss:0.2475 + XiCon Loss:3.0919 x Lambda(0.1)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.1445
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 13.192457437515259
Epoch: 7, Steps: 96 Train Loss: 0.5550 (Forecasting Loss:0.2458 + XiCon Loss:3.0917 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1427
Validation loss decreased (0.268466 --> 0.265263).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.872554063796997
Epoch: 8, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2445 + XiCon Loss:3.0970 x Lambda(0.1)), Vali MSE Loss: 0.2681 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 13.53410816192627
Epoch: 9, Steps: 96 Train Loss: 0.5541 (Forecasting Loss:0.2446 + XiCon Loss:3.0945 x Lambda(0.1)), Vali MSE Loss: 0.2682 Test MSE Loss: 0.1444
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 13.515392303466797
Epoch: 10, Steps: 96 Train Loss: 0.5540 (Forecasting Loss:0.2444 + XiCon Loss:3.0963 x Lambda(0.1)), Vali MSE Loss: 0.2669 Test MSE Loss: 0.1431
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 14.507527828216553
Epoch: 11, Steps: 96 Train Loss: 0.5545 (Forecasting Loss:0.2444 + XiCon Loss:3.1012 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.1432
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 14.016165733337402
Epoch: 12, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2440 + XiCon Loss:3.0983 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 13.894225120544434
Epoch: 13, Steps: 96 Train Loss: 0.5535 (Forecasting Loss:0.2442 + XiCon Loss:3.0932 x Lambda(0.1)), Vali MSE Loss: 0.2651 Test MSE Loss: 0.1433
Validation loss decreased (0.265263 --> 0.265085).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 13.63953709602356
Epoch: 14, Steps: 96 Train Loss: 0.5532 (Forecasting Loss:0.2438 + XiCon Loss:3.0941 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1433
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 13.937005758285522
Epoch: 15, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2439 + XiCon Loss:3.1038 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 13.409723281860352
Epoch: 16, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2436 + XiCon Loss:3.0973 x Lambda(0.1)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 13.251422882080078
Epoch: 17, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2436 + XiCon Loss:3.1020 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 14.001744508743286
Epoch: 18, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2442 + XiCon Loss:3.0972 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1434
Validation loss decreased (0.265085 --> 0.264985).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 13.449725866317749
Epoch: 19, Steps: 96 Train Loss: 0.5536 (Forecasting Loss:0.2438 + XiCon Loss:3.0983 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 13.16205096244812
Epoch: 20, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2439 + XiCon Loss:3.0985 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1434
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 13.935947895050049
Epoch: 21, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2440 + XiCon Loss:3.0986 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 14.159403800964355
Epoch: 22, Steps: 96 Train Loss: 0.5539 (Forecasting Loss:0.2440 + XiCon Loss:3.0996 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 14.452768564224243
Epoch: 23, Steps: 96 Train Loss: 0.5535 (Forecasting Loss:0.2436 + XiCon Loss:3.0991 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 14.040954351425171
Epoch: 24, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2439 + XiCon Loss:3.0990 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.1434
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 12.874656200408936
Epoch: 25, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2437 + XiCon Loss:3.0960 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.1434
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 13.545608282089233
Epoch: 26, Steps: 96 Train Loss: 0.5537 (Forecasting Loss:0.2438 + XiCon Loss:3.0996 x Lambda(0.1)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.1434
Validation loss decreased (0.264985 --> 0.264937).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 13.568477869033813
Epoch: 27, Steps: 96 Train Loss: 0.5541 (Forecasting Loss:0.2436 + XiCon Loss:3.1052 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1434
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 13.054455041885376
Epoch: 28, Steps: 96 Train Loss: 0.5536 (Forecasting Loss:0.2439 + XiCon Loss:3.0966 x Lambda(0.1)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1434
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 13.7404203414917
Epoch: 29, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2441 + XiCon Loss:3.0972 x Lambda(0.1)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1434
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 13.268577575683594
Epoch: 30, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2438 + XiCon Loss:3.0997 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 13.588414669036865
Epoch: 31, Steps: 96 Train Loss: 0.5543 (Forecasting Loss:0.2441 + XiCon Loss:3.1016 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.1434
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 13.287257194519043
Epoch: 32, Steps: 96 Train Loss: 0.5538 (Forecasting Loss:0.2440 + XiCon Loss:3.0980 x Lambda(0.1)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1434
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 14.926552057266235
Epoch: 33, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2442 + XiCon Loss:3.0996 x Lambda(0.1)), Vali MSE Loss: 0.2656 Test MSE Loss: 0.1434
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 13.525040864944458
Epoch: 34, Steps: 96 Train Loss: 0.5542 (Forecasting Loss:0.2442 + XiCon Loss:3.0991 x Lambda(0.1)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1434
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 13.72071361541748
Epoch: 35, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2439 + XiCon Loss:3.0944 x Lambda(0.1)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1434
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 12.985729694366455
Epoch: 36, Steps: 96 Train Loss: 0.5533 (Forecasting Loss:0.2437 + XiCon Loss:3.0959 x Lambda(0.1)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1434
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07387422025203705, mae:0.21291464567184448, mape:0.155736044049263, mspe:0.04083242267370224 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7523
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.475728273391724
Epoch: 1, Steps: 96 Train Loss: 1.0626 (Forecasting Loss:0.7479 + XiCon Loss:3.1474 x Lambda(0.1)), Vali MSE Loss: 0.5286 Test MSE Loss: 0.3407
Validation loss decreased (inf --> 0.528568).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 20.723812103271484
Epoch: 2, Steps: 96 Train Loss: 0.6663 (Forecasting Loss:0.3604 + XiCon Loss:3.0585 x Lambda(0.1)), Vali MSE Loss: 0.2880 Test MSE Loss: 0.1644
Validation loss decreased (0.528568 --> 0.288047).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 23.26684260368347
Epoch: 3, Steps: 96 Train Loss: 0.5531 (Forecasting Loss:0.2516 + XiCon Loss:3.0150 x Lambda(0.1)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.1784
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 22.63432788848877
Epoch: 4, Steps: 96 Train Loss: 0.5469 (Forecasting Loss:0.2412 + XiCon Loss:3.0572 x Lambda(0.1)), Vali MSE Loss: 0.2766 Test MSE Loss: 0.1604
Validation loss decreased (0.288047 --> 0.276558).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 22.855976104736328
Epoch: 5, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2367 + XiCon Loss:3.0898 x Lambda(0.1)), Vali MSE Loss: 0.2769 Test MSE Loss: 0.1614
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 22.551514148712158
Epoch: 6, Steps: 96 Train Loss: 0.5451 (Forecasting Loss:0.2348 + XiCon Loss:3.1028 x Lambda(0.1)), Vali MSE Loss: 0.2685 Test MSE Loss: 0.1575
Validation loss decreased (0.276558 --> 0.268546).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 22.16341280937195
Epoch: 7, Steps: 96 Train Loss: 0.5460 (Forecasting Loss:0.2342 + XiCon Loss:3.1180 x Lambda(0.1)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1606
Validation loss decreased (0.268546 --> 0.261760).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 22.075352430343628
Epoch: 8, Steps: 96 Train Loss: 0.5458 (Forecasting Loss:0.2334 + XiCon Loss:3.1240 x Lambda(0.1)), Vali MSE Loss: 0.2621 Test MSE Loss: 0.1621
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 22.02610945701599
Epoch: 9, Steps: 96 Train Loss: 0.5462 (Forecasting Loss:0.2333 + XiCon Loss:3.1290 x Lambda(0.1)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.1599
Validation loss decreased (0.261760 --> 0.260242).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 22.623172521591187
Epoch: 10, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2330 + XiCon Loss:3.1334 x Lambda(0.1)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1607
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 22.45866847038269
Epoch: 11, Steps: 96 Train Loss: 0.5459 (Forecasting Loss:0.2331 + XiCon Loss:3.1285 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1607
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 22.390674114227295
Epoch: 12, Steps: 96 Train Loss: 0.5463 (Forecasting Loss:0.2330 + XiCon Loss:3.1335 x Lambda(0.1)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1612
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 22.114534378051758
Epoch: 13, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2332 + XiCon Loss:3.1292 x Lambda(0.1)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1608
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 22.00852656364441
Epoch: 14, Steps: 96 Train Loss: 0.5459 (Forecasting Loss:0.2330 + XiCon Loss:3.1286 x Lambda(0.1)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.1610
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 22.40250325202942
Epoch: 15, Steps: 96 Train Loss: 0.5455 (Forecasting Loss:0.2328 + XiCon Loss:3.1274 x Lambda(0.1)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.1609
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 22.010133504867554
Epoch: 16, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2331 + XiCon Loss:3.1291 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1609
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 22.191072463989258
Epoch: 17, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2328 + XiCon Loss:3.1329 x Lambda(0.1)), Vali MSE Loss: 0.2608 Test MSE Loss: 0.1609
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 21.9229953289032
Epoch: 18, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2333 + XiCon Loss:3.1313 x Lambda(0.1)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.1609
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 22.570210218429565
Epoch: 19, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2330 + XiCon Loss:3.1346 x Lambda(0.1)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1609
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08760541677474976, mae:0.23213836550712585, mape:0.17424024641513824, mspe:0.05685604736208916 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7162
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.15678095817566
Epoch: 1, Steps: 96 Train Loss: 1.0296 (Forecasting Loss:0.7124 + XiCon Loss:3.1718 x Lambda(0.1)), Vali MSE Loss: 0.4067 Test MSE Loss: 0.2468
Validation loss decreased (inf --> 0.406684).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 13.573948860168457
Epoch: 2, Steps: 96 Train Loss: 0.7796 (Forecasting Loss:0.4691 + XiCon Loss:3.1051 x Lambda(0.1)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1633
Validation loss decreased (0.406684 --> 0.259428).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 13.765356540679932
Epoch: 3, Steps: 96 Train Loss: 0.5961 (Forecasting Loss:0.2907 + XiCon Loss:3.0542 x Lambda(0.1)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1406
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 13.573441982269287
Epoch: 4, Steps: 96 Train Loss: 0.5721 (Forecasting Loss:0.2623 + XiCon Loss:3.0978 x Lambda(0.1)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.1547
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 13.501655578613281
Epoch: 5, Steps: 96 Train Loss: 0.5647 (Forecasting Loss:0.2525 + XiCon Loss:3.1217 x Lambda(0.1)), Vali MSE Loss: 0.2728 Test MSE Loss: 0.1452
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 13.675571203231812
Epoch: 6, Steps: 96 Train Loss: 0.5630 (Forecasting Loss:0.2495 + XiCon Loss:3.1355 x Lambda(0.1)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.1464
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.218828201293945
Epoch: 7, Steps: 96 Train Loss: 0.5615 (Forecasting Loss:0.2476 + XiCon Loss:3.1392 x Lambda(0.1)), Vali MSE Loss: 0.2778 Test MSE Loss: 0.1529
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 13.553791046142578
Epoch: 8, Steps: 96 Train Loss: 0.5606 (Forecasting Loss:0.2459 + XiCon Loss:3.1475 x Lambda(0.1)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.1548
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 14.199795961380005
Epoch: 9, Steps: 96 Train Loss: 0.5605 (Forecasting Loss:0.2459 + XiCon Loss:3.1469 x Lambda(0.1)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.1549
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 14.328216075897217
Epoch: 10, Steps: 96 Train Loss: 0.5603 (Forecasting Loss:0.2456 + XiCon Loss:3.1476 x Lambda(0.1)), Vali MSE Loss: 0.2870 Test MSE Loss: 0.1539
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 13.834125518798828
Epoch: 11, Steps: 96 Train Loss: 0.5600 (Forecasting Loss:0.2456 + XiCon Loss:3.1432 x Lambda(0.1)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.1542
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 13.803774356842041
Epoch: 12, Steps: 96 Train Loss: 0.5600 (Forecasting Loss:0.2455 + XiCon Loss:3.1450 x Lambda(0.1)), Vali MSE Loss: 0.2844 Test MSE Loss: 0.1552
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.08943203836679459, mae:0.23706845939159393, mape:0.1682290881872177, mspe:0.04305076226592064 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6764
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.49483036994934
Epoch: 1, Steps: 96 Train Loss: 1.0638 (Forecasting Loss:0.7491 + XiCon Loss:3.1473 x Lambda(0.1)), Vali MSE Loss: 0.5495 Test MSE Loss: 0.3516
Validation loss decreased (inf --> 0.549536).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 20.508289337158203
Epoch: 2, Steps: 96 Train Loss: 0.7089 (Forecasting Loss:0.3993 + XiCon Loss:3.0964 x Lambda(0.1)), Vali MSE Loss: 0.3586 Test MSE Loss: 0.1629
Validation loss decreased (0.549536 --> 0.358624).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 22.210413694381714
Epoch: 3, Steps: 96 Train Loss: 0.5610 (Forecasting Loss:0.2533 + XiCon Loss:3.0766 x Lambda(0.1)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.1454
Validation loss decreased (0.358624 --> 0.270433).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 23.015007257461548
Epoch: 4, Steps: 96 Train Loss: 0.5526 (Forecasting Loss:0.2431 + XiCon Loss:3.0947 x Lambda(0.1)), Vali MSE Loss: 0.2395 Test MSE Loss: 0.1470
Validation loss decreased (0.270433 --> 0.239450).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 22.70977759361267
Epoch: 5, Steps: 96 Train Loss: 0.5493 (Forecasting Loss:0.2384 + XiCon Loss:3.1085 x Lambda(0.1)), Vali MSE Loss: 0.2339 Test MSE Loss: 0.1403
Validation loss decreased (0.239450 --> 0.233889).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 23.054069757461548
Epoch: 6, Steps: 96 Train Loss: 0.5475 (Forecasting Loss:0.2358 + XiCon Loss:3.1168 x Lambda(0.1)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1424
Validation loss decreased (0.233889 --> 0.230720).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 23.93248677253723
Epoch: 7, Steps: 96 Train Loss: 0.5468 (Forecasting Loss:0.2346 + XiCon Loss:3.1223 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1404
Validation loss decreased (0.230720 --> 0.228523).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 22.018672704696655
Epoch: 8, Steps: 96 Train Loss: 0.5462 (Forecasting Loss:0.2340 + XiCon Loss:3.1216 x Lambda(0.1)), Vali MSE Loss: 0.2269 Test MSE Loss: 0.1393
Validation loss decreased (0.228523 --> 0.226888).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 22.680307865142822
Epoch: 9, Steps: 96 Train Loss: 0.5458 (Forecasting Loss:0.2337 + XiCon Loss:3.1207 x Lambda(0.1)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.1391
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 22.674702405929565
Epoch: 10, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2332 + XiCon Loss:3.1242 x Lambda(0.1)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.1392
Validation loss decreased (0.226888 --> 0.226153).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 22.25804829597473
Epoch: 11, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2335 + XiCon Loss:3.1253 x Lambda(0.1)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 22.205734968185425
Epoch: 12, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2335 + XiCon Loss:3.1222 x Lambda(0.1)), Vali MSE Loss: 0.2279 Test MSE Loss: 0.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 21.668832778930664
Epoch: 13, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2334 + XiCon Loss:3.1229 x Lambda(0.1)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.1389
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 22.669314861297607
Epoch: 14, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2337 + XiCon Loss:3.1236 x Lambda(0.1)), Vali MSE Loss: 0.2270 Test MSE Loss: 0.1390
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 22.08433961868286
Epoch: 15, Steps: 96 Train Loss: 0.5452 (Forecasting Loss:0.2334 + XiCon Loss:3.1187 x Lambda(0.1)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1390
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 21.591378927230835
Epoch: 16, Steps: 96 Train Loss: 0.5455 (Forecasting Loss:0.2334 + XiCon Loss:3.1205 x Lambda(0.1)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.1390
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 22.263301849365234
Epoch: 17, Steps: 96 Train Loss: 0.5457 (Forecasting Loss:0.2335 + XiCon Loss:3.1221 x Lambda(0.1)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.1390
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 22.631437301635742
Epoch: 18, Steps: 96 Train Loss: 0.5461 (Forecasting Loss:0.2337 + XiCon Loss:3.1240 x Lambda(0.1)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.1390
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 22.43410325050354
Epoch: 19, Steps: 96 Train Loss: 0.5456 (Forecasting Loss:0.2332 + XiCon Loss:3.1233 x Lambda(0.1)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.1390
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 21.685802221298218
Epoch: 20, Steps: 96 Train Loss: 0.5464 (Forecasting Loss:0.2334 + XiCon Loss:3.1296 x Lambda(0.1)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.1390
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07072744518518448, mae:0.2077636569738388, mape:0.15678030252456665, mspe:0.0452633835375309 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0832+-0.01279, MAE:0.2266+-0.01915, MAPE:0.1654+-0.01076, MSPE:0.0462+-0.00772, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5833
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6963043
	speed: 0.0395s/iter; left time: 501.1074s
Epoch: 1 cost time: 4.505720376968384
Epoch: 1, Steps: 128 Train Loss: 31.0406 (Forecasting Loss:0.2931 + XiCon Loss:3.0747 x Lambda(10.0)), Vali MSE Loss: 0.2773 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.277323).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8812428
	speed: 0.0356s/iter; left time: 447.6700s
Epoch: 2 cost time: 4.33529806137085
Epoch: 2, Steps: 128 Train Loss: 29.2228 (Forecasting Loss:0.2570 + XiCon Loss:2.8966 x Lambda(10.0)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.2194
Validation loss decreased (0.277323 --> 0.256408).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.3575325
	speed: 0.0364s/iter; left time: 452.4483s
Epoch: 3 cost time: 4.456241130828857
Epoch: 3, Steps: 128 Train Loss: 28.8686 (Forecasting Loss:0.2437 + XiCon Loss:2.8625 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2209
Validation loss decreased (0.256408 --> 0.252600).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1747169
	speed: 0.0326s/iter; left time: 402.1230s
Epoch: 4 cost time: 4.320810794830322
Epoch: 4, Steps: 128 Train Loss: 30.3647 (Forecasting Loss:0.2379 + XiCon Loss:3.0127 x Lambda(10.0)), Vali MSE Loss: 0.2530 Test MSE Loss: 0.2057
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9392509
	speed: 0.0353s/iter; left time: 430.5277s
Epoch: 5 cost time: 4.539468288421631
Epoch: 5, Steps: 128 Train Loss: 30.6259 (Forecasting Loss:0.2347 + XiCon Loss:3.0391 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2076
Validation loss decreased (0.252600 --> 0.250809).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3880272
	speed: 0.0291s/iter; left time: 350.5827s
Epoch: 6 cost time: 3.665290117263794
Epoch: 6, Steps: 128 Train Loss: 30.6990 (Forecasting Loss:0.2329 + XiCon Loss:3.0466 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2061
Validation loss decreased (0.250809 --> 0.249695).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.7636013
	speed: 0.0229s/iter; left time: 273.0902s
Epoch: 7 cost time: 2.9744536876678467
Epoch: 7, Steps: 128 Train Loss: 30.7837 (Forecasting Loss:0.2318 + XiCon Loss:3.0552 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2066
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.0222073
	speed: 0.0247s/iter; left time: 291.2401s
Epoch: 8 cost time: 3.0151896476745605
Epoch: 8, Steps: 128 Train Loss: 30.8001 (Forecasting Loss:0.2316 + XiCon Loss:3.0568 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.2248421
	speed: 0.0332s/iter; left time: 387.2377s
Epoch: 9 cost time: 4.061391830444336
Epoch: 9, Steps: 128 Train Loss: 30.7638 (Forecasting Loss:0.2315 + XiCon Loss:3.0532 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2052
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1269398
	speed: 0.0306s/iter; left time: 352.9471s
Epoch: 10 cost time: 3.8032071590423584
Epoch: 10, Steps: 128 Train Loss: 30.6884 (Forecasting Loss:0.2314 + XiCon Loss:3.0457 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2054
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5448570
	speed: 0.0290s/iter; left time: 331.7506s
Epoch: 11 cost time: 3.7037434577941895
Epoch: 11, Steps: 128 Train Loss: 30.7490 (Forecasting Loss:0.2313 + XiCon Loss:3.0518 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2054
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7903690
	speed: 0.0261s/iter; left time: 295.0900s
Epoch: 12 cost time: 3.383664131164551
Epoch: 12, Steps: 128 Train Loss: 30.7890 (Forecasting Loss:0.2313 + XiCon Loss:3.0558 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2053
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.5253239
	speed: 0.0282s/iter; left time: 315.0352s
Epoch: 13 cost time: 3.5646283626556396
Epoch: 13, Steps: 128 Train Loss: 30.8375 (Forecasting Loss:0.2312 + XiCon Loss:3.0606 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2053
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.7478809
	speed: 0.0252s/iter; left time: 278.2997s
Epoch: 14 cost time: 3.548133611679077
Epoch: 14, Steps: 128 Train Loss: 30.8789 (Forecasting Loss:0.2309 + XiCon Loss:3.0648 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2053
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.5526886
	speed: 0.0273s/iter; left time: 297.9482s
Epoch: 15 cost time: 3.4176042079925537
Epoch: 15, Steps: 128 Train Loss: 30.7695 (Forecasting Loss:0.2310 + XiCon Loss:3.0539 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2053
Validation loss decreased (0.249695 --> 0.249677).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.2810059
	speed: 0.0252s/iter; left time: 272.1496s
Epoch: 16 cost time: 3.147423505783081
Epoch: 16, Steps: 128 Train Loss: 30.8409 (Forecasting Loss:0.2312 + XiCon Loss:3.0610 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2053
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.0682068
	speed: 0.0255s/iter; left time: 272.1007s
Epoch: 17 cost time: 3.260782480239868
Epoch: 17, Steps: 128 Train Loss: 30.9287 (Forecasting Loss:0.2312 + XiCon Loss:3.0697 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2053
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.4062824
	speed: 0.0305s/iter; left time: 320.7782s
Epoch: 18 cost time: 3.6958751678466797
Epoch: 18, Steps: 128 Train Loss: 30.8701 (Forecasting Loss:0.2312 + XiCon Loss:3.0639 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2053
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.6119213
	speed: 0.0287s/iter; left time: 298.3453s
Epoch: 19 cost time: 3.412816047668457
Epoch: 19, Steps: 128 Train Loss: 30.7261 (Forecasting Loss:0.2311 + XiCon Loss:3.0495 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2053
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.0405235
	speed: 0.0289s/iter; left time: 296.9804s
Epoch: 20 cost time: 3.4633233547210693
Epoch: 20, Steps: 128 Train Loss: 30.8241 (Forecasting Loss:0.2312 + XiCon Loss:3.0593 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2053
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.2944660
	speed: 0.0302s/iter; left time: 306.1370s
Epoch: 21 cost time: 3.900362491607666
Epoch: 21, Steps: 128 Train Loss: 30.8554 (Forecasting Loss:0.2309 + XiCon Loss:3.0624 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2053
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.0507240
	speed: 0.0288s/iter; left time: 288.0365s
Epoch: 22 cost time: 3.4606359004974365
Epoch: 22, Steps: 128 Train Loss: 30.8306 (Forecasting Loss:0.2312 + XiCon Loss:3.0599 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2053
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.6617260
	speed: 0.0235s/iter; left time: 232.0526s
Epoch: 23 cost time: 3.163745641708374
Epoch: 23, Steps: 128 Train Loss: 30.7764 (Forecasting Loss:0.2312 + XiCon Loss:3.0545 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2053
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.2285175
	speed: 0.0251s/iter; left time: 244.7213s
Epoch: 24 cost time: 3.30511474609375
Epoch: 24, Steps: 128 Train Loss: 30.7661 (Forecasting Loss:0.2311 + XiCon Loss:3.0535 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2053
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.4610119
	speed: 0.0235s/iter; left time: 226.3818s
Epoch: 25 cost time: 2.984933853149414
Epoch: 25, Steps: 128 Train Loss: 30.7657 (Forecasting Loss:0.2311 + XiCon Loss:3.0535 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2053
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13103604316711426, mae:0.2795664072036743, mape:0.6602675318717957, mspe:19.445066452026367 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6990
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.7672367
	speed: 0.0287s/iter; left time: 364.4161s
Epoch: 1 cost time: 3.7488811016082764
Epoch: 1, Steps: 128 Train Loss: 31.0321 (Forecasting Loss:0.2945 + XiCon Loss:3.0738 x Lambda(10.0)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.2300
Validation loss decreased (inf --> 0.276548).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.0786476
	speed: 0.0313s/iter; left time: 392.9071s
Epoch: 2 cost time: 3.9140727519989014
Epoch: 2, Steps: 128 Train Loss: 29.3056 (Forecasting Loss:0.2612 + XiCon Loss:2.9044 x Lambda(10.0)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.2278
Validation loss decreased (0.276548 --> 0.262000).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.3428516
	speed: 0.0302s/iter; left time: 375.2974s
Epoch: 3 cost time: 3.9051513671875
Epoch: 3, Steps: 128 Train Loss: 29.8559 (Forecasting Loss:0.2423 + XiCon Loss:2.9614 x Lambda(10.0)), Vali MSE Loss: 0.2632 Test MSE Loss: 0.2124
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.8335991
	speed: 0.0300s/iter; left time: 369.1028s
Epoch: 4 cost time: 3.6409478187561035
Epoch: 4, Steps: 128 Train Loss: 29.3850 (Forecasting Loss:0.2367 + XiCon Loss:2.9148 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2033
Validation loss decreased (0.262000 --> 0.248590).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.6292076
	speed: 0.0274s/iter; left time: 333.7270s
Epoch: 5 cost time: 3.3843915462493896
Epoch: 5, Steps: 128 Train Loss: 29.1802 (Forecasting Loss:0.2326 + XiCon Loss:2.8948 x Lambda(10.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2021
Validation loss decreased (0.248590 --> 0.247697).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.1658955
	speed: 0.0247s/iter; left time: 297.9493s
Epoch: 6 cost time: 3.2429392337799072
Epoch: 6, Steps: 128 Train Loss: 29.0994 (Forecasting Loss:0.2303 + XiCon Loss:2.8869 x Lambda(10.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.2041
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.8692627
	speed: 0.0212s/iter; left time: 253.3561s
Epoch: 7 cost time: 2.610477924346924
Epoch: 7, Steps: 128 Train Loss: 29.1172 (Forecasting Loss:0.2292 + XiCon Loss:2.8888 x Lambda(10.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.2021
Validation loss decreased (0.247697 --> 0.246763).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.5403080
	speed: 0.0278s/iter; left time: 327.8708s
Epoch: 8 cost time: 3.4927818775177
Epoch: 8, Steps: 128 Train Loss: 29.0388 (Forecasting Loss:0.2290 + XiCon Loss:2.8810 x Lambda(10.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.2026
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9260273
	speed: 0.0284s/iter; left time: 331.2343s
Epoch: 9 cost time: 3.465531587600708
Epoch: 9, Steps: 128 Train Loss: 29.0307 (Forecasting Loss:0.2286 + XiCon Loss:2.8802 x Lambda(10.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.2023
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.7474041
	speed: 0.0305s/iter; left time: 352.7579s
Epoch: 10 cost time: 3.7098000049591064
Epoch: 10, Steps: 128 Train Loss: 28.9911 (Forecasting Loss:0.2286 + XiCon Loss:2.8762 x Lambda(10.0)), Vali MSE Loss: 0.2467 Test MSE Loss: 0.2023
Validation loss decreased (0.246763 --> 0.246706).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3922672
	speed: 0.0328s/iter; left time: 375.1080s
Epoch: 11 cost time: 3.8966212272644043
Epoch: 11, Steps: 128 Train Loss: 29.0892 (Forecasting Loss:0.2286 + XiCon Loss:2.8861 x Lambda(10.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.2024
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.8315220
	speed: 0.0300s/iter; left time: 338.7162s
Epoch: 12 cost time: 3.7185471057891846
Epoch: 12, Steps: 128 Train Loss: 28.9852 (Forecasting Loss:0.2282 + XiCon Loss:2.8757 x Lambda(10.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.2023
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.4772072
	speed: 0.0277s/iter; left time: 309.7973s
Epoch: 13 cost time: 3.5357210636138916
Epoch: 13, Steps: 128 Train Loss: 29.0638 (Forecasting Loss:0.2285 + XiCon Loss:2.8835 x Lambda(10.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.2023
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.6243916
	speed: 0.0307s/iter; left time: 338.7073s
Epoch: 14 cost time: 3.92838716506958
Epoch: 14, Steps: 128 Train Loss: 29.0277 (Forecasting Loss:0.2284 + XiCon Loss:2.8799 x Lambda(10.0)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.2023
Validation loss decreased (0.246706 --> 0.246584).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.8536987
	speed: 0.0290s/iter; left time: 316.2719s
Epoch: 15 cost time: 3.753858804702759
Epoch: 15, Steps: 128 Train Loss: 29.0610 (Forecasting Loss:0.2284 + XiCon Loss:2.8833 x Lambda(10.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.2023
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.1109123
	speed: 0.0363s/iter; left time: 391.6038s
Epoch: 16 cost time: 4.646524667739868
Epoch: 16, Steps: 128 Train Loss: 29.0621 (Forecasting Loss:0.2284 + XiCon Loss:2.8834 x Lambda(10.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.2023
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5660114
	speed: 0.0295s/iter; left time: 313.7635s
Epoch: 17 cost time: 3.94828200340271
Epoch: 17, Steps: 128 Train Loss: 28.9823 (Forecasting Loss:0.2284 + XiCon Loss:2.8754 x Lambda(10.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.2023
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.6383343
	speed: 0.0287s/iter; left time: 302.5570s
Epoch: 18 cost time: 3.5630297660827637
Epoch: 18, Steps: 128 Train Loss: 29.0222 (Forecasting Loss:0.2283 + XiCon Loss:2.8794 x Lambda(10.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.2023
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.8827534
	speed: 0.0308s/iter; left time: 320.1757s
Epoch: 19 cost time: 3.984156608581543
Epoch: 19, Steps: 128 Train Loss: 29.0452 (Forecasting Loss:0.2283 + XiCon Loss:2.8817 x Lambda(10.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.2023
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.5194035
	speed: 0.0337s/iter; left time: 345.6728s
Epoch: 20 cost time: 4.171878337860107
Epoch: 20, Steps: 128 Train Loss: 28.9956 (Forecasting Loss:0.2284 + XiCon Loss:2.8767 x Lambda(10.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.2023
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 28.4456825
	speed: 0.0276s/iter; left time: 279.5939s
Epoch: 21 cost time: 3.2957231998443604
Epoch: 21, Steps: 128 Train Loss: 29.0856 (Forecasting Loss:0.2284 + XiCon Loss:2.8857 x Lambda(10.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.2023
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.6630783
	speed: 0.0224s/iter; left time: 224.2052s
Epoch: 22 cost time: 2.669842481613159
Epoch: 22, Steps: 128 Train Loss: 29.0044 (Forecasting Loss:0.2284 + XiCon Loss:2.8776 x Lambda(10.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.2023
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.5735912
	speed: 0.0200s/iter; left time: 198.0439s
Epoch: 23 cost time: 2.4515695571899414
Epoch: 23, Steps: 128 Train Loss: 29.0649 (Forecasting Loss:0.2286 + XiCon Loss:2.8836 x Lambda(10.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.2023
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 28.9221745
	speed: 0.0196s/iter; left time: 191.2273s
Epoch: 24 cost time: 2.3882033824920654
Epoch: 24, Steps: 128 Train Loss: 29.0336 (Forecasting Loss:0.2282 + XiCon Loss:2.8805 x Lambda(10.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.2023
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1275196224451065, mae:0.2770269215106964, mape:0.6773319244384766, mspe:20.180015563964844 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3928
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6425018
	speed: 0.0276s/iter; left time: 351.1821s
Epoch: 1 cost time: 3.2824954986572266
Epoch: 1, Steps: 128 Train Loss: 30.9461 (Forecasting Loss:0.2970 + XiCon Loss:3.0649 x Lambda(10.0)), Vali MSE Loss: 0.2755 Test MSE Loss: 0.2283
Validation loss decreased (inf --> 0.275479).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8498268
	speed: 0.0309s/iter; left time: 388.6009s
Epoch: 2 cost time: 3.7232584953308105
Epoch: 2, Steps: 128 Train Loss: 29.2450 (Forecasting Loss:0.2559 + XiCon Loss:2.8989 x Lambda(10.0)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.2153
Validation loss decreased (0.275479 --> 0.266058).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.5783195
	speed: 0.0277s/iter; left time: 345.0188s
Epoch: 3 cost time: 3.5919253826141357
Epoch: 3, Steps: 128 Train Loss: 29.2727 (Forecasting Loss:0.2443 + XiCon Loss:2.9028 x Lambda(10.0)), Vali MSE Loss: 0.2570 Test MSE Loss: 0.2062
Validation loss decreased (0.266058 --> 0.256980).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.7798786
	speed: 0.0217s/iter; left time: 267.5031s
Epoch: 4 cost time: 2.8715429306030273
Epoch: 4, Steps: 128 Train Loss: 30.2415 (Forecasting Loss:0.2372 + XiCon Loss:3.0004 x Lambda(10.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2057
Validation loss decreased (0.256980 --> 0.251031).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7883282
	speed: 0.0265s/iter; left time: 322.6437s
Epoch: 5 cost time: 3.2321834564208984
Epoch: 5, Steps: 128 Train Loss: 30.5802 (Forecasting Loss:0.2338 + XiCon Loss:3.0346 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2112
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6855240
	speed: 0.0243s/iter; left time: 293.6783s
Epoch: 6 cost time: 3.048452854156494
Epoch: 6, Steps: 128 Train Loss: 30.6278 (Forecasting Loss:0.2328 + XiCon Loss:3.0395 x Lambda(10.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2056
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.2301941
	speed: 0.0281s/iter; left time: 335.5335s
Epoch: 7 cost time: 3.3182458877563477
Epoch: 7, Steps: 128 Train Loss: 30.5444 (Forecasting Loss:0.2323 + XiCon Loss:3.0312 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2074
Validation loss decreased (0.251031 --> 0.249706).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.2915936
	speed: 0.0259s/iter; left time: 306.1711s
Epoch: 8 cost time: 3.3808958530426025
Epoch: 8, Steps: 128 Train Loss: 30.7270 (Forecasting Loss:0.2318 + XiCon Loss:3.0495 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2059
Validation loss decreased (0.249706 --> 0.249365).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.1642551
	speed: 0.0317s/iter; left time: 369.8883s
Epoch: 9 cost time: 4.007578134536743
Epoch: 9, Steps: 128 Train Loss: 30.4355 (Forecasting Loss:0.2316 + XiCon Loss:3.0204 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7912064
	speed: 0.0245s/iter; left time: 282.4590s
Epoch: 10 cost time: 3.1416749954223633
Epoch: 10, Steps: 128 Train Loss: 30.6208 (Forecasting Loss:0.2314 + XiCon Loss:3.0389 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2060
Validation loss decreased (0.249365 --> 0.249182).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3316479
	speed: 0.0201s/iter; left time: 229.0624s
Epoch: 11 cost time: 2.9199845790863037
Epoch: 11, Steps: 128 Train Loss: 30.4896 (Forecasting Loss:0.2315 + XiCon Loss:3.0258 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2060
Validation loss decreased (0.249182 --> 0.249169).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.6489067
	speed: 0.0259s/iter; left time: 292.5581s
Epoch: 12 cost time: 3.314354181289673
Epoch: 12, Steps: 128 Train Loss: 30.4880 (Forecasting Loss:0.2312 + XiCon Loss:3.0257 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.0225563
	speed: 0.0253s/iter; left time: 282.7485s
Epoch: 13 cost time: 3.1341073513031006
Epoch: 13, Steps: 128 Train Loss: 30.4656 (Forecasting Loss:0.2315 + XiCon Loss:3.0234 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2060
Validation loss decreased (0.249169 --> 0.249109).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.5514297
	speed: 0.0271s/iter; left time: 298.8052s
Epoch: 14 cost time: 3.2487289905548096
Epoch: 14, Steps: 128 Train Loss: 30.4342 (Forecasting Loss:0.2312 + XiCon Loss:3.0203 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2791958
	speed: 0.0281s/iter; left time: 307.0210s
Epoch: 15 cost time: 3.457658290863037
Epoch: 15, Steps: 128 Train Loss: 30.4074 (Forecasting Loss:0.2314 + XiCon Loss:3.0176 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2061
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.3831902
	speed: 0.0299s/iter; left time: 322.3743s
Epoch: 16 cost time: 3.6410233974456787
Epoch: 16, Steps: 128 Train Loss: 30.4500 (Forecasting Loss:0.2314 + XiCon Loss:3.0219 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2061
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.3843231
	speed: 0.0301s/iter; left time: 320.4803s
Epoch: 17 cost time: 3.680255651473999
Epoch: 17, Steps: 128 Train Loss: 30.5631 (Forecasting Loss:0.2314 + XiCon Loss:3.0332 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.8995647
	speed: 0.0315s/iter; left time: 331.3441s
Epoch: 18 cost time: 3.8038177490234375
Epoch: 18, Steps: 128 Train Loss: 30.5365 (Forecasting Loss:0.2313 + XiCon Loss:3.0305 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2061
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7464943
	speed: 0.0290s/iter; left time: 301.2564s
Epoch: 19 cost time: 3.5692543983459473
Epoch: 19, Steps: 128 Train Loss: 30.5832 (Forecasting Loss:0.2311 + XiCon Loss:3.0352 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2061
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.4983215
	speed: 0.0259s/iter; left time: 266.3945s
Epoch: 20 cost time: 3.3924171924591064
Epoch: 20, Steps: 128 Train Loss: 30.5304 (Forecasting Loss:0.2312 + XiCon Loss:3.0299 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2061
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.8887920
	speed: 0.0253s/iter; left time: 256.8530s
Epoch: 21 cost time: 3.5687527656555176
Epoch: 21, Steps: 128 Train Loss: 30.4995 (Forecasting Loss:0.2315 + XiCon Loss:3.0268 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2061
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.2746220
	speed: 0.0238s/iter; left time: 238.6752s
Epoch: 22 cost time: 2.759104013442993
Epoch: 22, Steps: 128 Train Loss: 30.5340 (Forecasting Loss:0.2312 + XiCon Loss:3.0303 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2061
Validation loss decreased (0.249109 --> 0.249099).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.4278469
	speed: 0.0271s/iter; left time: 267.9660s
Epoch: 23 cost time: 3.379084825515747
Epoch: 23, Steps: 128 Train Loss: 30.4611 (Forecasting Loss:0.2312 + XiCon Loss:3.0230 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2061
Validation loss decreased (0.249099 --> 0.248561).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.1403904
	speed: 0.0317s/iter; left time: 309.7777s
Epoch: 24 cost time: 3.7975094318389893
Epoch: 24, Steps: 128 Train Loss: 30.6013 (Forecasting Loss:0.2313 + XiCon Loss:3.0370 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2061
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.9851418
	speed: 0.0273s/iter; left time: 263.1279s
Epoch: 25 cost time: 3.564365863800049
Epoch: 25, Steps: 128 Train Loss: 30.4565 (Forecasting Loss:0.2313 + XiCon Loss:3.0225 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2061
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.5250549
	speed: 0.0278s/iter; left time: 263.9846s
Epoch: 26 cost time: 3.6112542152404785
Epoch: 26, Steps: 128 Train Loss: 30.4990 (Forecasting Loss:0.2314 + XiCon Loss:3.0268 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2061
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.6688824
	speed: 0.0290s/iter; left time: 272.2685s
Epoch: 27 cost time: 3.6329004764556885
Epoch: 27, Steps: 128 Train Loss: 30.5678 (Forecasting Loss:0.2314 + XiCon Loss:3.0336 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.9363689
	speed: 0.0282s/iter; left time: 260.9253s
Epoch: 28 cost time: 3.577117681503296
Epoch: 28, Steps: 128 Train Loss: 30.4620 (Forecasting Loss:0.2313 + XiCon Loss:3.0231 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2061
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.1722145
	speed: 0.0253s/iter; left time: 230.4285s
Epoch: 29 cost time: 3.2221808433532715
Epoch: 29, Steps: 128 Train Loss: 30.5010 (Forecasting Loss:0.2312 + XiCon Loss:3.0270 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2061
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 31.5237446
	speed: 0.0277s/iter; left time: 249.0685s
Epoch: 30 cost time: 3.7008109092712402
Epoch: 30, Steps: 128 Train Loss: 30.4064 (Forecasting Loss:0.2314 + XiCon Loss:3.0175 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2061
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.6674175
	speed: 0.0229s/iter; left time: 202.5618s
Epoch: 31 cost time: 2.821489095687866
Epoch: 31, Steps: 128 Train Loss: 30.4076 (Forecasting Loss:0.2315 + XiCon Loss:3.0176 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2061
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 29.3358307
	speed: 0.0266s/iter; left time: 232.5660s
Epoch: 32 cost time: 3.326958179473877
Epoch: 32, Steps: 128 Train Loss: 30.4419 (Forecasting Loss:0.2312 + XiCon Loss:3.0211 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2061
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 31.5882187
	speed: 0.0275s/iter; left time: 236.2691s
Epoch: 33 cost time: 3.5826008319854736
Epoch: 33, Steps: 128 Train Loss: 30.4472 (Forecasting Loss:0.2314 + XiCon Loss:3.0216 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2061
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13170716166496277, mae:0.2803977429866791, mape:0.668757438659668, mspe:19.9527530670166 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8115
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6738663
	speed: 0.0219s/iter; left time: 278.6086s
Epoch: 1 cost time: 3.0850069522857666
Epoch: 1, Steps: 128 Train Loss: 31.1018 (Forecasting Loss:0.2954 + XiCon Loss:3.0806 x Lambda(10.0)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.2312
Validation loss decreased (inf --> 0.273550).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.1023521
	speed: 0.0237s/iter; left time: 297.9873s
Epoch: 2 cost time: 2.896777391433716
Epoch: 2, Steps: 128 Train Loss: 29.3842 (Forecasting Loss:0.2558 + XiCon Loss:2.9128 x Lambda(10.0)), Vali MSE Loss: 0.2642 Test MSE Loss: 0.2140
Validation loss decreased (0.273550 --> 0.264201).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.1810017
	speed: 0.0341s/iter; left time: 424.6371s
Epoch: 3 cost time: 4.1169679164886475
Epoch: 3, Steps: 128 Train Loss: 30.8247 (Forecasting Loss:0.2434 + XiCon Loss:3.0581 x Lambda(10.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.2091
Validation loss decreased (0.264201 --> 0.253157).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7618427
	speed: 0.0338s/iter; left time: 416.9302s
Epoch: 4 cost time: 4.11433482170105
Epoch: 4, Steps: 128 Train Loss: 30.2945 (Forecasting Loss:0.2371 + XiCon Loss:3.0057 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2102
Validation loss decreased (0.253157 --> 0.250313).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.4412689
	speed: 0.0338s/iter; left time: 412.3769s
Epoch: 5 cost time: 4.045541763305664
Epoch: 5, Steps: 128 Train Loss: 29.9313 (Forecasting Loss:0.2345 + XiCon Loss:2.9697 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2031
Validation loss decreased (0.250313 --> 0.249436).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5605259
	speed: 0.0397s/iter; left time: 478.7492s
Epoch: 6 cost time: 4.7160115242004395
Epoch: 6, Steps: 128 Train Loss: 29.7129 (Forecasting Loss:0.2330 + XiCon Loss:2.9480 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2071
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.5861053
	speed: 0.0341s/iter; left time: 406.9757s
Epoch: 7 cost time: 4.274703741073608
Epoch: 7, Steps: 128 Train Loss: 29.6441 (Forecasting Loss:0.2321 + XiCon Loss:2.9412 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2053
Validation loss decreased (0.249436 --> 0.249125).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4350681
	speed: 0.0266s/iter; left time: 313.9616s
Epoch: 8 cost time: 3.244440793991089
Epoch: 8, Steps: 128 Train Loss: 29.6204 (Forecasting Loss:0.2319 + XiCon Loss:2.9389 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2057
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3631554
	speed: 0.0229s/iter; left time: 267.5128s
Epoch: 9 cost time: 2.9481072425842285
Epoch: 9, Steps: 128 Train Loss: 29.6995 (Forecasting Loss:0.2316 + XiCon Loss:2.9468 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2058
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.0350018
	speed: 0.0226s/iter; left time: 261.3163s
Epoch: 10 cost time: 2.8628194332122803
Epoch: 10, Steps: 128 Train Loss: 29.6079 (Forecasting Loss:0.2316 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2057
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5391827
	speed: 0.0278s/iter; left time: 317.3666s
Epoch: 11 cost time: 3.3798224925994873
Epoch: 11, Steps: 128 Train Loss: 29.7030 (Forecasting Loss:0.2315 + XiCon Loss:2.9471 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2058
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4995594
	speed: 0.0335s/iter; left time: 378.6485s
Epoch: 12 cost time: 4.104755163192749
Epoch: 12, Steps: 128 Train Loss: 29.6294 (Forecasting Loss:0.2316 + XiCon Loss:2.9398 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2057
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6908379
	speed: 0.0314s/iter; left time: 350.7809s
Epoch: 13 cost time: 3.7632646560668945
Epoch: 13, Steps: 128 Train Loss: 29.5957 (Forecasting Loss:0.2314 + XiCon Loss:2.9364 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2057
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.9837399
	speed: 0.0252s/iter; left time: 278.3241s
Epoch: 14 cost time: 3.3593204021453857
Epoch: 14, Steps: 128 Train Loss: 29.5664 (Forecasting Loss:0.2314 + XiCon Loss:2.9335 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2057
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.0214710
	speed: 0.0257s/iter; left time: 280.6794s
Epoch: 15 cost time: 3.2071242332458496
Epoch: 15, Steps: 128 Train Loss: 29.6478 (Forecasting Loss:0.2315 + XiCon Loss:2.9416 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2057
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8725300
	speed: 0.0252s/iter; left time: 272.2188s
Epoch: 16 cost time: 3.0819756984710693
Epoch: 16, Steps: 128 Train Loss: 29.6299 (Forecasting Loss:0.2314 + XiCon Loss:2.9398 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.6220722
	speed: 0.0227s/iter; left time: 241.8373s
Epoch: 17 cost time: 2.8866188526153564
Epoch: 17, Steps: 128 Train Loss: 29.6232 (Forecasting Loss:0.2313 + XiCon Loss:2.9392 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2057
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13127224147319794, mae:0.27927958965301514, mape:0.6612630486488342, mspe:19.629533767700195 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8270
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.9881897
	speed: 0.0265s/iter; left time: 336.1746s
Epoch: 1 cost time: 3.5125551223754883
Epoch: 1, Steps: 128 Train Loss: 31.1183 (Forecasting Loss:0.2961 + XiCon Loss:3.0822 x Lambda(10.0)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2282
Validation loss decreased (inf --> 0.272997).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.2456474
	speed: 0.0257s/iter; left time: 322.7949s
Epoch: 2 cost time: 3.292226552963257
Epoch: 2, Steps: 128 Train Loss: 29.5682 (Forecasting Loss:0.2544 + XiCon Loss:2.9314 x Lambda(10.0)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.2245
Validation loss decreased (0.272997 --> 0.261468).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4605122
	speed: 0.0254s/iter; left time: 315.5015s
Epoch: 3 cost time: 3.0865275859832764
Epoch: 3, Steps: 128 Train Loss: 30.0781 (Forecasting Loss:0.2425 + XiCon Loss:2.9836 x Lambda(10.0)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.2175
Validation loss decreased (0.261468 --> 0.257725).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7624531
	speed: 0.0259s/iter; left time: 318.8573s
Epoch: 4 cost time: 3.165506601333618
Epoch: 4, Steps: 128 Train Loss: 30.5031 (Forecasting Loss:0.2358 + XiCon Loss:3.0267 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2019
Validation loss decreased (0.257725 --> 0.251829).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0925903
	speed: 0.0259s/iter; left time: 315.3036s
Epoch: 5 cost time: 3.147409200668335
Epoch: 5, Steps: 128 Train Loss: 30.6825 (Forecasting Loss:0.2319 + XiCon Loss:3.0451 x Lambda(10.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2060
Validation loss decreased (0.251829 --> 0.251476).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.0921326
	speed: 0.0274s/iter; left time: 330.0291s
Epoch: 6 cost time: 3.3517234325408936
Epoch: 6, Steps: 128 Train Loss: 30.5356 (Forecasting Loss:0.2303 + XiCon Loss:3.0305 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2034
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.9372597
	speed: 0.0327s/iter; left time: 389.9936s
Epoch: 7 cost time: 3.894263982772827
Epoch: 7, Steps: 128 Train Loss: 30.7158 (Forecasting Loss:0.2298 + XiCon Loss:3.0486 x Lambda(10.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2038
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.7506313
	speed: 0.0326s/iter; left time: 384.7929s
Epoch: 8 cost time: 3.8212430477142334
Epoch: 8, Steps: 128 Train Loss: 30.8010 (Forecasting Loss:0.2296 + XiCon Loss:3.0571 x Lambda(10.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.2029
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.8280563
	speed: 0.0294s/iter; left time: 343.5222s
Epoch: 9 cost time: 3.6506922245025635
Epoch: 9, Steps: 128 Train Loss: 30.6967 (Forecasting Loss:0.2293 + XiCon Loss:3.0467 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2027
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8217392
	speed: 0.0259s/iter; left time: 298.6851s
Epoch: 10 cost time: 3.2864584922790527
Epoch: 10, Steps: 128 Train Loss: 30.7447 (Forecasting Loss:0.2293 + XiCon Loss:3.0515 x Lambda(10.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2024
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3992500
	speed: 0.0233s/iter; left time: 266.5569s
Epoch: 11 cost time: 2.997076988220215
Epoch: 11, Steps: 128 Train Loss: 30.7618 (Forecasting Loss:0.2290 + XiCon Loss:3.0533 x Lambda(10.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2023
Validation loss decreased (0.251476 --> 0.251268).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.8044891
	speed: 0.0247s/iter; left time: 278.4930s
Epoch: 12 cost time: 3.1176764965057373
Epoch: 12, Steps: 128 Train Loss: 30.7691 (Forecasting Loss:0.2292 + XiCon Loss:3.0540 x Lambda(10.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.2023
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4186516
	speed: 0.0267s/iter; left time: 298.1154s
Epoch: 13 cost time: 3.392820119857788
Epoch: 13, Steps: 128 Train Loss: 30.7245 (Forecasting Loss:0.2292 + XiCon Loss:3.0495 x Lambda(10.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.2022
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3517780
	speed: 0.0284s/iter; left time: 313.8021s
Epoch: 14 cost time: 3.4415066242218018
Epoch: 14, Steps: 128 Train Loss: 30.7051 (Forecasting Loss:0.2291 + XiCon Loss:3.0476 x Lambda(10.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2022
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.8609676
	speed: 0.0289s/iter; left time: 315.1792s
Epoch: 15 cost time: 3.4613564014434814
Epoch: 15, Steps: 128 Train Loss: 30.6344 (Forecasting Loss:0.2293 + XiCon Loss:3.0405 x Lambda(10.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2022
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9698467
	speed: 0.0328s/iter; left time: 353.0919s
Epoch: 16 cost time: 3.951247215270996
Epoch: 16, Steps: 128 Train Loss: 30.6818 (Forecasting Loss:0.2290 + XiCon Loss:3.0453 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2022
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.8470879
	speed: 0.0298s/iter; left time: 317.7827s
Epoch: 17 cost time: 3.5661332607269287
Epoch: 17, Steps: 128 Train Loss: 30.6502 (Forecasting Loss:0.2289 + XiCon Loss:3.0421 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2022
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.8237839
	speed: 0.0293s/iter; left time: 308.4571s
Epoch: 18 cost time: 3.52105712890625
Epoch: 18, Steps: 128 Train Loss: 30.7079 (Forecasting Loss:0.2290 + XiCon Loss:3.0479 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2022
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8111820
	speed: 0.0285s/iter; left time: 296.0614s
Epoch: 19 cost time: 3.5048251152038574
Epoch: 19, Steps: 128 Train Loss: 30.7105 (Forecasting Loss:0.2290 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.2022
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.4551392
	speed: 0.0287s/iter; left time: 294.2235s
Epoch: 20 cost time: 3.6313233375549316
Epoch: 20, Steps: 128 Train Loss: 30.6617 (Forecasting Loss:0.2290 + XiCon Loss:3.0433 x Lambda(10.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2022
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.8101273
	speed: 0.0286s/iter; left time: 289.7498s
Epoch: 21 cost time: 3.5866847038269043
Epoch: 21, Steps: 128 Train Loss: 30.7019 (Forecasting Loss:0.2292 + XiCon Loss:3.0473 x Lambda(10.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2022
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.12773345410823822, mae:0.27678969502449036, mape:0.6640219688415527, mspe:19.83409309387207 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1299+-0.00254, MAE:0.2786+-0.00200, MAPE:0.6663+-0.00866, MSPE:19.8083+-0.35317, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6912
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4405628
	speed: 0.0405s/iter; left time: 474.2603s
Epoch: 1 cost time: 4.799113512039185
Epoch: 1, Steps: 118 Train Loss: 0.4452 (Forecasting Loss:0.4140 + XiCon Loss:3.1217 x Lambda(0.01)), Vali MSE Loss: 0.4300 Test MSE Loss: 0.3241
Validation loss decreased (inf --> 0.429967).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3047024
	speed: 0.0477s/iter; left time: 552.8805s
Epoch: 2 cost time: 5.9361371994018555
Epoch: 2, Steps: 118 Train Loss: 0.3321 (Forecasting Loss:0.3008 + XiCon Loss:3.1361 x Lambda(0.01)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.2752
Validation loss decreased (0.429967 --> 0.368507).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3006116
	speed: 0.0571s/iter; left time: 654.9713s
Epoch: 3 cost time: 6.704802989959717
Epoch: 3, Steps: 118 Train Loss: 0.2885 (Forecasting Loss:0.2576 + XiCon Loss:3.0837 x Lambda(0.01)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.2657
Validation loss decreased (0.368507 --> 0.317203).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2931682
	speed: 0.0530s/iter; left time: 601.7373s
Epoch: 4 cost time: 6.380530595779419
Epoch: 4, Steps: 118 Train Loss: 0.2747 (Forecasting Loss:0.2440 + XiCon Loss:3.0663 x Lambda(0.01)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2521
Validation loss decreased (0.317203 --> 0.313341).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2578811
	speed: 0.0540s/iter; left time: 606.8301s
Epoch: 5 cost time: 6.159480333328247
Epoch: 5, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2387 + XiCon Loss:3.0553 x Lambda(0.01)), Vali MSE Loss: 0.3145 Test MSE Loss: 0.2518
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2547567
	speed: 0.0481s/iter; left time: 534.5649s
Epoch: 6 cost time: 5.8837890625
Epoch: 6, Steps: 118 Train Loss: 0.2663 (Forecasting Loss:0.2359 + XiCon Loss:3.0477 x Lambda(0.01)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2475
Validation loss decreased (0.313341 --> 0.307377).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2714747
	speed: 0.0475s/iter; left time: 521.7709s
Epoch: 7 cost time: 5.417747259140015
Epoch: 7, Steps: 118 Train Loss: 0.2648 (Forecasting Loss:0.2343 + XiCon Loss:3.0438 x Lambda(0.01)), Vali MSE Loss: 0.3105 Test MSE Loss: 0.2471
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2433533
	speed: 0.0459s/iter; left time: 499.5635s
Epoch: 8 cost time: 5.532255172729492
Epoch: 8, Steps: 118 Train Loss: 0.2640 (Forecasting Loss:0.2336 + XiCon Loss:3.0416 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.2469
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2572568
	speed: 0.0454s/iter; left time: 487.8682s
Epoch: 9 cost time: 5.32426118850708
Epoch: 9, Steps: 118 Train Loss: 0.2635 (Forecasting Loss:0.2331 + XiCon Loss:3.0415 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.2453
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2596520
	speed: 0.0483s/iter; left time: 513.5436s
Epoch: 10 cost time: 5.851552248001099
Epoch: 10, Steps: 118 Train Loss: 0.2634 (Forecasting Loss:0.2330 + XiCon Loss:3.0394 x Lambda(0.01)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.2459
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2609895
	speed: 0.0467s/iter; left time: 491.7833s
Epoch: 11 cost time: 5.338620901107788
Epoch: 11, Steps: 118 Train Loss: 0.2631 (Forecasting Loss:0.2327 + XiCon Loss:3.0396 x Lambda(0.01)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2453
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2623820
	speed: 0.0470s/iter; left time: 488.9797s
Epoch: 12 cost time: 5.643531322479248
Epoch: 12, Steps: 118 Train Loss: 0.2630 (Forecasting Loss:0.2326 + XiCon Loss:3.0397 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.2455
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2619778
	speed: 0.0446s/iter; left time: 459.1604s
Epoch: 13 cost time: 5.188045978546143
Epoch: 13, Steps: 118 Train Loss: 0.2629 (Forecasting Loss:0.2325 + XiCon Loss:3.0409 x Lambda(0.01)), Vali MSE Loss: 0.3088 Test MSE Loss: 0.2454
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2671576
	speed: 0.0462s/iter; left time: 469.4388s
Epoch: 14 cost time: 5.453667402267456
Epoch: 14, Steps: 118 Train Loss: 0.2629 (Forecasting Loss:0.2325 + XiCon Loss:3.0399 x Lambda(0.01)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.2454
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2411373
	speed: 0.0494s/iter; left time: 495.9891s
Epoch: 15 cost time: 5.701579809188843
Epoch: 15, Steps: 118 Train Loss: 0.2630 (Forecasting Loss:0.2326 + XiCon Loss:3.0374 x Lambda(0.01)), Vali MSE Loss: 0.3097 Test MSE Loss: 0.2454
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2734207
	speed: 0.0443s/iter; left time: 440.1846s
Epoch: 16 cost time: 5.342931509017944
Epoch: 16, Steps: 118 Train Loss: 0.2630 (Forecasting Loss:0.2326 + XiCon Loss:3.0382 x Lambda(0.01)), Vali MSE Loss: 0.3087 Test MSE Loss: 0.2454
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.16513735055923462, mae:0.32983991503715515, mape:0.6829157471656799, mspe:21.36023712158203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7391
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4133497
	speed: 0.0398s/iter; left time: 466.2579s
Epoch: 1 cost time: 4.95817232131958
Epoch: 1, Steps: 118 Train Loss: 0.4392 (Forecasting Loss:0.4081 + XiCon Loss:3.1107 x Lambda(0.01)), Vali MSE Loss: 0.4202 Test MSE Loss: 0.3056
Validation loss decreased (inf --> 0.420221).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3357808
	speed: 0.0412s/iter; left time: 476.6654s
Epoch: 2 cost time: 4.818103551864624
Epoch: 2, Steps: 118 Train Loss: 0.3625 (Forecasting Loss:0.3313 + XiCon Loss:3.1150 x Lambda(0.01)), Vali MSE Loss: 0.3666 Test MSE Loss: 0.2793
Validation loss decreased (0.420221 --> 0.366569).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2883325
	speed: 0.0453s/iter; left time: 519.2116s
Epoch: 3 cost time: 5.161140441894531
Epoch: 3, Steps: 118 Train Loss: 0.3107 (Forecasting Loss:0.2798 + XiCon Loss:3.0903 x Lambda(0.01)), Vali MSE Loss: 0.3740 Test MSE Loss: 0.2653
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2776016
	speed: 0.0391s/iter; left time: 444.1036s
Epoch: 4 cost time: 4.755462169647217
Epoch: 4, Steps: 118 Train Loss: 0.2877 (Forecasting Loss:0.2571 + XiCon Loss:3.0641 x Lambda(0.01)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.2545
Validation loss decreased (0.366569 --> 0.332485).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2823808
	speed: 0.0394s/iter; left time: 442.1981s
Epoch: 5 cost time: 4.780511856079102
Epoch: 5, Steps: 118 Train Loss: 0.2780 (Forecasting Loss:0.2475 + XiCon Loss:3.0496 x Lambda(0.01)), Vali MSE Loss: 0.3425 Test MSE Loss: 0.2633
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.3042849
	speed: 0.0414s/iter; left time: 460.0842s
Epoch: 6 cost time: 4.820528507232666
Epoch: 6, Steps: 118 Train Loss: 0.2736 (Forecasting Loss:0.2431 + XiCon Loss:3.0437 x Lambda(0.01)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.2617
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2645569
	speed: 0.0405s/iter; left time: 445.2486s
Epoch: 7 cost time: 5.038183212280273
Epoch: 7, Steps: 118 Train Loss: 0.2716 (Forecasting Loss:0.2413 + XiCon Loss:3.0377 x Lambda(0.01)), Vali MSE Loss: 0.3491 Test MSE Loss: 0.2701
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2720563
	speed: 0.0401s/iter; left time: 435.5963s
Epoch: 8 cost time: 4.814949989318848
Epoch: 8, Steps: 118 Train Loss: 0.2708 (Forecasting Loss:0.2404 + XiCon Loss:3.0349 x Lambda(0.01)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.2669
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2746349
	speed: 0.0282s/iter; left time: 303.2932s
Epoch: 9 cost time: 3.227843999862671
Epoch: 9, Steps: 118 Train Loss: 0.2702 (Forecasting Loss:0.2398 + XiCon Loss:3.0345 x Lambda(0.01)), Vali MSE Loss: 0.3445 Test MSE Loss: 0.2613
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2684824
	speed: 0.0350s/iter; left time: 372.7274s
Epoch: 10 cost time: 4.405649185180664
Epoch: 10, Steps: 118 Train Loss: 0.2695 (Forecasting Loss:0.2392 + XiCon Loss:3.0324 x Lambda(0.01)), Vali MSE Loss: 0.3459 Test MSE Loss: 0.2601
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2756819
	speed: 0.0442s/iter; left time: 465.1083s
Epoch: 11 cost time: 5.3005211353302
Epoch: 11, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2389 + XiCon Loss:3.0347 x Lambda(0.01)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2637
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2671944
	speed: 0.0418s/iter; left time: 434.6795s
Epoch: 12 cost time: 4.595119953155518
Epoch: 12, Steps: 118 Train Loss: 0.2696 (Forecasting Loss:0.2393 + XiCon Loss:3.0313 x Lambda(0.01)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2630
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2742864
	speed: 0.0418s/iter; left time: 429.5760s
Epoch: 13 cost time: 5.014357566833496
Epoch: 13, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2389 + XiCon Loss:3.0316 x Lambda(0.01)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.2629
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2672080
	speed: 0.0449s/iter; left time: 456.8616s
Epoch: 14 cost time: 5.396689176559448
Epoch: 14, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2390 + XiCon Loss:3.0301 x Lambda(0.01)), Vali MSE Loss: 0.3475 Test MSE Loss: 0.2624
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17290489375591278, mae:0.33604171872138977, mape:0.6307385563850403, mspe:16.06719398498535 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7573
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3545002
	speed: 0.0518s/iter; left time: 605.5595s
Epoch: 1 cost time: 6.226447582244873
Epoch: 1, Steps: 118 Train Loss: 0.4187 (Forecasting Loss:0.3874 + XiCon Loss:3.1282 x Lambda(0.01)), Vali MSE Loss: 0.3863 Test MSE Loss: 0.2897
Validation loss decreased (inf --> 0.386271).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3296372
	speed: 0.0525s/iter; left time: 608.5103s
Epoch: 2 cost time: 5.969612121582031
Epoch: 2, Steps: 118 Train Loss: 0.3567 (Forecasting Loss:0.3258 + XiCon Loss:3.0895 x Lambda(0.01)), Vali MSE Loss: 0.3423 Test MSE Loss: 0.2883
Validation loss decreased (0.386271 --> 0.342327).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3066392
	speed: 0.0400s/iter; left time: 458.1321s
Epoch: 3 cost time: 4.714390516281128
Epoch: 3, Steps: 118 Train Loss: 0.3008 (Forecasting Loss:0.2705 + XiCon Loss:3.0331 x Lambda(0.01)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2831
Validation loss decreased (0.342327 --> 0.323371).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2620656
	speed: 0.0393s/iter; left time: 446.2103s
Epoch: 4 cost time: 4.74418306350708
Epoch: 4, Steps: 118 Train Loss: 0.2827 (Forecasting Loss:0.2526 + XiCon Loss:3.0120 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2715
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2586125
	speed: 0.0436s/iter; left time: 489.3379s
Epoch: 5 cost time: 4.932523965835571
Epoch: 5, Steps: 118 Train Loss: 0.2755 (Forecasting Loss:0.2455 + XiCon Loss:3.0035 x Lambda(0.01)), Vali MSE Loss: 0.3302 Test MSE Loss: 0.2664
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2751808
	speed: 0.0357s/iter; left time: 396.5290s
Epoch: 6 cost time: 4.236765146255493
Epoch: 6, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2420 + XiCon Loss:3.0017 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2753
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2592228
	speed: 0.0361s/iter; left time: 396.7386s
Epoch: 7 cost time: 4.454760313034058
Epoch: 7, Steps: 118 Train Loss: 0.2697 (Forecasting Loss:0.2397 + XiCon Loss:2.9994 x Lambda(0.01)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.2795
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2732523
	speed: 0.0360s/iter; left time: 391.4398s
Epoch: 8 cost time: 4.382597923278809
Epoch: 8, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2389 + XiCon Loss:3.0017 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2758
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2828718
	speed: 0.0407s/iter; left time: 438.1779s
Epoch: 9 cost time: 4.720752000808716
Epoch: 9, Steps: 118 Train Loss: 0.2684 (Forecasting Loss:0.2384 + XiCon Loss:3.0027 x Lambda(0.01)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2770
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2491000
	speed: 0.0401s/iter; left time: 426.6178s
Epoch: 10 cost time: 4.852667808532715
Epoch: 10, Steps: 118 Train Loss: 0.2683 (Forecasting Loss:0.2383 + XiCon Loss:3.0005 x Lambda(0.01)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2755
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2735026
	speed: 0.0349s/iter; left time: 367.1890s
Epoch: 11 cost time: 4.413978338241577
Epoch: 11, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2381 + XiCon Loss:3.0016 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2760
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2579633
	speed: 0.0451s/iter; left time: 469.3429s
Epoch: 12 cost time: 5.060918092727661
Epoch: 12, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2382 + XiCon Loss:3.0013 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2768
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2664033
	speed: 0.0375s/iter; left time: 386.1177s
Epoch: 13 cost time: 4.674788236618042
Epoch: 13, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2382 + XiCon Loss:3.0003 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2763
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2052610069513321, mae:0.36101391911506653, mape:0.6170960664749146, mspe:14.288702964782715 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4351
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3688754
	speed: 0.0414s/iter; left time: 484.3789s
Epoch: 1 cost time: 4.976199150085449
Epoch: 1, Steps: 118 Train Loss: 0.4388 (Forecasting Loss:0.4076 + XiCon Loss:3.1177 x Lambda(0.01)), Vali MSE Loss: 0.4253 Test MSE Loss: 0.3139
Validation loss decreased (inf --> 0.425332).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2986967
	speed: 0.0449s/iter; left time: 520.4120s
Epoch: 2 cost time: 5.228764295578003
Epoch: 2, Steps: 118 Train Loss: 0.3227 (Forecasting Loss:0.2917 + XiCon Loss:3.0951 x Lambda(0.01)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2713
Validation loss decreased (0.425332 --> 0.325127).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3035720
	speed: 0.0465s/iter; left time: 532.6152s
Epoch: 3 cost time: 5.484210729598999
Epoch: 3, Steps: 118 Train Loss: 0.2819 (Forecasting Loss:0.2514 + XiCon Loss:3.0537 x Lambda(0.01)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2523
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2797549
	speed: 0.0468s/iter; left time: 531.4631s
Epoch: 4 cost time: 5.395175218582153
Epoch: 4, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2386 + XiCon Loss:3.0352 x Lambda(0.01)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.2526
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2602988
	speed: 0.0487s/iter; left time: 546.5673s
Epoch: 5 cost time: 5.889934539794922
Epoch: 5, Steps: 118 Train Loss: 0.2629 (Forecasting Loss:0.2326 + XiCon Loss:3.0267 x Lambda(0.01)), Vali MSE Loss: 0.3327 Test MSE Loss: 0.2459
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2788587
	speed: 0.0461s/iter; left time: 512.2181s
Epoch: 6 cost time: 5.415461301803589
Epoch: 6, Steps: 118 Train Loss: 0.2606 (Forecasting Loss:0.2304 + XiCon Loss:3.0186 x Lambda(0.01)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.2459
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2605457
	speed: 0.0469s/iter; left time: 516.0845s
Epoch: 7 cost time: 5.774770021438599
Epoch: 7, Steps: 118 Train Loss: 0.2591 (Forecasting Loss:0.2290 + XiCon Loss:3.0141 x Lambda(0.01)), Vali MSE Loss: 0.3294 Test MSE Loss: 0.2468
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2563183
	speed: 0.0486s/iter; left time: 528.4285s
Epoch: 8 cost time: 5.887182950973511
Epoch: 8, Steps: 118 Train Loss: 0.2585 (Forecasting Loss:0.2284 + XiCon Loss:3.0115 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2474
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2543723
	speed: 0.0488s/iter; left time: 525.0187s
Epoch: 9 cost time: 5.516375780105591
Epoch: 9, Steps: 118 Train Loss: 0.2581 (Forecasting Loss:0.2280 + XiCon Loss:3.0101 x Lambda(0.01)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.2470
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2677153
	speed: 0.0450s/iter; left time: 478.3129s
Epoch: 10 cost time: 5.452005386352539
Epoch: 10, Steps: 118 Train Loss: 0.2577 (Forecasting Loss:0.2276 + XiCon Loss:3.0092 x Lambda(0.01)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.2464
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2445550
	speed: 0.0469s/iter; left time: 493.1229s
Epoch: 11 cost time: 5.715665817260742
Epoch: 11, Steps: 118 Train Loss: 0.2577 (Forecasting Loss:0.2276 + XiCon Loss:3.0114 x Lambda(0.01)), Vali MSE Loss: 0.3298 Test MSE Loss: 0.2468
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2436614
	speed: 0.0487s/iter; left time: 506.1365s
Epoch: 12 cost time: 5.570675849914551
Epoch: 12, Steps: 118 Train Loss: 0.2577 (Forecasting Loss:0.2276 + XiCon Loss:3.0122 x Lambda(0.01)), Vali MSE Loss: 0.3294 Test MSE Loss: 0.2470
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19067926704883575, mae:0.35198143124580383, mape:0.7513881325721741, mspe:22.788585662841797 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.8442
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4100092
	speed: 0.0494s/iter; left time: 578.2020s
Epoch: 1 cost time: 5.887794494628906
Epoch: 1, Steps: 118 Train Loss: 0.4339 (Forecasting Loss:0.4027 + XiCon Loss:3.1168 x Lambda(0.01)), Vali MSE Loss: 0.4264 Test MSE Loss: 0.3147
Validation loss decreased (inf --> 0.426355).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3398929
	speed: 0.0502s/iter; left time: 581.3010s
Epoch: 2 cost time: 5.967563629150391
Epoch: 2, Steps: 118 Train Loss: 0.3476 (Forecasting Loss:0.3167 + XiCon Loss:3.0886 x Lambda(0.01)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.2711
Validation loss decreased (0.426355 --> 0.329577).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2959963
	speed: 0.0502s/iter; left time: 575.1681s
Epoch: 3 cost time: 5.980245590209961
Epoch: 3, Steps: 118 Train Loss: 0.2985 (Forecasting Loss:0.2682 + XiCon Loss:3.0292 x Lambda(0.01)), Vali MSE Loss: 0.3399 Test MSE Loss: 0.2611
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2813785
	speed: 0.0441s/iter; left time: 500.7614s
Epoch: 4 cost time: 4.992725610733032
Epoch: 4, Steps: 118 Train Loss: 0.2823 (Forecasting Loss:0.2519 + XiCon Loss:3.0347 x Lambda(0.01)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2609
Validation loss decreased (0.329577 --> 0.322826).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2719337
	speed: 0.0398s/iter; left time: 447.3862s
Epoch: 5 cost time: 4.750196218490601
Epoch: 5, Steps: 118 Train Loss: 0.2728 (Forecasting Loss:0.2424 + XiCon Loss:3.0412 x Lambda(0.01)), Vali MSE Loss: 0.3482 Test MSE Loss: 0.2710
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2717097
	speed: 0.0393s/iter; left time: 436.7512s
Epoch: 6 cost time: 4.611107349395752
Epoch: 6, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2387 + XiCon Loss:3.0486 x Lambda(0.01)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.2580
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2871103
	speed: 0.0412s/iter; left time: 452.5446s
Epoch: 7 cost time: 4.879035472869873
Epoch: 7, Steps: 118 Train Loss: 0.2663 (Forecasting Loss:0.2358 + XiCon Loss:3.0512 x Lambda(0.01)), Vali MSE Loss: 0.3390 Test MSE Loss: 0.2623
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2674151
	speed: 0.0423s/iter; left time: 460.4937s
Epoch: 8 cost time: 5.158950567245483
Epoch: 8, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2351 + XiCon Loss:3.0540 x Lambda(0.01)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.2599
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2666702
	speed: 0.0425s/iter; left time: 456.7084s
Epoch: 9 cost time: 4.962642669677734
Epoch: 9, Steps: 118 Train Loss: 0.2648 (Forecasting Loss:0.2343 + XiCon Loss:3.0515 x Lambda(0.01)), Vali MSE Loss: 0.3312 Test MSE Loss: 0.2607
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2586321
	speed: 0.0385s/iter; left time: 409.6630s
Epoch: 10 cost time: 4.78046441078186
Epoch: 10, Steps: 118 Train Loss: 0.2648 (Forecasting Loss:0.2342 + XiCon Loss:3.0545 x Lambda(0.01)), Vali MSE Loss: 0.3357 Test MSE Loss: 0.2624
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2608889
	speed: 0.0422s/iter; left time: 443.8998s
Epoch: 11 cost time: 4.8181328773498535
Epoch: 11, Steps: 118 Train Loss: 0.2644 (Forecasting Loss:0.2339 + XiCon Loss:3.0549 x Lambda(0.01)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.2607
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2641728
	speed: 0.0439s/iter; left time: 457.0248s
Epoch: 12 cost time: 5.293390274047852
Epoch: 12, Steps: 118 Train Loss: 0.2642 (Forecasting Loss:0.2337 + XiCon Loss:3.0541 x Lambda(0.01)), Vali MSE Loss: 0.3372 Test MSE Loss: 0.2608
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2718661
	speed: 0.0400s/iter; left time: 411.1369s
Epoch: 13 cost time: 4.870954275131226
Epoch: 13, Steps: 118 Train Loss: 0.2646 (Forecasting Loss:0.2340 + XiCon Loss:3.0542 x Lambda(0.01)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2611
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2508293
	speed: 0.0447s/iter; left time: 454.5524s
Epoch: 14 cost time: 5.2454400062561035
Epoch: 14, Steps: 118 Train Loss: 0.2641 (Forecasting Loss:0.2336 + XiCon Loss:3.0512 x Lambda(0.01)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.2611
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17770519852638245, mae:0.34418046474456787, mape:0.6462225317955017, mspe:17.14252471923828 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1823+-0.01965, MAE:0.3446+-0.01540, MAPE:0.6657+-0.06687, MSPE:18.3294+-4.47360, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6530
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5830941
	speed: 0.0562s/iter; left time: 595.4437s
Epoch: 1 cost time: 6.028040409088135
Epoch: 1, Steps: 107 Train Loss: 0.6371 (Forecasting Loss:0.6340 + XiCon Loss:3.1434 x Lambda(0.001)), Vali MSE Loss: 0.5962 Test MSE Loss: 0.4668
Validation loss decreased (inf --> 0.596244).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3091890
	speed: 0.0644s/iter; left time: 676.0226s
Epoch: 2 cost time: 7.0113630294799805
Epoch: 2, Steps: 107 Train Loss: 0.3619 (Forecasting Loss:0.3587 + XiCon Loss:3.1879 x Lambda(0.001)), Vali MSE Loss: 0.3781 Test MSE Loss: 0.2515
Validation loss decreased (0.596244 --> 0.378111).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2626936
	speed: 0.0629s/iter; left time: 653.3749s
Epoch: 3 cost time: 6.805069208145142
Epoch: 3, Steps: 107 Train Loss: 0.2770 (Forecasting Loss:0.2738 + XiCon Loss:3.1661 x Lambda(0.001)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2621
Validation loss decreased (0.378111 --> 0.353022).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2619518
	speed: 0.0605s/iter; left time: 621.5813s
Epoch: 4 cost time: 6.468695640563965
Epoch: 4, Steps: 107 Train Loss: 0.2627 (Forecasting Loss:0.2596 + XiCon Loss:3.1496 x Lambda(0.001)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2395
Validation loss decreased (0.353022 --> 0.320895).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2694969
	speed: 0.0632s/iter; left time: 643.1251s
Epoch: 5 cost time: 6.77004337310791
Epoch: 5, Steps: 107 Train Loss: 0.2577 (Forecasting Loss:0.2545 + XiCon Loss:3.1435 x Lambda(0.001)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.2398
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2448915
	speed: 0.0650s/iter; left time: 654.1312s
Epoch: 6 cost time: 6.95030403137207
Epoch: 6, Steps: 107 Train Loss: 0.2550 (Forecasting Loss:0.2519 + XiCon Loss:3.1393 x Lambda(0.001)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2423
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2609491
	speed: 0.0650s/iter; left time: 647.6497s
Epoch: 7 cost time: 6.990044116973877
Epoch: 7, Steps: 107 Train Loss: 0.2537 (Forecasting Loss:0.2505 + XiCon Loss:3.1360 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2418
Validation loss decreased (0.320895 --> 0.319007).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2518552
	speed: 0.0627s/iter; left time: 617.6007s
Epoch: 8 cost time: 6.81910252571106
Epoch: 8, Steps: 107 Train Loss: 0.2531 (Forecasting Loss:0.2499 + XiCon Loss:3.1352 x Lambda(0.001)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2422
Validation loss decreased (0.319007 --> 0.318398).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2570184
	speed: 0.0636s/iter; left time: 619.9208s
Epoch: 9 cost time: 6.835699796676636
Epoch: 9, Steps: 107 Train Loss: 0.2525 (Forecasting Loss:0.2494 + XiCon Loss:3.1329 x Lambda(0.001)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2409
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2481942
	speed: 0.0618s/iter; left time: 595.2035s
Epoch: 10 cost time: 6.655620336532593
Epoch: 10, Steps: 107 Train Loss: 0.2525 (Forecasting Loss:0.2494 + XiCon Loss:3.1318 x Lambda(0.001)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.2418
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2529074
	speed: 0.0674s/iter; left time: 642.3202s
Epoch: 11 cost time: 7.188944578170776
Epoch: 11, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2492 + XiCon Loss:3.1317 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2409
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2440561
	speed: 0.0715s/iter; left time: 674.0189s
Epoch: 12 cost time: 7.751193523406982
Epoch: 12, Steps: 107 Train Loss: 0.2521 (Forecasting Loss:0.2490 + XiCon Loss:3.1328 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2410
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2537780
	speed: 0.0683s/iter; left time: 636.2612s
Epoch: 13 cost time: 7.3782007694244385
Epoch: 13, Steps: 107 Train Loss: 0.2522 (Forecasting Loss:0.2490 + XiCon Loss:3.1330 x Lambda(0.001)), Vali MSE Loss: 0.3190 Test MSE Loss: 0.2412
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2503496
	speed: 0.0621s/iter; left time: 571.6654s
Epoch: 14 cost time: 6.627683877944946
Epoch: 14, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.1332 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2413
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2630859
	speed: 0.0629s/iter; left time: 572.9876s
Epoch: 15 cost time: 6.80359148979187
Epoch: 15, Steps: 107 Train Loss: 0.2523 (Forecasting Loss:0.2491 + XiCon Loss:3.1315 x Lambda(0.001)), Vali MSE Loss: 0.3189 Test MSE Loss: 0.2413
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2557982
	speed: 0.0684s/iter; left time: 615.0183s
Epoch: 16 cost time: 7.384870529174805
Epoch: 16, Steps: 107 Train Loss: 0.2521 (Forecasting Loss:0.2489 + XiCon Loss:3.1325 x Lambda(0.001)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2412
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2521881
	speed: 0.0676s/iter; left time: 600.4561s
Epoch: 17 cost time: 7.376997470855713
Epoch: 17, Steps: 107 Train Loss: 0.2521 (Forecasting Loss:0.2490 + XiCon Loss:3.1321 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2412
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.2468058
	speed: 0.0669s/iter; left time: 587.1014s
Epoch: 18 cost time: 7.188730478286743
Epoch: 18, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2493 + XiCon Loss:3.1322 x Lambda(0.001)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2412
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1599970906972885, mae:0.3244830071926117, mape:0.6445291042327881, mspe:17.040517807006836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7112
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5997749
	speed: 0.0488s/iter; left time: 517.7609s
Epoch: 1 cost time: 5.298416614532471
Epoch: 1, Steps: 107 Train Loss: 0.6159 (Forecasting Loss:0.6128 + XiCon Loss:3.1288 x Lambda(0.001)), Vali MSE Loss: 0.5467 Test MSE Loss: 0.4052
Validation loss decreased (inf --> 0.546690).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2995883
	speed: 0.0610s/iter; left time: 640.4572s
Epoch: 2 cost time: 6.602416276931763
Epoch: 2, Steps: 107 Train Loss: 0.3518 (Forecasting Loss:0.3486 + XiCon Loss:3.1584 x Lambda(0.001)), Vali MSE Loss: 0.4586 Test MSE Loss: 0.2514
Validation loss decreased (0.546690 --> 0.458641).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2814580
	speed: 0.0646s/iter; left time: 670.6414s
Epoch: 3 cost time: 6.967425107955933
Epoch: 3, Steps: 107 Train Loss: 0.2755 (Forecasting Loss:0.2724 + XiCon Loss:3.1326 x Lambda(0.001)), Vali MSE Loss: 0.4057 Test MSE Loss: 0.2487
Validation loss decreased (0.458641 --> 0.405658).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2514829
	speed: 0.0571s/iter; left time: 586.5258s
Epoch: 4 cost time: 6.186812400817871
Epoch: 4, Steps: 107 Train Loss: 0.2625 (Forecasting Loss:0.2594 + XiCon Loss:3.1273 x Lambda(0.001)), Vali MSE Loss: 0.3450 Test MSE Loss: 0.2394
Validation loss decreased (0.405658 --> 0.345012).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2576585
	speed: 0.0634s/iter; left time: 645.0935s
Epoch: 5 cost time: 6.8110880851745605
Epoch: 5, Steps: 107 Train Loss: 0.2571 (Forecasting Loss:0.2540 + XiCon Loss:3.1231 x Lambda(0.001)), Vali MSE Loss: 0.3653 Test MSE Loss: 0.2373
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2384497
	speed: 0.0632s/iter; left time: 636.5366s
Epoch: 6 cost time: 6.745810270309448
Epoch: 6, Steps: 107 Train Loss: 0.2539 (Forecasting Loss:0.2508 + XiCon Loss:3.1208 x Lambda(0.001)), Vali MSE Loss: 0.3538 Test MSE Loss: 0.2342
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2546330
	speed: 0.0627s/iter; left time: 624.1935s
Epoch: 7 cost time: 6.837496280670166
Epoch: 7, Steps: 107 Train Loss: 0.2527 (Forecasting Loss:0.2496 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.3503 Test MSE Loss: 0.2337
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2604671
	speed: 0.0637s/iter; left time: 627.3338s
Epoch: 8 cost time: 6.8723297119140625
Epoch: 8, Steps: 107 Train Loss: 0.2519 (Forecasting Loss:0.2487 + XiCon Loss:3.1190 x Lambda(0.001)), Vali MSE Loss: 0.3516 Test MSE Loss: 0.2333
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2421170
	speed: 0.0640s/iter; left time: 623.3543s
Epoch: 9 cost time: 6.976088047027588
Epoch: 9, Steps: 107 Train Loss: 0.2513 (Forecasting Loss:0.2482 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.3496 Test MSE Loss: 0.2342
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2444061
	speed: 0.0610s/iter; left time: 588.0934s
Epoch: 10 cost time: 6.631120204925537
Epoch: 10, Steps: 107 Train Loss: 0.2509 (Forecasting Loss:0.2478 + XiCon Loss:3.1205 x Lambda(0.001)), Vali MSE Loss: 0.3526 Test MSE Loss: 0.2344
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2551121
	speed: 0.0602s/iter; left time: 573.7774s
Epoch: 11 cost time: 6.4709978103637695
Epoch: 11, Steps: 107 Train Loss: 0.2509 (Forecasting Loss:0.2478 + XiCon Loss:3.1207 x Lambda(0.001)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.2340
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2511745
	speed: 0.0622s/iter; left time: 586.2939s
Epoch: 12 cost time: 6.634036540985107
Epoch: 12, Steps: 107 Train Loss: 0.2511 (Forecasting Loss:0.2480 + XiCon Loss:3.1209 x Lambda(0.001)), Vali MSE Loss: 0.3512 Test MSE Loss: 0.2340
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2557863
	speed: 0.0642s/iter; left time: 598.5811s
Epoch: 13 cost time: 6.846935749053955
Epoch: 13, Steps: 107 Train Loss: 0.2511 (Forecasting Loss:0.2479 + XiCon Loss:3.1176 x Lambda(0.001)), Vali MSE Loss: 0.3521 Test MSE Loss: 0.2341
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2552352
	speed: 0.0674s/iter; left time: 620.5500s
Epoch: 14 cost time: 7.322576999664307
Epoch: 14, Steps: 107 Train Loss: 0.2508 (Forecasting Loss:0.2477 + XiCon Loss:3.1202 x Lambda(0.001)), Vali MSE Loss: 0.3523 Test MSE Loss: 0.2341
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1566549837589264, mae:0.32224178314208984, mape:0.6687041521072388, mspe:18.862754821777344 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7947
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5914690
	speed: 0.0566s/iter; left time: 600.4570s
Epoch: 1 cost time: 6.1119279861450195
Epoch: 1, Steps: 107 Train Loss: 0.6202 (Forecasting Loss:0.6171 + XiCon Loss:3.1602 x Lambda(0.001)), Vali MSE Loss: 0.5247 Test MSE Loss: 0.3790
Validation loss decreased (inf --> 0.524666).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3154839
	speed: 0.0588s/iter; left time: 617.3413s
Epoch: 2 cost time: 6.339659690856934
Epoch: 2, Steps: 107 Train Loss: 0.4000 (Forecasting Loss:0.3969 + XiCon Loss:3.1224 x Lambda(0.001)), Vali MSE Loss: 0.3753 Test MSE Loss: 0.3254
Validation loss decreased (0.524666 --> 0.375320).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2843040
	speed: 0.0522s/iter; left time: 541.8539s
Epoch: 3 cost time: 5.586220026016235
Epoch: 3, Steps: 107 Train Loss: 0.2929 (Forecasting Loss:0.2898 + XiCon Loss:3.0896 x Lambda(0.001)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.2568
Validation loss decreased (0.375320 --> 0.345621).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2604060
	speed: 0.0503s/iter; left time: 516.9706s
Epoch: 4 cost time: 5.34985613822937
Epoch: 4, Steps: 107 Train Loss: 0.2708 (Forecasting Loss:0.2677 + XiCon Loss:3.0831 x Lambda(0.001)), Vali MSE Loss: 0.3472 Test MSE Loss: 0.2913
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2728065
	speed: 0.0492s/iter; left time: 500.3552s
Epoch: 5 cost time: 5.2841925621032715
Epoch: 5, Steps: 107 Train Loss: 0.2635 (Forecasting Loss:0.2605 + XiCon Loss:3.0806 x Lambda(0.001)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.2891
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2617626
	speed: 0.0487s/iter; left time: 489.9308s
Epoch: 6 cost time: 5.309982776641846
Epoch: 6, Steps: 107 Train Loss: 0.2603 (Forecasting Loss:0.2572 + XiCon Loss:3.0797 x Lambda(0.001)), Vali MSE Loss: 0.3619 Test MSE Loss: 0.2714
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2483454
	speed: 0.0495s/iter; left time: 493.3443s
Epoch: 7 cost time: 5.3681886196136475
Epoch: 7, Steps: 107 Train Loss: 0.2582 (Forecasting Loss:0.2551 + XiCon Loss:3.0797 x Lambda(0.001)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2601442
	speed: 0.0503s/iter; left time: 495.8821s
Epoch: 8 cost time: 5.524195432662964
Epoch: 8, Steps: 107 Train Loss: 0.2573 (Forecasting Loss:0.2542 + XiCon Loss:3.0788 x Lambda(0.001)), Vali MSE Loss: 0.3599 Test MSE Loss: 0.3009
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2522241
	speed: 0.0491s/iter; left time: 478.2816s
Epoch: 9 cost time: 5.263376474380493
Epoch: 9, Steps: 107 Train Loss: 0.2567 (Forecasting Loss:0.2536 + XiCon Loss:3.0796 x Lambda(0.001)), Vali MSE Loss: 0.3649 Test MSE Loss: 0.2943
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2472822
	speed: 0.0494s/iter; left time: 476.1689s
Epoch: 10 cost time: 5.347864151000977
Epoch: 10, Steps: 107 Train Loss: 0.2565 (Forecasting Loss:0.2534 + XiCon Loss:3.0782 x Lambda(0.001)), Vali MSE Loss: 0.3621 Test MSE Loss: 0.2961
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2553700
	speed: 0.0517s/iter; left time: 493.1898s
Epoch: 11 cost time: 5.537739992141724
Epoch: 11, Steps: 107 Train Loss: 0.2563 (Forecasting Loss:0.2533 + XiCon Loss:3.0777 x Lambda(0.001)), Vali MSE Loss: 0.3657 Test MSE Loss: 0.2963
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2539493
	speed: 0.0492s/iter; left time: 463.5169s
Epoch: 12 cost time: 5.305224895477295
Epoch: 12, Steps: 107 Train Loss: 0.2562 (Forecasting Loss:0.2531 + XiCon Loss:3.0803 x Lambda(0.001)), Vali MSE Loss: 0.3632 Test MSE Loss: 0.2991
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2517111
	speed: 0.0484s/iter; left time: 451.1338s
Epoch: 13 cost time: 5.168885707855225
Epoch: 13, Steps: 107 Train Loss: 0.2562 (Forecasting Loss:0.2531 + XiCon Loss:3.0784 x Lambda(0.001)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2988
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17416399717330933, mae:0.3394332528114319, mape:0.5737673044204712, mspe:13.06516170501709 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6131
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.6120039
	speed: 0.0467s/iter; left time: 495.1140s
Epoch: 1 cost time: 4.966631650924683
Epoch: 1, Steps: 107 Train Loss: 0.6207 (Forecasting Loss:0.6175 + XiCon Loss:3.1510 x Lambda(0.001)), Vali MSE Loss: 0.5745 Test MSE Loss: 0.4260
Validation loss decreased (inf --> 0.574477).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2947962
	speed: 0.0622s/iter; left time: 652.3155s
Epoch: 2 cost time: 6.608872890472412
Epoch: 2, Steps: 107 Train Loss: 0.3404 (Forecasting Loss:0.3373 + XiCon Loss:3.1100 x Lambda(0.001)), Vali MSE Loss: 0.4218 Test MSE Loss: 0.2570
Validation loss decreased (0.574477 --> 0.421806).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2634544
	speed: 0.0639s/iter; left time: 663.6339s
Epoch: 3 cost time: 6.950211524963379
Epoch: 3, Steps: 107 Train Loss: 0.2716 (Forecasting Loss:0.2685 + XiCon Loss:3.1067 x Lambda(0.001)), Vali MSE Loss: 0.3556 Test MSE Loss: 0.2448
Validation loss decreased (0.421806 --> 0.355622).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2585205
	speed: 0.0619s/iter; left time: 636.4167s
Epoch: 4 cost time: 6.6783061027526855
Epoch: 4, Steps: 107 Train Loss: 0.2597 (Forecasting Loss:0.2566 + XiCon Loss:3.1033 x Lambda(0.001)), Vali MSE Loss: 0.3659 Test MSE Loss: 0.2449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2649725
	speed: 0.0622s/iter; left time: 632.7357s
Epoch: 5 cost time: 6.787438631057739
Epoch: 5, Steps: 107 Train Loss: 0.2551 (Forecasting Loss:0.2520 + XiCon Loss:3.1018 x Lambda(0.001)), Vali MSE Loss: 0.3599 Test MSE Loss: 0.2414
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2551252
	speed: 0.0628s/iter; left time: 631.8470s
Epoch: 6 cost time: 6.818689823150635
Epoch: 6, Steps: 107 Train Loss: 0.2524 (Forecasting Loss:0.2493 + XiCon Loss:3.1024 x Lambda(0.001)), Vali MSE Loss: 0.3613 Test MSE Loss: 0.2390
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2507481
	speed: 0.0602s/iter; left time: 599.4389s
Epoch: 7 cost time: 6.484620809555054
Epoch: 7, Steps: 107 Train Loss: 0.2511 (Forecasting Loss:0.2480 + XiCon Loss:3.1009 x Lambda(0.001)), Vali MSE Loss: 0.3643 Test MSE Loss: 0.2454
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2617782
	speed: 0.0616s/iter; left time: 606.5628s
Epoch: 8 cost time: 6.568725347518921
Epoch: 8, Steps: 107 Train Loss: 0.2501 (Forecasting Loss:0.2470 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3648 Test MSE Loss: 0.2420
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2463458
	speed: 0.0642s/iter; left time: 625.3218s
Epoch: 9 cost time: 6.841765880584717
Epoch: 9, Steps: 107 Train Loss: 0.2498 (Forecasting Loss:0.2467 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3655 Test MSE Loss: 0.2411
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2568683
	speed: 0.0649s/iter; left time: 625.8425s
Epoch: 10 cost time: 6.999010324478149
Epoch: 10, Steps: 107 Train Loss: 0.2497 (Forecasting Loss:0.2466 + XiCon Loss:3.0997 x Lambda(0.001)), Vali MSE Loss: 0.3663 Test MSE Loss: 0.2417
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2564179
	speed: 0.0657s/iter; left time: 626.5079s
Epoch: 11 cost time: 7.026679039001465
Epoch: 11, Steps: 107 Train Loss: 0.2495 (Forecasting Loss:0.2464 + XiCon Loss:3.1000 x Lambda(0.001)), Vali MSE Loss: 0.3652 Test MSE Loss: 0.2419
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2432247
	speed: 0.0642s/iter; left time: 604.5815s
Epoch: 12 cost time: 6.88244366645813
Epoch: 12, Steps: 107 Train Loss: 0.2496 (Forecasting Loss:0.2465 + XiCon Loss:3.1010 x Lambda(0.001)), Vali MSE Loss: 0.3657 Test MSE Loss: 0.2422
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2479880
	speed: 0.0686s/iter; left time: 639.5176s
Epoch: 13 cost time: 7.2562665939331055
Epoch: 13, Steps: 107 Train Loss: 0.2494 (Forecasting Loss:0.2463 + XiCon Loss:3.0995 x Lambda(0.001)), Vali MSE Loss: 0.3653 Test MSE Loss: 0.2419
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.16129547357559204, mae:0.3282489776611328, mape:0.6609804630279541, mspe:18.291547775268555 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7234
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 0.5421518
	speed: 0.0488s/iter; left time: 517.6950s
Epoch: 1 cost time: 5.176966905593872
Epoch: 1, Steps: 107 Train Loss: 0.6232 (Forecasting Loss:0.6201 + XiCon Loss:3.1268 x Lambda(0.001)), Vali MSE Loss: 0.5741 Test MSE Loss: 0.4371
Validation loss decreased (inf --> 0.574081).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2881179
	speed: 0.0587s/iter; left time: 616.0377s
Epoch: 2 cost time: 6.37903904914856
Epoch: 2, Steps: 107 Train Loss: 0.3449 (Forecasting Loss:0.3418 + XiCon Loss:3.1344 x Lambda(0.001)), Vali MSE Loss: 0.3658 Test MSE Loss: 0.2556
Validation loss decreased (0.574081 --> 0.365813).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2646313
	speed: 0.0612s/iter; left time: 635.6370s
Epoch: 3 cost time: 6.629415512084961
Epoch: 3, Steps: 107 Train Loss: 0.2688 (Forecasting Loss:0.2656 + XiCon Loss:3.1221 x Lambda(0.001)), Vali MSE Loss: 0.3834 Test MSE Loss: 0.2750
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2583553
	speed: 0.0620s/iter; left time: 637.2348s
Epoch: 4 cost time: 6.553898572921753
Epoch: 4, Steps: 107 Train Loss: 0.2569 (Forecasting Loss:0.2538 + XiCon Loss:3.1077 x Lambda(0.001)), Vali MSE Loss: 0.3687 Test MSE Loss: 0.2868
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2455722
	speed: 0.0634s/iter; left time: 644.9783s
Epoch: 5 cost time: 6.768348455429077
Epoch: 5, Steps: 107 Train Loss: 0.2512 (Forecasting Loss:0.2481 + XiCon Loss:3.1032 x Lambda(0.001)), Vali MSE Loss: 0.3696 Test MSE Loss: 0.2866
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2470651
	speed: 0.0593s/iter; left time: 597.0708s
Epoch: 6 cost time: 6.421932697296143
Epoch: 6, Steps: 107 Train Loss: 0.2487 (Forecasting Loss:0.2456 + XiCon Loss:3.1013 x Lambda(0.001)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2838
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2307874
	speed: 0.0657s/iter; left time: 654.5690s
Epoch: 7 cost time: 7.154756546020508
Epoch: 7, Steps: 107 Train Loss: 0.2473 (Forecasting Loss:0.2442 + XiCon Loss:3.1019 x Lambda(0.001)), Vali MSE Loss: 0.3716 Test MSE Loss: 0.2882
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2451333
	speed: 0.0606s/iter; left time: 596.6146s
Epoch: 8 cost time: 6.585967302322388
Epoch: 8, Steps: 107 Train Loss: 0.2468 (Forecasting Loss:0.2437 + XiCon Loss:3.1013 x Lambda(0.001)), Vali MSE Loss: 0.3705 Test MSE Loss: 0.2849
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2499671
	speed: 0.0603s/iter; left time: 587.7309s
Epoch: 9 cost time: 6.529199600219727
Epoch: 9, Steps: 107 Train Loss: 0.2463 (Forecasting Loss:0.2432 + XiCon Loss:3.1008 x Lambda(0.001)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.2916
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2429992
	speed: 0.0607s/iter; left time: 585.4230s
Epoch: 10 cost time: 6.4903669357299805
Epoch: 10, Steps: 107 Train Loss: 0.2461 (Forecasting Loss:0.2430 + XiCon Loss:3.1014 x Lambda(0.001)), Vali MSE Loss: 0.3679 Test MSE Loss: 0.2919
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2497788
	speed: 0.0651s/iter; left time: 620.0787s
Epoch: 11 cost time: 6.974750518798828
Epoch: 11, Steps: 107 Train Loss: 0.2462 (Forecasting Loss:0.2431 + XiCon Loss:3.1003 x Lambda(0.001)), Vali MSE Loss: 0.3696 Test MSE Loss: 0.2906
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2412140
	speed: 0.0635s/iter; left time: 598.0939s
Epoch: 12 cost time: 6.806015968322754
Epoch: 12, Steps: 107 Train Loss: 0.2461 (Forecasting Loss:0.2430 + XiCon Loss:3.1010 x Lambda(0.001)), Vali MSE Loss: 0.3692 Test MSE Loss: 0.2916
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1735280305147171, mae:0.33767980337142944, mape:0.6529560089111328, mspe:17.310272216796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1651+-0.01011, MAE:0.3304+-0.00963, MAPE:0.6402+-0.04744, MSPE:16.9141+-2.82338, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6421
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.99517297744751
Epoch: 1, Steps: 96 Train Loss: 1.2911 (Forecasting Loss:0.9746 + XiCon Loss:3.1648 x Lambda(0.1)), Vali MSE Loss: 0.6605 Test MSE Loss: 0.9192
Validation loss decreased (inf --> 0.660478).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.793340682983398
Epoch: 2, Steps: 96 Train Loss: 1.0621 (Forecasting Loss:0.7476 + XiCon Loss:3.1448 x Lambda(0.1)), Vali MSE Loss: 0.6158 Test MSE Loss: 0.2713
Validation loss decreased (0.660478 --> 0.615771).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.86977481842041
Epoch: 3, Steps: 96 Train Loss: 0.8716 (Forecasting Loss:0.5570 + XiCon Loss:3.1460 x Lambda(0.1)), Vali MSE Loss: 0.5599 Test MSE Loss: 0.2551
Validation loss decreased (0.615771 --> 0.559884).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.469032287597656
Epoch: 4, Steps: 96 Train Loss: 0.8356 (Forecasting Loss:0.5220 + XiCon Loss:3.1365 x Lambda(0.1)), Vali MSE Loss: 0.5160 Test MSE Loss: 0.2578
Validation loss decreased (0.559884 --> 0.515991).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.524880647659302
Epoch: 5, Steps: 96 Train Loss: 0.8204 (Forecasting Loss:0.5071 + XiCon Loss:3.1328 x Lambda(0.1)), Vali MSE Loss: 0.5022 Test MSE Loss: 0.2570
Validation loss decreased (0.515991 --> 0.502207).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.38546895980835
Epoch: 6, Steps: 96 Train Loss: 0.8131 (Forecasting Loss:0.4999 + XiCon Loss:3.1315 x Lambda(0.1)), Vali MSE Loss: 0.4908 Test MSE Loss: 0.2638
Validation loss decreased (0.502207 --> 0.490849).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.859600305557251
Epoch: 7, Steps: 96 Train Loss: 0.8096 (Forecasting Loss:0.4967 + XiCon Loss:3.1289 x Lambda(0.1)), Vali MSE Loss: 0.4952 Test MSE Loss: 0.2591
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.223494529724121
Epoch: 8, Steps: 96 Train Loss: 0.8069 (Forecasting Loss:0.4941 + XiCon Loss:3.1281 x Lambda(0.1)), Vali MSE Loss: 0.4900 Test MSE Loss: 0.2615
Validation loss decreased (0.490849 --> 0.489999).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.572319984436035
Epoch: 9, Steps: 96 Train Loss: 0.8060 (Forecasting Loss:0.4933 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2611
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.271033763885498
Epoch: 10, Steps: 96 Train Loss: 0.8061 (Forecasting Loss:0.4934 + XiCon Loss:3.1271 x Lambda(0.1)), Vali MSE Loss: 0.4905 Test MSE Loss: 0.2610
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.089862823486328
Epoch: 11, Steps: 96 Train Loss: 0.8061 (Forecasting Loss:0.4933 + XiCon Loss:3.1280 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2611
Validation loss decreased (0.489999 --> 0.489802).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.136823892593384
Epoch: 12, Steps: 96 Train Loss: 0.8056 (Forecasting Loss:0.4928 + XiCon Loss:3.1276 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
Validation loss decreased (0.489802 --> 0.489572).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.978768348693848
Epoch: 13, Steps: 96 Train Loss: 0.8051 (Forecasting Loss:0.4923 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.427347660064697
Epoch: 14, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4922 + XiCon Loss:3.1282 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
Validation loss decreased (0.489572 --> 0.489331).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.242796421051025
Epoch: 15, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4922 + XiCon Loss:3.1285 x Lambda(0.1)), Vali MSE Loss: 0.4892 Test MSE Loss: 0.2613
Validation loss decreased (0.489331 --> 0.489164).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.197873592376709
Epoch: 16, Steps: 96 Train Loss: 0.8047 (Forecasting Loss:0.4919 + XiCon Loss:3.1279 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 4.459748983383179
Epoch: 17, Steps: 96 Train Loss: 0.8055 (Forecasting Loss:0.4927 + XiCon Loss:3.1275 x Lambda(0.1)), Vali MSE Loss: 0.4891 Test MSE Loss: 0.2613
Validation loss decreased (0.489164 --> 0.489131).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 4.637695789337158
Epoch: 18, Steps: 96 Train Loss: 0.8044 (Forecasting Loss:0.4915 + XiCon Loss:3.1287 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.56610894203186
Epoch: 19, Steps: 96 Train Loss: 0.8050 (Forecasting Loss:0.4923 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2613
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.359817981719971
Epoch: 20, Steps: 96 Train Loss: 0.8045 (Forecasting Loss:0.4918 + XiCon Loss:3.1269 x Lambda(0.1)), Vali MSE Loss: 0.4897 Test MSE Loss: 0.2613
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.40055251121521
Epoch: 21, Steps: 96 Train Loss: 0.8046 (Forecasting Loss:0.4919 + XiCon Loss:3.1274 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.787956476211548
Epoch: 22, Steps: 96 Train Loss: 0.8057 (Forecasting Loss:0.4929 + XiCon Loss:3.1286 x Lambda(0.1)), Vali MSE Loss: 0.4890 Test MSE Loss: 0.2613
Validation loss decreased (0.489131 --> 0.489049).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.719178676605225
Epoch: 23, Steps: 96 Train Loss: 0.8054 (Forecasting Loss:0.4925 + XiCon Loss:3.1287 x Lambda(0.1)), Vali MSE Loss: 0.4892 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.662058591842651
Epoch: 24, Steps: 96 Train Loss: 0.8058 (Forecasting Loss:0.4930 + XiCon Loss:3.1276 x Lambda(0.1)), Vali MSE Loss: 0.4898 Test MSE Loss: 0.2613
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.597346544265747
Epoch: 25, Steps: 96 Train Loss: 0.8047 (Forecasting Loss:0.4918 + XiCon Loss:3.1288 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2613
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 4.640811204910278
Epoch: 26, Steps: 96 Train Loss: 0.8044 (Forecasting Loss:0.4917 + XiCon Loss:3.1271 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 4.451732158660889
Epoch: 27, Steps: 96 Train Loss: 0.8040 (Forecasting Loss:0.4913 + XiCon Loss:3.1272 x Lambda(0.1)), Vali MSE Loss: 0.4899 Test MSE Loss: 0.2613
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 4.067102670669556
Epoch: 28, Steps: 96 Train Loss: 0.8060 (Forecasting Loss:0.4932 + XiCon Loss:3.1279 x Lambda(0.1)), Vali MSE Loss: 0.4893 Test MSE Loss: 0.2613
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 5.047380685806274
Epoch: 29, Steps: 96 Train Loss: 0.8049 (Forecasting Loss:0.4922 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.467770576477051
Epoch: 30, Steps: 96 Train Loss: 0.8042 (Forecasting Loss:0.4913 + XiCon Loss:3.1286 x Lambda(0.1)), Vali MSE Loss: 0.4895 Test MSE Loss: 0.2613
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 4.5476179122924805
Epoch: 31, Steps: 96 Train Loss: 0.8053 (Forecasting Loss:0.4926 + XiCon Loss:3.1270 x Lambda(0.1)), Vali MSE Loss: 0.4896 Test MSE Loss: 0.2613
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 4.3973548412323
Epoch: 32, Steps: 96 Train Loss: 0.8047 (Forecasting Loss:0.4918 + XiCon Loss:3.1282 x Lambda(0.1)), Vali MSE Loss: 0.4894 Test MSE Loss: 0.2613
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.1832345724105835, mae:0.3393525779247284, mape:0.6756976246833801, mspe:20.96727180480957 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7551
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.319866418838501
Epoch: 1, Steps: 96 Train Loss: 1.2878 (Forecasting Loss:0.9712 + XiCon Loss:3.1662 x Lambda(0.1)), Vali MSE Loss: 0.6861 Test MSE Loss: 0.9596
Validation loss decreased (inf --> 0.686091).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.792996406555176
Epoch: 2, Steps: 96 Train Loss: 1.1148 (Forecasting Loss:0.8000 + XiCon Loss:3.1475 x Lambda(0.1)), Vali MSE Loss: 0.5789 Test MSE Loss: 0.4637
Validation loss decreased (0.686091 --> 0.578919).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.40345573425293
Epoch: 3, Steps: 96 Train Loss: 0.9097 (Forecasting Loss:0.5969 + XiCon Loss:3.1281 x Lambda(0.1)), Vali MSE Loss: 0.4855 Test MSE Loss: 0.3099
Validation loss decreased (0.578919 --> 0.485453).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.336036682128906
Epoch: 4, Steps: 96 Train Loss: 0.8166 (Forecasting Loss:0.5049 + XiCon Loss:3.1167 x Lambda(0.1)), Vali MSE Loss: 0.4862 Test MSE Loss: 0.3179
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.714462518692017
Epoch: 5, Steps: 96 Train Loss: 0.7946 (Forecasting Loss:0.4838 + XiCon Loss:3.1084 x Lambda(0.1)), Vali MSE Loss: 0.4882 Test MSE Loss: 0.3244
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.8393967151641846
Epoch: 6, Steps: 96 Train Loss: 0.7862 (Forecasting Loss:0.4755 + XiCon Loss:3.1073 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3368
Validation loss decreased (0.485453 --> 0.481730).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.550065279006958
Epoch: 7, Steps: 96 Train Loss: 0.7836 (Forecasting Loss:0.4734 + XiCon Loss:3.1021 x Lambda(0.1)), Vali MSE Loss: 0.4830 Test MSE Loss: 0.3317
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.725919485092163
Epoch: 8, Steps: 96 Train Loss: 0.7804 (Forecasting Loss:0.4702 + XiCon Loss:3.1022 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3361
Validation loss decreased (0.481730 --> 0.480812).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.748828411102295
Epoch: 9, Steps: 96 Train Loss: 0.7788 (Forecasting Loss:0.4685 + XiCon Loss:3.1026 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3398
Validation loss decreased (0.480812 --> 0.480779).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.335176706314087
Epoch: 10, Steps: 96 Train Loss: 0.7791 (Forecasting Loss:0.4688 + XiCon Loss:3.1023 x Lambda(0.1)), Vali MSE Loss: 0.4809 Test MSE Loss: 0.3330
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.944797992706299
Epoch: 11, Steps: 96 Train Loss: 0.7764 (Forecasting Loss:0.4661 + XiCon Loss:3.1027 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3348
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.280363082885742
Epoch: 12, Steps: 96 Train Loss: 0.7797 (Forecasting Loss:0.4693 + XiCon Loss:3.1037 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3352
Validation loss decreased (0.480779 --> 0.480525).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.501697301864624
Epoch: 13, Steps: 96 Train Loss: 0.7788 (Forecasting Loss:0.4686 + XiCon Loss:3.1018 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3356
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.646830081939697
Epoch: 14, Steps: 96 Train Loss: 0.7776 (Forecasting Loss:0.4674 + XiCon Loss:3.1017 x Lambda(0.1)), Vali MSE Loss: 0.4820 Test MSE Loss: 0.3356
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.310157775878906
Epoch: 15, Steps: 96 Train Loss: 0.7785 (Forecasting Loss:0.4681 + XiCon Loss:3.1043 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.371441125869751
Epoch: 16, Steps: 96 Train Loss: 0.7780 (Forecasting Loss:0.4677 + XiCon Loss:3.1027 x Lambda(0.1)), Vali MSE Loss: 0.4813 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 4.633164644241333
Epoch: 17, Steps: 96 Train Loss: 0.7791 (Forecasting Loss:0.4687 + XiCon Loss:3.1035 x Lambda(0.1)), Vali MSE Loss: 0.4808 Test MSE Loss: 0.3358
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 4.819964408874512
Epoch: 18, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4685 + XiCon Loss:3.1020 x Lambda(0.1)), Vali MSE Loss: 0.4814 Test MSE Loss: 0.3358
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 4.588599920272827
Epoch: 19, Steps: 96 Train Loss: 0.7805 (Forecasting Loss:0.4701 + XiCon Loss:3.1042 x Lambda(0.1)), Vali MSE Loss: 0.4804 Test MSE Loss: 0.3358
Validation loss decreased (0.480525 --> 0.480449).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.893164873123169
Epoch: 20, Steps: 96 Train Loss: 0.7784 (Forecasting Loss:0.4679 + XiCon Loss:3.1053 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.7890167236328125
Epoch: 21, Steps: 96 Train Loss: 0.7772 (Forecasting Loss:0.4669 + XiCon Loss:3.1032 x Lambda(0.1)), Vali MSE Loss: 0.4821 Test MSE Loss: 0.3358
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.451422691345215
Epoch: 22, Steps: 96 Train Loss: 0.7802 (Forecasting Loss:0.4698 + XiCon Loss:3.1038 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.732336759567261
Epoch: 23, Steps: 96 Train Loss: 0.7777 (Forecasting Loss:0.4676 + XiCon Loss:3.1011 x Lambda(0.1)), Vali MSE Loss: 0.4807 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.561684846878052
Epoch: 24, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4684 + XiCon Loss:3.1029 x Lambda(0.1)), Vali MSE Loss: 0.4795 Test MSE Loss: 0.3358
Validation loss decreased (0.480449 --> 0.479543).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.4123334884643555
Epoch: 25, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4686 + XiCon Loss:3.1017 x Lambda(0.1)), Vali MSE Loss: 0.4798 Test MSE Loss: 0.3358
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 4.9339210987091064
Epoch: 26, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4683 + XiCon Loss:3.1037 x Lambda(0.1)), Vali MSE Loss: 0.4810 Test MSE Loss: 0.3358
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 4.270723581314087
Epoch: 27, Steps: 96 Train Loss: 0.7797 (Forecasting Loss:0.4694 + XiCon Loss:3.1028 x Lambda(0.1)), Vali MSE Loss: 0.4817 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 4.6488196849823
Epoch: 28, Steps: 96 Train Loss: 0.7798 (Forecasting Loss:0.4695 + XiCon Loss:3.1030 x Lambda(0.1)), Vali MSE Loss: 0.4801 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 4.586985111236572
Epoch: 29, Steps: 96 Train Loss: 0.7787 (Forecasting Loss:0.4682 + XiCon Loss:3.1045 x Lambda(0.1)), Vali MSE Loss: 0.4815 Test MSE Loss: 0.3358
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 4.9614417552948
Epoch: 30, Steps: 96 Train Loss: 0.7779 (Forecasting Loss:0.4676 + XiCon Loss:3.1035 x Lambda(0.1)), Vali MSE Loss: 0.4793 Test MSE Loss: 0.3358
Validation loss decreased (0.479543 --> 0.479278).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 4.8591649532318115
Epoch: 31, Steps: 96 Train Loss: 0.7796 (Forecasting Loss:0.4693 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4796 Test MSE Loss: 0.3358
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 4.552840948104858
Epoch: 32, Steps: 96 Train Loss: 0.7766 (Forecasting Loss:0.4664 + XiCon Loss:3.1024 x Lambda(0.1)), Vali MSE Loss: 0.4819 Test MSE Loss: 0.3358
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 4.478957414627075
Epoch: 33, Steps: 96 Train Loss: 0.7774 (Forecasting Loss:0.4670 + XiCon Loss:3.1047 x Lambda(0.1)), Vali MSE Loss: 0.4828 Test MSE Loss: 0.3358
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 4.5973803997039795
Epoch: 34, Steps: 96 Train Loss: 0.7772 (Forecasting Loss:0.4668 + XiCon Loss:3.1040 x Lambda(0.1)), Vali MSE Loss: 0.4804 Test MSE Loss: 0.3358
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 4.647815942764282
Epoch: 35, Steps: 96 Train Loss: 0.7786 (Forecasting Loss:0.4684 + XiCon Loss:3.1022 x Lambda(0.1)), Vali MSE Loss: 0.4805 Test MSE Loss: 0.3358
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 4.2788097858428955
Epoch: 36, Steps: 96 Train Loss: 0.7790 (Forecasting Loss:0.4687 + XiCon Loss:3.1026 x Lambda(0.1)), Vali MSE Loss: 0.4812 Test MSE Loss: 0.3358
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 4.283092737197876
Epoch: 37, Steps: 96 Train Loss: 0.7782 (Forecasting Loss:0.4679 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3358
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 4.60888409614563
Epoch: 38, Steps: 96 Train Loss: 0.7784 (Forecasting Loss:0.4681 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3358
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 4.8467206954956055
Epoch: 39, Steps: 96 Train Loss: 0.7785 (Forecasting Loss:0.4682 + XiCon Loss:3.1028 x Lambda(0.1)), Vali MSE Loss: 0.4803 Test MSE Loss: 0.3358
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 4.782687425613403
Epoch: 40, Steps: 96 Train Loss: 0.7782 (Forecasting Loss:0.4679 + XiCon Loss:3.1031 x Lambda(0.1)), Vali MSE Loss: 0.4829 Test MSE Loss: 0.3358
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2674218714237213, mae:0.40422189235687256, mape:0.7771968841552734, mspe:28.22757339477539 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.6265
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.579214096069336
Epoch: 1, Steps: 96 Train Loss: 1.2525 (Forecasting Loss:0.9379 + XiCon Loss:3.1459 x Lambda(0.1)), Vali MSE Loss: 0.6599 Test MSE Loss: 0.8491
Validation loss decreased (inf --> 0.659893).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.944272756576538
Epoch: 2, Steps: 96 Train Loss: 1.0561 (Forecasting Loss:0.7435 + XiCon Loss:3.1258 x Lambda(0.1)), Vali MSE Loss: 0.5985 Test MSE Loss: 0.3504
Validation loss decreased (0.659893 --> 0.598519).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.952480316162109
Epoch: 3, Steps: 96 Train Loss: 0.8691 (Forecasting Loss:0.5575 + XiCon Loss:3.1157 x Lambda(0.1)), Vali MSE Loss: 0.5626 Test MSE Loss: 0.2609
Validation loss decreased (0.598519 --> 0.562561).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.3954548835754395
Epoch: 4, Steps: 96 Train Loss: 0.8274 (Forecasting Loss:0.5160 + XiCon Loss:3.1143 x Lambda(0.1)), Vali MSE Loss: 0.6195 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.327025651931763
Epoch: 5, Steps: 96 Train Loss: 0.8136 (Forecasting Loss:0.5026 + XiCon Loss:3.1104 x Lambda(0.1)), Vali MSE Loss: 0.5312 Test MSE Loss: 0.2856
Validation loss decreased (0.562561 --> 0.531240).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.824557065963745
Epoch: 6, Steps: 96 Train Loss: 0.8054 (Forecasting Loss:0.4943 + XiCon Loss:3.1104 x Lambda(0.1)), Vali MSE Loss: 0.5266 Test MSE Loss: 0.2920
Validation loss decreased (0.531240 --> 0.526618).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.809418201446533
Epoch: 7, Steps: 96 Train Loss: 0.8019 (Forecasting Loss:0.4909 + XiCon Loss:3.1102 x Lambda(0.1)), Vali MSE Loss: 0.5316 Test MSE Loss: 0.2864
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.472001314163208
Epoch: 8, Steps: 96 Train Loss: 0.8010 (Forecasting Loss:0.4900 + XiCon Loss:3.1101 x Lambda(0.1)), Vali MSE Loss: 0.5338 Test MSE Loss: 0.2844
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.674750089645386
Epoch: 9, Steps: 96 Train Loss: 0.7985 (Forecasting Loss:0.4874 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.5341 Test MSE Loss: 0.2848
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 8.4231116771698
Epoch: 10, Steps: 96 Train Loss: 0.7983 (Forecasting Loss:0.4873 + XiCon Loss:3.1096 x Lambda(0.1)), Vali MSE Loss: 0.5366 Test MSE Loss: 0.2847
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.623584508895874
Epoch: 11, Steps: 96 Train Loss: 0.7984 (Forecasting Loss:0.4873 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.5340 Test MSE Loss: 0.2852
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.543878078460693
Epoch: 12, Steps: 96 Train Loss: 0.7976 (Forecasting Loss:0.4865 + XiCon Loss:3.1107 x Lambda(0.1)), Vali MSE Loss: 0.5325 Test MSE Loss: 0.2861
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.454833984375
Epoch: 13, Steps: 96 Train Loss: 0.7980 (Forecasting Loss:0.4870 + XiCon Loss:3.1108 x Lambda(0.1)), Vali MSE Loss: 0.5334 Test MSE Loss: 0.2861
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.3147056102752686
Epoch: 14, Steps: 96 Train Loss: 0.7973 (Forecasting Loss:0.4864 + XiCon Loss:3.1093 x Lambda(0.1)), Vali MSE Loss: 0.5330 Test MSE Loss: 0.2861
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.2847325801849365
Epoch: 15, Steps: 96 Train Loss: 0.7987 (Forecasting Loss:0.4875 + XiCon Loss:3.1113 x Lambda(0.1)), Vali MSE Loss: 0.5334 Test MSE Loss: 0.2861
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.51775336265564
Epoch: 16, Steps: 96 Train Loss: 0.7985 (Forecasting Loss:0.4875 + XiCon Loss:3.1100 x Lambda(0.1)), Vali MSE Loss: 0.5346 Test MSE Loss: 0.2861
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2172553986310959, mae:0.3667510151863098, mape:0.7314600348472595, mspe:24.6042423248291 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.5728
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.112131118774414
Epoch: 1, Steps: 96 Train Loss: 1.2387 (Forecasting Loss:0.9243 + XiCon Loss:3.1432 x Lambda(0.1)), Vali MSE Loss: 0.6504 Test MSE Loss: 0.8090
Validation loss decreased (inf --> 0.650428).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.437408924102783
Epoch: 2, Steps: 96 Train Loss: 1.1153 (Forecasting Loss:0.8013 + XiCon Loss:3.1395 x Lambda(0.1)), Vali MSE Loss: 0.5675 Test MSE Loss: 0.4015
Validation loss decreased (0.650428 --> 0.567501).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.420885324478149
Epoch: 3, Steps: 96 Train Loss: 0.8748 (Forecasting Loss:0.5609 + XiCon Loss:3.1392 x Lambda(0.1)), Vali MSE Loss: 0.6590 Test MSE Loss: 0.2756
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.9698400497436523
Epoch: 4, Steps: 96 Train Loss: 0.8098 (Forecasting Loss:0.4965 + XiCon Loss:3.1324 x Lambda(0.1)), Vali MSE Loss: 0.5492 Test MSE Loss: 0.2849
Validation loss decreased (0.567501 --> 0.549157).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.160706043243408
Epoch: 5, Steps: 96 Train Loss: 0.7898 (Forecasting Loss:0.4769 + XiCon Loss:3.1288 x Lambda(0.1)), Vali MSE Loss: 0.5669 Test MSE Loss: 0.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.249920129776001
Epoch: 6, Steps: 96 Train Loss: 0.7823 (Forecasting Loss:0.4695 + XiCon Loss:3.1271 x Lambda(0.1)), Vali MSE Loss: 0.5704 Test MSE Loss: 0.2820
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.496794700622559
Epoch: 7, Steps: 96 Train Loss: 0.7768 (Forecasting Loss:0.4640 + XiCon Loss:3.1280 x Lambda(0.1)), Vali MSE Loss: 0.5580 Test MSE Loss: 0.2857
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.584317684173584
Epoch: 8, Steps: 96 Train Loss: 0.7746 (Forecasting Loss:0.4621 + XiCon Loss:3.1257 x Lambda(0.1)), Vali MSE Loss: 0.5592 Test MSE Loss: 0.2858
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.536793947219849
Epoch: 9, Steps: 96 Train Loss: 0.7741 (Forecasting Loss:0.4615 + XiCon Loss:3.1254 x Lambda(0.1)), Vali MSE Loss: 0.5553 Test MSE Loss: 0.2875
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.613405704498291
Epoch: 10, Steps: 96 Train Loss: 0.7747 (Forecasting Loss:0.4620 + XiCon Loss:3.1273 x Lambda(0.1)), Vali MSE Loss: 0.5545 Test MSE Loss: 0.2879
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.462764501571655
Epoch: 11, Steps: 96 Train Loss: 0.7752 (Forecasting Loss:0.4626 + XiCon Loss:3.1257 x Lambda(0.1)), Vali MSE Loss: 0.5557 Test MSE Loss: 0.2875
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 3.913266658782959
Epoch: 12, Steps: 96 Train Loss: 0.7741 (Forecasting Loss:0.4615 + XiCon Loss:3.1252 x Lambda(0.1)), Vali MSE Loss: 0.5562 Test MSE Loss: 0.2873
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.73035454750061
Epoch: 13, Steps: 96 Train Loss: 0.7737 (Forecasting Loss:0.4611 + XiCon Loss:3.1258 x Lambda(0.1)), Vali MSE Loss: 0.5552 Test MSE Loss: 0.2873
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.025343656539917
Epoch: 14, Steps: 96 Train Loss: 0.7725 (Forecasting Loss:0.4598 + XiCon Loss:3.1269 x Lambda(0.1)), Vali MSE Loss: 0.5551 Test MSE Loss: 0.2874
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.20806950330734253, mae:0.36165615916252136, mape:0.6832956671714783, mspe:21.043214797973633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7092
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.5810980796813965
Epoch: 1, Steps: 96 Train Loss: 1.2284 (Forecasting Loss:0.9104 + XiCon Loss:3.1804 x Lambda(0.1)), Vali MSE Loss: 0.6232 Test MSE Loss: 0.7929
Validation loss decreased (inf --> 0.623236).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.517248630523682
Epoch: 2, Steps: 96 Train Loss: 1.0429 (Forecasting Loss:0.7317 + XiCon Loss:3.1121 x Lambda(0.1)), Vali MSE Loss: 0.5150 Test MSE Loss: 0.2712
Validation loss decreased (0.623236 --> 0.515000).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.504212141036987
Epoch: 3, Steps: 96 Train Loss: 0.8349 (Forecasting Loss:0.5275 + XiCon Loss:3.0738 x Lambda(0.1)), Vali MSE Loss: 0.5521 Test MSE Loss: 0.2848
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.773381233215332
Epoch: 4, Steps: 96 Train Loss: 0.7987 (Forecasting Loss:0.4929 + XiCon Loss:3.0587 x Lambda(0.1)), Vali MSE Loss: 0.5274 Test MSE Loss: 0.3218
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.477216482162476
Epoch: 5, Steps: 96 Train Loss: 0.7835 (Forecasting Loss:0.4782 + XiCon Loss:3.0524 x Lambda(0.1)), Vali MSE Loss: 0.5568 Test MSE Loss: 0.2947
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.4790143966674805
Epoch: 6, Steps: 96 Train Loss: 0.7775 (Forecasting Loss:0.4722 + XiCon Loss:3.0530 x Lambda(0.1)), Vali MSE Loss: 0.5301 Test MSE Loss: 0.3107
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.573296308517456
Epoch: 7, Steps: 96 Train Loss: 0.7719 (Forecasting Loss:0.4667 + XiCon Loss:3.0515 x Lambda(0.1)), Vali MSE Loss: 0.5258 Test MSE Loss: 0.3211
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.340986967086792
Epoch: 8, Steps: 96 Train Loss: 0.7714 (Forecasting Loss:0.4664 + XiCon Loss:3.0500 x Lambda(0.1)), Vali MSE Loss: 0.5260 Test MSE Loss: 0.3179
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.57249903678894
Epoch: 9, Steps: 96 Train Loss: 0.7707 (Forecasting Loss:0.4659 + XiCon Loss:3.0484 x Lambda(0.1)), Vali MSE Loss: 0.5275 Test MSE Loss: 0.3174
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.5018630027771
Epoch: 10, Steps: 96 Train Loss: 0.7696 (Forecasting Loss:0.4646 + XiCon Loss:3.0508 x Lambda(0.1)), Vali MSE Loss: 0.5255 Test MSE Loss: 0.3187
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.841655492782593
Epoch: 11, Steps: 96 Train Loss: 0.7703 (Forecasting Loss:0.4653 + XiCon Loss:3.0497 x Lambda(0.1)), Vali MSE Loss: 0.5253 Test MSE Loss: 0.3197
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.940011978149414
Epoch: 12, Steps: 96 Train Loss: 0.7712 (Forecasting Loss:0.4663 + XiCon Loss:3.0487 x Lambda(0.1)), Vali MSE Loss: 0.5252 Test MSE Loss: 0.3198
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.19322249293327332, mae:0.34922486543655396, mape:0.6882543563842773, mspe:21.050609588623047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2138+-0.04061, MAE:0.3642+-0.03077, MAPE:0.7112+-0.05316, MSPE:23.1786+-3.99956, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.2261
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.1177025
	speed: 0.0551s/iter; left time: 1453.6760s
	iters: 200, epoch: 1 | loss: 31.4935093
	speed: 0.0530s/iter; left time: 1393.8574s
Epoch: 1 cost time: 14.426445484161377
Epoch: 1, Steps: 265 Train Loss: 32.2951 (Forecasting Loss:0.2125 + XiCon Loss:3.2083 x Lambda(10.0)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.0981
Validation loss decreased (inf --> 0.145869).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.5524445
	speed: 0.0592s/iter; left time: 1546.1171s
	iters: 200, epoch: 2 | loss: 31.9648170
	speed: 0.0545s/iter; left time: 1418.6325s
Epoch: 2 cost time: 14.991375207901001
Epoch: 2, Steps: 265 Train Loss: 32.0142 (Forecasting Loss:0.1984 + XiCon Loss:3.1816 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0958
Validation loss decreased (0.145869 --> 0.144224).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6988850
	speed: 0.0578s/iter; left time: 1495.6210s
	iters: 200, epoch: 3 | loss: 30.5233097
	speed: 0.0562s/iter; left time: 1449.1905s
Epoch: 3 cost time: 15.15593671798706
Epoch: 3, Steps: 265 Train Loss: 30.9862 (Forecasting Loss:0.1935 + XiCon Loss:3.0793 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0952
Validation loss decreased (0.144224 --> 0.143366).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7250862
	speed: 0.0603s/iter; left time: 1544.2237s
	iters: 200, epoch: 4 | loss: 32.2369308
	speed: 0.0585s/iter; left time: 1492.9535s
Epoch: 4 cost time: 15.490818500518799
Epoch: 4, Steps: 265 Train Loss: 30.9013 (Forecasting Loss:0.1911 + XiCon Loss:3.0710 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0955
Validation loss decreased (0.143366 --> 0.143365).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.8501606
	speed: 0.0625s/iter; left time: 1582.5558s
	iters: 200, epoch: 5 | loss: 30.3264503
	speed: 0.0587s/iter; left time: 1482.8710s
Epoch: 5 cost time: 16.079537391662598
Epoch: 5, Steps: 265 Train Loss: 30.8529 (Forecasting Loss:0.1897 + XiCon Loss:3.0663 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0959
Validation loss decreased (0.143365 --> 0.142132).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.0567818
	speed: 0.0583s/iter; left time: 1461.9912s
	iters: 200, epoch: 6 | loss: 30.3118267
	speed: 0.0555s/iter; left time: 1385.1892s
Epoch: 6 cost time: 15.04671835899353
Epoch: 6, Steps: 265 Train Loss: 30.7983 (Forecasting Loss:0.1892 + XiCon Loss:3.0609 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0958
Validation loss decreased (0.142132 --> 0.141640).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2940807
	speed: 0.0622s/iter; left time: 1542.1706s
	iters: 200, epoch: 7 | loss: 30.7264786
	speed: 0.0557s/iter; left time: 1377.1699s
Epoch: 7 cost time: 15.671760320663452
Epoch: 7, Steps: 265 Train Loss: 30.8343 (Forecasting Loss:0.1888 + XiCon Loss:3.0645 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1711369
	speed: 0.0588s/iter; left time: 1443.2406s
	iters: 200, epoch: 8 | loss: 30.7651958
	speed: 0.0605s/iter; left time: 1480.0853s
Epoch: 8 cost time: 15.74722409248352
Epoch: 8, Steps: 265 Train Loss: 30.7973 (Forecasting Loss:0.1886 + XiCon Loss:3.0609 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0957
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.9927635
	speed: 0.0597s/iter; left time: 1450.3813s
	iters: 200, epoch: 9 | loss: 30.2051353
	speed: 0.0544s/iter; left time: 1314.2765s
Epoch: 9 cost time: 15.17099380493164
Epoch: 9, Steps: 265 Train Loss: 30.7726 (Forecasting Loss:0.1886 + XiCon Loss:3.0584 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0956
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5166187
	speed: 0.0705s/iter; left time: 1693.7338s
	iters: 200, epoch: 10 | loss: 30.5149231
	speed: 0.0628s/iter; left time: 1502.3487s
Epoch: 10 cost time: 17.650694847106934
Epoch: 10, Steps: 265 Train Loss: 30.7826 (Forecasting Loss:0.1885 + XiCon Loss:3.0594 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.2200260
	speed: 0.0674s/iter; left time: 1601.3418s
	iters: 200, epoch: 11 | loss: 31.6502476
	speed: 0.0484s/iter; left time: 1143.9297s
Epoch: 11 cost time: 14.710311889648438
Epoch: 11, Steps: 265 Train Loss: 30.8007 (Forecasting Loss:0.1886 + XiCon Loss:3.0612 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1268787
	speed: 0.0537s/iter; left time: 1261.7025s
	iters: 200, epoch: 12 | loss: 30.3006630
	speed: 0.0507s/iter; left time: 1185.3803s
Epoch: 12 cost time: 14.397184371948242
Epoch: 12, Steps: 265 Train Loss: 30.7983 (Forecasting Loss:0.1886 + XiCon Loss:3.0610 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7096901
	speed: 0.0573s/iter; left time: 1331.1450s
	iters: 200, epoch: 13 | loss: 32.0853653
	speed: 0.0581s/iter; left time: 1343.9755s
Epoch: 13 cost time: 15.60527229309082
Epoch: 13, Steps: 265 Train Loss: 30.7735 (Forecasting Loss:0.1885 + XiCon Loss:3.0585 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0957
Validation loss decreased (0.141640 --> 0.141568).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3580227
	speed: 0.0602s/iter; left time: 1382.7528s
	iters: 200, epoch: 14 | loss: 30.9103889
	speed: 0.0550s/iter; left time: 1257.1623s
Epoch: 14 cost time: 15.449991941452026
Epoch: 14, Steps: 265 Train Loss: 30.7415 (Forecasting Loss:0.1886 + XiCon Loss:3.0553 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.5314426
	speed: 0.0648s/iter; left time: 1471.2073s
	iters: 200, epoch: 15 | loss: 30.8161907
	speed: 0.0564s/iter; left time: 1274.1149s
Epoch: 15 cost time: 15.878505229949951
Epoch: 15, Steps: 265 Train Loss: 30.8102 (Forecasting Loss:0.1885 + XiCon Loss:3.0622 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.3037739
	speed: 0.0584s/iter; left time: 1310.2275s
	iters: 200, epoch: 16 | loss: 31.4903355
	speed: 0.0542s/iter; left time: 1209.7734s
Epoch: 16 cost time: 14.658366441726685
Epoch: 16, Steps: 265 Train Loss: 30.7461 (Forecasting Loss:0.1884 + XiCon Loss:3.0558 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0957
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.1229362
	speed: 0.0615s/iter; left time: 1363.6780s
	iters: 200, epoch: 17 | loss: 31.5894794
	speed: 0.0552s/iter; left time: 1218.5467s
Epoch: 17 cost time: 15.604810953140259
Epoch: 17, Steps: 265 Train Loss: 30.7664 (Forecasting Loss:0.1884 + XiCon Loss:3.0578 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0957
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.3228302
	speed: 0.0559s/iter; left time: 1223.6610s
	iters: 200, epoch: 18 | loss: 31.2096462
	speed: 0.0574s/iter; left time: 1251.4453s
Epoch: 18 cost time: 15.138908863067627
Epoch: 18, Steps: 265 Train Loss: 30.7476 (Forecasting Loss:0.1884 + XiCon Loss:3.0559 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2575169
	speed: 0.0566s/iter; left time: 1225.1951s
	iters: 200, epoch: 19 | loss: 31.1192856
	speed: 0.0581s/iter; left time: 1250.8678s
Epoch: 19 cost time: 15.172721862792969
Epoch: 19, Steps: 265 Train Loss: 30.7585 (Forecasting Loss:0.1885 + XiCon Loss:3.0570 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.3802929
	speed: 0.0581s/iter; left time: 1240.4769s
	iters: 200, epoch: 20 | loss: 30.3338566
	speed: 0.0590s/iter; left time: 1254.8505s
Epoch: 20 cost time: 15.459453821182251
Epoch: 20, Steps: 265 Train Loss: 30.7840 (Forecasting Loss:0.1884 + XiCon Loss:3.0596 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0957
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.6504841
	speed: 0.0612s/iter; left time: 1291.4999s
	iters: 200, epoch: 21 | loss: 30.4583359
	speed: 0.0641s/iter; left time: 1346.1342s
Epoch: 21 cost time: 16.469496965408325
Epoch: 21, Steps: 265 Train Loss: 30.7949 (Forecasting Loss:0.1885 + XiCon Loss:3.0606 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.3739357
	speed: 0.0713s/iter; left time: 1485.2113s
	iters: 200, epoch: 22 | loss: 30.7133694
	speed: 0.0624s/iter; left time: 1293.4823s
Epoch: 22 cost time: 16.673588037490845
Epoch: 22, Steps: 265 Train Loss: 30.7845 (Forecasting Loss:0.1884 + XiCon Loss:3.0596 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0957
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.4666157
	speed: 0.0480s/iter; left time: 988.3701s
	iters: 200, epoch: 23 | loss: 30.2557182
	speed: 0.0475s/iter; left time: 973.0820s
Epoch: 23 cost time: 13.008073568344116
Epoch: 23, Steps: 265 Train Loss: 30.7953 (Forecasting Loss:0.1885 + XiCon Loss:3.0607 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04044174775481224, mae:0.15094250440597534, mape:0.12001173943281174, mspe:0.027163784950971603 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.8985
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.2733002
	speed: 0.0604s/iter; left time: 1594.5229s
	iters: 200, epoch: 1 | loss: 31.4625263
	speed: 0.0536s/iter; left time: 1410.4042s
Epoch: 1 cost time: 14.871294021606445
Epoch: 1, Steps: 265 Train Loss: 32.1882 (Forecasting Loss:0.2101 + XiCon Loss:3.1978 x Lambda(10.0)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.0986
Validation loss decreased (inf --> 0.147996).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.2020359
	speed: 0.0597s/iter; left time: 1559.3842s
	iters: 200, epoch: 2 | loss: 30.6784554
	speed: 0.0561s/iter; left time: 1460.5721s
Epoch: 2 cost time: 15.391982555389404
Epoch: 2, Steps: 265 Train Loss: 31.9080 (Forecasting Loss:0.1984 + XiCon Loss:3.1710 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0980
Validation loss decreased (0.147996 --> 0.146495).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.2286835
	speed: 0.0599s/iter; left time: 1548.9908s
	iters: 200, epoch: 3 | loss: 32.3121262
	speed: 0.0592s/iter; left time: 1525.5560s
Epoch: 3 cost time: 15.550926446914673
Epoch: 3, Steps: 265 Train Loss: 33.0249 (Forecasting Loss:0.1937 + XiCon Loss:3.2831 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0956
Validation loss decreased (0.146495 --> 0.143404).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.9691086
	speed: 0.0593s/iter; left time: 1517.3491s
	iters: 200, epoch: 4 | loss: 31.6743298
	speed: 0.0571s/iter; left time: 1456.3940s
Epoch: 4 cost time: 15.378774404525757
Epoch: 4, Steps: 265 Train Loss: 31.6672 (Forecasting Loss:0.1912 + XiCon Loss:3.1476 x Lambda(10.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0953
Validation loss decreased (0.143404 --> 0.142963).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.6235790
	speed: 0.0575s/iter; left time: 1457.5023s
	iters: 200, epoch: 5 | loss: 30.8377514
	speed: 0.0561s/iter; left time: 1416.2324s
Epoch: 5 cost time: 15.346886157989502
Epoch: 5, Steps: 265 Train Loss: 31.3259 (Forecasting Loss:0.1902 + XiCon Loss:3.1136 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
Validation loss decreased (0.142963 --> 0.141940).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.2022896
	speed: 0.0598s/iter; left time: 1500.4620s
	iters: 200, epoch: 6 | loss: 30.7187309
	speed: 0.0556s/iter; left time: 1388.1253s
Epoch: 6 cost time: 15.318261623382568
Epoch: 6, Steps: 265 Train Loss: 31.1819 (Forecasting Loss:0.1899 + XiCon Loss:3.0992 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.7427349
	speed: 0.0635s/iter; left time: 1575.1214s
	iters: 200, epoch: 7 | loss: 31.5711060
	speed: 0.0538s/iter; left time: 1329.5136s
Epoch: 7 cost time: 15.797510385513306
Epoch: 7, Steps: 265 Train Loss: 31.1376 (Forecasting Loss:0.1895 + XiCon Loss:3.0948 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.141940 --> 0.141838).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.9559288
	speed: 0.0637s/iter; left time: 1563.6048s
	iters: 200, epoch: 8 | loss: 31.6831226
	speed: 0.0611s/iter; left time: 1494.7743s
Epoch: 8 cost time: 16.29782772064209
Epoch: 8, Steps: 265 Train Loss: 31.1864 (Forecasting Loss:0.1894 + XiCon Loss:3.0997 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141838 --> 0.141833).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.5180168
	speed: 0.0635s/iter; left time: 1540.9118s
	iters: 200, epoch: 9 | loss: 31.1275463
	speed: 0.0659s/iter; left time: 1593.2136s
Epoch: 9 cost time: 16.640297651290894
Epoch: 9, Steps: 265 Train Loss: 31.0829 (Forecasting Loss:0.1893 + XiCon Loss:3.0894 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141833 --> 0.141564).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7101917
	speed: 0.0617s/iter; left time: 1481.4513s
	iters: 200, epoch: 10 | loss: 30.8743114
	speed: 0.0562s/iter; left time: 1344.3761s
Epoch: 10 cost time: 15.37152361869812
Epoch: 10, Steps: 265 Train Loss: 31.1372 (Forecasting Loss:0.1892 + XiCon Loss:3.0948 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.7110786
	speed: 0.0610s/iter; left time: 1448.3358s
	iters: 200, epoch: 11 | loss: 31.4659367
	speed: 0.0551s/iter; left time: 1303.7830s
Epoch: 11 cost time: 15.270975828170776
Epoch: 11, Steps: 265 Train Loss: 31.1264 (Forecasting Loss:0.1892 + XiCon Loss:3.0937 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9141769
	speed: 0.0584s/iter; left time: 1372.3280s
	iters: 200, epoch: 12 | loss: 31.2008419
	speed: 0.0566s/iter; left time: 1323.1855s
Epoch: 12 cost time: 15.440568685531616
Epoch: 12, Steps: 265 Train Loss: 31.0956 (Forecasting Loss:0.1892 + XiCon Loss:3.0906 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4534874
	speed: 0.0584s/iter; left time: 1355.7466s
	iters: 200, epoch: 13 | loss: 30.8551159
	speed: 0.0579s/iter; left time: 1338.0804s
Epoch: 13 cost time: 15.165310859680176
Epoch: 13, Steps: 265 Train Loss: 31.1347 (Forecasting Loss:0.1893 + XiCon Loss:3.0945 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.7117710
	speed: 0.0586s/iter; left time: 1344.5493s
	iters: 200, epoch: 14 | loss: 31.5997868
	speed: 0.0567s/iter; left time: 1295.7988s
Epoch: 14 cost time: 15.20093059539795
Epoch: 14, Steps: 265 Train Loss: 31.0736 (Forecasting Loss:0.1892 + XiCon Loss:3.0884 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.2275143
	speed: 0.0566s/iter; left time: 1283.3697s
	iters: 200, epoch: 15 | loss: 32.0527115
	speed: 0.0558s/iter; left time: 1259.4750s
Epoch: 15 cost time: 14.844728469848633
Epoch: 15, Steps: 265 Train Loss: 31.0945 (Forecasting Loss:0.1892 + XiCon Loss:3.0905 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6212921
	speed: 0.0610s/iter; left time: 1368.5587s
	iters: 200, epoch: 16 | loss: 30.5268288
	speed: 0.0586s/iter; left time: 1307.9462s
Epoch: 16 cost time: 15.726746320724487
Epoch: 16, Steps: 265 Train Loss: 31.1314 (Forecasting Loss:0.1892 + XiCon Loss:3.0942 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.9094467
	speed: 0.0566s/iter; left time: 1255.0427s
	iters: 200, epoch: 17 | loss: 31.0266018
	speed: 0.0567s/iter; left time: 1250.7306s
Epoch: 17 cost time: 15.126384496688843
Epoch: 17, Steps: 265 Train Loss: 31.1377 (Forecasting Loss:0.1893 + XiCon Loss:3.0948 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.9558372
	speed: 0.0729s/iter; left time: 1596.1801s
	iters: 200, epoch: 18 | loss: 31.5452633
	speed: 0.1019s/iter; left time: 2220.6668s
Epoch: 18 cost time: 20.959816694259644
Epoch: 18, Steps: 265 Train Loss: 31.1340 (Forecasting Loss:0.1893 + XiCon Loss:3.0945 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5176945
	speed: 0.0605s/iter; left time: 1309.1983s
	iters: 200, epoch: 19 | loss: 31.4247341
	speed: 0.0703s/iter; left time: 1512.9359s
Epoch: 19 cost time: 17.430347442626953
Epoch: 19, Steps: 265 Train Loss: 31.0887 (Forecasting Loss:0.1892 + XiCon Loss:3.0899 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039314959198236465, mae:0.14941932260990143, mape:0.11857994645833969, mspe:0.026285693049430847 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.4288
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.1669540
	speed: 0.0684s/iter; left time: 1804.8911s
	iters: 200, epoch: 1 | loss: 31.4931717
	speed: 0.0609s/iter; left time: 1601.2009s
Epoch: 1 cost time: 16.91072392463684
Epoch: 1, Steps: 265 Train Loss: 32.1175 (Forecasting Loss:0.2113 + XiCon Loss:3.1906 x Lambda(10.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.146360).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.7428131
	speed: 0.0706s/iter; left time: 1844.6496s
	iters: 200, epoch: 2 | loss: 32.3890915
	speed: 0.0653s/iter; left time: 1700.1085s
Epoch: 2 cost time: 17.715483903884888
Epoch: 2, Steps: 265 Train Loss: 33.1942 (Forecasting Loss:0.1979 + XiCon Loss:3.2996 x Lambda(10.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0974
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.6667709
	speed: 0.0661s/iter; left time: 1711.2412s
	iters: 200, epoch: 3 | loss: 31.4107590
	speed: 0.0670s/iter; left time: 1725.8501s
Epoch: 3 cost time: 17.52876091003418
Epoch: 3, Steps: 265 Train Loss: 32.4523 (Forecasting Loss:0.1926 + XiCon Loss:3.2260 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0998
Validation loss decreased (0.146360 --> 0.143375).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.3940582
	speed: 0.0647s/iter; left time: 1656.8940s
	iters: 200, epoch: 4 | loss: 31.2727108
	speed: 0.0669s/iter; left time: 1707.4123s
Epoch: 4 cost time: 17.287738800048828
Epoch: 4, Steps: 265 Train Loss: 32.0779 (Forecasting Loss:0.1898 + XiCon Loss:3.1888 x Lambda(10.0)), Vali MSE Loss: 0.1453 Test MSE Loss: 0.0950
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.2969856
	speed: 0.0660s/iter; left time: 1671.7266s
	iters: 200, epoch: 5 | loss: 31.3596363
	speed: 0.0637s/iter; left time: 1607.9320s
Epoch: 5 cost time: 17.200589418411255
Epoch: 5, Steps: 265 Train Loss: 31.3369 (Forecasting Loss:0.1892 + XiCon Loss:3.1148 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0960
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6590557
	speed: 0.0668s/iter; left time: 1674.3952s
	iters: 200, epoch: 6 | loss: 30.9231167
	speed: 0.0660s/iter; left time: 1649.1189s
Epoch: 6 cost time: 17.58418917655945
Epoch: 6, Steps: 265 Train Loss: 31.1001 (Forecasting Loss:0.1887 + XiCon Loss:3.0911 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0963
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1659851
	speed: 0.0664s/iter; left time: 1647.2144s
	iters: 200, epoch: 7 | loss: 30.4176559
	speed: 0.0635s/iter; left time: 1569.7234s
Epoch: 7 cost time: 17.679933309555054
Epoch: 7, Steps: 265 Train Loss: 31.0297 (Forecasting Loss:0.1884 + XiCon Loss:3.0841 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0965
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.4909706
	speed: 0.0749s/iter; left time: 1839.4564s
	iters: 200, epoch: 8 | loss: 30.6392326
	speed: 0.0705s/iter; left time: 1722.9079s
Epoch: 8 cost time: 19.10569977760315
Epoch: 8, Steps: 265 Train Loss: 31.0872 (Forecasting Loss:0.1886 + XiCon Loss:3.0899 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0962
Validation loss decreased (0.143375 --> 0.143185).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0894127
	speed: 0.0682s/iter; left time: 1655.7639s
	iters: 200, epoch: 9 | loss: 31.5067215
	speed: 0.0662s/iter; left time: 1600.5012s
Epoch: 9 cost time: 17.657926559448242
Epoch: 9, Steps: 265 Train Loss: 31.0070 (Forecasting Loss:0.1884 + XiCon Loss:3.0819 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0963
Validation loss decreased (0.143185 --> 0.143174).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.0368233
	speed: 0.0658s/iter; left time: 1579.4385s
	iters: 200, epoch: 10 | loss: 30.8646545
	speed: 0.0634s/iter; left time: 1516.2751s
Epoch: 10 cost time: 17.481319904327393
Epoch: 10, Steps: 265 Train Loss: 30.9409 (Forecasting Loss:0.1885 + XiCon Loss:3.0752 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0961
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7968445
	speed: 0.0682s/iter; left time: 1620.8597s
	iters: 200, epoch: 11 | loss: 29.9206676
	speed: 0.0648s/iter; left time: 1533.3129s
Epoch: 11 cost time: 17.470604181289673
Epoch: 11, Steps: 265 Train Loss: 31.0163 (Forecasting Loss:0.1884 + XiCon Loss:3.0828 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1366138
	speed: 0.0692s/iter; left time: 1626.3003s
	iters: 200, epoch: 12 | loss: 30.7647495
	speed: 0.0644s/iter; left time: 1505.1508s
Epoch: 12 cost time: 17.620952606201172
Epoch: 12, Steps: 265 Train Loss: 31.0048 (Forecasting Loss:0.1883 + XiCon Loss:3.0817 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0960
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.3932590
	speed: 0.0668s/iter; left time: 1550.2621s
	iters: 200, epoch: 13 | loss: 31.5991459
	speed: 0.0642s/iter; left time: 1484.1907s
Epoch: 13 cost time: 17.553617238998413
Epoch: 13, Steps: 265 Train Loss: 30.9984 (Forecasting Loss:0.1882 + XiCon Loss:3.0810 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.0730972
	speed: 0.0698s/iter; left time: 1603.3898s
	iters: 200, epoch: 14 | loss: 31.2012863
	speed: 0.0636s/iter; left time: 1453.4597s
Epoch: 14 cost time: 17.47981095314026
Epoch: 14, Steps: 265 Train Loss: 31.0287 (Forecasting Loss:0.1883 + XiCon Loss:3.0840 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0960
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.5020218
	speed: 0.0693s/iter; left time: 1572.2828s
	iters: 200, epoch: 15 | loss: 31.0847454
	speed: 0.0677s/iter; left time: 1530.1206s
Epoch: 15 cost time: 18.065396308898926
Epoch: 15, Steps: 265 Train Loss: 31.0330 (Forecasting Loss:0.1883 + XiCon Loss:3.0845 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0960
Validation loss decreased (0.143174 --> 0.143075).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9372025
	speed: 0.0674s/iter; left time: 1512.3976s
	iters: 200, epoch: 16 | loss: 31.1993237
	speed: 0.0643s/iter; left time: 1435.7913s
Epoch: 16 cost time: 17.667102813720703
Epoch: 16, Steps: 265 Train Loss: 30.9931 (Forecasting Loss:0.1883 + XiCon Loss:3.0805 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3260288
	speed: 0.0729s/iter; left time: 1616.1397s
	iters: 200, epoch: 17 | loss: 30.4207478
	speed: 0.0665s/iter; left time: 1467.1262s
Epoch: 17 cost time: 18.583953857421875
Epoch: 17, Steps: 265 Train Loss: 30.9887 (Forecasting Loss:0.1882 + XiCon Loss:3.0801 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.3946438
	speed: 0.0691s/iter; left time: 1512.9018s
	iters: 200, epoch: 18 | loss: 32.5018616
	speed: 0.0662s/iter; left time: 1443.2797s
Epoch: 18 cost time: 17.808551788330078
Epoch: 18, Steps: 265 Train Loss: 30.9968 (Forecasting Loss:0.1882 + XiCon Loss:3.0809 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5497875
	speed: 0.0670s/iter; left time: 1448.8686s
	iters: 200, epoch: 19 | loss: 31.7540169
	speed: 0.0686s/iter; left time: 1476.6684s
Epoch: 19 cost time: 17.997556447982788
Epoch: 19, Steps: 265 Train Loss: 31.0337 (Forecasting Loss:0.1884 + XiCon Loss:3.0845 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.8742809
	speed: 0.0697s/iter; left time: 1489.9374s
	iters: 200, epoch: 20 | loss: 30.6872940
	speed: 0.0613s/iter; left time: 1304.5336s
Epoch: 20 cost time: 17.221923112869263
Epoch: 20, Steps: 265 Train Loss: 30.9810 (Forecasting Loss:0.1881 + XiCon Loss:3.0793 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0960
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.2882156
	speed: 0.0688s/iter; left time: 1452.6404s
	iters: 200, epoch: 21 | loss: 30.2708874
	speed: 0.0649s/iter; left time: 1363.2113s
Epoch: 21 cost time: 17.497722148895264
Epoch: 21, Steps: 265 Train Loss: 30.9850 (Forecasting Loss:0.1883 + XiCon Loss:3.0797 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.7522354
	speed: 0.0650s/iter; left time: 1355.3528s
	iters: 200, epoch: 22 | loss: 30.1243877
	speed: 0.0686s/iter; left time: 1423.3649s
Epoch: 22 cost time: 17.61049747467041
Epoch: 22, Steps: 265 Train Loss: 31.0095 (Forecasting Loss:0.1883 + XiCon Loss:3.0821 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0960
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.0020046
	speed: 0.0677s/iter; left time: 1391.7660s
	iters: 200, epoch: 23 | loss: 30.4982986
	speed: 0.0628s/iter; left time: 1285.3991s
Epoch: 23 cost time: 17.06540822982788
Epoch: 23, Steps: 265 Train Loss: 30.9597 (Forecasting Loss:0.1882 + XiCon Loss:3.0771 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0960
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.1487312
	speed: 0.0689s/iter; left time: 1399.9935s
	iters: 200, epoch: 24 | loss: 31.1762638
	speed: 0.0629s/iter; left time: 1271.8138s
Epoch: 24 cost time: 17.418978452682495
Epoch: 24, Steps: 265 Train Loss: 30.9835 (Forecasting Loss:0.1883 + XiCon Loss:3.0795 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0960
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.7524643
	speed: 0.0699s/iter; left time: 1401.3554s
	iters: 200, epoch: 25 | loss: 30.6149807
	speed: 0.0672s/iter; left time: 1340.7860s
Epoch: 25 cost time: 18.29244875907898
Epoch: 25, Steps: 265 Train Loss: 31.0193 (Forecasting Loss:0.1885 + XiCon Loss:3.0831 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0960
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04083975404500961, mae:0.15120002627372742, mape:0.12042930722236633, mspe:0.02777666226029396 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 24.1914
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.5063057
	speed: 0.0695s/iter; left time: 1834.2157s
	iters: 200, epoch: 1 | loss: 31.0617199
	speed: 0.0625s/iter; left time: 1644.5021s
Epoch: 1 cost time: 17.3954656124115
Epoch: 1, Steps: 265 Train Loss: 32.4647 (Forecasting Loss:0.2107 + XiCon Loss:3.2254 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.148307).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.0611763
	speed: 0.1179s/iter; left time: 3081.9907s
	iters: 200, epoch: 2 | loss: 31.4357777
	speed: 0.0640s/iter; left time: 1666.8194s
Epoch: 2 cost time: 20.841634035110474
Epoch: 2, Steps: 265 Train Loss: 32.3701 (Forecasting Loss:0.1985 + XiCon Loss:3.2172 x Lambda(10.0)), Vali MSE Loss: 0.1466 Test MSE Loss: 0.0968
Validation loss decreased (0.148307 --> 0.146559).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.3489056
	speed: 0.0711s/iter; left time: 1840.0162s
	iters: 200, epoch: 3 | loss: 30.3248463
	speed: 0.0692s/iter; left time: 1783.3258s
Epoch: 3 cost time: 18.50419044494629
Epoch: 3, Steps: 265 Train Loss: 30.9610 (Forecasting Loss:0.1934 + XiCon Loss:3.0768 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0963
Validation loss decreased (0.146559 --> 0.144020).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.4307499
	speed: 0.0690s/iter; left time: 1767.3068s
	iters: 200, epoch: 4 | loss: 31.1271019
	speed: 0.0665s/iter; left time: 1696.9266s
Epoch: 4 cost time: 17.79897451400757
Epoch: 4, Steps: 265 Train Loss: 30.7546 (Forecasting Loss:0.1912 + XiCon Loss:3.0563 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0953
Validation loss decreased (0.144020 --> 0.142626).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7966862
	speed: 0.0669s/iter; left time: 1696.2096s
	iters: 200, epoch: 5 | loss: 30.0437527
	speed: 0.0650s/iter; left time: 1639.6932s
Epoch: 5 cost time: 17.55073571205139
Epoch: 5, Steps: 265 Train Loss: 30.7573 (Forecasting Loss:0.1899 + XiCon Loss:3.0567 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0950
Validation loss decreased (0.142626 --> 0.142325).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.1359367
	speed: 0.0670s/iter; left time: 1681.3318s
	iters: 200, epoch: 6 | loss: 30.3417110
	speed: 0.0657s/iter; left time: 1641.9824s
Epoch: 6 cost time: 17.413862466812134
Epoch: 6, Steps: 265 Train Loss: 30.6073 (Forecasting Loss:0.1892 + XiCon Loss:3.0418 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0950
Validation loss decreased (0.142325 --> 0.142085).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6143875
	speed: 0.0672s/iter; left time: 1667.0800s
	iters: 200, epoch: 7 | loss: 30.1594982
	speed: 0.0638s/iter; left time: 1576.0020s
Epoch: 7 cost time: 17.32768177986145
Epoch: 7, Steps: 265 Train Loss: 30.6659 (Forecasting Loss:0.1892 + XiCon Loss:3.0477 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0948
Validation loss decreased (0.142085 --> 0.141783).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9603653
	speed: 0.0664s/iter; left time: 1631.0405s
	iters: 200, epoch: 8 | loss: 31.0631027
	speed: 0.0647s/iter; left time: 1582.6765s
Epoch: 8 cost time: 17.370257139205933
Epoch: 8, Steps: 265 Train Loss: 30.6246 (Forecasting Loss:0.1889 + XiCon Loss:3.0436 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3215828
	speed: 0.0766s/iter; left time: 1860.0120s
	iters: 200, epoch: 9 | loss: 29.9613400
	speed: 0.0720s/iter; left time: 1740.6920s
Epoch: 9 cost time: 19.41575860977173
Epoch: 9, Steps: 265 Train Loss: 30.5845 (Forecasting Loss:0.1888 + XiCon Loss:3.0396 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4461555
	speed: 0.0758s/iter; left time: 1820.2144s
	iters: 200, epoch: 10 | loss: 29.9965401
	speed: 0.0657s/iter; left time: 1572.0256s
Epoch: 10 cost time: 18.534768104553223
Epoch: 10, Steps: 265 Train Loss: 30.5707 (Forecasting Loss:0.1887 + XiCon Loss:3.0382 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3389225
	speed: 0.0693s/iter; left time: 1646.5947s
	iters: 200, epoch: 11 | loss: 30.1407986
	speed: 0.0636s/iter; left time: 1503.0984s
Epoch: 11 cost time: 17.62783718109131
Epoch: 11, Steps: 265 Train Loss: 30.6557 (Forecasting Loss:0.1886 + XiCon Loss:3.0467 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6415424
	speed: 0.0692s/iter; left time: 1625.2284s
	iters: 200, epoch: 12 | loss: 30.2685928
	speed: 0.0669s/iter; left time: 1564.1479s
Epoch: 12 cost time: 17.86247706413269
Epoch: 12, Steps: 265 Train Loss: 30.6023 (Forecasting Loss:0.1887 + XiCon Loss:3.0414 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
Validation loss decreased (0.141783 --> 0.141748).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4673500
	speed: 0.0697s/iter; left time: 1619.4794s
	iters: 200, epoch: 13 | loss: 30.6774673
	speed: 0.0661s/iter; left time: 1529.2422s
Epoch: 13 cost time: 18.010823726654053
Epoch: 13, Steps: 265 Train Loss: 30.5857 (Forecasting Loss:0.1887 + XiCon Loss:3.0397 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2271099
	speed: 0.0715s/iter; left time: 1640.7949s
	iters: 200, epoch: 14 | loss: 29.9398289
	speed: 0.0655s/iter; left time: 1497.5102s
Epoch: 14 cost time: 17.96204423904419
Epoch: 14, Steps: 265 Train Loss: 30.5394 (Forecasting Loss:0.1887 + XiCon Loss:3.0351 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.3314648
	speed: 0.0675s/iter; left time: 1530.5268s
	iters: 200, epoch: 15 | loss: 31.3080616
	speed: 0.0653s/iter; left time: 1475.8959s
Epoch: 15 cost time: 17.34292197227478
Epoch: 15, Steps: 265 Train Loss: 30.6596 (Forecasting Loss:0.1886 + XiCon Loss:3.0471 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
Validation loss decreased (0.141748 --> 0.141737).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.9983768
	speed: 0.0677s/iter; left time: 1518.8005s
	iters: 200, epoch: 16 | loss: 30.2106609
	speed: 0.0651s/iter; left time: 1452.5456s
Epoch: 16 cost time: 17.866569995880127
Epoch: 16, Steps: 265 Train Loss: 30.6357 (Forecasting Loss:0.1887 + XiCon Loss:3.0447 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
Validation loss decreased (0.141737 --> 0.141688).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.2051086
	speed: 0.0681s/iter; left time: 1509.3192s
	iters: 200, epoch: 17 | loss: 30.5521469
	speed: 0.0668s/iter; left time: 1473.3898s
Epoch: 17 cost time: 17.902427911758423
Epoch: 17, Steps: 265 Train Loss: 30.5783 (Forecasting Loss:0.1888 + XiCon Loss:3.0390 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.1112099
	speed: 0.0758s/iter; left time: 1660.7661s
	iters: 200, epoch: 18 | loss: 30.4422646
	speed: 0.0715s/iter; left time: 1557.4967s
Epoch: 18 cost time: 19.33639168739319
Epoch: 18, Steps: 265 Train Loss: 30.6258 (Forecasting Loss:0.1886 + XiCon Loss:3.0437 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.9539986
	speed: 0.0673s/iter; left time: 1455.0289s
	iters: 200, epoch: 19 | loss: 31.8259411
	speed: 0.0658s/iter; left time: 1416.1819s
Epoch: 19 cost time: 17.52591824531555
Epoch: 19, Steps: 265 Train Loss: 30.6287 (Forecasting Loss:0.1887 + XiCon Loss:3.0440 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.7187710
	speed: 0.0654s/iter; left time: 1397.8495s
	iters: 200, epoch: 20 | loss: 30.9172459
	speed: 0.0645s/iter; left time: 1372.5865s
Epoch: 20 cost time: 17.27663564682007
Epoch: 20, Steps: 265 Train Loss: 30.6247 (Forecasting Loss:0.1888 + XiCon Loss:3.0436 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.6324730
	speed: 0.0689s/iter; left time: 1453.8567s
	iters: 200, epoch: 21 | loss: 30.2372952
	speed: 0.0634s/iter; left time: 1331.5626s
Epoch: 21 cost time: 17.44684863090515
Epoch: 21, Steps: 265 Train Loss: 30.5748 (Forecasting Loss:0.1886 + XiCon Loss:3.0386 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.3992138
	speed: 0.0679s/iter; left time: 1415.4907s
	iters: 200, epoch: 22 | loss: 30.2889671
	speed: 0.0660s/iter; left time: 1367.8124s
Epoch: 22 cost time: 17.894801378250122
Epoch: 22, Steps: 265 Train Loss: 30.5797 (Forecasting Loss:0.1886 + XiCon Loss:3.0391 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.9884624
	speed: 0.0673s/iter; left time: 1384.7417s
	iters: 200, epoch: 23 | loss: 30.1417370
	speed: 0.0654s/iter; left time: 1339.4105s
Epoch: 23 cost time: 17.37528419494629
Epoch: 23, Steps: 265 Train Loss: 30.6376 (Forecasting Loss:0.1888 + XiCon Loss:3.0449 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.6494350
	speed: 0.0684s/iter; left time: 1389.9256s
	iters: 200, epoch: 24 | loss: 30.9356213
	speed: 0.0627s/iter; left time: 1267.2036s
Epoch: 24 cost time: 17.38323950767517
Epoch: 24, Steps: 265 Train Loss: 30.6152 (Forecasting Loss:0.1888 + XiCon Loss:3.0426 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.6542511
	speed: 0.0691s/iter; left time: 1385.6282s
	iters: 200, epoch: 25 | loss: 31.1747704
	speed: 0.0677s/iter; left time: 1350.7433s
Epoch: 25 cost time: 18.129936695098877
Epoch: 25, Steps: 265 Train Loss: 30.6305 (Forecasting Loss:0.1888 + XiCon Loss:3.0442 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.2441559
	speed: 0.0682s/iter; left time: 1348.7581s
	iters: 200, epoch: 26 | loss: 30.2084351
	speed: 0.0646s/iter; left time: 1271.2834s
Epoch: 26 cost time: 17.499613523483276
Epoch: 26, Steps: 265 Train Loss: 30.5865 (Forecasting Loss:0.1887 + XiCon Loss:3.0398 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03955517336726189, mae:0.14992551505565643, mape:0.11906332522630692, mspe:0.02647729031741619 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.4326
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.6181450
	speed: 0.0497s/iter; left time: 1310.8800s
	iters: 200, epoch: 1 | loss: 31.7292118
	speed: 0.0620s/iter; left time: 1631.5156s
Epoch: 1 cost time: 15.351752519607544
Epoch: 1, Steps: 265 Train Loss: 32.3783 (Forecasting Loss:0.2108 + XiCon Loss:3.2168 x Lambda(10.0)), Vali MSE Loss: 0.1488 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.148795).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.0457726
	speed: 0.0673s/iter; left time: 1759.0280s
	iters: 200, epoch: 2 | loss: 31.5731564
	speed: 0.0602s/iter; left time: 1568.3485s
Epoch: 2 cost time: 17.19778060913086
Epoch: 2, Steps: 265 Train Loss: 32.7603 (Forecasting Loss:0.1981 + XiCon Loss:3.2562 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0964
Validation loss decreased (0.148795 --> 0.145692).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7233391
	speed: 0.0677s/iter; left time: 1752.4090s
	iters: 200, epoch: 3 | loss: 30.6722450
	speed: 0.0620s/iter; left time: 1598.8158s
Epoch: 3 cost time: 16.850704431533813
Epoch: 3, Steps: 265 Train Loss: 31.5096 (Forecasting Loss:0.1935 + XiCon Loss:3.1316 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0957
Validation loss decreased (0.145692 --> 0.143616).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2006130
	speed: 0.0711s/iter; left time: 1820.4498s
	iters: 200, epoch: 4 | loss: 30.1603699
	speed: 0.0666s/iter; left time: 1699.1935s
Epoch: 4 cost time: 18.04469060897827
Epoch: 4, Steps: 265 Train Loss: 31.1454 (Forecasting Loss:0.1913 + XiCon Loss:3.0954 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0952
Validation loss decreased (0.143616 --> 0.142307).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.4369965
	speed: 0.0663s/iter; left time: 1680.1834s
	iters: 200, epoch: 5 | loss: 30.3451633
	speed: 0.0670s/iter; left time: 1692.2178s
Epoch: 5 cost time: 17.4714412689209
Epoch: 5, Steps: 265 Train Loss: 30.9845 (Forecasting Loss:0.1902 + XiCon Loss:3.0794 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0945
Validation loss decreased (0.142307 --> 0.141956).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9217987
	speed: 0.0629s/iter; left time: 1576.5800s
	iters: 200, epoch: 6 | loss: 31.2258492
	speed: 0.0630s/iter; left time: 1573.7239s
Epoch: 6 cost time: 16.754500150680542
Epoch: 6, Steps: 265 Train Loss: 30.9708 (Forecasting Loss:0.1898 + XiCon Loss:3.0781 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141956 --> 0.141749).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0683079
	speed: 0.0705s/iter; left time: 1748.5494s
	iters: 200, epoch: 7 | loss: 30.1399288
	speed: 0.0638s/iter; left time: 1575.4638s
Epoch: 7 cost time: 17.826378107070923
Epoch: 7, Steps: 265 Train Loss: 30.9087 (Forecasting Loss:0.1894 + XiCon Loss:3.0719 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141749 --> 0.141654).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.2279091
	speed: 0.0641s/iter; left time: 1573.1047s
	iters: 200, epoch: 8 | loss: 31.2102680
	speed: 0.0646s/iter; left time: 1578.1435s
Epoch: 8 cost time: 16.987799167633057
Epoch: 8, Steps: 265 Train Loss: 30.9197 (Forecasting Loss:0.1892 + XiCon Loss:3.0730 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.3905239
	speed: 0.0683s/iter; left time: 1657.2904s
	iters: 200, epoch: 9 | loss: 30.8664970
	speed: 0.0693s/iter; left time: 1675.6539s
Epoch: 9 cost time: 18.16839623451233
Epoch: 9, Steps: 265 Train Loss: 30.9392 (Forecasting Loss:0.1892 + XiCon Loss:3.0750 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1978760
	speed: 0.0729s/iter; left time: 1750.3337s
	iters: 200, epoch: 10 | loss: 31.8166313
	speed: 0.0654s/iter; left time: 1564.4513s
Epoch: 10 cost time: 17.869617462158203
Epoch: 10, Steps: 265 Train Loss: 30.8637 (Forecasting Loss:0.1892 + XiCon Loss:3.0675 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5460243
	speed: 0.0667s/iter; left time: 1584.9449s
	iters: 200, epoch: 11 | loss: 30.7848663
	speed: 0.0660s/iter; left time: 1560.9273s
Epoch: 11 cost time: 17.559749364852905
Epoch: 11, Steps: 265 Train Loss: 30.8860 (Forecasting Loss:0.1891 + XiCon Loss:3.0697 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.2536774
	speed: 0.0649s/iter; left time: 1523.7384s
	iters: 200, epoch: 12 | loss: 31.4767780
	speed: 0.0621s/iter; left time: 1453.0465s
Epoch: 12 cost time: 16.710923671722412
Epoch: 12, Steps: 265 Train Loss: 30.9264 (Forecasting Loss:0.1891 + XiCon Loss:3.0737 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.2833366
	speed: 0.0679s/iter; left time: 1576.5952s
	iters: 200, epoch: 13 | loss: 30.4913902
	speed: 0.0645s/iter; left time: 1491.6627s
Epoch: 13 cost time: 17.563333749771118
Epoch: 13, Steps: 265 Train Loss: 30.8608 (Forecasting Loss:0.1891 + XiCon Loss:3.0672 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.0982227
	speed: 0.0673s/iter; left time: 1544.7526s
	iters: 200, epoch: 14 | loss: 31.4738674
	speed: 0.0637s/iter; left time: 1454.9979s
Epoch: 14 cost time: 17.722533464431763
Epoch: 14, Steps: 265 Train Loss: 30.9452 (Forecasting Loss:0.1891 + XiCon Loss:3.0756 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.3725700
	speed: 0.0669s/iter; left time: 1518.4449s
	iters: 200, epoch: 15 | loss: 30.6839447
	speed: 0.0663s/iter; left time: 1496.8642s
Epoch: 15 cost time: 17.62032437324524
Epoch: 15, Steps: 265 Train Loss: 30.9302 (Forecasting Loss:0.1890 + XiCon Loss:3.0741 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141654 --> 0.141601).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.8531990
	speed: 0.0654s/iter; left time: 1465.8654s
	iters: 200, epoch: 16 | loss: 30.4097347
	speed: 0.0654s/iter; left time: 1459.0740s
Epoch: 16 cost time: 17.177985668182373
Epoch: 16, Steps: 265 Train Loss: 30.8783 (Forecasting Loss:0.1891 + XiCon Loss:3.0689 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
Validation loss decreased (0.141601 --> 0.141594).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.0253048
	speed: 0.0675s/iter; left time: 1496.4542s
	iters: 200, epoch: 17 | loss: 31.4993649
	speed: 0.0665s/iter; left time: 1467.9898s
Epoch: 17 cost time: 17.47115421295166
Epoch: 17, Steps: 265 Train Loss: 30.9585 (Forecasting Loss:0.1891 + XiCon Loss:3.0769 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.3200817
	speed: 0.0670s/iter; left time: 1466.8594s
	iters: 200, epoch: 18 | loss: 31.8330269
	speed: 0.0659s/iter; left time: 1435.5904s
Epoch: 18 cost time: 17.6642587184906
Epoch: 18, Steps: 265 Train Loss: 30.8659 (Forecasting Loss:0.1891 + XiCon Loss:3.0677 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.8174343
	speed: 0.0750s/iter; left time: 1622.1028s
	iters: 200, epoch: 19 | loss: 30.3570080
	speed: 0.0658s/iter; left time: 1417.0434s
Epoch: 19 cost time: 18.41810154914856
Epoch: 19, Steps: 265 Train Loss: 30.9078 (Forecasting Loss:0.1891 + XiCon Loss:3.0719 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0945
Validation loss decreased (0.141594 --> 0.141529).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5367985
	speed: 0.0647s/iter; left time: 1381.4893s
	iters: 200, epoch: 20 | loss: 30.3715744
	speed: 0.1123s/iter; left time: 2388.6918s
Epoch: 20 cost time: 24.08686137199402
Epoch: 20, Steps: 265 Train Loss: 30.8973 (Forecasting Loss:0.1891 + XiCon Loss:3.0708 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.9915714
	speed: 0.0632s/iter; left time: 1334.1344s
	iters: 200, epoch: 21 | loss: 31.4730911
	speed: 0.0645s/iter; left time: 1354.6694s
Epoch: 21 cost time: 16.866862773895264
Epoch: 21, Steps: 265 Train Loss: 30.8991 (Forecasting Loss:0.1891 + XiCon Loss:3.0710 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.4097385
	speed: 0.0679s/iter; left time: 1414.7593s
	iters: 200, epoch: 22 | loss: 31.5146351
	speed: 0.0616s/iter; left time: 1276.3336s
Epoch: 22 cost time: 16.990825414657593
Epoch: 22, Steps: 265 Train Loss: 30.8859 (Forecasting Loss:0.1892 + XiCon Loss:3.0697 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.5264587
	speed: 0.0650s/iter; left time: 1337.3026s
	iters: 200, epoch: 23 | loss: 30.6160812
	speed: 0.0644s/iter; left time: 1318.5143s
Epoch: 23 cost time: 17.309601306915283
Epoch: 23, Steps: 265 Train Loss: 30.8636 (Forecasting Loss:0.1890 + XiCon Loss:3.0675 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.7064190
	speed: 0.0668s/iter; left time: 1356.6211s
	iters: 200, epoch: 24 | loss: 30.2720833
	speed: 0.0649s/iter; left time: 1310.9140s
Epoch: 24 cost time: 17.56723976135254
Epoch: 24, Steps: 265 Train Loss: 30.8942 (Forecasting Loss:0.1892 + XiCon Loss:3.0705 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.0883484
	speed: 0.0661s/iter; left time: 1324.3313s
	iters: 200, epoch: 25 | loss: 31.9397125
	speed: 0.0623s/iter; left time: 1242.0203s
Epoch: 25 cost time: 16.95874547958374
Epoch: 25, Steps: 265 Train Loss: 30.9234 (Forecasting Loss:0.1891 + XiCon Loss:3.0734 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.4040813
	speed: 0.0687s/iter; left time: 1358.7987s
	iters: 200, epoch: 26 | loss: 30.6067047
	speed: 0.0613s/iter; left time: 1205.4486s
Epoch: 26 cost time: 17.3341121673584
Epoch: 26, Steps: 265 Train Loss: 30.8833 (Forecasting Loss:0.1890 + XiCon Loss:3.0694 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.7165241
	speed: 0.0668s/iter; left time: 1303.8496s
	iters: 200, epoch: 27 | loss: 30.2173271
	speed: 0.0646s/iter; left time: 1253.4110s
Epoch: 27 cost time: 17.178137063980103
Epoch: 27, Steps: 265 Train Loss: 30.8717 (Forecasting Loss:0.1890 + XiCon Loss:3.0683 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 31.0780811
	speed: 0.0658s/iter; left time: 1267.2730s
	iters: 200, epoch: 28 | loss: 32.1737099
	speed: 0.0633s/iter; left time: 1212.5668s
Epoch: 28 cost time: 17.42183256149292
Epoch: 28, Steps: 265 Train Loss: 30.9395 (Forecasting Loss:0.1890 + XiCon Loss:3.0750 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 31.0128441
	speed: 0.0841s/iter; left time: 1596.3706s
	iters: 200, epoch: 29 | loss: 30.4734249
	speed: 0.1091s/iter; left time: 2060.5388s
Epoch: 29 cost time: 23.67831587791443
Epoch: 29, Steps: 265 Train Loss: 30.9339 (Forecasting Loss:0.1889 + XiCon Loss:3.0745 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0945
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039420001208782196, mae:0.1496499925851822, mape:0.1187230721116066, mspe:0.026337239891290665 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0399+-0.00085, MAE:0.1502+-0.00099, MAPE:0.1194+-0.00101, MSPE:0.0268+-0.00080, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.1329
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3459423
	speed: 0.1071s/iter; left time: 2730.9538s
	iters: 200, epoch: 1 | loss: 0.3113701
	speed: 0.1072s/iter; left time: 2722.5336s
Epoch: 1 cost time: 27.570452451705933
Epoch: 1, Steps: 256 Train Loss: 0.3314 (Forecasting Loss:0.2981 + XiCon Loss:3.3309 x Lambda(0.01)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1593
Validation loss decreased (inf --> 0.209139).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2921340
	speed: 0.1464s/iter; left time: 3696.5944s
	iters: 200, epoch: 2 | loss: 0.2564441
	speed: 0.1550s/iter; left time: 3897.2583s
Epoch: 2 cost time: 39.53578448295593
Epoch: 2, Steps: 256 Train Loss: 0.2801 (Forecasting Loss:0.2473 + XiCon Loss:3.2740 x Lambda(0.01)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1845
Validation loss decreased (0.209139 --> 0.208801).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2295091
	speed: 0.1638s/iter; left time: 4093.2972s
	iters: 200, epoch: 3 | loss: 0.2226725
	speed: 0.1538s/iter; left time: 3826.9291s
Epoch: 3 cost time: 40.60837364196777
Epoch: 3, Steps: 256 Train Loss: 0.2269 (Forecasting Loss:0.1948 + XiCon Loss:3.2125 x Lambda(0.01)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1746
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2145057
	speed: 0.1552s/iter; left time: 3839.0095s
	iters: 200, epoch: 4 | loss: 0.1992611
	speed: 0.1612s/iter; left time: 3971.7159s
Epoch: 4 cost time: 41.093590259552
Epoch: 4, Steps: 256 Train Loss: 0.2070 (Forecasting Loss:0.1748 + XiCon Loss:3.2161 x Lambda(0.01)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.1879
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1919725
	speed: 0.1517s/iter; left time: 3714.3427s
	iters: 200, epoch: 5 | loss: 0.1930076
	speed: 0.1591s/iter; left time: 3879.0303s
Epoch: 5 cost time: 39.76186394691467
Epoch: 5, Steps: 256 Train Loss: 0.1963 (Forecasting Loss:0.1639 + XiCon Loss:3.2342 x Lambda(0.01)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.1862
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1963417
	speed: 0.1567s/iter; left time: 3794.6862s
	iters: 200, epoch: 6 | loss: 0.1906541
	speed: 0.1487s/iter; left time: 3586.4694s
Epoch: 6 cost time: 38.960283517837524
Epoch: 6, Steps: 256 Train Loss: 0.1907 (Forecasting Loss:0.1582 + XiCon Loss:3.2506 x Lambda(0.01)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.1879
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1884318
	speed: 0.1551s/iter; left time: 3718.1650s
	iters: 200, epoch: 7 | loss: 0.1867853
	speed: 0.1505s/iter; left time: 3590.5640s
Epoch: 7 cost time: 38.790607213974
Epoch: 7, Steps: 256 Train Loss: 0.1878 (Forecasting Loss:0.1552 + XiCon Loss:3.2598 x Lambda(0.01)), Vali MSE Loss: 0.2314 Test MSE Loss: 0.1906
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1956066
	speed: 0.1509s/iter; left time: 3577.1767s
	iters: 200, epoch: 8 | loss: 0.1886854
	speed: 0.1672s/iter; left time: 3947.7092s
Epoch: 8 cost time: 41.18058490753174
Epoch: 8, Steps: 256 Train Loss: 0.1863 (Forecasting Loss:0.1537 + XiCon Loss:3.2618 x Lambda(0.01)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1902
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1883396
	speed: 0.1520s/iter; left time: 3564.1424s
	iters: 200, epoch: 9 | loss: 0.1790087
	speed: 0.1519s/iter; left time: 3548.3853s
Epoch: 9 cost time: 39.6690731048584
Epoch: 9, Steps: 256 Train Loss: 0.1856 (Forecasting Loss:0.1530 + XiCon Loss:3.2630 x Lambda(0.01)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.1905
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1826046
	speed: 0.1507s/iter; left time: 3494.9713s
	iters: 200, epoch: 10 | loss: 0.1866978
	speed: 0.1572s/iter; left time: 3631.7285s
Epoch: 10 cost time: 39.62128257751465
Epoch: 10, Steps: 256 Train Loss: 0.1852 (Forecasting Loss:0.1526 + XiCon Loss:3.2644 x Lambda(0.01)), Vali MSE Loss: 0.2326 Test MSE Loss: 0.1909
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1873910
	speed: 0.1559s/iter; left time: 3575.6049s
	iters: 200, epoch: 11 | loss: 0.1810589
	speed: 0.1583s/iter; left time: 3615.2380s
Epoch: 11 cost time: 40.55902051925659
Epoch: 11, Steps: 256 Train Loss: 0.1851 (Forecasting Loss:0.1525 + XiCon Loss:3.2655 x Lambda(0.01)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1907
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1822203
	speed: 0.1621s/iter; left time: 3677.4480s
	iters: 200, epoch: 12 | loss: 0.1880683
	speed: 0.1587s/iter; left time: 3584.9806s
Epoch: 12 cost time: 40.878265619277954
Epoch: 12, Steps: 256 Train Loss: 0.1849 (Forecasting Loss:0.1523 + XiCon Loss:3.2640 x Lambda(0.01)), Vali MSE Loss: 0.2325 Test MSE Loss: 0.1907
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.10855849087238312, mae:0.2605205476284027, mape:0.19762340188026428, mspe:0.0640641301870346 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.5679
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3389515
	speed: 0.1121s/iter; left time: 2857.8900s
	iters: 200, epoch: 1 | loss: 0.2961674
	speed: 0.1079s/iter; left time: 2741.2126s
Epoch: 1 cost time: 28.002405166625977
Epoch: 1, Steps: 256 Train Loss: 0.3293 (Forecasting Loss:0.2963 + XiCon Loss:3.2962 x Lambda(0.01)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1546
Validation loss decreased (inf --> 0.203244).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2634857
	speed: 0.1476s/iter; left time: 3726.1333s
	iters: 200, epoch: 2 | loss: 0.2396104
	speed: 0.1661s/iter; left time: 4175.8350s
Epoch: 2 cost time: 40.87089395523071
Epoch: 2, Steps: 256 Train Loss: 0.2691 (Forecasting Loss:0.2367 + XiCon Loss:3.2443 x Lambda(0.01)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1813
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2238032
	speed: 0.1296s/iter; left time: 3239.2049s
	iters: 200, epoch: 3 | loss: 0.2083875
	speed: 0.1655s/iter; left time: 4118.0853s
Epoch: 3 cost time: 38.338621616363525
Epoch: 3, Steps: 256 Train Loss: 0.2214 (Forecasting Loss:0.1899 + XiCon Loss:3.1471 x Lambda(0.01)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1851
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1975624
	speed: 0.1538s/iter; left time: 3804.4003s
	iters: 200, epoch: 4 | loss: 0.1851557
	speed: 0.1639s/iter; left time: 4037.3485s
Epoch: 4 cost time: 40.90706157684326
Epoch: 4, Steps: 256 Train Loss: 0.1985 (Forecasting Loss:0.1674 + XiCon Loss:3.1110 x Lambda(0.01)), Vali MSE Loss: 0.2377 Test MSE Loss: 0.1947
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1849573
	speed: 0.1610s/iter; left time: 3940.3752s
	iters: 200, epoch: 5 | loss: 0.1829276
	speed: 0.1608s/iter; left time: 3920.8230s
Epoch: 5 cost time: 41.01762795448303
Epoch: 5, Steps: 256 Train Loss: 0.1863 (Forecasting Loss:0.1553 + XiCon Loss:3.0937 x Lambda(0.01)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.2021
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1843105
	speed: 0.1570s/iter; left time: 3803.0745s
	iters: 200, epoch: 6 | loss: 0.1748759
	speed: 0.1525s/iter; left time: 3678.0720s
Epoch: 6 cost time: 40.834233045578
Epoch: 6, Steps: 256 Train Loss: 0.1804 (Forecasting Loss:0.1495 + XiCon Loss:3.0879 x Lambda(0.01)), Vali MSE Loss: 0.2446 Test MSE Loss: 0.2065
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1746852
	speed: 0.1624s/iter; left time: 3891.7168s
	iters: 200, epoch: 7 | loss: 0.1738883
	speed: 0.1605s/iter; left time: 3829.2872s
Epoch: 7 cost time: 41.24302291870117
Epoch: 7, Steps: 256 Train Loss: 0.1775 (Forecasting Loss:0.1466 + XiCon Loss:3.0878 x Lambda(0.01)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.2083
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1805159
	speed: 0.1584s/iter; left time: 3754.7659s
	iters: 200, epoch: 8 | loss: 0.1772081
	speed: 0.1572s/iter; left time: 3710.7557s
Epoch: 8 cost time: 40.3122878074646
Epoch: 8, Steps: 256 Train Loss: 0.1760 (Forecasting Loss:0.1452 + XiCon Loss:3.0858 x Lambda(0.01)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.2103
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1788678
	speed: 0.1626s/iter; left time: 3812.3164s
	iters: 200, epoch: 9 | loss: 0.1750811
	speed: 0.1569s/iter; left time: 3664.1023s
Epoch: 9 cost time: 41.042540073394775
Epoch: 9, Steps: 256 Train Loss: 0.1753 (Forecasting Loss:0.1445 + XiCon Loss:3.0841 x Lambda(0.01)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2108
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1831823
	speed: 0.1579s/iter; left time: 3662.0658s
	iters: 200, epoch: 10 | loss: 0.1761026
	speed: 0.1672s/iter; left time: 3860.6930s
Epoch: 10 cost time: 41.277838468551636
Epoch: 10, Steps: 256 Train Loss: 0.1749 (Forecasting Loss:0.1440 + XiCon Loss:3.0818 x Lambda(0.01)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2114
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1823451
	speed: 0.1626s/iter; left time: 3729.8290s
	iters: 200, epoch: 11 | loss: 0.1697912
	speed: 0.1574s/iter; left time: 3595.9691s
Epoch: 11 cost time: 41.351308822631836
Epoch: 11, Steps: 256 Train Loss: 0.1747 (Forecasting Loss:0.1438 + XiCon Loss:3.0833 x Lambda(0.01)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2111
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08389682322740555, mae:0.22540029883384705, mape:0.16960375010967255, mspe:0.04782339930534363 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.1205
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3085074
	speed: 0.1078s/iter; left time: 2748.7499s
	iters: 200, epoch: 1 | loss: 0.3234722
	speed: 0.1029s/iter; left time: 2614.9165s
Epoch: 1 cost time: 26.929753065109253
Epoch: 1, Steps: 256 Train Loss: 0.3249 (Forecasting Loss:0.2915 + XiCon Loss:3.3408 x Lambda(0.01)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.1540
Validation loss decreased (inf --> 0.202212).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3250523
	speed: 0.1543s/iter; left time: 3894.5855s
	iters: 200, epoch: 2 | loss: 0.3024371
	speed: 0.1625s/iter; left time: 4086.8055s
Epoch: 2 cost time: 41.209664821624756
Epoch: 2, Steps: 256 Train Loss: 0.3182 (Forecasting Loss:0.2855 + XiCon Loss:3.2783 x Lambda(0.01)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1645
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2502568
	speed: 0.1585s/iter; left time: 3960.8354s
	iters: 200, epoch: 3 | loss: 0.2439003
	speed: 0.1642s/iter; left time: 4087.1037s
Epoch: 3 cost time: 41.400306940078735
Epoch: 3, Steps: 256 Train Loss: 0.2492 (Forecasting Loss:0.2172 + XiCon Loss:3.1974 x Lambda(0.01)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.1777
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2169245
	speed: 0.1526s/iter; left time: 3774.6810s
	iters: 200, epoch: 4 | loss: 0.2276582
	speed: 0.1387s/iter; left time: 3417.6965s
Epoch: 4 cost time: 39.87144660949707
Epoch: 4, Steps: 256 Train Loss: 0.2231 (Forecasting Loss:0.1912 + XiCon Loss:3.1957 x Lambda(0.01)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1782
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2181606
	speed: 0.1371s/iter; left time: 3355.2835s
	iters: 200, epoch: 5 | loss: 0.2066899
	speed: 0.1574s/iter; left time: 3836.7116s
Epoch: 5 cost time: 38.36120319366455
Epoch: 5, Steps: 256 Train Loss: 0.2134 (Forecasting Loss:0.1814 + XiCon Loss:3.1975 x Lambda(0.01)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1809
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2107635
	speed: 0.1647s/iter; left time: 3988.5598s
	iters: 200, epoch: 6 | loss: 0.2105557
	speed: 0.1639s/iter; left time: 3952.7521s
Epoch: 6 cost time: 40.85655736923218
Epoch: 6, Steps: 256 Train Loss: 0.2078 (Forecasting Loss:0.1758 + XiCon Loss:3.1987 x Lambda(0.01)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1828
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2088254
	speed: 0.1625s/iter; left time: 3894.7691s
	iters: 200, epoch: 7 | loss: 0.2101403
	speed: 0.1573s/iter; left time: 3753.0079s
Epoch: 7 cost time: 40.071674823760986
Epoch: 7, Steps: 256 Train Loss: 0.2052 (Forecasting Loss:0.1732 + XiCon Loss:3.2016 x Lambda(0.01)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1834
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2031013
	speed: 0.1572s/iter; left time: 3727.7890s
	iters: 200, epoch: 8 | loss: 0.2012776
	speed: 0.1425s/iter; left time: 3364.1365s
Epoch: 8 cost time: 39.49785614013672
Epoch: 8, Steps: 256 Train Loss: 0.2036 (Forecasting Loss:0.1716 + XiCon Loss:3.2025 x Lambda(0.01)), Vali MSE Loss: 0.2243 Test MSE Loss: 0.1843
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2015817
	speed: 0.1575s/iter; left time: 3692.9338s
	iters: 200, epoch: 9 | loss: 0.1969929
	speed: 0.1616s/iter; left time: 3774.1793s
Epoch: 9 cost time: 41.20732140541077
Epoch: 9, Steps: 256 Train Loss: 0.2028 (Forecasting Loss:0.1708 + XiCon Loss:3.2037 x Lambda(0.01)), Vali MSE Loss: 0.2241 Test MSE Loss: 0.1834
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2013042
	speed: 0.1608s/iter; left time: 3730.5306s
	iters: 200, epoch: 10 | loss: 0.2040490
	speed: 0.1583s/iter; left time: 3656.1606s
Epoch: 10 cost time: 40.82372975349426
Epoch: 10, Steps: 256 Train Loss: 0.2024 (Forecasting Loss:0.1703 + XiCon Loss:3.2036 x Lambda(0.01)), Vali MSE Loss: 0.2243 Test MSE Loss: 0.1844
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2055032
	speed: 0.1553s/iter; left time: 3561.6346s
	iters: 200, epoch: 11 | loss: 0.2017608
	speed: 0.1523s/iter; left time: 3478.1482s
Epoch: 11 cost time: 40.187684297561646
Epoch: 11, Steps: 256 Train Loss: 0.2023 (Forecasting Loss:0.1703 + XiCon Loss:3.2036 x Lambda(0.01)), Vali MSE Loss: 0.2244 Test MSE Loss: 0.1840
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.0842694491147995, mae:0.22370781004428864, mape:0.16541987657546997, mspe:0.044682107865810394 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.4122
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3185247
	speed: 0.1139s/iter; left time: 2905.4064s
	iters: 200, epoch: 1 | loss: 0.3186522
	speed: 0.1085s/iter; left time: 2756.8581s
Epoch: 1 cost time: 28.674802780151367
Epoch: 1, Steps: 256 Train Loss: 0.3315 (Forecasting Loss:0.2986 + XiCon Loss:3.2916 x Lambda(0.01)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1582
Validation loss decreased (inf --> 0.207086).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3339179
	speed: 0.1359s/iter; left time: 3432.0457s
	iters: 200, epoch: 2 | loss: 0.2750526
	speed: 0.1354s/iter; left time: 3404.8331s
Epoch: 2 cost time: 35.449298620224
Epoch: 2, Steps: 256 Train Loss: 0.3124 (Forecasting Loss:0.2785 + XiCon Loss:3.3954 x Lambda(0.01)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.1640
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2484996
	speed: 0.1534s/iter; left time: 3832.8612s
	iters: 200, epoch: 3 | loss: 0.2398252
	speed: 0.1421s/iter; left time: 3535.8111s
Epoch: 3 cost time: 38.76795530319214
Epoch: 3, Steps: 256 Train Loss: 0.2497 (Forecasting Loss:0.2172 + XiCon Loss:3.2444 x Lambda(0.01)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.1710
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2213348
	speed: 0.1470s/iter; left time: 3635.8054s
	iters: 200, epoch: 4 | loss: 0.2266333
	speed: 0.1538s/iter; left time: 3787.7827s
Epoch: 4 cost time: 38.33353567123413
Epoch: 4, Steps: 256 Train Loss: 0.2246 (Forecasting Loss:0.1925 + XiCon Loss:3.2031 x Lambda(0.01)), Vali MSE Loss: 0.2369 Test MSE Loss: 0.1836
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2190732
	speed: 0.1522s/iter; left time: 3725.7809s
	iters: 200, epoch: 5 | loss: 0.2096931
	speed: 0.1523s/iter; left time: 3713.5168s
Epoch: 5 cost time: 39.567662954330444
Epoch: 5, Steps: 256 Train Loss: 0.2132 (Forecasting Loss:0.1811 + XiCon Loss:3.2074 x Lambda(0.01)), Vali MSE Loss: 0.2294 Test MSE Loss: 0.1838
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1986482
	speed: 0.1595s/iter; left time: 3862.1622s
	iters: 200, epoch: 6 | loss: 0.2079310
	speed: 0.1438s/iter; left time: 3468.8883s
Epoch: 6 cost time: 38.56189775466919
Epoch: 6, Steps: 256 Train Loss: 0.2067 (Forecasting Loss:0.1745 + XiCon Loss:3.2155 x Lambda(0.01)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.1887
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2115935
	speed: 0.1555s/iter; left time: 3725.4522s
	iters: 200, epoch: 7 | loss: 0.1957403
	speed: 0.1561s/iter; left time: 3726.0730s
Epoch: 7 cost time: 39.44851303100586
Epoch: 7, Steps: 256 Train Loss: 0.2039 (Forecasting Loss:0.1717 + XiCon Loss:3.2225 x Lambda(0.01)), Vali MSE Loss: 0.2385 Test MSE Loss: 0.1909
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2069112
	speed: 0.1522s/iter; left time: 3609.1819s
	iters: 200, epoch: 8 | loss: 0.2013614
	speed: 0.1467s/iter; left time: 3463.2497s
Epoch: 8 cost time: 39.3918776512146
Epoch: 8, Steps: 256 Train Loss: 0.2023 (Forecasting Loss:0.1701 + XiCon Loss:3.2248 x Lambda(0.01)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.1928
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1974488
	speed: 0.1543s/iter; left time: 3619.6578s
	iters: 200, epoch: 9 | loss: 0.2072288
	speed: 0.1551s/iter; left time: 3622.9785s
Epoch: 9 cost time: 39.496214389801025
Epoch: 9, Steps: 256 Train Loss: 0.2016 (Forecasting Loss:0.1693 + XiCon Loss:3.2273 x Lambda(0.01)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.1931
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2029022
	speed: 0.1493s/iter; left time: 3462.5085s
	iters: 200, epoch: 10 | loss: 0.1970832
	speed: 0.1524s/iter; left time: 3520.4490s
Epoch: 10 cost time: 38.481252908706665
Epoch: 10, Steps: 256 Train Loss: 0.2013 (Forecasting Loss:0.1690 + XiCon Loss:3.2282 x Lambda(0.01)), Vali MSE Loss: 0.2422 Test MSE Loss: 0.1934
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2025648
	speed: 0.1577s/iter; left time: 3618.3092s
	iters: 200, epoch: 11 | loss: 0.2092039
	speed: 0.1506s/iter; left time: 3439.4531s
Epoch: 11 cost time: 39.18189072608948
Epoch: 11, Steps: 256 Train Loss: 0.2010 (Forecasting Loss:0.1688 + XiCon Loss:3.2267 x Lambda(0.01)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1936
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08670659363269806, mae:0.22975364327430725, mape:0.169317364692688, mspe:0.045532725751399994 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.8936
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.3284435
	speed: 0.1048s/iter; left time: 2673.5779s
	iters: 200, epoch: 1 | loss: 0.3179322
	speed: 0.1097s/iter; left time: 2786.2544s
Epoch: 1 cost time: 27.653417110443115
Epoch: 1, Steps: 256 Train Loss: 0.3290 (Forecasting Loss:0.2959 + XiCon Loss:3.3147 x Lambda(0.01)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1551
Validation loss decreased (inf --> 0.205273).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3696525
	speed: 0.1267s/iter; left time: 3199.7364s
	iters: 200, epoch: 2 | loss: 0.3206265
	speed: 0.1270s/iter; left time: 3192.8413s
Epoch: 2 cost time: 34.022650957107544
Epoch: 2, Steps: 256 Train Loss: 0.3405 (Forecasting Loss:0.3058 + XiCon Loss:3.4667 x Lambda(0.01)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1719
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.3402055
	speed: 0.1033s/iter; left time: 2581.6525s
	iters: 200, epoch: 3 | loss: 0.3379254
	speed: 0.1154s/iter; left time: 2873.3274s
Epoch: 3 cost time: 28.551032304763794
Epoch: 3, Steps: 256 Train Loss: 0.3349 (Forecasting Loss:0.3002 + XiCon Loss:3.4640 x Lambda(0.01)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1675
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.3114794
	speed: 0.1275s/iter; left time: 3154.4039s
	iters: 200, epoch: 4 | loss: 0.3223004
	speed: 0.1186s/iter; left time: 2920.7532s
Epoch: 4 cost time: 31.457550525665283
Epoch: 4, Steps: 256 Train Loss: 0.3285 (Forecasting Loss:0.2940 + XiCon Loss:3.4473 x Lambda(0.01)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1658
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.3247806
	speed: 0.1122s/iter; left time: 2746.1411s
	iters: 200, epoch: 5 | loss: 0.3146670
	speed: 0.1219s/iter; left time: 2970.4339s
Epoch: 5 cost time: 30.498752117156982
Epoch: 5, Steps: 256 Train Loss: 0.3187 (Forecasting Loss:0.2846 + XiCon Loss:3.4139 x Lambda(0.01)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.1604
Validation loss decreased (0.205273 --> 0.203753).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2805744
	speed: 0.1228s/iter; left time: 2973.3140s
	iters: 200, epoch: 6 | loss: 0.3128631
	speed: 0.1255s/iter; left time: 3027.2289s
Epoch: 6 cost time: 31.80767583847046
Epoch: 6, Steps: 256 Train Loss: 0.3069 (Forecasting Loss:0.2731 + XiCon Loss:3.3867 x Lambda(0.01)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1590
Validation loss decreased (0.203753 --> 0.198305).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.3022022
	speed: 0.1198s/iter; left time: 2871.9974s
	iters: 200, epoch: 7 | loss: 0.3187127
	speed: 0.1256s/iter; left time: 2998.3098s
Epoch: 7 cost time: 31.330278873443604
Epoch: 7, Steps: 256 Train Loss: 0.3022 (Forecasting Loss:0.2685 + XiCon Loss:3.3757 x Lambda(0.01)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1595
Validation loss decreased (0.198305 --> 0.195930).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.3163223
	speed: 0.1288s/iter; left time: 3054.6097s
	iters: 200, epoch: 8 | loss: 0.3068218
	speed: 0.1197s/iter; left time: 2826.5126s
Epoch: 8 cost time: 31.646952390670776
Epoch: 8, Steps: 256 Train Loss: 0.2996 (Forecasting Loss:0.2659 + XiCon Loss:3.3677 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.1595
Validation loss decreased (0.195930 --> 0.194743).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2954365
	speed: 0.1284s/iter; left time: 3012.2536s
	iters: 200, epoch: 9 | loss: 0.2980667
	speed: 0.1254s/iter; left time: 2927.3909s
Epoch: 9 cost time: 32.38461446762085
Epoch: 9, Steps: 256 Train Loss: 0.2985 (Forecasting Loss:0.2649 + XiCon Loss:3.3654 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.1593
Validation loss decreased (0.194743 --> 0.194474).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.3072328
	speed: 0.1308s/iter; left time: 3033.5512s
	iters: 200, epoch: 10 | loss: 0.2977188
	speed: 0.1250s/iter; left time: 2887.9637s
Epoch: 10 cost time: 32.50130748748779
Epoch: 10, Steps: 256 Train Loss: 0.2975 (Forecasting Loss:0.2639 + XiCon Loss:3.3642 x Lambda(0.01)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1592
Validation loss decreased (0.194474 --> 0.194164).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.3060153
	speed: 0.1281s/iter; left time: 2939.5848s
	iters: 200, epoch: 11 | loss: 0.3140150
	speed: 0.1195s/iter; left time: 2728.9800s
Epoch: 11 cost time: 31.867732286453247
Epoch: 11, Steps: 256 Train Loss: 0.2975 (Forecasting Loss:0.2638 + XiCon Loss:3.3630 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1591
Validation loss decreased (0.194164 --> 0.193940).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.3073319
	speed: 0.1250s/iter; left time: 2835.3568s
	iters: 200, epoch: 12 | loss: 0.2976678
	speed: 0.1236s/iter; left time: 2792.3851s
Epoch: 12 cost time: 31.534666538238525
Epoch: 12, Steps: 256 Train Loss: 0.2971 (Forecasting Loss:0.2635 + XiCon Loss:3.3625 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
Validation loss decreased (0.193940 --> 0.193812).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2926848
	speed: 0.1241s/iter; left time: 2784.0769s
	iters: 200, epoch: 13 | loss: 0.3005929
	speed: 0.1233s/iter; left time: 2752.1976s
Epoch: 13 cost time: 31.459975719451904
Epoch: 13, Steps: 256 Train Loss: 0.2972 (Forecasting Loss:0.2636 + XiCon Loss:3.3606 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1591
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.3020835
	speed: 0.1249s/iter; left time: 2769.4485s
	iters: 200, epoch: 14 | loss: 0.2997082
	speed: 0.1307s/iter; left time: 2884.5501s
Epoch: 14 cost time: 32.42396855354309
Epoch: 14, Steps: 256 Train Loss: 0.2971 (Forecasting Loss:0.2635 + XiCon Loss:3.3602 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
Validation loss decreased (0.193812 --> 0.193806).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2802579
	speed: 0.1261s/iter; left time: 2763.2177s
	iters: 200, epoch: 15 | loss: 0.2970130
	speed: 0.1227s/iter; left time: 2676.1600s
Epoch: 15 cost time: 31.990604639053345
Epoch: 15, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3599 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2910352
	speed: 0.1274s/iter; left time: 2760.5174s
	iters: 200, epoch: 16 | loss: 0.2987137
	speed: 0.1180s/iter; left time: 2545.2075s
Epoch: 16 cost time: 31.781131505966187
Epoch: 16, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2633 + XiCon Loss:3.3608 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.2946541
	speed: 0.1252s/iter; left time: 2679.6213s
	iters: 200, epoch: 17 | loss: 0.2931916
	speed: 0.1240s/iter; left time: 2642.4443s
Epoch: 17 cost time: 32.560845613479614
Epoch: 17, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2634 + XiCon Loss:3.3615 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.3009435
	speed: 0.1308s/iter; left time: 2766.1964s
	iters: 200, epoch: 18 | loss: 0.2839285
	speed: 0.1308s/iter; left time: 2753.0869s
Epoch: 18 cost time: 33.4485068321228
Epoch: 18, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2633 + XiCon Loss:3.3613 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1591
Validation loss decreased (0.193806 --> 0.193767).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 0.2975445
	speed: 0.1242s/iter; left time: 2594.2949s
	iters: 200, epoch: 19 | loss: 0.3010860
	speed: 0.1253s/iter; left time: 2604.7049s
Epoch: 19 cost time: 32.21888756752014
Epoch: 19, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3606 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 0.3226926
	speed: 0.1228s/iter; left time: 2533.9733s
	iters: 200, epoch: 20 | loss: 0.2800632
	speed: 0.1295s/iter; left time: 2659.6734s
Epoch: 20 cost time: 32.02545094490051
Epoch: 20, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2633 + XiCon Loss:3.3618 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 0.3091511
	speed: 0.1247s/iter; left time: 2542.0631s
	iters: 200, epoch: 21 | loss: 0.2968490
	speed: 0.1271s/iter; left time: 2577.4451s
Epoch: 21 cost time: 32.12256693840027
Epoch: 21, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3624 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 0.2951682
	speed: 0.1273s/iter; left time: 2562.7816s
	iters: 200, epoch: 22 | loss: 0.3165121
	speed: 0.1216s/iter; left time: 2435.2349s
Epoch: 22 cost time: 32.23755502700806
Epoch: 22, Steps: 256 Train Loss: 0.2968 (Forecasting Loss:0.2632 + XiCon Loss:3.3610 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 0.3067032
	speed: 0.1241s/iter; left time: 2466.4167s
	iters: 200, epoch: 23 | loss: 0.2962405
	speed: 0.1251s/iter; left time: 2472.9692s
Epoch: 23 cost time: 31.966015577316284
Epoch: 23, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3611 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 0.3065114
	speed: 0.1222s/iter; left time: 2395.9139s
	iters: 200, epoch: 24 | loss: 0.2892282
	speed: 0.1262s/iter; left time: 2462.6415s
Epoch: 24 cost time: 31.85497522354126
Epoch: 24, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2633 + XiCon Loss:3.3628 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.1592
Validation loss decreased (0.193767 --> 0.193736).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 0.2951972
	speed: 0.1242s/iter; left time: 2404.9880s
	iters: 200, epoch: 25 | loss: 0.2870182
	speed: 0.1235s/iter; left time: 2377.4206s
Epoch: 25 cost time: 31.54164981842041
Epoch: 25, Steps: 256 Train Loss: 0.2972 (Forecasting Loss:0.2636 + XiCon Loss:3.3608 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 0.3019899
	speed: 0.1297s/iter; left time: 2477.1452s
	iters: 200, epoch: 26 | loss: 0.2909514
	speed: 0.1203s/iter; left time: 2285.2124s
Epoch: 26 cost time: 32.15339255332947
Epoch: 26, Steps: 256 Train Loss: 0.2971 (Forecasting Loss:0.2634 + XiCon Loss:3.3606 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 0.3055438
	speed: 0.1336s/iter; left time: 2516.9979s
	iters: 200, epoch: 27 | loss: 0.2924817
	speed: 0.1209s/iter; left time: 2267.1692s
Epoch: 27 cost time: 32.33936619758606
Epoch: 27, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3622 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 0.2951296
	speed: 0.1337s/iter; left time: 2484.5890s
	iters: 200, epoch: 28 | loss: 0.2935420
	speed: 0.1171s/iter; left time: 2164.1623s
Epoch: 28 cost time: 32.070043087005615
Epoch: 28, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2634 + XiCon Loss:3.3610 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 0.2944500
	speed: 0.1328s/iter; left time: 2433.9246s
	iters: 200, epoch: 29 | loss: 0.3026902
	speed: 0.1197s/iter; left time: 2182.7155s
Epoch: 29 cost time: 32.05637884140015
Epoch: 29, Steps: 256 Train Loss: 0.2967 (Forecasting Loss:0.2631 + XiCon Loss:3.3622 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 0.2897293
	speed: 0.1248s/iter; left time: 2256.7456s
	iters: 200, epoch: 30 | loss: 0.2955253
	speed: 0.1231s/iter; left time: 2213.5463s
Epoch: 30 cost time: 32.163318157196045
Epoch: 30, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3611 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 0.3104835
	speed: 0.1277s/iter; left time: 2275.6322s
	iters: 200, epoch: 31 | loss: 0.2740186
	speed: 0.1261s/iter; left time: 2234.7843s
Epoch: 31 cost time: 32.047158002853394
Epoch: 31, Steps: 256 Train Loss: 0.2967 (Forecasting Loss:0.2631 + XiCon Loss:3.3609 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 0.2814685
	speed: 0.1264s/iter; left time: 2221.0276s
	iters: 200, epoch: 32 | loss: 0.2928753
	speed: 0.1193s/iter; left time: 2084.1096s
Epoch: 32 cost time: 31.320934772491455
Epoch: 32, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2634 + XiCon Loss:3.3617 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 0.3078496
	speed: 0.1260s/iter; left time: 2181.6077s
	iters: 200, epoch: 33 | loss: 0.2944573
	speed: 0.1183s/iter; left time: 2035.9285s
Epoch: 33 cost time: 31.190736770629883
Epoch: 33, Steps: 256 Train Loss: 0.2969 (Forecasting Loss:0.2633 + XiCon Loss:3.3621 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.1592
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 0.2823634
	speed: 0.1250s/iter; left time: 2132.1240s
	iters: 200, epoch: 34 | loss: 0.2918591
	speed: 0.1210s/iter; left time: 2051.8375s
Epoch: 34 cost time: 31.749674797058105
Epoch: 34, Steps: 256 Train Loss: 0.2970 (Forecasting Loss:0.2634 + XiCon Loss:3.3603 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1592
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08773714303970337, mae:0.23056508600711823, mape:0.17090091109275818, mspe:0.04707888141274452 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0902+-0.01288, MAE:0.2340+-0.01876, MAPE:0.1746+-0.01620, MSPE:0.0498+-0.00999, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.7511
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3433736
	speed: 0.1425s/iter; left time: 3463.5470s
	iters: 200, epoch: 1 | loss: 0.3182359
	speed: 0.1619s/iter; left time: 3918.5072s
Epoch: 1 cost time: 39.72724270820618
Epoch: 1, Steps: 244 Train Loss: 0.3526 (Forecasting Loss:0.3492 + XiCon Loss:3.4147 x Lambda(0.001)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1564
Validation loss decreased (inf --> 0.228275).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3119681
	speed: 0.2061s/iter; left time: 4959.2779s
	iters: 200, epoch: 2 | loss: 0.2802939
	speed: 0.2021s/iter; left time: 4842.2815s
Epoch: 2 cost time: 49.9177770614624
Epoch: 2, Steps: 244 Train Loss: 0.3055 (Forecasting Loss:0.3021 + XiCon Loss:3.3839 x Lambda(0.001)), Vali MSE Loss: 0.2673 Test MSE Loss: 0.1558
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2585363
	speed: 0.2070s/iter; left time: 4929.7172s
	iters: 200, epoch: 3 | loss: 0.2574957
	speed: 0.2024s/iter; left time: 4798.5001s
Epoch: 3 cost time: 50.24543237686157
Epoch: 3, Steps: 244 Train Loss: 0.2672 (Forecasting Loss:0.2639 + XiCon Loss:3.3511 x Lambda(0.001)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.1533
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2524049
	speed: 0.2007s/iter; left time: 4730.9678s
	iters: 200, epoch: 4 | loss: 0.2581768
	speed: 0.1953s/iter; left time: 4583.8310s
Epoch: 4 cost time: 48.61524248123169
Epoch: 4, Steps: 244 Train Loss: 0.2527 (Forecasting Loss:0.2493 + XiCon Loss:3.3118 x Lambda(0.001)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.1538
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2516466
	speed: 0.2044s/iter; left time: 4768.0042s
	iters: 200, epoch: 5 | loss: 0.2405627
	speed: 0.2063s/iter; left time: 4792.3658s
Epoch: 5 cost time: 49.356534004211426
Epoch: 5, Steps: 244 Train Loss: 0.2442 (Forecasting Loss:0.2409 + XiCon Loss:3.2921 x Lambda(0.001)), Vali MSE Loss: 0.2912 Test MSE Loss: 0.1543
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2350231
	speed: 0.2028s/iter; left time: 4681.0355s
	iters: 200, epoch: 6 | loss: 0.2476780
	speed: 0.2088s/iter; left time: 4799.1104s
Epoch: 6 cost time: 50.28185248374939
Epoch: 6, Steps: 244 Train Loss: 0.2408 (Forecasting Loss:0.2375 + XiCon Loss:3.2881 x Lambda(0.001)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.1558
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2231157
	speed: 0.2122s/iter; left time: 4846.5862s
	iters: 200, epoch: 7 | loss: 0.2380498
	speed: 0.1981s/iter; left time: 4504.8049s
Epoch: 7 cost time: 50.59903049468994
Epoch: 7, Steps: 244 Train Loss: 0.2385 (Forecasting Loss:0.2352 + XiCon Loss:3.2937 x Lambda(0.001)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.1565
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2503381
	speed: 0.1962s/iter; left time: 4431.9123s
	iters: 200, epoch: 8 | loss: 0.2439380
	speed: 0.2093s/iter; left time: 4707.7450s
Epoch: 8 cost time: 49.90295195579529
Epoch: 8, Steps: 244 Train Loss: 0.2372 (Forecasting Loss:0.2339 + XiCon Loss:3.2945 x Lambda(0.001)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.1550
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2273820
	speed: 0.2130s/iter; left time: 4759.2464s
	iters: 200, epoch: 9 | loss: 0.2345560
	speed: 0.2130s/iter; left time: 4738.5884s
Epoch: 9 cost time: 51.71815609931946
Epoch: 9, Steps: 244 Train Loss: 0.2367 (Forecasting Loss:0.2334 + XiCon Loss:3.2937 x Lambda(0.001)), Vali MSE Loss: 0.2959 Test MSE Loss: 0.1562
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2364371
	speed: 0.2129s/iter; left time: 4707.1997s
	iters: 200, epoch: 10 | loss: 0.2281028
	speed: 0.2125s/iter; left time: 4675.7805s
Epoch: 10 cost time: 51.775471210479736
Epoch: 10, Steps: 244 Train Loss: 0.2363 (Forecasting Loss:0.2330 + XiCon Loss:3.2946 x Lambda(0.001)), Vali MSE Loss: 0.2978 Test MSE Loss: 0.1557
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2166671
	speed: 0.2085s/iter; left time: 4557.1791s
	iters: 200, epoch: 11 | loss: 0.2256426
	speed: 0.2084s/iter; left time: 4534.7969s
Epoch: 11 cost time: 51.46559715270996
Epoch: 11, Steps: 244 Train Loss: 0.2360 (Forecasting Loss:0.2327 + XiCon Loss:3.2943 x Lambda(0.001)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.1556
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08476164191961288, mae:0.2281171828508377, mape:0.16171017289161682, mspe:0.03997210040688515 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.7130
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3344040
	speed: 0.1350s/iter; left time: 3281.7311s
	iters: 200, epoch: 1 | loss: 0.3395254
	speed: 0.1320s/iter; left time: 3194.3645s
Epoch: 1 cost time: 32.86035227775574
Epoch: 1, Steps: 244 Train Loss: 0.3420 (Forecasting Loss:0.3386 + XiCon Loss:3.4025 x Lambda(0.001)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1588
Validation loss decreased (inf --> 0.221854).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2987466
	speed: 0.2039s/iter; left time: 4904.7421s
	iters: 200, epoch: 2 | loss: 0.2814991
	speed: 0.2225s/iter; left time: 5331.1933s
Epoch: 2 cost time: 52.0543692111969
Epoch: 2, Steps: 244 Train Loss: 0.3145 (Forecasting Loss:0.3112 + XiCon Loss:3.3574 x Lambda(0.001)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.1608
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2641783
	speed: 0.2013s/iter; left time: 4793.0169s
	iters: 200, epoch: 3 | loss: 0.2523709
	speed: 0.2079s/iter; left time: 4929.1406s
Epoch: 3 cost time: 50.02220106124878
Epoch: 3, Steps: 244 Train Loss: 0.2646 (Forecasting Loss:0.2613 + XiCon Loss:3.3405 x Lambda(0.001)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.1615
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2395203
	speed: 0.2008s/iter; left time: 4731.9581s
	iters: 200, epoch: 4 | loss: 0.2336011
	speed: 0.2071s/iter; left time: 4860.8817s
Epoch: 4 cost time: 50.02225470542908
Epoch: 4, Steps: 244 Train Loss: 0.2459 (Forecasting Loss:0.2425 + XiCon Loss:3.3399 x Lambda(0.001)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.1625
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2530334
	speed: 0.2068s/iter; left time: 4822.4534s
	iters: 200, epoch: 5 | loss: 0.2375923
	speed: 0.2088s/iter; left time: 4850.0733s
Epoch: 5 cost time: 50.72311234474182
Epoch: 5, Steps: 244 Train Loss: 0.2374 (Forecasting Loss:0.2341 + XiCon Loss:3.3370 x Lambda(0.001)), Vali MSE Loss: 0.2878 Test MSE Loss: 0.1673
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2305860
	speed: 0.2056s/iter; left time: 4744.3311s
	iters: 200, epoch: 6 | loss: 0.2390492
	speed: 0.2055s/iter; left time: 4721.5016s
Epoch: 6 cost time: 50.70065784454346
Epoch: 6, Steps: 244 Train Loss: 0.2331 (Forecasting Loss:0.2298 + XiCon Loss:3.3306 x Lambda(0.001)), Vali MSE Loss: 0.2869 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2348322
	speed: 0.2124s/iter; left time: 4851.3330s
	iters: 200, epoch: 7 | loss: 0.2307177
	speed: 0.2031s/iter; left time: 4618.8567s
Epoch: 7 cost time: 51.148996114730835
Epoch: 7, Steps: 244 Train Loss: 0.2309 (Forecasting Loss:0.2276 + XiCon Loss:3.3289 x Lambda(0.001)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.1656
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2273688
	speed: 0.2069s/iter; left time: 4675.5729s
	iters: 200, epoch: 8 | loss: 0.2221539
	speed: 0.2086s/iter; left time: 4691.3912s
Epoch: 8 cost time: 50.84973073005676
Epoch: 8, Steps: 244 Train Loss: 0.2299 (Forecasting Loss:0.2265 + XiCon Loss:3.3285 x Lambda(0.001)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.1668
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2284335
	speed: 0.2034s/iter; left time: 4546.8681s
	iters: 200, epoch: 9 | loss: 0.2322051
	speed: 0.2061s/iter; left time: 4585.6711s
Epoch: 9 cost time: 49.80760860443115
Epoch: 9, Steps: 244 Train Loss: 0.2295 (Forecasting Loss:0.2262 + XiCon Loss:3.3283 x Lambda(0.001)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.1673
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2421047
	speed: 0.2130s/iter; left time: 4707.5669s
	iters: 200, epoch: 10 | loss: 0.2309312
	speed: 0.2037s/iter; left time: 4483.1434s
Epoch: 10 cost time: 50.72378969192505
Epoch: 10, Steps: 244 Train Loss: 0.2290 (Forecasting Loss:0.2257 + XiCon Loss:3.3284 x Lambda(0.001)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.1674
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2237533
	speed: 0.2080s/iter; left time: 4548.0981s
	iters: 200, epoch: 11 | loss: 0.2318436
	speed: 0.2056s/iter; left time: 4474.0003s
Epoch: 11 cost time: 50.40241050720215
Epoch: 11, Steps: 244 Train Loss: 0.2290 (Forecasting Loss:0.2257 + XiCon Loss:3.3281 x Lambda(0.001)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.1668
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08614175766706467, mae:0.23148013651371002, mape:0.16735459864139557, mspe:0.04365935176610947 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 28.4514
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3778640
	speed: 0.1328s/iter; left time: 3226.2253s
	iters: 200, epoch: 1 | loss: 0.3454662
	speed: 0.1292s/iter; left time: 3126.4624s
Epoch: 1 cost time: 32.938944816589355
Epoch: 1, Steps: 244 Train Loss: 0.3562 (Forecasting Loss:0.3528 + XiCon Loss:3.3920 x Lambda(0.001)), Vali MSE Loss: 0.2356 Test MSE Loss: 0.1521
Validation loss decreased (inf --> 0.235639).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2987102
	speed: 0.1899s/iter; left time: 4567.8504s
	iters: 200, epoch: 2 | loss: 0.2852146
	speed: 0.1866s/iter; left time: 4471.5276s
Epoch: 2 cost time: 44.66612243652344
Epoch: 2, Steps: 244 Train Loss: 0.3121 (Forecasting Loss:0.3087 + XiCon Loss:3.3763 x Lambda(0.001)), Vali MSE Loss: 0.3515 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2722165
	speed: 0.1939s/iter; left time: 4616.6305s
	iters: 200, epoch: 3 | loss: 0.2629856
	speed: 0.1695s/iter; left time: 4018.3004s
Epoch: 3 cost time: 44.631160497665405
Epoch: 3, Steps: 244 Train Loss: 0.2676 (Forecasting Loss:0.2642 + XiCon Loss:3.3439 x Lambda(0.001)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.1535
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2520234
	speed: 0.1937s/iter; left time: 4565.6311s
	iters: 200, epoch: 4 | loss: 0.2508705
	speed: 0.1671s/iter; left time: 3921.8576s
Epoch: 4 cost time: 44.146299839019775
Epoch: 4, Steps: 244 Train Loss: 0.2510 (Forecasting Loss:0.2477 + XiCon Loss:3.3338 x Lambda(0.001)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.1575
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2392748
	speed: 0.1931s/iter; left time: 4503.7283s
	iters: 200, epoch: 5 | loss: 0.2381113
	speed: 0.1866s/iter; left time: 4334.7133s
Epoch: 5 cost time: 46.13646578788757
Epoch: 5, Steps: 244 Train Loss: 0.2437 (Forecasting Loss:0.2404 + XiCon Loss:3.3302 x Lambda(0.001)), Vali MSE Loss: 0.3078 Test MSE Loss: 0.1539
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2465623
	speed: 0.1912s/iter; left time: 4412.9189s
	iters: 200, epoch: 6 | loss: 0.2258333
	speed: 0.1852s/iter; left time: 4255.6542s
Epoch: 6 cost time: 45.82668495178223
Epoch: 6, Steps: 244 Train Loss: 0.2400 (Forecasting Loss:0.2366 + XiCon Loss:3.3296 x Lambda(0.001)), Vali MSE Loss: 0.3003 Test MSE Loss: 0.1527
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2550042
	speed: 0.1921s/iter; left time: 4387.9466s
	iters: 200, epoch: 7 | loss: 0.2394673
	speed: 0.1846s/iter; left time: 4197.8293s
Epoch: 7 cost time: 46.082624673843384
Epoch: 7, Steps: 244 Train Loss: 0.2382 (Forecasting Loss:0.2348 + XiCon Loss:3.3273 x Lambda(0.001)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.1535
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2330868
	speed: 0.1919s/iter; left time: 4336.0777s
	iters: 200, epoch: 8 | loss: 0.2330273
	speed: 0.1882s/iter; left time: 4233.5741s
Epoch: 8 cost time: 46.28848695755005
Epoch: 8, Steps: 244 Train Loss: 0.2373 (Forecasting Loss:0.2339 + XiCon Loss:3.3272 x Lambda(0.001)), Vali MSE Loss: 0.3044 Test MSE Loss: 0.1528
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2334313
	speed: 0.1835s/iter; left time: 4101.0540s
	iters: 200, epoch: 9 | loss: 0.2317614
	speed: 0.1847s/iter; left time: 4109.6418s
Epoch: 9 cost time: 44.99458193778992
Epoch: 9, Steps: 244 Train Loss: 0.2365 (Forecasting Loss:0.2332 + XiCon Loss:3.3250 x Lambda(0.001)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.1525
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2383828
	speed: 0.1824s/iter; left time: 4032.5395s
	iters: 200, epoch: 10 | loss: 0.2407027
	speed: 0.1904s/iter; left time: 4189.5486s
Epoch: 10 cost time: 45.552478075027466
Epoch: 10, Steps: 244 Train Loss: 0.2364 (Forecasting Loss:0.2331 + XiCon Loss:3.3250 x Lambda(0.001)), Vali MSE Loss: 0.3039 Test MSE Loss: 0.1526
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2434183
	speed: 0.1815s/iter; left time: 3966.9324s
	iters: 200, epoch: 11 | loss: 0.2340445
	speed: 0.1835s/iter; left time: 3993.8190s
Epoch: 11 cost time: 45.283655405044556
Epoch: 11, Steps: 244 Train Loss: 0.2362 (Forecasting Loss:0.2329 + XiCon Loss:3.3265 x Lambda(0.001)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.1526
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.0802379921078682, mae:0.22395583987236023, mape:0.16083283722400665, mspe:0.03969341143965721 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.7827
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3647645
	speed: 0.1347s/iter; left time: 3272.3077s
	iters: 200, epoch: 1 | loss: 0.3295874
	speed: 0.1299s/iter; left time: 3143.1982s
Epoch: 1 cost time: 33.54564619064331
Epoch: 1, Steps: 244 Train Loss: 0.3494 (Forecasting Loss:0.3460 + XiCon Loss:3.3913 x Lambda(0.001)), Vali MSE Loss: 0.2401 Test MSE Loss: 0.1486
Validation loss decreased (inf --> 0.240117).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3129305
	speed: 0.2047s/iter; left time: 4925.6433s
	iters: 200, epoch: 2 | loss: 0.2703057
	speed: 0.2104s/iter; left time: 5039.7698s
Epoch: 2 cost time: 50.34580683708191
Epoch: 2, Steps: 244 Train Loss: 0.3020 (Forecasting Loss:0.2987 + XiCon Loss:3.3235 x Lambda(0.001)), Vali MSE Loss: 0.2632 Test MSE Loss: 0.1631
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2716021
	speed: 0.2038s/iter; left time: 4854.1445s
	iters: 200, epoch: 3 | loss: 0.2551107
	speed: 0.2012s/iter; left time: 4772.1587s
Epoch: 3 cost time: 49.303731203079224
Epoch: 3, Steps: 244 Train Loss: 0.2617 (Forecasting Loss:0.2584 + XiCon Loss:3.3061 x Lambda(0.001)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1549
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2446771
	speed: 0.2058s/iter; left time: 4849.9795s
	iters: 200, epoch: 4 | loss: 0.2494023
	speed: 0.2021s/iter; left time: 4743.4791s
Epoch: 4 cost time: 49.390875816345215
Epoch: 4, Steps: 244 Train Loss: 0.2435 (Forecasting Loss:0.2402 + XiCon Loss:3.3167 x Lambda(0.001)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.1517
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2341566
	speed: 0.2057s/iter; left time: 4797.6187s
	iters: 200, epoch: 5 | loss: 0.2327878
	speed: 0.1973s/iter; left time: 4581.3741s
Epoch: 5 cost time: 48.83849811553955
Epoch: 5, Steps: 244 Train Loss: 0.2340 (Forecasting Loss:0.2307 + XiCon Loss:3.3182 x Lambda(0.001)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.1533
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2345848
	speed: 0.2006s/iter; left time: 4630.4903s
	iters: 200, epoch: 6 | loss: 0.2291136
	speed: 0.2006s/iter; left time: 4609.7570s
Epoch: 6 cost time: 48.63032078742981
Epoch: 6, Steps: 244 Train Loss: 0.2292 (Forecasting Loss:0.2259 + XiCon Loss:3.3153 x Lambda(0.001)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.1689
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2175317
	speed: 0.2008s/iter; left time: 4586.7253s
	iters: 200, epoch: 7 | loss: 0.2247425
	speed: 0.1958s/iter; left time: 4450.9817s
Epoch: 7 cost time: 48.80381512641907
Epoch: 7, Steps: 244 Train Loss: 0.2267 (Forecasting Loss:0.2234 + XiCon Loss:3.3156 x Lambda(0.001)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.1681
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2212326
	speed: 0.2006s/iter; left time: 4532.1861s
	iters: 200, epoch: 8 | loss: 0.2258584
	speed: 0.1931s/iter; left time: 4342.4033s
Epoch: 8 cost time: 47.183878898620605
Epoch: 8, Steps: 244 Train Loss: 0.2253 (Forecasting Loss:0.2220 + XiCon Loss:3.3135 x Lambda(0.001)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.1668
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2147864
	speed: 0.1990s/iter; left time: 4447.7051s
	iters: 200, epoch: 9 | loss: 0.2204875
	speed: 0.1976s/iter; left time: 4396.4856s
Epoch: 9 cost time: 48.19739294052124
Epoch: 9, Steps: 244 Train Loss: 0.2247 (Forecasting Loss:0.2214 + XiCon Loss:3.3130 x Lambda(0.001)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.1677
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2285630
	speed: 0.2049s/iter; left time: 4529.8076s
	iters: 200, epoch: 10 | loss: 0.2311141
	speed: 0.1881s/iter; left time: 4139.2403s
Epoch: 10 cost time: 48.179760217666626
Epoch: 10, Steps: 244 Train Loss: 0.2244 (Forecasting Loss:0.2211 + XiCon Loss:3.3127 x Lambda(0.001)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.1691
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2296363
	speed: 0.1853s/iter; left time: 4050.8876s
	iters: 200, epoch: 11 | loss: 0.2194102
	speed: 0.1892s/iter; left time: 4116.1153s
Epoch: 11 cost time: 46.15758991241455
Epoch: 11, Steps: 244 Train Loss: 0.2242 (Forecasting Loss:0.2209 + XiCon Loss:3.3140 x Lambda(0.001)), Vali MSE Loss: 0.3340 Test MSE Loss: 0.1689
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.07751797884702682, mae:0.21969617903232574, mape:0.15787817537784576, mspe:0.03847430273890495 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 21.9711
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 0.3528069
	speed: 0.1318s/iter; left time: 3203.6651s
	iters: 200, epoch: 1 | loss: 0.2787000
	speed: 0.1355s/iter; left time: 3280.2883s
Epoch: 1 cost time: 32.51555395126343
Epoch: 1, Steps: 244 Train Loss: 0.3454 (Forecasting Loss:0.3420 + XiCon Loss:3.3961 x Lambda(0.001)), Vali MSE Loss: 0.2348 Test MSE Loss: 0.1629
Validation loss decreased (inf --> 0.234750).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3119939
	speed: 0.2107s/iter; left time: 5069.6375s
	iters: 200, epoch: 2 | loss: 0.2828530
	speed: 0.2136s/iter; left time: 5117.0061s
Epoch: 2 cost time: 52.29178762435913
Epoch: 2, Steps: 244 Train Loss: 0.3268 (Forecasting Loss:0.3234 + XiCon Loss:3.3545 x Lambda(0.001)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2406794
	speed: 0.2173s/iter; left time: 5174.9730s
	iters: 200, epoch: 3 | loss: 0.2686119
	speed: 0.2187s/iter; left time: 5187.2183s
Epoch: 3 cost time: 53.31308579444885
Epoch: 3, Steps: 244 Train Loss: 0.2589 (Forecasting Loss:0.2556 + XiCon Loss:3.3211 x Lambda(0.001)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1560
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2414764
	speed: 0.2218s/iter; left time: 5227.6502s
	iters: 200, epoch: 4 | loss: 0.2398386
	speed: 0.2155s/iter; left time: 5056.9953s
Epoch: 4 cost time: 53.32060241699219
Epoch: 4, Steps: 244 Train Loss: 0.2396 (Forecasting Loss:0.2363 + XiCon Loss:3.3170 x Lambda(0.001)), Vali MSE Loss: 0.2648 Test MSE Loss: 0.1602
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2342531
	speed: 0.2159s/iter; left time: 5035.7380s
	iters: 200, epoch: 5 | loss: 0.2340539
	speed: 0.2197s/iter; left time: 5103.6296s
Epoch: 5 cost time: 53.65627336502075
Epoch: 5, Steps: 244 Train Loss: 0.2310 (Forecasting Loss:0.2276 + XiCon Loss:3.3171 x Lambda(0.001)), Vali MSE Loss: 0.2682 Test MSE Loss: 0.1673
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2340332
	speed: 0.2157s/iter; left time: 4978.6652s
	iters: 200, epoch: 6 | loss: 0.2241199
	speed: 0.2095s/iter; left time: 4815.3547s
Epoch: 6 cost time: 52.14901399612427
Epoch: 6, Steps: 244 Train Loss: 0.2267 (Forecasting Loss:0.2234 + XiCon Loss:3.3167 x Lambda(0.001)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.1667
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2195586
	speed: 0.2194s/iter; left time: 5010.3334s
	iters: 200, epoch: 7 | loss: 0.2207675
	speed: 0.2163s/iter; left time: 4918.5701s
Epoch: 7 cost time: 52.97613048553467
Epoch: 7, Steps: 244 Train Loss: 0.2246 (Forecasting Loss:0.2213 + XiCon Loss:3.3174 x Lambda(0.001)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.1743
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2245856
	speed: 0.2180s/iter; left time: 4925.1555s
	iters: 200, epoch: 8 | loss: 0.2168256
	speed: 0.2095s/iter; left time: 4712.5897s
Epoch: 8 cost time: 52.22355508804321
Epoch: 8, Steps: 244 Train Loss: 0.2234 (Forecasting Loss:0.2201 + XiCon Loss:3.3166 x Lambda(0.001)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.1721
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2273040
	speed: 0.2218s/iter; left time: 4958.0200s
	iters: 200, epoch: 9 | loss: 0.2287304
	speed: 0.2109s/iter; left time: 4693.3531s
Epoch: 9 cost time: 52.384016275405884
Epoch: 9, Steps: 244 Train Loss: 0.2228 (Forecasting Loss:0.2195 + XiCon Loss:3.3179 x Lambda(0.001)), Vali MSE Loss: 0.2783 Test MSE Loss: 0.1729
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2262326
	speed: 0.2160s/iter; left time: 4774.8636s
	iters: 200, epoch: 10 | loss: 0.2183219
	speed: 0.2056s/iter; left time: 4523.7235s
Epoch: 10 cost time: 51.87553858757019
Epoch: 10, Steps: 244 Train Loss: 0.2225 (Forecasting Loss:0.2191 + XiCon Loss:3.3144 x Lambda(0.001)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.1726
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2346253
	speed: 0.2162s/iter; left time: 4726.2350s
	iters: 200, epoch: 11 | loss: 0.2238846
	speed: 0.2151s/iter; left time: 4681.4860s
Epoch: 11 cost time: 52.308188915252686
Epoch: 11, Steps: 244 Train Loss: 0.2222 (Forecasting Loss:0.2189 + XiCon Loss:3.3160 x Lambda(0.001)), Vali MSE Loss: 0.2802 Test MSE Loss: 0.1730
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.089942067861557, mae:0.2359180897474289, mape:0.16951872408390045, mspe:0.04447583854198456 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0837+-0.00609, MAE:0.2278+-0.00785, MAPE:0.1635+-0.00599, MSPE:0.0413+-0.00328, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.3128
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7688196
	speed: 0.1316s/iter; left time: 3052.2301s
	iters: 200, epoch: 1 | loss: 0.7479660
	speed: 0.1294s/iter; left time: 2990.3436s
Epoch: 1 cost time: 30.2811062335968
Epoch: 1, Steps: 233 Train Loss: 0.7702 (Forecasting Loss:0.4292 + XiCon Loss:3.4097 x Lambda(0.1)), Vali MSE Loss: 0.2992 Test MSE Loss: 0.1704
Validation loss decreased (inf --> 0.299191).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6752939
	speed: 0.1302s/iter; left time: 2990.1109s
	iters: 200, epoch: 2 | loss: 0.6199274
	speed: 0.1372s/iter; left time: 3137.6876s
Epoch: 2 cost time: 31.103156328201294
Epoch: 2, Steps: 233 Train Loss: 0.6631 (Forecasting Loss:0.3345 + XiCon Loss:3.2860 x Lambda(0.1)), Vali MSE Loss: 0.2390 Test MSE Loss: 0.1611
Validation loss decreased (0.299191 --> 0.238992).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6153387
	speed: 0.1361s/iter; left time: 3094.4869s
	iters: 200, epoch: 3 | loss: 0.6036177
	speed: 0.1380s/iter; left time: 3124.2926s
Epoch: 3 cost time: 31.712108850479126
Epoch: 3, Steps: 233 Train Loss: 0.6085 (Forecasting Loss:0.2853 + XiCon Loss:3.2320 x Lambda(0.1)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.1551
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6006793
	speed: 0.1301s/iter; left time: 2928.0815s
	iters: 200, epoch: 4 | loss: 0.5943254
	speed: 0.1155s/iter; left time: 2586.4700s
Epoch: 4 cost time: 29.02565288543701
Epoch: 4, Steps: 233 Train Loss: 0.5983 (Forecasting Loss:0.2769 + XiCon Loss:3.2146 x Lambda(0.1)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1619
Validation loss decreased (0.238992 --> 0.229298).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5926599
	speed: 0.1143s/iter; left time: 2544.9505s
	iters: 200, epoch: 5 | loss: 0.5883645
	speed: 0.1390s/iter; left time: 3082.2716s
Epoch: 5 cost time: 29.914955854415894
Epoch: 5, Steps: 233 Train Loss: 0.5933 (Forecasting Loss:0.2728 + XiCon Loss:3.2055 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1528
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5999670
	speed: 0.1425s/iter; left time: 3139.1356s
	iters: 200, epoch: 6 | loss: 0.5909547
	speed: 0.1447s/iter; left time: 3173.1164s
Epoch: 6 cost time: 33.387463092803955
Epoch: 6, Steps: 233 Train Loss: 0.5910 (Forecasting Loss:0.2708 + XiCon Loss:3.2023 x Lambda(0.1)), Vali MSE Loss: 0.2325 Test MSE Loss: 0.1578
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.6059427
	speed: 0.1475s/iter; left time: 3215.2733s
	iters: 200, epoch: 7 | loss: 0.6014513
	speed: 0.1144s/iter; left time: 2481.7402s
Epoch: 7 cost time: 31.231146812438965
Epoch: 7, Steps: 233 Train Loss: 0.5894 (Forecasting Loss:0.2695 + XiCon Loss:3.1990 x Lambda(0.1)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1564
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5738972
	speed: 0.1488s/iter; left time: 3208.5511s
	iters: 200, epoch: 8 | loss: 0.6012233
	speed: 0.1478s/iter; left time: 3172.4196s
Epoch: 8 cost time: 32.934086561203
Epoch: 8, Steps: 233 Train Loss: 0.5888 (Forecasting Loss:0.2690 + XiCon Loss:3.1978 x Lambda(0.1)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.1567
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5757922
	speed: 0.1512s/iter; left time: 3226.8535s
	iters: 200, epoch: 9 | loss: 0.5968171
	speed: 0.1389s/iter; left time: 2950.4108s
Epoch: 9 cost time: 33.99956655502319
Epoch: 9, Steps: 233 Train Loss: 0.5885 (Forecasting Loss:0.2687 + XiCon Loss:3.1977 x Lambda(0.1)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1576
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5848129
	speed: 0.1425s/iter; left time: 3007.1822s
	iters: 200, epoch: 10 | loss: 0.5876820
	speed: 0.1444s/iter; left time: 3031.9523s
Epoch: 10 cost time: 33.4301655292511
Epoch: 10, Steps: 233 Train Loss: 0.5881 (Forecasting Loss:0.2683 + XiCon Loss:3.1977 x Lambda(0.1)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.1559
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.6010262
	speed: 0.1450s/iter; left time: 3027.1992s
	iters: 200, epoch: 11 | loss: 0.5933350
	speed: 0.1500s/iter; left time: 3116.5175s
Epoch: 11 cost time: 34.41126871109009
Epoch: 11, Steps: 233 Train Loss: 0.5882 (Forecasting Loss:0.2684 + XiCon Loss:3.1972 x Lambda(0.1)), Vali MSE Loss: 0.2420 Test MSE Loss: 0.1571
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5915397
	speed: 0.1442s/iter; left time: 2975.7617s
	iters: 200, epoch: 12 | loss: 0.5671487
	speed: 0.1457s/iter; left time: 2993.0283s
Epoch: 12 cost time: 33.88317251205444
Epoch: 12, Steps: 233 Train Loss: 0.5879 (Forecasting Loss:0.2682 + XiCon Loss:3.1966 x Lambda(0.1)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1572
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5938542
	speed: 0.1498s/iter; left time: 3057.4595s
	iters: 200, epoch: 13 | loss: 0.5905374
	speed: 0.1461s/iter; left time: 2967.1233s
Epoch: 13 cost time: 34.676244497299194
Epoch: 13, Steps: 233 Train Loss: 0.5878 (Forecasting Loss:0.2682 + XiCon Loss:3.1963 x Lambda(0.1)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1567
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5827056
	speed: 0.1489s/iter; left time: 3003.2715s
	iters: 200, epoch: 14 | loss: 0.5755751
	speed: 0.1462s/iter; left time: 2934.6226s
Epoch: 14 cost time: 34.31956195831299
Epoch: 14, Steps: 233 Train Loss: 0.5883 (Forecasting Loss:0.2684 + XiCon Loss:3.1988 x Lambda(0.1)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1569
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08808677643537521, mae:0.23574581742286682, mape:0.16781969368457794, mspe:0.04293876886367798 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.0588
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7810479
	speed: 0.1320s/iter; left time: 3062.1131s
	iters: 200, epoch: 1 | loss: 0.7317935
	speed: 0.1357s/iter; left time: 3135.5258s
Epoch: 1 cost time: 31.370591163635254
Epoch: 1, Steps: 233 Train Loss: 0.7671 (Forecasting Loss:0.4272 + XiCon Loss:3.3992 x Lambda(0.1)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.1701
Validation loss decreased (inf --> 0.301440).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6585145
	speed: 0.1392s/iter; left time: 3196.6432s
	iters: 200, epoch: 2 | loss: 0.6301715
	speed: 0.1384s/iter; left time: 3164.3141s
Epoch: 2 cost time: 32.248464822769165
Epoch: 2, Steps: 233 Train Loss: 0.6599 (Forecasting Loss:0.3320 + XiCon Loss:3.2785 x Lambda(0.1)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1484
Validation loss decreased (0.301440 --> 0.240522).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6084436
	speed: 0.1319s/iter; left time: 2997.7347s
	iters: 200, epoch: 3 | loss: 0.6092080
	speed: 0.1362s/iter; left time: 3082.1029s
Epoch: 3 cost time: 31.334773778915405
Epoch: 3, Steps: 233 Train Loss: 0.6106 (Forecasting Loss:0.2861 + XiCon Loss:3.2446 x Lambda(0.1)), Vali MSE Loss: 0.2396 Test MSE Loss: 0.1522
Validation loss decreased (0.240522 --> 0.239562).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.6006633
	speed: 0.1430s/iter; left time: 3218.0197s
	iters: 200, epoch: 4 | loss: 0.5974935
	speed: 0.1355s/iter; left time: 3035.1314s
Epoch: 4 cost time: 32.39935541152954
Epoch: 4, Steps: 233 Train Loss: 0.5995 (Forecasting Loss:0.2755 + XiCon Loss:3.2400 x Lambda(0.1)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1489
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5924793
	speed: 0.1490s/iter; left time: 3318.7486s
	iters: 200, epoch: 5 | loss: 0.5810156
	speed: 0.1351s/iter; left time: 2995.2305s
Epoch: 5 cost time: 32.89289832115173
Epoch: 5, Steps: 233 Train Loss: 0.5935 (Forecasting Loss:0.2702 + XiCon Loss:3.2332 x Lambda(0.1)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1463
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5949802
	speed: 0.1471s/iter; left time: 3241.4013s
	iters: 200, epoch: 6 | loss: 0.5817240
	speed: 0.1344s/iter; left time: 2947.7938s
Epoch: 6 cost time: 32.6627254486084
Epoch: 6, Steps: 233 Train Loss: 0.5901 (Forecasting Loss:0.2672 + XiCon Loss:3.2288 x Lambda(0.1)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1450
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5706483
	speed: 0.1421s/iter; left time: 3097.2670s
	iters: 200, epoch: 7 | loss: 0.5963194
	speed: 0.1455s/iter; left time: 3158.3051s
Epoch: 7 cost time: 33.14020848274231
Epoch: 7, Steps: 233 Train Loss: 0.5886 (Forecasting Loss:0.2660 + XiCon Loss:3.2265 x Lambda(0.1)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.1446
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5896398
	speed: 0.1411s/iter; left time: 3043.0547s
	iters: 200, epoch: 8 | loss: 0.5772394
	speed: 0.1382s/iter; left time: 2966.4618s
Epoch: 8 cost time: 32.235782861709595
Epoch: 8, Steps: 233 Train Loss: 0.5878 (Forecasting Loss:0.2652 + XiCon Loss:3.2257 x Lambda(0.1)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.1442
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5959145
	speed: 0.1377s/iter; left time: 2937.5589s
	iters: 200, epoch: 9 | loss: 0.5937878
	speed: 0.1378s/iter; left time: 2925.9911s
Epoch: 9 cost time: 32.04357695579529
Epoch: 9, Steps: 233 Train Loss: 0.5870 (Forecasting Loss:0.2647 + XiCon Loss:3.2230 x Lambda(0.1)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1444
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.6009500
	speed: 0.1301s/iter; left time: 2746.4214s
	iters: 200, epoch: 10 | loss: 0.5794203
	speed: 0.1349s/iter; left time: 2833.3173s
Epoch: 10 cost time: 31.201995134353638
Epoch: 10, Steps: 233 Train Loss: 0.5872 (Forecasting Loss:0.2648 + XiCon Loss:3.2233 x Lambda(0.1)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1443
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5913144
	speed: 0.1406s/iter; left time: 2934.7622s
	iters: 200, epoch: 11 | loss: 0.5807778
	speed: 0.1332s/iter; left time: 2765.8368s
Epoch: 11 cost time: 31.757394790649414
Epoch: 11, Steps: 233 Train Loss: 0.5868 (Forecasting Loss:0.2645 + XiCon Loss:3.2234 x Lambda(0.1)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1444
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5924323
	speed: 0.1453s/iter; left time: 2999.2798s
	iters: 200, epoch: 12 | loss: 0.5902828
	speed: 0.1367s/iter; left time: 2807.7842s
Epoch: 12 cost time: 32.35866928100586
Epoch: 12, Steps: 233 Train Loss: 0.5868 (Forecasting Loss:0.2644 + XiCon Loss:3.2240 x Lambda(0.1)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1446
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5873657
	speed: 0.1391s/iter; left time: 2838.2921s
	iters: 200, epoch: 13 | loss: 0.5961090
	speed: 0.1328s/iter; left time: 2696.9933s
Epoch: 13 cost time: 31.66711735725403
Epoch: 13, Steps: 233 Train Loss: 0.5872 (Forecasting Loss:0.2648 + XiCon Loss:3.2245 x Lambda(0.1)), Vali MSE Loss: 0.2461 Test MSE Loss: 0.1445
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08006395399570465, mae:0.22438932955265045, mape:0.16106735169887543, mspe:0.04068249836564064 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.8147
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7782025
	speed: 0.1322s/iter; left time: 3068.1754s
	iters: 200, epoch: 1 | loss: 0.7235440
	speed: 0.1267s/iter; left time: 2926.3392s
Epoch: 1 cost time: 30.682005167007446
Epoch: 1, Steps: 233 Train Loss: 0.7709 (Forecasting Loss:0.4352 + XiCon Loss:3.3575 x Lambda(0.1)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.1665
Validation loss decreased (inf --> 0.281487).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6595373
	speed: 0.1417s/iter; left time: 3254.9130s
	iters: 200, epoch: 2 | loss: 0.6182812
	speed: 0.1279s/iter; left time: 2924.2650s
Epoch: 2 cost time: 31.656256914138794
Epoch: 2, Steps: 233 Train Loss: 0.6588 (Forecasting Loss:0.3341 + XiCon Loss:3.2472 x Lambda(0.1)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1722
Validation loss decreased (0.281487 --> 0.240626).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6036806
	speed: 0.1417s/iter; left time: 3220.6389s
	iters: 200, epoch: 3 | loss: 0.5865390
	speed: 0.1329s/iter; left time: 3007.8498s
Epoch: 3 cost time: 31.648810386657715
Epoch: 3, Steps: 233 Train Loss: 0.6018 (Forecasting Loss:0.2784 + XiCon Loss:3.2347 x Lambda(0.1)), Vali MSE Loss: 0.2297 Test MSE Loss: 0.1678
Validation loss decreased (0.240626 --> 0.229683).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5677947
	speed: 0.1400s/iter; left time: 3149.4256s
	iters: 200, epoch: 4 | loss: 0.5872132
	speed: 0.0970s/iter; left time: 2172.7140s
Epoch: 4 cost time: 28.274130821228027
Epoch: 4, Steps: 233 Train Loss: 0.5893 (Forecasting Loss:0.2669 + XiCon Loss:3.2244 x Lambda(0.1)), Vali MSE Loss: 0.2310 Test MSE Loss: 0.1614
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5780166
	speed: 0.1418s/iter; left time: 3157.2740s
	iters: 200, epoch: 5 | loss: 0.6072426
	speed: 0.1370s/iter; left time: 3037.5585s
Epoch: 5 cost time: 31.600374460220337
Epoch: 5, Steps: 233 Train Loss: 0.5831 (Forecasting Loss:0.2614 + XiCon Loss:3.2171 x Lambda(0.1)), Vali MSE Loss: 0.2296 Test MSE Loss: 0.1553
Validation loss decreased (0.229683 --> 0.229640).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5803686
	speed: 0.1478s/iter; left time: 3256.2597s
	iters: 200, epoch: 6 | loss: 0.5841246
	speed: 0.1398s/iter; left time: 3067.3200s
Epoch: 6 cost time: 33.07274675369263
Epoch: 6, Steps: 233 Train Loss: 0.5804 (Forecasting Loss:0.2593 + XiCon Loss:3.2119 x Lambda(0.1)), Vali MSE Loss: 0.2350 Test MSE Loss: 0.1581
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5774794
	speed: 0.0759s/iter; left time: 1654.2309s
	iters: 200, epoch: 7 | loss: 0.5745546
	speed: 0.1231s/iter; left time: 2670.6198s
Epoch: 7 cost time: 24.26502227783203
Epoch: 7, Steps: 233 Train Loss: 0.5789 (Forecasting Loss:0.2579 + XiCon Loss:3.2092 x Lambda(0.1)), Vali MSE Loss: 0.2323 Test MSE Loss: 0.1556
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5911852
	speed: 0.1414s/iter; left time: 3050.6809s
	iters: 200, epoch: 8 | loss: 0.5726885
	speed: 0.1028s/iter; left time: 2206.1753s
Epoch: 8 cost time: 27.116481065750122
Epoch: 8, Steps: 233 Train Loss: 0.5782 (Forecasting Loss:0.2573 + XiCon Loss:3.2086 x Lambda(0.1)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.1576
Validation loss decreased (0.229640 --> 0.227581).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5916539
	speed: 0.1418s/iter; left time: 3025.9513s
	iters: 200, epoch: 9 | loss: 0.5820817
	speed: 0.1400s/iter; left time: 2973.3190s
Epoch: 9 cost time: 32.224347829818726
Epoch: 9, Steps: 233 Train Loss: 0.5779 (Forecasting Loss:0.2571 + XiCon Loss:3.2084 x Lambda(0.1)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.1575
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5713356
	speed: 0.1420s/iter; left time: 2996.6165s
	iters: 200, epoch: 10 | loss: 0.5682061
	speed: 0.1383s/iter; left time: 2904.0346s
Epoch: 10 cost time: 32.44140315055847
Epoch: 10, Steps: 233 Train Loss: 0.5773 (Forecasting Loss:0.2566 + XiCon Loss:3.2073 x Lambda(0.1)), Vali MSE Loss: 0.2279 Test MSE Loss: 0.1582
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5680237
	speed: 0.0964s/iter; left time: 2012.5882s
	iters: 200, epoch: 11 | loss: 0.5820628
	speed: 0.1349s/iter; left time: 2802.4887s
Epoch: 11 cost time: 27.727760314941406
Epoch: 11, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2566 + XiCon Loss:3.2091 x Lambda(0.1)), Vali MSE Loss: 0.2290 Test MSE Loss: 0.1581
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5762197
	speed: 0.1331s/iter; left time: 2746.7008s
	iters: 200, epoch: 12 | loss: 0.5652843
	speed: 0.1421s/iter; left time: 2918.1043s
Epoch: 12 cost time: 32.22437262535095
Epoch: 12, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2566 + XiCon Loss:3.2082 x Lambda(0.1)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.1583
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.5889008
	speed: 0.1336s/iter; left time: 2725.1829s
	iters: 200, epoch: 13 | loss: 0.5877239
	speed: 0.1336s/iter; left time: 2712.7833s
Epoch: 13 cost time: 31.101985931396484
Epoch: 13, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2565 + XiCon Loss:3.2095 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1585
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.5841429
	speed: 0.1440s/iter; left time: 2904.3135s
	iters: 200, epoch: 14 | loss: 0.5716816
	speed: 0.1311s/iter; left time: 2630.8536s
Epoch: 14 cost time: 32.32445287704468
Epoch: 14, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2566 + XiCon Loss:3.2075 x Lambda(0.1)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1584
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.5922438
	speed: 0.1412s/iter; left time: 2814.8675s
	iters: 200, epoch: 15 | loss: 0.5819237
	speed: 0.1271s/iter; left time: 2520.7557s
Epoch: 15 cost time: 31.69723391532898
Epoch: 15, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2568 + XiCon Loss:3.2076 x Lambda(0.1)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1584
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.5963444
	speed: 0.1428s/iter; left time: 2814.6974s
	iters: 200, epoch: 16 | loss: 0.5714699
	speed: 0.1303s/iter; left time: 2554.5680s
Epoch: 16 cost time: 31.69840145111084
Epoch: 16, Steps: 233 Train Loss: 0.5773 (Forecasting Loss:0.2566 + XiCon Loss:3.2073 x Lambda(0.1)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1583
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 0.5911695
	speed: 0.1446s/iter; left time: 2815.5119s
	iters: 200, epoch: 17 | loss: 0.5739586
	speed: 0.1378s/iter; left time: 2669.9072s
Epoch: 17 cost time: 32.585248947143555
Epoch: 17, Steps: 233 Train Loss: 0.5776 (Forecasting Loss:0.2568 + XiCon Loss:3.2087 x Lambda(0.1)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1584
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 0.5793029
	speed: 0.1430s/iter; left time: 2751.7333s
	iters: 200, epoch: 18 | loss: 0.5753372
	speed: 0.1400s/iter; left time: 2679.3199s
Epoch: 18 cost time: 33.10126972198486
Epoch: 18, Steps: 233 Train Loss: 0.5774 (Forecasting Loss:0.2567 + XiCon Loss:3.2070 x Lambda(0.1)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1584
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08404985815286636, mae:0.23108266294002533, mape:0.1647927612066269, mspe:0.041435614228248596 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 22.2910
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8003001
	speed: 0.1318s/iter; left time: 3057.8205s
	iters: 200, epoch: 1 | loss: 0.7936062
	speed: 0.1335s/iter; left time: 3083.3825s
Epoch: 1 cost time: 31.116501092910767
Epoch: 1, Steps: 233 Train Loss: 0.7795 (Forecasting Loss:0.4427 + XiCon Loss:3.3675 x Lambda(0.1)), Vali MSE Loss: 0.2995 Test MSE Loss: 0.1948
Validation loss decreased (inf --> 0.299496).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6400751
	speed: 0.1550s/iter; left time: 3560.8028s
	iters: 200, epoch: 2 | loss: 0.6187738
	speed: 0.1690s/iter; left time: 3865.5700s
Epoch: 2 cost time: 37.5115110874176
Epoch: 2, Steps: 233 Train Loss: 0.6417 (Forecasting Loss:0.3290 + XiCon Loss:3.1264 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.1810
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.5729123
	speed: 0.1589s/iter; left time: 3612.1433s
	iters: 200, epoch: 3 | loss: 0.5887774
	speed: 0.1666s/iter; left time: 3770.5542s
Epoch: 3 cost time: 37.69253897666931
Epoch: 3, Steps: 233 Train Loss: 0.5937 (Forecasting Loss:0.2819 + XiCon Loss:3.1179 x Lambda(0.1)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.1868
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5756176
	speed: 0.1624s/iter; left time: 3654.7144s
	iters: 200, epoch: 4 | loss: 0.5759301
	speed: 0.1518s/iter; left time: 3400.2836s
Epoch: 4 cost time: 37.13343119621277
Epoch: 4, Steps: 233 Train Loss: 0.5857 (Forecasting Loss:0.2721 + XiCon Loss:3.1362 x Lambda(0.1)), Vali MSE Loss: 0.3148 Test MSE Loss: 0.1710
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5797585
	speed: 0.1574s/iter; left time: 3505.0133s
	iters: 200, epoch: 5 | loss: 0.5687925
	speed: 0.1535s/iter; left time: 3402.1885s
Epoch: 5 cost time: 36.08268070220947
Epoch: 5, Steps: 233 Train Loss: 0.5809 (Forecasting Loss:0.2669 + XiCon Loss:3.1394 x Lambda(0.1)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.1675
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5654430
	speed: 0.1553s/iter; left time: 3422.4028s
	iters: 200, epoch: 6 | loss: 0.5706112
	speed: 0.1540s/iter; left time: 3379.0739s
Epoch: 6 cost time: 36.47786068916321
Epoch: 6, Steps: 233 Train Loss: 0.5777 (Forecasting Loss:0.2643 + XiCon Loss:3.1343 x Lambda(0.1)), Vali MSE Loss: 0.3398 Test MSE Loss: 0.1603
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5803628
	speed: 0.1558s/iter; left time: 3397.7380s
	iters: 200, epoch: 7 | loss: 0.5878024
	speed: 0.1516s/iter; left time: 3289.1491s
Epoch: 7 cost time: 36.53125286102295
Epoch: 7, Steps: 233 Train Loss: 0.5763 (Forecasting Loss:0.2631 + XiCon Loss:3.1324 x Lambda(0.1)), Vali MSE Loss: 0.3286 Test MSE Loss: 0.1636
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5649949
	speed: 0.1569s/iter; left time: 3385.3517s
	iters: 200, epoch: 8 | loss: 0.5652210
	speed: 0.1543s/iter; left time: 3311.8673s
Epoch: 8 cost time: 36.18956780433655
Epoch: 8, Steps: 233 Train Loss: 0.5756 (Forecasting Loss:0.2623 + XiCon Loss:3.1330 x Lambda(0.1)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.1646
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5682275
	speed: 0.1578s/iter; left time: 3366.9934s
	iters: 200, epoch: 9 | loss: 0.5729417
	speed: 0.1501s/iter; left time: 3188.0948s
Epoch: 9 cost time: 35.73815131187439
Epoch: 9, Steps: 233 Train Loss: 0.5750 (Forecasting Loss:0.2618 + XiCon Loss:3.1323 x Lambda(0.1)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.1653
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5755656
	speed: 0.1536s/iter; left time: 3241.9641s
	iters: 200, epoch: 10 | loss: 0.5705860
	speed: 0.1486s/iter; left time: 3121.0194s
Epoch: 10 cost time: 35.29466986656189
Epoch: 10, Steps: 233 Train Loss: 0.5745 (Forecasting Loss:0.2613 + XiCon Loss:3.1311 x Lambda(0.1)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.1662
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5731239
	speed: 0.1546s/iter; left time: 3226.8176s
	iters: 200, epoch: 11 | loss: 0.5772573
	speed: 0.1515s/iter; left time: 3147.0392s
Epoch: 11 cost time: 35.50119113922119
Epoch: 11, Steps: 233 Train Loss: 0.5751 (Forecasting Loss:0.2618 + XiCon Loss:3.1331 x Lambda(0.1)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.1656
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11681826412677765, mae:0.27277836203575134, mape:0.19205409288406372, mspe:0.055049870163202286 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 23.0900
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.7679783
	speed: 0.1374s/iter; left time: 3187.1182s
	iters: 200, epoch: 1 | loss: 0.7688307
	speed: 0.1370s/iter; left time: 3165.9292s
Epoch: 1 cost time: 31.96867275238037
Epoch: 1, Steps: 233 Train Loss: 0.7807 (Forecasting Loss:0.4446 + XiCon Loss:3.3614 x Lambda(0.1)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.1972
Validation loss decreased (inf --> 0.302571).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.6436625
	speed: 0.1463s/iter; left time: 3359.8695s
	iters: 200, epoch: 2 | loss: 0.6150942
	speed: 0.0999s/iter; left time: 2285.0953s
Epoch: 2 cost time: 29.337154150009155
Epoch: 2, Steps: 233 Train Loss: 0.6593 (Forecasting Loss:0.3341 + XiCon Loss:3.2518 x Lambda(0.1)), Vali MSE Loss: 0.2997 Test MSE Loss: 0.1745
Validation loss decreased (0.302571 --> 0.299690).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.6131346
	speed: 0.1508s/iter; left time: 3429.5220s
	iters: 200, epoch: 3 | loss: 0.6180615
	speed: 0.1510s/iter; left time: 3417.5191s
Epoch: 3 cost time: 34.902761936187744
Epoch: 3, Steps: 233 Train Loss: 0.5985 (Forecasting Loss:0.2778 + XiCon Loss:3.2065 x Lambda(0.1)), Vali MSE Loss: 0.3298 Test MSE Loss: 0.1803
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.5894421
	speed: 0.1492s/iter; left time: 3358.1164s
	iters: 200, epoch: 4 | loss: 0.5733632
	speed: 0.1525s/iter; left time: 3416.6716s
Epoch: 4 cost time: 34.54380965232849
Epoch: 4, Steps: 233 Train Loss: 0.5866 (Forecasting Loss:0.2685 + XiCon Loss:3.1814 x Lambda(0.1)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.1625
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.5820313
	speed: 0.1489s/iter; left time: 3316.2704s
	iters: 200, epoch: 5 | loss: 0.5975330
	speed: 0.1561s/iter; left time: 3459.9856s
Epoch: 5 cost time: 35.85941219329834
Epoch: 5, Steps: 233 Train Loss: 0.5820 (Forecasting Loss:0.2644 + XiCon Loss:3.1762 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.1604
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.5797416
	speed: 0.1496s/iter; left time: 3296.2902s
	iters: 200, epoch: 6 | loss: 0.5799450
	speed: 0.1433s/iter; left time: 3142.4735s
Epoch: 6 cost time: 33.992196798324585
Epoch: 6, Steps: 233 Train Loss: 0.5795 (Forecasting Loss:0.2622 + XiCon Loss:3.1726 x Lambda(0.1)), Vali MSE Loss: 0.3331 Test MSE Loss: 0.1625
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.5789041
	speed: 0.1156s/iter; left time: 2519.8966s
	iters: 200, epoch: 7 | loss: 0.5796982
	speed: 0.1506s/iter; left time: 3268.0242s
Epoch: 7 cost time: 32.011932373046875
Epoch: 7, Steps: 233 Train Loss: 0.5786 (Forecasting Loss:0.2613 + XiCon Loss:3.1729 x Lambda(0.1)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.1641
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.5790331
	speed: 0.1464s/iter; left time: 3158.6419s
	iters: 200, epoch: 8 | loss: 0.5801921
	speed: 0.1213s/iter; left time: 2604.5117s
Epoch: 8 cost time: 32.09581136703491
Epoch: 8, Steps: 233 Train Loss: 0.5778 (Forecasting Loss:0.2606 + XiCon Loss:3.1720 x Lambda(0.1)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.1619
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.5739572
	speed: 0.1579s/iter; left time: 3368.1110s
	iters: 200, epoch: 9 | loss: 0.5786011
	speed: 0.1497s/iter; left time: 3178.9000s
Epoch: 9 cost time: 35.711509704589844
Epoch: 9, Steps: 233 Train Loss: 0.5775 (Forecasting Loss:0.2605 + XiCon Loss:3.1706 x Lambda(0.1)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.1622
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.5758449
	speed: 0.1521s/iter; left time: 3210.3592s
	iters: 200, epoch: 10 | loss: 0.5814962
	speed: 0.1499s/iter; left time: 3147.6302s
Epoch: 10 cost time: 35.18612289428711
Epoch: 10, Steps: 233 Train Loss: 0.5773 (Forecasting Loss:0.2601 + XiCon Loss:3.1717 x Lambda(0.1)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.1618
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.5780987
	speed: 0.1484s/iter; left time: 3096.4216s
	iters: 200, epoch: 11 | loss: 0.5917700
	speed: 0.1570s/iter; left time: 3261.3838s
Epoch: 11 cost time: 35.993181228637695
Epoch: 11, Steps: 233 Train Loss: 0.5772 (Forecasting Loss:0.2602 + XiCon Loss:3.1697 x Lambda(0.1)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.1619
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.5821024
	speed: 0.1510s/iter; left time: 3115.6146s
	iters: 200, epoch: 12 | loss: 0.5846121
	speed: 0.1515s/iter; left time: 3110.6962s
Epoch: 12 cost time: 35.10609579086304
Epoch: 12, Steps: 233 Train Loss: 0.5770 (Forecasting Loss:0.2597 + XiCon Loss:3.1728 x Lambda(0.1)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.1616
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09956423193216324, mae:0.24938562512397766, mape:0.1752508580684662, mspe:0.04643891006708145 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0937+-0.01841, MAE:0.2427+-0.02379, MAPE:0.1722+-0.01523, MSPE:0.0453+-0.00730, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.6408
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.0979614
	speed: 0.0694s/iter; left time: 1832.2113s
	iters: 200, epoch: 1 | loss: 32.3585320
	speed: 0.0618s/iter; left time: 1625.4467s
Epoch: 1 cost time: 17.04041814804077
Epoch: 1, Steps: 265 Train Loss: 32.8300 (Forecasting Loss:0.2280 + XiCon Loss:3.2602 x Lambda(10.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.209635).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.7688370
	speed: 0.0691s/iter; left time: 1807.1355s
	iters: 200, epoch: 2 | loss: 31.5408535
	speed: 0.0593s/iter; left time: 1545.2129s
Epoch: 2 cost time: 17.00802731513977
Epoch: 2, Steps: 265 Train Loss: 31.5016 (Forecasting Loss:0.2089 + XiCon Loss:3.1293 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1668
Validation loss decreased (0.209635 --> 0.206521).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.0700188
	speed: 0.0672s/iter; left time: 1739.1779s
	iters: 200, epoch: 3 | loss: 30.3305550
	speed: 0.0630s/iter; left time: 1624.4711s
Epoch: 3 cost time: 17.085359811782837
Epoch: 3, Steps: 265 Train Loss: 30.4730 (Forecasting Loss:0.2011 + XiCon Loss:3.0272 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1620
Validation loss decreased (0.206521 --> 0.203562).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2500420
	speed: 0.0689s/iter; left time: 1763.2298s
	iters: 200, epoch: 4 | loss: 30.6790905
	speed: 0.0618s/iter; left time: 1576.8362s
Epoch: 4 cost time: 16.88271737098694
Epoch: 4, Steps: 265 Train Loss: 30.3994 (Forecasting Loss:0.1987 + XiCon Loss:3.0201 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1606
Validation loss decreased (0.203562 --> 0.200740).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8902245
	speed: 0.0707s/iter; left time: 1790.7697s
	iters: 200, epoch: 5 | loss: 30.4195747
	speed: 0.0636s/iter; left time: 1604.3152s
Epoch: 5 cost time: 17.449888706207275
Epoch: 5, Steps: 265 Train Loss: 30.3637 (Forecasting Loss:0.1969 + XiCon Loss:3.0167 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1594
Validation loss decreased (0.200740 --> 0.198990).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7408638
	speed: 0.0693s/iter; left time: 1738.8562s
	iters: 200, epoch: 6 | loss: 30.3919086
	speed: 0.0593s/iter; left time: 1481.5495s
Epoch: 6 cost time: 16.933314323425293
Epoch: 6, Steps: 265 Train Loss: 30.3342 (Forecasting Loss:0.1962 + XiCon Loss:3.0138 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6724510
	speed: 0.0702s/iter; left time: 1740.6250s
	iters: 200, epoch: 7 | loss: 30.2759075
	speed: 0.0622s/iter; left time: 1536.1100s
Epoch: 7 cost time: 17.307728052139282
Epoch: 7, Steps: 265 Train Loss: 30.3651 (Forecasting Loss:0.1960 + XiCon Loss:3.0169 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1585
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4528389
	speed: 0.0712s/iter; left time: 1746.9089s
	iters: 200, epoch: 8 | loss: 30.3954544
	speed: 0.0611s/iter; left time: 1494.5099s
Epoch: 8 cost time: 17.227821350097656
Epoch: 8, Steps: 265 Train Loss: 30.3265 (Forecasting Loss:0.1958 + XiCon Loss:3.0131 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
Validation loss decreased (0.198990 --> 0.198941).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4476547
	speed: 0.0712s/iter; left time: 1728.7907s
	iters: 200, epoch: 9 | loss: 30.6667385
	speed: 0.0632s/iter; left time: 1527.8719s
Epoch: 9 cost time: 17.81861686706543
Epoch: 9, Steps: 265 Train Loss: 30.3562 (Forecasting Loss:0.1956 + XiCon Loss:3.0161 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1585
Validation loss decreased (0.198941 --> 0.198843).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2496490
	speed: 0.0658s/iter; left time: 1580.2382s
	iters: 200, epoch: 10 | loss: 30.5164547
	speed: 0.0583s/iter; left time: 1394.6459s
Epoch: 10 cost time: 15.423510551452637
Epoch: 10, Steps: 265 Train Loss: 30.3133 (Forecasting Loss:0.1956 + XiCon Loss:3.0118 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1585
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1803551
	speed: 0.0622s/iter; left time: 1478.1878s
	iters: 200, epoch: 11 | loss: 30.0663414
	speed: 0.0622s/iter; left time: 1471.8704s
Epoch: 11 cost time: 16.90341544151306
Epoch: 11, Steps: 265 Train Loss: 30.3547 (Forecasting Loss:0.1956 + XiCon Loss:3.0159 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1585
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1470833
	speed: 0.0563s/iter; left time: 1322.9106s
	iters: 200, epoch: 12 | loss: 30.7445335
	speed: 0.0580s/iter; left time: 1357.4214s
Epoch: 12 cost time: 15.18687105178833
Epoch: 12, Steps: 265 Train Loss: 30.3818 (Forecasting Loss:0.1956 + XiCon Loss:3.0186 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1585
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2990723
	speed: 0.0677s/iter; left time: 1571.8577s
	iters: 200, epoch: 13 | loss: 30.1098614
	speed: 0.0605s/iter; left time: 1398.0130s
Epoch: 13 cost time: 17.035617351531982
Epoch: 13, Steps: 265 Train Loss: 30.3345 (Forecasting Loss:0.1955 + XiCon Loss:3.0139 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1585
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8750210
	speed: 0.0704s/iter; left time: 1616.4180s
	iters: 200, epoch: 14 | loss: 30.5852280
	speed: 0.0630s/iter; left time: 1439.1545s
Epoch: 14 cost time: 17.45388889312744
Epoch: 14, Steps: 265 Train Loss: 30.3225 (Forecasting Loss:0.1955 + XiCon Loss:3.0127 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1585
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.8638020
	speed: 0.0676s/iter; left time: 1534.6971s
	iters: 200, epoch: 15 | loss: 30.2793961
	speed: 0.0648s/iter; left time: 1464.1333s
Epoch: 15 cost time: 17.429060459136963
Epoch: 15, Steps: 265 Train Loss: 30.3442 (Forecasting Loss:0.1955 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1585
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6175480
	speed: 0.0681s/iter; left time: 1527.4186s
	iters: 200, epoch: 16 | loss: 30.0943241
	speed: 0.0589s/iter; left time: 1314.6181s
Epoch: 16 cost time: 16.72283697128296
Epoch: 16, Steps: 265 Train Loss: 30.3263 (Forecasting Loss:0.1955 + XiCon Loss:3.0131 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1585
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.1114521
	speed: 0.0698s/iter; left time: 1546.7244s
	iters: 200, epoch: 17 | loss: 30.0416279
	speed: 0.0628s/iter; left time: 1384.5451s
Epoch: 17 cost time: 17.363196849822998
Epoch: 17, Steps: 265 Train Loss: 30.3084 (Forecasting Loss:0.1955 + XiCon Loss:3.0113 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1585
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.8983917
	speed: 0.0682s/iter; left time: 1492.8709s
	iters: 200, epoch: 18 | loss: 30.6983089
	speed: 0.0578s/iter; left time: 1258.9370s
Epoch: 18 cost time: 16.346086502075195
Epoch: 18, Steps: 265 Train Loss: 30.3321 (Forecasting Loss:0.1955 + XiCon Loss:3.0137 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1585
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2329521
	speed: 0.0708s/iter; left time: 1531.6829s
	iters: 200, epoch: 19 | loss: 30.2355976
	speed: 0.0651s/iter; left time: 1401.7024s
Epoch: 19 cost time: 17.412421941757202
Epoch: 19, Steps: 265 Train Loss: 30.3258 (Forecasting Loss:0.1955 + XiCon Loss:3.0130 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1585
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09160665422677994, mae:0.22531351447105408, mape:0.5421063303947449, mspe:11.2448091506958 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.8935
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.9439697
	speed: 0.0639s/iter; left time: 1687.7324s
	iters: 200, epoch: 1 | loss: 31.9309883
	speed: 0.0678s/iter; left time: 1782.3750s
Epoch: 1 cost time: 17.13395118713379
Epoch: 1, Steps: 265 Train Loss: 32.6858 (Forecasting Loss:0.2276 + XiCon Loss:3.2458 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1675
Validation loss decreased (inf --> 0.210618).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.3224621
	speed: 0.0663s/iter; left time: 1733.3898s
	iters: 200, epoch: 2 | loss: 31.6602592
	speed: 0.0621s/iter; left time: 1616.4277s
Epoch: 2 cost time: 17.299643754959106
Epoch: 2, Steps: 265 Train Loss: 31.6707 (Forecasting Loss:0.2075 + XiCon Loss:3.1463 x Lambda(10.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1681
Validation loss decreased (0.210618 --> 0.206701).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.5362511
	speed: 0.0636s/iter; left time: 1646.5469s
	iters: 200, epoch: 3 | loss: 30.4661846
	speed: 0.0649s/iter; left time: 1672.8505s
Epoch: 3 cost time: 16.919208765029907
Epoch: 3, Steps: 265 Train Loss: 30.4649 (Forecasting Loss:0.2008 + XiCon Loss:3.0264 x Lambda(10.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1621
Validation loss decreased (0.206701 --> 0.204465).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1081429
	speed: 0.0613s/iter; left time: 1568.8324s
	iters: 200, epoch: 4 | loss: 30.0975113
	speed: 0.0575s/iter; left time: 1466.6510s
Epoch: 4 cost time: 15.772499322891235
Epoch: 4, Steps: 265 Train Loss: 30.2597 (Forecasting Loss:0.1985 + XiCon Loss:3.0061 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1613
Validation loss decreased (0.204465 --> 0.200086).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1694164
	speed: 0.0634s/iter; left time: 1606.5585s
	iters: 200, epoch: 5 | loss: 30.6552391
	speed: 0.0560s/iter; left time: 1414.5186s
Epoch: 5 cost time: 15.999652862548828
Epoch: 5, Steps: 265 Train Loss: 30.2273 (Forecasting Loss:0.1969 + XiCon Loss:3.0030 x Lambda(10.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1605
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4560852
	speed: 0.0642s/iter; left time: 1610.1041s
	iters: 200, epoch: 6 | loss: 30.1265068
	speed: 0.0556s/iter; left time: 1388.7820s
Epoch: 6 cost time: 15.213337421417236
Epoch: 6, Steps: 265 Train Loss: 30.1932 (Forecasting Loss:0.1960 + XiCon Loss:2.9997 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1593
Validation loss decreased (0.200086 --> 0.198154).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8691578
	speed: 0.0661s/iter; left time: 1639.0351s
	iters: 200, epoch: 7 | loss: 30.6815071
	speed: 0.0638s/iter; left time: 1577.1529s
Epoch: 7 cost time: 17.598265171051025
Epoch: 7, Steps: 265 Train Loss: 30.1717 (Forecasting Loss:0.1959 + XiCon Loss:2.9976 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1595
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9287891
	speed: 0.0647s/iter; left time: 1587.0332s
	iters: 200, epoch: 8 | loss: 30.1374416
	speed: 0.0617s/iter; left time: 1507.2126s
Epoch: 8 cost time: 16.927446365356445
Epoch: 8, Steps: 265 Train Loss: 30.2049 (Forecasting Loss:0.1957 + XiCon Loss:3.0009 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1591
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.2646351
	speed: 0.0684s/iter; left time: 1661.1838s
	iters: 200, epoch: 9 | loss: 30.0075665
	speed: 0.0642s/iter; left time: 1552.9221s
Epoch: 9 cost time: 17.71241545677185
Epoch: 9, Steps: 265 Train Loss: 30.1939 (Forecasting Loss:0.1956 + XiCon Loss:2.9998 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3406296
	speed: 0.0698s/iter; left time: 1675.3726s
	iters: 200, epoch: 10 | loss: 30.3540707
	speed: 0.0589s/iter; left time: 1407.7517s
Epoch: 10 cost time: 17.323077917099
Epoch: 10, Steps: 265 Train Loss: 30.1805 (Forecasting Loss:0.1955 + XiCon Loss:2.9985 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3619995
	speed: 0.0651s/iter; left time: 1546.6499s
	iters: 200, epoch: 11 | loss: 29.9752369
	speed: 0.0984s/iter; left time: 2326.4978s
Epoch: 11 cost time: 20.327192544937134
Epoch: 11, Steps: 265 Train Loss: 30.1978 (Forecasting Loss:0.1954 + XiCon Loss:3.0002 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1590
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4194450
	speed: 0.0504s/iter; left time: 1183.6962s
	iters: 200, epoch: 12 | loss: 29.8061256
	speed: 0.0600s/iter; left time: 1403.3257s
Epoch: 12 cost time: 15.226560592651367
Epoch: 12, Steps: 265 Train Loss: 30.1759 (Forecasting Loss:0.1954 + XiCon Loss:2.9981 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1590
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.3461456
	speed: 0.0663s/iter; left time: 1538.7804s
	iters: 200, epoch: 13 | loss: 30.2022781
	speed: 0.0643s/iter; left time: 1485.9031s
Epoch: 13 cost time: 17.314825534820557
Epoch: 13, Steps: 265 Train Loss: 30.1942 (Forecasting Loss:0.1954 + XiCon Loss:2.9999 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1590
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.9641418
	speed: 0.0566s/iter; left time: 1298.4486s
	iters: 200, epoch: 14 | loss: 30.4688473
	speed: 0.0613s/iter; left time: 1401.5928s
Epoch: 14 cost time: 16.202807426452637
Epoch: 14, Steps: 265 Train Loss: 30.1633 (Forecasting Loss:0.1954 + XiCon Loss:2.9968 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1590
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2558956
	speed: 0.0670s/iter; left time: 1520.9736s
	iters: 200, epoch: 15 | loss: 29.5680466
	speed: 0.0619s/iter; left time: 1398.2988s
Epoch: 15 cost time: 17.578272104263306
Epoch: 15, Steps: 265 Train Loss: 30.1829 (Forecasting Loss:0.1954 + XiCon Loss:2.9987 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1590
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1791267
	speed: 0.0633s/iter; left time: 1419.6865s
	iters: 200, epoch: 16 | loss: 29.8793678
	speed: 0.0345s/iter; left time: 770.4774s
Epoch: 16 cost time: 12.08437991142273
Epoch: 16, Steps: 265 Train Loss: 30.1975 (Forecasting Loss:0.1953 + XiCon Loss:3.0002 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1590
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09201109409332275, mae:0.2265801578760147, mape:0.555362343788147, mspe:11.826910972595215 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.1076
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.5148277
	speed: 0.0668s/iter; left time: 1763.9085s
	iters: 200, epoch: 1 | loss: 32.5395737
	speed: 0.0462s/iter; left time: 1214.7456s
Epoch: 1 cost time: 14.38279104232788
Epoch: 1, Steps: 265 Train Loss: 33.0201 (Forecasting Loss:0.2259 + XiCon Loss:3.2794 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1670
Validation loss decreased (inf --> 0.210816).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7227688
	speed: 0.0501s/iter; left time: 1310.5011s
	iters: 200, epoch: 2 | loss: 34.3233337
	speed: 0.0617s/iter; left time: 1605.7447s
Epoch: 2 cost time: 15.551700353622437
Epoch: 2, Steps: 265 Train Loss: 32.6251 (Forecasting Loss:0.2085 + XiCon Loss:3.2417 x Lambda(10.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.1646
Validation loss decreased (0.210816 --> 0.204624).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.7368431
	speed: 0.0600s/iter; left time: 1552.9830s
	iters: 200, epoch: 3 | loss: 31.5882149
	speed: 0.0596s/iter; left time: 1535.4349s
Epoch: 3 cost time: 15.964085578918457
Epoch: 3, Steps: 265 Train Loss: 32.4390 (Forecasting Loss:0.2014 + XiCon Loss:3.2238 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1627
Validation loss decreased (0.204624 --> 0.201859).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5346451
	speed: 0.0619s/iter; left time: 1585.5874s
	iters: 200, epoch: 4 | loss: 31.6556492
	speed: 0.0324s/iter; left time: 825.4248s
Epoch: 4 cost time: 12.340856790542603
Epoch: 4, Steps: 265 Train Loss: 31.8170 (Forecasting Loss:0.1984 + XiCon Loss:3.1619 x Lambda(10.0)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1619
Validation loss decreased (0.201859 --> 0.201505).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.4930668
	speed: 0.0691s/iter; left time: 1751.2161s
	iters: 200, epoch: 5 | loss: 31.3400021
	speed: 0.0644s/iter; left time: 1626.3071s
Epoch: 5 cost time: 17.482773542404175
Epoch: 5, Steps: 265 Train Loss: 31.7439 (Forecasting Loss:0.1970 + XiCon Loss:3.1547 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1595
Validation loss decreased (0.201505 --> 0.200164).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.5295658
	speed: 0.0690s/iter; left time: 1730.0981s
	iters: 200, epoch: 6 | loss: 31.4003410
	speed: 0.0585s/iter; left time: 1460.5450s
Epoch: 6 cost time: 16.181426763534546
Epoch: 6, Steps: 265 Train Loss: 31.7200 (Forecasting Loss:0.1968 + XiCon Loss:3.1523 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1596
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.8690853
	speed: 0.0505s/iter; left time: 1252.0062s
	iters: 200, epoch: 7 | loss: 31.0284100
	speed: 0.0676s/iter; left time: 1670.8220s
Epoch: 7 cost time: 15.86614441871643
Epoch: 7, Steps: 265 Train Loss: 31.7156 (Forecasting Loss:0.1963 + XiCon Loss:3.1519 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1596
Validation loss decreased (0.200164 --> 0.199055).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.7194309
	speed: 0.0652s/iter; left time: 1600.9280s
	iters: 200, epoch: 8 | loss: 31.0514088
	speed: 0.0667s/iter; left time: 1631.2023s
Epoch: 8 cost time: 17.288139820098877
Epoch: 8, Steps: 265 Train Loss: 31.7199 (Forecasting Loss:0.1960 + XiCon Loss:3.1524 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.7206764
	speed: 0.0626s/iter; left time: 1520.1976s
	iters: 200, epoch: 9 | loss: 32.4349174
	speed: 0.0650s/iter; left time: 1572.1343s
Epoch: 9 cost time: 16.810556650161743
Epoch: 9, Steps: 265 Train Loss: 31.6262 (Forecasting Loss:0.1960 + XiCon Loss:3.1430 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1591
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7724380
	speed: 0.0652s/iter; left time: 1565.7980s
	iters: 200, epoch: 10 | loss: 32.8221054
	speed: 0.0697s/iter; left time: 1667.8602s
Epoch: 10 cost time: 17.431635856628418
Epoch: 10, Steps: 265 Train Loss: 31.5830 (Forecasting Loss:0.1959 + XiCon Loss:3.1387 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6690941
	speed: 0.0628s/iter; left time: 1491.5269s
	iters: 200, epoch: 11 | loss: 32.0939713
	speed: 0.0660s/iter; left time: 1559.9389s
Epoch: 11 cost time: 16.853225708007812
Epoch: 11, Steps: 265 Train Loss: 31.6721 (Forecasting Loss:0.1959 + XiCon Loss:3.1476 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.7547054
	speed: 0.0635s/iter; left time: 1492.3509s
	iters: 200, epoch: 12 | loss: 31.4427433
	speed: 0.0657s/iter; left time: 1537.0865s
Epoch: 12 cost time: 16.795140027999878
Epoch: 12, Steps: 265 Train Loss: 31.6659 (Forecasting Loss:0.1960 + XiCon Loss:3.1470 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1591
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.3302326
	speed: 0.0600s/iter; left time: 1394.2029s
	iters: 200, epoch: 13 | loss: 32.3030853
	speed: 0.0668s/iter; left time: 1544.6600s
Epoch: 13 cost time: 17.074870109558105
Epoch: 13, Steps: 265 Train Loss: 31.6715 (Forecasting Loss:0.1959 + XiCon Loss:3.1476 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1591
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2370186
	speed: 0.0667s/iter; left time: 1530.3213s
	iters: 200, epoch: 14 | loss: 31.2677021
	speed: 0.0602s/iter; left time: 1375.9825s
Epoch: 14 cost time: 16.602859258651733
Epoch: 14, Steps: 265 Train Loss: 31.6893 (Forecasting Loss:0.1958 + XiCon Loss:3.1494 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1591
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.0506210
	speed: 0.0611s/iter; left time: 1385.7201s
	iters: 200, epoch: 15 | loss: 31.3784103
	speed: 0.0577s/iter; left time: 1304.0347s
Epoch: 15 cost time: 15.266965389251709
Epoch: 15, Steps: 265 Train Loss: 31.6572 (Forecasting Loss:0.1958 + XiCon Loss:3.1461 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1591
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.5956573
	speed: 0.0603s/iter; left time: 1352.1600s
	iters: 200, epoch: 16 | loss: 31.1500168
	speed: 0.0617s/iter; left time: 1376.8560s
Epoch: 16 cost time: 16.19677758216858
Epoch: 16, Steps: 265 Train Loss: 31.6310 (Forecasting Loss:0.1959 + XiCon Loss:3.1435 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1591
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.3719082
	speed: 0.0652s/iter; left time: 1444.0309s
	iters: 200, epoch: 17 | loss: 32.4614525
	speed: 0.0611s/iter; left time: 1348.2679s
Epoch: 17 cost time: 16.546988010406494
Epoch: 17, Steps: 265 Train Loss: 31.7167 (Forecasting Loss:0.1959 + XiCon Loss:3.1521 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1591
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09250282496213913, mae:0.22671175003051758, mape:0.5468968152999878, mspe:11.34919548034668 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.0860
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.1165352
	speed: 0.0597s/iter; left time: 1576.3547s
	iters: 200, epoch: 1 | loss: 32.1479683
	speed: 0.0643s/iter; left time: 1689.9612s
Epoch: 1 cost time: 16.42123293876648
Epoch: 1, Steps: 265 Train Loss: 32.8098 (Forecasting Loss:0.2309 + XiCon Loss:3.2579 x Lambda(10.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1680
Validation loss decreased (inf --> 0.210935).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.1230698
	speed: 0.0656s/iter; left time: 1713.8776s
	iters: 200, epoch: 2 | loss: 32.1231346
	speed: 0.0581s/iter; left time: 1512.6943s
Epoch: 2 cost time: 16.29810667037964
Epoch: 2, Steps: 265 Train Loss: 32.5567 (Forecasting Loss:0.2076 + XiCon Loss:3.2349 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1710
Validation loss decreased (0.210935 --> 0.210218).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 34.6863632
	speed: 0.0624s/iter; left time: 1614.1383s
	iters: 200, epoch: 3 | loss: 33.5899200
	speed: 0.0627s/iter; left time: 1615.8597s
Epoch: 3 cost time: 16.531092643737793
Epoch: 3, Steps: 265 Train Loss: 33.7996 (Forecasting Loss:0.2013 + XiCon Loss:3.3598 x Lambda(10.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1614
Validation loss decreased (0.210218 --> 0.202041).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.6388702
	speed: 0.0665s/iter; left time: 1701.6293s
	iters: 200, epoch: 4 | loss: 32.8831253
	speed: 0.0632s/iter; left time: 1612.2977s
Epoch: 4 cost time: 16.73694920539856
Epoch: 4, Steps: 265 Train Loss: 33.7447 (Forecasting Loss:0.1985 + XiCon Loss:3.3546 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1597
Validation loss decreased (0.202041 --> 0.200662).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.9327774
	speed: 0.0663s/iter; left time: 1680.3693s
	iters: 200, epoch: 5 | loss: 32.5129585
	speed: 0.0617s/iter; left time: 1557.7585s
Epoch: 5 cost time: 16.905916929244995
Epoch: 5, Steps: 265 Train Loss: 33.6782 (Forecasting Loss:0.1975 + XiCon Loss:3.3481 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1596
Validation loss decreased (0.200662 --> 0.199609).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.7469864
	speed: 0.0662s/iter; left time: 1659.1170s
	iters: 200, epoch: 6 | loss: 33.3537560
	speed: 0.0637s/iter; left time: 1590.3130s
Epoch: 6 cost time: 16.980123043060303
Epoch: 6, Steps: 265 Train Loss: 33.4734 (Forecasting Loss:0.1966 + XiCon Loss:3.3277 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1598
Validation loss decreased (0.199609 --> 0.199575).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.9962463
	speed: 0.0572s/iter; left time: 1420.0011s
	iters: 200, epoch: 7 | loss: 34.7694283
	speed: 0.0619s/iter; left time: 1530.1361s
Epoch: 7 cost time: 16.086397886276245
Epoch: 7, Steps: 265 Train Loss: 33.5786 (Forecasting Loss:0.1964 + XiCon Loss:3.3382 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1595
Validation loss decreased (0.199575 --> 0.199499).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.1059189
	speed: 0.0631s/iter; left time: 1547.7089s
	iters: 200, epoch: 8 | loss: 32.6016808
	speed: 0.0615s/iter; left time: 1504.4753s
Epoch: 8 cost time: 16.344091415405273
Epoch: 8, Steps: 265 Train Loss: 33.4903 (Forecasting Loss:0.1962 + XiCon Loss:3.3294 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 34.3326073
	speed: 0.0578s/iter; left time: 1404.2431s
	iters: 200, epoch: 9 | loss: 32.3012161
	speed: 0.0639s/iter; left time: 1546.0677s
Epoch: 9 cost time: 16.363775730133057
Epoch: 9, Steps: 265 Train Loss: 33.6216 (Forecasting Loss:0.1960 + XiCon Loss:3.3426 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.0011520
	speed: 0.0694s/iter; left time: 1667.1015s
	iters: 200, epoch: 10 | loss: 32.7294693
	speed: 0.0618s/iter; left time: 1476.8544s
Epoch: 10 cost time: 17.23697519302368
Epoch: 10, Steps: 265 Train Loss: 33.5689 (Forecasting Loss:0.1960 + XiCon Loss:3.3373 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 34.1581039
	speed: 0.0622s/iter; left time: 1476.4584s
	iters: 200, epoch: 11 | loss: 33.6336746
	speed: 0.0603s/iter; left time: 1426.0470s
Epoch: 11 cost time: 15.724108934402466
Epoch: 11, Steps: 265 Train Loss: 33.5068 (Forecasting Loss:0.1960 + XiCon Loss:3.3311 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1591
Validation loss decreased (0.199499 --> 0.199481).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.9485817
	speed: 0.0584s/iter; left time: 1371.7815s
	iters: 200, epoch: 12 | loss: 33.1046257
	speed: 0.0601s/iter; left time: 1406.1183s
Epoch: 12 cost time: 15.879486322402954
Epoch: 12, Steps: 265 Train Loss: 33.5256 (Forecasting Loss:0.1960 + XiCon Loss:3.3330 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.6486244
	speed: 0.0580s/iter; left time: 1346.6951s
	iters: 200, epoch: 13 | loss: 33.1845245
	speed: 0.0626s/iter; left time: 1446.8897s
Epoch: 13 cost time: 16.000242948532104
Epoch: 13, Steps: 265 Train Loss: 33.4975 (Forecasting Loss:0.1959 + XiCon Loss:3.3302 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.4986496
	speed: 0.0633s/iter; left time: 1452.9511s
	iters: 200, epoch: 14 | loss: 32.9531021
	speed: 0.0657s/iter; left time: 1502.6517s
Epoch: 14 cost time: 17.221550703048706
Epoch: 14, Steps: 265 Train Loss: 33.5482 (Forecasting Loss:0.1959 + XiCon Loss:3.3352 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.8069878
	speed: 0.0632s/iter; left time: 1434.5624s
	iters: 200, epoch: 15 | loss: 34.6548004
	speed: 0.0636s/iter; left time: 1437.5194s
Epoch: 15 cost time: 17.14495539665222
Epoch: 15, Steps: 265 Train Loss: 33.4841 (Forecasting Loss:0.1959 + XiCon Loss:3.3288 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1590
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 34.8495407
	speed: 0.0653s/iter; left time: 1463.3917s
	iters: 200, epoch: 16 | loss: 34.6270027
	speed: 0.0613s/iter; left time: 1369.1759s
Epoch: 16 cost time: 16.652390241622925
Epoch: 16, Steps: 265 Train Loss: 33.5442 (Forecasting Loss:0.1959 + XiCon Loss:3.3348 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1590
Validation loss decreased (0.199481 --> 0.199264).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.5952644
	speed: 0.0625s/iter; left time: 1385.3008s
	iters: 200, epoch: 17 | loss: 33.2018852
	speed: 0.0618s/iter; left time: 1363.1820s
Epoch: 17 cost time: 16.602431297302246
Epoch: 17, Steps: 265 Train Loss: 33.5786 (Forecasting Loss:0.1960 + XiCon Loss:3.3383 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1590
Validation loss decreased (0.199264 --> 0.199241).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.6665154
	speed: 0.0699s/iter; left time: 1531.0427s
	iters: 200, epoch: 18 | loss: 33.9778557
	speed: 0.0638s/iter; left time: 1391.5232s
Epoch: 18 cost time: 17.43344020843506
Epoch: 18, Steps: 265 Train Loss: 33.4625 (Forecasting Loss:0.1959 + XiCon Loss:3.3267 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.7251854
	speed: 0.0618s/iter; left time: 1337.6557s
	iters: 200, epoch: 19 | loss: 32.7743835
	speed: 0.0612s/iter; left time: 1318.0018s
Epoch: 19 cost time: 16.437140464782715
Epoch: 19, Steps: 265 Train Loss: 33.5026 (Forecasting Loss:0.1959 + XiCon Loss:3.3307 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 34.1432762
	speed: 0.0625s/iter; left time: 1336.1007s
	iters: 200, epoch: 20 | loss: 32.3998528
	speed: 0.0651s/iter; left time: 1385.3441s
Epoch: 20 cost time: 16.944987535476685
Epoch: 20, Steps: 265 Train Loss: 33.5906 (Forecasting Loss:0.1960 + XiCon Loss:3.3395 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.4380112
	speed: 0.0603s/iter; left time: 1271.7837s
	iters: 200, epoch: 21 | loss: 34.1882515
	speed: 0.0583s/iter; left time: 1225.2335s
Epoch: 21 cost time: 15.993280410766602
Epoch: 21, Steps: 265 Train Loss: 33.5192 (Forecasting Loss:0.1959 + XiCon Loss:3.3323 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1590
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.0136948
	speed: 0.0636s/iter; left time: 1325.1573s
	iters: 200, epoch: 22 | loss: 32.6379356
	speed: 0.0604s/iter; left time: 1252.8636s
Epoch: 22 cost time: 16.369234323501587
Epoch: 22, Steps: 265 Train Loss: 33.5053 (Forecasting Loss:0.1959 + XiCon Loss:3.3309 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1590
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 34.2005615
	speed: 0.0603s/iter; left time: 1239.5917s
	iters: 200, epoch: 23 | loss: 33.1903305
	speed: 0.0631s/iter; left time: 1290.7903s
Epoch: 23 cost time: 16.221888303756714
Epoch: 23, Steps: 265 Train Loss: 33.5657 (Forecasting Loss:0.1959 + XiCon Loss:3.3370 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1590
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.3298264
	speed: 0.0638s/iter; left time: 1295.9473s
	iters: 200, epoch: 24 | loss: 33.2733765
	speed: 0.0625s/iter; left time: 1262.3790s
Epoch: 24 cost time: 16.58213973045349
Epoch: 24, Steps: 265 Train Loss: 33.5936 (Forecasting Loss:0.1960 + XiCon Loss:3.3398 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1590
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 34.6698914
	speed: 0.0617s/iter; left time: 1236.9963s
	iters: 200, epoch: 25 | loss: 33.8760185
	speed: 0.0608s/iter; left time: 1213.1133s
Epoch: 25 cost time: 16.054417848587036
Epoch: 25, Steps: 265 Train Loss: 33.5301 (Forecasting Loss:0.1958 + XiCon Loss:3.3334 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1590
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 33.3546371
	speed: 0.0558s/iter; left time: 1103.3673s
	iters: 200, epoch: 26 | loss: 34.5912094
	speed: 0.0601s/iter; left time: 1182.6625s
Epoch: 26 cost time: 15.62386178970337
Epoch: 26, Steps: 265 Train Loss: 33.5740 (Forecasting Loss:0.1958 + XiCon Loss:3.3378 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1590
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 34.0734863
	speed: 0.0583s/iter; left time: 1137.7647s
	iters: 200, epoch: 27 | loss: 34.0354538
	speed: 0.0644s/iter; left time: 1250.8628s
Epoch: 27 cost time: 16.088863849639893
Epoch: 27, Steps: 265 Train Loss: 33.5412 (Forecasting Loss:0.1959 + XiCon Loss:3.3345 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1590
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09212513267993927, mae:0.2259407490491867, mape:0.5430355668067932, mspe:11.189972877502441 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.2516
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.1889458
	speed: 0.0529s/iter; left time: 1397.3408s
	iters: 200, epoch: 1 | loss: 32.2962608
	speed: 0.0465s/iter; left time: 1222.2561s
Epoch: 1 cost time: 16.811274528503418
Epoch: 1, Steps: 265 Train Loss: 32.7543 (Forecasting Loss:0.2272 + XiCon Loss:3.2527 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1680
Validation loss decreased (inf --> 0.210283).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.0630302
	speed: 0.0473s/iter; left time: 1236.1630s
	iters: 200, epoch: 2 | loss: 33.9146347
	speed: 0.0337s/iter; left time: 878.3733s
Epoch: 2 cost time: 11.48249626159668
Epoch: 2, Steps: 265 Train Loss: 32.8251 (Forecasting Loss:0.2087 + XiCon Loss:3.2616 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1680
Validation loss decreased (0.210283 --> 0.207523).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.9221115
	speed: 0.0668s/iter; left time: 1728.7964s
	iters: 200, epoch: 3 | loss: 32.6728172
	speed: 0.0606s/iter; left time: 1560.9670s
Epoch: 3 cost time: 16.706157207489014
Epoch: 3, Steps: 265 Train Loss: 33.6742 (Forecasting Loss:0.2013 + XiCon Loss:3.3473 x Lambda(10.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1640
Validation loss decreased (0.207523 --> 0.204237).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.1274796
	speed: 0.0642s/iter; left time: 1643.3256s
	iters: 200, epoch: 4 | loss: 32.1612930
	speed: 0.0632s/iter; left time: 1612.7559s
Epoch: 4 cost time: 15.811135292053223
Epoch: 4, Steps: 265 Train Loss: 33.4633 (Forecasting Loss:0.1985 + XiCon Loss:3.3265 x Lambda(10.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1597
Validation loss decreased (0.204237 --> 0.200989).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.7624931
	speed: 0.0631s/iter; left time: 1598.2822s
	iters: 200, epoch: 5 | loss: 33.6756592
	speed: 0.0603s/iter; left time: 1520.9169s
Epoch: 5 cost time: 16.4981529712677
Epoch: 5, Steps: 265 Train Loss: 33.1445 (Forecasting Loss:0.1971 + XiCon Loss:3.2947 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1604
Validation loss decreased (0.200989 --> 0.200643).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.2431335
	speed: 0.0612s/iter; left time: 1535.6305s
	iters: 200, epoch: 6 | loss: 33.8700333
	speed: 0.0601s/iter; left time: 1501.4782s
Epoch: 6 cost time: 15.044095277786255
Epoch: 6, Steps: 265 Train Loss: 33.2731 (Forecasting Loss:0.1962 + XiCon Loss:3.3077 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1603
Validation loss decreased (0.200643 --> 0.199234).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.6149635
	speed: 0.0471s/iter; left time: 1168.3180s
	iters: 200, epoch: 7 | loss: 33.6232605
	speed: 0.0654s/iter; left time: 1615.5838s
Epoch: 7 cost time: 15.147181510925293
Epoch: 7, Steps: 265 Train Loss: 33.2800 (Forecasting Loss:0.1959 + XiCon Loss:3.3084 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1603
Validation loss decreased (0.199234 --> 0.198928).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.6262474
	speed: 0.0643s/iter; left time: 1579.1831s
	iters: 200, epoch: 8 | loss: 33.5621681
	speed: 0.0652s/iter; left time: 1594.9970s
Epoch: 8 cost time: 16.53235673904419
Epoch: 8, Steps: 265 Train Loss: 33.2589 (Forecasting Loss:0.1954 + XiCon Loss:3.3064 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1602
Validation loss decreased (0.198928 --> 0.198489).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.8880959
	speed: 0.0440s/iter; left time: 1069.1983s
	iters: 200, epoch: 9 | loss: 33.5840034
	speed: 0.0309s/iter; left time: 748.1730s
Epoch: 9 cost time: 11.470401525497437
Epoch: 9, Steps: 265 Train Loss: 33.2361 (Forecasting Loss:0.1955 + XiCon Loss:3.3041 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1604
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.1584778
	speed: 0.0654s/iter; left time: 1570.4529s
	iters: 200, epoch: 10 | loss: 32.8616867
	speed: 0.0599s/iter; left time: 1433.0047s
Epoch: 10 cost time: 16.544798612594604
Epoch: 10, Steps: 265 Train Loss: 33.1950 (Forecasting Loss:0.1952 + XiCon Loss:3.3000 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1604
Validation loss decreased (0.198489 --> 0.198385).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.8730202
	speed: 0.0627s/iter; left time: 1488.4925s
	iters: 200, epoch: 11 | loss: 33.6063156
	speed: 0.0499s/iter; left time: 1179.0776s
Epoch: 11 cost time: 15.568445920944214
Epoch: 11, Steps: 265 Train Loss: 33.1914 (Forecasting Loss:0.1954 + XiCon Loss:3.2996 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.2624168
	speed: 0.0634s/iter; left time: 1488.3665s
	iters: 200, epoch: 12 | loss: 33.3942299
	speed: 0.0602s/iter; left time: 1408.2713s
Epoch: 12 cost time: 16.403870820999146
Epoch: 12, Steps: 265 Train Loss: 33.2237 (Forecasting Loss:0.1952 + XiCon Loss:3.3028 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.3993835
	speed: 0.0534s/iter; left time: 1239.7122s
	iters: 200, epoch: 13 | loss: 32.4944000
	speed: 0.0355s/iter; left time: 821.0925s
Epoch: 13 cost time: 10.926882028579712
Epoch: 13, Steps: 265 Train Loss: 33.2408 (Forecasting Loss:0.1954 + XiCon Loss:3.3045 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
Validation loss decreased (0.198385 --> 0.198356).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.5750961
	speed: 0.0640s/iter; left time: 1468.8177s
	iters: 200, epoch: 14 | loss: 33.4100227
	speed: 0.0614s/iter; left time: 1403.4205s
Epoch: 14 cost time: 16.822572469711304
Epoch: 14, Steps: 265 Train Loss: 33.2875 (Forecasting Loss:0.1953 + XiCon Loss:3.3092 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.5744514
	speed: 0.0621s/iter; left time: 1409.1534s
	iters: 200, epoch: 15 | loss: 32.7817841
	speed: 0.0573s/iter; left time: 1294.2712s
Epoch: 15 cost time: 15.65423846244812
Epoch: 15, Steps: 265 Train Loss: 33.1936 (Forecasting Loss:0.1953 + XiCon Loss:3.2998 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1603
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.3978500
	speed: 0.0651s/iter; left time: 1460.0801s
	iters: 200, epoch: 16 | loss: 32.8478508
	speed: 0.0579s/iter; left time: 1292.5361s
Epoch: 16 cost time: 16.575573444366455
Epoch: 16, Steps: 265 Train Loss: 33.2752 (Forecasting Loss:0.1954 + XiCon Loss:3.3080 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
Validation loss decreased (0.198356 --> 0.198354).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.9425659
	speed: 0.0638s/iter; left time: 1414.2908s
	iters: 200, epoch: 17 | loss: 33.6895103
	speed: 0.0569s/iter; left time: 1255.8218s
Epoch: 17 cost time: 15.890961408615112
Epoch: 17, Steps: 265 Train Loss: 33.2707 (Forecasting Loss:0.1953 + XiCon Loss:3.3075 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.9514542
	speed: 0.0627s/iter; left time: 1373.6925s
	iters: 200, epoch: 18 | loss: 32.9290886
	speed: 0.0627s/iter; left time: 1366.3613s
Epoch: 18 cost time: 16.608725786209106
Epoch: 18, Steps: 265 Train Loss: 33.1959 (Forecasting Loss:0.1954 + XiCon Loss:3.3001 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.4242439
	speed: 0.0617s/iter; left time: 1335.7108s
	iters: 200, epoch: 19 | loss: 32.3199539
	speed: 0.0567s/iter; left time: 1221.6732s
Epoch: 19 cost time: 15.906636238098145
Epoch: 19, Steps: 265 Train Loss: 33.2260 (Forecasting Loss:0.1954 + XiCon Loss:3.3031 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.7347527
	speed: 0.0629s/iter; left time: 1344.7012s
	iters: 200, epoch: 20 | loss: 33.1247864
	speed: 0.0617s/iter; left time: 1312.5155s
Epoch: 20 cost time: 16.293102979660034
Epoch: 20, Steps: 265 Train Loss: 33.2377 (Forecasting Loss:0.1952 + XiCon Loss:3.3042 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.3008804
	speed: 0.0625s/iter; left time: 1318.0393s
	iters: 200, epoch: 21 | loss: 32.8516235
	speed: 0.0561s/iter; left time: 1177.8048s
Epoch: 21 cost time: 15.604934453964233
Epoch: 21, Steps: 265 Train Loss: 33.2601 (Forecasting Loss:0.1952 + XiCon Loss:3.3065 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.1048279
	speed: 0.0657s/iter; left time: 1369.5851s
	iters: 200, epoch: 22 | loss: 33.1924553
	speed: 0.0607s/iter; left time: 1258.7261s
Epoch: 22 cost time: 16.571475744247437
Epoch: 22, Steps: 265 Train Loss: 33.2405 (Forecasting Loss:0.1952 + XiCon Loss:3.3045 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1603
Validation loss decreased (0.198354 --> 0.198343).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.6207657
	speed: 0.0639s/iter; left time: 1315.1629s
	iters: 200, epoch: 23 | loss: 33.4928513
	speed: 0.0618s/iter; left time: 1264.4146s
Epoch: 23 cost time: 16.483520984649658
Epoch: 23, Steps: 265 Train Loss: 33.2254 (Forecasting Loss:0.1952 + XiCon Loss:3.3030 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1603
Validation loss decreased (0.198343 --> 0.198299).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.3026428
	speed: 0.0632s/iter; left time: 1283.3937s
	iters: 200, epoch: 24 | loss: 32.8357697
	speed: 0.0629s/iter; left time: 1270.7431s
Epoch: 24 cost time: 16.902658700942993
Epoch: 24, Steps: 265 Train Loss: 33.2892 (Forecasting Loss:0.1952 + XiCon Loss:3.3094 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.9895058
	speed: 0.0644s/iter; left time: 1290.3341s
	iters: 200, epoch: 25 | loss: 33.4149895
	speed: 0.0590s/iter; left time: 1176.4389s
Epoch: 25 cost time: 16.4560284614563
Epoch: 25, Steps: 265 Train Loss: 33.2491 (Forecasting Loss:0.1951 + XiCon Loss:3.3054 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 33.7064972
	speed: 0.0654s/iter; left time: 1292.6290s
	iters: 200, epoch: 26 | loss: 33.0297203
	speed: 0.0587s/iter; left time: 1154.2476s
Epoch: 26 cost time: 16.194197177886963
Epoch: 26, Steps: 265 Train Loss: 33.2350 (Forecasting Loss:0.1952 + XiCon Loss:3.3040 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 33.2958336
	speed: 0.0637s/iter; left time: 1242.3009s
	iters: 200, epoch: 27 | loss: 33.7467079
	speed: 0.0472s/iter; left time: 916.5260s
Epoch: 27 cost time: 14.616108179092407
Epoch: 27, Steps: 265 Train Loss: 33.2021 (Forecasting Loss:0.1952 + XiCon Loss:3.3007 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 33.1577110
	speed: 0.0641s/iter; left time: 1233.4096s
	iters: 200, epoch: 28 | loss: 34.1207504
	speed: 0.0607s/iter; left time: 1162.0361s
Epoch: 28 cost time: 16.480188846588135
Epoch: 28, Steps: 265 Train Loss: 33.1722 (Forecasting Loss:0.1953 + XiCon Loss:3.2977 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1603
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 33.1557655
	speed: 0.0556s/iter; left time: 1055.8889s
	iters: 200, epoch: 29 | loss: 34.5219650
	speed: 0.0507s/iter; left time: 956.4573s
Epoch: 29 cost time: 14.426334857940674
Epoch: 29, Steps: 265 Train Loss: 33.2642 (Forecasting Loss:0.1953 + XiCon Loss:3.3069 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1603
Validation loss decreased (0.198299 --> 0.198289).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 31.7993793
	speed: 0.0657s/iter; left time: 1228.7606s
	iters: 200, epoch: 30 | loss: 32.2491875
	speed: 0.0606s/iter; left time: 1127.7382s
Epoch: 30 cost time: 16.859665870666504
Epoch: 30, Steps: 265 Train Loss: 33.1993 (Forecasting Loss:0.1952 + XiCon Loss:3.3004 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 33.0564499
	speed: 0.0625s/iter; left time: 1153.9519s
	iters: 200, epoch: 31 | loss: 33.4263763
	speed: 0.0583s/iter; left time: 1070.6854s
Epoch: 31 cost time: 16.040157556533813
Epoch: 31, Steps: 265 Train Loss: 33.2092 (Forecasting Loss:0.1953 + XiCon Loss:3.3014 x Lambda(10.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1603
Validation loss decreased (0.198289 --> 0.197914).  Saving model ...
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 32.9596329
	speed: 0.0616s/iter; left time: 1120.4474s
	iters: 200, epoch: 32 | loss: 32.1707306
	speed: 0.0600s/iter; left time: 1085.6850s
Epoch: 32 cost time: 16.150779247283936
Epoch: 32, Steps: 265 Train Loss: 33.2406 (Forecasting Loss:0.1952 + XiCon Loss:3.3045 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 33.4654236
	speed: 0.0673s/iter; left time: 1205.5276s
	iters: 200, epoch: 33 | loss: 32.8587189
	speed: 0.0618s/iter; left time: 1100.9963s
Epoch: 33 cost time: 16.7206072807312
Epoch: 33, Steps: 265 Train Loss: 33.1886 (Forecasting Loss:0.1953 + XiCon Loss:3.2993 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1603
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 32.1924515
	speed: 0.0625s/iter; left time: 1104.0206s
	iters: 200, epoch: 34 | loss: 32.8345947
	speed: 0.0615s/iter; left time: 1079.8222s
Epoch: 34 cost time: 16.439981937408447
Epoch: 34, Steps: 265 Train Loss: 33.2897 (Forecasting Loss:0.1953 + XiCon Loss:3.3094 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1603
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 32.3165779
	speed: 0.0624s/iter; left time: 1085.6351s
	iters: 200, epoch: 35 | loss: 32.2586060
	speed: 0.0622s/iter; left time: 1074.7583s
Epoch: 35 cost time: 16.44955015182495
Epoch: 35, Steps: 265 Train Loss: 33.2578 (Forecasting Loss:0.1953 + XiCon Loss:3.3063 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 32.4940186
	speed: 0.0652s/iter; left time: 1117.1133s
	iters: 200, epoch: 36 | loss: 32.5204277
	speed: 0.0633s/iter; left time: 1077.6489s
Epoch: 36 cost time: 17.09448528289795
Epoch: 36, Steps: 265 Train Loss: 33.2119 (Forecasting Loss:0.1951 + XiCon Loss:3.3017 x Lambda(10.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1603
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 32.8025475
	speed: 0.0572s/iter; left time: 964.4398s
	iters: 200, epoch: 37 | loss: 33.1675911
	speed: 0.0590s/iter; left time: 988.7061s
Epoch: 37 cost time: 15.616226196289062
Epoch: 37, Steps: 265 Train Loss: 33.2931 (Forecasting Loss:0.1952 + XiCon Loss:3.3098 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 33.4735756
	speed: 0.0684s/iter; left time: 1135.4275s
	iters: 200, epoch: 38 | loss: 34.2709808
	speed: 0.0616s/iter; left time: 1015.9519s
Epoch: 38 cost time: 16.83986735343933
Epoch: 38, Steps: 265 Train Loss: 33.2860 (Forecasting Loss:0.1952 + XiCon Loss:3.3091 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1603
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 33.9289322
	speed: 0.0615s/iter; left time: 1004.9383s
	iters: 200, epoch: 39 | loss: 33.3358498
	speed: 0.0644s/iter; left time: 1045.6183s
Epoch: 39 cost time: 16.634876012802124
Epoch: 39, Steps: 265 Train Loss: 33.3012 (Forecasting Loss:0.1952 + XiCon Loss:3.3106 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1603
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 33.1070137
	speed: 0.0650s/iter; left time: 1044.1582s
	iters: 200, epoch: 40 | loss: 33.0788879
	speed: 0.0665s/iter; left time: 1061.5698s
Epoch: 40 cost time: 16.968947172164917
Epoch: 40, Steps: 265 Train Loss: 33.2000 (Forecasting Loss:0.1953 + XiCon Loss:3.3005 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1603
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-15
	iters: 100, epoch: 41 | loss: 32.2714996
	speed: 0.0598s/iter; left time: 945.6707s
	iters: 200, epoch: 41 | loss: 33.4610901
	speed: 0.0605s/iter; left time: 950.2873s
Epoch: 41 cost time: 16.11347270011902
Epoch: 41, Steps: 265 Train Loss: 33.2153 (Forecasting Loss:0.1952 + XiCon Loss:3.3020 x Lambda(10.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1603
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09323851764202118, mae:0.2274482250213623, mape:0.5459405779838562, mspe:11.298677444458008 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0923+-0.00076, MAE:0.2264+-0.00100, MAPE:0.5467+-0.00652, MSPE:11.3819+-0.31757, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.0748
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4597937
	speed: 0.0823s/iter; left time: 2098.2514s
	iters: 200, epoch: 1 | loss: 0.4942798
	speed: 0.0785s/iter; left time: 1994.9961s
Epoch: 1 cost time: 20.699224948883057
Epoch: 1, Steps: 256 Train Loss: 0.4681 (Forecasting Loss:0.4343 + XiCon Loss:3.3763 x Lambda(0.01)), Vali MSE Loss: 0.4131 Test MSE Loss: 0.3830
Validation loss decreased (inf --> 0.413082).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3595773
	speed: 0.0755s/iter; left time: 1905.6265s
	iters: 200, epoch: 2 | loss: 0.3664336
	speed: 0.0731s/iter; left time: 1837.0309s
Epoch: 2 cost time: 19.679287433624268
Epoch: 2, Steps: 256 Train Loss: 0.3730 (Forecasting Loss:0.3394 + XiCon Loss:3.3655 x Lambda(0.01)), Vali MSE Loss: 0.3278 Test MSE Loss: 0.3039
Validation loss decreased (0.413082 --> 0.327803).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3499241
	speed: 0.0824s/iter; left time: 2059.7208s
	iters: 200, epoch: 3 | loss: 0.3556211
	speed: 0.0828s/iter; left time: 2061.3333s
Epoch: 3 cost time: 20.65392518043518
Epoch: 3, Steps: 256 Train Loss: 0.3491 (Forecasting Loss:0.3156 + XiCon Loss:3.3520 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.3006
Validation loss decreased (0.327803 --> 0.320466).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3545968
	speed: 0.0909s/iter; left time: 2249.4252s
	iters: 200, epoch: 4 | loss: 0.3490763
	speed: 0.0846s/iter; left time: 2083.1466s
Epoch: 4 cost time: 22.14400053024292
Epoch: 4, Steps: 256 Train Loss: 0.3465 (Forecasting Loss:0.3130 + XiCon Loss:3.3507 x Lambda(0.01)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.3001
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3566172
	speed: 0.0820s/iter; left time: 2006.6866s
	iters: 200, epoch: 5 | loss: 0.3667912
	speed: 0.0776s/iter; left time: 1892.0929s
Epoch: 5 cost time: 20.507405996322632
Epoch: 5, Steps: 256 Train Loss: 0.3455 (Forecasting Loss:0.3120 + XiCon Loss:3.3495 x Lambda(0.01)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.3000
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3353120
	speed: 0.0851s/iter; left time: 2062.2854s
	iters: 200, epoch: 6 | loss: 0.3198713
	speed: 0.0824s/iter; left time: 1988.1752s
Epoch: 6 cost time: 21.36161184310913
Epoch: 6, Steps: 256 Train Loss: 0.3450 (Forecasting Loss:0.3115 + XiCon Loss:3.3491 x Lambda(0.01)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2996
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3633181
	speed: 0.0841s/iter; left time: 2014.8829s
	iters: 200, epoch: 7 | loss: 0.3339209
	speed: 0.0836s/iter; left time: 1994.4816s
Epoch: 7 cost time: 21.797739267349243
Epoch: 7, Steps: 256 Train Loss: 0.3448 (Forecasting Loss:0.3113 + XiCon Loss:3.3493 x Lambda(0.01)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2995
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3421902
	speed: 0.0782s/iter; left time: 1854.7477s
	iters: 200, epoch: 8 | loss: 0.3270984
	speed: 0.0706s/iter; left time: 1666.7429s
Epoch: 8 cost time: 17.43443489074707
Epoch: 8, Steps: 256 Train Loss: 0.3447 (Forecasting Loss:0.3113 + XiCon Loss:3.3497 x Lambda(0.01)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2996
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3745891
	speed: 0.1234s/iter; left time: 2894.3129s
	iters: 200, epoch: 9 | loss: 0.3463178
	speed: 0.0729s/iter; left time: 1701.8085s
Epoch: 9 cost time: 22.23853325843811
Epoch: 9, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3501 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3491177
	speed: 0.0829s/iter; left time: 1922.4507s
	iters: 200, epoch: 10 | loss: 0.3560654
	speed: 0.0848s/iter; left time: 1957.6494s
Epoch: 10 cost time: 21.46263289451599
Epoch: 10, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3487 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3549280
	speed: 0.0828s/iter; left time: 1900.6415s
	iters: 200, epoch: 11 | loss: 0.3616199
	speed: 0.0816s/iter; left time: 1864.0125s
Epoch: 11 cost time: 20.411866664886475
Epoch: 11, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3501 x Lambda(0.01)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2996
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3509156
	speed: 0.0850s/iter; left time: 1927.8303s
	iters: 200, epoch: 12 | loss: 0.3345410
	speed: 0.0821s/iter; left time: 1853.8326s
Epoch: 12 cost time: 21.623372793197632
Epoch: 12, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3496 x Lambda(0.01)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2996
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3523008
	speed: 0.0816s/iter; left time: 1829.4707s
	iters: 200, epoch: 13 | loss: 0.3430568
	speed: 0.0808s/iter; left time: 1804.3884s
Epoch: 13 cost time: 20.930058002471924
Epoch: 13, Steps: 256 Train Loss: 0.3446 (Forecasting Loss:0.3111 + XiCon Loss:3.3503 x Lambda(0.01)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2996
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22695432603359222, mae:0.3742711842060089, mape:0.7468461990356445, mspe:18.98110580444336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 21.2296
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.5325575
	speed: 0.0808s/iter; left time: 2059.7651s
	iters: 200, epoch: 1 | loss: 0.4550280
	speed: 0.0756s/iter; left time: 1919.6961s
Epoch: 1 cost time: 20.540189027786255
Epoch: 1, Steps: 256 Train Loss: 0.4691 (Forecasting Loss:0.4349 + XiCon Loss:3.4199 x Lambda(0.01)), Vali MSE Loss: 0.4158 Test MSE Loss: 0.3855
Validation loss decreased (inf --> 0.415774).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3550091
	speed: 0.0758s/iter; left time: 1912.3817s
	iters: 200, epoch: 2 | loss: 0.3408517
	speed: 0.0508s/iter; left time: 1277.0940s
Epoch: 2 cost time: 14.796023845672607
Epoch: 2, Steps: 256 Train Loss: 0.3798 (Forecasting Loss:0.3460 + XiCon Loss:3.3737 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2977
Validation loss decreased (0.415774 --> 0.316163).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3586735
	speed: 0.0787s/iter; left time: 1966.6063s
	iters: 200, epoch: 3 | loss: 0.3504467
	speed: 0.0765s/iter; left time: 1903.7389s
Epoch: 3 cost time: 20.169369220733643
Epoch: 3, Steps: 256 Train Loss: 0.3509 (Forecasting Loss:0.3174 + XiCon Loss:3.3496 x Lambda(0.01)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2951
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3484678
	speed: 0.0852s/iter; left time: 2106.6169s
	iters: 200, epoch: 4 | loss: 0.3509644
	speed: 0.0731s/iter; left time: 1800.5686s
Epoch: 4 cost time: 20.330063819885254
Epoch: 4, Steps: 256 Train Loss: 0.3479 (Forecasting Loss:0.3145 + XiCon Loss:3.3474 x Lambda(0.01)), Vali MSE Loss: 0.3156 Test MSE Loss: 0.2944
Validation loss decreased (0.316163 --> 0.315619).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3901722
	speed: 0.0847s/iter; left time: 2072.7608s
	iters: 200, epoch: 5 | loss: 0.3606284
	speed: 0.0822s/iter; left time: 2004.1092s
Epoch: 5 cost time: 21.096679210662842
Epoch: 5, Steps: 256 Train Loss: 0.3469 (Forecasting Loss:0.3134 + XiCon Loss:3.3468 x Lambda(0.01)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3541721
	speed: 0.0835s/iter; left time: 2022.3188s
	iters: 200, epoch: 6 | loss: 0.3350490
	speed: 0.0786s/iter; left time: 1895.4220s
Epoch: 6 cost time: 20.189321756362915
Epoch: 6, Steps: 256 Train Loss: 0.3464 (Forecasting Loss:0.3129 + XiCon Loss:3.3451 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2940
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3382017
	speed: 0.0816s/iter; left time: 1955.9503s
	iters: 200, epoch: 7 | loss: 0.3496910
	speed: 0.0778s/iter; left time: 1855.7309s
Epoch: 7 cost time: 20.833232164382935
Epoch: 7, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3457 x Lambda(0.01)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2940
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3680489
	speed: 0.0807s/iter; left time: 1912.7560s
	iters: 200, epoch: 8 | loss: 0.3397509
	speed: 0.0778s/iter; left time: 1837.6321s
Epoch: 8 cost time: 19.64432954788208
Epoch: 8, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3451 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3268842
	speed: 0.0750s/iter; left time: 1760.0801s
	iters: 200, epoch: 9 | loss: 0.3670520
	speed: 0.0754s/iter; left time: 1761.4509s
Epoch: 9 cost time: 19.330350399017334
Epoch: 9, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3449 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3760346
	speed: 0.0873s/iter; left time: 2025.7140s
	iters: 200, epoch: 10 | loss: 0.3375864
	speed: 0.0818s/iter; left time: 1889.4519s
Epoch: 10 cost time: 20.99436354637146
Epoch: 10, Steps: 256 Train Loss: 0.3458 (Forecasting Loss:0.3124 + XiCon Loss:3.3455 x Lambda(0.01)), Vali MSE Loss: 0.3164 Test MSE Loss: 0.2939
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3629217
	speed: 0.0780s/iter; left time: 1788.2952s
	iters: 200, epoch: 11 | loss: 0.3477456
	speed: 0.0820s/iter; left time: 1873.8084s
Epoch: 11 cost time: 20.26155400276184
Epoch: 11, Steps: 256 Train Loss: 0.3458 (Forecasting Loss:0.3124 + XiCon Loss:3.3438 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3275627
	speed: 0.0851s/iter; left time: 1931.3978s
	iters: 200, epoch: 12 | loss: 0.3375014
	speed: 0.0785s/iter; left time: 1773.9775s
Epoch: 12 cost time: 20.562400102615356
Epoch: 12, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3452 x Lambda(0.01)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.2939
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3403607
	speed: 0.0842s/iter; left time: 1887.6291s
	iters: 200, epoch: 13 | loss: 0.3806778
	speed: 0.0786s/iter; left time: 1755.5535s
Epoch: 13 cost time: 20.696990489959717
Epoch: 13, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3450 x Lambda(0.01)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.2939
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3473841
	speed: 0.0801s/iter; left time: 1776.2804s
	iters: 200, epoch: 14 | loss: 0.3403091
	speed: 0.0767s/iter; left time: 1692.9726s
Epoch: 14 cost time: 19.669158458709717
Epoch: 14, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3124 + XiCon Loss:3.3468 x Lambda(0.01)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2939
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22010526061058044, mae:0.3687763214111328, mape:0.7495585083961487, mspe:19.59543800354004 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 23.3667
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4388419
	speed: 0.0871s/iter; left time: 2221.9764s
	iters: 200, epoch: 1 | loss: 0.4396994
	speed: 0.0876s/iter; left time: 2224.8038s
Epoch: 1 cost time: 22.60159206390381
Epoch: 1, Steps: 256 Train Loss: 0.4657 (Forecasting Loss:0.4320 + XiCon Loss:3.3747 x Lambda(0.01)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3812
Validation loss decreased (inf --> 0.411456).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3664501
	speed: 0.0815s/iter; left time: 2058.6987s
	iters: 200, epoch: 2 | loss: 0.3539749
	speed: 0.0846s/iter; left time: 2127.9844s
Epoch: 2 cost time: 21.27786159515381
Epoch: 2, Steps: 256 Train Loss: 0.3771 (Forecasting Loss:0.3436 + XiCon Loss:3.3538 x Lambda(0.01)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.3001
Validation loss decreased (0.411456 --> 0.330535).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3473403
	speed: 0.0888s/iter; left time: 2219.7612s
	iters: 200, epoch: 3 | loss: 0.3369035
	speed: 0.0792s/iter; left time: 1972.1301s
Epoch: 3 cost time: 21.32974338531494
Epoch: 3, Steps: 256 Train Loss: 0.3505 (Forecasting Loss:0.3171 + XiCon Loss:3.3410 x Lambda(0.01)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2960
Validation loss decreased (0.330535 --> 0.321183).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3309548
	speed: 0.0842s/iter; left time: 2081.7504s
	iters: 200, epoch: 4 | loss: 0.3603208
	speed: 0.0841s/iter; left time: 2071.1886s
Epoch: 4 cost time: 21.575902938842773
Epoch: 4, Steps: 256 Train Loss: 0.3479 (Forecasting Loss:0.3145 + XiCon Loss:3.3408 x Lambda(0.01)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.2969
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3740544
	speed: 0.0928s/iter; left time: 2270.3096s
	iters: 200, epoch: 5 | loss: 0.3529109
	speed: 0.0851s/iter; left time: 2073.3951s
Epoch: 5 cost time: 22.652339696884155
Epoch: 5, Steps: 256 Train Loss: 0.3469 (Forecasting Loss:0.3135 + XiCon Loss:3.3411 x Lambda(0.01)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2963
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3244809
	speed: 0.0876s/iter; left time: 2120.7026s
	iters: 200, epoch: 6 | loss: 0.3450604
	speed: 0.0841s/iter; left time: 2029.3232s
Epoch: 6 cost time: 21.971104860305786
Epoch: 6, Steps: 256 Train Loss: 0.3464 (Forecasting Loss:0.3130 + XiCon Loss:3.3375 x Lambda(0.01)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2966
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3382589
	speed: 0.0885s/iter; left time: 2121.6578s
	iters: 200, epoch: 7 | loss: 0.3520672
	speed: 0.0829s/iter; left time: 1977.8042s
Epoch: 7 cost time: 21.562079668045044
Epoch: 7, Steps: 256 Train Loss: 0.3462 (Forecasting Loss:0.3128 + XiCon Loss:3.3401 x Lambda(0.01)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2967
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3425137
	speed: 0.0930s/iter; left time: 2204.6557s
	iters: 200, epoch: 8 | loss: 0.3405903
	speed: 0.0838s/iter; left time: 1977.4018s
Epoch: 8 cost time: 22.60772943496704
Epoch: 8, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3378 x Lambda(0.01)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2965
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3355669
	speed: 0.0880s/iter; left time: 2062.7328s
	iters: 200, epoch: 9 | loss: 0.3357329
	speed: 0.0872s/iter; left time: 2035.2334s
Epoch: 9 cost time: 22.159560203552246
Epoch: 9, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3392 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3766266
	speed: 0.0913s/iter; left time: 2117.7042s
	iters: 200, epoch: 10 | loss: 0.3593146
	speed: 0.0832s/iter; left time: 1922.5163s
Epoch: 10 cost time: 22.76487898826599
Epoch: 10, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3125 + XiCon Loss:3.3390 x Lambda(0.01)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2965
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3748458
	speed: 0.0841s/iter; left time: 1929.0715s
	iters: 200, epoch: 11 | loss: 0.3622197
	speed: 0.0868s/iter; left time: 1981.5746s
Epoch: 11 cost time: 21.58408832550049
Epoch: 11, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3125 + XiCon Loss:3.3403 x Lambda(0.01)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2965
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3191658
	speed: 0.0865s/iter; left time: 1961.4389s
	iters: 200, epoch: 12 | loss: 0.3360857
	speed: 0.0878s/iter; left time: 1983.9489s
Epoch: 12 cost time: 21.96508479118347
Epoch: 12, Steps: 256 Train Loss: 0.3459 (Forecasting Loss:0.3125 + XiCon Loss:3.3402 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3640258
	speed: 0.0817s/iter; left time: 1833.1250s
	iters: 200, epoch: 13 | loss: 0.3593566
	speed: 0.0870s/iter; left time: 1941.5327s
Epoch: 13 cost time: 21.793959856033325
Epoch: 13, Steps: 256 Train Loss: 0.3460 (Forecasting Loss:0.3126 + XiCon Loss:3.3400 x Lambda(0.01)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2965
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22188453376293182, mae:0.37006741762161255, mape:0.7376893162727356, mspe:18.823774337768555 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.3751
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4658884
	speed: 0.0733s/iter; left time: 1868.8584s
	iters: 200, epoch: 1 | loss: 0.4497345
	speed: 0.0711s/iter; left time: 1807.1982s
Epoch: 1 cost time: 18.824143409729004
Epoch: 1, Steps: 256 Train Loss: 0.4657 (Forecasting Loss:0.4319 + XiCon Loss:3.3817 x Lambda(0.01)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3766
Validation loss decreased (inf --> 0.405968).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3620114
	speed: 0.0798s/iter; left time: 2015.0592s
	iters: 200, epoch: 2 | loss: 0.3726897
	speed: 0.0773s/iter; left time: 1942.8460s
Epoch: 2 cost time: 19.894809246063232
Epoch: 2, Steps: 256 Train Loss: 0.3785 (Forecasting Loss:0.3449 + XiCon Loss:3.3532 x Lambda(0.01)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3028
Validation loss decreased (0.405968 --> 0.338513).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3530533
	speed: 0.0789s/iter; left time: 1970.8655s
	iters: 200, epoch: 3 | loss: 0.3483055
	speed: 0.0706s/iter; left time: 1757.5864s
Epoch: 3 cost time: 19.06680679321289
Epoch: 3, Steps: 256 Train Loss: 0.3564 (Forecasting Loss:0.3230 + XiCon Loss:3.3373 x Lambda(0.01)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.2995
Validation loss decreased (0.338513 --> 0.334844).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3656766
	speed: 0.0791s/iter; left time: 1955.5223s
	iters: 200, epoch: 4 | loss: 0.3595839
	speed: 0.0780s/iter; left time: 1920.1583s
Epoch: 4 cost time: 20.506101369857788
Epoch: 4, Steps: 256 Train Loss: 0.3528 (Forecasting Loss:0.3195 + XiCon Loss:3.3301 x Lambda(0.01)), Vali MSE Loss: 0.3321 Test MSE Loss: 0.2985
Validation loss decreased (0.334844 --> 0.332081).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3502494
	speed: 0.0759s/iter; left time: 1858.0915s
	iters: 200, epoch: 5 | loss: 0.3554369
	speed: 0.0694s/iter; left time: 1691.9919s
Epoch: 5 cost time: 18.602147817611694
Epoch: 5, Steps: 256 Train Loss: 0.3514 (Forecasting Loss:0.3181 + XiCon Loss:3.3271 x Lambda(0.01)), Vali MSE Loss: 0.3302 Test MSE Loss: 0.2977
Validation loss decreased (0.332081 --> 0.330214).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3400291
	speed: 0.0861s/iter; left time: 2085.2088s
	iters: 200, epoch: 6 | loss: 0.3630057
	speed: 0.0696s/iter; left time: 1678.7527s
Epoch: 6 cost time: 20.001733541488647
Epoch: 6, Steps: 256 Train Loss: 0.3507 (Forecasting Loss:0.3175 + XiCon Loss:3.3237 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2976
Validation loss decreased (0.330214 --> 0.329506).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3204943
	speed: 0.0803s/iter; left time: 1925.2848s
	iters: 200, epoch: 7 | loss: 0.3404861
	speed: 0.0629s/iter; left time: 1500.7221s
Epoch: 7 cost time: 17.513447999954224
Epoch: 7, Steps: 256 Train Loss: 0.3505 (Forecasting Loss:0.3172 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.2975
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3573624
	speed: 0.0724s/iter; left time: 1716.6466s
	iters: 200, epoch: 8 | loss: 0.3497944
	speed: 0.0717s/iter; left time: 1692.2123s
Epoch: 8 cost time: 18.373076915740967
Epoch: 8, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3234 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2974
Validation loss decreased (0.329506 --> 0.329280).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3360338
	speed: 0.0755s/iter; left time: 1769.5310s
	iters: 200, epoch: 9 | loss: 0.3401926
	speed: 0.0685s/iter; left time: 1598.8636s
Epoch: 9 cost time: 18.09707236289978
Epoch: 9, Steps: 256 Train Loss: 0.3502 (Forecasting Loss:0.3169 + XiCon Loss:3.3234 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
Validation loss decreased (0.329280 --> 0.329170).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3717244
	speed: 0.0738s/iter; left time: 1711.2028s
	iters: 200, epoch: 10 | loss: 0.3374980
	speed: 0.0695s/iter; left time: 1605.9782s
Epoch: 10 cost time: 18.67162585258484
Epoch: 10, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3220 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3540392
	speed: 0.0801s/iter; left time: 1838.3937s
	iters: 200, epoch: 11 | loss: 0.3572367
	speed: 0.0785s/iter; left time: 1794.0954s
Epoch: 11 cost time: 19.931566953659058
Epoch: 11, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329170 --> 0.329001).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3290201
	speed: 0.0723s/iter; left time: 1639.4141s
	iters: 200, epoch: 12 | loss: 0.3465213
	speed: 0.0728s/iter; left time: 1643.3470s
Epoch: 12 cost time: 18.734543085098267
Epoch: 12, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3220 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3406723
	speed: 0.0801s/iter; left time: 1797.0706s
	iters: 200, epoch: 13 | loss: 0.3673925
	speed: 0.0747s/iter; left time: 1668.5021s
Epoch: 13 cost time: 19.57453179359436
Epoch: 13, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3219 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3565239
	speed: 0.0703s/iter; left time: 1559.1029s
	iters: 200, epoch: 14 | loss: 0.3407329
	speed: 0.0552s/iter; left time: 1218.7376s
Epoch: 14 cost time: 14.59174919128418
Epoch: 14, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.3489657
	speed: 0.0748s/iter; left time: 1640.2586s
	iters: 200, epoch: 15 | loss: 0.3449319
	speed: 0.0400s/iter; left time: 871.6522s
Epoch: 15 cost time: 15.305536031723022
Epoch: 15, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.329001 --> 0.328994).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.3452480
	speed: 0.0784s/iter; left time: 1697.3535s
	iters: 200, epoch: 16 | loss: 0.3262837
	speed: 0.0700s/iter; left time: 1509.6862s
Epoch: 16 cost time: 18.753653526306152
Epoch: 16, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3225 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
Validation loss decreased (0.328994 --> 0.328957).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.3625050
	speed: 0.0741s/iter; left time: 1586.2562s
	iters: 200, epoch: 17 | loss: 0.3503117
	speed: 0.0704s/iter; left time: 1500.3012s
Epoch: 17 cost time: 16.95410132408142
Epoch: 17, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3227 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.3364883
	speed: 0.0804s/iter; left time: 1700.3819s
	iters: 200, epoch: 18 | loss: 0.3304088
	speed: 0.0679s/iter; left time: 1429.0944s
Epoch: 18 cost time: 18.74711537361145
Epoch: 18, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3235 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328957 --> 0.328938).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.3547241
	speed: 0.0767s/iter; left time: 1601.9087s
	iters: 200, epoch: 19 | loss: 0.3417089
	speed: 0.0707s/iter; left time: 1470.0115s
Epoch: 19 cost time: 18.328577756881714
Epoch: 19, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.3390859
	speed: 0.0371s/iter; left time: 766.2310s
	iters: 200, epoch: 20 | loss: 0.3409251
	speed: 0.0497s/iter; left time: 1019.7410s
Epoch: 20 cost time: 13.233399629592896
Epoch: 20, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3230 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.3587429
	speed: 0.0790s/iter; left time: 1610.1620s
	iters: 200, epoch: 21 | loss: 0.3537740
	speed: 0.0720s/iter; left time: 1460.2080s
Epoch: 21 cost time: 19.06541085243225
Epoch: 21, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3233 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328938 --> 0.328892).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.3559007
	speed: 0.0759s/iter; left time: 1527.1124s
	iters: 200, epoch: 22 | loss: 0.3560362
	speed: 0.0621s/iter; left time: 1243.0087s
Epoch: 22 cost time: 15.635592460632324
Epoch: 22, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3167 + XiCon Loss:3.3225 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.3392797
	speed: 0.0489s/iter; left time: 971.3444s
	iters: 200, epoch: 23 | loss: 0.3523072
	speed: 0.0727s/iter; left time: 1437.5600s
Epoch: 23 cost time: 16.403363466262817
Epoch: 23, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3218 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.3604485
	speed: 0.0769s/iter; left time: 1508.4946s
	iters: 200, epoch: 24 | loss: 0.3370080
	speed: 0.0794s/iter; left time: 1548.7952s
Epoch: 24 cost time: 19.604767560958862
Epoch: 24, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3230 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.3560485
	speed: 0.0743s/iter; left time: 1438.0077s
	iters: 200, epoch: 25 | loss: 0.3849900
	speed: 0.0753s/iter; left time: 1449.8891s
Epoch: 25 cost time: 18.983556985855103
Epoch: 25, Steps: 256 Train Loss: 0.3502 (Forecasting Loss:0.3169 + XiCon Loss:3.3228 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.3553910
	speed: 0.0815s/iter; left time: 1557.0959s
	iters: 200, epoch: 26 | loss: 0.3426820
	speed: 0.0737s/iter; left time: 1399.9134s
Epoch: 26 cost time: 19.622711181640625
Epoch: 26, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3228 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
Validation loss decreased (0.328892 --> 0.328871).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.3648277
	speed: 0.0757s/iter; left time: 1426.5691s
	iters: 200, epoch: 27 | loss: 0.3438713
	speed: 0.0720s/iter; left time: 1348.8731s
Epoch: 27 cost time: 18.724263668060303
Epoch: 27, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3237 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.3459506
	speed: 0.0749s/iter; left time: 1391.4127s
	iters: 200, epoch: 28 | loss: 0.3584675
	speed: 0.0797s/iter; left time: 1473.5347s
Epoch: 28 cost time: 19.74081325531006
Epoch: 28, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3224 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.3475559
	speed: 0.0709s/iter; left time: 1300.0950s
	iters: 200, epoch: 29 | loss: 0.3568518
	speed: 0.0632s/iter; left time: 1152.3738s
Epoch: 29 cost time: 17.28813624382019
Epoch: 29, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3208 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.3813756
	speed: 0.0812s/iter; left time: 1467.2310s
	iters: 200, epoch: 30 | loss: 0.3556790
	speed: 0.0723s/iter; left time: 1300.1457s
Epoch: 30 cost time: 19.23375105857849
Epoch: 30, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3168 + XiCon Loss:3.3221 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.3435668
	speed: 0.0724s/iter; left time: 1289.5176s
	iters: 200, epoch: 31 | loss: 0.3415790
	speed: 0.0682s/iter; left time: 1208.2248s
Epoch: 31 cost time: 18.18270230293274
Epoch: 31, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3222 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.3466884
	speed: 0.0765s/iter; left time: 1344.3008s
	iters: 200, epoch: 32 | loss: 0.3474194
	speed: 0.0742s/iter; left time: 1295.1074s
Epoch: 32 cost time: 19.403924703598022
Epoch: 32, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3233 x Lambda(0.01)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2974
Validation loss decreased (0.328871 --> 0.328776).  Saving model ...
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.3436513
	speed: 0.0762s/iter; left time: 1319.6581s
	iters: 200, epoch: 33 | loss: 0.3431852
	speed: 0.0686s/iter; left time: 1181.1536s
Epoch: 33 cost time: 18.358059644699097
Epoch: 33, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3223 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.3387200
	speed: 0.0829s/iter; left time: 1413.0855s
	iters: 200, epoch: 34 | loss: 0.3207744
	speed: 0.0712s/iter; left time: 1206.4491s
Epoch: 34 cost time: 19.454366445541382
Epoch: 34, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3223 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.3439185
	speed: 0.0774s/iter; left time: 1299.2929s
	iters: 200, epoch: 35 | loss: 0.3434622
	speed: 0.0692s/iter; left time: 1155.4126s
Epoch: 35 cost time: 18.43804931640625
Epoch: 35, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3243 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.3372617
	speed: 0.0794s/iter; left time: 1313.8946s
	iters: 200, epoch: 36 | loss: 0.3293749
	speed: 0.0726s/iter; left time: 1193.5435s
Epoch: 36 cost time: 19.75959086418152
Epoch: 36, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3218 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.3318730
	speed: 0.0777s/iter; left time: 1265.0349s
	iters: 200, epoch: 37 | loss: 0.3298318
	speed: 0.0689s/iter; left time: 1114.7873s
Epoch: 37 cost time: 18.499385118484497
Epoch: 37, Steps: 256 Train Loss: 0.3500 (Forecasting Loss:0.3167 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2974
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.3425495
	speed: 0.0815s/iter; left time: 1306.6142s
	iters: 200, epoch: 38 | loss: 0.3564153
	speed: 0.0736s/iter; left time: 1173.0568s
Epoch: 38 cost time: 20.006712198257446
Epoch: 38, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3225 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.3442765
	speed: 0.0798s/iter; left time: 1258.6636s
	iters: 200, epoch: 39 | loss: 0.3310623
	speed: 0.0704s/iter; left time: 1103.8514s
Epoch: 39 cost time: 18.588276863098145
Epoch: 39, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3220 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.3752123
	speed: 0.0767s/iter; left time: 1189.5248s
	iters: 200, epoch: 40 | loss: 0.3838871
	speed: 0.0672s/iter; left time: 1036.3069s
Epoch: 40 cost time: 18.705586433410645
Epoch: 40, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3230 x Lambda(0.01)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.2974
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.3636210
	speed: 0.0806s/iter; left time: 1230.7353s
	iters: 200, epoch: 41 | loss: 0.3533970
	speed: 0.0720s/iter; left time: 1092.1864s
Epoch: 41 cost time: 18.833805561065674
Epoch: 41, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3168 + XiCon Loss:3.3245 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.3828817
	speed: 0.0797s/iter; left time: 1195.6152s
	iters: 200, epoch: 42 | loss: 0.3358825
	speed: 0.0745s/iter; left time: 1109.9735s
Epoch: 42 cost time: 19.384526252746582
Epoch: 42, Steps: 256 Train Loss: 0.3501 (Forecasting Loss:0.3169 + XiCon Loss:3.3229 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.2974
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22055743634700775, mae:0.37419819831848145, mape:0.7276193499565125, mspe:18.853490829467773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.6906
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 0.4359719
	speed: 0.0831s/iter; left time: 2119.3383s
	iters: 200, epoch: 1 | loss: 0.4908116
	speed: 0.0776s/iter; left time: 1970.5133s
Epoch: 1 cost time: 20.568324327468872
Epoch: 1, Steps: 256 Train Loss: 0.4719 (Forecasting Loss:0.4380 + XiCon Loss:3.3895 x Lambda(0.01)), Vali MSE Loss: 0.3983 Test MSE Loss: 0.3709
Validation loss decreased (inf --> 0.398278).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.3844323
	speed: 0.0813s/iter; left time: 2053.1462s
	iters: 200, epoch: 2 | loss: 0.4056878
	speed: 0.0764s/iter; left time: 1920.0590s
Epoch: 2 cost time: 20.045679092407227
Epoch: 2, Steps: 256 Train Loss: 0.3845 (Forecasting Loss:0.3508 + XiCon Loss:3.3641 x Lambda(0.01)), Vali MSE Loss: 0.3303 Test MSE Loss: 0.3010
Validation loss decreased (0.398278 --> 0.330300).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.3532179
	speed: 0.0823s/iter; left time: 2057.4406s
	iters: 200, epoch: 3 | loss: 0.3567604
	speed: 0.0810s/iter; left time: 2015.4890s
Epoch: 3 cost time: 20.89963698387146
Epoch: 3, Steps: 256 Train Loss: 0.3556 (Forecasting Loss:0.3223 + XiCon Loss:3.3311 x Lambda(0.01)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.3015
Validation loss decreased (0.330300 --> 0.311235).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.3301518
	speed: 0.0827s/iter; left time: 2045.4332s
	iters: 200, epoch: 4 | loss: 0.3423942
	speed: 0.0750s/iter; left time: 1848.0107s
Epoch: 4 cost time: 19.907449960708618
Epoch: 4, Steps: 256 Train Loss: 0.3476 (Forecasting Loss:0.3144 + XiCon Loss:3.3231 x Lambda(0.01)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.3031
Validation loss decreased (0.311235 --> 0.308481).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.3269014
	speed: 0.0842s/iter; left time: 2060.7963s
	iters: 200, epoch: 5 | loss: 0.3303845
	speed: 0.0773s/iter; left time: 1885.1977s
Epoch: 5 cost time: 20.760586261749268
Epoch: 5, Steps: 256 Train Loss: 0.3452 (Forecasting Loss:0.3120 + XiCon Loss:3.3205 x Lambda(0.01)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.3036
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.3411723
	speed: 0.0868s/iter; left time: 2102.0518s
	iters: 200, epoch: 6 | loss: 0.3422559
	speed: 0.0786s/iter; left time: 1895.7964s
Epoch: 6 cost time: 20.73108458518982
Epoch: 6, Steps: 256 Train Loss: 0.3442 (Forecasting Loss:0.3110 + XiCon Loss:3.3197 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3040
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.3424238
	speed: 0.0794s/iter; left time: 1902.1565s
	iters: 200, epoch: 7 | loss: 0.3705553
	speed: 0.0782s/iter; left time: 1865.4196s
Epoch: 7 cost time: 20.36293363571167
Epoch: 7, Steps: 256 Train Loss: 0.3436 (Forecasting Loss:0.3104 + XiCon Loss:3.3177 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3041
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.3417428
	speed: 0.0784s/iter; left time: 1858.1637s
	iters: 200, epoch: 8 | loss: 0.3545330
	speed: 0.0702s/iter; left time: 1658.4472s
Epoch: 8 cost time: 19.033123016357422
Epoch: 8, Steps: 256 Train Loss: 0.3435 (Forecasting Loss:0.3103 + XiCon Loss:3.3193 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.3042
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.3328263
	speed: 0.0816s/iter; left time: 1912.8634s
	iters: 200, epoch: 9 | loss: 0.3485990
	speed: 0.0808s/iter; left time: 1885.8996s
Epoch: 9 cost time: 20.580074787139893
Epoch: 9, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3170 x Lambda(0.01)), Vali MSE Loss: 0.3093 Test MSE Loss: 0.3042
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.3318454
	speed: 0.0833s/iter; left time: 1932.4666s
	iters: 200, epoch: 10 | loss: 0.3350500
	speed: 0.0728s/iter; left time: 1681.7927s
Epoch: 10 cost time: 19.819395780563354
Epoch: 10, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3169 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.3472699
	speed: 0.0843s/iter; left time: 1933.2760s
	iters: 200, epoch: 11 | loss: 0.3336700
	speed: 0.0820s/iter; left time: 1873.3451s
Epoch: 11 cost time: 21.086445569992065
Epoch: 11, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3178 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.3504202
	speed: 0.0756s/iter; left time: 1715.9237s
	iters: 200, epoch: 12 | loss: 0.3526486
	speed: 0.0736s/iter; left time: 1661.2896s
Epoch: 12 cost time: 19.52813220024109
Epoch: 12, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3100 + XiCon Loss:3.3173 x Lambda(0.01)), Vali MSE Loss: 0.3091 Test MSE Loss: 0.3043
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.3148145
	speed: 0.0826s/iter; left time: 1852.2165s
	iters: 200, epoch: 13 | loss: 0.3615506
	speed: 0.0787s/iter; left time: 1757.7918s
Epoch: 13 cost time: 20.746673822402954
Epoch: 13, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3101 + XiCon Loss:3.3171 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.3564137
	speed: 0.0764s/iter; left time: 1694.3322s
	iters: 200, epoch: 14 | loss: 0.3372966
	speed: 0.0757s/iter; left time: 1671.4448s
Epoch: 14 cost time: 19.78327512741089
Epoch: 14, Steps: 256 Train Loss: 0.3432 (Forecasting Loss:0.3100 + XiCon Loss:3.3184 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.3043
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22974133491516113, mae:0.3765351176261902, mape:0.7666910886764526, mspe:20.7893123626709 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2238+-0.00531, MAE:0.3728+-0.00401, MAPE:0.7457+-0.01808, MSPE:19.4086+-1.03405, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.5413
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.7956102
	speed: 0.1231s/iter; left time: 2992.1667s
	iters: 200, epoch: 1 | loss: 3.7775326
	speed: 0.1214s/iter; left time: 2938.5878s
Epoch: 1 cost time: 30.224023818969727
Epoch: 1, Steps: 244 Train Loss: 3.8291 (Forecasting Loss:0.4576 + XiCon Loss:3.3715 x Lambda(1.0)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.3567
Validation loss decreased (inf --> 0.455320).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5758033
	speed: 0.1276s/iter; left time: 3070.1915s
	iters: 200, epoch: 2 | loss: 3.5714822
	speed: 0.1207s/iter; left time: 2892.6412s
Epoch: 2 cost time: 30.662734031677246
Epoch: 2, Steps: 244 Train Loss: 3.5976 (Forecasting Loss:0.3666 + XiCon Loss:3.2310 x Lambda(1.0)), Vali MSE Loss: 0.3671 Test MSE Loss: 0.3020
Validation loss decreased (0.455320 --> 0.367133).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5675919
	speed: 0.1232s/iter; left time: 2934.6499s
	iters: 200, epoch: 3 | loss: 3.6052334
	speed: 0.1259s/iter; left time: 2984.5354s
Epoch: 3 cost time: 30.60604166984558
Epoch: 3, Steps: 244 Train Loss: 3.5973 (Forecasting Loss:0.3467 + XiCon Loss:3.2507 x Lambda(1.0)), Vali MSE Loss: 0.3804 Test MSE Loss: 0.2935
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5780773
	speed: 0.1296s/iter; left time: 3054.3048s
	iters: 200, epoch: 4 | loss: 3.5563819
	speed: 0.0969s/iter; left time: 2273.9324s
Epoch: 4 cost time: 25.74484157562256
Epoch: 4, Steps: 244 Train Loss: 3.5764 (Forecasting Loss:0.3430 + XiCon Loss:3.2333 x Lambda(1.0)), Vali MSE Loss: 0.3514 Test MSE Loss: 0.2910
Validation loss decreased (0.367133 --> 0.351367).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5929041
	speed: 0.1240s/iter; left time: 2893.1776s
	iters: 200, epoch: 5 | loss: 3.6238780
	speed: 0.1286s/iter; left time: 2987.8083s
Epoch: 5 cost time: 30.918041706085205
Epoch: 5, Steps: 244 Train Loss: 3.5650 (Forecasting Loss:0.3413 + XiCon Loss:3.2237 x Lambda(1.0)), Vali MSE Loss: 0.3492 Test MSE Loss: 0.2924
Validation loss decreased (0.351367 --> 0.349210).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5592833
	speed: 0.1159s/iter; left time: 2674.3720s
	iters: 200, epoch: 6 | loss: 3.5559158
	speed: 0.1251s/iter; left time: 2874.9713s
Epoch: 6 cost time: 29.8614239692688
Epoch: 6, Steps: 244 Train Loss: 3.5577 (Forecasting Loss:0.3397 + XiCon Loss:3.2180 x Lambda(1.0)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.2927
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5354984
	speed: 0.1268s/iter; left time: 2895.8075s
	iters: 200, epoch: 7 | loss: 3.5477192
	speed: 0.1197s/iter; left time: 2722.3286s
Epoch: 7 cost time: 28.563066720962524
Epoch: 7, Steps: 244 Train Loss: 3.5543 (Forecasting Loss:0.3395 + XiCon Loss:3.2149 x Lambda(1.0)), Vali MSE Loss: 0.3533 Test MSE Loss: 0.2914
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5201445
	speed: 0.1027s/iter; left time: 2320.1199s
	iters: 200, epoch: 8 | loss: 3.5934544
	speed: 0.1247s/iter; left time: 2805.1480s
Epoch: 8 cost time: 28.560543298721313
Epoch: 8, Steps: 244 Train Loss: 3.5542 (Forecasting Loss:0.3397 + XiCon Loss:3.2145 x Lambda(1.0)), Vali MSE Loss: 0.3567 Test MSE Loss: 0.2918
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5037169
	speed: 0.1300s/iter; left time: 2905.1001s
	iters: 200, epoch: 9 | loss: 3.5312710
	speed: 0.0993s/iter; left time: 2208.5333s
Epoch: 9 cost time: 26.05265235900879
Epoch: 9, Steps: 244 Train Loss: 3.5520 (Forecasting Loss:0.3393 + XiCon Loss:3.2127 x Lambda(1.0)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.2916
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5218151
	speed: 0.1292s/iter; left time: 2855.7347s
	iters: 200, epoch: 10 | loss: 3.5181315
	speed: 0.1280s/iter; left time: 2817.0436s
Epoch: 10 cost time: 31.616809844970703
Epoch: 10, Steps: 244 Train Loss: 3.5514 (Forecasting Loss:0.3390 + XiCon Loss:3.2123 x Lambda(1.0)), Vali MSE Loss: 0.3543 Test MSE Loss: 0.2916
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6106193
	speed: 0.1284s/iter; left time: 2807.6995s
	iters: 200, epoch: 11 | loss: 3.5314198
	speed: 0.1328s/iter; left time: 2889.0270s
Epoch: 11 cost time: 31.778528451919556
Epoch: 11, Steps: 244 Train Loss: 3.5514 (Forecasting Loss:0.3395 + XiCon Loss:3.2120 x Lambda(1.0)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.2916
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5688415
	speed: 0.1311s/iter; left time: 2833.9700s
	iters: 200, epoch: 12 | loss: 3.5169461
	speed: 0.1243s/iter; left time: 2673.8788s
Epoch: 12 cost time: 31.27268695831299
Epoch: 12, Steps: 244 Train Loss: 3.5512 (Forecasting Loss:0.3393 + XiCon Loss:3.2119 x Lambda(1.0)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.2916
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5883555
	speed: 0.1301s/iter; left time: 2780.9923s
	iters: 200, epoch: 13 | loss: 3.5376563
	speed: 0.1285s/iter; left time: 2732.7160s
Epoch: 13 cost time: 31.730053663253784
Epoch: 13, Steps: 244 Train Loss: 3.5519 (Forecasting Loss:0.3387 + XiCon Loss:3.2132 x Lambda(1.0)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.2916
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5109675
	speed: 0.1317s/iter; left time: 2782.1865s
	iters: 200, epoch: 14 | loss: 3.6175308
	speed: 0.1294s/iter; left time: 2720.5807s
Epoch: 14 cost time: 32.14522576332092
Epoch: 14, Steps: 244 Train Loss: 3.5478 (Forecasting Loss:0.3388 + XiCon Loss:3.2089 x Lambda(1.0)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.2916
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5835776
	speed: 0.1294s/iter; left time: 2702.3308s
	iters: 200, epoch: 15 | loss: 3.5571351
	speed: 0.1248s/iter; left time: 2593.0506s
Epoch: 15 cost time: 31.187164783477783
Epoch: 15, Steps: 244 Train Loss: 3.5498 (Forecasting Loss:0.3392 + XiCon Loss:3.2106 x Lambda(1.0)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.2916
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.21350215375423431, mae:0.37133610248565674, mape:0.7091946601867676, mspe:19.98935317993164 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.4476
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.7964439
	speed: 0.1188s/iter; left time: 2886.9111s
	iters: 200, epoch: 1 | loss: 3.8139851
	speed: 0.1148s/iter; left time: 2778.3938s
Epoch: 1 cost time: 28.59228539466858
Epoch: 1, Steps: 244 Train Loss: 3.8294 (Forecasting Loss:0.4646 + XiCon Loss:3.3648 x Lambda(1.0)), Vali MSE Loss: 0.4797 Test MSE Loss: 0.3856
Validation loss decreased (inf --> 0.479739).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5606048
	speed: 0.1169s/iter; left time: 2812.6949s
	iters: 200, epoch: 2 | loss: 3.5516677
	speed: 0.1149s/iter; left time: 2751.8598s
Epoch: 2 cost time: 28.71087098121643
Epoch: 2, Steps: 244 Train Loss: 3.5987 (Forecasting Loss:0.3867 + XiCon Loss:3.2119 x Lambda(1.0)), Vali MSE Loss: 0.3785 Test MSE Loss: 0.2967
Validation loss decreased (0.479739 --> 0.378476).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5872350
	speed: 0.1198s/iter; left time: 2851.6265s
	iters: 200, epoch: 3 | loss: 3.6153107
	speed: 0.1222s/iter; left time: 2896.9062s
Epoch: 3 cost time: 29.3928804397583
Epoch: 3, Steps: 244 Train Loss: 3.6192 (Forecasting Loss:0.3633 + XiCon Loss:3.2559 x Lambda(1.0)), Vali MSE Loss: 0.3716 Test MSE Loss: 0.2983
Validation loss decreased (0.378476 --> 0.371560).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7225699
	speed: 0.1204s/iter; left time: 2837.4669s
	iters: 200, epoch: 4 | loss: 3.6591144
	speed: 0.1185s/iter; left time: 2780.9755s
Epoch: 4 cost time: 28.965723037719727
Epoch: 4, Steps: 244 Train Loss: 3.6232 (Forecasting Loss:0.3580 + XiCon Loss:3.2651 x Lambda(1.0)), Vali MSE Loss: 0.3767 Test MSE Loss: 0.3018
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5742197
	speed: 0.1238s/iter; left time: 2887.4888s
	iters: 200, epoch: 5 | loss: 3.5752757
	speed: 0.1166s/iter; left time: 2708.7399s
Epoch: 5 cost time: 29.092069625854492
Epoch: 5, Steps: 244 Train Loss: 3.5961 (Forecasting Loss:0.3548 + XiCon Loss:3.2413 x Lambda(1.0)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.3019
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5402813
	speed: 0.1197s/iter; left time: 2762.1355s
	iters: 200, epoch: 6 | loss: 3.5783591
	speed: 0.1154s/iter; left time: 2651.5571s
Epoch: 6 cost time: 29.210438013076782
Epoch: 6, Steps: 244 Train Loss: 3.5872 (Forecasting Loss:0.3524 + XiCon Loss:3.2348 x Lambda(1.0)), Vali MSE Loss: 0.3728 Test MSE Loss: 0.3019
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5488167
	speed: 0.1162s/iter; left time: 2653.9787s
	iters: 200, epoch: 7 | loss: 3.6167560
	speed: 0.1181s/iter; left time: 2685.5837s
Epoch: 7 cost time: 28.711003303527832
Epoch: 7, Steps: 244 Train Loss: 3.5867 (Forecasting Loss:0.3518 + XiCon Loss:3.2349 x Lambda(1.0)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3019
Validation loss decreased (0.371560 --> 0.370445).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5641060
	speed: 0.1198s/iter; left time: 2707.0865s
	iters: 200, epoch: 8 | loss: 3.6072140
	speed: 0.1163s/iter; left time: 2616.9609s
Epoch: 8 cost time: 28.908612489700317
Epoch: 8, Steps: 244 Train Loss: 3.5816 (Forecasting Loss:0.3511 + XiCon Loss:3.2304 x Lambda(1.0)), Vali MSE Loss: 0.3707 Test MSE Loss: 0.3020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5856493
	speed: 0.1251s/iter; left time: 2795.3459s
	iters: 200, epoch: 9 | loss: 3.5606687
	speed: 0.1178s/iter; left time: 2620.8724s
Epoch: 9 cost time: 29.479187488555908
Epoch: 9, Steps: 244 Train Loss: 3.5809 (Forecasting Loss:0.3509 + XiCon Loss:3.2300 x Lambda(1.0)), Vali MSE Loss: 0.3700 Test MSE Loss: 0.3020
Validation loss decreased (0.370445 --> 0.370028).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5615084
	speed: 0.1245s/iter; left time: 2752.1178s
	iters: 200, epoch: 10 | loss: 3.6337748
	speed: 0.1217s/iter; left time: 2676.9453s
Epoch: 10 cost time: 29.421285152435303
Epoch: 10, Steps: 244 Train Loss: 3.5795 (Forecasting Loss:0.3507 + XiCon Loss:3.2288 x Lambda(1.0)), Vali MSE Loss: 0.3702 Test MSE Loss: 0.3020
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5794001
	speed: 0.1204s/iter; left time: 2631.0671s
	iters: 200, epoch: 11 | loss: 3.5841949
	speed: 0.1186s/iter; left time: 2581.3649s
Epoch: 11 cost time: 29.036978483200073
Epoch: 11, Steps: 244 Train Loss: 3.5794 (Forecasting Loss:0.3506 + XiCon Loss:3.2288 x Lambda(1.0)), Vali MSE Loss: 0.3707 Test MSE Loss: 0.3021
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5891573
	speed: 0.1138s/iter; left time: 2459.9934s
	iters: 200, epoch: 12 | loss: 3.5118997
	speed: 0.1179s/iter; left time: 2537.4191s
Epoch: 12 cost time: 28.115811586380005
Epoch: 12, Steps: 244 Train Loss: 3.5767 (Forecasting Loss:0.3506 + XiCon Loss:3.2260 x Lambda(1.0)), Vali MSE Loss: 0.3707 Test MSE Loss: 0.3021
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5383859
	speed: 0.1236s/iter; left time: 2641.7735s
	iters: 200, epoch: 13 | loss: 3.5570283
	speed: 0.1167s/iter; left time: 2483.4756s
Epoch: 13 cost time: 29.138508558273315
Epoch: 13, Steps: 244 Train Loss: 3.5781 (Forecasting Loss:0.3508 + XiCon Loss:3.2273 x Lambda(1.0)), Vali MSE Loss: 0.3702 Test MSE Loss: 0.3021
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4630702
	speed: 0.1199s/iter; left time: 2533.5238s
	iters: 200, epoch: 14 | loss: 3.5463901
	speed: 0.1206s/iter; left time: 2536.3231s
Epoch: 14 cost time: 29.37277626991272
Epoch: 14, Steps: 244 Train Loss: 3.5784 (Forecasting Loss:0.3506 + XiCon Loss:3.2278 x Lambda(1.0)), Vali MSE Loss: 0.3706 Test MSE Loss: 0.3021
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5622211
	speed: 0.1173s/iter; left time: 2450.0655s
	iters: 200, epoch: 15 | loss: 3.5910347
	speed: 0.1196s/iter; left time: 2485.1171s
Epoch: 15 cost time: 29.034305572509766
Epoch: 15, Steps: 244 Train Loss: 3.5798 (Forecasting Loss:0.3505 + XiCon Loss:3.2294 x Lambda(1.0)), Vali MSE Loss: 0.3702 Test MSE Loss: 0.3021
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6046174
	speed: 0.1246s/iter; left time: 2571.1608s
	iters: 200, epoch: 16 | loss: 3.5019569
	speed: 0.1136s/iter; left time: 2333.9859s
Epoch: 16 cost time: 29.243129014968872
Epoch: 16, Steps: 244 Train Loss: 3.5764 (Forecasting Loss:0.3506 + XiCon Loss:3.2258 x Lambda(1.0)), Vali MSE Loss: 0.3706 Test MSE Loss: 0.3021
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5587709
	speed: 0.1213s/iter; left time: 2474.2376s
	iters: 200, epoch: 17 | loss: 3.5590701
	speed: 0.1183s/iter; left time: 2401.5054s
Epoch: 17 cost time: 28.845460414886475
Epoch: 17, Steps: 244 Train Loss: 3.5774 (Forecasting Loss:0.3506 + XiCon Loss:3.2268 x Lambda(1.0)), Vali MSE Loss: 0.3705 Test MSE Loss: 0.3021
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6193423
	speed: 0.1201s/iter; left time: 2420.2763s
	iters: 200, epoch: 18 | loss: 3.6233115
	speed: 0.1131s/iter; left time: 2268.7292s
Epoch: 18 cost time: 28.569214820861816
Epoch: 18, Steps: 244 Train Loss: 3.5786 (Forecasting Loss:0.3505 + XiCon Loss:3.2282 x Lambda(1.0)), Vali MSE Loss: 0.3702 Test MSE Loss: 0.3021
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.5872452
	speed: 0.1178s/iter; left time: 2345.8622s
	iters: 200, epoch: 19 | loss: 3.6232991
	speed: 0.1121s/iter; left time: 2220.5249s
Epoch: 19 cost time: 28.007020473480225
Epoch: 19, Steps: 244 Train Loss: 3.5805 (Forecasting Loss:0.3504 + XiCon Loss:3.2301 x Lambda(1.0)), Vali MSE Loss: 0.3703 Test MSE Loss: 0.3021
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22473818063735962, mae:0.37924662232398987, mape:0.679093599319458, mspe:18.208175659179688 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.6974
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.8462110
	speed: 0.1092s/iter; left time: 2654.2264s
	iters: 200, epoch: 1 | loss: 3.7784681
	speed: 0.1149s/iter; left time: 2779.5325s
Epoch: 1 cost time: 27.747198820114136
Epoch: 1, Steps: 244 Train Loss: 3.8336 (Forecasting Loss:0.4592 + XiCon Loss:3.3744 x Lambda(1.0)), Vali MSE Loss: 0.4463 Test MSE Loss: 0.3472
Validation loss decreased (inf --> 0.446275).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5933611
	speed: 0.1216s/iter; left time: 2926.4746s
	iters: 200, epoch: 2 | loss: 3.5506003
	speed: 0.1221s/iter; left time: 2923.9565s
Epoch: 2 cost time: 30.27524447441101
Epoch: 2, Steps: 244 Train Loss: 3.5921 (Forecasting Loss:0.3962 + XiCon Loss:3.1959 x Lambda(1.0)), Vali MSE Loss: 0.4234 Test MSE Loss: 0.3316
Validation loss decreased (0.446275 --> 0.423431).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5895650
	speed: 0.1461s/iter; left time: 3478.2854s
	iters: 200, epoch: 3 | loss: 3.6836674
	speed: 0.0847s/iter; left time: 2009.4495s
Epoch: 3 cost time: 28.996114492416382
Epoch: 3, Steps: 244 Train Loss: 3.5874 (Forecasting Loss:0.3832 + XiCon Loss:3.2042 x Lambda(1.0)), Vali MSE Loss: 0.4277 Test MSE Loss: 0.3314
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7184980
	speed: 0.1490s/iter; left time: 3512.0074s
	iters: 200, epoch: 4 | loss: 3.7200150
	speed: 0.1497s/iter; left time: 3512.4094s
Epoch: 4 cost time: 36.013155460357666
Epoch: 4, Steps: 244 Train Loss: 3.6600 (Forecasting Loss:0.3793 + XiCon Loss:3.2807 x Lambda(1.0)), Vali MSE Loss: 0.4174 Test MSE Loss: 0.3260
Validation loss decreased (0.423431 --> 0.417353).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.8228865
	speed: 0.1328s/iter; left time: 3098.2509s
	iters: 200, epoch: 5 | loss: 3.8402140
	speed: 0.1455s/iter; left time: 3379.4890s
Epoch: 5 cost time: 34.461652517318726
Epoch: 5, Steps: 244 Train Loss: 3.7053 (Forecasting Loss:0.3768 + XiCon Loss:3.3285 x Lambda(1.0)), Vali MSE Loss: 0.4150 Test MSE Loss: 0.3248
Validation loss decreased (0.417353 --> 0.414995).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.7962227
	speed: 0.1483s/iter; left time: 3423.4850s
	iters: 200, epoch: 6 | loss: 3.6896641
	speed: 0.0758s/iter; left time: 1741.7980s
Epoch: 6 cost time: 28.668721914291382
Epoch: 6, Steps: 244 Train Loss: 3.7204 (Forecasting Loss:0.3750 + XiCon Loss:3.3454 x Lambda(1.0)), Vali MSE Loss: 0.4186 Test MSE Loss: 0.3275
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6680698
	speed: 0.1485s/iter; left time: 3392.0375s
	iters: 200, epoch: 7 | loss: 3.7517235
	speed: 0.1432s/iter; left time: 3255.5614s
Epoch: 7 cost time: 35.43550109863281
Epoch: 7, Steps: 244 Train Loss: 3.7284 (Forecasting Loss:0.3743 + XiCon Loss:3.3541 x Lambda(1.0)), Vali MSE Loss: 0.4155 Test MSE Loss: 0.3248
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.7325263
	speed: 0.0824s/iter; left time: 1861.2905s
	iters: 200, epoch: 8 | loss: 3.7595098
	speed: 0.1462s/iter; left time: 3288.3662s
Epoch: 8 cost time: 29.1909601688385
Epoch: 8, Steps: 244 Train Loss: 3.7322 (Forecasting Loss:0.3739 + XiCon Loss:3.3583 x Lambda(1.0)), Vali MSE Loss: 0.4143 Test MSE Loss: 0.3244
Validation loss decreased (0.414995 --> 0.414272).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.7186694
	speed: 0.1515s/iter; left time: 3386.0109s
	iters: 200, epoch: 9 | loss: 3.7377319
	speed: 0.1395s/iter; left time: 3103.7644s
Epoch: 9 cost time: 35.82741594314575
Epoch: 9, Steps: 244 Train Loss: 3.7339 (Forecasting Loss:0.3736 + XiCon Loss:3.3603 x Lambda(1.0)), Vali MSE Loss: 0.4151 Test MSE Loss: 0.3242
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.7037740
	speed: 0.1494s/iter; left time: 3301.9235s
	iters: 200, epoch: 10 | loss: 3.8632467
	speed: 0.1467s/iter; left time: 3228.3100s
Epoch: 10 cost time: 36.27716016769409
Epoch: 10, Steps: 244 Train Loss: 3.7430 (Forecasting Loss:0.3733 + XiCon Loss:3.3696 x Lambda(1.0)), Vali MSE Loss: 0.4154 Test MSE Loss: 0.3247
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.7436461
	speed: 0.1436s/iter; left time: 3138.8141s
	iters: 200, epoch: 11 | loss: 3.6404681
	speed: 0.1484s/iter; left time: 3228.9721s
Epoch: 11 cost time: 35.79323101043701
Epoch: 11, Steps: 244 Train Loss: 3.7344 (Forecasting Loss:0.3731 + XiCon Loss:3.3612 x Lambda(1.0)), Vali MSE Loss: 0.4150 Test MSE Loss: 0.3244
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.7476242
	speed: 0.1452s/iter; left time: 3138.5262s
	iters: 200, epoch: 12 | loss: 3.6827738
	speed: 0.1492s/iter; left time: 3209.9575s
Epoch: 12 cost time: 35.91243004798889
Epoch: 12, Steps: 244 Train Loss: 3.7394 (Forecasting Loss:0.3737 + XiCon Loss:3.3658 x Lambda(1.0)), Vali MSE Loss: 0.4151 Test MSE Loss: 0.3244
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.7587895
	speed: 0.1451s/iter; left time: 3101.5213s
	iters: 200, epoch: 13 | loss: 3.8225818
	speed: 0.1452s/iter; left time: 3088.0207s
Epoch: 13 cost time: 35.33566856384277
Epoch: 13, Steps: 244 Train Loss: 3.7361 (Forecasting Loss:0.3733 + XiCon Loss:3.3629 x Lambda(1.0)), Vali MSE Loss: 0.4152 Test MSE Loss: 0.3245
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.7193341
	speed: 0.1523s/iter; left time: 3217.2930s
	iters: 200, epoch: 14 | loss: 3.6612830
	speed: 0.1448s/iter; left time: 3044.6299s
Epoch: 14 cost time: 35.981119871139526
Epoch: 14, Steps: 244 Train Loss: 3.7353 (Forecasting Loss:0.3733 + XiCon Loss:3.3620 x Lambda(1.0)), Vali MSE Loss: 0.4150 Test MSE Loss: 0.3245
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.7263649
	speed: 0.1455s/iter; left time: 3039.1021s
	iters: 200, epoch: 15 | loss: 3.6623764
	speed: 0.1432s/iter; left time: 2977.1607s
Epoch: 15 cost time: 34.751670360565186
Epoch: 15, Steps: 244 Train Loss: 3.7420 (Forecasting Loss:0.3734 + XiCon Loss:3.3686 x Lambda(1.0)), Vali MSE Loss: 0.4152 Test MSE Loss: 0.3245
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.8321035
	speed: 0.1405s/iter; left time: 2899.4994s
	iters: 200, epoch: 16 | loss: 3.7748392
	speed: 0.1411s/iter; left time: 2898.7338s
Epoch: 16 cost time: 34.190922498703
Epoch: 16, Steps: 244 Train Loss: 3.7433 (Forecasting Loss:0.3734 + XiCon Loss:3.3699 x Lambda(1.0)), Vali MSE Loss: 0.4151 Test MSE Loss: 0.3245
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6642866
	speed: 0.1389s/iter; left time: 2833.3845s
	iters: 200, epoch: 17 | loss: 3.7974319
	speed: 0.1392s/iter; left time: 2826.1825s
Epoch: 17 cost time: 34.29254364967346
Epoch: 17, Steps: 244 Train Loss: 3.7391 (Forecasting Loss:0.3735 + XiCon Loss:3.3656 x Lambda(1.0)), Vali MSE Loss: 0.4151 Test MSE Loss: 0.3245
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.8479857
	speed: 0.1473s/iter; left time: 2969.1568s
	iters: 200, epoch: 18 | loss: 3.6848159
	speed: 0.1262s/iter; left time: 2531.2931s
Epoch: 18 cost time: 33.43288445472717
Epoch: 18, Steps: 244 Train Loss: 3.7362 (Forecasting Loss:0.3733 + XiCon Loss:3.3629 x Lambda(1.0)), Vali MSE Loss: 0.4150 Test MSE Loss: 0.3245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2500440776348114, mae:0.3986623287200928, mape:0.651852548122406, mspe:14.443078994750977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.1256
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.8227842
	speed: 0.1079s/iter; left time: 2623.0457s
	iters: 200, epoch: 1 | loss: 3.8412838
	speed: 0.1111s/iter; left time: 2687.5250s
Epoch: 1 cost time: 27.083996295928955
Epoch: 1, Steps: 244 Train Loss: 3.8432 (Forecasting Loss:0.4593 + XiCon Loss:3.3839 x Lambda(1.0)), Vali MSE Loss: 0.4490 Test MSE Loss: 0.3516
Validation loss decreased (inf --> 0.448980).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5868025
	speed: 0.1134s/iter; left time: 2728.5107s
	iters: 200, epoch: 2 | loss: 3.4856563
	speed: 0.1069s/iter; left time: 2561.9121s
Epoch: 2 cost time: 26.653947114944458
Epoch: 2, Steps: 244 Train Loss: 3.5968 (Forecasting Loss:0.3863 + XiCon Loss:3.2104 x Lambda(1.0)), Vali MSE Loss: 0.3664 Test MSE Loss: 0.3265
Validation loss decreased (0.448980 --> 0.366386).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4778504
	speed: 0.1178s/iter; left time: 2805.6226s
	iters: 200, epoch: 3 | loss: 3.5062032
	speed: 0.1142s/iter; left time: 2709.1750s
Epoch: 3 cost time: 28.20365333557129
Epoch: 3, Steps: 244 Train Loss: 3.5256 (Forecasting Loss:0.3540 + XiCon Loss:3.1716 x Lambda(1.0)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3273
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6153131
	speed: 0.1118s/iter; left time: 2636.0192s
	iters: 200, epoch: 4 | loss: 3.5563293
	speed: 0.1121s/iter; left time: 2630.6333s
Epoch: 4 cost time: 27.450458765029907
Epoch: 4, Steps: 244 Train Loss: 3.5571 (Forecasting Loss:0.3522 + XiCon Loss:3.2049 x Lambda(1.0)), Vali MSE Loss: 0.3821 Test MSE Loss: 0.3390
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5749915
	speed: 0.1141s/iter; left time: 2662.1546s
	iters: 200, epoch: 5 | loss: 3.5587676
	speed: 0.1104s/iter; left time: 2564.4035s
Epoch: 5 cost time: 27.076335668563843
Epoch: 5, Steps: 244 Train Loss: 3.5706 (Forecasting Loss:0.3516 + XiCon Loss:3.2191 x Lambda(1.0)), Vali MSE Loss: 0.3666 Test MSE Loss: 0.3354
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5985796
	speed: 0.1149s/iter; left time: 2652.4152s
	iters: 200, epoch: 6 | loss: 3.6161020
	speed: 0.1109s/iter; left time: 2548.1543s
Epoch: 6 cost time: 27.613688468933105
Epoch: 6, Steps: 244 Train Loss: 3.5710 (Forecasting Loss:0.3503 + XiCon Loss:3.2207 x Lambda(1.0)), Vali MSE Loss: 0.3623 Test MSE Loss: 0.3341
Validation loss decreased (0.366386 --> 0.362340).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5516751
	speed: 0.1110s/iter; left time: 2533.7926s
	iters: 200, epoch: 7 | loss: 3.6323311
	speed: 0.1122s/iter; left time: 2550.7986s
Epoch: 7 cost time: 27.443959712982178
Epoch: 7, Steps: 244 Train Loss: 3.5728 (Forecasting Loss:0.3500 + XiCon Loss:3.2228 x Lambda(1.0)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.3347
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4812386
	speed: 0.1177s/iter; left time: 2658.6645s
	iters: 200, epoch: 8 | loss: 3.5981283
	speed: 0.1102s/iter; left time: 2479.1643s
Epoch: 8 cost time: 27.664854288101196
Epoch: 8, Steps: 244 Train Loss: 3.5709 (Forecasting Loss:0.3501 + XiCon Loss:3.2208 x Lambda(1.0)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.3356
Validation loss decreased (0.362340 --> 0.361640).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5604286
	speed: 0.1171s/iter; left time: 2616.6896s
	iters: 200, epoch: 9 | loss: 3.5347300
	speed: 0.1141s/iter; left time: 2539.2601s
Epoch: 9 cost time: 28.186192274093628
Epoch: 9, Steps: 244 Train Loss: 3.5751 (Forecasting Loss:0.3498 + XiCon Loss:3.2253 x Lambda(1.0)), Vali MSE Loss: 0.3619 Test MSE Loss: 0.3350
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5317533
	speed: 0.1114s/iter; left time: 2462.0375s
	iters: 200, epoch: 10 | loss: 3.6047537
	speed: 0.1108s/iter; left time: 2438.3103s
Epoch: 10 cost time: 27.241798400878906
Epoch: 10, Steps: 244 Train Loss: 3.5733 (Forecasting Loss:0.3499 + XiCon Loss:3.2234 x Lambda(1.0)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.3351
Validation loss decreased (0.361640 --> 0.360020).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5479596
	speed: 0.1148s/iter; left time: 2509.5015s
	iters: 200, epoch: 11 | loss: 3.5350392
	speed: 0.1109s/iter; left time: 2412.7668s
Epoch: 11 cost time: 27.477295637130737
Epoch: 11, Steps: 244 Train Loss: 3.5695 (Forecasting Loss:0.3495 + XiCon Loss:3.2200 x Lambda(1.0)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.3355
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6082954
	speed: 0.1151s/iter; left time: 2487.1746s
	iters: 200, epoch: 12 | loss: 3.5239542
	speed: 0.1121s/iter; left time: 2412.7806s
Epoch: 12 cost time: 27.548278331756592
Epoch: 12, Steps: 244 Train Loss: 3.5729 (Forecasting Loss:0.3498 + XiCon Loss:3.2230 x Lambda(1.0)), Vali MSE Loss: 0.3610 Test MSE Loss: 0.3355
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5475261
	speed: 0.1096s/iter; left time: 2341.6321s
	iters: 200, epoch: 13 | loss: 3.5696325
	speed: 0.1116s/iter; left time: 2374.3431s
Epoch: 13 cost time: 27.240967750549316
Epoch: 13, Steps: 244 Train Loss: 3.5722 (Forecasting Loss:0.3496 + XiCon Loss:3.2226 x Lambda(1.0)), Vali MSE Loss: 0.3609 Test MSE Loss: 0.3355
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6394022
	speed: 0.1152s/iter; left time: 2434.5221s
	iters: 200, epoch: 14 | loss: 3.6293256
	speed: 0.1107s/iter; left time: 2328.9278s
Epoch: 14 cost time: 27.267699003219604
Epoch: 14, Steps: 244 Train Loss: 3.5740 (Forecasting Loss:0.3493 + XiCon Loss:3.2248 x Lambda(1.0)), Vali MSE Loss: 0.3609 Test MSE Loss: 0.3355
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6332808
	speed: 0.1139s/iter; left time: 2378.9067s
	iters: 200, epoch: 15 | loss: 3.6045103
	speed: 0.1118s/iter; left time: 2324.1801s
Epoch: 15 cost time: 27.65271806716919
Epoch: 15, Steps: 244 Train Loss: 3.5719 (Forecasting Loss:0.3494 + XiCon Loss:3.2225 x Lambda(1.0)), Vali MSE Loss: 0.3612 Test MSE Loss: 0.3355
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.5741851
	speed: 0.1124s/iter; left time: 2319.0172s
	iters: 200, epoch: 16 | loss: 3.5769925
	speed: 0.1135s/iter; left time: 2331.9124s
Epoch: 16 cost time: 27.570378303527832
Epoch: 16, Steps: 244 Train Loss: 3.5733 (Forecasting Loss:0.3497 + XiCon Loss:3.2236 x Lambda(1.0)), Vali MSE Loss: 0.3610 Test MSE Loss: 0.3355
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6369135
	speed: 0.1166s/iter; left time: 2378.1198s
	iters: 200, epoch: 17 | loss: 3.5879188
	speed: 0.1078s/iter; left time: 2187.7148s
Epoch: 17 cost time: 26.795220136642456
Epoch: 17, Steps: 244 Train Loss: 3.5710 (Forecasting Loss:0.3495 + XiCon Loss:3.2215 x Lambda(1.0)), Vali MSE Loss: 0.3609 Test MSE Loss: 0.3355
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6184497
	speed: 0.1192s/iter; left time: 2401.6826s
	iters: 200, epoch: 18 | loss: 3.6168904
	speed: 0.0563s/iter; left time: 1128.3164s
Epoch: 18 cost time: 20.169584035873413
Epoch: 18, Steps: 244 Train Loss: 3.5780 (Forecasting Loss:0.3497 + XiCon Loss:3.2284 x Lambda(1.0)), Vali MSE Loss: 0.3610 Test MSE Loss: 0.3355
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.5835338
	speed: 0.1148s/iter; left time: 2285.5247s
	iters: 200, epoch: 19 | loss: 3.6047187
	speed: 0.1134s/iter; left time: 2245.6780s
Epoch: 19 cost time: 27.643013954162598
Epoch: 19, Steps: 244 Train Loss: 3.5745 (Forecasting Loss:0.3500 + XiCon Loss:3.2245 x Lambda(1.0)), Vali MSE Loss: 0.3610 Test MSE Loss: 0.3355
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.5481396
	speed: 0.1042s/iter; left time: 2049.3624s
	iters: 200, epoch: 20 | loss: 3.5350327
	speed: 0.1036s/iter; left time: 2026.9009s
Epoch: 20 cost time: 25.6484112739563
Epoch: 20, Steps: 244 Train Loss: 3.5754 (Forecasting Loss:0.3498 + XiCon Loss:3.2255 x Lambda(1.0)), Vali MSE Loss: 0.3610 Test MSE Loss: 0.3355
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.26411762833595276, mae:0.40611711144447327, mape:0.73879474401474, mspe:20.068904876708984 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8933
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.8379347
	speed: 0.0630s/iter; left time: 1530.3962s
	iters: 200, epoch: 1 | loss: 3.8191826
	speed: 0.0830s/iter; left time: 2008.4885s
Epoch: 1 cost time: 19.52685284614563
Epoch: 1, Steps: 244 Train Loss: 3.8290 (Forecasting Loss:0.4593 + XiCon Loss:3.3696 x Lambda(1.0)), Vali MSE Loss: 0.4651 Test MSE Loss: 0.3694
Validation loss decreased (inf --> 0.465087).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5272114
	speed: 0.1145s/iter; left time: 2755.5288s
	iters: 200, epoch: 2 | loss: 3.6084666
	speed: 0.1112s/iter; left time: 2663.4857s
Epoch: 2 cost time: 27.158457279205322
Epoch: 2, Steps: 244 Train Loss: 3.5848 (Forecasting Loss:0.3779 + XiCon Loss:3.2069 x Lambda(1.0)), Vali MSE Loss: 0.3669 Test MSE Loss: 0.3061
Validation loss decreased (0.465087 --> 0.366907).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4953508
	speed: 0.0605s/iter; left time: 1441.2902s
	iters: 200, epoch: 3 | loss: 3.5857415
	speed: 0.1023s/iter; left time: 2425.6468s
Epoch: 3 cost time: 21.091989517211914
Epoch: 3, Steps: 244 Train Loss: 3.5541 (Forecasting Loss:0.3489 + XiCon Loss:3.2052 x Lambda(1.0)), Vali MSE Loss: 0.3670 Test MSE Loss: 0.2953
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6010642
	speed: 0.1170s/iter; left time: 2758.3120s
	iters: 200, epoch: 4 | loss: 3.5320566
	speed: 0.1085s/iter; left time: 2546.5069s
Epoch: 4 cost time: 27.335395097732544
Epoch: 4, Steps: 244 Train Loss: 3.5562 (Forecasting Loss:0.3433 + XiCon Loss:3.2129 x Lambda(1.0)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.2893
Validation loss decreased (0.366907 --> 0.340465).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5162852
	speed: 0.1153s/iter; left time: 2689.3857s
	iters: 200, epoch: 5 | loss: 3.4789209
	speed: 0.1113s/iter; left time: 2585.6258s
Epoch: 5 cost time: 27.635705709457397
Epoch: 5, Steps: 244 Train Loss: 3.5480 (Forecasting Loss:0.3410 + XiCon Loss:3.2070 x Lambda(1.0)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.2911
Validation loss decreased (0.340465 --> 0.339348).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5491662
	speed: 0.1108s/iter; left time: 2557.7983s
	iters: 200, epoch: 6 | loss: 3.5797811
	speed: 0.1058s/iter; left time: 2430.4102s
Epoch: 6 cost time: 26.57263445854187
Epoch: 6, Steps: 244 Train Loss: 3.5421 (Forecasting Loss:0.3400 + XiCon Loss:3.2021 x Lambda(1.0)), Vali MSE Loss: 0.3389 Test MSE Loss: 0.2898
Validation loss decreased (0.339348 --> 0.338880).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5394306
	speed: 0.1155s/iter; left time: 2637.5241s
	iters: 200, epoch: 7 | loss: 3.5330145
	speed: 0.1096s/iter; left time: 2490.9276s
Epoch: 7 cost time: 27.142051696777344
Epoch: 7, Steps: 244 Train Loss: 3.5375 (Forecasting Loss:0.3401 + XiCon Loss:3.1975 x Lambda(1.0)), Vali MSE Loss: 0.3367 Test MSE Loss: 0.2903
Validation loss decreased (0.338880 --> 0.336652).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5538568
	speed: 0.1124s/iter; left time: 2539.0019s
	iters: 200, epoch: 8 | loss: 3.5404265
	speed: 0.1093s/iter; left time: 2459.4077s
Epoch: 8 cost time: 27.076435089111328
Epoch: 8, Steps: 244 Train Loss: 3.5390 (Forecasting Loss:0.3397 + XiCon Loss:3.1993 x Lambda(1.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2906
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4811752
	speed: 0.1094s/iter; left time: 2445.3586s
	iters: 200, epoch: 9 | loss: 3.5603888
	speed: 0.1092s/iter; left time: 2428.5154s
Epoch: 9 cost time: 26.835691690444946
Epoch: 9, Steps: 244 Train Loss: 3.5333 (Forecasting Loss:0.3392 + XiCon Loss:3.1941 x Lambda(1.0)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.2904
Validation loss decreased (0.336652 --> 0.336042).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4692783
	speed: 0.1146s/iter; left time: 2532.7817s
	iters: 200, epoch: 10 | loss: 3.4906292
	speed: 0.1094s/iter; left time: 2407.7317s
Epoch: 10 cost time: 27.15282154083252
Epoch: 10, Steps: 244 Train Loss: 3.5314 (Forecasting Loss:0.3392 + XiCon Loss:3.1922 x Lambda(1.0)), Vali MSE Loss: 0.3349 Test MSE Loss: 0.2904
Validation loss decreased (0.336042 --> 0.334864).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5507228
	speed: 0.1147s/iter; left time: 2506.6009s
	iters: 200, epoch: 11 | loss: 3.5121903
	speed: 0.1114s/iter; left time: 2425.1532s
Epoch: 11 cost time: 27.509275197982788
Epoch: 11, Steps: 244 Train Loss: 3.5344 (Forecasting Loss:0.3394 + XiCon Loss:3.1949 x Lambda(1.0)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.2904
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5208864
	speed: 0.1068s/iter; left time: 2309.1689s
	iters: 200, epoch: 12 | loss: 3.5505307
	speed: 0.1083s/iter; left time: 2330.8302s
Epoch: 12 cost time: 26.439505100250244
Epoch: 12, Steps: 244 Train Loss: 3.5336 (Forecasting Loss:0.3394 + XiCon Loss:3.1941 x Lambda(1.0)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.2904
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6107171
	speed: 0.1154s/iter; left time: 2466.9765s
	iters: 200, epoch: 13 | loss: 3.5720453
	speed: 0.1107s/iter; left time: 2355.3392s
Epoch: 13 cost time: 27.203057289123535
Epoch: 13, Steps: 244 Train Loss: 3.5334 (Forecasting Loss:0.3392 + XiCon Loss:3.1943 x Lambda(1.0)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.2903
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5592480
	speed: 0.1128s/iter; left time: 2384.3113s
	iters: 200, epoch: 14 | loss: 3.4895611
	speed: 0.1112s/iter; left time: 2337.9547s
Epoch: 14 cost time: 27.307507038116455
Epoch: 14, Steps: 244 Train Loss: 3.5329 (Forecasting Loss:0.3391 + XiCon Loss:3.1938 x Lambda(1.0)), Vali MSE Loss: 0.3353 Test MSE Loss: 0.2904
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4928877
	speed: 0.1061s/iter; left time: 2215.5677s
	iters: 200, epoch: 15 | loss: 3.5371065
	speed: 0.1109s/iter; left time: 2305.8904s
Epoch: 15 cost time: 26.546818733215332
Epoch: 15, Steps: 244 Train Loss: 3.5348 (Forecasting Loss:0.3393 + XiCon Loss:3.1955 x Lambda(1.0)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.2904
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.5010023
	speed: 0.1173s/iter; left time: 2421.8816s
	iters: 200, epoch: 16 | loss: 3.5769663
	speed: 0.1090s/iter; left time: 2239.3071s
Epoch: 16 cost time: 27.336149215698242
Epoch: 16, Steps: 244 Train Loss: 3.5322 (Forecasting Loss:0.3391 + XiCon Loss:3.1932 x Lambda(1.0)), Vali MSE Loss: 0.3350 Test MSE Loss: 0.2904
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5307424
	speed: 0.1142s/iter; left time: 2329.5703s
	iters: 200, epoch: 17 | loss: 3.5084503
	speed: 0.1112s/iter; left time: 2256.7867s
Epoch: 17 cost time: 27.669047832489014
Epoch: 17, Steps: 244 Train Loss: 3.5316 (Forecasting Loss:0.3389 + XiCon Loss:3.1927 x Lambda(1.0)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.2904
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.5158348
	speed: 0.1072s/iter; left time: 2160.9081s
	iters: 200, epoch: 18 | loss: 3.5494804
	speed: 0.1113s/iter; left time: 2231.7520s
Epoch: 18 cost time: 26.680864334106445
Epoch: 18, Steps: 244 Train Loss: 3.5350 (Forecasting Loss:0.3396 + XiCon Loss:3.1954 x Lambda(1.0)), Vali MSE Loss: 0.3351 Test MSE Loss: 0.2904
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4872463
	speed: 0.1159s/iter; left time: 2308.0622s
	iters: 200, epoch: 19 | loss: 3.5481572
	speed: 0.1086s/iter; left time: 2150.8942s
Epoch: 19 cost time: 26.893811225891113
Epoch: 19, Steps: 244 Train Loss: 3.5338 (Forecasting Loss:0.3393 + XiCon Loss:3.1946 x Lambda(1.0)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.2904
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.5225077
	speed: 0.1132s/iter; left time: 2226.9382s
	iters: 200, epoch: 20 | loss: 3.5339842
	speed: 0.1122s/iter; left time: 2195.2806s
Epoch: 20 cost time: 27.5192928314209
Epoch: 20, Steps: 244 Train Loss: 3.5336 (Forecasting Loss:0.3393 + XiCon Loss:3.1943 x Lambda(1.0)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.2904
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.21230116486549377, mae:0.368545264005661, mape:0.6654021739959717, mspe:17.113832473754883 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2329+-0.02869, MAE:0.3848+-0.02080, MAPE:0.6889+-0.04356, MSPE:17.9647+-2.89284, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.6581
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8569445
	speed: 0.2218s/iter; left time: 5146.7420s
	iters: 200, epoch: 1 | loss: 0.8825793
	speed: 0.2176s/iter; left time: 5026.6906s
Epoch: 1 cost time: 51.732232332229614
Epoch: 1, Steps: 233 Train Loss: 0.8841 (Forecasting Loss:0.5456 + XiCon Loss:3.3849 x Lambda(0.1)), Vali MSE Loss: 0.4974 Test MSE Loss: 0.3892
Validation loss decreased (inf --> 0.497400).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7182029
	speed: 0.2339s/iter; left time: 5372.3459s
	iters: 200, epoch: 2 | loss: 0.7046548
	speed: 0.2254s/iter; left time: 5155.2368s
Epoch: 2 cost time: 53.11984419822693
Epoch: 2, Steps: 233 Train Loss: 0.7297 (Forecasting Loss:0.3959 + XiCon Loss:3.3374 x Lambda(0.1)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.3444
Validation loss decreased (0.497400 --> 0.377084).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7082120
	speed: 0.2276s/iter; left time: 5174.3578s
	iters: 200, epoch: 3 | loss: 0.6999216
	speed: 0.2225s/iter; left time: 5035.3868s
Epoch: 3 cost time: 52.70301413536072
Epoch: 3, Steps: 233 Train Loss: 0.7044 (Forecasting Loss:0.3755 + XiCon Loss:3.2891 x Lambda(0.1)), Vali MSE Loss: 0.3777 Test MSE Loss: 0.3370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6866922
	speed: 0.2268s/iter; left time: 5103.3256s
	iters: 200, epoch: 4 | loss: 0.6773236
	speed: 0.2215s/iter; left time: 4961.8030s
Epoch: 4 cost time: 52.51209878921509
Epoch: 4, Steps: 233 Train Loss: 0.6958 (Forecasting Loss:0.3689 + XiCon Loss:3.2687 x Lambda(0.1)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3243
Validation loss decreased (0.377084 --> 0.374692).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.7052623
	speed: 0.2241s/iter; left time: 4991.5335s
	iters: 200, epoch: 5 | loss: 0.6943823
	speed: 0.2261s/iter; left time: 5012.2880s
Epoch: 5 cost time: 53.036969900131226
Epoch: 5, Steps: 233 Train Loss: 0.6912 (Forecasting Loss:0.3655 + XiCon Loss:3.2574 x Lambda(0.1)), Vali MSE Loss: 0.3714 Test MSE Loss: 0.3194
Validation loss decreased (0.374692 --> 0.371398).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6874256
	speed: 0.2263s/iter; left time: 4987.8275s
	iters: 200, epoch: 6 | loss: 0.6962928
	speed: 0.2286s/iter; left time: 5014.8539s
Epoch: 6 cost time: 53.17422890663147
Epoch: 6, Steps: 233 Train Loss: 0.6885 (Forecasting Loss:0.3632 + XiCon Loss:3.2522 x Lambda(0.1)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.3224
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6902179
	speed: 0.2317s/iter; left time: 5051.4821s
	iters: 200, epoch: 7 | loss: 0.7006786
	speed: 0.2271s/iter; left time: 4928.7649s
Epoch: 7 cost time: 53.25253486633301
Epoch: 7, Steps: 233 Train Loss: 0.6870 (Forecasting Loss:0.3620 + XiCon Loss:3.2497 x Lambda(0.1)), Vali MSE Loss: 0.3711 Test MSE Loss: 0.3209
Validation loss decreased (0.371398 --> 0.371067).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6746187
	speed: 0.1633s/iter; left time: 3522.7449s
	iters: 200, epoch: 8 | loss: 0.6688810
	speed: 0.1893s/iter; left time: 4063.9802s
Epoch: 8 cost time: 41.86154007911682
Epoch: 8, Steps: 233 Train Loss: 0.6866 (Forecasting Loss:0.3616 + XiCon Loss:3.2502 x Lambda(0.1)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3212
Validation loss decreased (0.371067 --> 0.370378).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6750309
	speed: 0.2007s/iter; left time: 4282.9299s
	iters: 200, epoch: 9 | loss: 0.6870548
	speed: 0.1928s/iter; left time: 4094.4479s
Epoch: 9 cost time: 45.64259600639343
Epoch: 9, Steps: 233 Train Loss: 0.6858 (Forecasting Loss:0.3612 + XiCon Loss:3.2465 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3207
Validation loss decreased (0.370378 --> 0.368329).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.7007950
	speed: 0.1963s/iter; left time: 4141.8904s
	iters: 200, epoch: 10 | loss: 0.6940972
	speed: 0.1946s/iter; left time: 4086.7543s
Epoch: 10 cost time: 45.496891021728516
Epoch: 10, Steps: 233 Train Loss: 0.6857 (Forecasting Loss:0.3610 + XiCon Loss:3.2479 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3208
Validation loss decreased (0.368329 --> 0.368312).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6867552
	speed: 0.2013s/iter; left time: 4202.2330s
	iters: 200, epoch: 11 | loss: 0.6733717
	speed: 0.1932s/iter; left time: 4013.2164s
Epoch: 11 cost time: 45.8524067401886
Epoch: 11, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3609 + XiCon Loss:3.2474 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3207
Validation loss decreased (0.368312 --> 0.368157).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6926097
	speed: 0.1949s/iter; left time: 4021.9599s
	iters: 200, epoch: 12 | loss: 0.6754780
	speed: 0.1941s/iter; left time: 3987.4130s
Epoch: 12 cost time: 45.728084087371826
Epoch: 12, Steps: 233 Train Loss: 0.6854 (Forecasting Loss:0.3608 + XiCon Loss:3.2459 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3207
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6513836
	speed: 0.1900s/iter; left time: 3877.8865s
	iters: 200, epoch: 13 | loss: 0.6870291
	speed: 0.1925s/iter; left time: 3909.2333s
Epoch: 13 cost time: 44.640756607055664
Epoch: 13, Steps: 233 Train Loss: 0.6854 (Forecasting Loss:0.3609 + XiCon Loss:3.2452 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3207
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6936278
	speed: 0.1963s/iter; left time: 3960.6444s
	iters: 200, epoch: 14 | loss: 0.6796328
	speed: 0.1930s/iter; left time: 3874.5112s
Epoch: 14 cost time: 45.39228844642639
Epoch: 14, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3610 + XiCon Loss:3.2466 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3207
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6908798
	speed: 0.1934s/iter; left time: 3855.6943s
	iters: 200, epoch: 15 | loss: 0.6814781
	speed: 0.1942s/iter; left time: 3851.9766s
Epoch: 15 cost time: 45.22241711616516
Epoch: 15, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3610 + XiCon Loss:3.2458 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3207
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6908543
	speed: 0.1999s/iter; left time: 3939.1973s
	iters: 200, epoch: 16 | loss: 0.6790168
	speed: 0.1931s/iter; left time: 3786.0294s
Epoch: 16 cost time: 45.83657622337341
Epoch: 16, Steps: 233 Train Loss: 0.6857 (Forecasting Loss:0.3610 + XiCon Loss:3.2472 x Lambda(0.1)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.3206
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.7038676
	speed: 0.1978s/iter; left time: 3851.5026s
	iters: 200, epoch: 17 | loss: 0.7102718
	speed: 0.1920s/iter; left time: 3719.4179s
Epoch: 17 cost time: 45.097243309020996
Epoch: 17, Steps: 233 Train Loss: 0.6856 (Forecasting Loss:0.3608 + XiCon Loss:3.2475 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3206
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6786063
	speed: 0.1932s/iter; left time: 3717.8648s
	iters: 200, epoch: 18 | loss: 0.6720940
	speed: 0.1942s/iter; left time: 3716.9805s
Epoch: 18 cost time: 44.983760833740234
Epoch: 18, Steps: 233 Train Loss: 0.6853 (Forecasting Loss:0.3608 + XiCon Loss:3.2457 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3206
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.7046142
	speed: 0.1974s/iter; left time: 3752.6128s
	iters: 200, epoch: 19 | loss: 0.6880677
	speed: 0.1918s/iter; left time: 3625.8870s
Epoch: 19 cost time: 45.46806263923645
Epoch: 19, Steps: 233 Train Loss: 0.6855 (Forecasting Loss:0.3608 + XiCon Loss:3.2469 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3206
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.6867769
	speed: 0.1716s/iter; left time: 3221.2280s
	iters: 200, epoch: 20 | loss: 0.6868469
	speed: 0.1918s/iter; left time: 3581.6628s
Epoch: 20 cost time: 42.564343214035034
Epoch: 20, Steps: 233 Train Loss: 0.6854 (Forecasting Loss:0.3609 + XiCon Loss:3.2454 x Lambda(0.1)), Vali MSE Loss: 0.3684 Test MSE Loss: 0.3206
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6799731
	speed: 0.1893s/iter; left time: 3509.4052s
	iters: 200, epoch: 21 | loss: 0.6647775
	speed: 0.1905s/iter; left time: 3512.6853s
Epoch: 21 cost time: 44.48289084434509
Epoch: 21, Steps: 233 Train Loss: 0.6855 (Forecasting Loss:0.3609 + XiCon Loss:3.2459 x Lambda(0.1)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3206
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2505277097225189, mae:0.390800803899765, mape:0.6845133304595947, mspe:18.971487045288086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.9735
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.9051291
	speed: 0.1766s/iter; left time: 4096.6988s
	iters: 200, epoch: 1 | loss: 0.8437515
	speed: 0.1822s/iter; left time: 4208.0536s
Epoch: 1 cost time: 41.68878436088562
Epoch: 1, Steps: 233 Train Loss: 0.8890 (Forecasting Loss:0.5509 + XiCon Loss:3.3813 x Lambda(0.1)), Vali MSE Loss: 0.5002 Test MSE Loss: 0.4024
Validation loss decreased (inf --> 0.500158).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.7374600
	speed: 0.1846s/iter; left time: 4239.8456s
	iters: 200, epoch: 2 | loss: 0.6987020
	speed: 0.1876s/iter; left time: 4289.8846s
Epoch: 2 cost time: 43.41082167625427
Epoch: 2, Steps: 233 Train Loss: 0.7294 (Forecasting Loss:0.4013 + XiCon Loss:3.2816 x Lambda(0.1)), Vali MSE Loss: 0.3712 Test MSE Loss: 0.3173
Validation loss decreased (0.500158 --> 0.371205).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6898100
	speed: 0.1838s/iter; left time: 4179.6439s
	iters: 200, epoch: 3 | loss: 0.6780462
	speed: 0.1830s/iter; left time: 4142.5794s
Epoch: 3 cost time: 42.56176471710205
Epoch: 3, Steps: 233 Train Loss: 0.6835 (Forecasting Loss:0.3631 + XiCon Loss:3.2047 x Lambda(0.1)), Vali MSE Loss: 0.3470 Test MSE Loss: 0.3072
Validation loss decreased (0.371205 --> 0.347022).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6694638
	speed: 0.1767s/iter; left time: 3977.1204s
	iters: 200, epoch: 4 | loss: 0.6564098
	speed: 0.1914s/iter; left time: 4287.8796s
Epoch: 4 cost time: 42.599440574645996
Epoch: 4, Steps: 233 Train Loss: 0.6648 (Forecasting Loss:0.3398 + XiCon Loss:3.2499 x Lambda(0.1)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.3141
Validation loss decreased (0.347022 --> 0.323879).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6670449
	speed: 0.1822s/iter; left time: 4056.7222s
	iters: 200, epoch: 5 | loss: 0.6809413
	speed: 0.1846s/iter; left time: 4091.8396s
Epoch: 5 cost time: 42.494099855422974
Epoch: 5, Steps: 233 Train Loss: 0.6587 (Forecasting Loss:0.3327 + XiCon Loss:3.2594 x Lambda(0.1)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.3329
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6464636
	speed: 0.1884s/iter; left time: 4151.1202s
	iters: 200, epoch: 6 | loss: 0.6634992
	speed: 0.1820s/iter; left time: 3992.4897s
Epoch: 6 cost time: 42.94277882575989
Epoch: 6, Steps: 233 Train Loss: 0.6567 (Forecasting Loss:0.3305 + XiCon Loss:3.2615 x Lambda(0.1)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.3165
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6541729
	speed: 0.1815s/iter; left time: 3957.0842s
	iters: 200, epoch: 7 | loss: 0.6626078
	speed: 0.1895s/iter; left time: 4113.7318s
Epoch: 7 cost time: 42.966394901275635
Epoch: 7, Steps: 233 Train Loss: 0.6555 (Forecasting Loss:0.3294 + XiCon Loss:3.2615 x Lambda(0.1)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.3192
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6527016
	speed: 0.1865s/iter; left time: 4021.9955s
	iters: 200, epoch: 8 | loss: 0.6530143
	speed: 0.1752s/iter; left time: 3761.9019s
Epoch: 8 cost time: 42.007761001586914
Epoch: 8, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3287 + XiCon Loss:3.2632 x Lambda(0.1)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.3187
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6583816
	speed: 0.1883s/iter; left time: 4018.2008s
	iters: 200, epoch: 9 | loss: 0.6513028
	speed: 0.1788s/iter; left time: 3797.0626s
Epoch: 9 cost time: 42.48532581329346
Epoch: 9, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3287 + XiCon Loss:3.2635 x Lambda(0.1)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.3195
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6525800
	speed: 0.1891s/iter; left time: 3991.5901s
	iters: 200, epoch: 10 | loss: 0.6312204
	speed: 0.1455s/iter; left time: 3056.2318s
Epoch: 10 cost time: 39.3670608997345
Epoch: 10, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3287 + XiCon Loss:3.2633 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.3167
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6378751
	speed: 0.1805s/iter; left time: 3767.5175s
	iters: 200, epoch: 11 | loss: 0.6578074
	speed: 0.1828s/iter; left time: 3796.9787s
Epoch: 11 cost time: 41.97033882141113
Epoch: 11, Steps: 233 Train Loss: 0.6549 (Forecasting Loss:0.3285 + XiCon Loss:3.2633 x Lambda(0.1)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.3184
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6661439
	speed: 0.1812s/iter; left time: 3740.1054s
	iters: 200, epoch: 12 | loss: 0.6766064
	speed: 0.1769s/iter; left time: 3634.0127s
Epoch: 12 cost time: 41.98857569694519
Epoch: 12, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3286 + XiCon Loss:3.2634 x Lambda(0.1)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.3182
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6645939
	speed: 0.1840s/iter; left time: 3754.9494s
	iters: 200, epoch: 13 | loss: 0.6692513
	speed: 0.1858s/iter; left time: 3772.9953s
Epoch: 13 cost time: 43.14180016517639
Epoch: 13, Steps: 233 Train Loss: 0.6551 (Forecasting Loss:0.3288 + XiCon Loss:3.2639 x Lambda(0.1)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.3179
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6615524
	speed: 0.1835s/iter; left time: 3701.4931s
	iters: 200, epoch: 14 | loss: 0.6502243
	speed: 0.1812s/iter; left time: 3637.7179s
Epoch: 14 cost time: 42.31235718727112
Epoch: 14, Steps: 233 Train Loss: 0.6546 (Forecasting Loss:0.3284 + XiCon Loss:3.2623 x Lambda(0.1)), Vali MSE Loss: 0.3261 Test MSE Loss: 0.3180
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2354879081249237, mae:0.39272892475128174, mape:0.6280032396316528, mspe:13.920926094055176 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.7237
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8645269
	speed: 0.1742s/iter; left time: 4042.5879s
	iters: 200, epoch: 1 | loss: 0.9040644
	speed: 0.1801s/iter; left time: 4161.0375s
Epoch: 1 cost time: 41.777425050735474
Epoch: 1, Steps: 233 Train Loss: 0.8928 (Forecasting Loss:0.5542 + XiCon Loss:3.3861 x Lambda(0.1)), Vali MSE Loss: 0.5434 Test MSE Loss: 0.4560
Validation loss decreased (inf --> 0.543405).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6823409
	speed: 0.1842s/iter; left time: 4230.0063s
	iters: 200, epoch: 2 | loss: 0.6592119
	speed: 0.1881s/iter; left time: 4301.4895s
Epoch: 2 cost time: 43.419148683547974
Epoch: 2, Steps: 233 Train Loss: 0.7255 (Forecasting Loss:0.3985 + XiCon Loss:3.2704 x Lambda(0.1)), Vali MSE Loss: 0.3590 Test MSE Loss: 0.3064
Validation loss decreased (0.543405 --> 0.359036).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.7145377
	speed: 0.1923s/iter; left time: 4372.0680s
	iters: 200, epoch: 3 | loss: 0.6535467
	speed: 0.1764s/iter; left time: 3993.3379s
Epoch: 3 cost time: 42.754202127456665
Epoch: 3, Steps: 233 Train Loss: 0.6630 (Forecasting Loss:0.3351 + XiCon Loss:3.2794 x Lambda(0.1)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.2970
Validation loss decreased (0.359036 --> 0.311060).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6514897
	speed: 0.1835s/iter; left time: 4129.6575s
	iters: 200, epoch: 4 | loss: 0.6456743
	speed: 0.1777s/iter; left time: 3981.5598s
Epoch: 4 cost time: 43.101181745529175
Epoch: 4, Steps: 233 Train Loss: 0.6579 (Forecasting Loss:0.3298 + XiCon Loss:3.2816 x Lambda(0.1)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2997
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6555284
	speed: 0.1856s/iter; left time: 4133.0221s
	iters: 200, epoch: 5 | loss: 0.6284535
	speed: 0.1871s/iter; left time: 4147.2286s
Epoch: 5 cost time: 42.95703315734863
Epoch: 5, Steps: 233 Train Loss: 0.6550 (Forecasting Loss:0.3276 + XiCon Loss:3.2746 x Lambda(0.1)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.2970
Validation loss decreased (0.311060 --> 0.306888).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6609105
	speed: 0.1822s/iter; left time: 4014.7306s
	iters: 200, epoch: 6 | loss: 0.6499426
	speed: 0.1850s/iter; left time: 4058.5050s
Epoch: 6 cost time: 42.437090158462524
Epoch: 6, Steps: 233 Train Loss: 0.6537 (Forecasting Loss:0.3268 + XiCon Loss:3.2688 x Lambda(0.1)), Vali MSE Loss: 0.3057 Test MSE Loss: 0.2973
Validation loss decreased (0.306888 --> 0.305670).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6510437
	speed: 0.1827s/iter; left time: 3982.8534s
	iters: 200, epoch: 7 | loss: 0.6738405
	speed: 0.1788s/iter; left time: 3880.2796s
Epoch: 7 cost time: 41.898995876312256
Epoch: 7, Steps: 233 Train Loss: 0.6527 (Forecasting Loss:0.3260 + XiCon Loss:3.2667 x Lambda(0.1)), Vali MSE Loss: 0.3074 Test MSE Loss: 0.2934
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6529072
	speed: 0.1802s/iter; left time: 3886.9938s
	iters: 200, epoch: 8 | loss: 0.6395510
	speed: 0.1635s/iter; left time: 3510.4876s
Epoch: 8 cost time: 39.03582763671875
Epoch: 8, Steps: 233 Train Loss: 0.6523 (Forecasting Loss:0.3258 + XiCon Loss:3.2649 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2963
Validation loss decreased (0.305670 --> 0.304919).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6878275
	speed: 0.1777s/iter; left time: 3790.7156s
	iters: 200, epoch: 9 | loss: 0.6697573
	speed: 0.1844s/iter; left time: 3915.3995s
Epoch: 9 cost time: 41.895768880844116
Epoch: 9, Steps: 233 Train Loss: 0.6523 (Forecasting Loss:0.3254 + XiCon Loss:3.2689 x Lambda(0.1)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.2964
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6596134
	speed: 0.1848s/iter; left time: 3900.4426s
	iters: 200, epoch: 10 | loss: 0.6490582
	speed: 0.1844s/iter; left time: 3874.0406s
Epoch: 10 cost time: 42.970529079437256
Epoch: 10, Steps: 233 Train Loss: 0.6521 (Forecasting Loss:0.3256 + XiCon Loss:3.2652 x Lambda(0.1)), Vali MSE Loss: 0.3052 Test MSE Loss: 0.2969
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6429240
	speed: 0.1861s/iter; left time: 3883.4129s
	iters: 200, epoch: 11 | loss: 0.6374407
	speed: 0.1859s/iter; left time: 3860.5697s
Epoch: 11 cost time: 43.083560943603516
Epoch: 11, Steps: 233 Train Loss: 0.6524 (Forecasting Loss:0.3258 + XiCon Loss:3.2655 x Lambda(0.1)), Vali MSE Loss: 0.3053 Test MSE Loss: 0.2967
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6711006
	speed: 0.1857s/iter; left time: 3831.5414s
	iters: 200, epoch: 12 | loss: 0.6411085
	speed: 0.1883s/iter; left time: 3867.2577s
Epoch: 12 cost time: 43.50255346298218
Epoch: 12, Steps: 233 Train Loss: 0.6521 (Forecasting Loss:0.3256 + XiCon Loss:3.2648 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6509924
	speed: 0.1877s/iter; left time: 3829.4749s
	iters: 200, epoch: 13 | loss: 0.6621314
	speed: 0.1800s/iter; left time: 3655.4643s
Epoch: 13 cost time: 42.70690107345581
Epoch: 13, Steps: 233 Train Loss: 0.6520 (Forecasting Loss:0.3255 + XiCon Loss:3.2649 x Lambda(0.1)), Vali MSE Loss: 0.3051 Test MSE Loss: 0.2968
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6637392
	speed: 0.1824s/iter; left time: 3680.1374s
	iters: 200, epoch: 14 | loss: 0.6482751
	speed: 0.1849s/iter; left time: 3711.3800s
Epoch: 14 cost time: 42.6395058631897
Epoch: 14, Steps: 233 Train Loss: 0.6519 (Forecasting Loss:0.3251 + XiCon Loss:3.2678 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6325260
	speed: 0.1797s/iter; left time: 3583.0348s
	iters: 200, epoch: 15 | loss: 0.6657848
	speed: 0.1926s/iter; left time: 3821.7852s
Epoch: 15 cost time: 43.1304817199707
Epoch: 15, Steps: 233 Train Loss: 0.6520 (Forecasting Loss:0.3257 + XiCon Loss:3.2629 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6468331
	speed: 0.1902s/iter; left time: 3749.0236s
	iters: 200, epoch: 16 | loss: 0.6504409
	speed: 0.1823s/iter; left time: 3574.0048s
Epoch: 16 cost time: 43.52718186378479
Epoch: 16, Steps: 233 Train Loss: 0.6523 (Forecasting Loss:0.3256 + XiCon Loss:3.2670 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 0.6528025
	speed: 0.1848s/iter; left time: 3599.4762s
	iters: 200, epoch: 17 | loss: 0.6669329
	speed: 0.1864s/iter; left time: 3611.1009s
Epoch: 17 cost time: 43.013423204422
Epoch: 17, Steps: 233 Train Loss: 0.6518 (Forecasting Loss:0.3253 + XiCon Loss:3.2658 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2968
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 0.6544860
	speed: 0.1829s/iter; left time: 3519.1191s
	iters: 200, epoch: 18 | loss: 0.6682826
	speed: 0.1796s/iter; left time: 3437.9758s
Epoch: 18 cost time: 42.43622541427612
Epoch: 18, Steps: 233 Train Loss: 0.6522 (Forecasting Loss:0.3257 + XiCon Loss:3.2654 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2968
Validation loss decreased (0.304919 --> 0.304918).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 0.6586137
	speed: 0.1857s/iter; left time: 3528.9278s
	iters: 200, epoch: 19 | loss: 0.6385301
	speed: 0.1856s/iter; left time: 3510.0300s
Epoch: 19 cost time: 43.291996479034424
Epoch: 19, Steps: 233 Train Loss: 0.6522 (Forecasting Loss:0.3255 + XiCon Loss:3.2666 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 0.6645250
	speed: 0.1904s/iter; left time: 3573.9339s
	iters: 200, epoch: 20 | loss: 0.6525025
	speed: 0.1899s/iter; left time: 3546.4478s
Epoch: 20 cost time: 44.01751780509949
Epoch: 20, Steps: 233 Train Loss: 0.6519 (Forecasting Loss:0.3254 + XiCon Loss:3.2654 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 0.6406059
	speed: 0.1661s/iter; left time: 3079.9804s
	iters: 200, epoch: 21 | loss: 0.6668333
	speed: 0.1786s/iter; left time: 3293.0863s
Epoch: 21 cost time: 40.595142126083374
Epoch: 21, Steps: 233 Train Loss: 0.6517 (Forecasting Loss:0.3253 + XiCon Loss:3.2636 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 0.6529596
	speed: 0.1842s/iter; left time: 3373.1346s
	iters: 200, epoch: 22 | loss: 0.6436521
	speed: 0.1826s/iter; left time: 3324.4774s
Epoch: 22 cost time: 42.8238787651062
Epoch: 22, Steps: 233 Train Loss: 0.6522 (Forecasting Loss:0.3257 + XiCon Loss:3.2651 x Lambda(0.1)), Vali MSE Loss: 0.3052 Test MSE Loss: 0.2968
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 0.6620225
	speed: 0.1855s/iter; left time: 3353.2404s
	iters: 200, epoch: 23 | loss: 0.6519983
	speed: 0.1804s/iter; left time: 3243.0781s
Epoch: 23 cost time: 43.35849452018738
Epoch: 23, Steps: 233 Train Loss: 0.6525 (Forecasting Loss:0.3257 + XiCon Loss:3.2682 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 0.6771858
	speed: 0.1859s/iter; left time: 3317.6263s
	iters: 200, epoch: 24 | loss: 0.6657310
	speed: 0.1779s/iter; left time: 3155.9084s
Epoch: 24 cost time: 42.21818447113037
Epoch: 24, Steps: 233 Train Loss: 0.6521 (Forecasting Loss:0.3256 + XiCon Loss:3.2654 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 0.6622351
	speed: 0.1852s/iter; left time: 3261.7775s
	iters: 200, epoch: 25 | loss: 0.6486654
	speed: 0.1855s/iter; left time: 3248.1778s
Epoch: 25 cost time: 43.423871755599976
Epoch: 25, Steps: 233 Train Loss: 0.6520 (Forecasting Loss:0.3253 + XiCon Loss:3.2668 x Lambda(0.1)), Vali MSE Loss: 0.3049 Test MSE Loss: 0.2968
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 0.6798211
	speed: 0.1855s/iter; left time: 3224.0956s
	iters: 200, epoch: 26 | loss: 0.6478945
	speed: 0.1832s/iter; left time: 3165.3282s
Epoch: 26 cost time: 42.87854719161987
Epoch: 26, Steps: 233 Train Loss: 0.6522 (Forecasting Loss:0.3256 + XiCon Loss:3.2654 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 0.6665686
	speed: 0.1811s/iter; left time: 3105.3125s
	iters: 200, epoch: 27 | loss: 0.6796072
	speed: 0.1865s/iter; left time: 3177.8999s
Epoch: 27 cost time: 42.57504200935364
Epoch: 27, Steps: 233 Train Loss: 0.6526 (Forecasting Loss:0.3256 + XiCon Loss:3.2692 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.2968
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 0.6553712
	speed: 0.1817s/iter; left time: 3071.7904s
	iters: 200, epoch: 28 | loss: 0.6354319
	speed: 0.1779s/iter; left time: 2990.9084s
Epoch: 28 cost time: 41.79924750328064
Epoch: 28, Steps: 233 Train Loss: 0.6524 (Forecasting Loss:0.3259 + XiCon Loss:3.2652 x Lambda(0.1)), Vali MSE Loss: 0.3051 Test MSE Loss: 0.2968
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21689987182617188, mae:0.3767203092575073, mape:0.6289718151092529, mspe:14.446998596191406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.0602
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8402930
	speed: 0.1754s/iter; left time: 4069.1176s
	iters: 200, epoch: 1 | loss: 0.8513177
	speed: 0.1771s/iter; left time: 4090.4889s
Epoch: 1 cost time: 41.6601140499115
Epoch: 1, Steps: 233 Train Loss: 0.8896 (Forecasting Loss:0.5506 + XiCon Loss:3.3897 x Lambda(0.1)), Vali MSE Loss: 0.5321 Test MSE Loss: 0.4415
Validation loss decreased (inf --> 0.532065).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6652064
	speed: 0.1814s/iter; left time: 4166.2536s
	iters: 200, epoch: 2 | loss: 0.6576316
	speed: 0.2052s/iter; left time: 4693.5007s
Epoch: 2 cost time: 45.59057283401489
Epoch: 2, Steps: 233 Train Loss: 0.7145 (Forecasting Loss:0.3839 + XiCon Loss:3.3059 x Lambda(0.1)), Vali MSE Loss: 0.3411 Test MSE Loss: 0.2902
Validation loss decreased (0.532065 --> 0.341091).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6512688
	speed: 0.2342s/iter; left time: 5324.9673s
	iters: 200, epoch: 3 | loss: 0.6639776
	speed: 0.2344s/iter; left time: 5305.5358s
Epoch: 3 cost time: 54.90716361999512
Epoch: 3, Steps: 233 Train Loss: 0.6531 (Forecasting Loss:0.3236 + XiCon Loss:3.2946 x Lambda(0.1)), Vali MSE Loss: 0.3716 Test MSE Loss: 0.2880
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6440458
	speed: 0.2089s/iter; left time: 4701.7445s
	iters: 200, epoch: 4 | loss: 0.6484671
	speed: 0.2716s/iter; left time: 6083.9266s
Epoch: 4 cost time: 56.84184408187866
Epoch: 4, Steps: 233 Train Loss: 0.6453 (Forecasting Loss:0.3163 + XiCon Loss:3.2907 x Lambda(0.1)), Vali MSE Loss: 0.4070 Test MSE Loss: 0.2919
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6329069
	speed: 0.2696s/iter; left time: 6003.1148s
	iters: 200, epoch: 5 | loss: 0.6310418
	speed: 0.2781s/iter; left time: 6164.8451s
Epoch: 5 cost time: 63.92402529716492
Epoch: 5, Steps: 233 Train Loss: 0.6429 (Forecasting Loss:0.3136 + XiCon Loss:3.2925 x Lambda(0.1)), Vali MSE Loss: 0.3900 Test MSE Loss: 0.2923
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6534200
	speed: 0.2625s/iter; left time: 5784.8861s
	iters: 200, epoch: 6 | loss: 0.6281303
	speed: 0.2826s/iter; left time: 6199.4003s
Epoch: 6 cost time: 63.612032413482666
Epoch: 6, Steps: 233 Train Loss: 0.6417 (Forecasting Loss:0.3125 + XiCon Loss:3.2919 x Lambda(0.1)), Vali MSE Loss: 0.3908 Test MSE Loss: 0.2936
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6714303
	speed: 0.2747s/iter; left time: 5990.1787s
	iters: 200, epoch: 7 | loss: 0.6101195
	speed: 0.2753s/iter; left time: 5974.2058s
Epoch: 7 cost time: 64.06656527519226
Epoch: 7, Steps: 233 Train Loss: 0.6408 (Forecasting Loss:0.3118 + XiCon Loss:3.2901 x Lambda(0.1)), Vali MSE Loss: 0.3856 Test MSE Loss: 0.2921
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6417404
	speed: 0.2742s/iter; left time: 5915.0125s
	iters: 200, epoch: 8 | loss: 0.6254752
	speed: 0.2740s/iter; left time: 5882.2966s
Epoch: 8 cost time: 63.69673228263855
Epoch: 8, Steps: 233 Train Loss: 0.6407 (Forecasting Loss:0.3117 + XiCon Loss:3.2903 x Lambda(0.1)), Vali MSE Loss: 0.3873 Test MSE Loss: 0.2906
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6236172
	speed: 0.2798s/iter; left time: 5969.2667s
	iters: 200, epoch: 9 | loss: 0.6515951
	speed: 0.2730s/iter; left time: 5797.3393s
Epoch: 9 cost time: 64.65956044197083
Epoch: 9, Steps: 233 Train Loss: 0.6407 (Forecasting Loss:0.3115 + XiCon Loss:3.2920 x Lambda(0.1)), Vali MSE Loss: 0.3871 Test MSE Loss: 0.2918
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6417385
	speed: 0.2817s/iter; left time: 5944.5847s
	iters: 200, epoch: 10 | loss: 0.6459342
	speed: 0.2735s/iter; left time: 5745.3882s
Epoch: 10 cost time: 64.34496068954468
Epoch: 10, Steps: 233 Train Loss: 0.6402 (Forecasting Loss:0.3111 + XiCon Loss:3.2907 x Lambda(0.1)), Vali MSE Loss: 0.3873 Test MSE Loss: 0.2917
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6361698
	speed: 0.2768s/iter; left time: 5777.1622s
	iters: 200, epoch: 11 | loss: 0.6481904
	speed: 0.2746s/iter; left time: 5704.5309s
Epoch: 11 cost time: 64.6002745628357
Epoch: 11, Steps: 233 Train Loss: 0.6402 (Forecasting Loss:0.3114 + XiCon Loss:3.2888 x Lambda(0.1)), Vali MSE Loss: 0.3885 Test MSE Loss: 0.2919
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6356696
	speed: 0.2813s/iter; left time: 5806.0939s
	iters: 200, epoch: 12 | loss: 0.6316093
	speed: 0.2792s/iter; left time: 5733.5105s
Epoch: 12 cost time: 65.37525296211243
Epoch: 12, Steps: 233 Train Loss: 0.6401 (Forecasting Loss:0.3112 + XiCon Loss:3.2892 x Lambda(0.1)), Vali MSE Loss: 0.3883 Test MSE Loss: 0.2920
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21140500903129578, mae:0.36906322836875916, mape:0.6596061587333679, mspe:16.65989112854004 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.8186
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 0.8916349
	speed: 0.1872s/iter; left time: 4342.5548s
	iters: 200, epoch: 1 | loss: 0.8835578
	speed: 0.1939s/iter; left time: 4478.9283s
Epoch: 1 cost time: 44.43121886253357
Epoch: 1, Steps: 233 Train Loss: 0.8980 (Forecasting Loss:0.5587 + XiCon Loss:3.3926 x Lambda(0.1)), Vali MSE Loss: 0.5595 Test MSE Loss: 0.4754
Validation loss decreased (inf --> 0.559488).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.6797522
	speed: 0.1973s/iter; left time: 4531.1914s
	iters: 200, epoch: 2 | loss: 0.6410407
	speed: 0.2140s/iter; left time: 4894.8111s
Epoch: 2 cost time: 48.629762411117554
Epoch: 2, Steps: 233 Train Loss: 0.7046 (Forecasting Loss:0.3773 + XiCon Loss:3.2722 x Lambda(0.1)), Vali MSE Loss: 0.3833 Test MSE Loss: 0.2967
Validation loss decreased (0.559488 --> 0.383338).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.6632457
	speed: 0.2333s/iter; left time: 5303.9882s
	iters: 200, epoch: 3 | loss: 0.6446158
	speed: 0.2394s/iter; left time: 5419.8277s
Epoch: 3 cost time: 55.28200721740723
Epoch: 3, Steps: 233 Train Loss: 0.6544 (Forecasting Loss:0.3258 + XiCon Loss:3.2855 x Lambda(0.1)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.3032
Validation loss decreased (0.383338 --> 0.358900).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.6401339
	speed: 0.1855s/iter; left time: 4173.3727s
	iters: 200, epoch: 4 | loss: 0.6480041
	speed: 0.2329s/iter; left time: 5217.2362s
Epoch: 4 cost time: 49.65943431854248
Epoch: 4, Steps: 233 Train Loss: 0.6517 (Forecasting Loss:0.3208 + XiCon Loss:3.3090 x Lambda(0.1)), Vali MSE Loss: 0.3481 Test MSE Loss: 0.2990
Validation loss decreased (0.358900 --> 0.348129).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.6297952
	speed: 0.2389s/iter; left time: 5320.8863s
	iters: 200, epoch: 5 | loss: 0.6682582
	speed: 0.2356s/iter; left time: 5222.9953s
Epoch: 5 cost time: 55.19857478141785
Epoch: 5, Steps: 233 Train Loss: 0.6501 (Forecasting Loss:0.3186 + XiCon Loss:3.3152 x Lambda(0.1)), Vali MSE Loss: 0.3449 Test MSE Loss: 0.2980
Validation loss decreased (0.348129 --> 0.344937).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.6299353
	speed: 0.2347s/iter; left time: 5171.3088s
	iters: 200, epoch: 6 | loss: 0.6576976
	speed: 0.2475s/iter; left time: 5428.9510s
Epoch: 6 cost time: 56.39507842063904
Epoch: 6, Steps: 233 Train Loss: 0.6493 (Forecasting Loss:0.3177 + XiCon Loss:3.3159 x Lambda(0.1)), Vali MSE Loss: 0.3412 Test MSE Loss: 0.2977
Validation loss decreased (0.344937 --> 0.341161).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.6392584
	speed: 0.2477s/iter; left time: 5399.8139s
	iters: 200, epoch: 7 | loss: 0.6628638
	speed: 0.2457s/iter; left time: 5332.4542s
Epoch: 7 cost time: 57.1810781955719
Epoch: 7, Steps: 233 Train Loss: 0.6484 (Forecasting Loss:0.3169 + XiCon Loss:3.3151 x Lambda(0.1)), Vali MSE Loss: 0.3470 Test MSE Loss: 0.2975
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.6748831
	speed: 0.2476s/iter; left time: 5340.6222s
	iters: 200, epoch: 8 | loss: 0.6359967
	speed: 0.2485s/iter; left time: 5335.2438s
Epoch: 8 cost time: 57.967158794403076
Epoch: 8, Steps: 233 Train Loss: 0.6484 (Forecasting Loss:0.3167 + XiCon Loss:3.3164 x Lambda(0.1)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2983
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.6515876
	speed: 0.2506s/iter; left time: 5347.0405s
	iters: 200, epoch: 9 | loss: 0.6439717
	speed: 0.2417s/iter; left time: 5132.7377s
Epoch: 9 cost time: 57.30353927612305
Epoch: 9, Steps: 233 Train Loss: 0.6482 (Forecasting Loss:0.3166 + XiCon Loss:3.3162 x Lambda(0.1)), Vali MSE Loss: 0.3458 Test MSE Loss: 0.2981
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.6346817
	speed: 0.2381s/iter; left time: 5025.1463s
	iters: 200, epoch: 10 | loss: 0.6604408
	speed: 0.2489s/iter; left time: 5228.1311s
Epoch: 10 cost time: 56.88551115989685
Epoch: 10, Steps: 233 Train Loss: 0.6480 (Forecasting Loss:0.3164 + XiCon Loss:3.3162 x Lambda(0.1)), Vali MSE Loss: 0.3446 Test MSE Loss: 0.2994
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.6564587
	speed: 0.2400s/iter; left time: 5008.9939s
	iters: 200, epoch: 11 | loss: 0.6598198
	speed: 0.2386s/iter; left time: 4956.2681s
Epoch: 11 cost time: 56.02248430252075
Epoch: 11, Steps: 233 Train Loss: 0.6481 (Forecasting Loss:0.3166 + XiCon Loss:3.3152 x Lambda(0.1)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.2983
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.6378450
	speed: 0.2443s/iter; left time: 5042.0808s
	iters: 200, epoch: 12 | loss: 0.6725156
	speed: 0.2397s/iter; left time: 4923.7141s
Epoch: 12 cost time: 56.46623682975769
Epoch: 12, Steps: 233 Train Loss: 0.6475 (Forecasting Loss:0.3160 + XiCon Loss:3.3155 x Lambda(0.1)), Vali MSE Loss: 0.3459 Test MSE Loss: 0.2983
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.6439039
	speed: 0.2398s/iter; left time: 4892.7089s
	iters: 200, epoch: 13 | loss: 0.6323717
	speed: 0.2399s/iter; left time: 4871.1204s
Epoch: 13 cost time: 56.31162095069885
Epoch: 13, Steps: 233 Train Loss: 0.6478 (Forecasting Loss:0.3162 + XiCon Loss:3.3160 x Lambda(0.1)), Vali MSE Loss: 0.3458 Test MSE Loss: 0.2984
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.6411548
	speed: 0.2459s/iter; left time: 4959.5419s
	iters: 200, epoch: 14 | loss: 0.6419244
	speed: 0.2475s/iter; left time: 4967.1409s
Epoch: 14 cost time: 57.50365447998047
Epoch: 14, Steps: 233 Train Loss: 0.6477 (Forecasting Loss:0.3164 + XiCon Loss:3.3136 x Lambda(0.1)), Vali MSE Loss: 0.3457 Test MSE Loss: 0.2984
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.6708041
	speed: 0.2463s/iter; left time: 4911.2777s
	iters: 200, epoch: 15 | loss: 0.6347365
	speed: 0.2489s/iter; left time: 4937.1770s
Epoch: 15 cost time: 57.19776391983032
Epoch: 15, Steps: 233 Train Loss: 0.6480 (Forecasting Loss:0.3163 + XiCon Loss:3.3169 x Lambda(0.1)), Vali MSE Loss: 0.3455 Test MSE Loss: 0.2984
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 0.6485940
	speed: 0.2557s/iter; left time: 5038.0565s
	iters: 200, epoch: 16 | loss: 0.6559069
	speed: 0.2441s/iter; left time: 4786.4611s
Epoch: 16 cost time: 58.072885036468506
Epoch: 16, Steps: 233 Train Loss: 0.6482 (Forecasting Loss:0.3165 + XiCon Loss:3.3171 x Lambda(0.1)), Vali MSE Loss: 0.3457 Test MSE Loss: 0.2985
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2197209745645523, mae:0.3756607472896576, mape:0.6643121242523193, mspe:16.46573829650879 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2268+-0.01986, MAE:0.3810+-0.01277, MAPE:0.6531+-0.03020, MSPE:16.0930+-2.49673, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
