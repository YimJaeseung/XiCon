Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2996
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.4034495
	speed: 0.0166s/iter; left time: 211.1580s
Epoch: 1 cost time: 1.9732437133789062
Epoch: 1, Steps: 128 Train Loss: 3.4262 (Forecasting Loss:0.2444 + XiCon Loss:3.1818 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173707).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2018242
	speed: 0.0123s/iter; left time: 154.3788s
Epoch: 2 cost time: 1.5279757976531982
Epoch: 2, Steps: 128 Train Loss: 3.2117 (Forecasting Loss:0.2452 + XiCon Loss:2.9664 x Lambda(1.0)), Vali MSE Loss: 0.1781 Test MSE Loss: 0.1304
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 2.9401028
	speed: 0.0132s/iter; left time: 164.7815s
Epoch: 3 cost time: 1.6680023670196533
Epoch: 3, Steps: 128 Train Loss: 3.1045 (Forecasting Loss:0.2297 + XiCon Loss:2.8748 x Lambda(1.0)), Vali MSE Loss: 0.1690 Test MSE Loss: 0.1244
Validation loss decreased (0.173707 --> 0.169024).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2502787
	speed: 0.0123s/iter; left time: 151.8862s
Epoch: 4 cost time: 1.5382061004638672
Epoch: 4, Steps: 128 Train Loss: 3.1416 (Forecasting Loss:0.2179 + XiCon Loss:2.9237 x Lambda(1.0)), Vali MSE Loss: 0.1816 Test MSE Loss: 0.1222
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1207042
	speed: 0.0122s/iter; left time: 148.2792s
Epoch: 5 cost time: 1.526320219039917
Epoch: 5, Steps: 128 Train Loss: 3.1408 (Forecasting Loss:0.2081 + XiCon Loss:2.9327 x Lambda(1.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1223
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0466197
	speed: 0.0121s/iter; left time: 145.9979s
Epoch: 6 cost time: 1.5211145877838135
Epoch: 6, Steps: 128 Train Loss: 3.1099 (Forecasting Loss:0.2044 + XiCon Loss:2.9055 x Lambda(1.0)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.1178
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1111915
	speed: 0.0124s/iter; left time: 148.3405s
Epoch: 7 cost time: 1.542490005493164
Epoch: 7, Steps: 128 Train Loss: 3.1045 (Forecasting Loss:0.2027 + XiCon Loss:2.9018 x Lambda(1.0)), Vali MSE Loss: 0.1816 Test MSE Loss: 0.1191
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1324580
	speed: 0.0121s/iter; left time: 142.4512s
Epoch: 8 cost time: 1.5150446891784668
Epoch: 8, Steps: 128 Train Loss: 3.0986 (Forecasting Loss:0.2019 + XiCon Loss:2.8967 x Lambda(1.0)), Vali MSE Loss: 0.1836 Test MSE Loss: 0.1205
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0948286
	speed: 0.0128s/iter; left time: 149.2519s
Epoch: 9 cost time: 1.5820293426513672
Epoch: 9, Steps: 128 Train Loss: 3.0952 (Forecasting Loss:0.2015 + XiCon Loss:2.8937 x Lambda(1.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1193
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0721881
	speed: 0.0121s/iter; left time: 139.2971s
Epoch: 10 cost time: 1.511589527130127
Epoch: 10, Steps: 128 Train Loss: 3.0985 (Forecasting Loss:0.2012 + XiCon Loss:2.8973 x Lambda(1.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1199
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1575699
	speed: 0.0121s/iter; left time: 138.5246s
Epoch: 11 cost time: 1.5276105403900146
Epoch: 11, Steps: 128 Train Loss: 3.0938 (Forecasting Loss:0.2009 + XiCon Loss:2.8929 x Lambda(1.0)), Vali MSE Loss: 0.1832 Test MSE Loss: 0.1198
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0396421
	speed: 0.0121s/iter; left time: 136.5065s
Epoch: 12 cost time: 1.5093128681182861
Epoch: 12, Steps: 128 Train Loss: 3.0953 (Forecasting Loss:0.2006 + XiCon Loss:2.8947 x Lambda(1.0)), Vali MSE Loss: 0.1831 Test MSE Loss: 0.1197
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1390581
	speed: 0.0120s/iter; left time: 133.6389s
Epoch: 13 cost time: 1.496933937072754
Epoch: 13, Steps: 128 Train Loss: 3.0944 (Forecasting Loss:0.2008 + XiCon Loss:2.8936 x Lambda(1.0)), Vali MSE Loss: 0.1831 Test MSE Loss: 0.1198
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.06012716889381409, mae:0.18861350417137146, mape:0.14949850738048553, mspe:0.04163312166929245 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1733
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3591824
	speed: 0.0124s/iter; left time: 157.8081s
Epoch: 1 cost time: 1.5410330295562744
Epoch: 1, Steps: 128 Train Loss: 3.4067 (Forecasting Loss:0.2443 + XiCon Loss:3.1624 x Lambda(1.0)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1234
Validation loss decreased (inf --> 0.175268).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.4999049
	speed: 0.0120s/iter; left time: 150.6433s
Epoch: 2 cost time: 1.5069870948791504
Epoch: 2, Steps: 128 Train Loss: 3.3511 (Forecasting Loss:0.2501 + XiCon Loss:3.1010 x Lambda(1.0)), Vali MSE Loss: 0.1827 Test MSE Loss: 0.1290
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2944500
	speed: 0.0129s/iter; left time: 160.8046s
Epoch: 3 cost time: 1.5954256057739258
Epoch: 3, Steps: 128 Train Loss: 3.3313 (Forecasting Loss:0.2291 + XiCon Loss:3.1022 x Lambda(1.0)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1194
Validation loss decreased (0.175268 --> 0.168427).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.3958778
	speed: 0.0122s/iter; left time: 150.7400s
Epoch: 4 cost time: 1.5230214595794678
Epoch: 4, Steps: 128 Train Loss: 3.3038 (Forecasting Loss:0.2210 + XiCon Loss:3.0828 x Lambda(1.0)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.1199
Validation loss decreased (0.168427 --> 0.166470).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2561235
	speed: 0.0122s/iter; left time: 148.3531s
Epoch: 5 cost time: 1.5221621990203857
Epoch: 5, Steps: 128 Train Loss: 3.2779 (Forecasting Loss:0.2175 + XiCon Loss:3.0604 x Lambda(1.0)), Vali MSE Loss: 0.1662 Test MSE Loss: 0.1157
Validation loss decreased (0.166470 --> 0.166240).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2557182
	speed: 0.0123s/iter; left time: 148.3763s
Epoch: 6 cost time: 1.5300328731536865
Epoch: 6, Steps: 128 Train Loss: 3.2565 (Forecasting Loss:0.2151 + XiCon Loss:3.0414 x Lambda(1.0)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1154
Validation loss decreased (0.166240 --> 0.165024).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.3331945
	speed: 0.0135s/iter; left time: 160.7617s
Epoch: 7 cost time: 1.6603834629058838
Epoch: 7, Steps: 128 Train Loss: 3.2672 (Forecasting Loss:0.2145 + XiCon Loss:3.0527 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1166
Validation loss decreased (0.165024 --> 0.164103).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2133265
	speed: 0.0120s/iter; left time: 141.9297s
Epoch: 8 cost time: 1.5081865787506104
Epoch: 8, Steps: 128 Train Loss: 3.2626 (Forecasting Loss:0.2138 + XiCon Loss:3.0488 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1157
Validation loss decreased (0.164103 --> 0.163659).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.2233458
	speed: 0.0122s/iter; left time: 142.2679s
Epoch: 9 cost time: 1.5310053825378418
Epoch: 9, Steps: 128 Train Loss: 3.2600 (Forecasting Loss:0.2134 + XiCon Loss:3.0467 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1969516
	speed: 0.0126s/iter; left time: 145.6306s
Epoch: 10 cost time: 1.5933077335357666
Epoch: 10, Steps: 128 Train Loss: 3.2573 (Forecasting Loss:0.2133 + XiCon Loss:3.0440 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1158
Validation loss decreased (0.163659 --> 0.163480).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.3033533
	speed: 0.0135s/iter; left time: 153.6165s
Epoch: 11 cost time: 1.6507108211517334
Epoch: 11, Steps: 128 Train Loss: 3.2578 (Forecasting Loss:0.2130 + XiCon Loss:3.0448 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2721543
	speed: 0.0121s/iter; left time: 136.4891s
Epoch: 12 cost time: 1.5094387531280518
Epoch: 12, Steps: 128 Train Loss: 3.2587 (Forecasting Loss:0.2129 + XiCon Loss:3.0458 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.3252821
	speed: 0.0120s/iter; left time: 133.7054s
Epoch: 13 cost time: 1.4958198070526123
Epoch: 13, Steps: 128 Train Loss: 3.2595 (Forecasting Loss:0.2129 + XiCon Loss:3.0466 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.2367189
	speed: 0.0122s/iter; left time: 134.3306s
Epoch: 14 cost time: 1.543215036392212
Epoch: 14, Steps: 128 Train Loss: 3.2597 (Forecasting Loss:0.2130 + XiCon Loss:3.0467 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1158
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.2811470
	speed: 0.0120s/iter; left time: 131.3544s
Epoch: 15 cost time: 1.5302696228027344
Epoch: 15, Steps: 128 Train Loss: 3.2582 (Forecasting Loss:0.2130 + XiCon Loss:3.0451 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1158
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1868057
	speed: 0.0123s/iter; left time: 132.8594s
Epoch: 16 cost time: 1.5349094867706299
Epoch: 16, Steps: 128 Train Loss: 3.2603 (Forecasting Loss:0.2129 + XiCon Loss:3.0474 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1158
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1861923
	speed: 0.0124s/iter; left time: 132.6226s
Epoch: 17 cost time: 1.5498766899108887
Epoch: 17, Steps: 128 Train Loss: 3.2576 (Forecasting Loss:0.2131 + XiCon Loss:3.0445 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1854022
	speed: 0.0119s/iter; left time: 125.5100s
Epoch: 18 cost time: 1.491258144378662
Epoch: 18, Steps: 128 Train Loss: 3.2520 (Forecasting Loss:0.2130 + XiCon Loss:3.0390 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1158
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2236204
	speed: 0.0122s/iter; left time: 127.1815s
Epoch: 19 cost time: 1.531909465789795
Epoch: 19, Steps: 128 Train Loss: 3.2553 (Forecasting Loss:0.2129 + XiCon Loss:3.0423 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.2702072
	speed: 0.0129s/iter; left time: 132.6661s
Epoch: 20 cost time: 1.5996687412261963
Epoch: 20, Steps: 128 Train Loss: 3.2517 (Forecasting Loss:0.2130 + XiCon Loss:3.0387 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1158
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05423459783196449, mae:0.17741061747074127, mape:0.14089281857013702, mspe:0.03707188740372658 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3074
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3523803
	speed: 0.0124s/iter; left time: 157.5859s
Epoch: 1 cost time: 1.536266803741455
Epoch: 1, Steps: 128 Train Loss: 3.3983 (Forecasting Loss:0.2441 + XiCon Loss:3.1542 x Lambda(1.0)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1210
Validation loss decreased (inf --> 0.170376).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.3364806
	speed: 0.0126s/iter; left time: 158.7360s
Epoch: 2 cost time: 1.609116554260254
Epoch: 2, Steps: 128 Train Loss: 3.3055 (Forecasting Loss:0.2484 + XiCon Loss:3.0571 x Lambda(1.0)), Vali MSE Loss: 0.1807 Test MSE Loss: 0.1209
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2911067
	speed: 0.0127s/iter; left time: 158.5808s
Epoch: 3 cost time: 1.5743176937103271
Epoch: 3, Steps: 128 Train Loss: 3.2369 (Forecasting Loss:0.2320 + XiCon Loss:3.0050 x Lambda(1.0)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1220
Validation loss decreased (0.170376 --> 0.165682).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1450243
	speed: 0.0127s/iter; left time: 156.2176s
Epoch: 4 cost time: 1.6006369590759277
Epoch: 4, Steps: 128 Train Loss: 3.1918 (Forecasting Loss:0.2232 + XiCon Loss:2.9686 x Lambda(1.0)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1231
Validation loss decreased (0.165682 --> 0.165664).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1899972
	speed: 0.0126s/iter; left time: 153.8620s
Epoch: 5 cost time: 1.5608322620391846
Epoch: 5, Steps: 128 Train Loss: 3.1787 (Forecasting Loss:0.2178 + XiCon Loss:2.9609 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
Validation loss decreased (0.165664 --> 0.163556).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1251292
	speed: 0.0129s/iter; left time: 155.7949s
Epoch: 6 cost time: 1.591888427734375
Epoch: 6, Steps: 128 Train Loss: 3.1698 (Forecasting Loss:0.2151 + XiCon Loss:2.9548 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1160
Validation loss decreased (0.163556 --> 0.163425).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1908870
	speed: 0.0124s/iter; left time: 148.3609s
Epoch: 7 cost time: 1.5510950088500977
Epoch: 7, Steps: 128 Train Loss: 3.1709 (Forecasting Loss:0.2144 + XiCon Loss:2.9565 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1163
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1147418
	speed: 0.0131s/iter; left time: 154.9955s
Epoch: 8 cost time: 1.6403472423553467
Epoch: 8, Steps: 128 Train Loss: 3.1720 (Forecasting Loss:0.2139 + XiCon Loss:2.9581 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1165
Validation loss decreased (0.163425 --> 0.163328).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1806693
	speed: 0.0123s/iter; left time: 143.6902s
Epoch: 9 cost time: 1.5346078872680664
Epoch: 9, Steps: 128 Train Loss: 3.1681 (Forecasting Loss:0.2136 + XiCon Loss:2.9545 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1154
Validation loss decreased (0.163328 --> 0.163054).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2211435
	speed: 0.0124s/iter; left time: 143.7345s
Epoch: 10 cost time: 1.5701444149017334
Epoch: 10, Steps: 128 Train Loss: 3.1612 (Forecasting Loss:0.2134 + XiCon Loss:2.9478 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1559269
	speed: 0.0122s/iter; left time: 139.4949s
Epoch: 11 cost time: 1.5249109268188477
Epoch: 11, Steps: 128 Train Loss: 3.1712 (Forecasting Loss:0.2130 + XiCon Loss:2.9582 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1671648
	speed: 0.0121s/iter; left time: 136.5071s
Epoch: 12 cost time: 1.509547472000122
Epoch: 12, Steps: 128 Train Loss: 3.1693 (Forecasting Loss:0.2132 + XiCon Loss:2.9560 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1154
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1080086
	speed: 0.0122s/iter; left time: 136.4006s
Epoch: 13 cost time: 1.5517611503601074
Epoch: 13, Steps: 128 Train Loss: 3.1689 (Forecasting Loss:0.2130 + XiCon Loss:2.9559 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1997263
	speed: 0.0121s/iter; left time: 133.3857s
Epoch: 14 cost time: 1.5081100463867188
Epoch: 14, Steps: 128 Train Loss: 3.1657 (Forecasting Loss:0.2132 + XiCon Loss:2.9526 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1995835
	speed: 0.0126s/iter; left time: 137.1613s
Epoch: 15 cost time: 1.593045711517334
Epoch: 15, Steps: 128 Train Loss: 3.1696 (Forecasting Loss:0.2131 + XiCon Loss:2.9565 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0975547
	speed: 0.0121s/iter; left time: 129.9992s
Epoch: 16 cost time: 1.5091161727905273
Epoch: 16, Steps: 128 Train Loss: 3.1629 (Forecasting Loss:0.2131 + XiCon Loss:2.9498 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.2585859
	speed: 0.0123s/iter; left time: 131.0564s
Epoch: 17 cost time: 1.5370001792907715
Epoch: 17, Steps: 128 Train Loss: 3.1678 (Forecasting Loss:0.2131 + XiCon Loss:2.9546 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.2157321
	speed: 0.0124s/iter; left time: 130.6875s
Epoch: 18 cost time: 1.542292833328247
Epoch: 18, Steps: 128 Train Loss: 3.1659 (Forecasting Loss:0.2131 + XiCon Loss:2.9527 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1155
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2132564
	speed: 0.0122s/iter; left time: 127.0668s
Epoch: 19 cost time: 1.5304217338562012
Epoch: 19, Steps: 128 Train Loss: 3.1639 (Forecasting Loss:0.2132 + XiCon Loss:2.9507 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1155
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05409630388021469, mae:0.17674970626831055, mape:0.14043593406677246, mspe:0.03706881031394005 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2070
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3643143
	speed: 0.0122s/iter; left time: 154.8090s
Epoch: 1 cost time: 1.523632526397705
Epoch: 1, Steps: 128 Train Loss: 3.4094 (Forecasting Loss:0.2423 + XiCon Loss:3.1671 x Lambda(1.0)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1213
Validation loss decreased (inf --> 0.172393).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.3081706
	speed: 0.0123s/iter; left time: 154.4245s
Epoch: 2 cost time: 1.5338850021362305
Epoch: 2, Steps: 128 Train Loss: 3.2791 (Forecasting Loss:0.2467 + XiCon Loss:3.0324 x Lambda(1.0)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1275
Validation loss decreased (0.172393 --> 0.172363).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.2260008
	speed: 0.0124s/iter; left time: 154.4686s
Epoch: 3 cost time: 1.5478627681732178
Epoch: 3, Steps: 128 Train Loss: 3.2517 (Forecasting Loss:0.2300 + XiCon Loss:3.0217 x Lambda(1.0)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1239
Validation loss decreased (0.172363 --> 0.170034).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1592698
	speed: 0.0124s/iter; left time: 152.5676s
Epoch: 4 cost time: 1.5442728996276855
Epoch: 4, Steps: 128 Train Loss: 3.1925 (Forecasting Loss:0.2211 + XiCon Loss:2.9714 x Lambda(1.0)), Vali MSE Loss: 0.1694 Test MSE Loss: 0.1165
Validation loss decreased (0.170034 --> 0.169428).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2570157
	speed: 0.0123s/iter; left time: 150.5107s
Epoch: 5 cost time: 1.5459387302398682
Epoch: 5, Steps: 128 Train Loss: 3.1680 (Forecasting Loss:0.2179 + XiCon Loss:2.9501 x Lambda(1.0)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1142
Validation loss decreased (0.169428 --> 0.166937).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1512551
	speed: 0.0129s/iter; left time: 155.3070s
Epoch: 6 cost time: 1.6273465156555176
Epoch: 6, Steps: 128 Train Loss: 3.1442 (Forecasting Loss:0.2154 + XiCon Loss:2.9288 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1147
Validation loss decreased (0.166937 --> 0.164130).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0599818
	speed: 0.0121s/iter; left time: 144.5479s
Epoch: 7 cost time: 1.5125477313995361
Epoch: 7, Steps: 128 Train Loss: 3.1418 (Forecasting Loss:0.2141 + XiCon Loss:2.9277 x Lambda(1.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1146
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1453400
	speed: 0.0121s/iter; left time: 142.9335s
Epoch: 8 cost time: 1.5389072895050049
Epoch: 8, Steps: 128 Train Loss: 3.1360 (Forecasting Loss:0.2132 + XiCon Loss:2.9228 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1146
Validation loss decreased (0.164130 --> 0.163931).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0664902
	speed: 0.0121s/iter; left time: 141.7082s
Epoch: 9 cost time: 1.5178558826446533
Epoch: 9, Steps: 128 Train Loss: 3.1344 (Forecasting Loss:0.2129 + XiCon Loss:2.9215 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1147
Validation loss decreased (0.163931 --> 0.163522).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2228074
	speed: 0.0129s/iter; left time: 148.6500s
Epoch: 10 cost time: 1.5867254734039307
Epoch: 10, Steps: 128 Train Loss: 3.1411 (Forecasting Loss:0.2128 + XiCon Loss:2.9283 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1149
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2532620
	speed: 0.0123s/iter; left time: 140.0690s
Epoch: 11 cost time: 1.5414013862609863
Epoch: 11, Steps: 128 Train Loss: 3.1383 (Forecasting Loss:0.2126 + XiCon Loss:2.9257 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
Validation loss decreased (0.163522 --> 0.163359).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1657927
	speed: 0.0129s/iter; left time: 145.9445s
Epoch: 12 cost time: 1.6031396389007568
Epoch: 12, Steps: 128 Train Loss: 3.1321 (Forecasting Loss:0.2127 + XiCon Loss:2.9194 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
Validation loss decreased (0.163359 --> 0.163322).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0245624
	speed: 0.0127s/iter; left time: 141.7197s
Epoch: 13 cost time: 1.5745930671691895
Epoch: 13, Steps: 128 Train Loss: 3.1321 (Forecasting Loss:0.2126 + XiCon Loss:2.9194 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.2436121
	speed: 0.0128s/iter; left time: 140.7502s
Epoch: 14 cost time: 1.5839006900787354
Epoch: 14, Steps: 128 Train Loss: 3.1298 (Forecasting Loss:0.2127 + XiCon Loss:2.9171 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1841328
	speed: 0.0122s/iter; left time: 132.6454s
Epoch: 15 cost time: 1.522148609161377
Epoch: 15, Steps: 128 Train Loss: 3.1308 (Forecasting Loss:0.2126 + XiCon Loss:2.9181 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
Validation loss decreased (0.163322 --> 0.163248).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1216037
	speed: 0.0122s/iter; left time: 131.7429s
Epoch: 16 cost time: 1.5352530479431152
Epoch: 16, Steps: 128 Train Loss: 3.1325 (Forecasting Loss:0.2124 + XiCon Loss:2.9200 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1148
Validation loss decreased (0.163248 --> 0.162934).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1182926
	speed: 0.0123s/iter; left time: 131.3083s
Epoch: 17 cost time: 1.540952444076538
Epoch: 17, Steps: 128 Train Loss: 3.1331 (Forecasting Loss:0.2126 + XiCon Loss:2.9205 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1863792
	speed: 0.0121s/iter; left time: 127.7565s
Epoch: 18 cost time: 1.512800693511963
Epoch: 18, Steps: 128 Train Loss: 3.1329 (Forecasting Loss:0.2124 + XiCon Loss:2.9204 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1616526
	speed: 0.0123s/iter; left time: 128.2390s
Epoch: 19 cost time: 1.5410213470458984
Epoch: 19, Steps: 128 Train Loss: 3.1322 (Forecasting Loss:0.2127 + XiCon Loss:2.9195 x Lambda(1.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1148
Validation loss decreased (0.162934 --> 0.162921).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1376660
	speed: 0.0124s/iter; left time: 127.5256s
Epoch: 20 cost time: 1.5482449531555176
Epoch: 20, Steps: 128 Train Loss: 3.1321 (Forecasting Loss:0.2125 + XiCon Loss:2.9196 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1135058
	speed: 0.0127s/iter; left time: 128.5544s
Epoch: 21 cost time: 1.5965404510498047
Epoch: 21, Steps: 128 Train Loss: 3.1287 (Forecasting Loss:0.2124 + XiCon Loss:2.9163 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0974674
	speed: 0.0130s/iter; left time: 130.0367s
Epoch: 22 cost time: 1.6416382789611816
Epoch: 22, Steps: 128 Train Loss: 3.1319 (Forecasting Loss:0.2126 + XiCon Loss:2.9193 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1657970
	speed: 0.0125s/iter; left time: 123.3434s
Epoch: 23 cost time: 1.5528631210327148
Epoch: 23, Steps: 128 Train Loss: 3.1398 (Forecasting Loss:0.2127 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0765886
	speed: 0.0121s/iter; left time: 118.4810s
Epoch: 24 cost time: 1.518768310546875
Epoch: 24, Steps: 128 Train Loss: 3.1344 (Forecasting Loss:0.2126 + XiCon Loss:2.9218 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1069312
	speed: 0.0123s/iter; left time: 118.7026s
Epoch: 25 cost time: 1.5391552448272705
Epoch: 25, Steps: 128 Train Loss: 3.1380 (Forecasting Loss:0.2125 + XiCon Loss:2.9255 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0830505
	speed: 0.0128s/iter; left time: 121.3139s
Epoch: 26 cost time: 1.5927088260650635
Epoch: 26, Steps: 128 Train Loss: 3.1341 (Forecasting Loss:0.2125 + XiCon Loss:2.9216 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1942346
	speed: 0.0124s/iter; left time: 116.5888s
Epoch: 27 cost time: 1.584871768951416
Epoch: 27, Steps: 128 Train Loss: 3.1316 (Forecasting Loss:0.2126 + XiCon Loss:2.9190 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1210470
	speed: 0.0121s/iter; left time: 111.9686s
Epoch: 28 cost time: 1.5201518535614014
Epoch: 28, Steps: 128 Train Loss: 3.1309 (Forecasting Loss:0.2126 + XiCon Loss:2.9182 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.2309515
	speed: 0.0130s/iter; left time: 118.4936s
Epoch: 29 cost time: 1.63038969039917
Epoch: 29, Steps: 128 Train Loss: 3.1349 (Forecasting Loss:0.2123 + XiCon Loss:2.9226 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05382274091243744, mae:0.1757698953151703, mape:0.13961096107959747, mspe:0.03690464794635773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3264
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3895700
	speed: 0.0133s/iter; left time: 168.7933s
Epoch: 1 cost time: 1.6675517559051514
Epoch: 1, Steps: 128 Train Loss: 3.4124 (Forecasting Loss:0.2449 + XiCon Loss:3.1676 x Lambda(1.0)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1213
Validation loss decreased (inf --> 0.172915).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1102042
	speed: 0.0124s/iter; left time: 155.7902s
Epoch: 2 cost time: 1.5716540813446045
Epoch: 2, Steps: 128 Train Loss: 3.1901 (Forecasting Loss:0.2468 + XiCon Loss:2.9433 x Lambda(1.0)), Vali MSE Loss: 0.1807 Test MSE Loss: 0.1254
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.3899515
	speed: 0.0128s/iter; left time: 159.5457s
Epoch: 3 cost time: 1.606903314590454
Epoch: 3, Steps: 128 Train Loss: 3.1555 (Forecasting Loss:0.2299 + XiCon Loss:2.9256 x Lambda(1.0)), Vali MSE Loss: 0.1689 Test MSE Loss: 0.1208
Validation loss decreased (0.172915 --> 0.168926).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2633739
	speed: 0.0126s/iter; left time: 154.8776s
Epoch: 4 cost time: 1.5545318126678467
Epoch: 4, Steps: 128 Train Loss: 3.2588 (Forecasting Loss:0.2223 + XiCon Loss:3.0365 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1216
Validation loss decreased (0.168926 --> 0.164349).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2215734
	speed: 0.0129s/iter; left time: 156.7470s
Epoch: 5 cost time: 1.5897486209869385
Epoch: 5, Steps: 128 Train Loss: 3.2092 (Forecasting Loss:0.2179 + XiCon Loss:2.9913 x Lambda(1.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1748741
	speed: 0.0127s/iter; left time: 152.9635s
Epoch: 6 cost time: 1.597193956375122
Epoch: 6, Steps: 128 Train Loss: 3.1869 (Forecasting Loss:0.2149 + XiCon Loss:2.9720 x Lambda(1.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1164
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1747499
	speed: 0.0132s/iter; left time: 157.1390s
Epoch: 7 cost time: 1.6167171001434326
Epoch: 7, Steps: 128 Train Loss: 3.1778 (Forecasting Loss:0.2142 + XiCon Loss:2.9636 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1148
Validation loss decreased (0.164349 --> 0.163785).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2320800
	speed: 0.0124s/iter; left time: 145.9215s
Epoch: 8 cost time: 1.5374717712402344
Epoch: 8, Steps: 128 Train Loss: 3.1709 (Forecasting Loss:0.2134 + XiCon Loss:2.9575 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1154
Validation loss decreased (0.163785 --> 0.163763).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1599765
	speed: 0.0121s/iter; left time: 141.5964s
Epoch: 9 cost time: 1.5230929851531982
Epoch: 9, Steps: 128 Train Loss: 3.1803 (Forecasting Loss:0.2132 + XiCon Loss:2.9671 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1259251
	speed: 0.0125s/iter; left time: 144.6139s
Epoch: 10 cost time: 1.556084394454956
Epoch: 10, Steps: 128 Train Loss: 3.1720 (Forecasting Loss:0.2129 + XiCon Loss:2.9591 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2320240
	speed: 0.0121s/iter; left time: 138.2804s
Epoch: 11 cost time: 1.5076076984405518
Epoch: 11, Steps: 128 Train Loss: 3.1764 (Forecasting Loss:0.2129 + XiCon Loss:2.9635 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
Validation loss decreased (0.163763 --> 0.163417).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1081762
	speed: 0.0121s/iter; left time: 136.9517s
Epoch: 12 cost time: 1.5168609619140625
Epoch: 12, Steps: 128 Train Loss: 3.1712 (Forecasting Loss:0.2127 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1628788
	speed: 0.0122s/iter; left time: 136.5968s
Epoch: 13 cost time: 1.5326762199401855
Epoch: 13, Steps: 128 Train Loss: 3.1713 (Forecasting Loss:0.2129 + XiCon Loss:2.9584 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1809175
	speed: 0.0121s/iter; left time: 134.0970s
Epoch: 14 cost time: 1.5154321193695068
Epoch: 14, Steps: 128 Train Loss: 3.1743 (Forecasting Loss:0.2126 + XiCon Loss:2.9617 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.2268069
	speed: 0.0123s/iter; left time: 133.8519s
Epoch: 15 cost time: 1.5228416919708252
Epoch: 15, Steps: 128 Train Loss: 3.1765 (Forecasting Loss:0.2127 + XiCon Loss:2.9638 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2360430
	speed: 0.0127s/iter; left time: 136.6340s
Epoch: 16 cost time: 1.5699288845062256
Epoch: 16, Steps: 128 Train Loss: 3.1718 (Forecasting Loss:0.2128 + XiCon Loss:2.9591 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
Validation loss decreased (0.163417 --> 0.163398).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1764004
	speed: 0.0123s/iter; left time: 130.5151s
Epoch: 17 cost time: 1.5415153503417969
Epoch: 17, Steps: 128 Train Loss: 3.1710 (Forecasting Loss:0.2128 + XiCon Loss:2.9582 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
Validation loss decreased (0.163398 --> 0.163333).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1741827
	speed: 0.0121s/iter; left time: 127.7379s
Epoch: 18 cost time: 1.5247235298156738
Epoch: 18, Steps: 128 Train Loss: 3.1711 (Forecasting Loss:0.2129 + XiCon Loss:2.9583 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1153
Validation loss decreased (0.163333 --> 0.162959).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1412997
	speed: 0.0123s/iter; left time: 128.2571s
Epoch: 19 cost time: 1.5338172912597656
Epoch: 19, Steps: 128 Train Loss: 3.1696 (Forecasting Loss:0.2128 + XiCon Loss:2.9568 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1153
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.2100236
	speed: 0.0122s/iter; left time: 125.0326s
Epoch: 20 cost time: 1.5198757648468018
Epoch: 20, Steps: 128 Train Loss: 3.1724 (Forecasting Loss:0.2128 + XiCon Loss:2.9596 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1153
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1253662
	speed: 0.0124s/iter; left time: 125.4207s
Epoch: 21 cost time: 1.5414435863494873
Epoch: 21, Steps: 128 Train Loss: 3.1741 (Forecasting Loss:0.2127 + XiCon Loss:2.9614 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1153
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.2579334
	speed: 0.0122s/iter; left time: 121.8281s
Epoch: 22 cost time: 1.5264778137207031
Epoch: 22, Steps: 128 Train Loss: 3.1732 (Forecasting Loss:0.2128 + XiCon Loss:2.9604 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1004925
	speed: 0.0123s/iter; left time: 121.6973s
Epoch: 23 cost time: 1.5322704315185547
Epoch: 23, Steps: 128 Train Loss: 3.1717 (Forecasting Loss:0.2128 + XiCon Loss:2.9589 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1153
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1731861
	speed: 0.0121s/iter; left time: 118.2898s
Epoch: 24 cost time: 1.5158281326293945
Epoch: 24, Steps: 128 Train Loss: 3.1683 (Forecasting Loss:0.2128 + XiCon Loss:2.9556 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.2783768
	speed: 0.0132s/iter; left time: 126.8124s
Epoch: 25 cost time: 1.6497702598571777
Epoch: 25, Steps: 128 Train Loss: 3.1726 (Forecasting Loss:0.2127 + XiCon Loss:2.9599 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1153
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.1844494
	speed: 0.0124s/iter; left time: 117.3660s
Epoch: 26 cost time: 1.5683691501617432
Epoch: 26, Steps: 128 Train Loss: 3.1686 (Forecasting Loss:0.2128 + XiCon Loss:2.9557 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1153
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1588054
	speed: 0.0123s/iter; left time: 114.8790s
Epoch: 27 cost time: 1.5308947563171387
Epoch: 27, Steps: 128 Train Loss: 3.1735 (Forecasting Loss:0.2128 + XiCon Loss:2.9607 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1153
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1827815
	speed: 0.0123s/iter; left time: 113.8559s
Epoch: 28 cost time: 1.5418894290924072
Epoch: 28, Steps: 128 Train Loss: 3.1710 (Forecasting Loss:0.2129 + XiCon Loss:2.9582 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1153
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05419743433594704, mae:0.17638669908046722, mape:0.14003439247608185, mspe:0.03711450472474098 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0553+-0.00336, MAE:0.1790+-0.00672, MAPE:0.1421+-0.00517, MSPE:0.0380+-0.00255, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3178
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 32.3926239
	speed: 0.0165s/iter; left time: 205.9655s
Epoch: 1 cost time: 1.9495477676391602
Epoch: 1, Steps: 126 Train Loss: 32.3362 (Forecasting Loss:0.2774 + XiCon Loss:3.2059 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1441
Validation loss decreased (inf --> 0.197690).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.3136673
	speed: 0.0144s/iter; left time: 178.7862s
Epoch: 2 cost time: 1.791449785232544
Epoch: 2, Steps: 126 Train Loss: 30.3385 (Forecasting Loss:0.2608 + XiCon Loss:3.0078 x Lambda(10.0)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1390
Validation loss decreased (0.197690 --> 0.192122).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7902260
	speed: 0.0153s/iter; left time: 186.8721s
Epoch: 3 cost time: 1.882850170135498
Epoch: 3, Steps: 126 Train Loss: 30.4147 (Forecasting Loss:0.2519 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.1874 Test MSE Loss: 0.1431
Validation loss decreased (0.192122 --> 0.187412).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1774311
	speed: 0.0146s/iter; left time: 176.7085s
Epoch: 4 cost time: 1.8103320598602295
Epoch: 4, Steps: 126 Train Loss: 29.9769 (Forecasting Loss:0.2446 + XiCon Loss:2.9732 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1436
Validation loss decreased (0.187412 --> 0.186551).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7414837
	speed: 0.0147s/iter; left time: 176.3250s
Epoch: 5 cost time: 1.821709394454956
Epoch: 5, Steps: 126 Train Loss: 29.8900 (Forecasting Loss:0.2394 + XiCon Loss:2.9651 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1398
Validation loss decreased (0.186551 --> 0.184295).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3908863
	speed: 0.0147s/iter; left time: 174.0209s
Epoch: 6 cost time: 1.8184127807617188
Epoch: 6, Steps: 126 Train Loss: 29.8655 (Forecasting Loss:0.2369 + XiCon Loss:2.9629 x Lambda(10.0)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.1398
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0810204
	speed: 0.0149s/iter; left time: 175.5635s
Epoch: 7 cost time: 1.848785161972046
Epoch: 7, Steps: 126 Train Loss: 29.9220 (Forecasting Loss:0.2353 + XiCon Loss:2.9687 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1413
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2748184
	speed: 0.0147s/iter; left time: 171.1133s
Epoch: 8 cost time: 1.8199243545532227
Epoch: 8, Steps: 126 Train Loss: 29.8699 (Forecasting Loss:0.2353 + XiCon Loss:2.9635 x Lambda(10.0)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0477715
	speed: 0.0146s/iter; left time: 167.8420s
Epoch: 9 cost time: 1.8071315288543701
Epoch: 9, Steps: 126 Train Loss: 29.8912 (Forecasting Loss:0.2346 + XiCon Loss:2.9657 x Lambda(10.0)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1404
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7557659
	speed: 0.0146s/iter; left time: 166.0660s
Epoch: 10 cost time: 1.8158977031707764
Epoch: 10, Steps: 126 Train Loss: 29.8332 (Forecasting Loss:0.2349 + XiCon Loss:2.9598 x Lambda(10.0)), Vali MSE Loss: 0.1846 Test MSE Loss: 0.1405
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.0852642
	speed: 0.0145s/iter; left time: 162.9013s
Epoch: 11 cost time: 1.7936415672302246
Epoch: 11, Steps: 126 Train Loss: 29.7955 (Forecasting Loss:0.2347 + XiCon Loss:2.9561 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1404
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.2877903
	speed: 0.0147s/iter; left time: 163.7688s
Epoch: 12 cost time: 1.8255155086517334
Epoch: 12, Steps: 126 Train Loss: 29.8041 (Forecasting Loss:0.2347 + XiCon Loss:2.9569 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1404
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.3151417
	speed: 0.0146s/iter; left time: 160.2711s
Epoch: 13 cost time: 1.8035540580749512
Epoch: 13, Steps: 126 Train Loss: 29.8306 (Forecasting Loss:0.2341 + XiCon Loss:2.9597 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1405
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2731876
	speed: 0.0147s/iter; left time: 159.3290s
Epoch: 14 cost time: 1.8106930255889893
Epoch: 14, Steps: 126 Train Loss: 29.7579 (Forecasting Loss:0.2345 + XiCon Loss:2.9523 x Lambda(10.0)), Vali MSE Loss: 0.1847 Test MSE Loss: 0.1404
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.6695004
	speed: 0.0145s/iter; left time: 155.7668s
Epoch: 15 cost time: 1.794189691543579
Epoch: 15, Steps: 126 Train Loss: 29.8572 (Forecasting Loss:0.2349 + XiCon Loss:2.9622 x Lambda(10.0)), Vali MSE Loss: 0.1846 Test MSE Loss: 0.1404
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07295883446931839, mae:0.20666369795799255, mape:0.15858972072601318, mspe:0.044451966881752014 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1671
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 32.1582680
	speed: 0.0136s/iter; left time: 170.2139s
Epoch: 1 cost time: 1.672574758529663
Epoch: 1, Steps: 126 Train Loss: 32.2227 (Forecasting Loss:0.2793 + XiCon Loss:3.1943 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1449
Validation loss decreased (inf --> 0.198197).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8669548
	speed: 0.0150s/iter; left time: 185.9580s
Epoch: 2 cost time: 1.8692491054534912
Epoch: 2, Steps: 126 Train Loss: 30.3391 (Forecasting Loss:0.2642 + XiCon Loss:3.0075 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1406
Validation loss decreased (0.198197 --> 0.197693).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8247719
	speed: 0.0151s/iter; left time: 184.4917s
Epoch: 3 cost time: 1.8676974773406982
Epoch: 3, Steps: 126 Train Loss: 30.5500 (Forecasting Loss:0.2530 + XiCon Loss:3.0297 x Lambda(10.0)), Vali MSE Loss: 0.1897 Test MSE Loss: 0.1381
Validation loss decreased (0.197693 --> 0.189711).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6759224
	speed: 0.0152s/iter; left time: 183.7958s
Epoch: 4 cost time: 1.8740429878234863
Epoch: 4, Steps: 126 Train Loss: 30.4729 (Forecasting Loss:0.2452 + XiCon Loss:3.0228 x Lambda(10.0)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.1366
Validation loss decreased (0.189711 --> 0.188312).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.6449490
	speed: 0.0153s/iter; left time: 183.8898s
Epoch: 5 cost time: 1.8940846920013428
Epoch: 5, Steps: 126 Train Loss: 30.4249 (Forecasting Loss:0.2425 + XiCon Loss:3.0182 x Lambda(10.0)), Vali MSE Loss: 0.1849 Test MSE Loss: 0.1341
Validation loss decreased (0.188312 --> 0.184941).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5431538
	speed: 0.0152s/iter; left time: 180.7613s
Epoch: 6 cost time: 1.882396936416626
Epoch: 6, Steps: 126 Train Loss: 30.2615 (Forecasting Loss:0.2410 + XiCon Loss:3.0021 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1363
Validation loss decreased (0.184941 --> 0.184505).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.5905876
	speed: 0.0152s/iter; left time: 178.2242s
Epoch: 7 cost time: 1.8803231716156006
Epoch: 7, Steps: 126 Train Loss: 30.2617 (Forecasting Loss:0.2401 + XiCon Loss:3.0022 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1356
Validation loss decreased (0.184505 --> 0.184256).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5241165
	speed: 0.0151s/iter; left time: 174.9628s
Epoch: 8 cost time: 1.8705408573150635
Epoch: 8, Steps: 126 Train Loss: 30.2263 (Forecasting Loss:0.2401 + XiCon Loss:2.9986 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1353
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.4799366
	speed: 0.0155s/iter; left time: 177.6247s
Epoch: 9 cost time: 1.9107697010040283
Epoch: 9, Steps: 126 Train Loss: 30.1847 (Forecasting Loss:0.2402 + XiCon Loss:2.9944 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1353
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3724461
	speed: 0.0153s/iter; left time: 174.3086s
Epoch: 10 cost time: 1.8920981884002686
Epoch: 10, Steps: 126 Train Loss: 30.1679 (Forecasting Loss:0.2397 + XiCon Loss:2.9928 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6804066
	speed: 0.0153s/iter; left time: 171.8115s
Epoch: 11 cost time: 1.8941936492919922
Epoch: 11, Steps: 126 Train Loss: 30.1400 (Forecasting Loss:0.2395 + XiCon Loss:2.9900 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.5135860
	speed: 0.0153s/iter; left time: 170.2461s
Epoch: 12 cost time: 1.8980131149291992
Epoch: 12, Steps: 126 Train Loss: 30.1945 (Forecasting Loss:0.2398 + XiCon Loss:2.9955 x Lambda(10.0)), Vali MSE Loss: 0.1842 Test MSE Loss: 0.1352
Validation loss decreased (0.184256 --> 0.184206).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2851334
	speed: 0.0153s/iter; left time: 167.9596s
Epoch: 13 cost time: 1.895035743713379
Epoch: 13, Steps: 126 Train Loss: 30.1776 (Forecasting Loss:0.2397 + XiCon Loss:2.9938 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.6108398
	speed: 0.0160s/iter; left time: 174.2364s
Epoch: 14 cost time: 1.9973015785217285
Epoch: 14, Steps: 126 Train Loss: 30.1644 (Forecasting Loss:0.2391 + XiCon Loss:2.9925 x Lambda(10.0)), Vali MSE Loss: 0.1842 Test MSE Loss: 0.1352
Validation loss decreased (0.184206 --> 0.184180).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.9153080
	speed: 0.0155s/iter; left time: 165.9505s
Epoch: 15 cost time: 1.9083280563354492
Epoch: 15, Steps: 126 Train Loss: 30.2241 (Forecasting Loss:0.2390 + XiCon Loss:2.9985 x Lambda(10.0)), Vali MSE Loss: 0.1841 Test MSE Loss: 0.1352
Validation loss decreased (0.184180 --> 0.184145).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.9498806
	speed: 0.0155s/iter; left time: 164.0407s
Epoch: 16 cost time: 1.9110283851623535
Epoch: 16, Steps: 126 Train Loss: 30.0901 (Forecasting Loss:0.2397 + XiCon Loss:2.9850 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5395927
	speed: 0.0153s/iter; left time: 160.2892s
Epoch: 17 cost time: 1.9063444137573242
Epoch: 17, Steps: 126 Train Loss: 30.1562 (Forecasting Loss:0.2392 + XiCon Loss:2.9917 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.7577515
	speed: 0.0152s/iter; left time: 157.2554s
Epoch: 18 cost time: 1.9086246490478516
Epoch: 18, Steps: 126 Train Loss: 30.1779 (Forecasting Loss:0.2397 + XiCon Loss:2.9938 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8414040
	speed: 0.0155s/iter; left time: 158.4645s
Epoch: 19 cost time: 1.909470558166504
Epoch: 19, Steps: 126 Train Loss: 30.1087 (Forecasting Loss:0.2393 + XiCon Loss:2.9869 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.7182140
	speed: 0.0153s/iter; left time: 154.9552s
Epoch: 20 cost time: 1.8981928825378418
Epoch: 20, Steps: 126 Train Loss: 30.2268 (Forecasting Loss:0.2394 + XiCon Loss:2.9987 x Lambda(10.0)), Vali MSE Loss: 0.1842 Test MSE Loss: 0.1352
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.4219494
	speed: 0.0152s/iter; left time: 151.9770s
Epoch: 21 cost time: 1.8871121406555176
Epoch: 21, Steps: 126 Train Loss: 30.1873 (Forecasting Loss:0.2395 + XiCon Loss:2.9948 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.6824493
	speed: 0.0151s/iter; left time: 149.0313s
Epoch: 22 cost time: 1.879011869430542
Epoch: 22, Steps: 126 Train Loss: 30.1482 (Forecasting Loss:0.2399 + XiCon Loss:2.9908 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.3225803
	speed: 0.0161s/iter; left time: 156.3882s
Epoch: 23 cost time: 1.976062297821045
Epoch: 23, Steps: 126 Train Loss: 30.2185 (Forecasting Loss:0.2395 + XiCon Loss:2.9979 x Lambda(10.0)), Vali MSE Loss: 0.1842 Test MSE Loss: 0.1352
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.6191235
	speed: 0.0152s/iter; left time: 145.7893s
Epoch: 24 cost time: 1.883284568786621
Epoch: 24, Steps: 126 Train Loss: 30.1006 (Forecasting Loss:0.2398 + XiCon Loss:2.9861 x Lambda(10.0)), Vali MSE Loss: 0.1842 Test MSE Loss: 0.1352
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.5333881
	speed: 0.0155s/iter; left time: 146.9070s
Epoch: 25 cost time: 1.9186875820159912
Epoch: 25, Steps: 126 Train Loss: 30.1700 (Forecasting Loss:0.2395 + XiCon Loss:2.9930 x Lambda(10.0)), Vali MSE Loss: 0.1843 Test MSE Loss: 0.1352
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06857273727655411, mae:0.2018314152956009, mape:0.15513567626476288, mspe:0.04209918901324272 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1717
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 31.8388920
	speed: 0.0136s/iter; left time: 170.4851s
Epoch: 1 cost time: 1.6843881607055664
Epoch: 1, Steps: 126 Train Loss: 32.1964 (Forecasting Loss:0.2758 + XiCon Loss:3.1921 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1463
Validation loss decreased (inf --> 0.197793).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9317150
	speed: 0.0148s/iter; left time: 182.8528s
Epoch: 2 cost time: 1.8682315349578857
Epoch: 2, Steps: 126 Train Loss: 30.3564 (Forecasting Loss:0.2634 + XiCon Loss:3.0093 x Lambda(10.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.1471138
	speed: 0.0153s/iter; left time: 187.9474s
Epoch: 3 cost time: 1.8957223892211914
Epoch: 3, Steps: 126 Train Loss: 30.8443 (Forecasting Loss:0.2528 + XiCon Loss:3.0591 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1402
Validation loss decreased (0.197793 --> 0.193213).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.6896324
	speed: 0.0160s/iter; left time: 193.4952s
Epoch: 4 cost time: 1.981830358505249
Epoch: 4, Steps: 126 Train Loss: 30.9954 (Forecasting Loss:0.2452 + XiCon Loss:3.0750 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1377
Validation loss decreased (0.193213 --> 0.186500).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.1530418
	speed: 0.0150s/iter; left time: 179.3995s
Epoch: 5 cost time: 1.8479413986206055
Epoch: 5, Steps: 126 Train Loss: 30.8076 (Forecasting Loss:0.2411 + XiCon Loss:3.0566 x Lambda(10.0)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.1368
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9850521
	speed: 0.0151s/iter; left time: 179.1047s
Epoch: 6 cost time: 1.8584766387939453
Epoch: 6, Steps: 126 Train Loss: 30.7113 (Forecasting Loss:0.2387 + XiCon Loss:3.0473 x Lambda(10.0)), Vali MSE Loss: 0.1899 Test MSE Loss: 0.1385
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.8794346
	speed: 0.0149s/iter; left time: 174.8591s
Epoch: 7 cost time: 1.8406920433044434
Epoch: 7, Steps: 126 Train Loss: 30.6819 (Forecasting Loss:0.2369 + XiCon Loss:3.0445 x Lambda(10.0)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1374
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2142582
	speed: 0.0151s/iter; left time: 175.3639s
Epoch: 8 cost time: 1.8640763759613037
Epoch: 8, Steps: 126 Train Loss: 30.7183 (Forecasting Loss:0.2363 + XiCon Loss:3.0482 x Lambda(10.0)), Vali MSE Loss: 0.1893 Test MSE Loss: 0.1377
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3414688
	speed: 0.0149s/iter; left time: 170.9953s
Epoch: 9 cost time: 1.8414175510406494
Epoch: 9, Steps: 126 Train Loss: 30.5819 (Forecasting Loss:0.2365 + XiCon Loss:3.0345 x Lambda(10.0)), Vali MSE Loss: 0.1892 Test MSE Loss: 0.1375
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4043999
	speed: 0.0150s/iter; left time: 170.9678s
Epoch: 10 cost time: 1.8698630332946777
Epoch: 10, Steps: 126 Train Loss: 30.6045 (Forecasting Loss:0.2362 + XiCon Loss:3.0368 x Lambda(10.0)), Vali MSE Loss: 0.1893 Test MSE Loss: 0.1375
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0644379
	speed: 0.0152s/iter; left time: 170.6155s
Epoch: 11 cost time: 1.8774347305297852
Epoch: 11, Steps: 126 Train Loss: 30.6342 (Forecasting Loss:0.2362 + XiCon Loss:3.0398 x Lambda(10.0)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1375
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9021416
	speed: 0.0150s/iter; left time: 166.3305s
Epoch: 12 cost time: 1.8556313514709473
Epoch: 12, Steps: 126 Train Loss: 30.6025 (Forecasting Loss:0.2362 + XiCon Loss:3.0366 x Lambda(10.0)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1375
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.0123444
	speed: 0.0149s/iter; left time: 164.2668s
Epoch: 13 cost time: 1.8532114028930664
Epoch: 13, Steps: 126 Train Loss: 30.6294 (Forecasting Loss:0.2359 + XiCon Loss:3.0394 x Lambda(10.0)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1374
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.1351986
	speed: 0.0150s/iter; left time: 162.8970s
Epoch: 14 cost time: 1.8578712940216064
Epoch: 14, Steps: 126 Train Loss: 30.6701 (Forecasting Loss:0.2360 + XiCon Loss:3.0434 x Lambda(10.0)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1374
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.0701637789607048, mae:0.20517250895500183, mape:0.15785247087478638, mspe:0.044032081961631775 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1313
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 32.0173187
	speed: 0.0137s/iter; left time: 170.9097s
Epoch: 1 cost time: 1.69930100440979
Epoch: 1, Steps: 126 Train Loss: 32.2255 (Forecasting Loss:0.2766 + XiCon Loss:3.1949 x Lambda(10.0)), Vali MSE Loss: 0.1967 Test MSE Loss: 0.1435
Validation loss decreased (inf --> 0.196658).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.3470955
	speed: 0.0148s/iter; left time: 182.6774s
Epoch: 2 cost time: 1.845759630203247
Epoch: 2, Steps: 126 Train Loss: 30.5637 (Forecasting Loss:0.2625 + XiCon Loss:3.0301 x Lambda(10.0)), Vali MSE Loss: 0.1963 Test MSE Loss: 0.1452
Validation loss decreased (0.196658 --> 0.196344).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.5345688
	speed: 0.0161s/iter; left time: 197.0926s
Epoch: 3 cost time: 1.988405466079712
Epoch: 3, Steps: 126 Train Loss: 30.5467 (Forecasting Loss:0.2526 + XiCon Loss:3.0294 x Lambda(10.0)), Vali MSE Loss: 0.1889 Test MSE Loss: 0.1354
Validation loss decreased (0.196344 --> 0.188918).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1868839
	speed: 0.0153s/iter; left time: 185.0785s
Epoch: 4 cost time: 1.9260635375976562
Epoch: 4, Steps: 126 Train Loss: 31.0487 (Forecasting Loss:0.2473 + XiCon Loss:3.0801 x Lambda(10.0)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.1385
Validation loss decreased (0.188918 --> 0.188117).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1220951
	speed: 0.0150s/iter; left time: 180.0783s
Epoch: 5 cost time: 1.8640968799591064
Epoch: 5, Steps: 126 Train Loss: 30.7424 (Forecasting Loss:0.2447 + XiCon Loss:3.0498 x Lambda(10.0)), Vali MSE Loss: 0.1873 Test MSE Loss: 0.1371
Validation loss decreased (0.188117 --> 0.187326).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.8267860
	speed: 0.0156s/iter; left time: 185.3914s
Epoch: 6 cost time: 1.9565625190734863
Epoch: 6, Steps: 126 Train Loss: 30.6349 (Forecasting Loss:0.2431 + XiCon Loss:3.0392 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1365
Validation loss decreased (0.187326 --> 0.186253).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1837940
	speed: 0.0155s/iter; left time: 182.1420s
Epoch: 7 cost time: 1.9387259483337402
Epoch: 7, Steps: 126 Train Loss: 30.6496 (Forecasting Loss:0.2424 + XiCon Loss:3.0407 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1374
Validation loss decreased (0.186253 --> 0.186138).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.7867260
	speed: 0.0151s/iter; left time: 175.9869s
Epoch: 8 cost time: 1.8697035312652588
Epoch: 8, Steps: 126 Train Loss: 30.5831 (Forecasting Loss:0.2421 + XiCon Loss:3.0341 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1365
Validation loss decreased (0.186138 --> 0.186131).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3182240
	speed: 0.0150s/iter; left time: 172.7279s
Epoch: 9 cost time: 1.8626172542572021
Epoch: 9, Steps: 126 Train Loss: 30.5550 (Forecasting Loss:0.2416 + XiCon Loss:3.0313 x Lambda(10.0)), Vali MSE Loss: 0.1860 Test MSE Loss: 0.1366
Validation loss decreased (0.186131 --> 0.186022).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1340389
	speed: 0.0150s/iter; left time: 170.7019s
Epoch: 10 cost time: 1.8596243858337402
Epoch: 10, Steps: 126 Train Loss: 30.5268 (Forecasting Loss:0.2417 + XiCon Loss:3.0285 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1366
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.6443176
	speed: 0.0150s/iter; left time: 168.1339s
Epoch: 11 cost time: 1.8526756763458252
Epoch: 11, Steps: 126 Train Loss: 30.5550 (Forecasting Loss:0.2417 + XiCon Loss:3.0313 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1366
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1286335
	speed: 0.0157s/iter; left time: 174.0035s
Epoch: 12 cost time: 1.944059133529663
Epoch: 12, Steps: 126 Train Loss: 30.5419 (Forecasting Loss:0.2415 + XiCon Loss:3.0300 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1366
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6285954
	speed: 0.0150s/iter; left time: 165.0975s
Epoch: 13 cost time: 1.8610541820526123
Epoch: 13, Steps: 126 Train Loss: 30.5072 (Forecasting Loss:0.2415 + XiCon Loss:3.0266 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1366
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.4043980
	speed: 0.0152s/iter; left time: 164.9661s
Epoch: 14 cost time: 1.8824105262756348
Epoch: 14, Steps: 126 Train Loss: 30.5315 (Forecasting Loss:0.2413 + XiCon Loss:3.0290 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.4777756
	speed: 0.0154s/iter; left time: 165.2101s
Epoch: 15 cost time: 1.9030814170837402
Epoch: 15, Steps: 126 Train Loss: 30.5243 (Forecasting Loss:0.2414 + XiCon Loss:3.0283 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1366
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.0519924
	speed: 0.0152s/iter; left time: 161.3659s
Epoch: 16 cost time: 1.8816499710083008
Epoch: 16, Steps: 126 Train Loss: 30.4767 (Forecasting Loss:0.2414 + XiCon Loss:3.0235 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1366
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.0752316
	speed: 0.0157s/iter; left time: 164.9449s
Epoch: 17 cost time: 1.9400997161865234
Epoch: 17, Steps: 126 Train Loss: 30.5202 (Forecasting Loss:0.2414 + XiCon Loss:3.0279 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1366
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.5473766
	speed: 0.0151s/iter; left time: 156.4326s
Epoch: 18 cost time: 1.8762810230255127
Epoch: 18, Steps: 126 Train Loss: 30.5610 (Forecasting Loss:0.2417 + XiCon Loss:3.0319 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1366
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.1438465
	speed: 0.0151s/iter; left time: 154.9511s
Epoch: 19 cost time: 1.8722641468048096
Epoch: 19, Steps: 126 Train Loss: 30.5033 (Forecasting Loss:0.2415 + XiCon Loss:3.0262 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1366
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06973738223314285, mae:0.20346036553382874, mape:0.15592248737812042, mspe:0.04206240922212601 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2786
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 32.1039543
	speed: 0.0143s/iter; left time: 179.1126s
Epoch: 1 cost time: 1.7587521076202393
Epoch: 1, Steps: 126 Train Loss: 32.2344 (Forecasting Loss:0.2769 + XiCon Loss:3.1958 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1449
Validation loss decreased (inf --> 0.195452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.5743561
	speed: 0.0150s/iter; left time: 185.2609s
Epoch: 2 cost time: 1.8820312023162842
Epoch: 2, Steps: 126 Train Loss: 30.2207 (Forecasting Loss:0.2634 + XiCon Loss:2.9957 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1442
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.9911060
	speed: 0.0157s/iter; left time: 192.2686s
Epoch: 3 cost time: 1.9239799976348877
Epoch: 3, Steps: 126 Train Loss: 29.8034 (Forecasting Loss:0.2510 + XiCon Loss:2.9552 x Lambda(10.0)), Vali MSE Loss: 0.1866 Test MSE Loss: 0.1342
Validation loss decreased (0.195452 --> 0.186552).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.8974571
	speed: 0.0152s/iter; left time: 183.7347s
Epoch: 4 cost time: 1.8862831592559814
Epoch: 4, Steps: 126 Train Loss: 30.8459 (Forecasting Loss:0.2457 + XiCon Loss:3.0600 x Lambda(10.0)), Vali MSE Loss: 0.1877 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.9732704
	speed: 0.0156s/iter; left time: 186.5619s
Epoch: 5 cost time: 1.9203860759735107
Epoch: 5, Steps: 126 Train Loss: 30.6764 (Forecasting Loss:0.2438 + XiCon Loss:3.0433 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1326
Validation loss decreased (0.186552 --> 0.186343).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5039978
	speed: 0.0154s/iter; left time: 182.4660s
Epoch: 6 cost time: 1.9057652950286865
Epoch: 6, Steps: 126 Train Loss: 30.5870 (Forecasting Loss:0.2420 + XiCon Loss:3.0345 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1353
Validation loss decreased (0.186343 --> 0.185750).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8315258
	speed: 0.0152s/iter; left time: 178.4530s
Epoch: 7 cost time: 1.8703618049621582
Epoch: 7, Steps: 126 Train Loss: 30.5452 (Forecasting Loss:0.2410 + XiCon Loss:3.0304 x Lambda(10.0)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1348
Validation loss decreased (0.185750 --> 0.185637).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.3323116
	speed: 0.0150s/iter; left time: 174.5311s
Epoch: 8 cost time: 1.8582608699798584
Epoch: 8, Steps: 126 Train Loss: 30.5566 (Forecasting Loss:0.2400 + XiCon Loss:3.0317 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1345
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5541420
	speed: 0.0150s/iter; left time: 172.2020s
Epoch: 9 cost time: 1.8771367073059082
Epoch: 9, Steps: 126 Train Loss: 30.4985 (Forecasting Loss:0.2397 + XiCon Loss:3.0259 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1346
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.4272251
	speed: 0.0159s/iter; left time: 180.9568s
Epoch: 10 cost time: 1.9521102905273438
Epoch: 10, Steps: 126 Train Loss: 30.4985 (Forecasting Loss:0.2395 + XiCon Loss:3.0259 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1346
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0715866
	speed: 0.0149s/iter; left time: 167.7204s
Epoch: 11 cost time: 1.8518667221069336
Epoch: 11, Steps: 126 Train Loss: 30.5226 (Forecasting Loss:0.2393 + XiCon Loss:3.0283 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.2683468
	speed: 0.0150s/iter; left time: 166.6615s
Epoch: 12 cost time: 1.8604497909545898
Epoch: 12, Steps: 126 Train Loss: 30.4551 (Forecasting Loss:0.2394 + XiCon Loss:3.0216 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.1625919
	speed: 0.0151s/iter; left time: 166.0776s
Epoch: 13 cost time: 1.900357723236084
Epoch: 13, Steps: 126 Train Loss: 30.4839 (Forecasting Loss:0.2394 + XiCon Loss:3.0245 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2021217
	speed: 0.0149s/iter; left time: 161.8706s
Epoch: 14 cost time: 1.8545069694519043
Epoch: 14, Steps: 126 Train Loss: 30.4570 (Forecasting Loss:0.2390 + XiCon Loss:3.0218 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2317829
	speed: 0.0149s/iter; left time: 160.2973s
Epoch: 15 cost time: 1.8534696102142334
Epoch: 15, Steps: 126 Train Loss: 30.5016 (Forecasting Loss:0.2392 + XiCon Loss:3.0262 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6412888
	speed: 0.0151s/iter; left time: 160.0973s
Epoch: 16 cost time: 1.8645944595336914
Epoch: 16, Steps: 126 Train Loss: 30.5581 (Forecasting Loss:0.2392 + XiCon Loss:3.0319 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3872776
	speed: 0.0155s/iter; left time: 162.5091s
Epoch: 17 cost time: 1.9188289642333984
Epoch: 17, Steps: 126 Train Loss: 30.5449 (Forecasting Loss:0.2393 + XiCon Loss:3.0306 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1345
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06890121847391129, mae:0.20062817633152008, mape:0.1534656435251236, mspe:0.04112958535552025 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0701+-0.00216, MAE:0.2036+-0.00303, MAPE:0.1562+-0.00257, MSPE:0.0428+-0.00176, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3710
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 32.1934738
	speed: 0.0209s/iter; left time: 257.2851s
Epoch: 1 cost time: 2.485459327697754
Epoch: 1, Steps: 124 Train Loss: 32.2838 (Forecasting Loss:0.2940 + XiCon Loss:3.1990 x Lambda(10.0)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1623
Validation loss decreased (inf --> 0.216282).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.1972160
	speed: 0.0188s/iter; left time: 229.4510s
Epoch: 2 cost time: 2.35571551322937
Epoch: 2, Steps: 124 Train Loss: 30.8887 (Forecasting Loss:0.2803 + XiCon Loss:3.0608 x Lambda(10.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1551
Validation loss decreased (0.216282 --> 0.212261).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6772270
	speed: 0.0229s/iter; left time: 275.8467s
Epoch: 3 cost time: 2.841776132583618
Epoch: 3, Steps: 124 Train Loss: 31.0141 (Forecasting Loss:0.2664 + XiCon Loss:3.0748 x Lambda(10.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1433
Validation loss decreased (0.212261 --> 0.206061).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.3484402
	speed: 0.0232s/iter; left time: 276.9913s
Epoch: 4 cost time: 2.8761837482452393
Epoch: 4, Steps: 124 Train Loss: 30.5965 (Forecasting Loss:0.2583 + XiCon Loss:3.0338 x Lambda(10.0)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1436
Validation loss decreased (0.206061 --> 0.202933).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2954826
	speed: 0.0229s/iter; left time: 270.8718s
Epoch: 5 cost time: 2.815553665161133
Epoch: 5, Steps: 124 Train Loss: 30.4366 (Forecasting Loss:0.2549 + XiCon Loss:3.0182 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1451
Validation loss decreased (0.202933 --> 0.201190).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.1077404
	speed: 0.0224s/iter; left time: 261.9990s
Epoch: 6 cost time: 2.754469633102417
Epoch: 6, Steps: 124 Train Loss: 30.4096 (Forecasting Loss:0.2529 + XiCon Loss:3.0157 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1442
Validation loss decreased (0.201190 --> 0.199577).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0944958
	speed: 0.0226s/iter; left time: 261.1156s
Epoch: 7 cost time: 2.78226637840271
Epoch: 7, Steps: 124 Train Loss: 30.2873 (Forecasting Loss:0.2515 + XiCon Loss:3.0036 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1436
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.6635284
	speed: 0.0223s/iter; left time: 255.3952s
Epoch: 8 cost time: 2.766191005706787
Epoch: 8, Steps: 124 Train Loss: 30.2801 (Forecasting Loss:0.2510 + XiCon Loss:3.0029 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1444
Validation loss decreased (0.199577 --> 0.199577).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5314388
	speed: 0.0224s/iter; left time: 253.0147s
Epoch: 9 cost time: 2.7486770153045654
Epoch: 9, Steps: 124 Train Loss: 30.3217 (Forecasting Loss:0.2506 + XiCon Loss:3.0071 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1446
Validation loss decreased (0.199577 --> 0.199553).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8979588
	speed: 0.0225s/iter; left time: 251.1627s
Epoch: 10 cost time: 2.7871158123016357
Epoch: 10, Steps: 124 Train Loss: 30.2984 (Forecasting Loss:0.2509 + XiCon Loss:3.0048 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1446
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7971516
	speed: 0.0224s/iter; left time: 247.6817s
Epoch: 11 cost time: 2.754894971847534
Epoch: 11, Steps: 124 Train Loss: 30.3289 (Forecasting Loss:0.2509 + XiCon Loss:3.0078 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1445
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.5333405
	speed: 0.0223s/iter; left time: 244.4359s
Epoch: 12 cost time: 2.7547080516815186
Epoch: 12, Steps: 124 Train Loss: 30.3138 (Forecasting Loss:0.2505 + XiCon Loss:3.0063 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1445
Validation loss decreased (0.199553 --> 0.199406).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4132843
	speed: 0.0226s/iter; left time: 244.2257s
Epoch: 13 cost time: 2.7762038707733154
Epoch: 13, Steps: 124 Train Loss: 30.3011 (Forecasting Loss:0.2504 + XiCon Loss:3.0051 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1445
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.7542152
	speed: 0.0226s/iter; left time: 241.8303s
Epoch: 14 cost time: 2.7821054458618164
Epoch: 14, Steps: 124 Train Loss: 30.3030 (Forecasting Loss:0.2503 + XiCon Loss:3.0053 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1445
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.8057804
	speed: 0.0226s/iter; left time: 238.2853s
Epoch: 15 cost time: 2.770357370376587
Epoch: 15, Steps: 124 Train Loss: 30.3173 (Forecasting Loss:0.2504 + XiCon Loss:3.0067 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1445
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1310177
	speed: 0.0228s/iter; left time: 237.9992s
Epoch: 16 cost time: 2.7982382774353027
Epoch: 16, Steps: 124 Train Loss: 30.2970 (Forecasting Loss:0.2506 + XiCon Loss:3.0046 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1445
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.5050354
	speed: 0.0226s/iter; left time: 232.7117s
Epoch: 17 cost time: 2.7821390628814697
Epoch: 17, Steps: 124 Train Loss: 30.3342 (Forecasting Loss:0.2506 + XiCon Loss:3.0084 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1445
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.8643837
	speed: 0.0226s/iter; left time: 230.1837s
Epoch: 18 cost time: 2.7810890674591064
Epoch: 18, Steps: 124 Train Loss: 30.2681 (Forecasting Loss:0.2501 + XiCon Loss:3.0018 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1445
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5185204
	speed: 0.0225s/iter; left time: 226.7811s
Epoch: 19 cost time: 2.7651805877685547
Epoch: 19, Steps: 124 Train Loss: 30.3119 (Forecasting Loss:0.2505 + XiCon Loss:3.0061 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1445
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.7103729
	speed: 0.0228s/iter; left time: 226.2633s
Epoch: 20 cost time: 2.793334484100342
Epoch: 20, Steps: 124 Train Loss: 30.3231 (Forecasting Loss:0.2507 + XiCon Loss:3.0072 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1445
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.5381985
	speed: 0.0228s/iter; left time: 223.6544s
Epoch: 21 cost time: 2.7967381477355957
Epoch: 21, Steps: 124 Train Loss: 30.3462 (Forecasting Loss:0.2506 + XiCon Loss:3.0096 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1445
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.3885098
	speed: 0.0226s/iter; left time: 219.4726s
Epoch: 22 cost time: 2.7803573608398438
Epoch: 22, Steps: 124 Train Loss: 30.3082 (Forecasting Loss:0.2507 + XiCon Loss:3.0058 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1445
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07411311566829681, mae:0.21495087444782257, mape:0.16304931044578552, mspe:0.04534202814102173 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2244
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 32.0240440
	speed: 0.0179s/iter; left time: 220.2970s
Epoch: 1 cost time: 2.1882293224334717
Epoch: 1, Steps: 124 Train Loss: 32.2629 (Forecasting Loss:0.2945 + XiCon Loss:3.1968 x Lambda(10.0)), Vali MSE Loss: 0.2159 Test MSE Loss: 0.1619
Validation loss decreased (inf --> 0.215886).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.4462070
	speed: 0.0190s/iter; left time: 231.6171s
Epoch: 2 cost time: 2.3256852626800537
Epoch: 2, Steps: 124 Train Loss: 30.9715 (Forecasting Loss:0.2810 + XiCon Loss:3.0691 x Lambda(10.0)), Vali MSE Loss: 0.2238 Test MSE Loss: 0.1575
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2182236
	speed: 0.0221s/iter; left time: 265.8542s
Epoch: 3 cost time: 2.744717597961426
Epoch: 3, Steps: 124 Train Loss: 31.2190 (Forecasting Loss:0.2690 + XiCon Loss:3.0950 x Lambda(10.0)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1508
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.3855515
	speed: 0.0236s/iter; left time: 282.0988s
Epoch: 4 cost time: 2.9125254154205322
Epoch: 4, Steps: 124 Train Loss: 30.7578 (Forecasting Loss:0.2606 + XiCon Loss:3.0497 x Lambda(10.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.1549
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3838253
	speed: 0.0239s/iter; left time: 282.3784s
Epoch: 5 cost time: 2.9358527660369873
Epoch: 5, Steps: 124 Train Loss: 30.5514 (Forecasting Loss:0.2567 + XiCon Loss:3.0295 x Lambda(10.0)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.1539
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.8694115
	speed: 0.0235s/iter; left time: 274.1861s
Epoch: 6 cost time: 2.8963212966918945
Epoch: 6, Steps: 124 Train Loss: 30.5358 (Forecasting Loss:0.2542 + XiCon Loss:3.0282 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1488
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8073483
	speed: 0.0237s/iter; left time: 274.0737s
Epoch: 7 cost time: 2.91104793548584
Epoch: 7, Steps: 124 Train Loss: 30.4257 (Forecasting Loss:0.2520 + XiCon Loss:3.0174 x Lambda(10.0)), Vali MSE Loss: 0.2218 Test MSE Loss: 0.1489
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.7106609
	speed: 0.0236s/iter; left time: 269.5468s
Epoch: 8 cost time: 2.907839775085449
Epoch: 8, Steps: 124 Train Loss: 30.3816 (Forecasting Loss:0.2518 + XiCon Loss:3.0130 x Lambda(10.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1482
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.2873516
	speed: 0.0235s/iter; left time: 265.7965s
Epoch: 9 cost time: 2.8946337699890137
Epoch: 9, Steps: 124 Train Loss: 30.3778 (Forecasting Loss:0.2518 + XiCon Loss:3.0126 x Lambda(10.0)), Vali MSE Loss: 0.2232 Test MSE Loss: 0.1493
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9427090
	speed: 0.0236s/iter; left time: 263.7002s
Epoch: 10 cost time: 2.9092345237731934
Epoch: 10, Steps: 124 Train Loss: 30.4648 (Forecasting Loss:0.2515 + XiCon Loss:3.0213 x Lambda(10.0)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.1486
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6600876
	speed: 0.0234s/iter; left time: 259.0036s
Epoch: 11 cost time: 2.8863866329193115
Epoch: 11, Steps: 124 Train Loss: 30.4256 (Forecasting Loss:0.2511 + XiCon Loss:3.0175 x Lambda(10.0)), Vali MSE Loss: 0.2218 Test MSE Loss: 0.1487
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08744975924491882, mae:0.23638209700584412, mape:0.1770065873861313, mspe:0.050488557666540146 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1940
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 32.1995430
	speed: 0.0180s/iter; left time: 221.5219s
Epoch: 1 cost time: 2.2031702995300293
Epoch: 1, Steps: 124 Train Loss: 32.2146 (Forecasting Loss:0.3040 + XiCon Loss:3.1911 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1629
Validation loss decreased (inf --> 0.220444).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1868916
	speed: 0.0217s/iter; left time: 263.8515s
Epoch: 2 cost time: 2.656116008758545
Epoch: 2, Steps: 124 Train Loss: 30.6953 (Forecasting Loss:0.2824 + XiCon Loss:3.0413 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1568
Validation loss decreased (0.220444 --> 0.210345).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.9975414
	speed: 0.0217s/iter; left time: 261.7133s
Epoch: 3 cost time: 2.725308418273926
Epoch: 3, Steps: 124 Train Loss: 30.8387 (Forecasting Loss:0.2673 + XiCon Loss:3.0571 x Lambda(10.0)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.1487
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.7176762
	speed: 0.0238s/iter; left time: 283.7541s
Epoch: 4 cost time: 2.9460854530334473
Epoch: 4, Steps: 124 Train Loss: 30.1505 (Forecasting Loss:0.2599 + XiCon Loss:2.9891 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1532
Validation loss decreased (0.210345 --> 0.207489).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2108002
	speed: 0.0251s/iter; left time: 295.7767s
Epoch: 5 cost time: 3.0933616161346436
Epoch: 5, Steps: 124 Train Loss: 29.9956 (Forecasting Loss:0.2561 + XiCon Loss:2.9739 x Lambda(10.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1511
Validation loss decreased (0.207489 --> 0.206578).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4654465
	speed: 0.0253s/iter; left time: 294.9916s
Epoch: 6 cost time: 3.0935068130493164
Epoch: 6, Steps: 124 Train Loss: 29.8907 (Forecasting Loss:0.2537 + XiCon Loss:2.9637 x Lambda(10.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1485
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.9294415
	speed: 0.0248s/iter; left time: 286.2385s
Epoch: 7 cost time: 3.0608482360839844
Epoch: 7, Steps: 124 Train Loss: 29.9246 (Forecasting Loss:0.2527 + XiCon Loss:2.9672 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1490
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.3644524
	speed: 0.0246s/iter; left time: 281.1628s
Epoch: 8 cost time: 3.0372538566589355
Epoch: 8, Steps: 124 Train Loss: 29.8687 (Forecasting Loss:0.2521 + XiCon Loss:2.9617 x Lambda(10.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1483
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4905968
	speed: 0.0250s/iter; left time: 282.1813s
Epoch: 9 cost time: 3.0676097869873047
Epoch: 9, Steps: 124 Train Loss: 29.7979 (Forecasting Loss:0.2523 + XiCon Loss:2.9546 x Lambda(10.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1485
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9245415
	speed: 0.0245s/iter; left time: 273.7282s
Epoch: 10 cost time: 3.0190234184265137
Epoch: 10, Steps: 124 Train Loss: 29.8382 (Forecasting Loss:0.2513 + XiCon Loss:2.9587 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1484
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.9731674
	speed: 0.0243s/iter; left time: 268.5299s
Epoch: 11 cost time: 3.0184309482574463
Epoch: 11, Steps: 124 Train Loss: 29.8628 (Forecasting Loss:0.2521 + XiCon Loss:2.9611 x Lambda(10.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1485
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.2349548
	speed: 0.0248s/iter; left time: 271.7274s
Epoch: 12 cost time: 3.0582003593444824
Epoch: 12, Steps: 124 Train Loss: 29.8581 (Forecasting Loss:0.2515 + XiCon Loss:2.9607 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1484
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.8880482
	speed: 0.0244s/iter; left time: 264.2784s
Epoch: 13 cost time: 3.0119833946228027
Epoch: 13, Steps: 124 Train Loss: 29.8860 (Forecasting Loss:0.2513 + XiCon Loss:2.9635 x Lambda(10.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1484
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.7499046
	speed: 0.0248s/iter; left time: 264.6507s
Epoch: 14 cost time: 3.0463547706604004
Epoch: 14, Steps: 124 Train Loss: 29.9269 (Forecasting Loss:0.2520 + XiCon Loss:2.9675 x Lambda(10.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1484
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4594402
	speed: 0.0247s/iter; left time: 260.5883s
Epoch: 15 cost time: 3.042947769165039
Epoch: 15, Steps: 124 Train Loss: 29.9729 (Forecasting Loss:0.2511 + XiCon Loss:2.9722 x Lambda(10.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1484
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.0797097310423851, mae:0.2224244475364685, mape:0.16619336605072021, mspe:0.04540648311376572 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2160
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 32.1506844
	speed: 0.0178s/iter; left time: 219.0607s
Epoch: 1 cost time: 2.1807000637054443
Epoch: 1, Steps: 124 Train Loss: 32.4860 (Forecasting Loss:0.2946 + XiCon Loss:3.2191 x Lambda(10.0)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.1595
Validation loss decreased (inf --> 0.214561).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.2369785
	speed: 0.0215s/iter; left time: 261.4281s
Epoch: 2 cost time: 2.6953792572021484
Epoch: 2, Steps: 124 Train Loss: 30.9266 (Forecasting Loss:0.2828 + XiCon Loss:3.0644 x Lambda(10.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.4374275
	speed: 0.0219s/iter; left time: 264.2460s
Epoch: 3 cost time: 2.6867785453796387
Epoch: 3, Steps: 124 Train Loss: 31.1778 (Forecasting Loss:0.2691 + XiCon Loss:3.0909 x Lambda(10.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1543
Validation loss decreased (0.214561 --> 0.207407).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.8886490
	speed: 0.0210s/iter; left time: 250.7783s
Epoch: 4 cost time: 2.5256340503692627
Epoch: 4, Steps: 124 Train Loss: 30.9733 (Forecasting Loss:0.2626 + XiCon Loss:3.0711 x Lambda(10.0)), Vali MSE Loss: 0.2054 Test MSE Loss: 0.1533
Validation loss decreased (0.207407 --> 0.205423).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.0263596
	speed: 0.0185s/iter; left time: 218.9634s
Epoch: 5 cost time: 2.2729196548461914
Epoch: 5, Steps: 124 Train Loss: 30.7960 (Forecasting Loss:0.2581 + XiCon Loss:3.0538 x Lambda(10.0)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.1466
Validation loss decreased (0.205423 --> 0.204866).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.1189423
	speed: 0.0181s/iter; left time: 211.3112s
Epoch: 6 cost time: 2.213563919067383
Epoch: 6, Steps: 124 Train Loss: 30.7200 (Forecasting Loss:0.2561 + XiCon Loss:3.0464 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1525
Validation loss decreased (0.204866 --> 0.203450).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.7171326
	speed: 0.0179s/iter; left time: 207.2404s
Epoch: 7 cost time: 2.191890001296997
Epoch: 7, Steps: 124 Train Loss: 30.6986 (Forecasting Loss:0.2550 + XiCon Loss:3.0444 x Lambda(10.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1489
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.2734947
	speed: 0.0181s/iter; left time: 207.3983s
Epoch: 8 cost time: 2.2249348163604736
Epoch: 8, Steps: 124 Train Loss: 30.6264 (Forecasting Loss:0.2545 + XiCon Loss:3.0372 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1490
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7548027
	speed: 0.0180s/iter; left time: 203.6471s
Epoch: 9 cost time: 2.2011239528656006
Epoch: 9, Steps: 124 Train Loss: 30.6380 (Forecasting Loss:0.2541 + XiCon Loss:3.0384 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1489
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.9106312
	speed: 0.0177s/iter; left time: 198.1902s
Epoch: 10 cost time: 2.1750309467315674
Epoch: 10, Steps: 124 Train Loss: 30.5757 (Forecasting Loss:0.2540 + XiCon Loss:3.0322 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1489
Validation loss decreased (0.203450 --> 0.203295).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8743477
	speed: 0.0179s/iter; left time: 197.8684s
Epoch: 11 cost time: 2.1962358951568604
Epoch: 11, Steps: 124 Train Loss: 30.6013 (Forecasting Loss:0.2538 + XiCon Loss:3.0348 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1490
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.0157986
	speed: 0.0179s/iter; left time: 196.0478s
Epoch: 12 cost time: 2.195774793624878
Epoch: 12, Steps: 124 Train Loss: 30.5936 (Forecasting Loss:0.2537 + XiCon Loss:3.0340 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1490
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8635941
	speed: 0.0179s/iter; left time: 193.2650s
Epoch: 13 cost time: 2.2007362842559814
Epoch: 13, Steps: 124 Train Loss: 30.5580 (Forecasting Loss:0.2538 + XiCon Loss:3.0304 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1490
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.0578804
	speed: 0.0179s/iter; left time: 191.4104s
Epoch: 14 cost time: 2.192734956741333
Epoch: 14, Steps: 124 Train Loss: 30.6016 (Forecasting Loss:0.2536 + XiCon Loss:3.0348 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1490
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3967113
	speed: 0.0180s/iter; left time: 190.1032s
Epoch: 15 cost time: 2.20503306388855
Epoch: 15, Steps: 124 Train Loss: 30.6367 (Forecasting Loss:0.2538 + XiCon Loss:3.0383 x Lambda(10.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1490
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.1313095
	speed: 0.0179s/iter; left time: 187.3221s
Epoch: 16 cost time: 2.191837787628174
Epoch: 16, Steps: 124 Train Loss: 30.6963 (Forecasting Loss:0.2537 + XiCon Loss:3.0443 x Lambda(10.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1490
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.7958641
	speed: 0.0178s/iter; left time: 183.8886s
Epoch: 17 cost time: 2.1878662109375
Epoch: 17, Steps: 124 Train Loss: 30.6799 (Forecasting Loss:0.2537 + XiCon Loss:3.0426 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1490
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.6503029
	speed: 0.0176s/iter; left time: 179.8487s
Epoch: 18 cost time: 2.171433210372925
Epoch: 18, Steps: 124 Train Loss: 30.6824 (Forecasting Loss:0.2536 + XiCon Loss:3.0429 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1490
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.6499119
	speed: 0.0180s/iter; left time: 180.9891s
Epoch: 19 cost time: 2.201808214187622
Epoch: 19, Steps: 124 Train Loss: 30.6424 (Forecasting Loss:0.2539 + XiCon Loss:3.0389 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1490
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.3560009
	speed: 0.0181s/iter; left time: 179.6210s
Epoch: 20 cost time: 2.2100484371185303
Epoch: 20, Steps: 124 Train Loss: 30.6274 (Forecasting Loss:0.2537 + XiCon Loss:3.0374 x Lambda(10.0)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1490
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07812480628490448, mae:0.2197541892528534, mape:0.16429373621940613, mspe:0.04443705454468727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2551
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 32.1870003
	speed: 0.0179s/iter; left time: 220.2286s
Epoch: 1 cost time: 2.1996030807495117
Epoch: 1, Steps: 124 Train Loss: 32.1842 (Forecasting Loss:0.2946 + XiCon Loss:3.1890 x Lambda(10.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1613
Validation loss decreased (inf --> 0.216556).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.1531143
	speed: 0.0222s/iter; left time: 270.1269s
Epoch: 2 cost time: 2.7917141914367676
Epoch: 2, Steps: 124 Train Loss: 30.5398 (Forecasting Loss:0.2838 + XiCon Loss:3.0256 x Lambda(10.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1603
Validation loss decreased (0.216556 --> 0.214274).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.1252270
	speed: 0.0238s/iter; left time: 287.4534s
Epoch: 3 cost time: 2.920039415359497
Epoch: 3, Steps: 124 Train Loss: 29.3144 (Forecasting Loss:0.2732 + XiCon Loss:2.9041 x Lambda(10.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1610
Validation loss decreased (0.214274 --> 0.207328).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.9353752
	speed: 0.0244s/iter; left time: 290.5054s
Epoch: 4 cost time: 3.022969961166382
Epoch: 4, Steps: 124 Train Loss: 29.0321 (Forecasting Loss:0.2632 + XiCon Loss:2.8769 x Lambda(10.0)), Vali MSE Loss: 0.2046 Test MSE Loss: 0.1570
Validation loss decreased (0.207328 --> 0.204619).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4511147
	speed: 0.0243s/iter; left time: 287.0606s
Epoch: 5 cost time: 2.990966796875
Epoch: 5, Steps: 124 Train Loss: 28.9150 (Forecasting Loss:0.2522 + XiCon Loss:2.8663 x Lambda(10.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1531
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.7232666
	speed: 0.0243s/iter; left time: 283.8517s
Epoch: 6 cost time: 2.9704182147979736
Epoch: 6, Steps: 124 Train Loss: 28.8793 (Forecasting Loss:0.2488 + XiCon Loss:2.8631 x Lambda(10.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1545
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.5122910
	speed: 0.0239s/iter; left time: 275.7237s
Epoch: 7 cost time: 2.935553550720215
Epoch: 7, Steps: 124 Train Loss: 28.8415 (Forecasting Loss:0.2481 + XiCon Loss:2.8593 x Lambda(10.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1528
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.7303410
	speed: 0.0233s/iter; left time: 266.8594s
Epoch: 8 cost time: 2.877854585647583
Epoch: 8, Steps: 124 Train Loss: 28.8175 (Forecasting Loss:0.2473 + XiCon Loss:2.8570 x Lambda(10.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1522
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.5731163
	speed: 0.0236s/iter; left time: 267.2390s
Epoch: 9 cost time: 2.9087975025177
Epoch: 9, Steps: 124 Train Loss: 28.8724 (Forecasting Loss:0.2474 + XiCon Loss:2.8625 x Lambda(10.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1527
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.6477489
	speed: 0.0235s/iter; left time: 262.4733s
Epoch: 10 cost time: 2.8776659965515137
Epoch: 10, Steps: 124 Train Loss: 28.8185 (Forecasting Loss:0.2471 + XiCon Loss:2.8571 x Lambda(10.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1530
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.6304836
	speed: 0.0234s/iter; left time: 258.8895s
Epoch: 11 cost time: 2.886559247970581
Epoch: 11, Steps: 124 Train Loss: 28.7629 (Forecasting Loss:0.2469 + XiCon Loss:2.8516 x Lambda(10.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1528
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.9505882
	speed: 0.0234s/iter; left time: 256.1620s
Epoch: 12 cost time: 2.8820457458496094
Epoch: 12, Steps: 124 Train Loss: 28.7713 (Forecasting Loss:0.2468 + XiCon Loss:2.8524 x Lambda(10.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1528
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3747444
	speed: 0.0234s/iter; left time: 253.0415s
Epoch: 13 cost time: 2.8873353004455566
Epoch: 13, Steps: 124 Train Loss: 28.8056 (Forecasting Loss:0.2471 + XiCon Loss:2.8559 x Lambda(10.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1528
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.5503922
	speed: 0.0236s/iter; left time: 252.7896s
Epoch: 14 cost time: 2.9322562217712402
Epoch: 14, Steps: 124 Train Loss: 28.8085 (Forecasting Loss:0.2468 + XiCon Loss:2.8562 x Lambda(10.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1528
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.0847005620598793, mae:0.22921237349510193, mape:0.17179124057292938, mspe:0.049718618392944336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0808+-0.00658, MAE:0.2245+-0.01041, MAPE:0.1685+-0.00724, MSPE:0.0471+-0.00348, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3545
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3705901
	speed: 0.0440s/iter; left time: 515.0470s
Epoch: 1 cost time: 5.141008377075195
Epoch: 1, Steps: 118 Train Loss: 0.3627 (Forecasting Loss:0.3594 + XiCon Loss:3.2311 x Lambda(0.001)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.258898).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2762772
	speed: 0.0415s/iter; left time: 480.6294s
Epoch: 2 cost time: 5.086802244186401
Epoch: 2, Steps: 118 Train Loss: 0.2996 (Forecasting Loss:0.2963 + XiCon Loss:3.2245 x Lambda(0.001)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.1500
Validation loss decreased (0.258898 --> 0.251055).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2398043
	speed: 0.0541s/iter; left time: 620.0639s
Epoch: 3 cost time: 6.4315574169158936
Epoch: 3, Steps: 118 Train Loss: 0.2372 (Forecasting Loss:0.2340 + XiCon Loss:3.2000 x Lambda(0.001)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1441
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2134917
	speed: 0.0548s/iter; left time: 622.3390s
Epoch: 4 cost time: 6.4966816902160645
Epoch: 4, Steps: 118 Train Loss: 0.2225 (Forecasting Loss:0.2193 + XiCon Loss:3.1915 x Lambda(0.001)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1475
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2093270
	speed: 0.0554s/iter; left time: 622.5259s
Epoch: 5 cost time: 6.604402303695679
Epoch: 5, Steps: 118 Train Loss: 0.2168 (Forecasting Loss:0.2136 + XiCon Loss:3.1894 x Lambda(0.001)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.1466
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2190581
	speed: 0.0573s/iter; left time: 636.3187s
Epoch: 6 cost time: 6.8304619789123535
Epoch: 6, Steps: 118 Train Loss: 0.2142 (Forecasting Loss:0.2110 + XiCon Loss:3.1871 x Lambda(0.001)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.1477
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2127331
	speed: 0.0583s/iter; left time: 640.8120s
Epoch: 7 cost time: 6.906604051589966
Epoch: 7, Steps: 118 Train Loss: 0.2128 (Forecasting Loss:0.2096 + XiCon Loss:3.1858 x Lambda(0.001)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1488
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2140102
	speed: 0.0617s/iter; left time: 671.2335s
Epoch: 8 cost time: 7.241034030914307
Epoch: 8, Steps: 118 Train Loss: 0.2121 (Forecasting Loss:0.2090 + XiCon Loss:3.1850 x Lambda(0.001)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.1473
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2036536
	speed: 0.0584s/iter; left time: 627.6873s
Epoch: 9 cost time: 6.906885385513306
Epoch: 9, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2082 + XiCon Loss:3.1844 x Lambda(0.001)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1477
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2220391
	speed: 0.0616s/iter; left time: 655.7920s
Epoch: 10 cost time: 7.257808446884155
Epoch: 10, Steps: 118 Train Loss: 0.2116 (Forecasting Loss:0.2084 + XiCon Loss:3.1841 x Lambda(0.001)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.1479
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2222866
	speed: 0.0589s/iter; left time: 619.7979s
Epoch: 11 cost time: 7.000132322311401
Epoch: 11, Steps: 118 Train Loss: 0.2114 (Forecasting Loss:0.2082 + XiCon Loss:3.1847 x Lambda(0.001)), Vali MSE Loss: 0.2604 Test MSE Loss: 0.1476
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2061695
	speed: 0.0585s/iter; left time: 608.3448s
Epoch: 12 cost time: 6.968284845352173
Epoch: 12, Steps: 118 Train Loss: 0.2112 (Forecasting Loss:0.2081 + XiCon Loss:3.1839 x Lambda(0.001)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.1477
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07777582854032516, mae:0.22231601178646088, mape:0.16743697226047516, mspe:0.048925723880529404 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2590
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3102679
	speed: 0.0411s/iter; left time: 481.0084s
Epoch: 1 cost time: 4.862484693527222
Epoch: 1, Steps: 118 Train Loss: 0.3567 (Forecasting Loss:0.3535 + XiCon Loss:3.2256 x Lambda(0.001)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.1627
Validation loss decreased (inf --> 0.256374).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2836227
	speed: 0.0418s/iter; left time: 484.0077s
Epoch: 2 cost time: 4.955703496932983
Epoch: 2, Steps: 118 Train Loss: 0.3036 (Forecasting Loss:0.3004 + XiCon Loss:3.2152 x Lambda(0.001)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1480
Validation loss decreased (0.256374 --> 0.218534).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2454369
	speed: 0.0412s/iter; left time: 472.5438s
Epoch: 3 cost time: 4.90977668762207
Epoch: 3, Steps: 118 Train Loss: 0.2588 (Forecasting Loss:0.2556 + XiCon Loss:3.2073 x Lambda(0.001)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1470
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2382521
	speed: 0.0412s/iter; left time: 467.0755s
Epoch: 4 cost time: 4.866235017776489
Epoch: 4, Steps: 118 Train Loss: 0.2408 (Forecasting Loss:0.2375 + XiCon Loss:3.2071 x Lambda(0.001)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.1457
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2279669
	speed: 0.0436s/iter; left time: 489.8826s
Epoch: 5 cost time: 5.116360664367676
Epoch: 5, Steps: 118 Train Loss: 0.2318 (Forecasting Loss:0.2286 + XiCon Loss:3.2063 x Lambda(0.001)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1447
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2349028
	speed: 0.0434s/iter; left time: 481.8741s
Epoch: 6 cost time: 5.085068941116333
Epoch: 6, Steps: 118 Train Loss: 0.2282 (Forecasting Loss:0.2250 + XiCon Loss:3.2063 x Lambda(0.001)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1449
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2346833
	speed: 0.0425s/iter; left time: 466.8975s
Epoch: 7 cost time: 4.987672328948975
Epoch: 7, Steps: 118 Train Loss: 0.2266 (Forecasting Loss:0.2234 + XiCon Loss:3.2062 x Lambda(0.001)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1450
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2386093
	speed: 0.0455s/iter; left time: 494.6813s
Epoch: 8 cost time: 5.319532871246338
Epoch: 8, Steps: 118 Train Loss: 0.2254 (Forecasting Loss:0.2222 + XiCon Loss:3.2056 x Lambda(0.001)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1455
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2215619
	speed: 0.0414s/iter; left time: 444.8040s
Epoch: 9 cost time: 5.18780255317688
Epoch: 9, Steps: 118 Train Loss: 0.2250 (Forecasting Loss:0.2218 + XiCon Loss:3.2062 x Lambda(0.001)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1444
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2342028
	speed: 0.0439s/iter; left time: 466.8062s
Epoch: 10 cost time: 5.150444030761719
Epoch: 10, Steps: 118 Train Loss: 0.2248 (Forecasting Loss:0.2216 + XiCon Loss:3.2054 x Lambda(0.001)), Vali MSE Loss: 0.2420 Test MSE Loss: 0.1450
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2325029
	speed: 0.0421s/iter; left time: 442.7594s
Epoch: 11 cost time: 4.98075795173645
Epoch: 11, Steps: 118 Train Loss: 0.2250 (Forecasting Loss:0.2218 + XiCon Loss:3.2066 x Lambda(0.001)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1447
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2195325
	speed: 0.0413s/iter; left time: 429.5813s
Epoch: 12 cost time: 4.89157509803772
Epoch: 12, Steps: 118 Train Loss: 0.2250 (Forecasting Loss:0.2218 + XiCon Loss:3.2060 x Lambda(0.001)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.1444
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07555536180734634, mae:0.22034917771816254, mape:0.1662980616092682, mspe:0.0461212582886219 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1759
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3267930
	speed: 0.0414s/iter; left time: 484.4409s
Epoch: 1 cost time: 4.916424036026001
Epoch: 1, Steps: 118 Train Loss: 0.3578 (Forecasting Loss:0.3545 + XiCon Loss:3.2246 x Lambda(0.001)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1640
Validation loss decreased (inf --> 0.253625).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2704282
	speed: 0.0439s/iter; left time: 508.0151s
Epoch: 2 cost time: 5.257087230682373
Epoch: 2, Steps: 118 Train Loss: 0.3042 (Forecasting Loss:0.3011 + XiCon Loss:3.1897 x Lambda(0.001)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.1453
Validation loss decreased (0.253625 --> 0.250996).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2399288
	speed: 0.0484s/iter; left time: 554.6597s
Epoch: 3 cost time: 5.745010614395142
Epoch: 3, Steps: 118 Train Loss: 0.2419 (Forecasting Loss:0.2387 + XiCon Loss:3.1472 x Lambda(0.001)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.1539
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2146708
	speed: 0.0558s/iter; left time: 633.2753s
Epoch: 4 cost time: 6.534752130508423
Epoch: 4, Steps: 118 Train Loss: 0.2234 (Forecasting Loss:0.2203 + XiCon Loss:3.1472 x Lambda(0.001)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.1477
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2180072
	speed: 0.0531s/iter; left time: 596.1151s
Epoch: 5 cost time: 6.3460853099823
Epoch: 5, Steps: 118 Train Loss: 0.2166 (Forecasting Loss:0.2135 + XiCon Loss:3.1461 x Lambda(0.001)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.1513
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2183130
	speed: 0.0546s/iter; left time: 606.5536s
Epoch: 6 cost time: 6.492506265640259
Epoch: 6, Steps: 118 Train Loss: 0.2133 (Forecasting Loss:0.2101 + XiCon Loss:3.1463 x Lambda(0.001)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.1493
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2171312
	speed: 0.0551s/iter; left time: 605.5213s
Epoch: 7 cost time: 6.515837669372559
Epoch: 7, Steps: 118 Train Loss: 0.2118 (Forecasting Loss:0.2086 + XiCon Loss:3.1460 x Lambda(0.001)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1512
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2066891
	speed: 0.0544s/iter; left time: 591.9171s
Epoch: 8 cost time: 6.453096151351929
Epoch: 8, Steps: 118 Train Loss: 0.2110 (Forecasting Loss:0.2079 + XiCon Loss:3.1461 x Lambda(0.001)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1501
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2125218
	speed: 0.0538s/iter; left time: 579.2481s
Epoch: 9 cost time: 6.41970682144165
Epoch: 9, Steps: 118 Train Loss: 0.2107 (Forecasting Loss:0.2075 + XiCon Loss:3.1439 x Lambda(0.001)), Vali MSE Loss: 0.2634 Test MSE Loss: 0.1502
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2050074
	speed: 0.0570s/iter; left time: 606.5178s
Epoch: 10 cost time: 6.68970799446106
Epoch: 10, Steps: 118 Train Loss: 0.2105 (Forecasting Loss:0.2073 + XiCon Loss:3.1445 x Lambda(0.001)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1503
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2245428
	speed: 0.0544s/iter; left time: 571.9942s
Epoch: 11 cost time: 6.428804874420166
Epoch: 11, Steps: 118 Train Loss: 0.2103 (Forecasting Loss:0.2072 + XiCon Loss:3.1442 x Lambda(0.001)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1506
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2157889
	speed: 0.0578s/iter; left time: 601.0819s
Epoch: 12 cost time: 6.810304164886475
Epoch: 12, Steps: 118 Train Loss: 0.2104 (Forecasting Loss:0.2072 + XiCon Loss:3.1447 x Lambda(0.001)), Vali MSE Loss: 0.2629 Test MSE Loss: 0.1503
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07469864934682846, mae:0.21599669754505157, mape:0.1630067527294159, mspe:0.048157546669244766 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2942
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3243178
	speed: 0.0412s/iter; left time: 482.6509s
Epoch: 1 cost time: 4.879071235656738
Epoch: 1, Steps: 118 Train Loss: 0.3553 (Forecasting Loss:0.3521 + XiCon Loss:3.2262 x Lambda(0.001)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1590
Validation loss decreased (inf --> 0.255511).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2623054
	speed: 0.0434s/iter; left time: 502.6850s
Epoch: 2 cost time: 5.11551308631897
Epoch: 2, Steps: 118 Train Loss: 0.3165 (Forecasting Loss:0.3133 + XiCon Loss:3.2142 x Lambda(0.001)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1383
Validation loss decreased (0.255511 --> 0.228881).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2465264
	speed: 0.0455s/iter; left time: 521.8196s
Epoch: 3 cost time: 5.4187517166137695
Epoch: 3, Steps: 118 Train Loss: 0.2466 (Forecasting Loss:0.2434 + XiCon Loss:3.1818 x Lambda(0.001)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1368
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2254975
	speed: 0.0522s/iter; left time: 592.1461s
Epoch: 4 cost time: 6.108527898788452
Epoch: 4, Steps: 118 Train Loss: 0.2282 (Forecasting Loss:0.2250 + XiCon Loss:3.1684 x Lambda(0.001)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.1404
Validation loss decreased (0.228881 --> 0.228736).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2326175
	speed: 0.0499s/iter; left time: 560.5619s
Epoch: 5 cost time: 5.918140172958374
Epoch: 5, Steps: 118 Train Loss: 0.2223 (Forecasting Loss:0.2191 + XiCon Loss:3.1659 x Lambda(0.001)), Vali MSE Loss: 0.2324 Test MSE Loss: 0.1388
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2099980
	speed: 0.0500s/iter; left time: 556.0866s
Epoch: 6 cost time: 5.897803783416748
Epoch: 6, Steps: 118 Train Loss: 0.2191 (Forecasting Loss:0.2159 + XiCon Loss:3.1658 x Lambda(0.001)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1365
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2155814
	speed: 0.0499s/iter; left time: 548.1751s
Epoch: 7 cost time: 5.8918352127075195
Epoch: 7, Steps: 118 Train Loss: 0.2178 (Forecasting Loss:0.2146 + XiCon Loss:3.1662 x Lambda(0.001)), Vali MSE Loss: 0.2387 Test MSE Loss: 0.1371
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2235262
	speed: 0.0493s/iter; left time: 536.6313s
Epoch: 8 cost time: 5.838695287704468
Epoch: 8, Steps: 118 Train Loss: 0.2170 (Forecasting Loss:0.2139 + XiCon Loss:3.1657 x Lambda(0.001)), Vali MSE Loss: 0.2378 Test MSE Loss: 0.1376
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2228330
	speed: 0.0504s/iter; left time: 541.7690s
Epoch: 9 cost time: 5.947788953781128
Epoch: 9, Steps: 118 Train Loss: 0.2167 (Forecasting Loss:0.2136 + XiCon Loss:3.1663 x Lambda(0.001)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.1369
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2221011
	speed: 0.0499s/iter; left time: 530.8641s
Epoch: 10 cost time: 5.920757532119751
Epoch: 10, Steps: 118 Train Loss: 0.2166 (Forecasting Loss:0.2135 + XiCon Loss:3.1651 x Lambda(0.001)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1368
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2202632
	speed: 0.0502s/iter; left time: 528.1577s
Epoch: 11 cost time: 5.953274250030518
Epoch: 11, Steps: 118 Train Loss: 0.2164 (Forecasting Loss:0.2132 + XiCon Loss:3.1663 x Lambda(0.001)), Vali MSE Loss: 0.2400 Test MSE Loss: 0.1369
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2130407
	speed: 0.0495s/iter; left time: 515.2846s
Epoch: 12 cost time: 5.855046033859253
Epoch: 12, Steps: 118 Train Loss: 0.2162 (Forecasting Loss:0.2130 + XiCon Loss:3.1672 x Lambda(0.001)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1368
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2264770
	speed: 0.0507s/iter; left time: 521.4947s
Epoch: 13 cost time: 6.037660837173462
Epoch: 13, Steps: 118 Train Loss: 0.2163 (Forecasting Loss:0.2131 + XiCon Loss:3.1662 x Lambda(0.001)), Vali MSE Loss: 0.2403 Test MSE Loss: 0.1368
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2031866
	speed: 0.0487s/iter; left time: 495.6090s
Epoch: 14 cost time: 5.820322275161743
Epoch: 14, Steps: 118 Train Loss: 0.2163 (Forecasting Loss:0.2132 + XiCon Loss:3.1669 x Lambda(0.001)), Vali MSE Loss: 0.2402 Test MSE Loss: 0.1368
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07009579986333847, mae:0.2107216715812683, mape:0.157369464635849, mspe:0.0425412617623806 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3038
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3341671
	speed: 0.0412s/iter; left time: 481.5751s
Epoch: 1 cost time: 4.858655214309692
Epoch: 1, Steps: 118 Train Loss: 0.3567 (Forecasting Loss:0.3535 + XiCon Loss:3.2262 x Lambda(0.001)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1621
Validation loss decreased (inf --> 0.255393).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2746633
	speed: 0.0467s/iter; left time: 540.7976s
Epoch: 2 cost time: 5.444841623306274
Epoch: 2, Steps: 118 Train Loss: 0.3058 (Forecasting Loss:0.3026 + XiCon Loss:3.2113 x Lambda(0.001)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1479
Validation loss decreased (0.255393 --> 0.227091).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2416992
	speed: 0.0421s/iter; left time: 482.8945s
Epoch: 3 cost time: 4.99229621887207
Epoch: 3, Steps: 118 Train Loss: 0.2494 (Forecasting Loss:0.2462 + XiCon Loss:3.1856 x Lambda(0.001)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.1348
Validation loss decreased (0.227091 --> 0.222428).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2247858
	speed: 0.0427s/iter; left time: 484.4714s
Epoch: 4 cost time: 5.041706800460815
Epoch: 4, Steps: 118 Train Loss: 0.2280 (Forecasting Loss:0.2249 + XiCon Loss:3.1592 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1378
Validation loss decreased (0.222428 --> 0.216230).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2109916
	speed: 0.0444s/iter; left time: 498.2298s
Epoch: 5 cost time: 5.220510959625244
Epoch: 5, Steps: 118 Train Loss: 0.2213 (Forecasting Loss:0.2181 + XiCon Loss:3.1556 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1371
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2098636
	speed: 0.0429s/iter; left time: 476.2696s
Epoch: 6 cost time: 5.080476999282837
Epoch: 6, Steps: 118 Train Loss: 0.2186 (Forecasting Loss:0.2154 + XiCon Loss:3.1537 x Lambda(0.001)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.1390
Validation loss decreased (0.216230 --> 0.215616).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2099102
	speed: 0.0471s/iter; left time: 518.2755s
Epoch: 7 cost time: 5.506070613861084
Epoch: 7, Steps: 118 Train Loss: 0.2172 (Forecasting Loss:0.2141 + XiCon Loss:3.1524 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2058044
	speed: 0.0453s/iter; left time: 492.9507s
Epoch: 8 cost time: 5.359412431716919
Epoch: 8, Steps: 118 Train Loss: 0.2162 (Forecasting Loss:0.2130 + XiCon Loss:3.1503 x Lambda(0.001)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1369
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2094200
	speed: 0.0438s/iter; left time: 471.6091s
Epoch: 9 cost time: 5.165333986282349
Epoch: 9, Steps: 118 Train Loss: 0.2160 (Forecasting Loss:0.2129 + XiCon Loss:3.1528 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1380
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2005587
	speed: 0.0461s/iter; left time: 490.5383s
Epoch: 10 cost time: 5.3984375
Epoch: 10, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2124 + XiCon Loss:3.1517 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1383
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2243886
	speed: 0.0493s/iter; left time: 518.3597s
Epoch: 11 cost time: 5.739860534667969
Epoch: 11, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2124 + XiCon Loss:3.1521 x Lambda(0.001)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1384
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2166169
	speed: 0.0430s/iter; left time: 447.7416s
Epoch: 12 cost time: 5.104349136352539
Epoch: 12, Steps: 118 Train Loss: 0.2157 (Forecasting Loss:0.2126 + XiCon Loss:3.1521 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1385
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2123075
	speed: 0.0450s/iter; left time: 463.0124s
Epoch: 13 cost time: 5.302126169204712
Epoch: 13, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2125 + XiCon Loss:3.1525 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1384
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2157248
	speed: 0.0439s/iter; left time: 446.4560s
Epoch: 14 cost time: 5.222093820571899
Epoch: 14, Steps: 118 Train Loss: 0.2152 (Forecasting Loss:0.2121 + XiCon Loss:3.1520 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1385
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2303033
	speed: 0.0431s/iter; left time: 433.3695s
Epoch: 15 cost time: 5.091748237609863
Epoch: 15, Steps: 118 Train Loss: 0.2153 (Forecasting Loss:0.2121 + XiCon Loss:3.1510 x Lambda(0.001)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1385
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2180655
	speed: 0.0453s/iter; left time: 450.3038s
Epoch: 16 cost time: 5.319439172744751
Epoch: 16, Steps: 118 Train Loss: 0.2154 (Forecasting Loss:0.2123 + XiCon Loss:3.1520 x Lambda(0.001)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1385
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.06822666525840759, mae:0.20976272225379944, mape:0.1585124433040619, mspe:0.043316490948200226 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0733+-0.00493, MAE:0.2158+-0.00695, MAPE:0.1625+-0.00560, MSPE:0.0458+-0.00352, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2912
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3598549
	speed: 0.0156s/iter; left time: 197.8101s
Epoch: 1 cost time: 1.861100435256958
Epoch: 1, Steps: 128 Train Loss: 3.4480 (Forecasting Loss:0.2930 + XiCon Loss:3.1550 x Lambda(1.0)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.2328
Validation loss decreased (inf --> 0.277104).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1608257
	speed: 0.0126s/iter; left time: 158.2364s
Epoch: 2 cost time: 1.5763158798217773
Epoch: 2, Steps: 128 Train Loss: 3.2286 (Forecasting Loss:0.2575 + XiCon Loss:2.9710 x Lambda(1.0)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.2209
Validation loss decreased (0.277104 --> 0.256365).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4092379
	speed: 0.0127s/iter; left time: 158.0307s
Epoch: 3 cost time: 1.5983896255493164
Epoch: 3, Steps: 128 Train Loss: 3.2494 (Forecasting Loss:0.2435 + XiCon Loss:3.0059 x Lambda(1.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.2203
Validation loss decreased (0.256365 --> 0.253389).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4365211
	speed: 0.0128s/iter; left time: 157.7040s
Epoch: 4 cost time: 1.6017022132873535
Epoch: 4, Steps: 128 Train Loss: 3.4071 (Forecasting Loss:0.2375 + XiCon Loss:3.1696 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.2059
Validation loss decreased (0.253389 --> 0.252059).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4633429
	speed: 0.0132s/iter; left time: 160.9908s
Epoch: 5 cost time: 1.6466994285583496
Epoch: 5, Steps: 128 Train Loss: 3.4723 (Forecasting Loss:0.2345 + XiCon Loss:3.2379 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2082
Validation loss decreased (0.252059 --> 0.248859).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4991076
	speed: 0.0130s/iter; left time: 156.2732s
Epoch: 6 cost time: 1.6269123554229736
Epoch: 6, Steps: 128 Train Loss: 3.4776 (Forecasting Loss:0.2324 + XiCon Loss:3.2452 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2064
Validation loss decreased (0.248859 --> 0.247734).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4779425
	speed: 0.0127s/iter; left time: 151.4257s
Epoch: 7 cost time: 1.5936172008514404
Epoch: 7, Steps: 128 Train Loss: 3.4788 (Forecasting Loss:0.2310 + XiCon Loss:3.2479 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.2072
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4735913
	speed: 0.0137s/iter; left time: 162.0175s
Epoch: 8 cost time: 1.7049407958984375
Epoch: 8, Steps: 128 Train Loss: 3.4918 (Forecasting Loss:0.2306 + XiCon Loss:3.2612 x Lambda(1.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2065
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4943807
	speed: 0.0129s/iter; left time: 150.6634s
Epoch: 9 cost time: 1.6099567413330078
Epoch: 9, Steps: 128 Train Loss: 3.4746 (Forecasting Loss:0.2305 + XiCon Loss:3.2440 x Lambda(1.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2058
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4673214
	speed: 0.0127s/iter; left time: 146.9403s
Epoch: 10 cost time: 1.5923519134521484
Epoch: 10, Steps: 128 Train Loss: 3.4845 (Forecasting Loss:0.2303 + XiCon Loss:3.2542 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2060
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4419265
	speed: 0.0128s/iter; left time: 145.7059s
Epoch: 11 cost time: 1.595468282699585
Epoch: 11, Steps: 128 Train Loss: 3.4893 (Forecasting Loss:0.2303 + XiCon Loss:3.2590 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2060
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5007651
	speed: 0.0127s/iter; left time: 143.1721s
Epoch: 12 cost time: 1.5886867046356201
Epoch: 12, Steps: 128 Train Loss: 3.4763 (Forecasting Loss:0.2302 + XiCon Loss:3.2461 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2060
Validation loss decreased (0.247734 --> 0.247698).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3908069
	speed: 0.0139s/iter; left time: 155.1275s
Epoch: 13 cost time: 1.7039568424224854
Epoch: 13, Steps: 128 Train Loss: 3.4783 (Forecasting Loss:0.2303 + XiCon Loss:3.2480 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.2060
Validation loss decreased (0.247698 --> 0.247527).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4984875
	speed: 0.0127s/iter; left time: 140.4869s
Epoch: 14 cost time: 1.594879150390625
Epoch: 14, Steps: 128 Train Loss: 3.4951 (Forecasting Loss:0.2300 + XiCon Loss:3.2650 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.5084114
	speed: 0.0134s/iter; left time: 145.8837s
Epoch: 15 cost time: 1.6646792888641357
Epoch: 15, Steps: 128 Train Loss: 3.4801 (Forecasting Loss:0.2300 + XiCon Loss:3.2501 x Lambda(1.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.2060
Validation loss decreased (0.247527 --> 0.247314).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2550890
	speed: 0.0137s/iter; left time: 147.5070s
Epoch: 16 cost time: 1.7107722759246826
Epoch: 16, Steps: 128 Train Loss: 3.4725 (Forecasting Loss:0.2302 + XiCon Loss:3.2422 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.6809950
	speed: 0.0130s/iter; left time: 138.9707s
Epoch: 17 cost time: 1.6207709312438965
Epoch: 17, Steps: 128 Train Loss: 3.4957 (Forecasting Loss:0.2303 + XiCon Loss:3.2654 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4631014
	speed: 0.0127s/iter; left time: 133.8659s
Epoch: 18 cost time: 1.59678316116333
Epoch: 18, Steps: 128 Train Loss: 3.4777 (Forecasting Loss:0.2302 + XiCon Loss:3.2475 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.2060
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4776118
	speed: 0.0128s/iter; left time: 133.1252s
Epoch: 19 cost time: 1.6023163795471191
Epoch: 19, Steps: 128 Train Loss: 3.4801 (Forecasting Loss:0.2302 + XiCon Loss:3.2499 x Lambda(1.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2060
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4982736
	speed: 0.0127s/iter; left time: 130.8714s
Epoch: 20 cost time: 1.594658374786377
Epoch: 20, Steps: 128 Train Loss: 3.4801 (Forecasting Loss:0.2302 + XiCon Loss:3.2499 x Lambda(1.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.2060
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.5263405
	speed: 0.0129s/iter; left time: 130.7290s
Epoch: 21 cost time: 1.6084322929382324
Epoch: 21, Steps: 128 Train Loss: 3.4908 (Forecasting Loss:0.2299 + XiCon Loss:3.2609 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2060
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.6594627
	speed: 0.0127s/iter; left time: 126.7730s
Epoch: 22 cost time: 1.5855538845062256
Epoch: 22, Steps: 128 Train Loss: 3.4855 (Forecasting Loss:0.2302 + XiCon Loss:3.2553 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2060
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.5282202
	speed: 0.0127s/iter; left time: 125.5629s
Epoch: 23 cost time: 1.5945627689361572
Epoch: 23, Steps: 128 Train Loss: 3.4879 (Forecasting Loss:0.2302 + XiCon Loss:3.2577 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2060
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.6933053
	speed: 0.0127s/iter; left time: 124.3246s
Epoch: 24 cost time: 1.5949647426605225
Epoch: 24, Steps: 128 Train Loss: 3.5004 (Forecasting Loss:0.2302 + XiCon Loss:3.2702 x Lambda(1.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.2060
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.5855241
	speed: 0.0126s/iter; left time: 121.6828s
Epoch: 25 cost time: 1.585859775543213
Epoch: 25, Steps: 128 Train Loss: 3.4791 (Forecasting Loss:0.2301 + XiCon Loss:3.2490 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.2060
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13167229294776917, mae:0.2803502678871155, mape:0.6689979434013367, mspe:19.8503360748291 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2326
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3814101
	speed: 0.0130s/iter; left time: 164.8965s
Epoch: 1 cost time: 1.6118550300598145
Epoch: 1, Steps: 128 Train Loss: 3.4491 (Forecasting Loss:0.2935 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.2750 Test MSE Loss: 0.2275
Validation loss decreased (inf --> 0.275037).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2557619
	speed: 0.0135s/iter; left time: 169.9669s
Epoch: 2 cost time: 1.7131085395812988
Epoch: 2, Steps: 128 Train Loss: 3.2617 (Forecasting Loss:0.2559 + XiCon Loss:3.0058 x Lambda(1.0)), Vali MSE Loss: 0.2709 Test MSE Loss: 0.2371
Validation loss decreased (0.275037 --> 0.270869).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1910229
	speed: 0.0135s/iter; left time: 168.1088s
Epoch: 3 cost time: 1.683305263519287
Epoch: 3, Steps: 128 Train Loss: 3.1851 (Forecasting Loss:0.2389 + XiCon Loss:2.9462 x Lambda(1.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.2058
Validation loss decreased (0.270869 --> 0.258568).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1215622
	speed: 0.0132s/iter; left time: 162.0989s
Epoch: 4 cost time: 1.6647539138793945
Epoch: 4, Steps: 128 Train Loss: 3.1358 (Forecasting Loss:0.2332 + XiCon Loss:2.9027 x Lambda(1.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.2051
Validation loss decreased (0.258568 --> 0.247239).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0684118
	speed: 0.0128s/iter; left time: 156.3900s
Epoch: 5 cost time: 1.6068572998046875
Epoch: 5, Steps: 128 Train Loss: 3.1115 (Forecasting Loss:0.2296 + XiCon Loss:2.8820 x Lambda(1.0)), Vali MSE Loss: 0.2422 Test MSE Loss: 0.2053
Validation loss decreased (0.247239 --> 0.242153).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0964558
	speed: 0.0131s/iter; left time: 157.4790s
Epoch: 6 cost time: 1.6282806396484375
Epoch: 6, Steps: 128 Train Loss: 3.0942 (Forecasting Loss:0.2267 + XiCon Loss:2.8675 x Lambda(1.0)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.2091
Validation loss decreased (0.242153 --> 0.241673).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0555787
	speed: 0.0130s/iter; left time: 155.4149s
Epoch: 7 cost time: 1.6435749530792236
Epoch: 7, Steps: 128 Train Loss: 3.0902 (Forecasting Loss:0.2254 + XiCon Loss:2.8648 x Lambda(1.0)), Vali MSE Loss: 0.2413 Test MSE Loss: 0.2073
Validation loss decreased (0.241673 --> 0.241258).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1259847
	speed: 0.0128s/iter; left time: 151.2196s
Epoch: 8 cost time: 1.5985333919525146
Epoch: 8, Steps: 128 Train Loss: 3.0917 (Forecasting Loss:0.2245 + XiCon Loss:2.8672 x Lambda(1.0)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.2077
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0652862
	speed: 0.0130s/iter; left time: 152.2554s
Epoch: 9 cost time: 1.6359128952026367
Epoch: 9, Steps: 128 Train Loss: 3.0790 (Forecasting Loss:0.2245 + XiCon Loss:2.8545 x Lambda(1.0)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.2078
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0405889
	speed: 0.0129s/iter; left time: 149.0039s
Epoch: 10 cost time: 1.6214182376861572
Epoch: 10, Steps: 128 Train Loss: 3.0834 (Forecasting Loss:0.2241 + XiCon Loss:2.8593 x Lambda(1.0)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.2075
Validation loss decreased (0.241258 --> 0.240932).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1102710
	speed: 0.0130s/iter; left time: 148.7134s
Epoch: 11 cost time: 1.6278743743896484
Epoch: 11, Steps: 128 Train Loss: 3.0832 (Forecasting Loss:0.2242 + XiCon Loss:2.8590 x Lambda(1.0)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.2075
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0288327
	speed: 0.0139s/iter; left time: 156.7608s
Epoch: 12 cost time: 1.7312085628509521
Epoch: 12, Steps: 128 Train Loss: 3.0770 (Forecasting Loss:0.2239 + XiCon Loss:2.8531 x Lambda(1.0)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.2075
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1893556
	speed: 0.0129s/iter; left time: 144.4360s
Epoch: 13 cost time: 1.6112897396087646
Epoch: 13, Steps: 128 Train Loss: 3.0853 (Forecasting Loss:0.2233 + XiCon Loss:2.8619 x Lambda(1.0)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.2075
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1147678
	speed: 0.0132s/iter; left time: 145.4856s
Epoch: 14 cost time: 1.6380512714385986
Epoch: 14, Steps: 128 Train Loss: 3.0813 (Forecasting Loss:0.2236 + XiCon Loss:2.8577 x Lambda(1.0)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.2075
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1017075
	speed: 0.0134s/iter; left time: 145.9246s
Epoch: 15 cost time: 1.6675951480865479
Epoch: 15, Steps: 128 Train Loss: 3.0841 (Forecasting Loss:0.2235 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.2411 Test MSE Loss: 0.2075
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0216687
	speed: 0.0132s/iter; left time: 142.5944s
Epoch: 16 cost time: 1.6632304191589355
Epoch: 16, Steps: 128 Train Loss: 3.0808 (Forecasting Loss:0.2237 + XiCon Loss:2.8571 x Lambda(1.0)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.2075
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0769374
	speed: 0.0127s/iter; left time: 134.9741s
Epoch: 17 cost time: 1.5864038467407227
Epoch: 17, Steps: 128 Train Loss: 3.0815 (Forecasting Loss:0.2239 + XiCon Loss:2.8577 x Lambda(1.0)), Vali MSE Loss: 0.2418 Test MSE Loss: 0.2075
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.0552180
	speed: 0.0133s/iter; left time: 139.6434s
Epoch: 18 cost time: 1.6555347442626953
Epoch: 18, Steps: 128 Train Loss: 3.0810 (Forecasting Loss:0.2236 + XiCon Loss:2.8574 x Lambda(1.0)), Vali MSE Loss: 0.2418 Test MSE Loss: 0.2075
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0760159
	speed: 0.0128s/iter; left time: 133.1839s
Epoch: 19 cost time: 1.6069364547729492
Epoch: 19, Steps: 128 Train Loss: 3.0845 (Forecasting Loss:0.2235 + XiCon Loss:2.8610 x Lambda(1.0)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.2075
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0621619
	speed: 0.0127s/iter; left time: 130.8604s
Epoch: 20 cost time: 1.6017158031463623
Epoch: 20, Steps: 128 Train Loss: 3.0809 (Forecasting Loss:0.2234 + XiCon Loss:2.8575 x Lambda(1.0)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.2075
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13194629549980164, mae:0.28306758403778076, mape:0.6790180802345276, mspe:19.155553817749023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1767
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.4010112
	speed: 0.0137s/iter; left time: 174.3362s
Epoch: 1 cost time: 1.730567455291748
Epoch: 1, Steps: 128 Train Loss: 3.4276 (Forecasting Loss:0.2902 + XiCon Loss:3.1375 x Lambda(1.0)), Vali MSE Loss: 0.2712 Test MSE Loss: 0.2278
Validation loss decreased (inf --> 0.271225).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2291386
	speed: 0.0130s/iter; left time: 163.7673s
Epoch: 2 cost time: 1.625244379043579
Epoch: 2, Steps: 128 Train Loss: 3.2490 (Forecasting Loss:0.2521 + XiCon Loss:2.9970 x Lambda(1.0)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.2219
Validation loss decreased (0.271225 --> 0.270358).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2775416
	speed: 0.0130s/iter; left time: 162.1271s
Epoch: 3 cost time: 1.6259875297546387
Epoch: 3, Steps: 128 Train Loss: 3.3268 (Forecasting Loss:0.2435 + XiCon Loss:3.0833 x Lambda(1.0)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.2108
Validation loss decreased (0.270358 --> 0.254121).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2861745
	speed: 0.0128s/iter; left time: 157.0652s
Epoch: 4 cost time: 1.5976343154907227
Epoch: 4, Steps: 128 Train Loss: 3.2631 (Forecasting Loss:0.2349 + XiCon Loss:3.0282 x Lambda(1.0)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.2051
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2331474
	speed: 0.0126s/iter; left time: 153.5078s
Epoch: 5 cost time: 1.5740175247192383
Epoch: 5, Steps: 128 Train Loss: 3.2360 (Forecasting Loss:0.2313 + XiCon Loss:3.0047 x Lambda(1.0)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.2011
Validation loss decreased (0.254121 --> 0.251396).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2243207
	speed: 0.0126s/iter; left time: 152.3648s
Epoch: 6 cost time: 1.5903620719909668
Epoch: 6, Steps: 128 Train Loss: 3.2322 (Forecasting Loss:0.2295 + XiCon Loss:3.0027 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2037
Validation loss decreased (0.251396 --> 0.249257).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2686794
	speed: 0.0128s/iter; left time: 152.1825s
Epoch: 7 cost time: 1.6031019687652588
Epoch: 7, Steps: 128 Train Loss: 3.2253 (Forecasting Loss:0.2282 + XiCon Loss:2.9972 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2029
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1383295
	speed: 0.0127s/iter; left time: 150.3130s
Epoch: 8 cost time: 1.5908877849578857
Epoch: 8, Steps: 128 Train Loss: 3.2196 (Forecasting Loss:0.2275 + XiCon Loss:2.9921 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2020
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2893047
	speed: 0.0127s/iter; left time: 148.6136s
Epoch: 9 cost time: 1.5895600318908691
Epoch: 9, Steps: 128 Train Loss: 3.2178 (Forecasting Loss:0.2270 + XiCon Loss:2.9909 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2027
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1692922
	speed: 0.0128s/iter; left time: 148.2273s
Epoch: 10 cost time: 1.6048946380615234
Epoch: 10, Steps: 128 Train Loss: 3.2106 (Forecasting Loss:0.2266 + XiCon Loss:2.9840 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2032
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1908302
	speed: 0.0126s/iter; left time: 143.6857s
Epoch: 11 cost time: 1.5769264698028564
Epoch: 11, Steps: 128 Train Loss: 3.2139 (Forecasting Loss:0.2265 + XiCon Loss:2.9874 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2030
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2259743
	speed: 0.0127s/iter; left time: 143.8721s
Epoch: 12 cost time: 1.5900490283966064
Epoch: 12, Steps: 128 Train Loss: 3.2135 (Forecasting Loss:0.2268 + XiCon Loss:2.9867 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2030
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2611616
	speed: 0.0128s/iter; left time: 142.4659s
Epoch: 13 cost time: 1.5928776264190674
Epoch: 13, Steps: 128 Train Loss: 3.2114 (Forecasting Loss:0.2270 + XiCon Loss:2.9844 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2030
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2603815
	speed: 0.0130s/iter; left time: 143.6957s
Epoch: 14 cost time: 1.6254823207855225
Epoch: 14, Steps: 128 Train Loss: 3.2056 (Forecasting Loss:0.2265 + XiCon Loss:2.9790 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2030
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2465277
	speed: 0.0135s/iter; left time: 147.6608s
Epoch: 15 cost time: 1.6779110431671143
Epoch: 15, Steps: 128 Train Loss: 3.2166 (Forecasting Loss:0.2268 + XiCon Loss:2.9899 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2030
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2317185
	speed: 0.0128s/iter; left time: 137.9754s
Epoch: 16 cost time: 1.6235768795013428
Epoch: 16, Steps: 128 Train Loss: 3.2181 (Forecasting Loss:0.2265 + XiCon Loss:2.9916 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2030
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1299670785665512, mae:0.27751168608665466, mape:0.6669161915779114, mspe:19.573516845703125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2622
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.4040263
	speed: 0.0126s/iter; left time: 160.3794s
Epoch: 1 cost time: 1.5800530910491943
Epoch: 1, Steps: 128 Train Loss: 3.4387 (Forecasting Loss:0.2938 + XiCon Loss:3.1449 x Lambda(1.0)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.2249
Validation loss decreased (inf --> 0.270760).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2673972
	speed: 0.0128s/iter; left time: 160.8229s
Epoch: 2 cost time: 1.6042125225067139
Epoch: 2, Steps: 128 Train Loss: 3.2725 (Forecasting Loss:0.2589 + XiCon Loss:3.0135 x Lambda(1.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2170
Validation loss decreased (0.270760 --> 0.258201).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2570214
	speed: 0.0127s/iter; left time: 157.5774s
Epoch: 3 cost time: 1.5870065689086914
Epoch: 3, Steps: 128 Train Loss: 3.2643 (Forecasting Loss:0.2416 + XiCon Loss:3.0227 x Lambda(1.0)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.2145
Validation loss decreased (0.258201 --> 0.254894).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2543728
	speed: 0.0128s/iter; left time: 157.1038s
Epoch: 4 cost time: 1.594179391860962
Epoch: 4, Steps: 128 Train Loss: 3.2610 (Forecasting Loss:0.2369 + XiCon Loss:3.0241 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2111
Validation loss decreased (0.254894 --> 0.249018).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2890077
	speed: 0.0131s/iter; left time: 159.9433s
Epoch: 5 cost time: 1.641303539276123
Epoch: 5, Steps: 128 Train Loss: 3.2782 (Forecasting Loss:0.2341 + XiCon Loss:3.0440 x Lambda(1.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.2096
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2881565
	speed: 0.0139s/iter; left time: 167.3619s
Epoch: 6 cost time: 1.7456550598144531
Epoch: 6, Steps: 128 Train Loss: 3.2771 (Forecasting Loss:0.2329 + XiCon Loss:3.0442 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2078
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2324076
	speed: 0.0130s/iter; left time: 154.9031s
Epoch: 7 cost time: 1.6153628826141357
Epoch: 7, Steps: 128 Train Loss: 3.2849 (Forecasting Loss:0.2316 + XiCon Loss:3.0533 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1837649
	speed: 0.0127s/iter; left time: 149.7002s
Epoch: 8 cost time: 1.596468448638916
Epoch: 8, Steps: 128 Train Loss: 3.2952 (Forecasting Loss:0.2312 + XiCon Loss:3.0640 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2074
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3056660
	speed: 0.0132s/iter; left time: 153.7578s
Epoch: 9 cost time: 1.6670787334442139
Epoch: 9, Steps: 128 Train Loss: 3.2908 (Forecasting Loss:0.2310 + XiCon Loss:3.0598 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2069
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2019043
	speed: 0.0127s/iter; left time: 147.2157s
Epoch: 10 cost time: 1.5880672931671143
Epoch: 10, Steps: 128 Train Loss: 3.2848 (Forecasting Loss:0.2309 + XiCon Loss:3.0539 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2070
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1947956
	speed: 0.0127s/iter; left time: 144.5229s
Epoch: 11 cost time: 1.5870330333709717
Epoch: 11, Steps: 128 Train Loss: 3.2837 (Forecasting Loss:0.2308 + XiCon Loss:3.0530 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2071
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2765532
	speed: 0.0137s/iter; left time: 154.8426s
Epoch: 12 cost time: 1.7182352542877197
Epoch: 12, Steps: 128 Train Loss: 3.2881 (Forecasting Loss:0.2306 + XiCon Loss:3.0574 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2071
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4321659
	speed: 0.0130s/iter; left time: 145.3827s
Epoch: 13 cost time: 1.618985652923584
Epoch: 13, Steps: 128 Train Loss: 3.2890 (Forecasting Loss:0.2307 + XiCon Loss:3.0583 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2071
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1872973
	speed: 0.0128s/iter; left time: 141.8204s
Epoch: 14 cost time: 1.6055634021759033
Epoch: 14, Steps: 128 Train Loss: 3.2877 (Forecasting Loss:0.2309 + XiCon Loss:3.0569 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2071
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.137188121676445, mae:0.28496307134628296, mape:0.6809492707252502, mspe:20.77337646484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3093
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3843317
	speed: 0.0143s/iter; left time: 181.4915s
Epoch: 1 cost time: 1.7668766975402832
Epoch: 1, Steps: 128 Train Loss: 3.4452 (Forecasting Loss:0.2955 + XiCon Loss:3.1497 x Lambda(1.0)), Vali MSE Loss: 0.2774 Test MSE Loss: 0.2303
Validation loss decreased (inf --> 0.277393).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1014853
	speed: 0.0128s/iter; left time: 161.2002s
Epoch: 2 cost time: 1.602954387664795
Epoch: 2, Steps: 128 Train Loss: 3.2178 (Forecasting Loss:0.2565 + XiCon Loss:2.9612 x Lambda(1.0)), Vali MSE Loss: 0.2712 Test MSE Loss: 0.2147
Validation loss decreased (0.277393 --> 0.271210).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1504447
	speed: 0.0128s/iter; left time: 159.6554s
Epoch: 3 cost time: 1.6087684631347656
Epoch: 3, Steps: 128 Train Loss: 3.2111 (Forecasting Loss:0.2435 + XiCon Loss:2.9676 x Lambda(1.0)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.2116
Validation loss decreased (0.271210 --> 0.259445).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2607312
	speed: 0.0137s/iter; left time: 168.3441s
Epoch: 4 cost time: 1.6853101253509521
Epoch: 4, Steps: 128 Train Loss: 3.2892 (Forecasting Loss:0.2370 + XiCon Loss:3.0522 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2116
Validation loss decreased (0.259445 --> 0.251018).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2406607
	speed: 0.0134s/iter; left time: 163.5798s
Epoch: 5 cost time: 1.6596522331237793
Epoch: 5, Steps: 128 Train Loss: 3.2919 (Forecasting Loss:0.2343 + XiCon Loss:3.0575 x Lambda(1.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2062
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3653479
	speed: 0.0128s/iter; left time: 154.6006s
Epoch: 6 cost time: 1.6056921482086182
Epoch: 6, Steps: 128 Train Loss: 3.2891 (Forecasting Loss:0.2325 + XiCon Loss:3.0566 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.2089
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3752713
	speed: 0.0136s/iter; left time: 162.7578s
Epoch: 7 cost time: 1.7139723300933838
Epoch: 7, Steps: 128 Train Loss: 3.2843 (Forecasting Loss:0.2318 + XiCon Loss:3.0525 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2067
Validation loss decreased (0.251018 --> 0.249950).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3943515
	speed: 0.0129s/iter; left time: 151.8856s
Epoch: 8 cost time: 1.637526273727417
Epoch: 8, Steps: 128 Train Loss: 3.3014 (Forecasting Loss:0.2315 + XiCon Loss:3.0700 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2061
Validation loss decreased (0.249950 --> 0.249865).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1422534
	speed: 0.0130s/iter; left time: 152.0490s
Epoch: 9 cost time: 1.6417315006256104
Epoch: 9, Steps: 128 Train Loss: 3.3046 (Forecasting Loss:0.2310 + XiCon Loss:3.0736 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4323485
	speed: 0.0127s/iter; left time: 146.2654s
Epoch: 10 cost time: 1.5843334197998047
Epoch: 10, Steps: 128 Train Loss: 3.2962 (Forecasting Loss:0.2310 + XiCon Loss:3.0652 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1956232
	speed: 0.0127s/iter; left time: 144.8756s
Epoch: 11 cost time: 1.5874273777008057
Epoch: 11, Steps: 128 Train Loss: 3.2950 (Forecasting Loss:0.2306 + XiCon Loss:3.0644 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2059
Validation loss decreased (0.249865 --> 0.249576).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3160648
	speed: 0.0128s/iter; left time: 144.3187s
Epoch: 12 cost time: 1.5957250595092773
Epoch: 12, Steps: 128 Train Loss: 3.3019 (Forecasting Loss:0.2307 + XiCon Loss:3.0712 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2059
Validation loss decreased (0.249576 --> 0.249079).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3891814
	speed: 0.0127s/iter; left time: 141.8084s
Epoch: 13 cost time: 1.6006417274475098
Epoch: 13, Steps: 128 Train Loss: 3.2955 (Forecasting Loss:0.2307 + XiCon Loss:3.0648 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3035097
	speed: 0.0137s/iter; left time: 151.5638s
Epoch: 14 cost time: 1.719900131225586
Epoch: 14, Steps: 128 Train Loss: 3.2945 (Forecasting Loss:0.2307 + XiCon Loss:3.0638 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3375463
	speed: 0.0132s/iter; left time: 143.6851s
Epoch: 15 cost time: 1.639758825302124
Epoch: 15, Steps: 128 Train Loss: 3.2836 (Forecasting Loss:0.2307 + XiCon Loss:3.0530 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4396222
	speed: 0.0126s/iter; left time: 136.3458s
Epoch: 16 cost time: 1.6035983562469482
Epoch: 16, Steps: 128 Train Loss: 3.2912 (Forecasting Loss:0.2307 + XiCon Loss:3.0605 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2059
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2604074
	speed: 0.0128s/iter; left time: 136.4920s
Epoch: 17 cost time: 1.602820873260498
Epoch: 17, Steps: 128 Train Loss: 3.2923 (Forecasting Loss:0.2309 + XiCon Loss:3.0615 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2059
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2276282
	speed: 0.0127s/iter; left time: 133.8244s
Epoch: 18 cost time: 1.5892724990844727
Epoch: 18, Steps: 128 Train Loss: 3.2920 (Forecasting Loss:0.2308 + XiCon Loss:3.0612 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2059
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3679438
	speed: 0.0137s/iter; left time: 142.3025s
Epoch: 19 cost time: 1.6941428184509277
Epoch: 19, Steps: 128 Train Loss: 3.2973 (Forecasting Loss:0.2307 + XiCon Loss:3.0666 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2059
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4511960
	speed: 0.0128s/iter; left time: 131.1142s
Epoch: 20 cost time: 1.5988619327545166
Epoch: 20, Steps: 128 Train Loss: 3.3046 (Forecasting Loss:0.2307 + XiCon Loss:3.0739 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2059
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3922713
	speed: 0.0128s/iter; left time: 129.4582s
Epoch: 21 cost time: 1.592663288116455
Epoch: 21, Steps: 128 Train Loss: 3.2887 (Forecasting Loss:0.2307 + XiCon Loss:3.0580 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2117686
	speed: 0.0134s/iter; left time: 133.8816s
Epoch: 22 cost time: 1.6566107273101807
Epoch: 22, Steps: 128 Train Loss: 3.2917 (Forecasting Loss:0.2308 + XiCon Loss:3.0609 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2059
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13160070776939392, mae:0.28018197417259216, mape:0.6604570746421814, mspe:19.437360763549805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1325+-0.00341, MAE:0.2812+-0.00357, MAPE:0.6713+-0.01066, MSPE:19.7580+-0.77026, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3440
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.4514422
	speed: 0.0167s/iter; left time: 208.6330s
Epoch: 1 cost time: 1.9932608604431152
Epoch: 1, Steps: 126 Train Loss: 3.4762 (Forecasting Loss:0.3209 + XiCon Loss:3.1553 x Lambda(1.0)), Vali MSE Loss: 0.3107 Test MSE Loss: 0.2701
Validation loss decreased (inf --> 0.310721).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2356887
	speed: 0.0160s/iter; left time: 198.1254s
Epoch: 2 cost time: 1.9937944412231445
Epoch: 2, Steps: 126 Train Loss: 3.2621 (Forecasting Loss:0.2929 + XiCon Loss:2.9692 x Lambda(1.0)), Vali MSE Loss: 0.3015 Test MSE Loss: 0.2530
Validation loss decreased (0.310721 --> 0.301472).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3135347
	speed: 0.0156s/iter; left time: 190.5826s
Epoch: 3 cost time: 1.9314169883728027
Epoch: 3, Steps: 126 Train Loss: 3.2140 (Forecasting Loss:0.2796 + XiCon Loss:2.9344 x Lambda(1.0)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.2595
Validation loss decreased (0.301472 --> 0.293609).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2807131
	speed: 0.0161s/iter; left time: 194.6928s
Epoch: 4 cost time: 1.9932751655578613
Epoch: 4, Steps: 126 Train Loss: 3.3482 (Forecasting Loss:0.2715 + XiCon Loss:3.0768 x Lambda(1.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2472
Validation loss decreased (0.293609 --> 0.291878).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.6323812
	speed: 0.0159s/iter; left time: 190.9702s
Epoch: 5 cost time: 1.9747095108032227
Epoch: 5, Steps: 126 Train Loss: 3.4084 (Forecasting Loss:0.2689 + XiCon Loss:3.1395 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2448
Validation loss decreased (0.291878 --> 0.288803).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.5338237
	speed: 0.0159s/iter; left time: 188.3424s
Epoch: 6 cost time: 1.9679417610168457
Epoch: 6, Steps: 126 Train Loss: 3.4473 (Forecasting Loss:0.2672 + XiCon Loss:3.1800 x Lambda(1.0)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4828293
	speed: 0.0162s/iter; left time: 189.9528s
Epoch: 7 cost time: 1.992818832397461
Epoch: 7, Steps: 126 Train Loss: 3.4403 (Forecasting Loss:0.2662 + XiCon Loss:3.1741 x Lambda(1.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2457
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5378296
	speed: 0.0157s/iter; left time: 182.3558s
Epoch: 8 cost time: 1.9511926174163818
Epoch: 8, Steps: 126 Train Loss: 3.4593 (Forecasting Loss:0.2657 + XiCon Loss:3.1936 x Lambda(1.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2449
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.6039507
	speed: 0.0156s/iter; left time: 179.2272s
Epoch: 9 cost time: 1.9345669746398926
Epoch: 9, Steps: 126 Train Loss: 3.4519 (Forecasting Loss:0.2655 + XiCon Loss:3.1864 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2453
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3897419
	speed: 0.0165s/iter; left time: 187.3988s
Epoch: 10 cost time: 2.0226452350616455
Epoch: 10, Steps: 126 Train Loss: 3.4448 (Forecasting Loss:0.2651 + XiCon Loss:3.1797 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2452
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.6905234
	speed: 0.0157s/iter; left time: 176.5627s
Epoch: 11 cost time: 1.945403814315796
Epoch: 11, Steps: 126 Train Loss: 3.4429 (Forecasting Loss:0.2653 + XiCon Loss:3.1776 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2450
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4033756
	speed: 0.0159s/iter; left time: 177.0186s
Epoch: 12 cost time: 1.9751660823822021
Epoch: 12, Steps: 126 Train Loss: 3.4699 (Forecasting Loss:0.2649 + XiCon Loss:3.2050 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2450
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5324216
	speed: 0.0158s/iter; left time: 173.4444s
Epoch: 13 cost time: 1.9494423866271973
Epoch: 13, Steps: 126 Train Loss: 3.4557 (Forecasting Loss:0.2653 + XiCon Loss:3.1904 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2450
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2822413
	speed: 0.0159s/iter; left time: 173.1448s
Epoch: 14 cost time: 1.966845989227295
Epoch: 14, Steps: 126 Train Loss: 3.4531 (Forecasting Loss:0.2650 + XiCon Loss:3.1882 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2450
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.5820527
	speed: 0.0156s/iter; left time: 167.3022s
Epoch: 15 cost time: 1.932628870010376
Epoch: 15, Steps: 126 Train Loss: 3.4378 (Forecasting Loss:0.2650 + XiCon Loss:3.1727 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2450
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16715611517429352, mae:0.32235080003738403, mape:0.6849381327629089, mspe:20.23769760131836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2106
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.4456487
	speed: 0.0148s/iter; left time: 184.8850s
Epoch: 1 cost time: 1.806518793106079
Epoch: 1, Steps: 126 Train Loss: 3.4672 (Forecasting Loss:0.3178 + XiCon Loss:3.1494 x Lambda(1.0)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2664
Validation loss decreased (inf --> 0.307977).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2676890
	speed: 0.0160s/iter; left time: 197.9985s
Epoch: 2 cost time: 1.9612033367156982
Epoch: 2, Steps: 126 Train Loss: 3.2810 (Forecasting Loss:0.2912 + XiCon Loss:2.9897 x Lambda(1.0)), Vali MSE Loss: 0.2983 Test MSE Loss: 0.2613
Validation loss decreased (0.307977 --> 0.298276).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2019525
	speed: 0.0152s/iter; left time: 186.2691s
Epoch: 3 cost time: 1.882521629333496
Epoch: 3, Steps: 126 Train Loss: 3.2324 (Forecasting Loss:0.2787 + XiCon Loss:2.9537 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2598
Validation loss decreased (0.298276 --> 0.288282).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3885496
	speed: 0.0158s/iter; left time: 191.5171s
Epoch: 4 cost time: 1.9584364891052246
Epoch: 4, Steps: 126 Train Loss: 3.3079 (Forecasting Loss:0.2722 + XiCon Loss:3.0357 x Lambda(1.0)), Vali MSE Loss: 0.2935 Test MSE Loss: 0.2424
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4226134
	speed: 0.0159s/iter; left time: 190.8178s
Epoch: 5 cost time: 1.9755454063415527
Epoch: 5, Steps: 126 Train Loss: 3.3171 (Forecasting Loss:0.2691 + XiCon Loss:3.0480 x Lambda(1.0)), Vali MSE Loss: 0.2939 Test MSE Loss: 0.2440
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3486028
	speed: 0.0160s/iter; left time: 190.0071s
Epoch: 6 cost time: 1.9859585762023926
Epoch: 6, Steps: 126 Train Loss: 3.2978 (Forecasting Loss:0.2682 + XiCon Loss:3.0295 x Lambda(1.0)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.2428
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3607578
	speed: 0.0160s/iter; left time: 188.0693s
Epoch: 7 cost time: 1.9877040386199951
Epoch: 7, Steps: 126 Train Loss: 3.2749 (Forecasting Loss:0.2672 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.2417
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2690878
	speed: 0.0158s/iter; left time: 183.7513s
Epoch: 8 cost time: 1.97251558303833
Epoch: 8, Steps: 126 Train Loss: 3.2686 (Forecasting Loss:0.2673 + XiCon Loss:3.0012 x Lambda(1.0)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.2423
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2409406
	speed: 0.0162s/iter; left time: 185.8038s
Epoch: 9 cost time: 2.001697540283203
Epoch: 9, Steps: 126 Train Loss: 3.2705 (Forecasting Loss:0.2668 + XiCon Loss:3.0037 x Lambda(1.0)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.2424
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2774053
	speed: 0.0166s/iter; left time: 189.2563s
Epoch: 10 cost time: 2.0568857192993164
Epoch: 10, Steps: 126 Train Loss: 3.2682 (Forecasting Loss:0.2665 + XiCon Loss:3.0017 x Lambda(1.0)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.2425
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2800398
	speed: 0.0160s/iter; left time: 179.4837s
Epoch: 11 cost time: 1.9873180389404297
Epoch: 11, Steps: 126 Train Loss: 3.2669 (Forecasting Loss:0.2670 + XiCon Loss:2.9999 x Lambda(1.0)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.2424
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3236108
	speed: 0.0158s/iter; left time: 175.7983s
Epoch: 12 cost time: 1.981548547744751
Epoch: 12, Steps: 126 Train Loss: 3.2700 (Forecasting Loss:0.2667 + XiCon Loss:3.0033 x Lambda(1.0)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.2424
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2628031
	speed: 0.0161s/iter; left time: 176.4765s
Epoch: 13 cost time: 1.996659278869629
Epoch: 13, Steps: 126 Train Loss: 3.2659 (Forecasting Loss:0.2665 + XiCon Loss:2.9994 x Lambda(1.0)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.2424
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1839485764503479, mae:0.3356969952583313, mape:0.7128876447677612, mspe:22.5164737701416 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2164
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3585556
	speed: 0.0148s/iter; left time: 184.4390s
Epoch: 1 cost time: 1.8350181579589844
Epoch: 1, Steps: 126 Train Loss: 3.4569 (Forecasting Loss:0.3163 + XiCon Loss:3.1406 x Lambda(1.0)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.2651
Validation loss decreased (inf --> 0.307272).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3086333
	speed: 0.0154s/iter; left time: 190.4815s
Epoch: 2 cost time: 1.9258105754852295
Epoch: 2, Steps: 126 Train Loss: 3.3199 (Forecasting Loss:0.2912 + XiCon Loss:3.0287 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2746
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5512671
	speed: 0.0162s/iter; left time: 198.9409s
Epoch: 3 cost time: 2.0112075805664062
Epoch: 3, Steps: 126 Train Loss: 3.4792 (Forecasting Loss:0.2797 + XiCon Loss:3.1995 x Lambda(1.0)), Vali MSE Loss: 0.2981 Test MSE Loss: 0.2592
Validation loss decreased (0.307272 --> 0.298101).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4610171
	speed: 0.0160s/iter; left time: 194.2481s
Epoch: 4 cost time: 1.9870750904083252
Epoch: 4, Steps: 126 Train Loss: 3.3944 (Forecasting Loss:0.2734 + XiCon Loss:3.1210 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.2529
Validation loss decreased (0.298101 --> 0.290629).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2732143
	speed: 0.0159s/iter; left time: 191.3010s
Epoch: 5 cost time: 1.985506534576416
Epoch: 5, Steps: 126 Train Loss: 3.3516 (Forecasting Loss:0.2701 + XiCon Loss:3.0815 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2478
Validation loss decreased (0.290629 --> 0.289803).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2827194
	speed: 0.0167s/iter; left time: 198.5238s
Epoch: 6 cost time: 2.059586763381958
Epoch: 6, Steps: 126 Train Loss: 3.3415 (Forecasting Loss:0.2687 + XiCon Loss:3.0727 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2478
Validation loss decreased (0.289803 --> 0.289772).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3007138
	speed: 0.0157s/iter; left time: 184.9566s
Epoch: 7 cost time: 1.9604451656341553
Epoch: 7, Steps: 126 Train Loss: 3.3385 (Forecasting Loss:0.2676 + XiCon Loss:3.0709 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2474
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2236111
	speed: 0.0162s/iter; left time: 188.1070s
Epoch: 8 cost time: 2.0524449348449707
Epoch: 8, Steps: 126 Train Loss: 3.3245 (Forecasting Loss:0.2670 + XiCon Loss:3.0575 x Lambda(1.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.2475
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2631521
	speed: 0.0159s/iter; left time: 183.1879s
Epoch: 9 cost time: 1.9812517166137695
Epoch: 9, Steps: 126 Train Loss: 3.3197 (Forecasting Loss:0.2669 + XiCon Loss:3.0528 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2478
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2945642
	speed: 0.0158s/iter; left time: 179.3166s
Epoch: 10 cost time: 1.9641587734222412
Epoch: 10, Steps: 126 Train Loss: 3.3241 (Forecasting Loss:0.2664 + XiCon Loss:3.0577 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2478
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3577754
	speed: 0.0160s/iter; left time: 180.1799s
Epoch: 11 cost time: 1.9889249801635742
Epoch: 11, Steps: 126 Train Loss: 3.3361 (Forecasting Loss:0.2667 + XiCon Loss:3.0694 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2477
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3442345
	speed: 0.0158s/iter; left time: 175.6703s
Epoch: 12 cost time: 1.9585111141204834
Epoch: 12, Steps: 126 Train Loss: 3.3289 (Forecasting Loss:0.2668 + XiCon Loss:3.0622 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2477
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3143420
	speed: 0.0159s/iter; left time: 174.6485s
Epoch: 13 cost time: 1.9800055027008057
Epoch: 13, Steps: 126 Train Loss: 3.3287 (Forecasting Loss:0.2661 + XiCon Loss:3.0626 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2477
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3599019
	speed: 0.0161s/iter; left time: 174.6627s
Epoch: 14 cost time: 1.9995625019073486
Epoch: 14, Steps: 126 Train Loss: 3.3320 (Forecasting Loss:0.2663 + XiCon Loss:3.0657 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2477
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3804657
	speed: 0.0164s/iter; left time: 175.8738s
Epoch: 15 cost time: 2.023197889328003
Epoch: 15, Steps: 126 Train Loss: 3.3306 (Forecasting Loss:0.2665 + XiCon Loss:3.0641 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2477
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2723246
	speed: 0.0162s/iter; left time: 171.7065s
Epoch: 16 cost time: 2.011554002761841
Epoch: 16, Steps: 126 Train Loss: 3.3222 (Forecasting Loss:0.2665 + XiCon Loss:3.0557 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2477
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1702750325202942, mae:0.3252296447753906, mape:0.6810311675071716, mspe:20.012454986572266 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2587
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.4339013
	speed: 0.0143s/iter; left time: 178.9757s
Epoch: 1 cost time: 1.7684087753295898
Epoch: 1, Steps: 126 Train Loss: 3.4579 (Forecasting Loss:0.3191 + XiCon Loss:3.1388 x Lambda(1.0)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2673
Validation loss decreased (inf --> 0.307883).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3749526
	speed: 0.0155s/iter; left time: 192.0948s
Epoch: 2 cost time: 1.9243764877319336
Epoch: 2, Steps: 126 Train Loss: 3.3412 (Forecasting Loss:0.2932 + XiCon Loss:3.0480 x Lambda(1.0)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.2643
Validation loss decreased (0.307883 --> 0.298505).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2838089
	speed: 0.0155s/iter; left time: 189.9954s
Epoch: 3 cost time: 1.9242374897003174
Epoch: 3, Steps: 126 Train Loss: 3.3583 (Forecasting Loss:0.2773 + XiCon Loss:3.0810 x Lambda(1.0)), Vali MSE Loss: 0.3025 Test MSE Loss: 0.2569
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3478498
	speed: 0.0155s/iter; left time: 188.0605s
Epoch: 4 cost time: 1.930088996887207
Epoch: 4, Steps: 126 Train Loss: 3.3229 (Forecasting Loss:0.2700 + XiCon Loss:3.0529 x Lambda(1.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.2583
Validation loss decreased (0.298505 --> 0.291928).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3644462
	speed: 0.0154s/iter; left time: 184.4159s
Epoch: 5 cost time: 1.9127931594848633
Epoch: 5, Steps: 126 Train Loss: 3.3017 (Forecasting Loss:0.2692 + XiCon Loss:3.0325 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2518
Validation loss decreased (0.291928 --> 0.290169).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2263699
	speed: 0.0154s/iter; left time: 182.9166s
Epoch: 6 cost time: 1.9233324527740479
Epoch: 6, Steps: 126 Train Loss: 3.2939 (Forecasting Loss:0.2676 + XiCon Loss:3.0263 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2477
Validation loss decreased (0.290169 --> 0.289077).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2342291
	speed: 0.0157s/iter; left time: 184.3208s
Epoch: 7 cost time: 1.9421849250793457
Epoch: 7, Steps: 126 Train Loss: 3.2881 (Forecasting Loss:0.2660 + XiCon Loss:3.0220 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2473
Validation loss decreased (0.289077 --> 0.289012).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2764356
	speed: 0.0155s/iter; left time: 179.6545s
Epoch: 8 cost time: 1.9167098999023438
Epoch: 8, Steps: 126 Train Loss: 3.2792 (Forecasting Loss:0.2658 + XiCon Loss:3.0134 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2467
Validation loss decreased (0.289012 --> 0.288759).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2176900
	speed: 0.0159s/iter; left time: 182.5216s
Epoch: 9 cost time: 1.9589996337890625
Epoch: 9, Steps: 126 Train Loss: 3.2791 (Forecasting Loss:0.2650 + XiCon Loss:3.0141 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2467
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2857165
	speed: 0.0158s/iter; left time: 179.4083s
Epoch: 10 cost time: 1.9563758373260498
Epoch: 10, Steps: 126 Train Loss: 3.2787 (Forecasting Loss:0.2650 + XiCon Loss:3.0137 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2469
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2763443
	speed: 0.0158s/iter; left time: 177.0530s
Epoch: 11 cost time: 1.9761569499969482
Epoch: 11, Steps: 126 Train Loss: 3.2722 (Forecasting Loss:0.2647 + XiCon Loss:3.0074 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2471
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2221165
	speed: 0.0158s/iter; left time: 176.1329s
Epoch: 12 cost time: 1.959583044052124
Epoch: 12, Steps: 126 Train Loss: 3.2743 (Forecasting Loss:0.2650 + XiCon Loss:3.0093 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2471
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3095315
	speed: 0.0155s/iter; left time: 170.4425s
Epoch: 13 cost time: 1.9259240627288818
Epoch: 13, Steps: 126 Train Loss: 3.2824 (Forecasting Loss:0.2654 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2471
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1951747
	speed: 0.0156s/iter; left time: 169.1031s
Epoch: 14 cost time: 1.9297728538513184
Epoch: 14, Steps: 126 Train Loss: 3.2823 (Forecasting Loss:0.2653 + XiCon Loss:3.0170 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2471
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2614725
	speed: 0.0156s/iter; left time: 167.4406s
Epoch: 15 cost time: 1.9342396259307861
Epoch: 15, Steps: 126 Train Loss: 3.2736 (Forecasting Loss:0.2653 + XiCon Loss:3.0082 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2471
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1977632
	speed: 0.0157s/iter; left time: 166.5027s
Epoch: 16 cost time: 1.9411072731018066
Epoch: 16, Steps: 126 Train Loss: 3.2834 (Forecasting Loss:0.2649 + XiCon Loss:3.0185 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2471
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1937296
	speed: 0.0154s/iter; left time: 161.6416s
Epoch: 17 cost time: 1.912801742553711
Epoch: 17, Steps: 126 Train Loss: 3.2765 (Forecasting Loss:0.2650 + XiCon Loss:3.0115 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2471
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3040419
	speed: 0.0163s/iter; left time: 169.1025s
Epoch: 18 cost time: 2.0074381828308105
Epoch: 18, Steps: 126 Train Loss: 3.2742 (Forecasting Loss:0.2653 + XiCon Loss:3.0089 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2471
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16969700157642365, mae:0.3237490653991699, mape:0.6802071928977966, mspe:20.022523880004883 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2552
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.4276679
	speed: 0.0142s/iter; left time: 177.1874s
Epoch: 1 cost time: 1.7541463375091553
Epoch: 1, Steps: 126 Train Loss: 3.4687 (Forecasting Loss:0.3184 + XiCon Loss:3.1503 x Lambda(1.0)), Vali MSE Loss: 0.3110 Test MSE Loss: 0.2678
Validation loss decreased (inf --> 0.310990).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2416048
	speed: 0.0151s/iter; left time: 186.8750s
Epoch: 2 cost time: 1.8798296451568604
Epoch: 2, Steps: 126 Train Loss: 3.2736 (Forecasting Loss:0.2920 + XiCon Loss:2.9817 x Lambda(1.0)), Vali MSE Loss: 0.3013 Test MSE Loss: 0.2648
Validation loss decreased (0.310990 --> 0.301338).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3623474
	speed: 0.0155s/iter; left time: 189.3516s
Epoch: 3 cost time: 1.9236950874328613
Epoch: 3, Steps: 126 Train Loss: 3.3132 (Forecasting Loss:0.2780 + XiCon Loss:3.0353 x Lambda(1.0)), Vali MSE Loss: 0.2956 Test MSE Loss: 0.2590
Validation loss decreased (0.301338 --> 0.295640).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.6731691
	speed: 0.0154s/iter; left time: 187.0242s
Epoch: 4 cost time: 1.9150128364562988
Epoch: 4, Steps: 126 Train Loss: 3.3839 (Forecasting Loss:0.2737 + XiCon Loss:3.1103 x Lambda(1.0)), Vali MSE Loss: 0.2957 Test MSE Loss: 0.2524
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3024461
	speed: 0.0155s/iter; left time: 185.6524s
Epoch: 5 cost time: 1.9227561950683594
Epoch: 5, Steps: 126 Train Loss: 3.4066 (Forecasting Loss:0.2697 + XiCon Loss:3.1369 x Lambda(1.0)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.2492
Validation loss decreased (0.295640 --> 0.294327).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4327214
	speed: 0.0158s/iter; left time: 187.0794s
Epoch: 6 cost time: 1.9472520351409912
Epoch: 6, Steps: 126 Train Loss: 3.4219 (Forecasting Loss:0.2670 + XiCon Loss:3.1549 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2473
Validation loss decreased (0.294327 --> 0.289776).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4225945
	speed: 0.0157s/iter; left time: 183.9346s
Epoch: 7 cost time: 1.9338958263397217
Epoch: 7, Steps: 126 Train Loss: 3.4132 (Forecasting Loss:0.2665 + XiCon Loss:3.1467 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2468
Validation loss decreased (0.289776 --> 0.289414).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4125144
	speed: 0.0156s/iter; left time: 181.6433s
Epoch: 8 cost time: 1.9330809116363525
Epoch: 8, Steps: 126 Train Loss: 3.4232 (Forecasting Loss:0.2661 + XiCon Loss:3.1571 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2466
Validation loss decreased (0.289414 --> 0.288308).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3921082
	speed: 0.0156s/iter; left time: 178.8199s
Epoch: 9 cost time: 1.929887056350708
Epoch: 9, Steps: 126 Train Loss: 3.4249 (Forecasting Loss:0.2656 + XiCon Loss:3.1593 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2464
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4668369
	speed: 0.0154s/iter; left time: 175.1783s
Epoch: 10 cost time: 1.9140870571136475
Epoch: 10, Steps: 126 Train Loss: 3.4275 (Forecasting Loss:0.2656 + XiCon Loss:3.1620 x Lambda(1.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.2464
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4014230
	speed: 0.0156s/iter; left time: 174.8750s
Epoch: 11 cost time: 1.927241563796997
Epoch: 11, Steps: 126 Train Loss: 3.4305 (Forecasting Loss:0.2652 + XiCon Loss:3.1653 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2463
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5881453
	speed: 0.0158s/iter; left time: 175.3977s
Epoch: 12 cost time: 1.9558277130126953
Epoch: 12, Steps: 126 Train Loss: 3.4274 (Forecasting Loss:0.2652 + XiCon Loss:3.1622 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2464
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4515960
	speed: 0.0155s/iter; left time: 169.9730s
Epoch: 13 cost time: 1.9181692600250244
Epoch: 13, Steps: 126 Train Loss: 3.4262 (Forecasting Loss:0.2653 + XiCon Loss:3.1609 x Lambda(1.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.2464
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3733008
	speed: 0.0153s/iter; left time: 166.0645s
Epoch: 14 cost time: 1.9001939296722412
Epoch: 14, Steps: 126 Train Loss: 3.4295 (Forecasting Loss:0.2656 + XiCon Loss:3.1639 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2464
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3927672
	speed: 0.0155s/iter; left time: 166.1768s
Epoch: 15 cost time: 1.9209659099578857
Epoch: 15, Steps: 126 Train Loss: 3.4192 (Forecasting Loss:0.2656 + XiCon Loss:3.1536 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2464
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2552114
	speed: 0.0155s/iter; left time: 164.4157s
Epoch: 16 cost time: 1.9315578937530518
Epoch: 16, Steps: 126 Train Loss: 3.4304 (Forecasting Loss:0.2655 + XiCon Loss:3.1649 x Lambda(1.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.2464
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3501561
	speed: 0.0156s/iter; left time: 163.9117s
Epoch: 17 cost time: 1.935436725616455
Epoch: 17, Steps: 126 Train Loss: 3.4280 (Forecasting Loss:0.2655 + XiCon Loss:3.1626 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2464
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4034014
	speed: 0.0153s/iter; left time: 158.6814s
Epoch: 18 cost time: 1.9060382843017578
Epoch: 18, Steps: 126 Train Loss: 3.4321 (Forecasting Loss:0.2655 + XiCon Loss:3.1666 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2464
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16913384199142456, mae:0.3240429162979126, mape:0.6755332946777344, mspe:19.757593154907227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1720+-0.00839, MAE:0.3262+-0.00670, MAPE:0.6869+-0.01850, MSPE:20.5093+-1.40908, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2562
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.4346998
	speed: 0.0187s/iter; left time: 229.7521s
Epoch: 1 cost time: 2.2084503173828125
Epoch: 1, Steps: 124 Train Loss: 3.4999 (Forecasting Loss:0.3418 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.3463 Test MSE Loss: 0.2925
Validation loss decreased (inf --> 0.346332).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2497573
	speed: 0.0184s/iter; left time: 223.5200s
Epoch: 2 cost time: 2.2611136436462402
Epoch: 2, Steps: 124 Train Loss: 3.2931 (Forecasting Loss:0.3137 + XiCon Loss:2.9793 x Lambda(1.0)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.2893
Validation loss decreased (0.346332 --> 0.338670).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3029189
	speed: 0.0189s/iter; left time: 227.3195s
Epoch: 3 cost time: 2.314741373062134
Epoch: 3, Steps: 124 Train Loss: 3.3111 (Forecasting Loss:0.3022 + XiCon Loss:3.0089 x Lambda(1.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.2709
Validation loss decreased (0.338670 --> 0.330834).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4577594
	speed: 0.0189s/iter; left time: 225.5057s
Epoch: 4 cost time: 2.320274829864502
Epoch: 4, Steps: 124 Train Loss: 3.4084 (Forecasting Loss:0.2948 + XiCon Loss:3.1136 x Lambda(1.0)), Vali MSE Loss: 0.3259 Test MSE Loss: 0.2742
Validation loss decreased (0.330834 --> 0.325934).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3477104
	speed: 0.0190s/iter; left time: 224.1356s
Epoch: 5 cost time: 2.353123188018799
Epoch: 5, Steps: 124 Train Loss: 3.4298 (Forecasting Loss:0.2899 + XiCon Loss:3.1400 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2704
Validation loss decreased (0.325934 --> 0.322649).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4015355
	speed: 0.0190s/iter; left time: 222.2323s
Epoch: 6 cost time: 2.3309378623962402
Epoch: 6, Steps: 124 Train Loss: 3.4132 (Forecasting Loss:0.2883 + XiCon Loss:3.1249 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2685
Validation loss decreased (0.322649 --> 0.322103).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3772409
	speed: 0.0190s/iter; left time: 219.9946s
Epoch: 7 cost time: 2.3417723178863525
Epoch: 7, Steps: 124 Train Loss: 3.4150 (Forecasting Loss:0.2872 + XiCon Loss:3.1278 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2688
Validation loss decreased (0.322103 --> 0.320131).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5126152
	speed: 0.0194s/iter; left time: 221.4033s
Epoch: 8 cost time: 2.370023727416992
Epoch: 8, Steps: 124 Train Loss: 3.4346 (Forecasting Loss:0.2866 + XiCon Loss:3.1480 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2688
Validation loss decreased (0.320131 --> 0.320090).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3586926
	speed: 0.0195s/iter; left time: 220.1481s
Epoch: 9 cost time: 2.3928236961364746
Epoch: 9, Steps: 124 Train Loss: 3.4180 (Forecasting Loss:0.2864 + XiCon Loss:3.1315 x Lambda(1.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.6183677
	speed: 0.0191s/iter; left time: 213.3607s
Epoch: 10 cost time: 2.342725992202759
Epoch: 10, Steps: 124 Train Loss: 3.4191 (Forecasting Loss:0.2861 + XiCon Loss:3.1330 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2679
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.7530632
	speed: 0.0193s/iter; left time: 213.1703s
Epoch: 11 cost time: 2.361071825027466
Epoch: 11, Steps: 124 Train Loss: 3.4069 (Forecasting Loss:0.2859 + XiCon Loss:3.1210 x Lambda(1.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2680
Validation loss decreased (0.320090 --> 0.319532).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2060771
	speed: 0.0193s/iter; left time: 211.1723s
Epoch: 12 cost time: 2.3678581714630127
Epoch: 12, Steps: 124 Train Loss: 3.4128 (Forecasting Loss:0.2863 + XiCon Loss:3.1265 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2679
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3743591
	speed: 0.0192s/iter; left time: 207.8570s
Epoch: 13 cost time: 2.3715672492980957
Epoch: 13, Steps: 124 Train Loss: 3.4193 (Forecasting Loss:0.2858 + XiCon Loss:3.1336 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2679
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4570928
	speed: 0.0193s/iter; left time: 206.0954s
Epoch: 14 cost time: 2.3662493228912354
Epoch: 14, Steps: 124 Train Loss: 3.4171 (Forecasting Loss:0.2859 + XiCon Loss:3.1312 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2679
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3671851
	speed: 0.0189s/iter; left time: 199.8301s
Epoch: 15 cost time: 2.3312864303588867
Epoch: 15, Steps: 124 Train Loss: 3.4142 (Forecasting Loss:0.2858 + XiCon Loss:3.1285 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2679
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3603621
	speed: 0.0189s/iter; left time: 197.7704s
Epoch: 16 cost time: 2.327575445175171
Epoch: 16, Steps: 124 Train Loss: 3.4272 (Forecasting Loss:0.2860 + XiCon Loss:3.1412 x Lambda(1.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2679
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3421485
	speed: 0.0195s/iter; left time: 201.1545s
Epoch: 17 cost time: 2.38446044921875
Epoch: 17, Steps: 124 Train Loss: 3.4093 (Forecasting Loss:0.2859 + XiCon Loss:3.1234 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2679
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3648601
	speed: 0.0192s/iter; left time: 196.1571s
Epoch: 18 cost time: 2.351369619369507
Epoch: 18, Steps: 124 Train Loss: 3.4162 (Forecasting Loss:0.2860 + XiCon Loss:3.1301 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2679
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4713387
	speed: 0.0193s/iter; left time: 194.8179s
Epoch: 19 cost time: 2.36550235748291
Epoch: 19, Steps: 124 Train Loss: 3.4116 (Forecasting Loss:0.2857 + XiCon Loss:3.1259 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2679
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4556324
	speed: 0.0191s/iter; left time: 189.8971s
Epoch: 20 cost time: 2.3360819816589355
Epoch: 20, Steps: 124 Train Loss: 3.4272 (Forecasting Loss:0.2858 + XiCon Loss:3.1413 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2679
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4273510
	speed: 0.0191s/iter; left time: 187.4198s
Epoch: 21 cost time: 2.344609498977661
Epoch: 21, Steps: 124 Train Loss: 3.4259 (Forecasting Loss:0.2861 + XiCon Loss:3.1399 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2679
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1876864731311798, mae:0.3482478857040405, mape:0.6766196489334106, mspe:18.248401641845703 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2069
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.4252002
	speed: 0.0159s/iter; left time: 195.7701s
Epoch: 1 cost time: 1.9421982765197754
Epoch: 1, Steps: 124 Train Loss: 3.4873 (Forecasting Loss:0.3370 + XiCon Loss:3.1504 x Lambda(1.0)), Vali MSE Loss: 0.3435 Test MSE Loss: 0.2854
Validation loss decreased (inf --> 0.343541).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4315648
	speed: 0.0183s/iter; left time: 222.8791s
Epoch: 2 cost time: 2.2373604774475098
Epoch: 2, Steps: 124 Train Loss: 3.3335 (Forecasting Loss:0.3146 + XiCon Loss:3.0189 x Lambda(1.0)), Vali MSE Loss: 0.3357 Test MSE Loss: 0.2847
Validation loss decreased (0.343541 --> 0.335669).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4555469
	speed: 0.0187s/iter; left time: 224.9337s
Epoch: 3 cost time: 2.3157386779785156
Epoch: 3, Steps: 124 Train Loss: 3.5028 (Forecasting Loss:0.3025 + XiCon Loss:3.2003 x Lambda(1.0)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.5026836
	speed: 0.0182s/iter; left time: 217.0124s
Epoch: 4 cost time: 2.2255332469940186
Epoch: 4, Steps: 124 Train Loss: 3.5912 (Forecasting Loss:0.2963 + XiCon Loss:3.2950 x Lambda(1.0)), Vali MSE Loss: 0.3311 Test MSE Loss: 0.2752
Validation loss decreased (0.335669 --> 0.331053).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5017097
	speed: 0.0185s/iter; left time: 218.4395s
Epoch: 5 cost time: 2.270603895187378
Epoch: 5, Steps: 124 Train Loss: 3.5749 (Forecasting Loss:0.2918 + XiCon Loss:3.2831 x Lambda(1.0)), Vali MSE Loss: 0.3282 Test MSE Loss: 0.2754
Validation loss decreased (0.331053 --> 0.328169).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.5629435
	speed: 0.0190s/iter; left time: 222.0071s
Epoch: 6 cost time: 2.330655097961426
Epoch: 6, Steps: 124 Train Loss: 3.5684 (Forecasting Loss:0.2895 + XiCon Loss:3.2790 x Lambda(1.0)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.2798
Validation loss decreased (0.328169 --> 0.324632).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.7822766
	speed: 0.0190s/iter; left time: 220.0654s
Epoch: 7 cost time: 2.325644016265869
Epoch: 7, Steps: 124 Train Loss: 3.5527 (Forecasting Loss:0.2884 + XiCon Loss:3.2642 x Lambda(1.0)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2797
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4773731
	speed: 0.0183s/iter; left time: 209.0725s
Epoch: 8 cost time: 2.278782606124878
Epoch: 8, Steps: 124 Train Loss: 3.5490 (Forecasting Loss:0.2879 + XiCon Loss:3.2610 x Lambda(1.0)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2794
Validation loss decreased (0.324632 --> 0.324447).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.5889368
	speed: 0.0189s/iter; left time: 214.1268s
Epoch: 9 cost time: 2.314509391784668
Epoch: 9, Steps: 124 Train Loss: 3.5542 (Forecasting Loss:0.2878 + XiCon Loss:3.2664 x Lambda(1.0)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2795
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.6022389
	speed: 0.0189s/iter; left time: 211.1338s
Epoch: 10 cost time: 2.3170173168182373
Epoch: 10, Steps: 124 Train Loss: 3.5480 (Forecasting Loss:0.2877 + XiCon Loss:3.2603 x Lambda(1.0)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2794
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.6026127
	speed: 0.0186s/iter; left time: 205.3106s
Epoch: 11 cost time: 2.275386333465576
Epoch: 11, Steps: 124 Train Loss: 3.5754 (Forecasting Loss:0.2873 + XiCon Loss:3.2881 x Lambda(1.0)), Vali MSE Loss: 0.3255 Test MSE Loss: 0.2795
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5124066
	speed: 0.0185s/iter; left time: 202.7300s
Epoch: 12 cost time: 2.2789885997772217
Epoch: 12, Steps: 124 Train Loss: 3.5533 (Forecasting Loss:0.2869 + XiCon Loss:3.2663 x Lambda(1.0)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2795
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5365770
	speed: 0.0187s/iter; left time: 202.0432s
Epoch: 13 cost time: 2.292522668838501
Epoch: 13, Steps: 124 Train Loss: 3.5641 (Forecasting Loss:0.2873 + XiCon Loss:3.2768 x Lambda(1.0)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2795
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.8137488
	speed: 0.0189s/iter; left time: 202.2728s
Epoch: 14 cost time: 2.334770679473877
Epoch: 14, Steps: 124 Train Loss: 3.5495 (Forecasting Loss:0.2875 + XiCon Loss:3.2621 x Lambda(1.0)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.2795
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4179506
	speed: 0.0187s/iter; left time: 197.4462s
Epoch: 15 cost time: 2.312264919281006
Epoch: 15, Steps: 124 Train Loss: 3.5427 (Forecasting Loss:0.2875 + XiCon Loss:3.2552 x Lambda(1.0)), Vali MSE Loss: 0.3250 Test MSE Loss: 0.2795
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.6039343
	speed: 0.0191s/iter; left time: 199.4463s
Epoch: 16 cost time: 2.333836317062378
Epoch: 16, Steps: 124 Train Loss: 3.5455 (Forecasting Loss:0.2873 + XiCon Loss:3.2581 x Lambda(1.0)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.2795
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.5120831
	speed: 0.0186s/iter; left time: 191.9137s
Epoch: 17 cost time: 2.2745890617370605
Epoch: 17, Steps: 124 Train Loss: 3.5570 (Forecasting Loss:0.2874 + XiCon Loss:3.2696 x Lambda(1.0)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2795
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.5519884
	speed: 0.0184s/iter; left time: 188.0563s
Epoch: 18 cost time: 2.2765941619873047
Epoch: 18, Steps: 124 Train Loss: 3.5722 (Forecasting Loss:0.2876 + XiCon Loss:3.2847 x Lambda(1.0)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2795
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19943641126155853, mae:0.35930413007736206, mape:0.6785561442375183, mspe:17.937156677246094 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2992
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.4195340
	speed: 0.0159s/iter; left time: 195.6904s
Epoch: 1 cost time: 1.9460577964782715
Epoch: 1, Steps: 124 Train Loss: 3.5007 (Forecasting Loss:0.3378 + XiCon Loss:3.1630 x Lambda(1.0)), Vali MSE Loss: 0.3428 Test MSE Loss: 0.2840
Validation loss decreased (inf --> 0.342775).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2564728
	speed: 0.0184s/iter; left time: 223.5385s
Epoch: 2 cost time: 2.2519266605377197
Epoch: 2, Steps: 124 Train Loss: 3.2937 (Forecasting Loss:0.3161 + XiCon Loss:2.9775 x Lambda(1.0)), Vali MSE Loss: 0.3400 Test MSE Loss: 0.2978
Validation loss decreased (0.342775 --> 0.340032).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1796622
	speed: 0.0188s/iter; left time: 226.3805s
Epoch: 3 cost time: 2.317399024963379
Epoch: 3, Steps: 124 Train Loss: 3.3125 (Forecasting Loss:0.2992 + XiCon Loss:3.0133 x Lambda(1.0)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.2796
Validation loss decreased (0.340032 --> 0.331385).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4402916
	speed: 0.0189s/iter; left time: 225.2404s
Epoch: 4 cost time: 2.3154094219207764
Epoch: 4, Steps: 124 Train Loss: 3.4867 (Forecasting Loss:0.2887 + XiCon Loss:3.1980 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2755
Validation loss decreased (0.331385 --> 0.320216).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4274187
	speed: 0.0190s/iter; left time: 224.4005s
Epoch: 5 cost time: 2.310866594314575
Epoch: 5, Steps: 124 Train Loss: 3.4610 (Forecasting Loss:0.2834 + XiCon Loss:3.1776 x Lambda(1.0)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.2743
Validation loss decreased (0.320216 --> 0.317597).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3239233
	speed: 0.0188s/iter; left time: 219.3412s
Epoch: 6 cost time: 2.284127712249756
Epoch: 6, Steps: 124 Train Loss: 3.4621 (Forecasting Loss:0.2796 + XiCon Loss:3.1825 x Lambda(1.0)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.2690
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4211073
	speed: 0.0183s/iter; left time: 211.5708s
Epoch: 7 cost time: 2.245668649673462
Epoch: 7, Steps: 124 Train Loss: 3.4521 (Forecasting Loss:0.2773 + XiCon Loss:3.1748 x Lambda(1.0)), Vali MSE Loss: 0.3145 Test MSE Loss: 0.2696
Validation loss decreased (0.317597 --> 0.314519).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4650524
	speed: 0.0183s/iter; left time: 208.9913s
Epoch: 8 cost time: 2.234553575515747
Epoch: 8, Steps: 124 Train Loss: 3.4484 (Forecasting Loss:0.2755 + XiCon Loss:3.1729 x Lambda(1.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2696
Validation loss decreased (0.314519 --> 0.313187).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.5467141
	speed: 0.0185s/iter; left time: 208.7240s
Epoch: 9 cost time: 2.2493021488189697
Epoch: 9, Steps: 124 Train Loss: 3.4539 (Forecasting Loss:0.2755 + XiCon Loss:3.1785 x Lambda(1.0)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.2689
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3908737
	speed: 0.0183s/iter; left time: 205.0440s
Epoch: 10 cost time: 2.2913875579833984
Epoch: 10, Steps: 124 Train Loss: 3.4421 (Forecasting Loss:0.2752 + XiCon Loss:3.1669 x Lambda(1.0)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2685
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3847122
	speed: 0.0178s/iter; left time: 196.4965s
Epoch: 11 cost time: 2.184828519821167
Epoch: 11, Steps: 124 Train Loss: 3.4540 (Forecasting Loss:0.2750 + XiCon Loss:3.1790 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2684
Validation loss decreased (0.313187 --> 0.312687).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5012643
	speed: 0.0181s/iter; left time: 198.4336s
Epoch: 12 cost time: 2.2274529933929443
Epoch: 12, Steps: 124 Train Loss: 3.4369 (Forecasting Loss:0.2746 + XiCon Loss:3.1623 x Lambda(1.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4148772
	speed: 0.0182s/iter; left time: 197.1880s
Epoch: 13 cost time: 2.2207720279693604
Epoch: 13, Steps: 124 Train Loss: 3.4383 (Forecasting Loss:0.2746 + XiCon Loss:3.1638 x Lambda(1.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4499183
	speed: 0.0178s/iter; left time: 190.5283s
Epoch: 14 cost time: 2.184028387069702
Epoch: 14, Steps: 124 Train Loss: 3.4586 (Forecasting Loss:0.2747 + XiCon Loss:3.1839 x Lambda(1.0)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2970831
	speed: 0.0182s/iter; left time: 192.5139s
Epoch: 15 cost time: 2.240825891494751
Epoch: 15, Steps: 124 Train Loss: 3.4441 (Forecasting Loss:0.2747 + XiCon Loss:3.1694 x Lambda(1.0)), Vali MSE Loss: 0.3125 Test MSE Loss: 0.2684
Validation loss decreased (0.312687 --> 0.312542).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4433820
	speed: 0.0184s/iter; left time: 192.2364s
Epoch: 16 cost time: 2.2465410232543945
Epoch: 16, Steps: 124 Train Loss: 3.4491 (Forecasting Loss:0.2746 + XiCon Loss:3.1746 x Lambda(1.0)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.5533168
	speed: 0.0180s/iter; left time: 185.8086s
Epoch: 17 cost time: 2.195244550704956
Epoch: 17, Steps: 124 Train Loss: 3.4355 (Forecasting Loss:0.2747 + XiCon Loss:3.1608 x Lambda(1.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3172591
	speed: 0.0180s/iter; left time: 183.9040s
Epoch: 18 cost time: 2.2171926498413086
Epoch: 18, Steps: 124 Train Loss: 3.4633 (Forecasting Loss:0.2746 + XiCon Loss:3.1887 x Lambda(1.0)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.5407934
	speed: 0.0183s/iter; left time: 183.9386s
Epoch: 19 cost time: 2.2234647274017334
Epoch: 19, Steps: 124 Train Loss: 3.4556 (Forecasting Loss:0.2748 + XiCon Loss:3.1808 x Lambda(1.0)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4528110
	speed: 0.0180s/iter; left time: 178.7943s
Epoch: 20 cost time: 2.217158079147339
Epoch: 20, Steps: 124 Train Loss: 3.4547 (Forecasting Loss:0.2748 + XiCon Loss:3.1799 x Lambda(1.0)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2684
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3814502
	speed: 0.0184s/iter; left time: 181.0208s
Epoch: 21 cost time: 2.252833843231201
Epoch: 21, Steps: 124 Train Loss: 3.4374 (Forecasting Loss:0.2746 + XiCon Loss:3.1628 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2684
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.4310346
	speed: 0.0182s/iter; left time: 176.1426s
Epoch: 22 cost time: 2.2290492057800293
Epoch: 22, Steps: 124 Train Loss: 3.4533 (Forecasting Loss:0.2750 + XiCon Loss:3.1783 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2684
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.4023268
	speed: 0.0181s/iter; left time: 173.6635s
Epoch: 23 cost time: 2.2147974967956543
Epoch: 23, Steps: 124 Train Loss: 3.4453 (Forecasting Loss:0.2746 + XiCon Loss:3.1706 x Lambda(1.0)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2684
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3968914
	speed: 0.0180s/iter; left time: 169.8092s
Epoch: 24 cost time: 2.1962695121765137
Epoch: 24, Steps: 124 Train Loss: 3.4346 (Forecasting Loss:0.2746 + XiCon Loss:3.1600 x Lambda(1.0)), Vali MSE Loss: 0.3124 Test MSE Loss: 0.2684
Validation loss decreased (0.312542 --> 0.312395).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.6179652
	speed: 0.0181s/iter; left time: 168.7734s
Epoch: 25 cost time: 2.2252352237701416
Epoch: 25, Steps: 124 Train Loss: 3.4383 (Forecasting Loss:0.2749 + XiCon Loss:3.1635 x Lambda(1.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2684
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3324769
	speed: 0.0181s/iter; left time: 166.7058s
Epoch: 26 cost time: 2.2108211517333984
Epoch: 26, Steps: 124 Train Loss: 3.4294 (Forecasting Loss:0.2747 + XiCon Loss:3.1547 x Lambda(1.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.5150406
	speed: 0.0178s/iter; left time: 161.8352s
Epoch: 27 cost time: 2.208768844604492
Epoch: 27, Steps: 124 Train Loss: 3.4356 (Forecasting Loss:0.2749 + XiCon Loss:3.1607 x Lambda(1.0)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2684
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.4565778
	speed: 0.0182s/iter; left time: 162.8756s
Epoch: 28 cost time: 2.221529960632324
Epoch: 28, Steps: 124 Train Loss: 3.4550 (Forecasting Loss:0.2748 + XiCon Loss:3.1803 x Lambda(1.0)), Vali MSE Loss: 0.3136 Test MSE Loss: 0.2684
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.4418340
	speed: 0.0180s/iter; left time: 159.2496s
Epoch: 29 cost time: 2.2061479091644287
Epoch: 29, Steps: 124 Train Loss: 3.4322 (Forecasting Loss:0.2743 + XiCon Loss:3.1580 x Lambda(1.0)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.2684
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2883139
	speed: 0.0179s/iter; left time: 155.9085s
Epoch: 30 cost time: 2.201641321182251
Epoch: 30, Steps: 124 Train Loss: 3.4483 (Forecasting Loss:0.2746 + XiCon Loss:3.1737 x Lambda(1.0)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2684
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.4436917
	speed: 0.0182s/iter; left time: 155.7997s
Epoch: 31 cost time: 2.225517511367798
Epoch: 31, Steps: 124 Train Loss: 3.4495 (Forecasting Loss:0.2745 + XiCon Loss:3.1750 x Lambda(1.0)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.2684
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.5472884
	speed: 0.0180s/iter; left time: 152.2004s
Epoch: 32 cost time: 2.205779790878296
Epoch: 32, Steps: 124 Train Loss: 3.4485 (Forecasting Loss:0.2748 + XiCon Loss:3.1737 x Lambda(1.0)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2684
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.5653951
	speed: 0.0179s/iter; left time: 149.2050s
Epoch: 33 cost time: 2.2057178020477295
Epoch: 33, Steps: 124 Train Loss: 3.4462 (Forecasting Loss:0.2748 + XiCon Loss:3.1714 x Lambda(1.0)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2684
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.4087691
	speed: 0.0179s/iter; left time: 146.7311s
Epoch: 34 cost time: 2.1940534114837646
Epoch: 34, Steps: 124 Train Loss: 3.4342 (Forecasting Loss:0.2746 + XiCon Loss:3.1596 x Lambda(1.0)), Vali MSE Loss: 0.3124 Test MSE Loss: 0.2684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18808983266353607, mae:0.34873807430267334, mape:0.659523606300354, mspe:16.067441940307617 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2639
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.4876976
	speed: 0.0157s/iter; left time: 193.6727s
Epoch: 1 cost time: 1.930192232131958
Epoch: 1, Steps: 124 Train Loss: 3.4749 (Forecasting Loss:0.3373 + XiCon Loss:3.1376 x Lambda(1.0)), Vali MSE Loss: 0.3421 Test MSE Loss: 0.2854
Validation loss decreased (inf --> 0.342071).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2159963
	speed: 0.0189s/iter; left time: 229.9628s
Epoch: 2 cost time: 2.2958498001098633
Epoch: 2, Steps: 124 Train Loss: 3.2845 (Forecasting Loss:0.3155 + XiCon Loss:2.9690 x Lambda(1.0)), Vali MSE Loss: 0.3332 Test MSE Loss: 0.2943
Validation loss decreased (0.342071 --> 0.333249).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3782654
	speed: 0.0182s/iter; left time: 219.6211s
Epoch: 3 cost time: 2.2351877689361572
Epoch: 3, Steps: 124 Train Loss: 3.3204 (Forecasting Loss:0.3021 + XiCon Loss:3.0183 x Lambda(1.0)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2866
Validation loss decreased (0.333249 --> 0.325139).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3423994
	speed: 0.0186s/iter; left time: 222.0391s
Epoch: 4 cost time: 2.2871344089508057
Epoch: 4, Steps: 124 Train Loss: 3.3798 (Forecasting Loss:0.2950 + XiCon Loss:3.0848 x Lambda(1.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2801
Validation loss decreased (0.325139 --> 0.323161).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3451524
	speed: 0.0189s/iter; left time: 222.9835s
Epoch: 5 cost time: 2.3171353340148926
Epoch: 5, Steps: 124 Train Loss: 3.4109 (Forecasting Loss:0.2910 + XiCon Loss:3.1199 x Lambda(1.0)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2709
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.5252345
	speed: 0.0188s/iter; left time: 219.6215s
Epoch: 6 cost time: 2.3341023921966553
Epoch: 6, Steps: 124 Train Loss: 3.4167 (Forecasting Loss:0.2890 + XiCon Loss:3.1277 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2759
Validation loss decreased (0.323161 --> 0.321192).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3165631
	speed: 0.0189s/iter; left time: 218.7047s
Epoch: 7 cost time: 2.315675735473633
Epoch: 7, Steps: 124 Train Loss: 3.4302 (Forecasting Loss:0.2876 + XiCon Loss:3.1426 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2737
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4067433
	speed: 0.0189s/iter; left time: 216.0764s
Epoch: 8 cost time: 2.3168535232543945
Epoch: 8, Steps: 124 Train Loss: 3.4363 (Forecasting Loss:0.2867 + XiCon Loss:3.1496 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2735
Validation loss decreased (0.321192 --> 0.320802).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4123089
	speed: 0.0190s/iter; left time: 214.7680s
Epoch: 9 cost time: 2.3158118724823
Epoch: 9, Steps: 124 Train Loss: 3.4467 (Forecasting Loss:0.2865 + XiCon Loss:3.1603 x Lambda(1.0)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2738
Validation loss decreased (0.320802 --> 0.319769).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.5280623
	speed: 0.0192s/iter; left time: 214.3871s
Epoch: 10 cost time: 2.3481459617614746
Epoch: 10, Steps: 124 Train Loss: 3.4461 (Forecasting Loss:0.2863 + XiCon Loss:3.1598 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2736
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4026756
	speed: 0.0187s/iter; left time: 206.4400s
Epoch: 11 cost time: 2.300689458847046
Epoch: 11, Steps: 124 Train Loss: 3.4383 (Forecasting Loss:0.2861 + XiCon Loss:3.1522 x Lambda(1.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2736
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.6255627
	speed: 0.0187s/iter; left time: 204.9714s
Epoch: 12 cost time: 2.293837070465088
Epoch: 12, Steps: 124 Train Loss: 3.4387 (Forecasting Loss:0.2860 + XiCon Loss:3.1527 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2734
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4762683
	speed: 0.0188s/iter; left time: 203.0682s
Epoch: 13 cost time: 2.3085577487945557
Epoch: 13, Steps: 124 Train Loss: 3.4529 (Forecasting Loss:0.2857 + XiCon Loss:3.1671 x Lambda(1.0)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.2735
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.5508950
	speed: 0.0189s/iter; left time: 201.7434s
Epoch: 14 cost time: 2.3160741329193115
Epoch: 14, Steps: 124 Train Loss: 3.4308 (Forecasting Loss:0.2861 + XiCon Loss:3.1447 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2735
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4299650
	speed: 0.0185s/iter; left time: 195.6534s
Epoch: 15 cost time: 2.280543088912964
Epoch: 15, Steps: 124 Train Loss: 3.4450 (Forecasting Loss:0.2861 + XiCon Loss:3.1588 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2735
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.5117035
	speed: 0.0191s/iter; left time: 198.9973s
Epoch: 16 cost time: 2.3367645740509033
Epoch: 16, Steps: 124 Train Loss: 3.4368 (Forecasting Loss:0.2858 + XiCon Loss:3.1510 x Lambda(1.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2735
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4845557
	speed: 0.0186s/iter; left time: 192.4001s
Epoch: 17 cost time: 2.3017988204956055
Epoch: 17, Steps: 124 Train Loss: 3.4348 (Forecasting Loss:0.2861 + XiCon Loss:3.1486 x Lambda(1.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2735
Validation loss decreased (0.319769 --> 0.319493).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4052322
	speed: 0.0189s/iter; left time: 192.4181s
Epoch: 18 cost time: 2.3156893253326416
Epoch: 18, Steps: 124 Train Loss: 3.4481 (Forecasting Loss:0.2859 + XiCon Loss:3.1622 x Lambda(1.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3395097
	speed: 0.0192s/iter; left time: 193.0576s
Epoch: 19 cost time: 2.349573850631714
Epoch: 19, Steps: 124 Train Loss: 3.4486 (Forecasting Loss:0.2858 + XiCon Loss:3.1628 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2735
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.5003941
	speed: 0.0191s/iter; left time: 190.1640s
Epoch: 20 cost time: 2.3335602283477783
Epoch: 20, Steps: 124 Train Loss: 3.4375 (Forecasting Loss:0.2860 + XiCon Loss:3.1515 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2735
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4888167
	speed: 0.0191s/iter; left time: 187.5826s
Epoch: 21 cost time: 2.335536003112793
Epoch: 21, Steps: 124 Train Loss: 3.4338 (Forecasting Loss:0.2859 + XiCon Loss:3.1479 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2735
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5283306
	speed: 0.0188s/iter; left time: 182.6950s
Epoch: 22 cost time: 2.3564987182617188
Epoch: 22, Steps: 124 Train Loss: 3.4324 (Forecasting Loss:0.2860 + XiCon Loss:3.1464 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2735
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.5924325
	speed: 0.0188s/iter; left time: 180.1560s
Epoch: 23 cost time: 2.3255221843719482
Epoch: 23, Steps: 124 Train Loss: 3.4375 (Forecasting Loss:0.2859 + XiCon Loss:3.1516 x Lambda(1.0)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2735
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4883261
	speed: 0.0187s/iter; left time: 176.3659s
Epoch: 24 cost time: 2.3082468509674072
Epoch: 24, Steps: 124 Train Loss: 3.4514 (Forecasting Loss:0.2860 + XiCon Loss:3.1654 x Lambda(1.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.2735
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3842645
	speed: 0.0187s/iter; left time: 174.3606s
Epoch: 25 cost time: 2.2883198261260986
Epoch: 25, Steps: 124 Train Loss: 3.4461 (Forecasting Loss:0.2860 + XiCon Loss:3.1601 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2735
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3562658
	speed: 0.0187s/iter; left time: 172.2674s
Epoch: 26 cost time: 2.298854112625122
Epoch: 26, Steps: 124 Train Loss: 3.4481 (Forecasting Loss:0.2861 + XiCon Loss:3.1620 x Lambda(1.0)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2735
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.4128327
	speed: 0.0192s/iter; left time: 174.4242s
Epoch: 27 cost time: 2.356487512588501
Epoch: 27, Steps: 124 Train Loss: 3.4439 (Forecasting Loss:0.2860 + XiCon Loss:3.1579 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2735
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1931522935628891, mae:0.35381659865379333, mape:0.6655946373939514, mspe:17.710176467895508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2688
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.4489927
	speed: 0.0158s/iter; left time: 194.8497s
Epoch: 1 cost time: 1.9348690509796143
Epoch: 1, Steps: 124 Train Loss: 3.4765 (Forecasting Loss:0.3381 + XiCon Loss:3.1384 x Lambda(1.0)), Vali MSE Loss: 0.3455 Test MSE Loss: 0.2908
Validation loss decreased (inf --> 0.345452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2607996
	speed: 0.0186s/iter; left time: 226.8061s
Epoch: 2 cost time: 2.273249626159668
Epoch: 2, Steps: 124 Train Loss: 3.2983 (Forecasting Loss:0.3135 + XiCon Loss:2.9848 x Lambda(1.0)), Vali MSE Loss: 0.3394 Test MSE Loss: 0.2838
Validation loss decreased (0.345452 --> 0.339448).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3856478
	speed: 0.0190s/iter; left time: 229.3433s
Epoch: 3 cost time: 2.3282289505004883
Epoch: 3, Steps: 124 Train Loss: 3.3179 (Forecasting Loss:0.3001 + XiCon Loss:3.0178 x Lambda(1.0)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.2659
Validation loss decreased (0.339448 --> 0.338818).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2044344
	speed: 0.0183s/iter; left time: 218.1258s
Epoch: 4 cost time: 2.2368881702423096
Epoch: 4, Steps: 124 Train Loss: 3.2816 (Forecasting Loss:0.2928 + XiCon Loss:2.9888 x Lambda(1.0)), Vali MSE Loss: 0.3331 Test MSE Loss: 0.2703
Validation loss decreased (0.338818 --> 0.333092).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3139729
	speed: 0.0182s/iter; left time: 214.4036s
Epoch: 5 cost time: 2.233672857284546
Epoch: 5, Steps: 124 Train Loss: 3.2387 (Forecasting Loss:0.2877 + XiCon Loss:2.9510 x Lambda(1.0)), Vali MSE Loss: 0.3272 Test MSE Loss: 0.2719
Validation loss decreased (0.333092 --> 0.327157).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1566980
	speed: 0.0183s/iter; left time: 214.1950s
Epoch: 6 cost time: 2.241518259048462
Epoch: 6, Steps: 124 Train Loss: 3.2156 (Forecasting Loss:0.2850 + XiCon Loss:2.9305 x Lambda(1.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2603
Validation loss decreased (0.327157 --> 0.323198).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2204411
	speed: 0.0183s/iter; left time: 211.1250s
Epoch: 7 cost time: 2.245347261428833
Epoch: 7, Steps: 124 Train Loss: 3.2173 (Forecasting Loss:0.2826 + XiCon Loss:2.9348 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2628
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1671014
	speed: 0.0185s/iter; left time: 211.3854s
Epoch: 8 cost time: 2.2599217891693115
Epoch: 8, Steps: 124 Train Loss: 3.2192 (Forecasting Loss:0.2823 + XiCon Loss:2.9369 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2616
Validation loss decreased (0.323198 --> 0.321913).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1741307
	speed: 0.0179s/iter; left time: 202.8570s
Epoch: 9 cost time: 2.2158703804016113
Epoch: 9, Steps: 124 Train Loss: 3.2070 (Forecasting Loss:0.2816 + XiCon Loss:2.9254 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2606
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1852033
	speed: 0.0184s/iter; left time: 205.3574s
Epoch: 10 cost time: 2.247331142425537
Epoch: 10, Steps: 124 Train Loss: 3.2055 (Forecasting Loss:0.2812 + XiCon Loss:2.9243 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2607
Validation loss decreased (0.321913 --> 0.321687).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1145620
	speed: 0.0183s/iter; left time: 201.8950s
Epoch: 11 cost time: 2.2734568119049072
Epoch: 11, Steps: 124 Train Loss: 3.2061 (Forecasting Loss:0.2808 + XiCon Loss:2.9254 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2610
Validation loss decreased (0.321687 --> 0.321352).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1107991
	speed: 0.0179s/iter; left time: 195.9446s
Epoch: 12 cost time: 2.1934731006622314
Epoch: 12, Steps: 124 Train Loss: 3.2093 (Forecasting Loss:0.2808 + XiCon Loss:2.9285 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2610
Validation loss decreased (0.321352 --> 0.321337).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2296760
	speed: 0.0183s/iter; left time: 198.1524s
Epoch: 13 cost time: 2.256000518798828
Epoch: 13, Steps: 124 Train Loss: 3.2094 (Forecasting Loss:0.2810 + XiCon Loss:2.9283 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2610
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1383371
	speed: 0.0182s/iter; left time: 194.6334s
Epoch: 14 cost time: 2.2268083095550537
Epoch: 14, Steps: 124 Train Loss: 3.2087 (Forecasting Loss:0.2808 + XiCon Loss:2.9279 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2610
Validation loss decreased (0.321337 --> 0.321176).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1925368
	speed: 0.0180s/iter; left time: 190.5343s
Epoch: 15 cost time: 2.212705135345459
Epoch: 15, Steps: 124 Train Loss: 3.2014 (Forecasting Loss:0.2808 + XiCon Loss:2.9206 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2610
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1219423
	speed: 0.0181s/iter; left time: 189.1159s
Epoch: 16 cost time: 2.2119345664978027
Epoch: 16, Steps: 124 Train Loss: 3.2080 (Forecasting Loss:0.2809 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2610
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1472855
	speed: 0.0181s/iter; left time: 186.2624s
Epoch: 17 cost time: 2.2238409519195557
Epoch: 17, Steps: 124 Train Loss: 3.2041 (Forecasting Loss:0.2811 + XiCon Loss:2.9230 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2610
Validation loss decreased (0.321176 --> 0.321171).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1945753
	speed: 0.0179s/iter; left time: 182.5584s
Epoch: 18 cost time: 2.1966898441314697
Epoch: 18, Steps: 124 Train Loss: 3.2064 (Forecasting Loss:0.2810 + XiCon Loss:2.9253 x Lambda(1.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2610
Validation loss decreased (0.321171 --> 0.320990).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2151210
	speed: 0.0180s/iter; left time: 180.8240s
Epoch: 19 cost time: 2.216212749481201
Epoch: 19, Steps: 124 Train Loss: 3.2022 (Forecasting Loss:0.2809 + XiCon Loss:2.9213 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2610
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1226215
	speed: 0.0184s/iter; left time: 182.5921s
Epoch: 20 cost time: 2.239699602127075
Epoch: 20, Steps: 124 Train Loss: 3.2071 (Forecasting Loss:0.2810 + XiCon Loss:2.9261 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2610
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2620704
	speed: 0.0182s/iter; left time: 178.3453s
Epoch: 21 cost time: 2.2325263023376465
Epoch: 21, Steps: 124 Train Loss: 3.2118 (Forecasting Loss:0.2809 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2610
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1415713
	speed: 0.0181s/iter; left time: 175.9133s
Epoch: 22 cost time: 2.217026472091675
Epoch: 22, Steps: 124 Train Loss: 3.1973 (Forecasting Loss:0.2809 + XiCon Loss:2.9164 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2610
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1744304
	speed: 0.0181s/iter; left time: 172.8418s
Epoch: 23 cost time: 2.2044570446014404
Epoch: 23, Steps: 124 Train Loss: 3.2027 (Forecasting Loss:0.2809 + XiCon Loss:2.9218 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2610
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2504559
	speed: 0.0183s/iter; left time: 173.2672s
Epoch: 24 cost time: 2.2462007999420166
Epoch: 24, Steps: 124 Train Loss: 3.2019 (Forecasting Loss:0.2807 + XiCon Loss:2.9212 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2610
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2454510
	speed: 0.0180s/iter; left time: 168.1123s
Epoch: 25 cost time: 2.217332363128662
Epoch: 25, Steps: 124 Train Loss: 3.2049 (Forecasting Loss:0.2811 + XiCon Loss:2.9238 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2610
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2247083
	speed: 0.0184s/iter; left time: 169.2699s
Epoch: 26 cost time: 2.242368459701538
Epoch: 26, Steps: 124 Train Loss: 3.2082 (Forecasting Loss:0.2810 + XiCon Loss:2.9272 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2610
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3217821
	speed: 0.0183s/iter; left time: 166.0968s
Epoch: 27 cost time: 2.2400879859924316
Epoch: 27, Steps: 124 Train Loss: 3.2073 (Forecasting Loss:0.2811 + XiCon Loss:2.9262 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2610
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2483971
	speed: 0.0180s/iter; left time: 161.0931s
Epoch: 28 cost time: 2.203792095184326
Epoch: 28, Steps: 124 Train Loss: 3.2059 (Forecasting Loss:0.2808 + XiCon Loss:2.9251 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2610
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.17970310151576996, mae:0.34227797389030457, mape:0.6696857810020447, mspe:18.41556167602539 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1896+-0.00907, MAE:0.3505+-0.00796, MAPE:0.6700+-0.00974, MSPE:17.6757+-1.16667, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2887
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4554866
	speed: 0.0191s/iter; left time: 223.3098s
Epoch: 1 cost time: 2.182612419128418
Epoch: 1, Steps: 118 Train Loss: 0.4768 (Forecasting Loss:0.4736 + XiCon Loss:3.2268 x Lambda(0.001)), Vali MSE Loss: 0.4757 Test MSE Loss: 0.3612
Validation loss decreased (inf --> 0.475684).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3713450
	speed: 0.0163s/iter; left time: 188.7548s
Epoch: 2 cost time: 1.9066863059997559
Epoch: 2, Steps: 118 Train Loss: 0.3498 (Forecasting Loss:0.3466 + XiCon Loss:3.2252 x Lambda(0.001)), Vali MSE Loss: 0.3779 Test MSE Loss: 0.2872
Validation loss decreased (0.475684 --> 0.377944).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3065337
	speed: 0.0160s/iter; left time: 183.7358s
Epoch: 3 cost time: 1.8854379653930664
Epoch: 3, Steps: 118 Train Loss: 0.3136 (Forecasting Loss:0.3104 + XiCon Loss:3.2238 x Lambda(0.001)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.2778
Validation loss decreased (0.377944 --> 0.373651).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3193890
	speed: 0.0162s/iter; left time: 183.7033s
Epoch: 4 cost time: 1.89707350730896
Epoch: 4, Steps: 118 Train Loss: 0.3088 (Forecasting Loss:0.3056 + XiCon Loss:3.2212 x Lambda(0.001)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2798
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3113807
	speed: 0.0160s/iter; left time: 179.8301s
Epoch: 5 cost time: 1.8794426918029785
Epoch: 5, Steps: 118 Train Loss: 0.3066 (Forecasting Loss:0.3034 + XiCon Loss:3.2197 x Lambda(0.001)), Vali MSE Loss: 0.3832 Test MSE Loss: 0.2812
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2908003
	speed: 0.0162s/iter; left time: 180.1693s
Epoch: 6 cost time: 1.9042108058929443
Epoch: 6, Steps: 118 Train Loss: 0.3056 (Forecasting Loss:0.3023 + XiCon Loss:3.2208 x Lambda(0.001)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.2802
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3089306
	speed: 0.0161s/iter; left time: 176.5220s
Epoch: 7 cost time: 1.8849892616271973
Epoch: 7, Steps: 118 Train Loss: 0.3057 (Forecasting Loss:0.3025 + XiCon Loss:3.2203 x Lambda(0.001)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2805
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2896355
	speed: 0.0162s/iter; left time: 175.9663s
Epoch: 8 cost time: 1.9032344818115234
Epoch: 8, Steps: 118 Train Loss: 0.3047 (Forecasting Loss:0.3015 + XiCon Loss:3.2203 x Lambda(0.001)), Vali MSE Loss: 0.3755 Test MSE Loss: 0.2807
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3029224
	speed: 0.0160s/iter; left time: 172.3874s
Epoch: 9 cost time: 1.9028253555297852
Epoch: 9, Steps: 118 Train Loss: 0.3049 (Forecasting Loss:0.3017 + XiCon Loss:3.2209 x Lambda(0.001)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.2808
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3065044
	speed: 0.0164s/iter; left time: 174.6593s
Epoch: 10 cost time: 1.921506643295288
Epoch: 10, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3016 + XiCon Loss:3.2214 x Lambda(0.001)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.2808
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2958759
	speed: 0.0160s/iter; left time: 168.1167s
Epoch: 11 cost time: 1.8758544921875
Epoch: 11, Steps: 118 Train Loss: 0.3049 (Forecasting Loss:0.3017 + XiCon Loss:3.2209 x Lambda(0.001)), Vali MSE Loss: 0.3765 Test MSE Loss: 0.2808
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3165725
	speed: 0.0159s/iter; left time: 165.3049s
Epoch: 12 cost time: 1.8651869297027588
Epoch: 12, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3016 + XiCon Loss:3.2217 x Lambda(0.001)), Vali MSE Loss: 0.3770 Test MSE Loss: 0.2808
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2933616
	speed: 0.0159s/iter; left time: 163.2175s
Epoch: 13 cost time: 1.8625257015228271
Epoch: 13, Steps: 118 Train Loss: 0.3047 (Forecasting Loss:0.3014 + XiCon Loss:3.2198 x Lambda(0.001)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2808
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19793030619621277, mae:0.35758912563323975, mape:0.6932340264320374, mspe:23.380760192871094 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1596
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4366789
	speed: 0.0165s/iter; left time: 192.9052s
Epoch: 1 cost time: 1.9311845302581787
Epoch: 1, Steps: 118 Train Loss: 0.4717 (Forecasting Loss:0.4685 + XiCon Loss:3.2343 x Lambda(0.001)), Vali MSE Loss: 0.4889 Test MSE Loss: 0.3764
Validation loss decreased (inf --> 0.488925).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3002492
	speed: 0.0160s/iter; left time: 185.7318s
Epoch: 2 cost time: 1.881821870803833
Epoch: 2, Steps: 118 Train Loss: 0.3485 (Forecasting Loss:0.3453 + XiCon Loss:3.2380 x Lambda(0.001)), Vali MSE Loss: 0.3579 Test MSE Loss: 0.2695
Validation loss decreased (0.488925 --> 0.357854).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2869968
	speed: 0.0165s/iter; left time: 188.9803s
Epoch: 3 cost time: 1.9379487037658691
Epoch: 3, Steps: 118 Train Loss: 0.2814 (Forecasting Loss:0.2782 + XiCon Loss:3.2370 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2673
Validation loss decreased (0.357854 --> 0.315665).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2612928
	speed: 0.0169s/iter; left time: 192.0571s
Epoch: 4 cost time: 1.9890031814575195
Epoch: 4, Steps: 118 Train Loss: 0.2715 (Forecasting Loss:0.2682 + XiCon Loss:3.2312 x Lambda(0.001)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.2658
Validation loss decreased (0.315665 --> 0.311984).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2670857
	speed: 0.0171s/iter; left time: 191.5567s
Epoch: 5 cost time: 1.99951171875
Epoch: 5, Steps: 118 Train Loss: 0.2684 (Forecasting Loss:0.2652 + XiCon Loss:3.2266 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2663
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2560751
	speed: 0.0169s/iter; left time: 187.8721s
Epoch: 6 cost time: 1.9850575923919678
Epoch: 6, Steps: 118 Train Loss: 0.2669 (Forecasting Loss:0.2637 + XiCon Loss:3.2245 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2678
Validation loss decreased (0.311984 --> 0.311329).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2712924
	speed: 0.0172s/iter; left time: 189.2203s
Epoch: 7 cost time: 2.01712703704834
Epoch: 7, Steps: 118 Train Loss: 0.2661 (Forecasting Loss:0.2629 + XiCon Loss:3.2231 x Lambda(0.001)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2679
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2567498
	speed: 0.0170s/iter; left time: 185.0529s
Epoch: 8 cost time: 1.9982142448425293
Epoch: 8, Steps: 118 Train Loss: 0.2659 (Forecasting Loss:0.2627 + XiCon Loss:3.2221 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2517235
	speed: 0.0170s/iter; left time: 183.1333s
Epoch: 9 cost time: 2.0019257068634033
Epoch: 9, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2626 + XiCon Loss:3.2226 x Lambda(0.001)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.2677
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2710641
	speed: 0.0171s/iter; left time: 182.1084s
Epoch: 10 cost time: 2.004422187805176
Epoch: 10, Steps: 118 Train Loss: 0.2659 (Forecasting Loss:0.2627 + XiCon Loss:3.2222 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2758922
	speed: 0.0173s/iter; left time: 181.8146s
Epoch: 11 cost time: 2.0231261253356934
Epoch: 11, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2623 + XiCon Loss:3.2217 x Lambda(0.001)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2581804
	speed: 0.0171s/iter; left time: 177.7183s
Epoch: 12 cost time: 2.0023412704467773
Epoch: 12, Steps: 118 Train Loss: 0.2656 (Forecasting Loss:0.2624 + XiCon Loss:3.2230 x Lambda(0.001)), Vali MSE Loss: 0.3137 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2825565
	speed: 0.0169s/iter; left time: 173.7232s
Epoch: 13 cost time: 1.9793071746826172
Epoch: 13, Steps: 118 Train Loss: 0.2654 (Forecasting Loss:0.2622 + XiCon Loss:3.2231 x Lambda(0.001)), Vali MSE Loss: 0.3135 Test MSE Loss: 0.2680
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2552147
	speed: 0.0171s/iter; left time: 173.3853s
Epoch: 14 cost time: 1.9959502220153809
Epoch: 14, Steps: 118 Train Loss: 0.2656 (Forecasting Loss:0.2624 + XiCon Loss:3.2231 x Lambda(0.001)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.2680
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2688369
	speed: 0.0170s/iter; left time: 170.6145s
Epoch: 15 cost time: 1.9878361225128174
Epoch: 15, Steps: 118 Train Loss: 0.2656 (Forecasting Loss:0.2623 + XiCon Loss:3.2239 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2680
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2609017
	speed: 0.0170s/iter; left time: 168.3699s
Epoch: 16 cost time: 1.9933109283447266
Epoch: 16, Steps: 118 Train Loss: 0.2653 (Forecasting Loss:0.2621 + XiCon Loss:3.2228 x Lambda(0.001)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.2680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18611106276512146, mae:0.3495689630508423, mape:0.6736235618591309, mspe:18.202470779418945 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2322
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4508551
	speed: 0.0166s/iter; left time: 194.0260s
Epoch: 1 cost time: 1.9377598762512207
Epoch: 1, Steps: 118 Train Loss: 0.4725 (Forecasting Loss:0.4693 + XiCon Loss:3.2225 x Lambda(0.001)), Vali MSE Loss: 0.4768 Test MSE Loss: 0.3596
Validation loss decreased (inf --> 0.476795).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.2847650
	speed: 0.0163s/iter; left time: 189.2211s
Epoch: 2 cost time: 1.9413504600524902
Epoch: 2, Steps: 118 Train Loss: 0.3436 (Forecasting Loss:0.3404 + XiCon Loss:3.1928 x Lambda(0.001)), Vali MSE Loss: 0.3618 Test MSE Loss: 0.2610
Validation loss decreased (0.476795 --> 0.361825).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2801608
	speed: 0.0177s/iter; left time: 203.0601s
Epoch: 3 cost time: 2.086465358734131
Epoch: 3, Steps: 118 Train Loss: 0.2831 (Forecasting Loss:0.2799 + XiCon Loss:3.1619 x Lambda(0.001)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2590
Validation loss decreased (0.361825 --> 0.338579).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2750183
	speed: 0.0184s/iter; left time: 208.5865s
Epoch: 4 cost time: 2.1496527194976807
Epoch: 4, Steps: 118 Train Loss: 0.2754 (Forecasting Loss:0.2722 + XiCon Loss:3.1555 x Lambda(0.001)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.2585
Validation loss decreased (0.338579 --> 0.318356).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2666568
	speed: 0.0181s/iter; left time: 203.5021s
Epoch: 5 cost time: 2.1224775314331055
Epoch: 5, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2687 + XiCon Loss:3.1510 x Lambda(0.001)), Vali MSE Loss: 0.3149 Test MSE Loss: 0.2578
Validation loss decreased (0.318356 --> 0.314893).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2839499
	speed: 0.0182s/iter; left time: 201.6979s
Epoch: 6 cost time: 2.139768362045288
Epoch: 6, Steps: 118 Train Loss: 0.2704 (Forecasting Loss:0.2673 + XiCon Loss:3.1485 x Lambda(0.001)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.2593
Validation loss decreased (0.314893 --> 0.313409).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2654347
	speed: 0.0183s/iter; left time: 200.9410s
Epoch: 7 cost time: 2.138288736343384
Epoch: 7, Steps: 118 Train Loss: 0.2697 (Forecasting Loss:0.2665 + XiCon Loss:3.1482 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2587
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2601492
	speed: 0.0181s/iter; left time: 196.3592s
Epoch: 8 cost time: 2.1235785484313965
Epoch: 8, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2661 + XiCon Loss:3.1463 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2594
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2758203
	speed: 0.0180s/iter; left time: 193.6990s
Epoch: 9 cost time: 2.1128690242767334
Epoch: 9, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2662 + XiCon Loss:3.1464 x Lambda(0.001)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2592
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2676995
	speed: 0.0180s/iter; left time: 191.5055s
Epoch: 10 cost time: 2.1159069538116455
Epoch: 10, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2658 + XiCon Loss:3.1461 x Lambda(0.001)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2594
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2745290
	speed: 0.0180s/iter; left time: 189.8647s
Epoch: 11 cost time: 2.115687608718872
Epoch: 11, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2660 + XiCon Loss:3.1456 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2594
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2780784
	speed: 0.0182s/iter; left time: 188.8155s
Epoch: 12 cost time: 2.1312804222106934
Epoch: 12, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2656 + XiCon Loss:3.1451 x Lambda(0.001)), Vali MSE Loss: 0.3178 Test MSE Loss: 0.2594
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3101672
	speed: 0.0181s/iter; left time: 186.5977s
Epoch: 13 cost time: 2.1311073303222656
Epoch: 13, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.1452 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2594
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2491066
	speed: 0.0187s/iter; left time: 190.0867s
Epoch: 14 cost time: 2.1945672035217285
Epoch: 14, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.1462 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2594
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2732705
	speed: 0.0181s/iter; left time: 181.8980s
Epoch: 15 cost time: 2.1267576217651367
Epoch: 15, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2659 + XiCon Loss:3.1478 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2594
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2891508
	speed: 0.0179s/iter; left time: 177.5285s
Epoch: 16 cost time: 2.09822154045105
Epoch: 16, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.1472 x Lambda(0.001)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2594
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17644597589969635, mae:0.3420966565608978, mape:0.6958734393119812, mspe:21.34725570678711 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2564
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4675663
	speed: 0.0163s/iter; left time: 190.7016s
Epoch: 1 cost time: 1.9115333557128906
Epoch: 1, Steps: 118 Train Loss: 0.4996 (Forecasting Loss:0.4964 + XiCon Loss:3.2250 x Lambda(0.001)), Vali MSE Loss: 0.5422 Test MSE Loss: 0.4452
Validation loss decreased (inf --> 0.542249).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3097136
	speed: 0.0161s/iter; left time: 186.8975s
Epoch: 2 cost time: 1.8976280689239502
Epoch: 2, Steps: 118 Train Loss: 0.3704 (Forecasting Loss:0.3671 + XiCon Loss:3.2265 x Lambda(0.001)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.2744
Validation loss decreased (0.542249 --> 0.358908).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2781564
	speed: 0.0173s/iter; left time: 198.8569s
Epoch: 3 cost time: 2.035884141921997
Epoch: 3, Steps: 118 Train Loss: 0.2914 (Forecasting Loss:0.2882 + XiCon Loss:3.2369 x Lambda(0.001)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2682
Validation loss decreased (0.358908 --> 0.326739).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2773923
	speed: 0.0176s/iter; left time: 199.4849s
Epoch: 4 cost time: 2.06429123878479
Epoch: 4, Steps: 118 Train Loss: 0.2760 (Forecasting Loss:0.2728 + XiCon Loss:3.2383 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2660
Validation loss decreased (0.326739 --> 0.322230).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2735258
	speed: 0.0174s/iter; left time: 195.5633s
Epoch: 5 cost time: 2.0507540702819824
Epoch: 5, Steps: 118 Train Loss: 0.2715 (Forecasting Loss:0.2683 + XiCon Loss:3.2349 x Lambda(0.001)), Vali MSE Loss: 0.3174 Test MSE Loss: 0.2655
Validation loss decreased (0.322230 --> 0.317387).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2612285
	speed: 0.0177s/iter; left time: 196.9415s
Epoch: 6 cost time: 2.070366144180298
Epoch: 6, Steps: 118 Train Loss: 0.2700 (Forecasting Loss:0.2667 + XiCon Loss:3.2341 x Lambda(0.001)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2651
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2836951
	speed: 0.0177s/iter; left time: 194.6244s
Epoch: 7 cost time: 2.0801339149475098
Epoch: 7, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2655 + XiCon Loss:3.2350 x Lambda(0.001)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2651
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2595611
	speed: 0.0179s/iter; left time: 194.3977s
Epoch: 8 cost time: 2.104708671569824
Epoch: 8, Steps: 118 Train Loss: 0.2683 (Forecasting Loss:0.2651 + XiCon Loss:3.2350 x Lambda(0.001)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2583301
	speed: 0.0176s/iter; left time: 189.3788s
Epoch: 9 cost time: 2.07354736328125
Epoch: 9, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2648 + XiCon Loss:3.2344 x Lambda(0.001)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2658
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2526756
	speed: 0.0177s/iter; left time: 188.7285s
Epoch: 10 cost time: 2.0885469913482666
Epoch: 10, Steps: 118 Train Loss: 0.2678 (Forecasting Loss:0.2646 + XiCon Loss:3.2344 x Lambda(0.001)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.2657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2807881
	speed: 0.0182s/iter; left time: 191.5226s
Epoch: 11 cost time: 2.1294140815734863
Epoch: 11, Steps: 118 Train Loss: 0.2678 (Forecasting Loss:0.2645 + XiCon Loss:3.2327 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2638691
	speed: 0.0179s/iter; left time: 186.5188s
Epoch: 12 cost time: 2.153379440307617
Epoch: 12, Steps: 118 Train Loss: 0.2681 (Forecasting Loss:0.2649 + XiCon Loss:3.2337 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2652989
	speed: 0.0178s/iter; left time: 183.1195s
Epoch: 13 cost time: 2.0863535404205322
Epoch: 13, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2647 + XiCon Loss:3.2336 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2665467
	speed: 0.0182s/iter; left time: 184.6815s
Epoch: 14 cost time: 2.1235220432281494
Epoch: 14, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2650 + XiCon Loss:3.2326 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2562268
	speed: 0.0179s/iter; left time: 180.3734s
Epoch: 15 cost time: 2.1001651287078857
Epoch: 15, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2648 + XiCon Loss:3.2345 x Lambda(0.001)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18284614384174347, mae:0.348134845495224, mape:0.7116502523422241, mspe:20.3117733001709 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1828
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4438861
	speed: 0.0165s/iter; left time: 193.6105s
Epoch: 1 cost time: 1.9317512512207031
Epoch: 1, Steps: 118 Train Loss: 0.4780 (Forecasting Loss:0.4748 + XiCon Loss:3.2564 x Lambda(0.001)), Vali MSE Loss: 0.5074 Test MSE Loss: 0.4006
Validation loss decreased (inf --> 0.507355).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3170019
	speed: 0.0162s/iter; left time: 187.8038s
Epoch: 2 cost time: 1.9004466533660889
Epoch: 2, Steps: 118 Train Loss: 0.3507 (Forecasting Loss:0.3475 + XiCon Loss:3.2395 x Lambda(0.001)), Vali MSE Loss: 0.3515 Test MSE Loss: 0.2702
Validation loss decreased (0.507355 --> 0.351459).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2704147
	speed: 0.0163s/iter; left time: 186.8628s
Epoch: 3 cost time: 1.923060655593872
Epoch: 3, Steps: 118 Train Loss: 0.2854 (Forecasting Loss:0.2822 + XiCon Loss:3.1959 x Lambda(0.001)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.2723
Validation loss decreased (0.351459 --> 0.327545).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2672860
	speed: 0.0165s/iter; left time: 187.4908s
Epoch: 4 cost time: 1.9533591270446777
Epoch: 4, Steps: 118 Train Loss: 0.2775 (Forecasting Loss:0.2743 + XiCon Loss:3.1912 x Lambda(0.001)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2662
Validation loss decreased (0.327545 --> 0.319448).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2880265
	speed: 0.0169s/iter; left time: 189.7789s
Epoch: 5 cost time: 1.9852912425994873
Epoch: 5, Steps: 118 Train Loss: 0.2745 (Forecasting Loss:0.2713 + XiCon Loss:3.1899 x Lambda(0.001)), Vali MSE Loss: 0.3175 Test MSE Loss: 0.2610
Validation loss decreased (0.319448 --> 0.317549).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2725608
	speed: 0.0163s/iter; left time: 181.0552s
Epoch: 6 cost time: 1.9090852737426758
Epoch: 6, Steps: 118 Train Loss: 0.2735 (Forecasting Loss:0.2703 + XiCon Loss:3.1903 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2617
Validation loss decreased (0.317549 --> 0.316881).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2807886
	speed: 0.0161s/iter; left time: 176.9937s
Epoch: 7 cost time: 1.886782169342041
Epoch: 7, Steps: 118 Train Loss: 0.2726 (Forecasting Loss:0.2694 + XiCon Loss:3.1895 x Lambda(0.001)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2604
Validation loss decreased (0.316881 --> 0.316673).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2459455
	speed: 0.0161s/iter; left time: 175.1909s
Epoch: 8 cost time: 1.8926217555999756
Epoch: 8, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2690 + XiCon Loss:3.1888 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2596
Validation loss decreased (0.316673 --> 0.315226).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2667486
	speed: 0.0163s/iter; left time: 175.4093s
Epoch: 9 cost time: 1.9057068824768066
Epoch: 9, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1892 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2598
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2875518
	speed: 0.0166s/iter; left time: 176.3410s
Epoch: 10 cost time: 1.9332993030548096
Epoch: 10, Steps: 118 Train Loss: 0.2723 (Forecasting Loss:0.2691 + XiCon Loss:3.1904 x Lambda(0.001)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.2599
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2522607
	speed: 0.0167s/iter; left time: 175.1890s
Epoch: 11 cost time: 1.9422290325164795
Epoch: 11, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2690 + XiCon Loss:3.1898 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2598
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2676497
	speed: 0.0161s/iter; left time: 167.5414s
Epoch: 12 cost time: 1.8833162784576416
Epoch: 12, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2688 + XiCon Loss:3.1898 x Lambda(0.001)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2598
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2424699
	speed: 0.0161s/iter; left time: 165.4306s
Epoch: 13 cost time: 1.8843305110931396
Epoch: 13, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2687 + XiCon Loss:3.1897 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2598
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2775058
	speed: 0.0161s/iter; left time: 164.1277s
Epoch: 14 cost time: 1.8893804550170898
Epoch: 14, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2688 + XiCon Loss:3.1882 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2598
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2706166
	speed: 0.0168s/iter; left time: 168.5016s
Epoch: 15 cost time: 1.9711430072784424
Epoch: 15, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.1900 x Lambda(0.001)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.2598
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2600798
	speed: 0.0163s/iter; left time: 161.8305s
Epoch: 16 cost time: 1.90836501121521
Epoch: 16, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2690 + XiCon Loss:3.1895 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2597
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2624259
	speed: 0.0165s/iter; left time: 162.1966s
Epoch: 17 cost time: 1.9347405433654785
Epoch: 17, Steps: 118 Train Loss: 0.2723 (Forecasting Loss:0.2691 + XiCon Loss:3.1916 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2597
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2894003
	speed: 0.0163s/iter; left time: 157.8740s
Epoch: 18 cost time: 1.903757095336914
Epoch: 18, Steps: 118 Train Loss: 0.2723 (Forecasting Loss:0.2691 + XiCon Loss:3.1894 x Lambda(0.001)), Vali MSE Loss: 0.3162 Test MSE Loss: 0.2597
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17701034247875214, mae:0.34224194288253784, mape:0.7659193873405457, mspe:23.968276977539062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1841+-0.01086, MAE:0.3479+-0.00791, MAPE:0.7081+-0.04352, MSPE:21.4421+-2.90678, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4403
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.5616016
	speed: 0.0403s/iter; left time: 1068.7834s
	iters: 200, epoch: 1 | loss: 3.4769573
	speed: 0.0342s/iter; left time: 903.1664s
Epoch: 1 cost time: 9.736793756484985
Epoch: 1, Steps: 266 Train Loss: 3.5632 (Forecasting Loss:0.1678 + XiCon Loss:3.3954 x Lambda(1.0)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.0790
Validation loss decreased (inf --> 0.115001).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4949684
	speed: 0.0379s/iter; left time: 994.5785s
	iters: 200, epoch: 2 | loss: 3.5717003
	speed: 0.0368s/iter; left time: 961.8726s
Epoch: 2 cost time: 9.863286256790161
Epoch: 2, Steps: 266 Train Loss: 3.5150 (Forecasting Loss:0.1503 + XiCon Loss:3.3646 x Lambda(1.0)), Vali MSE Loss: 0.1119 Test MSE Loss: 0.0760
Validation loss decreased (0.115001 --> 0.111866).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5334897
	speed: 0.0387s/iter; left time: 1005.8691s
	iters: 200, epoch: 3 | loss: 3.3703578
	speed: 0.0357s/iter; left time: 924.5316s
Epoch: 3 cost time: 9.815273761749268
Epoch: 3, Steps: 266 Train Loss: 3.4177 (Forecasting Loss:0.1452 + XiCon Loss:3.2725 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0760
Validation loss decreased (0.111866 --> 0.109681).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3364174
	speed: 0.0369s/iter; left time: 948.0128s
	iters: 200, epoch: 4 | loss: 3.4028022
	speed: 0.0360s/iter; left time: 920.7185s
Epoch: 4 cost time: 9.684489250183105
Epoch: 4, Steps: 266 Train Loss: 3.4074 (Forecasting Loss:0.1433 + XiCon Loss:3.2642 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0748
Validation loss decreased (0.109681 --> 0.108609).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3964763
	speed: 0.0385s/iter; left time: 979.9641s
	iters: 200, epoch: 5 | loss: 3.4219818
	speed: 0.0366s/iter; left time: 926.0828s
Epoch: 5 cost time: 9.965756893157959
Epoch: 5, Steps: 266 Train Loss: 3.4053 (Forecasting Loss:0.1424 + XiCon Loss:3.2629 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0744
Validation loss decreased (0.108609 --> 0.107801).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3704965
	speed: 0.0387s/iter; left time: 974.3820s
	iters: 200, epoch: 6 | loss: 3.3657839
	speed: 0.0360s/iter; left time: 902.1351s
Epoch: 6 cost time: 9.857534646987915
Epoch: 6, Steps: 266 Train Loss: 3.3981 (Forecasting Loss:0.1421 + XiCon Loss:3.2561 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0742
Validation loss decreased (0.107801 --> 0.107691).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3419087
	speed: 0.0375s/iter; left time: 934.2068s
	iters: 200, epoch: 7 | loss: 3.3378794
	speed: 0.0358s/iter; left time: 888.9359s
Epoch: 7 cost time: 9.75205397605896
Epoch: 7, Steps: 266 Train Loss: 3.3954 (Forecasting Loss:0.1418 + XiCon Loss:3.2536 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
Validation loss decreased (0.107691 --> 0.107459).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4551685
	speed: 0.0374s/iter; left time: 921.5290s
	iters: 200, epoch: 8 | loss: 3.3699398
	speed: 0.0355s/iter; left time: 871.8822s
Epoch: 8 cost time: 9.641674280166626
Epoch: 8, Steps: 266 Train Loss: 3.3959 (Forecasting Loss:0.1417 + XiCon Loss:3.2542 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3585913
	speed: 0.0382s/iter; left time: 931.2842s
	iters: 200, epoch: 9 | loss: 3.3796816
	speed: 0.0361s/iter; left time: 875.0503s
Epoch: 9 cost time: 9.813073635101318
Epoch: 9, Steps: 266 Train Loss: 3.3951 (Forecasting Loss:0.1416 + XiCon Loss:3.2535 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0743
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3761332
	speed: 0.0393s/iter; left time: 948.0026s
	iters: 200, epoch: 10 | loss: 3.3625298
	speed: 0.0352s/iter; left time: 845.9252s
Epoch: 10 cost time: 9.835144519805908
Epoch: 10, Steps: 266 Train Loss: 3.3962 (Forecasting Loss:0.1416 + XiCon Loss:3.2546 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4422536
	speed: 0.0379s/iter; left time: 904.4780s
	iters: 200, epoch: 11 | loss: 3.4178777
	speed: 0.0359s/iter; left time: 851.7824s
Epoch: 11 cost time: 9.770268440246582
Epoch: 11, Steps: 266 Train Loss: 3.3910 (Forecasting Loss:0.1415 + XiCon Loss:3.2495 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3451240
	speed: 0.0386s/iter; left time: 909.0194s
	iters: 200, epoch: 12 | loss: 3.4225094
	speed: 0.0354s/iter; left time: 830.8941s
Epoch: 12 cost time: 9.738753318786621
Epoch: 12, Steps: 266 Train Loss: 3.3950 (Forecasting Loss:0.1415 + XiCon Loss:3.2535 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107459 --> 0.107446).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3731616
	speed: 0.0379s/iter; left time: 883.3114s
	iters: 200, epoch: 13 | loss: 3.3991263
	speed: 0.0366s/iter; left time: 849.8557s
Epoch: 13 cost time: 9.893470764160156
Epoch: 13, Steps: 266 Train Loss: 3.4001 (Forecasting Loss:0.1415 + XiCon Loss:3.2586 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3222678
	speed: 0.0421s/iter; left time: 969.9218s
	iters: 200, epoch: 14 | loss: 3.4374678
	speed: 0.0369s/iter; left time: 847.5257s
Epoch: 14 cost time: 10.268101930618286
Epoch: 14, Steps: 266 Train Loss: 3.3948 (Forecasting Loss:0.1415 + XiCon Loss:3.2533 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107446 --> 0.107388).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4557412
	speed: 0.0388s/iter; left time: 883.5514s
	iters: 200, epoch: 15 | loss: 3.3253732
	speed: 0.0354s/iter; left time: 801.7929s
Epoch: 15 cost time: 9.812982320785522
Epoch: 15, Steps: 266 Train Loss: 3.3943 (Forecasting Loss:0.1415 + XiCon Loss:3.2528 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.5100060
	speed: 0.0379s/iter; left time: 852.9154s
	iters: 200, epoch: 16 | loss: 3.4558458
	speed: 0.0360s/iter; left time: 806.7890s
Epoch: 16 cost time: 9.781332731246948
Epoch: 16, Steps: 266 Train Loss: 3.3927 (Forecasting Loss:0.1415 + XiCon Loss:3.2512 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3577814
	speed: 0.0381s/iter; left time: 848.3645s
	iters: 200, epoch: 17 | loss: 3.4202912
	speed: 0.0356s/iter; left time: 788.1050s
Epoch: 17 cost time: 9.727062225341797
Epoch: 17, Steps: 266 Train Loss: 3.3942 (Forecasting Loss:0.1415 + XiCon Loss:3.2527 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3855681
	speed: 0.0383s/iter; left time: 842.4099s
	iters: 200, epoch: 18 | loss: 3.3689625
	speed: 0.0362s/iter; left time: 792.9265s
Epoch: 18 cost time: 9.822244882583618
Epoch: 18, Steps: 266 Train Loss: 3.3901 (Forecasting Loss:0.1415 + XiCon Loss:3.2485 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4431119
	speed: 0.0382s/iter; left time: 829.7991s
	iters: 200, epoch: 19 | loss: 3.3265088
	speed: 0.0363s/iter; left time: 784.7202s
Epoch: 19 cost time: 9.862694501876831
Epoch: 19, Steps: 266 Train Loss: 3.3948 (Forecasting Loss:0.1415 + XiCon Loss:3.2533 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3730276
	speed: 0.0394s/iter; left time: 845.1229s
	iters: 200, epoch: 20 | loss: 3.3265712
	speed: 0.0363s/iter; left time: 773.8981s
Epoch: 20 cost time: 10.024271726608276
Epoch: 20, Steps: 266 Train Loss: 3.3926 (Forecasting Loss:0.1415 + XiCon Loss:3.2512 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3554032
	speed: 0.0382s/iter; left time: 808.4005s
	iters: 200, epoch: 21 | loss: 3.5135167
	speed: 0.0358s/iter; left time: 754.2114s
Epoch: 21 cost time: 9.789321422576904
Epoch: 21, Steps: 266 Train Loss: 3.3930 (Forecasting Loss:0.1415 + XiCon Loss:3.2515 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5141277
	speed: 0.0387s/iter; left time: 809.3775s
	iters: 200, epoch: 22 | loss: 3.3917308
	speed: 0.0355s/iter; left time: 739.6787s
Epoch: 22 cost time: 9.778631210327148
Epoch: 22, Steps: 266 Train Loss: 3.3950 (Forecasting Loss:0.1414 + XiCon Loss:3.2535 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107388 --> 0.107371).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3377974
	speed: 0.0382s/iter; left time: 788.5407s
	iters: 200, epoch: 23 | loss: 3.3832078
	speed: 0.0357s/iter; left time: 733.1026s
Epoch: 23 cost time: 9.718129396438599
Epoch: 23, Steps: 266 Train Loss: 3.3974 (Forecasting Loss:0.1415 + XiCon Loss:3.2558 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3982430
	speed: 0.0385s/iter; left time: 784.2288s
	iters: 200, epoch: 24 | loss: 3.4089496
	speed: 0.0363s/iter; left time: 735.6233s
Epoch: 24 cost time: 9.869326829910278
Epoch: 24, Steps: 266 Train Loss: 3.3940 (Forecasting Loss:0.1415 + XiCon Loss:3.2525 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4508996
	speed: 0.0389s/iter; left time: 781.8333s
	iters: 200, epoch: 25 | loss: 3.3138785
	speed: 0.0370s/iter; left time: 741.6005s
Epoch: 25 cost time: 9.98726201057434
Epoch: 25, Steps: 266 Train Loss: 3.3952 (Forecasting Loss:0.1415 + XiCon Loss:3.2537 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3444135
	speed: 0.0385s/iter; left time: 765.2307s
	iters: 200, epoch: 26 | loss: 3.3530200
	speed: 0.0361s/iter; left time: 713.8908s
Epoch: 26 cost time: 9.870101690292358
Epoch: 26, Steps: 266 Train Loss: 3.3948 (Forecasting Loss:0.1415 + XiCon Loss:3.2534 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.4608319
	speed: 0.0379s/iter; left time: 742.6289s
	iters: 200, epoch: 27 | loss: 3.3419902
	speed: 0.0355s/iter; left time: 690.7567s
Epoch: 27 cost time: 9.736613750457764
Epoch: 27, Steps: 266 Train Loss: 3.3952 (Forecasting Loss:0.1415 + XiCon Loss:3.2537 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.3210759
	speed: 0.0385s/iter; left time: 744.0073s
	iters: 200, epoch: 28 | loss: 3.4284163
	speed: 0.0369s/iter; left time: 708.3854s
Epoch: 28 cost time: 9.94129729270935
Epoch: 28, Steps: 266 Train Loss: 3.3906 (Forecasting Loss:0.1415 + XiCon Loss:3.2491 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.3819139
	speed: 0.0393s/iter; left time: 747.8428s
	iters: 200, epoch: 29 | loss: 3.4747148
	speed: 0.0364s/iter; left time: 690.3367s
Epoch: 29 cost time: 10.014632940292358
Epoch: 29, Steps: 266 Train Loss: 3.3956 (Forecasting Loss:0.1415 + XiCon Loss:3.2541 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.4186802
	speed: 0.0382s/iter; left time: 717.8832s
	iters: 200, epoch: 30 | loss: 3.3350513
	speed: 0.0354s/iter; left time: 661.9038s
Epoch: 30 cost time: 9.710510015487671
Epoch: 30, Steps: 266 Train Loss: 3.3969 (Forecasting Loss:0.1415 + XiCon Loss:3.2554 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.3673885
	speed: 0.0374s/iter; left time: 692.8206s
	iters: 200, epoch: 31 | loss: 3.3619173
	speed: 0.0357s/iter; left time: 658.3302s
Epoch: 31 cost time: 9.75063443183899
Epoch: 31, Steps: 266 Train Loss: 3.3978 (Forecasting Loss:0.1415 + XiCon Loss:3.2563 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.3592176
	speed: 0.0377s/iter; left time: 687.6737s
	iters: 200, epoch: 32 | loss: 3.4964414
	speed: 0.0362s/iter; left time: 656.3036s
Epoch: 32 cost time: 9.798822164535522
Epoch: 32, Steps: 266 Train Loss: 3.3933 (Forecasting Loss:0.1415 + XiCon Loss:3.2518 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0264680664986372, mae:0.12200114876031876, mape:0.098622165620327, mspe:0.01965632475912571 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.2330
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.5780823
	speed: 0.0389s/iter; left time: 1030.8327s
	iters: 200, epoch: 1 | loss: 3.4980323
	speed: 0.0347s/iter; left time: 915.2777s
Epoch: 1 cost time: 9.658264636993408
Epoch: 1, Steps: 266 Train Loss: 3.5731 (Forecasting Loss:0.1670 + XiCon Loss:3.4061 x Lambda(1.0)), Vali MSE Loss: 0.1154 Test MSE Loss: 0.0777
Validation loss decreased (inf --> 0.115383).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.6708727
	speed: 0.0371s/iter; left time: 974.0435s
	iters: 200, epoch: 2 | loss: 3.5625312
	speed: 0.0356s/iter; left time: 930.4348s
Epoch: 2 cost time: 9.595714092254639
Epoch: 2, Steps: 266 Train Loss: 3.5879 (Forecasting Loss:0.1504 + XiCon Loss:3.4375 x Lambda(1.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.0762
Validation loss decreased (0.115383 --> 0.111048).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4686968
	speed: 0.0377s/iter; left time: 979.7876s
	iters: 200, epoch: 3 | loss: 3.3977239
	speed: 0.0351s/iter; left time: 908.0383s
Epoch: 3 cost time: 9.689592123031616
Epoch: 3, Steps: 266 Train Loss: 3.4406 (Forecasting Loss:0.1454 + XiCon Loss:3.2952 x Lambda(1.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.0752
Validation loss decreased (0.111048 --> 0.108839).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4043326
	speed: 0.0377s/iter; left time: 968.6232s
	iters: 200, epoch: 4 | loss: 3.3234127
	speed: 0.0353s/iter; left time: 903.6969s
Epoch: 4 cost time: 9.707357406616211
Epoch: 4, Steps: 266 Train Loss: 3.3820 (Forecasting Loss:0.1433 + XiCon Loss:3.2387 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0749
Validation loss decreased (0.108839 --> 0.108380).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3208649
	speed: 0.0373s/iter; left time: 948.3181s
	iters: 200, epoch: 5 | loss: 3.4953382
	speed: 0.0357s/iter; left time: 905.2316s
Epoch: 5 cost time: 9.71232008934021
Epoch: 5, Steps: 266 Train Loss: 3.3740 (Forecasting Loss:0.1426 + XiCon Loss:3.2314 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0747
Validation loss decreased (0.108380 --> 0.107975).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3096952
	speed: 0.0382s/iter; left time: 960.6773s
	iters: 200, epoch: 6 | loss: 3.3324409
	speed: 0.0347s/iter; left time: 870.9958s
Epoch: 6 cost time: 9.687872648239136
Epoch: 6, Steps: 266 Train Loss: 3.3711 (Forecasting Loss:0.1421 + XiCon Loss:3.2290 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0743
Validation loss decreased (0.107975 --> 0.107809).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4296300
	speed: 0.0376s/iter; left time: 936.5452s
	iters: 200, epoch: 7 | loss: 3.4024212
	speed: 0.0354s/iter; left time: 878.9040s
Epoch: 7 cost time: 9.63736081123352
Epoch: 7, Steps: 266 Train Loss: 3.3696 (Forecasting Loss:0.1418 + XiCon Loss:3.2278 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107809 --> 0.107517).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3384821
	speed: 0.0379s/iter; left time: 933.6539s
	iters: 200, epoch: 8 | loss: 3.4410865
	speed: 0.0357s/iter; left time: 876.8165s
Epoch: 8 cost time: 9.8073251247406
Epoch: 8, Steps: 266 Train Loss: 3.3671 (Forecasting Loss:0.1416 + XiCon Loss:3.2254 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3509483
	speed: 0.0377s/iter; left time: 917.8467s
	iters: 200, epoch: 9 | loss: 3.4079552
	speed: 0.0358s/iter; left time: 869.6120s
Epoch: 9 cost time: 9.73490309715271
Epoch: 9, Steps: 266 Train Loss: 3.3656 (Forecasting Loss:0.1416 + XiCon Loss:3.2240 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107517 --> 0.107510).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3334885
	speed: 0.0378s/iter; left time: 911.5177s
	iters: 200, epoch: 10 | loss: 3.4742277
	speed: 0.0353s/iter; left time: 846.4076s
Epoch: 10 cost time: 9.719038486480713
Epoch: 10, Steps: 266 Train Loss: 3.3679 (Forecasting Loss:0.1416 + XiCon Loss:3.2263 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107510 --> 0.107502).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4060733
	speed: 0.0368s/iter; left time: 877.7457s
	iters: 200, epoch: 11 | loss: 3.3415642
	speed: 0.0356s/iter; left time: 845.9339s
Epoch: 11 cost time: 9.552292585372925
Epoch: 11, Steps: 266 Train Loss: 3.3606 (Forecasting Loss:0.1415 + XiCon Loss:3.2191 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107502 --> 0.107463).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4925632
	speed: 0.0376s/iter; left time: 887.1631s
	iters: 200, epoch: 12 | loss: 3.4568949
	speed: 0.0358s/iter; left time: 841.0558s
Epoch: 12 cost time: 9.72335147857666
Epoch: 12, Steps: 266 Train Loss: 3.3624 (Forecasting Loss:0.1414 + XiCon Loss:3.2210 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107463 --> 0.107460).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3290632
	speed: 0.0379s/iter; left time: 884.5469s
	iters: 200, epoch: 13 | loss: 3.3271315
	speed: 0.0357s/iter; left time: 829.1785s
Epoch: 13 cost time: 9.778807640075684
Epoch: 13, Steps: 266 Train Loss: 3.3645 (Forecasting Loss:0.1415 + XiCon Loss:3.2230 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107460 --> 0.107453).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3257914
	speed: 0.0376s/iter; left time: 867.0422s
	iters: 200, epoch: 14 | loss: 3.3588352
	speed: 0.0358s/iter; left time: 821.0356s
Epoch: 14 cost time: 9.749770402908325
Epoch: 14, Steps: 266 Train Loss: 3.3650 (Forecasting Loss:0.1415 + XiCon Loss:3.2235 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2792022
	speed: 0.0375s/iter; left time: 854.5637s
	iters: 200, epoch: 15 | loss: 3.4343824
	speed: 0.0345s/iter; left time: 783.4283s
Epoch: 15 cost time: 9.551810503005981
Epoch: 15, Steps: 266 Train Loss: 3.3611 (Forecasting Loss:0.1416 + XiCon Loss:3.2196 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107453 --> 0.107453).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2979600
	speed: 0.0383s/iter; left time: 863.1959s
	iters: 200, epoch: 16 | loss: 3.3981419
	speed: 0.0359s/iter; left time: 803.5872s
Epoch: 16 cost time: 9.760649681091309
Epoch: 16, Steps: 266 Train Loss: 3.3602 (Forecasting Loss:0.1415 + XiCon Loss:3.2188 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4143147
	speed: 0.0380s/iter; left time: 846.1459s
	iters: 200, epoch: 17 | loss: 3.4702506
	speed: 0.0355s/iter; left time: 786.4953s
Epoch: 17 cost time: 9.75725531578064
Epoch: 17, Steps: 266 Train Loss: 3.3692 (Forecasting Loss:0.1415 + XiCon Loss:3.2277 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107453 --> 0.107439).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3146167
	speed: 0.0382s/iter; left time: 839.8271s
	iters: 200, epoch: 18 | loss: 3.4151673
	speed: 0.0359s/iter; left time: 784.6004s
Epoch: 18 cost time: 9.788816213607788
Epoch: 18, Steps: 266 Train Loss: 3.3605 (Forecasting Loss:0.1415 + XiCon Loss:3.2190 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107439 --> 0.107380).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3733959
	speed: 0.0382s/iter; left time: 830.0093s
	iters: 200, epoch: 19 | loss: 3.4852734
	speed: 0.0350s/iter; left time: 756.1552s
Epoch: 19 cost time: 9.615338802337646
Epoch: 19, Steps: 266 Train Loss: 3.3704 (Forecasting Loss:0.1414 + XiCon Loss:3.2290 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3393521
	speed: 0.0373s/iter; left time: 800.3329s
	iters: 200, epoch: 20 | loss: 3.4486139
	speed: 0.0353s/iter; left time: 752.9820s
Epoch: 20 cost time: 9.632773160934448
Epoch: 20, Steps: 266 Train Loss: 3.3651 (Forecasting Loss:0.1415 + XiCon Loss:3.2237 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107380 --> 0.107371).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3238931
	speed: 0.0382s/iter; left time: 808.7440s
	iters: 200, epoch: 21 | loss: 3.4356437
	speed: 0.0364s/iter; left time: 768.3040s
Epoch: 21 cost time: 9.846864700317383
Epoch: 21, Steps: 266 Train Loss: 3.3713 (Forecasting Loss:0.1415 + XiCon Loss:3.2298 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.4769311
	speed: 0.0372s/iter; left time: 777.6079s
	iters: 200, epoch: 22 | loss: 3.3753006
	speed: 0.0347s/iter; left time: 722.9394s
Epoch: 22 cost time: 9.587367057800293
Epoch: 22, Steps: 266 Train Loss: 3.3687 (Forecasting Loss:0.1415 + XiCon Loss:3.2273 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3234346
	speed: 0.0377s/iter; left time: 779.0456s
	iters: 200, epoch: 23 | loss: 3.3592060
	speed: 0.0360s/iter; left time: 739.8440s
Epoch: 23 cost time: 9.77790379524231
Epoch: 23, Steps: 266 Train Loss: 3.3668 (Forecasting Loss:0.1415 + XiCon Loss:3.2253 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2941303
	speed: 0.0380s/iter; left time: 774.2126s
	iters: 200, epoch: 24 | loss: 3.3922675
	speed: 0.0363s/iter; left time: 735.8063s
Epoch: 24 cost time: 9.796374797821045
Epoch: 24, Steps: 266 Train Loss: 3.3673 (Forecasting Loss:0.1415 + XiCon Loss:3.2258 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4339356
	speed: 0.0384s/iter; left time: 772.3726s
	iters: 200, epoch: 25 | loss: 3.3385522
	speed: 0.0365s/iter; left time: 730.4317s
Epoch: 25 cost time: 9.886973142623901
Epoch: 25, Steps: 266 Train Loss: 3.3630 (Forecasting Loss:0.1415 + XiCon Loss:3.2215 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3251538
	speed: 0.0379s/iter; left time: 752.7090s
	iters: 200, epoch: 26 | loss: 3.3114324
	speed: 0.0355s/iter; left time: 700.2715s
Epoch: 26 cost time: 9.654531955718994
Epoch: 26, Steps: 266 Train Loss: 3.3646 (Forecasting Loss:0.1415 + XiCon Loss:3.2232 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.4869795
	speed: 0.0375s/iter; left time: 733.6217s
	iters: 200, epoch: 27 | loss: 3.2800770
	speed: 0.0359s/iter; left time: 700.4607s
Epoch: 27 cost time: 9.730865478515625
Epoch: 27, Steps: 266 Train Loss: 3.3680 (Forecasting Loss:0.1415 + XiCon Loss:3.2266 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.3397255
	speed: 0.0379s/iter; left time: 733.1172s
	iters: 200, epoch: 28 | loss: 3.3212452
	speed: 0.0355s/iter; left time: 682.4980s
Epoch: 28 cost time: 9.689921140670776
Epoch: 28, Steps: 266 Train Loss: 3.3659 (Forecasting Loss:0.1415 + XiCon Loss:3.2244 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.3292072
	speed: 0.0378s/iter; left time: 720.5484s
	iters: 200, epoch: 29 | loss: 3.3325486
	speed: 0.0350s/iter; left time: 663.9060s
Epoch: 29 cost time: 9.642349481582642
Epoch: 29, Steps: 266 Train Loss: 3.3620 (Forecasting Loss:0.1415 + XiCon Loss:3.2205 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.3346708
	speed: 0.0372s/iter; left time: 699.6252s
	iters: 200, epoch: 30 | loss: 3.4297578
	speed: 0.0360s/iter; left time: 672.9380s
Epoch: 30 cost time: 9.755263328552246
Epoch: 30, Steps: 266 Train Loss: 3.3643 (Forecasting Loss:0.1415 + XiCon Loss:3.2228 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0263561699539423, mae:0.12182634323835373, mape:0.0984584167599678, mspe:0.019574496895074844 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.3913
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.5577345
	speed: 0.0384s/iter; left time: 1018.2978s
	iters: 200, epoch: 1 | loss: 3.4771633
	speed: 0.0349s/iter; left time: 920.8775s
Epoch: 1 cost time: 9.685420751571655
Epoch: 1, Steps: 266 Train Loss: 3.5437 (Forecasting Loss:0.1689 + XiCon Loss:3.3749 x Lambda(1.0)), Vali MSE Loss: 0.1183 Test MSE Loss: 0.0809
Validation loss decreased (inf --> 0.118278).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.9348333
	speed: 0.0379s/iter; left time: 994.3635s
	iters: 200, epoch: 2 | loss: 3.4755793
	speed: 0.0362s/iter; left time: 946.7231s
Epoch: 2 cost time: 9.809300661087036
Epoch: 2, Steps: 266 Train Loss: 3.6449 (Forecasting Loss:0.1509 + XiCon Loss:3.4940 x Lambda(1.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.0784
Validation loss decreased (0.118278 --> 0.113593).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3367457
	speed: 0.0375s/iter; left time: 973.7204s
	iters: 200, epoch: 3 | loss: 3.7250614
	speed: 0.0354s/iter; left time: 914.6989s
Epoch: 3 cost time: 9.658864974975586
Epoch: 3, Steps: 266 Train Loss: 3.6138 (Forecasting Loss:0.1456 + XiCon Loss:3.4683 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0754
Validation loss decreased (0.113593 --> 0.109705).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.7183623
	speed: 0.0369s/iter; left time: 947.9530s
	iters: 200, epoch: 4 | loss: 3.5312078
	speed: 0.0348s/iter; left time: 890.8337s
Epoch: 4 cost time: 9.550301551818848
Epoch: 4, Steps: 266 Train Loss: 3.6131 (Forecasting Loss:0.1436 + XiCon Loss:3.4695 x Lambda(1.0)), Vali MSE Loss: 0.1085 Test MSE Loss: 0.0749
Validation loss decreased (0.109705 --> 0.108515).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.6131368
	speed: 0.0379s/iter; left time: 964.9009s
	iters: 200, epoch: 5 | loss: 3.5976732
	speed: 0.0350s/iter; left time: 886.5537s
Epoch: 5 cost time: 9.618874788284302
Epoch: 5, Steps: 266 Train Loss: 3.5447 (Forecasting Loss:0.1425 + XiCon Loss:3.4022 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0744
Validation loss decreased (0.108515 --> 0.108101).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.6766253
	speed: 0.0377s/iter; left time: 948.0451s
	iters: 200, epoch: 6 | loss: 3.5866654
	speed: 0.0353s/iter; left time: 884.3448s
Epoch: 6 cost time: 9.67913269996643
Epoch: 6, Steps: 266 Train Loss: 3.5569 (Forecasting Loss:0.1420 + XiCon Loss:3.4149 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0744
Validation loss decreased (0.108101 --> 0.107619).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5677123
	speed: 0.0373s/iter; left time: 928.9776s
	iters: 200, epoch: 7 | loss: 3.5147703
	speed: 0.0351s/iter; left time: 871.0234s
Epoch: 7 cost time: 9.616415739059448
Epoch: 7, Steps: 266 Train Loss: 3.5239 (Forecasting Loss:0.1417 + XiCon Loss:3.3823 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0742
Validation loss decreased (0.107619 --> 0.107581).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4791882
	speed: 0.0374s/iter; left time: 922.0806s
	iters: 200, epoch: 8 | loss: 3.3866327
	speed: 0.0360s/iter; left time: 883.8861s
Epoch: 8 cost time: 9.721490383148193
Epoch: 8, Steps: 266 Train Loss: 3.4912 (Forecasting Loss:0.1416 + XiCon Loss:3.3496 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107581 --> 0.107422).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3284383
	speed: 0.0376s/iter; left time: 916.5014s
	iters: 200, epoch: 9 | loss: 3.4651461
	speed: 0.0351s/iter; left time: 852.0916s
Epoch: 9 cost time: 9.63126826286316
Epoch: 9, Steps: 266 Train Loss: 3.4810 (Forecasting Loss:0.1416 + XiCon Loss:3.3395 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.5244055
	speed: 0.0384s/iter; left time: 924.9677s
	iters: 200, epoch: 10 | loss: 3.5809937
	speed: 0.0358s/iter; left time: 859.4012s
Epoch: 10 cost time: 9.708296775817871
Epoch: 10, Steps: 266 Train Loss: 3.4794 (Forecasting Loss:0.1415 + XiCon Loss:3.3379 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107422 --> 0.107399).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.6808484
	speed: 0.0382s/iter; left time: 910.6788s
	iters: 200, epoch: 11 | loss: 3.4883327
	speed: 0.0356s/iter; left time: 845.5706s
Epoch: 11 cost time: 9.70377516746521
Epoch: 11, Steps: 266 Train Loss: 3.4727 (Forecasting Loss:0.1415 + XiCon Loss:3.3311 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4811265
	speed: 0.0380s/iter; left time: 896.3137s
	iters: 200, epoch: 12 | loss: 3.5166247
	speed: 0.0358s/iter; left time: 840.8881s
Epoch: 12 cost time: 9.755795955657959
Epoch: 12, Steps: 266 Train Loss: 3.4711 (Forecasting Loss:0.1415 + XiCon Loss:3.3296 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4251864
	speed: 0.0378s/iter; left time: 881.6582s
	iters: 200, epoch: 13 | loss: 3.3902044
	speed: 0.0344s/iter; left time: 798.5137s
Epoch: 13 cost time: 9.532789945602417
Epoch: 13, Steps: 266 Train Loss: 3.4712 (Forecasting Loss:0.1415 + XiCon Loss:3.3298 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4731524
	speed: 0.0380s/iter; left time: 876.6142s
	iters: 200, epoch: 14 | loss: 3.5133572
	speed: 0.0353s/iter; left time: 809.9564s
Epoch: 14 cost time: 9.726891040802002
Epoch: 14, Steps: 266 Train Loss: 3.4785 (Forecasting Loss:0.1415 + XiCon Loss:3.3369 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.5273335
	speed: 0.0377s/iter; left time: 857.5857s
	iters: 200, epoch: 15 | loss: 3.6195884
	speed: 0.0360s/iter; left time: 815.5935s
Epoch: 15 cost time: 9.794825077056885
Epoch: 15, Steps: 266 Train Loss: 3.4782 (Forecasting Loss:0.1415 + XiCon Loss:3.3367 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.5668297
	speed: 0.0377s/iter; left time: 848.3907s
	iters: 200, epoch: 16 | loss: 3.3333213
	speed: 0.0352s/iter; left time: 788.9475s
Epoch: 16 cost time: 9.596036672592163
Epoch: 16, Steps: 266 Train Loss: 3.4755 (Forecasting Loss:0.1415 + XiCon Loss:3.3340 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.5810087
	speed: 0.0380s/iter; left time: 844.2875s
	iters: 200, epoch: 17 | loss: 3.5663314
	speed: 0.0351s/iter; left time: 777.8554s
Epoch: 17 cost time: 9.61715054512024
Epoch: 17, Steps: 266 Train Loss: 3.4834 (Forecasting Loss:0.1415 + XiCon Loss:3.3419 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107399 --> 0.107381).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4883595
	speed: 0.0376s/iter; left time: 826.8804s
	iters: 200, epoch: 18 | loss: 3.4141021
	speed: 0.0356s/iter; left time: 778.1052s
Epoch: 18 cost time: 9.74263858795166
Epoch: 18, Steps: 266 Train Loss: 3.4803 (Forecasting Loss:0.1414 + XiCon Loss:3.3389 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4367862
	speed: 0.0381s/iter; left time: 826.2420s
	iters: 200, epoch: 19 | loss: 3.5418100
	speed: 0.0358s/iter; left time: 774.2318s
Epoch: 19 cost time: 9.810209035873413
Epoch: 19, Steps: 266 Train Loss: 3.4764 (Forecasting Loss:0.1414 + XiCon Loss:3.3350 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.5182216
	speed: 0.0376s/iter; left time: 805.6909s
	iters: 200, epoch: 20 | loss: 3.5071061
	speed: 0.0351s/iter; left time: 748.6159s
Epoch: 20 cost time: 9.62510895729065
Epoch: 20, Steps: 266 Train Loss: 3.4779 (Forecasting Loss:0.1415 + XiCon Loss:3.3364 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4616334
	speed: 0.0380s/iter; left time: 804.4060s
	iters: 200, epoch: 21 | loss: 3.4802215
	speed: 0.0344s/iter; left time: 724.9035s
Epoch: 21 cost time: 9.637425422668457
Epoch: 21, Steps: 266 Train Loss: 3.4781 (Forecasting Loss:0.1415 + XiCon Loss:3.3365 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5259330
	speed: 0.0376s/iter; left time: 786.5045s
	iters: 200, epoch: 22 | loss: 3.4264035
	speed: 0.0359s/iter; left time: 746.7144s
Epoch: 22 cost time: 9.780454397201538
Epoch: 22, Steps: 266 Train Loss: 3.4758 (Forecasting Loss:0.1415 + XiCon Loss:3.3343 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.5302386
	speed: 0.0378s/iter; left time: 781.4153s
	iters: 200, epoch: 23 | loss: 3.3877537
	speed: 0.0356s/iter; left time: 731.7334s
Epoch: 23 cost time: 9.72962212562561
Epoch: 23, Steps: 266 Train Loss: 3.4671 (Forecasting Loss:0.1415 + XiCon Loss:3.3256 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4933212
	speed: 0.0374s/iter; left time: 762.8283s
	iters: 200, epoch: 24 | loss: 3.5379601
	speed: 0.0349s/iter; left time: 708.8487s
Epoch: 24 cost time: 9.589995384216309
Epoch: 24, Steps: 266 Train Loss: 3.4747 (Forecasting Loss:0.1415 + XiCon Loss:3.3332 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3375766
	speed: 0.0373s/iter; left time: 749.4919s
	iters: 200, epoch: 25 | loss: 3.5782826
	speed: 0.0352s/iter; left time: 703.6619s
Epoch: 25 cost time: 9.590847969055176
Epoch: 25, Steps: 266 Train Loss: 3.4667 (Forecasting Loss:0.1415 + XiCon Loss:3.3252 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.7735903
	speed: 0.0374s/iter; left time: 742.9941s
	iters: 200, epoch: 26 | loss: 3.3688142
	speed: 0.0366s/iter; left time: 722.3043s
Epoch: 26 cost time: 9.782812118530273
Epoch: 26, Steps: 266 Train Loss: 3.4758 (Forecasting Loss:0.1415 + XiCon Loss:3.3343 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.5428617
	speed: 0.0377s/iter; left time: 737.9210s
	iters: 200, epoch: 27 | loss: 3.6598859
	speed: 0.0355s/iter; left time: 692.3597s
Epoch: 27 cost time: 9.701735019683838
Epoch: 27, Steps: 266 Train Loss: 3.4781 (Forecasting Loss:0.1415 + XiCon Loss:3.3366 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026429269462823868, mae:0.12201058119535446, mape:0.09854533523321152, mspe:0.01956813409924507 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.8011
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.6105068
	speed: 0.0376s/iter; left time: 995.3939s
	iters: 200, epoch: 1 | loss: 3.4606495
	speed: 0.0351s/iter; left time: 926.5681s
Epoch: 1 cost time: 9.6143798828125
Epoch: 1, Steps: 266 Train Loss: 3.5686 (Forecasting Loss:0.1668 + XiCon Loss:3.4017 x Lambda(1.0)), Vali MSE Loss: 0.1138 Test MSE Loss: 0.0788
Validation loss decreased (inf --> 0.113842).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.8020668
	speed: 0.0385s/iter; left time: 1009.0890s
	iters: 200, epoch: 2 | loss: 3.7855022
	speed: 0.0356s/iter; left time: 931.4887s
Epoch: 2 cost time: 9.763224840164185
Epoch: 2, Steps: 266 Train Loss: 3.7170 (Forecasting Loss:0.1511 + XiCon Loss:3.5659 x Lambda(1.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.0766
Validation loss decreased (0.113842 --> 0.110484).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.6478789
	speed: 0.0368s/iter; left time: 955.7608s
	iters: 200, epoch: 3 | loss: 3.4813845
	speed: 0.0351s/iter; left time: 908.5540s
Epoch: 3 cost time: 9.561963558197021
Epoch: 3, Steps: 266 Train Loss: 3.5443 (Forecasting Loss:0.1452 + XiCon Loss:3.3991 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.0752
Validation loss decreased (0.110484 --> 0.109100).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.5139589
	speed: 0.0383s/iter; left time: 985.3875s
	iters: 200, epoch: 4 | loss: 3.4021952
	speed: 0.0359s/iter; left time: 918.1589s
Epoch: 4 cost time: 9.781991958618164
Epoch: 4, Steps: 266 Train Loss: 3.4581 (Forecasting Loss:0.1436 + XiCon Loss:3.3145 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0746
Validation loss decreased (0.109100 --> 0.108035).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4308293
	speed: 0.0379s/iter; left time: 965.3112s
	iters: 200, epoch: 5 | loss: 3.5987010
	speed: 0.0356s/iter; left time: 902.8749s
Epoch: 5 cost time: 9.664474487304688
Epoch: 5, Steps: 266 Train Loss: 3.4255 (Forecasting Loss:0.1425 + XiCon Loss:3.2830 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0741
Validation loss decreased (0.108035 --> 0.107724).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4947369
	speed: 0.0375s/iter; left time: 944.1495s
	iters: 200, epoch: 6 | loss: 3.3630164
	speed: 0.0356s/iter; left time: 892.2175s
Epoch: 6 cost time: 9.674334049224854
Epoch: 6, Steps: 266 Train Loss: 3.4152 (Forecasting Loss:0.1421 + XiCon Loss:3.2731 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107724 --> 0.107586).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4629805
	speed: 0.0374s/iter; left time: 932.1654s
	iters: 200, epoch: 7 | loss: 3.4541142
	speed: 0.0348s/iter; left time: 864.3067s
Epoch: 7 cost time: 9.568402290344238
Epoch: 7, Steps: 266 Train Loss: 3.4090 (Forecasting Loss:0.1419 + XiCon Loss:3.2671 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107586 --> 0.107445).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4836693
	speed: 0.0373s/iter; left time: 919.5197s
	iters: 200, epoch: 8 | loss: 3.3797781
	speed: 0.0351s/iter; left time: 861.5262s
Epoch: 8 cost time: 9.586345911026001
Epoch: 8, Steps: 266 Train Loss: 3.4134 (Forecasting Loss:0.1417 + XiCon Loss:3.2717 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3656819
	speed: 0.0380s/iter; left time: 925.3201s
	iters: 200, epoch: 9 | loss: 3.3505216
	speed: 0.0358s/iter; left time: 868.8990s
Epoch: 9 cost time: 9.71880030632019
Epoch: 9, Steps: 266 Train Loss: 3.4055 (Forecasting Loss:0.1416 + XiCon Loss:3.2639 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4723270
	speed: 0.0370s/iter; left time: 891.7720s
	iters: 200, epoch: 10 | loss: 3.3596134
	speed: 0.0340s/iter; left time: 817.4299s
Epoch: 10 cost time: 9.454878330230713
Epoch: 10, Steps: 266 Train Loss: 3.4098 (Forecasting Loss:0.1416 + XiCon Loss:3.2682 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107445 --> 0.107432).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4552026
	speed: 0.0373s/iter; left time: 890.0827s
	iters: 200, epoch: 11 | loss: 3.5213244
	speed: 0.0360s/iter; left time: 853.9642s
Epoch: 11 cost time: 9.715761661529541
Epoch: 11, Steps: 266 Train Loss: 3.4115 (Forecasting Loss:0.1415 + XiCon Loss:3.2700 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107432 --> 0.107344).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3268209
	speed: 0.0367s/iter; left time: 866.1016s
	iters: 200, epoch: 12 | loss: 3.3815012
	speed: 0.0356s/iter; left time: 836.1816s
Epoch: 12 cost time: 9.565893411636353
Epoch: 12, Steps: 266 Train Loss: 3.4075 (Forecasting Loss:0.1416 + XiCon Loss:3.2659 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3822794
	speed: 0.0376s/iter; left time: 877.0324s
	iters: 200, epoch: 13 | loss: 3.3941622
	speed: 0.0352s/iter; left time: 817.4944s
Epoch: 13 cost time: 9.668119668960571
Epoch: 13, Steps: 266 Train Loss: 3.4078 (Forecasting Loss:0.1416 + XiCon Loss:3.2662 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3424220
	speed: 0.0375s/iter; left time: 864.8860s
	iters: 200, epoch: 14 | loss: 3.3559990
	speed: 0.0358s/iter; left time: 821.3032s
Epoch: 14 cost time: 9.720024108886719
Epoch: 14, Steps: 266 Train Loss: 3.4076 (Forecasting Loss:0.1415 + XiCon Loss:3.2661 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4674623
	speed: 0.0376s/iter; left time: 856.9607s
	iters: 200, epoch: 15 | loss: 3.4528415
	speed: 0.0349s/iter; left time: 792.1957s
Epoch: 15 cost time: 9.595834732055664
Epoch: 15, Steps: 266 Train Loss: 3.4099 (Forecasting Loss:0.1416 + XiCon Loss:3.2683 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3817554
	speed: 0.0378s/iter; left time: 852.0255s
	iters: 200, epoch: 16 | loss: 3.3401923
	speed: 0.0353s/iter; left time: 790.4497s
Epoch: 16 cost time: 9.62954068183899
Epoch: 16, Steps: 266 Train Loss: 3.4046 (Forecasting Loss:0.1415 + XiCon Loss:3.2631 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3975754
	speed: 0.0373s/iter; left time: 830.7943s
	iters: 200, epoch: 17 | loss: 3.3618581
	speed: 0.0356s/iter; left time: 788.4444s
Epoch: 17 cost time: 9.660390615463257
Epoch: 17, Steps: 266 Train Loss: 3.4063 (Forecasting Loss:0.1416 + XiCon Loss:3.2647 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.5279176
	speed: 0.0371s/iter; left time: 814.5381s
	iters: 200, epoch: 18 | loss: 3.3457193
	speed: 0.0352s/iter; left time: 769.4055s
Epoch: 18 cost time: 9.602326154708862
Epoch: 18, Steps: 266 Train Loss: 3.4133 (Forecasting Loss:0.1415 + XiCon Loss:3.2718 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3745422
	speed: 0.0377s/iter; left time: 819.0601s
	iters: 200, epoch: 19 | loss: 3.3513813
	speed: 0.0356s/iter; left time: 768.3423s
Epoch: 19 cost time: 9.711022853851318
Epoch: 19, Steps: 266 Train Loss: 3.4092 (Forecasting Loss:0.1416 + XiCon Loss:3.2676 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3523664
	speed: 0.0376s/iter; left time: 806.4011s
	iters: 200, epoch: 20 | loss: 3.4628804
	speed: 0.0365s/iter; left time: 779.1161s
Epoch: 20 cost time: 9.783330202102661
Epoch: 20, Steps: 266 Train Loss: 3.4096 (Forecasting Loss:0.1416 + XiCon Loss:3.2681 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4024997
	speed: 0.0375s/iter; left time: 794.3271s
	iters: 200, epoch: 21 | loss: 3.3861296
	speed: 0.0346s/iter; left time: 728.5377s
Epoch: 21 cost time: 9.573924541473389
Epoch: 21, Steps: 266 Train Loss: 3.4077 (Forecasting Loss:0.1416 + XiCon Loss:3.2661 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026367858052253723, mae:0.12180151045322418, mape:0.09839358180761337, mspe:0.019546784460544586 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.2418
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.5671096
	speed: 0.0376s/iter; left time: 995.5839s
	iters: 200, epoch: 1 | loss: 3.5093281
	speed: 0.0349s/iter; left time: 921.9065s
Epoch: 1 cost time: 9.612568378448486
Epoch: 1, Steps: 266 Train Loss: 3.5855 (Forecasting Loss:0.1695 + XiCon Loss:3.4160 x Lambda(1.0)), Vali MSE Loss: 0.1158 Test MSE Loss: 0.0800
Validation loss decreased (inf --> 0.115784).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.7990544
	speed: 0.0378s/iter; left time: 991.6663s
	iters: 200, epoch: 2 | loss: 3.5668545
	speed: 0.0362s/iter; left time: 946.0042s
Epoch: 2 cost time: 9.792532920837402
Epoch: 2, Steps: 266 Train Loss: 3.6596 (Forecasting Loss:0.1503 + XiCon Loss:3.5093 x Lambda(1.0)), Vali MSE Loss: 0.1115 Test MSE Loss: 0.0760
Validation loss decreased (0.115784 --> 0.111464).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5199530
	speed: 0.0386s/iter; left time: 1002.9924s
	iters: 200, epoch: 3 | loss: 3.5604794
	speed: 0.0362s/iter; left time: 936.5901s
Epoch: 3 cost time: 9.907361030578613
Epoch: 3, Steps: 266 Train Loss: 3.4982 (Forecasting Loss:0.1452 + XiCon Loss:3.3530 x Lambda(1.0)), Vali MSE Loss: 0.1100 Test MSE Loss: 0.0756
Validation loss decreased (0.111464 --> 0.110019).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3281879
	speed: 0.0391s/iter; left time: 1003.8908s
	iters: 200, epoch: 4 | loss: 3.5647707
	speed: 0.0370s/iter; left time: 947.0200s
Epoch: 4 cost time: 10.0702543258667
Epoch: 4, Steps: 266 Train Loss: 3.4010 (Forecasting Loss:0.1435 + XiCon Loss:3.2575 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0748
Validation loss decreased (0.110019 --> 0.108382).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3695323
	speed: 0.0374s/iter; left time: 950.9123s
	iters: 200, epoch: 5 | loss: 3.4613252
	speed: 0.0360s/iter; left time: 911.0437s
Epoch: 5 cost time: 9.661592960357666
Epoch: 5, Steps: 266 Train Loss: 3.3957 (Forecasting Loss:0.1427 + XiCon Loss:3.2531 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0742
Validation loss decreased (0.108382 --> 0.108062).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4898062
	speed: 0.0390s/iter; left time: 980.5200s
	iters: 200, epoch: 6 | loss: 3.4297230
	speed: 0.0360s/iter; left time: 902.9452s
Epoch: 6 cost time: 9.93839955329895
Epoch: 6, Steps: 266 Train Loss: 3.3932 (Forecasting Loss:0.1420 + XiCon Loss:3.2512 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0742
Validation loss decreased (0.108062 --> 0.107815).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4024289
	speed: 0.0378s/iter; left time: 941.5218s
	iters: 200, epoch: 7 | loss: 3.4485505
	speed: 0.0359s/iter; left time: 890.5256s
Epoch: 7 cost time: 9.740455627441406
Epoch: 7, Steps: 266 Train Loss: 3.3922 (Forecasting Loss:0.1418 + XiCon Loss:3.2504 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0742
Validation loss decreased (0.107815 --> 0.107637).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4512906
	speed: 0.0383s/iter; left time: 942.8364s
	iters: 200, epoch: 8 | loss: 3.4345846
	speed: 0.0362s/iter; left time: 889.1785s
Epoch: 8 cost time: 9.875048398971558
Epoch: 8, Steps: 266 Train Loss: 3.3945 (Forecasting Loss:0.1416 + XiCon Loss:3.2529 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4444177
	speed: 0.0384s/iter; left time: 936.7332s
	iters: 200, epoch: 9 | loss: 3.3218203
	speed: 0.0357s/iter; left time: 867.1648s
Epoch: 9 cost time: 9.768929719924927
Epoch: 9, Steps: 266 Train Loss: 3.3891 (Forecasting Loss:0.1416 + XiCon Loss:3.2474 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
Validation loss decreased (0.107637 --> 0.107574).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3488328
	speed: 0.0379s/iter; left time: 912.5258s
	iters: 200, epoch: 10 | loss: 3.4493945
	speed: 0.0351s/iter; left time: 843.6512s
Epoch: 10 cost time: 9.720760583877563
Epoch: 10, Steps: 266 Train Loss: 3.3910 (Forecasting Loss:0.1416 + XiCon Loss:3.2495 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107574 --> 0.107543).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3495767
	speed: 0.0390s/iter; left time: 928.9789s
	iters: 200, epoch: 11 | loss: 3.3207698
	speed: 0.0371s/iter; left time: 879.8281s
Epoch: 11 cost time: 9.98703384399414
Epoch: 11, Steps: 266 Train Loss: 3.3901 (Forecasting Loss:0.1415 + XiCon Loss:3.2486 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107543 --> 0.107534).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4366968
	speed: 0.0380s/iter; left time: 895.0901s
	iters: 200, epoch: 12 | loss: 3.3193099
	speed: 0.0358s/iter; left time: 841.3033s
Epoch: 12 cost time: 9.83675765991211
Epoch: 12, Steps: 266 Train Loss: 3.3900 (Forecasting Loss:0.1415 + XiCon Loss:3.2485 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107534 --> 0.107515).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5546999
	speed: 0.0381s/iter; left time: 887.4684s
	iters: 200, epoch: 13 | loss: 3.4484956
	speed: 0.0369s/iter; left time: 856.7364s
Epoch: 13 cost time: 9.868009805679321
Epoch: 13, Steps: 266 Train Loss: 3.3937 (Forecasting Loss:0.1415 + XiCon Loss:3.2522 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107515 --> 0.107501).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4589431
	speed: 0.0381s/iter; left time: 877.4960s
	iters: 200, epoch: 14 | loss: 3.4399662
	speed: 0.0359s/iter; left time: 823.1557s
Epoch: 14 cost time: 9.835837841033936
Epoch: 14, Steps: 266 Train Loss: 3.3862 (Forecasting Loss:0.1415 + XiCon Loss:3.2447 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4383683
	speed: 0.0383s/iter; left time: 872.6644s
	iters: 200, epoch: 15 | loss: 3.3318856
	speed: 0.0353s/iter; left time: 799.9910s
Epoch: 15 cost time: 9.844070672988892
Epoch: 15, Steps: 266 Train Loss: 3.3966 (Forecasting Loss:0.1416 + XiCon Loss:3.2550 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4534993
	speed: 0.0389s/iter; left time: 876.0737s
	iters: 200, epoch: 16 | loss: 3.3372996
	speed: 0.0361s/iter; left time: 810.0665s
Epoch: 16 cost time: 9.959206104278564
Epoch: 16, Steps: 266 Train Loss: 3.3896 (Forecasting Loss:0.1415 + XiCon Loss:3.2481 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4036460
	speed: 0.0381s/iter; left time: 846.9879s
	iters: 200, epoch: 17 | loss: 3.3974922
	speed: 0.0356s/iter; left time: 788.6043s
Epoch: 17 cost time: 9.803781747817993
Epoch: 17, Steps: 266 Train Loss: 3.3902 (Forecasting Loss:0.1416 + XiCon Loss:3.2486 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4195147
	speed: 0.0382s/iter; left time: 840.6678s
	iters: 200, epoch: 18 | loss: 3.4454775
	speed: 0.0362s/iter; left time: 791.3885s
Epoch: 18 cost time: 9.878217935562134
Epoch: 18, Steps: 266 Train Loss: 3.3908 (Forecasting Loss:0.1416 + XiCon Loss:3.2492 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.5663025
	speed: 0.0380s/iter; left time: 824.5904s
	iters: 200, epoch: 19 | loss: 3.3891194
	speed: 0.0361s/iter; left time: 780.7753s
Epoch: 19 cost time: 9.802277326583862
Epoch: 19, Steps: 266 Train Loss: 3.3878 (Forecasting Loss:0.1416 + XiCon Loss:3.2462 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107501 --> 0.107470).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3359041
	speed: 0.0390s/iter; left time: 836.1620s
	iters: 200, epoch: 20 | loss: 3.4725404
	speed: 0.0360s/iter; left time: 768.6775s
Epoch: 20 cost time: 9.855702638626099
Epoch: 20, Steps: 266 Train Loss: 3.3983 (Forecasting Loss:0.1416 + XiCon Loss:3.2568 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3556309
	speed: 0.0380s/iter; left time: 805.7767s
	iters: 200, epoch: 21 | loss: 3.3124030
	speed: 0.0365s/iter; left time: 768.6372s
Epoch: 21 cost time: 9.788379669189453
Epoch: 21, Steps: 266 Train Loss: 3.3937 (Forecasting Loss:0.1416 + XiCon Loss:3.2521 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3422840
	speed: 0.0383s/iter; left time: 801.3880s
	iters: 200, epoch: 22 | loss: 3.3272955
	speed: 0.0368s/iter; left time: 765.2569s
Epoch: 22 cost time: 9.928630352020264
Epoch: 22, Steps: 266 Train Loss: 3.3905 (Forecasting Loss:0.1415 + XiCon Loss:3.2489 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3289070
	speed: 0.0384s/iter; left time: 792.2732s
	iters: 200, epoch: 23 | loss: 3.3252451
	speed: 0.0362s/iter; left time: 744.8712s
Epoch: 23 cost time: 9.812107801437378
Epoch: 23, Steps: 266 Train Loss: 3.3881 (Forecasting Loss:0.1416 + XiCon Loss:3.2465 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3449113
	speed: 0.0387s/iter; left time: 789.4412s
	iters: 200, epoch: 24 | loss: 3.4616754
	speed: 0.0358s/iter; left time: 725.7953s
Epoch: 24 cost time: 9.866360664367676
Epoch: 24, Steps: 266 Train Loss: 3.3914 (Forecasting Loss:0.1415 + XiCon Loss:3.2498 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3142216
	speed: 0.0382s/iter; left time: 768.1659s
	iters: 200, epoch: 25 | loss: 3.3034625
	speed: 0.0355s/iter; left time: 709.9832s
Epoch: 25 cost time: 9.693613052368164
Epoch: 25, Steps: 266 Train Loss: 3.3918 (Forecasting Loss:0.1416 + XiCon Loss:3.2502 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0740
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.4317908
	speed: 0.0373s/iter; left time: 740.6156s
	iters: 200, epoch: 26 | loss: 3.3563151
	speed: 0.0364s/iter; left time: 719.3641s
Epoch: 26 cost time: 9.755428791046143
Epoch: 26, Steps: 266 Train Loss: 3.3954 (Forecasting Loss:0.1416 + XiCon Loss:3.2538 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.4621701
	speed: 0.0382s/iter; left time: 747.5277s
	iters: 200, epoch: 27 | loss: 3.4472938
	speed: 0.0357s/iter; left time: 694.6642s
Epoch: 27 cost time: 9.806618690490723
Epoch: 27, Steps: 266 Train Loss: 3.3964 (Forecasting Loss:0.1416 + XiCon Loss:3.2548 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.3503439
	speed: 0.0379s/iter; left time: 733.0102s
	iters: 200, epoch: 28 | loss: 3.4304497
	speed: 0.0366s/iter; left time: 703.0665s
Epoch: 28 cost time: 9.953608751296997
Epoch: 28, Steps: 266 Train Loss: 3.3981 (Forecasting Loss:0.1416 + XiCon Loss:3.2565 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.3454974
	speed: 0.0375s/iter; left time: 714.2154s
	iters: 200, epoch: 29 | loss: 3.5630403
	speed: 0.0352s/iter; left time: 667.2729s
Epoch: 29 cost time: 9.681200742721558
Epoch: 29, Steps: 266 Train Loss: 3.3899 (Forecasting Loss:0.1415 + XiCon Loss:3.2484 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026330333203077316, mae:0.12175702303647995, mape:0.09835945814847946, mspe:0.019464846700429916 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0264+-0.00007, MAE:0.1219+-0.00015, MAPE:0.0985+-0.00013, MSPE:0.0196+-0.00009, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.3224
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 34.1611786
	speed: 0.0508s/iter; left time: 1340.5251s
	iters: 200, epoch: 1 | loss: 33.2437057
	speed: 0.0446s/iter; left time: 1172.8950s
Epoch: 1 cost time: 12.47189974784851
Epoch: 1, Steps: 265 Train Loss: 34.0630 (Forecasting Loss:0.2098 + XiCon Loss:3.3853 x Lambda(10.0)), Vali MSE Loss: 0.1484 Test MSE Loss: 0.0985
Validation loss decreased (inf --> 0.148433).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 35.6399879
	speed: 0.0496s/iter; left time: 1296.0398s
	iters: 200, epoch: 2 | loss: 33.1865234
	speed: 0.0458s/iter; left time: 1192.5104s
Epoch: 2 cost time: 12.577385902404785
Epoch: 2, Steps: 265 Train Loss: 34.3892 (Forecasting Loss:0.1987 + XiCon Loss:3.4190 x Lambda(10.0)), Vali MSE Loss: 0.1453 Test MSE Loss: 0.0960
Validation loss decreased (0.148433 --> 0.145306).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.8064270
	speed: 0.0481s/iter; left time: 1243.4079s
	iters: 200, epoch: 3 | loss: 32.1802406
	speed: 0.0470s/iter; left time: 1211.1641s
Epoch: 3 cost time: 12.601867198944092
Epoch: 3, Steps: 265 Train Loss: 33.0040 (Forecasting Loss:0.1930 + XiCon Loss:3.2811 x Lambda(10.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0956
Validation loss decreased (0.145306 --> 0.143597).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.2360153
	speed: 0.0481s/iter; left time: 1231.3910s
	iters: 200, epoch: 4 | loss: 33.9276733
	speed: 0.0473s/iter; left time: 1207.5176s
Epoch: 4 cost time: 12.616495132446289
Epoch: 4, Steps: 265 Train Loss: 32.9017 (Forecasting Loss:0.1913 + XiCon Loss:3.2710 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0957
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.2932663
	speed: 0.0483s/iter; left time: 1222.9938s
	iters: 200, epoch: 5 | loss: 33.2184410
	speed: 0.0466s/iter; left time: 1175.4332s
Epoch: 5 cost time: 12.630136013031006
Epoch: 5, Steps: 265 Train Loss: 32.8577 (Forecasting Loss:0.1906 + XiCon Loss:3.2667 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0952
Validation loss decreased (0.143597 --> 0.142603).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.2873878
	speed: 0.0499s/iter; left time: 1251.1535s
	iters: 200, epoch: 6 | loss: 33.1397285
	speed: 0.0471s/iter; left time: 1176.5262s
Epoch: 6 cost time: 12.782909870147705
Epoch: 6, Steps: 265 Train Loss: 32.7678 (Forecasting Loss:0.1899 + XiCon Loss:3.2578 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.142603 --> 0.141844).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.1547394
	speed: 0.0491s/iter; left time: 1218.1734s
	iters: 200, epoch: 7 | loss: 32.6184425
	speed: 0.0460s/iter; left time: 1136.2488s
Epoch: 7 cost time: 12.540666103363037
Epoch: 7, Steps: 265 Train Loss: 32.7253 (Forecasting Loss:0.1895 + XiCon Loss:3.2536 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.0533257
	speed: 0.0490s/iter; left time: 1202.4929s
	iters: 200, epoch: 8 | loss: 33.9298515
	speed: 0.0469s/iter; left time: 1146.3174s
Epoch: 8 cost time: 12.612872123718262
Epoch: 8, Steps: 265 Train Loss: 32.7352 (Forecasting Loss:0.1895 + XiCon Loss:3.2546 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141844 --> 0.141831).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.1540413
	speed: 0.0479s/iter; left time: 1161.9568s
	iters: 200, epoch: 9 | loss: 32.1160278
	speed: 0.0470s/iter; left time: 1137.2881s
Epoch: 9 cost time: 12.572935819625854
Epoch: 9, Steps: 265 Train Loss: 32.7144 (Forecasting Loss:0.1893 + XiCon Loss:3.2525 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.141831 --> 0.141781).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.0539894
	speed: 0.0493s/iter; left time: 1184.8007s
	iters: 200, epoch: 10 | loss: 32.0429726
	speed: 0.0480s/iter; left time: 1148.1408s
Epoch: 10 cost time: 12.783650875091553
Epoch: 10, Steps: 265 Train Loss: 32.5987 (Forecasting Loss:0.1893 + XiCon Loss:3.2409 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141781 --> 0.141643).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.0852928
	speed: 0.0494s/iter; left time: 1173.5182s
	iters: 200, epoch: 11 | loss: 32.1687927
	speed: 0.0470s/iter; left time: 1112.3223s
Epoch: 11 cost time: 12.704626083374023
Epoch: 11, Steps: 265 Train Loss: 32.6232 (Forecasting Loss:0.1893 + XiCon Loss:3.2434 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.0249519
	speed: 0.0491s/iter; left time: 1153.1147s
	iters: 200, epoch: 12 | loss: 32.5078354
	speed: 0.0464s/iter; left time: 1085.3443s
Epoch: 12 cost time: 12.647831201553345
Epoch: 12, Steps: 265 Train Loss: 32.5474 (Forecasting Loss:0.1892 + XiCon Loss:3.2358 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141643 --> 0.141609).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.1102638
	speed: 0.0489s/iter; left time: 1135.1348s
	iters: 200, epoch: 13 | loss: 33.7902908
	speed: 0.0464s/iter; left time: 1071.8885s
Epoch: 13 cost time: 12.610074758529663
Epoch: 13, Steps: 265 Train Loss: 32.5975 (Forecasting Loss:0.1892 + XiCon Loss:3.2408 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2116280
	speed: 0.0493s/iter; left time: 1130.7749s
	iters: 200, epoch: 14 | loss: 32.2075043
	speed: 0.0467s/iter; left time: 1068.5031s
Epoch: 14 cost time: 12.672451972961426
Epoch: 14, Steps: 265 Train Loss: 32.6648 (Forecasting Loss:0.1893 + XiCon Loss:3.2475 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.9324188
	speed: 0.0482s/iter; left time: 1093.7451s
	iters: 200, epoch: 15 | loss: 33.1374779
	speed: 0.0464s/iter; left time: 1048.3527s
Epoch: 15 cost time: 12.574687719345093
Epoch: 15, Steps: 265 Train Loss: 32.6186 (Forecasting Loss:0.1891 + XiCon Loss:3.2430 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.0324249
	speed: 0.0488s/iter; left time: 1093.5070s
	iters: 200, epoch: 16 | loss: 34.0090790
	speed: 0.0482s/iter; left time: 1076.7080s
Epoch: 16 cost time: 12.803871631622314
Epoch: 16, Steps: 265 Train Loss: 32.6614 (Forecasting Loss:0.1892 + XiCon Loss:3.2472 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141609 --> 0.141554).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.0603180
	speed: 0.0492s/iter; left time: 1089.4059s
	iters: 200, epoch: 17 | loss: 33.9301949
	speed: 0.0473s/iter; left time: 1043.7819s
Epoch: 17 cost time: 12.748620748519897
Epoch: 17, Steps: 265 Train Loss: 32.6510 (Forecasting Loss:0.1892 + XiCon Loss:3.2462 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.1930695
	speed: 0.0488s/iter; left time: 1069.1186s
	iters: 200, epoch: 18 | loss: 33.4040070
	speed: 0.0463s/iter; left time: 1008.8487s
Epoch: 18 cost time: 12.622555017471313
Epoch: 18, Steps: 265 Train Loss: 32.7169 (Forecasting Loss:0.1891 + XiCon Loss:3.2528 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.1723328
	speed: 0.0481s/iter; left time: 1040.6811s
	iters: 200, epoch: 19 | loss: 32.0386467
	speed: 0.0469s/iter; left time: 1009.0273s
Epoch: 19 cost time: 12.520168542861938
Epoch: 19, Steps: 265 Train Loss: 32.6495 (Forecasting Loss:0.1892 + XiCon Loss:3.2460 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.9840279
	speed: 0.0481s/iter; left time: 1027.4717s
	iters: 200, epoch: 20 | loss: 32.3012810
	speed: 0.0465s/iter; left time: 987.8524s
Epoch: 20 cost time: 12.545382976531982
Epoch: 20, Steps: 265 Train Loss: 32.6041 (Forecasting Loss:0.1892 + XiCon Loss:3.2415 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.7274437
	speed: 0.0488s/iter; left time: 1030.7671s
	iters: 200, epoch: 21 | loss: 32.2548561
	speed: 0.0464s/iter; left time: 974.0494s
Epoch: 21 cost time: 12.67125153541565
Epoch: 21, Steps: 265 Train Loss: 32.6792 (Forecasting Loss:0.1892 + XiCon Loss:3.2490 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.5082321
	speed: 0.0496s/iter; left time: 1033.7275s
	iters: 200, epoch: 22 | loss: 32.2817116
	speed: 0.0478s/iter; left time: 991.3619s
Epoch: 22 cost time: 12.852776527404785
Epoch: 22, Steps: 265 Train Loss: 32.6474 (Forecasting Loss:0.1891 + XiCon Loss:3.2458 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.0556831
	speed: 0.0490s/iter; left time: 1007.1019s
	iters: 200, epoch: 23 | loss: 33.2603912
	speed: 0.0471s/iter; left time: 963.6060s
Epoch: 23 cost time: 12.72331714630127
Epoch: 23, Steps: 265 Train Loss: 32.6702 (Forecasting Loss:0.1893 + XiCon Loss:3.2481 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.2445488
	speed: 0.0487s/iter; left time: 989.6124s
	iters: 200, epoch: 24 | loss: 32.1282921
	speed: 0.0465s/iter; left time: 939.5568s
Epoch: 24 cost time: 12.596706628799438
Epoch: 24, Steps: 265 Train Loss: 32.6250 (Forecasting Loss:0.1892 + XiCon Loss:3.2436 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 33.2592468
	speed: 0.0492s/iter; left time: 986.8443s
	iters: 200, epoch: 25 | loss: 32.2750778
	speed: 0.0467s/iter; left time: 931.4376s
Epoch: 25 cost time: 12.669386863708496
Epoch: 25, Steps: 265 Train Loss: 32.6252 (Forecasting Loss:0.1892 + XiCon Loss:3.2436 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.1689186
	speed: 0.0484s/iter; left time: 956.9760s
	iters: 200, epoch: 26 | loss: 32.2306862
	speed: 0.0469s/iter; left time: 922.8324s
Epoch: 26 cost time: 12.620356321334839
Epoch: 26, Steps: 265 Train Loss: 32.6351 (Forecasting Loss:0.1892 + XiCon Loss:3.2446 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03934004157781601, mae:0.14944609999656677, mape:0.11865159869194031, mspe:0.02634851075708866 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.3781
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.6894875
	speed: 0.0477s/iter; left time: 1259.4511s
	iters: 200, epoch: 1 | loss: 32.8926125
	speed: 0.0452s/iter; left time: 1187.8142s
Epoch: 1 cost time: 12.321486473083496
Epoch: 1, Steps: 265 Train Loss: 33.9799 (Forecasting Loss:0.2123 + XiCon Loss:3.3768 x Lambda(10.0)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.146755).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 37.8864708
	speed: 0.0496s/iter; left time: 1297.5352s
	iters: 200, epoch: 2 | loss: 34.5617180
	speed: 0.0471s/iter; left time: 1226.7338s
Epoch: 2 cost time: 12.73256254196167
Epoch: 2, Steps: 265 Train Loss: 35.9631 (Forecasting Loss:0.1980 + XiCon Loss:3.5765 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1003
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 36.1491089
	speed: 0.0493s/iter; left time: 1276.3508s
	iters: 200, epoch: 3 | loss: 34.3427238
	speed: 0.0466s/iter; left time: 1201.6866s
Epoch: 3 cost time: 12.624476194381714
Epoch: 3, Steps: 265 Train Loss: 34.8835 (Forecasting Loss:0.1926 + XiCon Loss:3.4691 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0955
Validation loss decreased (0.146755 --> 0.144231).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.0369453
	speed: 0.0493s/iter; left time: 1262.0270s
	iters: 200, epoch: 4 | loss: 33.2847862
	speed: 0.0468s/iter; left time: 1193.2463s
Epoch: 4 cost time: 12.735758781433105
Epoch: 4, Steps: 265 Train Loss: 34.3994 (Forecasting Loss:0.1910 + XiCon Loss:3.4208 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0952
Validation loss decreased (0.144231 --> 0.143067).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.7339478
	speed: 0.0484s/iter; left time: 1227.3830s
	iters: 200, epoch: 5 | loss: 34.7588043
	speed: 0.0470s/iter; left time: 1186.7746s
Epoch: 5 cost time: 12.606221437454224
Epoch: 5, Steps: 265 Train Loss: 34.0322 (Forecasting Loss:0.1898 + XiCon Loss:3.3842 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0952
Validation loss decreased (0.143067 --> 0.141991).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 34.3723488
	speed: 0.0496s/iter; left time: 1244.6272s
	iters: 200, epoch: 6 | loss: 32.5671387
	speed: 0.0473s/iter; left time: 1181.9680s
Epoch: 6 cost time: 12.757442235946655
Epoch: 6, Steps: 265 Train Loss: 33.9054 (Forecasting Loss:0.1894 + XiCon Loss:3.3716 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0959
Validation loss decreased (0.141991 --> 0.141855).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 35.9094505
	speed: 0.0488s/iter; left time: 1210.9705s
	iters: 200, epoch: 7 | loss: 34.0177689
	speed: 0.0467s/iter; left time: 1153.0744s
Epoch: 7 cost time: 12.630825281143188
Epoch: 7, Steps: 265 Train Loss: 33.7931 (Forecasting Loss:0.1886 + XiCon Loss:3.3604 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0978
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.5444336
	speed: 0.0497s/iter; left time: 1221.0564s
	iters: 200, epoch: 8 | loss: 32.1683884
	speed: 0.0469s/iter; left time: 1147.3196s
Epoch: 8 cost time: 12.756235122680664
Epoch: 8, Steps: 265 Train Loss: 33.7904 (Forecasting Loss:0.1882 + XiCon Loss:3.3602 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0975
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 34.9788857
	speed: 0.0491s/iter; left time: 1192.9832s
	iters: 200, epoch: 9 | loss: 32.3848763
	speed: 0.0470s/iter; left time: 1136.5271s
Epoch: 9 cost time: 12.713773488998413
Epoch: 9, Steps: 265 Train Loss: 33.6992 (Forecasting Loss:0.1879 + XiCon Loss:3.3511 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0971
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.4039230
	speed: 0.0491s/iter; left time: 1179.4819s
	iters: 200, epoch: 10 | loss: 34.2828407
	speed: 0.0467s/iter; left time: 1116.1304s
Epoch: 10 cost time: 12.66200065612793
Epoch: 10, Steps: 265 Train Loss: 33.7049 (Forecasting Loss:0.1880 + XiCon Loss:3.3517 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0976
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.5744171
	speed: 0.0495s/iter; left time: 1175.9811s
	iters: 200, epoch: 11 | loss: 32.5047455
	speed: 0.0465s/iter; left time: 1099.4704s
Epoch: 11 cost time: 12.62752890586853
Epoch: 11, Steps: 265 Train Loss: 33.7196 (Forecasting Loss:0.1880 + XiCon Loss:3.3532 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.0974
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.4102020
	speed: 0.0490s/iter; left time: 1149.8528s
	iters: 200, epoch: 12 | loss: 32.9853325
	speed: 0.0475s/iter; left time: 1109.6945s
Epoch: 12 cost time: 12.734805822372437
Epoch: 12, Steps: 265 Train Loss: 33.7225 (Forecasting Loss:0.1879 + XiCon Loss:3.3535 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0975
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 35.4825478
	speed: 0.0487s/iter; left time: 1130.1763s
	iters: 200, epoch: 13 | loss: 32.9708672
	speed: 0.0465s/iter; left time: 1074.5824s
Epoch: 13 cost time: 12.540652513504028
Epoch: 13, Steps: 265 Train Loss: 33.6992 (Forecasting Loss:0.1880 + XiCon Loss:3.3511 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0975
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.6738205
	speed: 0.0489s/iter; left time: 1122.6140s
	iters: 200, epoch: 14 | loss: 35.4731636
	speed: 0.0470s/iter; left time: 1073.1951s
Epoch: 14 cost time: 12.704136371612549
Epoch: 14, Steps: 265 Train Loss: 33.8200 (Forecasting Loss:0.1880 + XiCon Loss:3.3632 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.0975
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.8249321
	speed: 0.0491s/iter; left time: 1113.9713s
	iters: 200, epoch: 15 | loss: 35.0552788
	speed: 0.0472s/iter; left time: 1066.1828s
Epoch: 15 cost time: 12.774288654327393
Epoch: 15, Steps: 265 Train Loss: 33.7598 (Forecasting Loss:0.1879 + XiCon Loss:3.3572 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.0975
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.3851891
	speed: 0.0480s/iter; left time: 1077.0335s
	iters: 200, epoch: 16 | loss: 34.6492996
	speed: 0.0466s/iter; left time: 1039.8722s
Epoch: 16 cost time: 12.546577215194702
Epoch: 16, Steps: 265 Train Loss: 33.6096 (Forecasting Loss:0.1878 + XiCon Loss:3.3422 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0975
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04070766642689705, mae:0.1510711908340454, mape:0.11978256702423096, mspe:0.027028711512684822 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.0832
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.5678940
	speed: 0.0483s/iter; left time: 1275.3405s
	iters: 200, epoch: 1 | loss: 33.8586540
	speed: 0.0451s/iter; left time: 1186.2541s
Epoch: 1 cost time: 12.265487909317017
Epoch: 1, Steps: 265 Train Loss: 34.0660 (Forecasting Loss:0.2119 + XiCon Loss:3.3854 x Lambda(10.0)), Vali MSE Loss: 0.1489 Test MSE Loss: 0.0988
Validation loss decreased (inf --> 0.148867).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.9388084
	speed: 0.0495s/iter; left time: 1292.6307s
	iters: 200, epoch: 2 | loss: 33.0246468
	speed: 0.0473s/iter; left time: 1230.7157s
Epoch: 2 cost time: 12.763659715652466
Epoch: 2, Steps: 265 Train Loss: 35.0032 (Forecasting Loss:0.1981 + XiCon Loss:3.4805 x Lambda(10.0)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.0986
Validation loss decreased (0.148867 --> 0.148173).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 34.0599365
	speed: 0.0486s/iter; left time: 1258.2571s
	iters: 200, epoch: 3 | loss: 34.6116943
	speed: 0.0468s/iter; left time: 1204.8465s
Epoch: 3 cost time: 12.646367073059082
Epoch: 3, Steps: 265 Train Loss: 34.5508 (Forecasting Loss:0.1933 + XiCon Loss:3.4357 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0966
Validation loss decreased (0.148173 --> 0.143277).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 35.1058464
	speed: 0.0491s/iter; left time: 1257.2253s
	iters: 200, epoch: 4 | loss: 35.1151199
	speed: 0.0468s/iter; left time: 1194.0993s
Epoch: 4 cost time: 12.673227787017822
Epoch: 4, Steps: 265 Train Loss: 34.4648 (Forecasting Loss:0.1912 + XiCon Loss:3.4274 x Lambda(10.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0954
Validation loss decreased (0.143277 --> 0.143018).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 34.6933670
	speed: 0.0490s/iter; left time: 1241.7138s
	iters: 200, epoch: 5 | loss: 33.5414009
	speed: 0.0473s/iter; left time: 1194.7908s
Epoch: 5 cost time: 12.724584579467773
Epoch: 5, Steps: 265 Train Loss: 34.0997 (Forecasting Loss:0.1899 + XiCon Loss:3.3910 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0959
Validation loss decreased (0.143018 --> 0.141869).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.1516609
	speed: 0.0500s/iter; left time: 1254.6968s
	iters: 200, epoch: 6 | loss: 33.6035728
	speed: 0.0478s/iter; left time: 1194.7146s
Epoch: 6 cost time: 12.90775990486145
Epoch: 6, Steps: 265 Train Loss: 34.0457 (Forecasting Loss:0.1894 + XiCon Loss:3.3856 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.7478256
	speed: 0.0493s/iter; left time: 1223.3599s
	iters: 200, epoch: 7 | loss: 32.6079140
	speed: 0.0469s/iter; left time: 1158.7154s
Epoch: 7 cost time: 12.701130390167236
Epoch: 7, Steps: 265 Train Loss: 34.0474 (Forecasting Loss:0.1892 + XiCon Loss:3.3858 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0958
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 34.4700470
	speed: 0.0494s/iter; left time: 1212.7091s
	iters: 200, epoch: 8 | loss: 33.0369415
	speed: 0.0467s/iter; left time: 1140.6893s
Epoch: 8 cost time: 12.650974750518799
Epoch: 8, Steps: 265 Train Loss: 33.8469 (Forecasting Loss:0.1891 + XiCon Loss:3.3658 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
Validation loss decreased (0.141869 --> 0.141814).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.6873817
	speed: 0.0486s/iter; left time: 1178.9341s
	iters: 200, epoch: 9 | loss: 33.9580269
	speed: 0.0471s/iter; left time: 1138.9582s
Epoch: 9 cost time: 12.70006251335144
Epoch: 9, Steps: 265 Train Loss: 34.1033 (Forecasting Loss:0.1891 + XiCon Loss:3.3914 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0959
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.9678535
	speed: 0.0497s/iter; left time: 1193.7622s
	iters: 200, epoch: 10 | loss: 32.7340622
	speed: 0.0470s/iter; left time: 1122.9057s
Epoch: 10 cost time: 12.770395994186401
Epoch: 10, Steps: 265 Train Loss: 34.0787 (Forecasting Loss:0.1892 + XiCon Loss:3.3889 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0959
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 34.4254150
	speed: 0.0500s/iter; left time: 1188.0011s
	iters: 200, epoch: 11 | loss: 33.6206932
	speed: 0.0474s/iter; left time: 1120.4386s
Epoch: 11 cost time: 12.861321449279785
Epoch: 11, Steps: 265 Train Loss: 34.2327 (Forecasting Loss:0.1893 + XiCon Loss:3.4043 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0958
Validation loss decreased (0.141814 --> 0.141747).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.1679726
	speed: 0.0490s/iter; left time: 1149.9614s
	iters: 200, epoch: 12 | loss: 33.7331352
	speed: 0.0472s/iter; left time: 1102.9515s
Epoch: 12 cost time: 12.720150232315063
Epoch: 12, Steps: 265 Train Loss: 34.2892 (Forecasting Loss:0.1893 + XiCon Loss:3.4100 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.9094353
	speed: 0.0485s/iter; left time: 1125.5392s
	iters: 200, epoch: 13 | loss: 34.3644485
	speed: 0.0479s/iter; left time: 1107.0594s
Epoch: 13 cost time: 12.791752815246582
Epoch: 13, Steps: 265 Train Loss: 34.1922 (Forecasting Loss:0.1892 + XiCon Loss:3.4003 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 34.6579742
	speed: 0.0496s/iter; left time: 1137.7086s
	iters: 200, epoch: 14 | loss: 34.6603012
	speed: 0.0472s/iter; left time: 1078.9063s
Epoch: 14 cost time: 12.749101638793945
Epoch: 14, Steps: 265 Train Loss: 34.2670 (Forecasting Loss:0.1893 + XiCon Loss:3.4078 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 34.0836029
	speed: 0.0489s/iter; left time: 1109.9343s
	iters: 200, epoch: 15 | loss: 34.3637543
	speed: 0.0468s/iter; left time: 1057.4185s
Epoch: 15 cost time: 12.734019994735718
Epoch: 15, Steps: 265 Train Loss: 34.2338 (Forecasting Loss:0.1893 + XiCon Loss:3.4044 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 35.4303589
	speed: 0.0499s/iter; left time: 1119.5263s
	iters: 200, epoch: 16 | loss: 33.1581917
	speed: 0.0475s/iter; left time: 1059.5169s
Epoch: 16 cost time: 12.826060056686401
Epoch: 16, Steps: 265 Train Loss: 34.3848 (Forecasting Loss:0.1892 + XiCon Loss:3.4196 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
Validation loss decreased (0.141747 --> 0.141673).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.5929604
	speed: 0.0490s/iter; left time: 1085.8968s
	iters: 200, epoch: 17 | loss: 35.6072769
	speed: 0.0461s/iter; left time: 1017.2908s
Epoch: 17 cost time: 12.595124006271362
Epoch: 17, Steps: 265 Train Loss: 34.1865 (Forecasting Loss:0.1893 + XiCon Loss:3.3997 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.4573898
	speed: 0.0495s/iter; left time: 1084.2800s
	iters: 200, epoch: 18 | loss: 36.2453041
	speed: 0.0473s/iter; left time: 1031.1470s
Epoch: 18 cost time: 12.782017230987549
Epoch: 18, Steps: 265 Train Loss: 34.2816 (Forecasting Loss:0.1893 + XiCon Loss:3.4092 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.8345566
	speed: 0.0491s/iter; left time: 1062.2587s
	iters: 200, epoch: 19 | loss: 34.4345627
	speed: 0.0470s/iter; left time: 1011.1333s
Epoch: 19 cost time: 12.70638132095337
Epoch: 19, Steps: 265 Train Loss: 34.2688 (Forecasting Loss:0.1894 + XiCon Loss:3.4079 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 34.9991989
	speed: 0.0488s/iter; left time: 1043.6664s
	iters: 200, epoch: 20 | loss: 33.9048920
	speed: 0.0470s/iter; left time: 1000.0630s
Epoch: 20 cost time: 12.718374967575073
Epoch: 20, Steps: 265 Train Loss: 34.2309 (Forecasting Loss:0.1892 + XiCon Loss:3.4042 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 34.4760818
	speed: 0.0496s/iter; left time: 1046.2180s
	iters: 200, epoch: 21 | loss: 35.2886124
	speed: 0.0470s/iter; left time: 987.9449s
Epoch: 21 cost time: 12.774559497833252
Epoch: 21, Steps: 265 Train Loss: 34.2514 (Forecasting Loss:0.1893 + XiCon Loss:3.4062 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 34.0631104
	speed: 0.0495s/iter; left time: 1032.0843s
	iters: 200, epoch: 22 | loss: 33.0885811
	speed: 0.0480s/iter; left time: 995.7113s
Epoch: 22 cost time: 12.828283548355103
Epoch: 22, Steps: 265 Train Loss: 34.2286 (Forecasting Loss:0.1893 + XiCon Loss:3.4039 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.9945869
	speed: 0.0492s/iter; left time: 1011.4075s
	iters: 200, epoch: 23 | loss: 34.1179695
	speed: 0.0474s/iter; left time: 970.3076s
Epoch: 23 cost time: 12.7880277633667
Epoch: 23, Steps: 265 Train Loss: 34.3627 (Forecasting Loss:0.1892 + XiCon Loss:3.4173 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0957
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 35.6735878
	speed: 0.0492s/iter; left time: 999.5416s
	iters: 200, epoch: 24 | loss: 36.0399246
	speed: 0.0470s/iter; left time: 949.5147s
Epoch: 24 cost time: 12.683334350585938
Epoch: 24, Steps: 265 Train Loss: 34.3192 (Forecasting Loss:0.1892 + XiCon Loss:3.4130 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0957
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 35.6588249
	speed: 0.0492s/iter; left time: 985.1430s
	iters: 200, epoch: 25 | loss: 33.4712067
	speed: 0.0466s/iter; left time: 929.2679s
Epoch: 25 cost time: 12.745790481567383
Epoch: 25, Steps: 265 Train Loss: 34.2468 (Forecasting Loss:0.1892 + XiCon Loss:3.4058 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0957
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 33.6871986
	speed: 0.0500s/iter; left time: 987.9992s
	iters: 200, epoch: 26 | loss: 34.1557922
	speed: 0.0463s/iter; left time: 910.7648s
Epoch: 26 cost time: 12.742512226104736
Epoch: 26, Steps: 265 Train Loss: 34.1703 (Forecasting Loss:0.1893 + XiCon Loss:3.3981 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0957
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.040285371243953705, mae:0.15120050311088562, mape:0.119916632771492, mspe:0.026777680963277817 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4051
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.7895584
	speed: 0.0482s/iter; left time: 1272.7112s
	iters: 200, epoch: 1 | loss: 33.2073441
	speed: 0.0446s/iter; left time: 1174.2290s
Epoch: 1 cost time: 12.312870740890503
Epoch: 1, Steps: 265 Train Loss: 33.7928 (Forecasting Loss:0.2095 + XiCon Loss:3.3583 x Lambda(10.0)), Vali MSE Loss: 0.1473 Test MSE Loss: 0.1002
Validation loss decreased (inf --> 0.147267).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 41.9448395
	speed: 0.0502s/iter; left time: 1311.9246s
	iters: 200, epoch: 2 | loss: 40.2910690
	speed: 0.0465s/iter; left time: 1211.0287s
Epoch: 2 cost time: 12.74491834640503
Epoch: 2, Steps: 265 Train Loss: 39.2621 (Forecasting Loss:0.1974 + XiCon Loss:3.9065 x Lambda(10.0)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.0968
Validation loss decreased (0.147267 --> 0.145905).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 35.0854378
	speed: 0.0496s/iter; left time: 1282.3933s
	iters: 200, epoch: 3 | loss: 33.9346886
	speed: 0.0477s/iter; left time: 1228.4152s
Epoch: 3 cost time: 12.827258110046387
Epoch: 3, Steps: 265 Train Loss: 38.0461 (Forecasting Loss:0.1928 + XiCon Loss:3.7853 x Lambda(10.0)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.0969
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 36.4220695
	speed: 0.0497s/iter; left time: 1271.8572s
	iters: 200, epoch: 4 | loss: 33.8621559
	speed: 0.0472s/iter; left time: 1204.6001s
Epoch: 4 cost time: 12.790355205535889
Epoch: 4, Steps: 265 Train Loss: 36.6755 (Forecasting Loss:0.1909 + XiCon Loss:3.6485 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0947
Validation loss decreased (0.145905 --> 0.143078).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.9060097
	speed: 0.0492s/iter; left time: 1247.5378s
	iters: 200, epoch: 5 | loss: 35.7764091
	speed: 0.0472s/iter; left time: 1191.3171s
Epoch: 5 cost time: 12.701355218887329
Epoch: 5, Steps: 265 Train Loss: 36.6491 (Forecasting Loss:0.1898 + XiCon Loss:3.6459 x Lambda(10.0)), Vali MSE Loss: 0.1427 Test MSE Loss: 0.0950
Validation loss decreased (0.143078 --> 0.142719).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 35.6950874
	speed: 0.0491s/iter; left time: 1230.3790s
	iters: 200, epoch: 6 | loss: 38.0454865
	speed: 0.0470s/iter; left time: 1174.8463s
Epoch: 6 cost time: 12.703718662261963
Epoch: 6, Steps: 265 Train Loss: 36.2726 (Forecasting Loss:0.1892 + XiCon Loss:3.6083 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0943
Validation loss decreased (0.142719 --> 0.142060).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 35.7652893
	speed: 0.0486s/iter; left time: 1204.9232s
	iters: 200, epoch: 7 | loss: 34.3017197
	speed: 0.0466s/iter; left time: 1152.3218s
Epoch: 7 cost time: 12.676873445510864
Epoch: 7, Steps: 265 Train Loss: 35.8862 (Forecasting Loss:0.1890 + XiCon Loss:3.5697 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 35.9248581
	speed: 0.0485s/iter; left time: 1190.3220s
	iters: 200, epoch: 8 | loss: 36.9259987
	speed: 0.0460s/iter; left time: 1124.9111s
Epoch: 8 cost time: 12.538230180740356
Epoch: 8, Steps: 265 Train Loss: 36.0187 (Forecasting Loss:0.1889 + XiCon Loss:3.5830 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0942
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 36.7279053
	speed: 0.0491s/iter; left time: 1191.4609s
	iters: 200, epoch: 9 | loss: 35.8607292
	speed: 0.0470s/iter; left time: 1135.5794s
Epoch: 9 cost time: 12.693817377090454
Epoch: 9, Steps: 265 Train Loss: 35.9635 (Forecasting Loss:0.1888 + XiCon Loss:3.5775 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
Validation loss decreased (0.142060 --> 0.141879).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 34.6002197
	speed: 0.0497s/iter; left time: 1192.8344s
	iters: 200, epoch: 10 | loss: 36.6442909
	speed: 0.0475s/iter; left time: 1135.7249s
Epoch: 10 cost time: 12.80277943611145
Epoch: 10, Steps: 265 Train Loss: 35.8846 (Forecasting Loss:0.1888 + XiCon Loss:3.5696 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 35.5940323
	speed: 0.0497s/iter; left time: 1180.0274s
	iters: 200, epoch: 11 | loss: 37.5012665
	speed: 0.0474s/iter; left time: 1121.4102s
Epoch: 11 cost time: 12.785913705825806
Epoch: 11, Steps: 265 Train Loss: 35.8953 (Forecasting Loss:0.1889 + XiCon Loss:3.5706 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.1582184
	speed: 0.0493s/iter; left time: 1158.7277s
	iters: 200, epoch: 12 | loss: 34.7870827
	speed: 0.0472s/iter; left time: 1102.8797s
Epoch: 12 cost time: 12.72066354751587
Epoch: 12, Steps: 265 Train Loss: 35.8534 (Forecasting Loss:0.1888 + XiCon Loss:3.5665 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
Validation loss decreased (0.141879 --> 0.141846).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 36.1206474
	speed: 0.0493s/iter; left time: 1144.3144s
	iters: 200, epoch: 13 | loss: 34.4198952
	speed: 0.0483s/iter; left time: 1115.7080s
Epoch: 13 cost time: 12.810793161392212
Epoch: 13, Steps: 265 Train Loss: 35.8989 (Forecasting Loss:0.1888 + XiCon Loss:3.5710 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0942
Validation loss decreased (0.141846 --> 0.141704).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 38.6501503
	speed: 0.0503s/iter; left time: 1153.5721s
	iters: 200, epoch: 14 | loss: 37.2794151
	speed: 0.0469s/iter; left time: 1070.9683s
Epoch: 14 cost time: 12.832283020019531
Epoch: 14, Steps: 265 Train Loss: 35.9067 (Forecasting Loss:0.1889 + XiCon Loss:3.5718 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 36.5837708
	speed: 0.0488s/iter; left time: 1106.7608s
	iters: 200, epoch: 15 | loss: 35.4475021
	speed: 0.0465s/iter; left time: 1051.4869s
Epoch: 15 cost time: 12.579099893569946
Epoch: 15, Steps: 265 Train Loss: 35.8799 (Forecasting Loss:0.1888 + XiCon Loss:3.5691 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 35.9036407
	speed: 0.0499s/iter; left time: 1119.3836s
	iters: 200, epoch: 16 | loss: 34.4169655
	speed: 0.0474s/iter; left time: 1059.2180s
Epoch: 16 cost time: 12.796379089355469
Epoch: 16, Steps: 265 Train Loss: 35.8259 (Forecasting Loss:0.1889 + XiCon Loss:3.5637 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 36.8378830
	speed: 0.0487s/iter; left time: 1079.5890s
	iters: 200, epoch: 17 | loss: 35.2445488
	speed: 0.0465s/iter; left time: 1024.8127s
Epoch: 17 cost time: 12.545319557189941
Epoch: 17, Steps: 265 Train Loss: 35.9310 (Forecasting Loss:0.1889 + XiCon Loss:3.5742 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 35.1065254
	speed: 0.0492s/iter; left time: 1077.9186s
	iters: 200, epoch: 18 | loss: 37.1862373
	speed: 0.0471s/iter; left time: 1027.0641s
Epoch: 18 cost time: 12.652565002441406
Epoch: 18, Steps: 265 Train Loss: 35.8105 (Forecasting Loss:0.1888 + XiCon Loss:3.5622 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 34.1321907
	speed: 0.0485s/iter; left time: 1048.2293s
	iters: 200, epoch: 19 | loss: 35.7348251
	speed: 0.0468s/iter; left time: 1008.5828s
Epoch: 19 cost time: 12.616648435592651
Epoch: 19, Steps: 265 Train Loss: 35.8966 (Forecasting Loss:0.1889 + XiCon Loss:3.5708 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 38.0298576
	speed: 0.0501s/iter; left time: 1069.9363s
	iters: 200, epoch: 20 | loss: 36.7968750
	speed: 0.0475s/iter; left time: 1009.5231s
Epoch: 20 cost time: 12.917658805847168
Epoch: 20, Steps: 265 Train Loss: 35.9963 (Forecasting Loss:0.1888 + XiCon Loss:3.5808 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 35.6127701
	speed: 0.0486s/iter; left time: 1025.3965s
	iters: 200, epoch: 21 | loss: 36.3570862
	speed: 0.0468s/iter; left time: 982.1270s
Epoch: 21 cost time: 12.675430536270142
Epoch: 21, Steps: 265 Train Loss: 35.8707 (Forecasting Loss:0.1888 + XiCon Loss:3.5682 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0942
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 39.0991554
	speed: 0.0502s/iter; left time: 1046.8491s
	iters: 200, epoch: 22 | loss: 35.5441971
	speed: 0.0471s/iter; left time: 976.3327s
Epoch: 22 cost time: 12.831861972808838
Epoch: 22, Steps: 265 Train Loss: 35.8059 (Forecasting Loss:0.1889 + XiCon Loss:3.5617 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 35.4970093
	speed: 0.0493s/iter; left time: 1014.7934s
	iters: 200, epoch: 23 | loss: 36.5628014
	speed: 0.0469s/iter; left time: 959.7220s
Epoch: 23 cost time: 12.717170000076294
Epoch: 23, Steps: 265 Train Loss: 35.9237 (Forecasting Loss:0.1889 + XiCon Loss:3.5735 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0942
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039159394800662994, mae:0.14928185939788818, mape:0.11848524957895279, mspe:0.02630811557173729 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.7861
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.8149223
	speed: 0.0475s/iter; left time: 1253.8777s
	iters: 200, epoch: 1 | loss: 33.3329849
	speed: 0.0458s/iter; left time: 1205.7591s
Epoch: 1 cost time: 12.315019845962524
Epoch: 1, Steps: 265 Train Loss: 33.9427 (Forecasting Loss:0.2125 + XiCon Loss:3.3730 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.148298).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 37.1700363
	speed: 0.0495s/iter; left time: 1295.0315s
	iters: 200, epoch: 2 | loss: 33.0094109
	speed: 0.0469s/iter; left time: 1221.2030s
Epoch: 2 cost time: 12.771402359008789
Epoch: 2, Steps: 265 Train Loss: 35.2416 (Forecasting Loss:0.1987 + XiCon Loss:3.5043 x Lambda(10.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.0967
Validation loss decreased (0.148298 --> 0.145993).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.5103683
	speed: 0.0500s/iter; left time: 1293.5856s
	iters: 200, epoch: 3 | loss: 34.0042267
	speed: 0.0460s/iter; left time: 1184.5035s
Epoch: 3 cost time: 12.672300100326538
Epoch: 3, Steps: 265 Train Loss: 34.4539 (Forecasting Loss:0.1931 + XiCon Loss:3.4261 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0956
Validation loss decreased (0.145993 --> 0.143153).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.0010605
	speed: 0.0496s/iter; left time: 1270.7065s
	iters: 200, epoch: 4 | loss: 32.6611099
	speed: 0.0468s/iter; left time: 1194.4506s
Epoch: 4 cost time: 12.752872467041016
Epoch: 4, Steps: 265 Train Loss: 33.9046 (Forecasting Loss:0.1914 + XiCon Loss:3.3713 x Lambda(10.0)), Vali MSE Loss: 0.1428 Test MSE Loss: 0.0952
Validation loss decreased (0.143153 --> 0.142801).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 34.8384209
	speed: 0.0492s/iter; left time: 1245.5193s
	iters: 200, epoch: 5 | loss: 34.0236359
	speed: 0.0466s/iter; left time: 1176.7095s
Epoch: 5 cost time: 12.677120923995972
Epoch: 5, Steps: 265 Train Loss: 33.7616 (Forecasting Loss:0.1900 + XiCon Loss:3.3572 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0955
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.5603256
	speed: 0.0489s/iter; left time: 1227.1899s
	iters: 200, epoch: 6 | loss: 33.3313942
	speed: 0.0473s/iter; left time: 1180.8410s
Epoch: 6 cost time: 12.747699975967407
Epoch: 6, Steps: 265 Train Loss: 33.4742 (Forecasting Loss:0.1897 + XiCon Loss:3.3284 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0949
Validation loss decreased (0.142801 --> 0.142073).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.7567177
	speed: 0.0492s/iter; left time: 1219.4829s
	iters: 200, epoch: 7 | loss: 34.1094017
	speed: 0.0469s/iter; left time: 1158.8003s
Epoch: 7 cost time: 12.744832754135132
Epoch: 7, Steps: 265 Train Loss: 33.3954 (Forecasting Loss:0.1894 + XiCon Loss:3.3206 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0950
Validation loss decreased (0.142073 --> 0.142052).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.8052292
	speed: 0.0482s/iter; left time: 1184.1466s
	iters: 200, epoch: 8 | loss: 34.0425415
	speed: 0.0465s/iter; left time: 1137.5905s
Epoch: 8 cost time: 12.585883378982544
Epoch: 8, Steps: 265 Train Loss: 33.4328 (Forecasting Loss:0.1892 + XiCon Loss:3.3244 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
Validation loss decreased (0.142052 --> 0.141792).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.3311958
	speed: 0.0490s/iter; left time: 1190.8915s
	iters: 200, epoch: 9 | loss: 33.3912773
	speed: 0.0477s/iter; left time: 1153.2927s
Epoch: 9 cost time: 12.766226053237915
Epoch: 9, Steps: 265 Train Loss: 33.2998 (Forecasting Loss:0.1891 + XiCon Loss:3.3111 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
Validation loss decreased (0.141792 --> 0.141630).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.0823364
	speed: 0.0489s/iter; left time: 1175.4238s
	iters: 200, epoch: 10 | loss: 32.9233437
	speed: 0.0477s/iter; left time: 1141.0814s
Epoch: 10 cost time: 12.767728328704834
Epoch: 10, Steps: 265 Train Loss: 33.3277 (Forecasting Loss:0.1890 + XiCon Loss:3.3139 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.9880867
	speed: 0.0493s/iter; left time: 1169.8843s
	iters: 200, epoch: 11 | loss: 32.6973305
	speed: 0.0476s/iter; left time: 1125.2296s
Epoch: 11 cost time: 12.758257627487183
Epoch: 11, Steps: 265 Train Loss: 33.3120 (Forecasting Loss:0.1891 + XiCon Loss:3.3123 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
Validation loss decreased (0.141630 --> 0.141630).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.4496460
	speed: 0.0487s/iter; left time: 1143.2642s
	iters: 200, epoch: 12 | loss: 33.0054092
	speed: 0.0468s/iter; left time: 1094.0160s
Epoch: 12 cost time: 12.627713441848755
Epoch: 12, Steps: 265 Train Loss: 33.2697 (Forecasting Loss:0.1890 + XiCon Loss:3.3081 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.0755005
	speed: 0.0495s/iter; left time: 1148.7389s
	iters: 200, epoch: 13 | loss: 33.0470772
	speed: 0.0475s/iter; left time: 1099.2220s
Epoch: 13 cost time: 12.802447080612183
Epoch: 13, Steps: 265 Train Loss: 33.2950 (Forecasting Loss:0.1890 + XiCon Loss:3.3106 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 34.3010025
	speed: 0.0501s/iter; left time: 1149.5850s
	iters: 200, epoch: 14 | loss: 33.2266273
	speed: 0.0475s/iter; left time: 1086.3530s
Epoch: 14 cost time: 12.850173234939575
Epoch: 14, Steps: 265 Train Loss: 33.3288 (Forecasting Loss:0.1890 + XiCon Loss:3.3140 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.5478401
	speed: 0.0495s/iter; left time: 1122.2105s
	iters: 200, epoch: 15 | loss: 33.4216614
	speed: 0.0470s/iter; left time: 1061.8444s
Epoch: 15 cost time: 12.737552404403687
Epoch: 15, Steps: 265 Train Loss: 33.3294 (Forecasting Loss:0.1889 + XiCon Loss:3.3141 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.9432335
	speed: 0.0485s/iter; left time: 1087.8667s
	iters: 200, epoch: 16 | loss: 33.5119858
	speed: 0.0478s/iter; left time: 1067.3504s
Epoch: 16 cost time: 12.715282917022705
Epoch: 16, Steps: 265 Train Loss: 33.2859 (Forecasting Loss:0.1889 + XiCon Loss:3.3097 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.4435234
	speed: 0.0487s/iter; left time: 1079.9222s
	iters: 200, epoch: 17 | loss: 33.9551697
	speed: 0.0467s/iter; left time: 1031.0217s
Epoch: 17 cost time: 12.596272945404053
Epoch: 17, Steps: 265 Train Loss: 33.2903 (Forecasting Loss:0.1890 + XiCon Loss:3.3101 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.4611626
	speed: 0.0488s/iter; left time: 1069.4821s
	iters: 200, epoch: 18 | loss: 33.9543839
	speed: 0.0466s/iter; left time: 1016.7646s
Epoch: 18 cost time: 12.623844861984253
Epoch: 18, Steps: 265 Train Loss: 33.3504 (Forecasting Loss:0.1889 + XiCon Loss:3.3161 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 34.0409317
	speed: 0.0491s/iter; left time: 1062.0311s
	iters: 200, epoch: 19 | loss: 33.2769737
	speed: 0.0465s/iter; left time: 1002.2589s
Epoch: 19 cost time: 12.59935474395752
Epoch: 19, Steps: 265 Train Loss: 33.3058 (Forecasting Loss:0.1890 + XiCon Loss:3.3117 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.7122231
	speed: 0.0494s/iter; left time: 1056.4544s
	iters: 200, epoch: 20 | loss: 33.2790337
	speed: 0.0473s/iter; left time: 1006.4838s
Epoch: 20 cost time: 12.788978576660156
Epoch: 20, Steps: 265 Train Loss: 33.3197 (Forecasting Loss:0.1890 + XiCon Loss:3.3131 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.4668274
	speed: 0.0492s/iter; left time: 1038.1220s
	iters: 200, epoch: 21 | loss: 33.0978546
	speed: 0.0465s/iter; left time: 977.3263s
Epoch: 21 cost time: 12.613542795181274
Epoch: 21, Steps: 265 Train Loss: 33.2973 (Forecasting Loss:0.1891 + XiCon Loss:3.3108 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03965204954147339, mae:0.1502009630203247, mape:0.11918768286705017, mspe:0.02646288275718689 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0398+-0.00081, MAE:0.1502+-0.00110, MAPE:0.1192+-0.00080, MSPE:0.0266+-0.00038, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6766
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5863847
	speed: 0.0397s/iter; left time: 1043.8607s
	iters: 200, epoch: 1 | loss: 0.6017259
	speed: 0.0346s/iter; left time: 907.0948s
Epoch: 1 cost time: 9.671535015106201
Epoch: 1, Steps: 264 Train Loss: 0.5790 (Forecasting Loss:0.2365 + XiCon Loss:3.4257 x Lambda(0.1)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1154
Validation loss decreased (inf --> 0.172859).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.6052573
	speed: 0.0425s/iter; left time: 1105.4279s
	iters: 200, epoch: 2 | loss: 0.5984631
	speed: 0.0380s/iter; left time: 984.3636s
Epoch: 2 cost time: 10.523438692092896
Epoch: 2, Steps: 264 Train Loss: 0.5764 (Forecasting Loss:0.2442 + XiCon Loss:3.3225 x Lambda(0.1)), Vali MSE Loss: 0.1789 Test MSE Loss: 0.1182
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5539506
	speed: 0.0393s/iter; left time: 1012.3067s
	iters: 200, epoch: 3 | loss: 0.5166041
	speed: 0.0372s/iter; left time: 955.9626s
Epoch: 3 cost time: 10.084202527999878
Epoch: 3, Steps: 264 Train Loss: 0.5594 (Forecasting Loss:0.2339 + XiCon Loss:3.2543 x Lambda(0.1)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.1138
Validation loss decreased (0.172859 --> 0.172345).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5338706
	speed: 0.0388s/iter; left time: 988.6592s
	iters: 200, epoch: 4 | loss: 0.5785466
	speed: 0.0379s/iter; left time: 961.9231s
Epoch: 4 cost time: 10.10456919670105
Epoch: 4, Steps: 264 Train Loss: 0.5533 (Forecasting Loss:0.2299 + XiCon Loss:3.2345 x Lambda(0.1)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1139
Validation loss decreased (0.172345 --> 0.171860).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5500504
	speed: 0.0402s/iter; left time: 1013.6095s
	iters: 200, epoch: 5 | loss: 0.5309644
	speed: 0.0373s/iter; left time: 939.0281s
Epoch: 5 cost time: 10.213032722473145
Epoch: 5, Steps: 264 Train Loss: 0.5511 (Forecasting Loss:0.2284 + XiCon Loss:3.2268 x Lambda(0.1)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1127
Validation loss decreased (0.171860 --> 0.171119).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5439941
	speed: 0.0388s/iter; left time: 968.3974s
	iters: 200, epoch: 6 | loss: 0.5366507
	speed: 0.0369s/iter; left time: 917.8121s
Epoch: 6 cost time: 9.95726227760315
Epoch: 6, Steps: 264 Train Loss: 0.5501 (Forecasting Loss:0.2275 + XiCon Loss:3.2263 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1126
Validation loss decreased (0.171119 --> 0.170316).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5608346
	speed: 0.0399s/iter; left time: 986.4833s
	iters: 200, epoch: 7 | loss: 0.5374138
	speed: 0.0371s/iter; left time: 913.0963s
Epoch: 7 cost time: 10.115077495574951
Epoch: 7, Steps: 264 Train Loss: 0.5493 (Forecasting Loss:0.2269 + XiCon Loss:3.2246 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1130
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5371143
	speed: 0.0399s/iter; left time: 974.6191s
	iters: 200, epoch: 8 | loss: 0.5556794
	speed: 0.0369s/iter; left time: 898.9909s
Epoch: 8 cost time: 10.159247636795044
Epoch: 8, Steps: 264 Train Loss: 0.5492 (Forecasting Loss:0.2266 + XiCon Loss:3.2252 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
Validation loss decreased (0.170316 --> 0.170095).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5339354
	speed: 0.0397s/iter; left time: 960.8060s
	iters: 200, epoch: 9 | loss: 0.5442494
	speed: 0.0364s/iter; left time: 877.5312s
Epoch: 9 cost time: 10.069901466369629
Epoch: 9, Steps: 264 Train Loss: 0.5488 (Forecasting Loss:0.2265 + XiCon Loss:3.2232 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1127
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5760089
	speed: 0.0394s/iter; left time: 941.8213s
	iters: 200, epoch: 10 | loss: 0.5624300
	speed: 0.0376s/iter; left time: 895.8763s
Epoch: 10 cost time: 10.15526556968689
Epoch: 10, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2265 + XiCon Loss:3.2227 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170095 --> 0.169995).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5414218
	speed: 0.0401s/iter; left time: 948.4139s
	iters: 200, epoch: 11 | loss: 0.5376212
	speed: 0.0380s/iter; left time: 894.9321s
Epoch: 11 cost time: 10.214284181594849
Epoch: 11, Steps: 264 Train Loss: 0.5483 (Forecasting Loss:0.2263 + XiCon Loss:3.2205 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5695957
	speed: 0.0395s/iter; left time: 925.0561s
	iters: 200, epoch: 12 | loss: 0.5408905
	speed: 0.0373s/iter; left time: 868.4623s
Epoch: 12 cost time: 10.085424900054932
Epoch: 12, Steps: 264 Train Loss: 0.5488 (Forecasting Loss:0.2264 + XiCon Loss:3.2241 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5379648
	speed: 0.0395s/iter; left time: 913.2238s
	iters: 200, epoch: 13 | loss: 0.5311996
	speed: 0.0375s/iter; left time: 863.6731s
Epoch: 13 cost time: 10.25790286064148
Epoch: 13, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2264 + XiCon Loss:3.2227 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5651275
	speed: 0.0409s/iter; left time: 935.7340s
	iters: 200, epoch: 14 | loss: 0.5401539
	speed: 0.0375s/iter; left time: 854.7849s
Epoch: 14 cost time: 10.280759334564209
Epoch: 14, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2263 + XiCon Loss:3.2235 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5536363
	speed: 0.0398s/iter; left time: 898.6332s
	iters: 200, epoch: 15 | loss: 0.5561154
	speed: 0.0376s/iter; left time: 845.7461s
Epoch: 15 cost time: 10.097107887268066
Epoch: 15, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2263 + XiCon Loss:3.2242 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5342452
	speed: 0.0398s/iter; left time: 890.1465s
	iters: 200, epoch: 16 | loss: 0.5480282
	speed: 0.0373s/iter; left time: 830.5542s
Epoch: 16 cost time: 10.149937868118286
Epoch: 16, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2263 + XiCon Loss:3.2222 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5519645
	speed: 0.0396s/iter; left time: 875.0715s
	iters: 200, epoch: 17 | loss: 0.5467848
	speed: 0.0374s/iter; left time: 822.9086s
Epoch: 17 cost time: 10.159444332122803
Epoch: 17, Steps: 264 Train Loss: 0.5492 (Forecasting Loss:0.2263 + XiCon Loss:3.2281 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1125
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5542864
	speed: 0.0400s/iter; left time: 872.1949s
	iters: 200, epoch: 18 | loss: 0.5384420
	speed: 0.0366s/iter; left time: 795.0537s
Epoch: 18 cost time: 10.099029064178467
Epoch: 18, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2264 + XiCon Loss:3.2216 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5371930
	speed: 0.0396s/iter; left time: 852.7155s
	iters: 200, epoch: 19 | loss: 0.5680208
	speed: 0.0385s/iter; left time: 825.9025s
Epoch: 19 cost time: 10.238544225692749
Epoch: 19, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2262 + XiCon Loss:3.2223 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5605499
	speed: 0.0396s/iter; left time: 842.6949s
	iters: 200, epoch: 20 | loss: 0.5435731
	speed: 0.0376s/iter; left time: 796.7896s
Epoch: 20 cost time: 10.179672479629517
Epoch: 20, Steps: 264 Train Loss: 0.5483 (Forecasting Loss:0.2263 + XiCon Loss:3.2198 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1125
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.052554093301296234, mae:0.17247843742370605, mape:0.1345963478088379, mspe:0.03225688636302948 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.0664
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5747579
	speed: 0.0373s/iter; left time: 980.3513s
	iters: 200, epoch: 1 | loss: 0.5712873
	speed: 0.0339s/iter; left time: 888.2571s
Epoch: 1 cost time: 9.318689584732056
Epoch: 1, Steps: 264 Train Loss: 0.5824 (Forecasting Loss:0.2380 + XiCon Loss:3.4444 x Lambda(0.1)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1145
Validation loss decreased (inf --> 0.172752).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5845912
	speed: 0.0410s/iter; left time: 1068.6229s
	iters: 200, epoch: 2 | loss: 0.5410838
	speed: 0.0379s/iter; left time: 983.6834s
Epoch: 2 cost time: 10.362400531768799
Epoch: 2, Steps: 264 Train Loss: 0.5734 (Forecasting Loss:0.2415 + XiCon Loss:3.3190 x Lambda(0.1)), Vali MSE Loss: 0.1781 Test MSE Loss: 0.1172
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5278385
	speed: 0.0402s/iter; left time: 1035.9853s
	iters: 200, epoch: 3 | loss: 0.5729908
	speed: 0.0376s/iter; left time: 964.4433s
Epoch: 3 cost time: 10.198732137680054
Epoch: 3, Steps: 264 Train Loss: 0.5552 (Forecasting Loss:0.2342 + XiCon Loss:3.2100 x Lambda(0.1)), Vali MSE Loss: 0.1751 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5402640
	speed: 0.0398s/iter; left time: 1015.4546s
	iters: 200, epoch: 4 | loss: 0.5767837
	speed: 0.0373s/iter; left time: 947.4246s
Epoch: 4 cost time: 10.173949480056763
Epoch: 4, Steps: 264 Train Loss: 0.5506 (Forecasting Loss:0.2310 + XiCon Loss:3.1963 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1133
Validation loss decreased (0.172752 --> 0.170909).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5580239
	speed: 0.0400s/iter; left time: 1009.0141s
	iters: 200, epoch: 5 | loss: 0.5671339
	speed: 0.0379s/iter; left time: 953.9379s
Epoch: 5 cost time: 10.188225269317627
Epoch: 5, Steps: 264 Train Loss: 0.5473 (Forecasting Loss:0.2284 + XiCon Loss:3.1892 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1139
Validation loss decreased (0.170909 --> 0.170809).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5564235
	speed: 0.0400s/iter; left time: 999.7307s
	iters: 200, epoch: 6 | loss: 0.5486282
	speed: 0.0384s/iter; left time: 956.5181s
Epoch: 6 cost time: 10.327350616455078
Epoch: 6, Steps: 264 Train Loss: 0.5462 (Forecasting Loss:0.2274 + XiCon Loss:3.1882 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1130
Validation loss decreased (0.170809 --> 0.170054).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5350232
	speed: 0.0398s/iter; left time: 983.7285s
	iters: 200, epoch: 7 | loss: 0.5555527
	speed: 0.0391s/iter; left time: 963.4631s
Epoch: 7 cost time: 10.304500579833984
Epoch: 7, Steps: 264 Train Loss: 0.5457 (Forecasting Loss:0.2267 + XiCon Loss:3.1898 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1129
Validation loss decreased (0.170054 --> 0.169785).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5395414
	speed: 0.0402s/iter; left time: 982.5275s
	iters: 200, epoch: 8 | loss: 0.5536691
	speed: 0.0375s/iter; left time: 912.7235s
Epoch: 8 cost time: 10.176772832870483
Epoch: 8, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2263 + XiCon Loss:3.1870 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1133
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5473225
	speed: 0.0404s/iter; left time: 977.4932s
	iters: 200, epoch: 9 | loss: 0.5128133
	speed: 0.0383s/iter; left time: 921.4562s
Epoch: 9 cost time: 10.258610725402832
Epoch: 9, Steps: 264 Train Loss: 0.5449 (Forecasting Loss:0.2265 + XiCon Loss:3.1839 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1127
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5429358
	speed: 0.0406s/iter; left time: 971.6068s
	iters: 200, epoch: 10 | loss: 0.5619456
	speed: 0.0374s/iter; left time: 890.5214s
Epoch: 10 cost time: 10.288071632385254
Epoch: 10, Steps: 264 Train Loss: 0.5454 (Forecasting Loss:0.2264 + XiCon Loss:3.1901 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5455649
	speed: 0.0403s/iter; left time: 952.8010s
	iters: 200, epoch: 11 | loss: 0.5392632
	speed: 0.0379s/iter; left time: 894.0109s
Epoch: 11 cost time: 10.263409852981567
Epoch: 11, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2263 + XiCon Loss:3.1868 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1129
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5593735
	speed: 0.0398s/iter; left time: 931.2340s
	iters: 200, epoch: 12 | loss: 0.5254409
	speed: 0.0385s/iter; left time: 897.1632s
Epoch: 12 cost time: 10.273744344711304
Epoch: 12, Steps: 264 Train Loss: 0.5452 (Forecasting Loss:0.2263 + XiCon Loss:3.1886 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
Validation loss decreased (0.169785 --> 0.169783).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5365900
	speed: 0.0398s/iter; left time: 920.6482s
	iters: 200, epoch: 13 | loss: 0.5412023
	speed: 0.0383s/iter; left time: 882.0134s
Epoch: 13 cost time: 10.230660200119019
Epoch: 13, Steps: 264 Train Loss: 0.5449 (Forecasting Loss:0.2262 + XiCon Loss:3.1868 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5325338
	speed: 0.0396s/iter; left time: 906.1271s
	iters: 200, epoch: 14 | loss: 0.5538504
	speed: 0.0378s/iter; left time: 861.1388s
Epoch: 14 cost time: 10.199848175048828
Epoch: 14, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2262 + XiCon Loss:3.1885 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5587002
	speed: 0.0404s/iter; left time: 914.2835s
	iters: 200, epoch: 15 | loss: 0.5458204
	speed: 0.0375s/iter; left time: 843.6630s
Epoch: 15 cost time: 10.215511083602905
Epoch: 15, Steps: 264 Train Loss: 0.5449 (Forecasting Loss:0.2262 + XiCon Loss:3.1868 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5395970
	speed: 0.0397s/iter; left time: 886.2128s
	iters: 200, epoch: 16 | loss: 0.5398385
	speed: 0.0394s/iter; left time: 875.6719s
Epoch: 16 cost time: 10.428351163864136
Epoch: 16, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2262 + XiCon Loss:3.1877 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
Validation loss decreased (0.169783 --> 0.169767).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5259519
	speed: 0.0402s/iter; left time: 887.5012s
	iters: 200, epoch: 17 | loss: 0.5725917
	speed: 0.0377s/iter; left time: 828.3092s
Epoch: 17 cost time: 10.263545513153076
Epoch: 17, Steps: 264 Train Loss: 0.5448 (Forecasting Loss:0.2262 + XiCon Loss:3.1862 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
Validation loss decreased (0.169767 --> 0.169766).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5551147
	speed: 0.0400s/iter; left time: 872.6273s
	iters: 200, epoch: 18 | loss: 0.5755829
	speed: 0.0388s/iter; left time: 841.5396s
Epoch: 18 cost time: 10.278862237930298
Epoch: 18, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2262 + XiCon Loss:3.1878 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5632998
	speed: 0.0393s/iter; left time: 846.7223s
	iters: 200, epoch: 19 | loss: 0.5396419
	speed: 0.0386s/iter; left time: 828.5322s
Epoch: 19 cost time: 10.268519401550293
Epoch: 19, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2263 + XiCon Loss:3.1872 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5475079
	speed: 0.0403s/iter; left time: 858.4443s
	iters: 200, epoch: 20 | loss: 0.5176534
	speed: 0.0379s/iter; left time: 802.0024s
Epoch: 20 cost time: 10.271066665649414
Epoch: 20, Steps: 264 Train Loss: 0.5446 (Forecasting Loss:0.2262 + XiCon Loss:3.1845 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1128
Validation loss decreased (0.169766 --> 0.169658).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5387431
	speed: 0.0402s/iter; left time: 846.0539s
	iters: 200, epoch: 21 | loss: 0.5933158
	speed: 0.0372s/iter; left time: 778.5461s
Epoch: 21 cost time: 10.109878301620483
Epoch: 21, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2264 + XiCon Loss:3.1862 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 0.5568892
	speed: 0.0403s/iter; left time: 835.8042s
	iters: 200, epoch: 22 | loss: 0.5655124
	speed: 0.0389s/iter; left time: 802.6294s
Epoch: 22 cost time: 10.298032522201538
Epoch: 22, Steps: 264 Train Loss: 0.5448 (Forecasting Loss:0.2263 + XiCon Loss:3.1851 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 0.5483880
	speed: 0.0399s/iter; left time: 818.2111s
	iters: 200, epoch: 23 | loss: 0.5380614
	speed: 0.0376s/iter; left time: 767.5882s
Epoch: 23 cost time: 10.170866012573242
Epoch: 23, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2263 + XiCon Loss:3.1869 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 0.5231337
	speed: 0.0400s/iter; left time: 810.1379s
	iters: 200, epoch: 24 | loss: 0.5386446
	speed: 0.0383s/iter; left time: 770.3144s
Epoch: 24 cost time: 10.295695304870605
Epoch: 24, Steps: 264 Train Loss: 0.5448 (Forecasting Loss:0.2262 + XiCon Loss:3.1862 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 0.5319649
	speed: 0.0389s/iter; left time: 776.4708s
	iters: 200, epoch: 25 | loss: 0.5188874
	speed: 0.0381s/iter; left time: 757.4947s
Epoch: 25 cost time: 10.133164644241333
Epoch: 25, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2262 + XiCon Loss:3.1884 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 0.5567155
	speed: 0.0402s/iter; left time: 792.4695s
	iters: 200, epoch: 26 | loss: 0.5447183
	speed: 0.0379s/iter; left time: 743.2754s
Epoch: 26 cost time: 10.235597133636475
Epoch: 26, Steps: 264 Train Loss: 0.5451 (Forecasting Loss:0.2263 + XiCon Loss:3.1880 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 0.5828377
	speed: 0.0403s/iter; left time: 783.9874s
	iters: 200, epoch: 27 | loss: 0.5431321
	speed: 0.0374s/iter; left time: 724.1341s
Epoch: 27 cost time: 10.245326042175293
Epoch: 27, Steps: 264 Train Loss: 0.5451 (Forecasting Loss:0.2263 + XiCon Loss:3.1874 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 0.5458719
	speed: 0.0398s/iter; left time: 762.4383s
	iters: 200, epoch: 28 | loss: 0.5569769
	speed: 0.0379s/iter; left time: 723.7595s
Epoch: 28 cost time: 10.243513584136963
Epoch: 28, Steps: 264 Train Loss: 0.5449 (Forecasting Loss:0.2262 + XiCon Loss:3.1869 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 0.5395280
	speed: 0.0400s/iter; left time: 755.9969s
	iters: 200, epoch: 29 | loss: 0.5504415
	speed: 0.0379s/iter; left time: 713.7322s
Epoch: 29 cost time: 10.250014305114746
Epoch: 29, Steps: 264 Train Loss: 0.5452 (Forecasting Loss:0.2263 + XiCon Loss:3.1892 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 0.5264194
	speed: 0.0401s/iter; left time: 746.8486s
	iters: 200, epoch: 30 | loss: 0.5393032
	speed: 0.0377s/iter; left time: 698.4992s
Epoch: 30 cost time: 10.210118055343628
Epoch: 30, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2263 + XiCon Loss:3.1871 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1128
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05288315564393997, mae:0.1727197766304016, mape:0.1345611810684204, mspe:0.03224700689315796 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.2039
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5675129
	speed: 0.0373s/iter; left time: 982.1513s
	iters: 200, epoch: 1 | loss: 0.5677142
	speed: 0.0348s/iter; left time: 911.5348s
Epoch: 1 cost time: 9.423816680908203
Epoch: 1, Steps: 264 Train Loss: 0.5802 (Forecasting Loss:0.2366 + XiCon Loss:3.4364 x Lambda(0.1)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1149
Validation loss decreased (inf --> 0.173534).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5182318
	speed: 0.0433s/iter; left time: 1127.5063s
	iters: 200, epoch: 2 | loss: 0.5659630
	speed: 0.0410s/iter; left time: 1064.4195s
Epoch: 2 cost time: 10.955881595611572
Epoch: 2, Steps: 264 Train Loss: 0.5702 (Forecasting Loss:0.2405 + XiCon Loss:3.2969 x Lambda(0.1)), Vali MSE Loss: 0.1760 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5633322
	speed: 0.0399s/iter; left time: 1028.7003s
	iters: 200, epoch: 3 | loss: 0.5481061
	speed: 0.0379s/iter; left time: 971.7663s
Epoch: 3 cost time: 10.25198769569397
Epoch: 3, Steps: 264 Train Loss: 0.5566 (Forecasting Loss:0.2327 + XiCon Loss:3.2386 x Lambda(0.1)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1145
Validation loss decreased (0.173534 --> 0.172902).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5365565
	speed: 0.0400s/iter; left time: 1019.2374s
	iters: 200, epoch: 4 | loss: 0.5381263
	speed: 0.0380s/iter; left time: 965.2072s
Epoch: 4 cost time: 10.258071660995483
Epoch: 4, Steps: 264 Train Loss: 0.5521 (Forecasting Loss:0.2292 + XiCon Loss:3.2285 x Lambda(0.1)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1148
Validation loss decreased (0.172902 --> 0.171382).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5408937
	speed: 0.0392s/iter; left time: 989.5342s
	iters: 200, epoch: 5 | loss: 0.5573094
	speed: 0.0370s/iter; left time: 931.4317s
Epoch: 5 cost time: 10.071637868881226
Epoch: 5, Steps: 264 Train Loss: 0.5490 (Forecasting Loss:0.2264 + XiCon Loss:3.2263 x Lambda(0.1)), Vali MSE Loss: 0.1774 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5614485
	speed: 0.0394s/iter; left time: 985.0559s
	iters: 200, epoch: 6 | loss: 0.5545949
	speed: 0.0374s/iter; left time: 930.1202s
Epoch: 6 cost time: 10.095670938491821
Epoch: 6, Steps: 264 Train Loss: 0.5471 (Forecasting Loss:0.2248 + XiCon Loss:3.2228 x Lambda(0.1)), Vali MSE Loss: 0.1787 Test MSE Loss: 0.1159
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5722913
	speed: 0.0396s/iter; left time: 979.6442s
	iters: 200, epoch: 7 | loss: 0.5475584
	speed: 0.0379s/iter; left time: 933.6337s
Epoch: 7 cost time: 10.189845561981201
Epoch: 7, Steps: 264 Train Loss: 0.5461 (Forecasting Loss:0.2239 + XiCon Loss:3.2223 x Lambda(0.1)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1165
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5561687
	speed: 0.0401s/iter; left time: 981.6435s
	iters: 200, epoch: 8 | loss: 0.5545701
	speed: 0.0376s/iter; left time: 916.2856s
Epoch: 8 cost time: 10.21982741355896
Epoch: 8, Steps: 264 Train Loss: 0.5457 (Forecasting Loss:0.2237 + XiCon Loss:3.2197 x Lambda(0.1)), Vali MSE Loss: 0.1759 Test MSE Loss: 0.1158
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5359336
	speed: 0.0404s/iter; left time: 976.6031s
	iters: 200, epoch: 9 | loss: 0.5446109
	speed: 0.0373s/iter; left time: 899.2203s
Epoch: 9 cost time: 10.231647491455078
Epoch: 9, Steps: 264 Train Loss: 0.5453 (Forecasting Loss:0.2233 + XiCon Loss:3.2200 x Lambda(0.1)), Vali MSE Loss: 0.1776 Test MSE Loss: 0.1172
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5661662
	speed: 0.0407s/iter; left time: 974.4404s
	iters: 200, epoch: 10 | loss: 0.5191240
	speed: 0.0381s/iter; left time: 906.6936s
Epoch: 10 cost time: 10.308873653411865
Epoch: 10, Steps: 264 Train Loss: 0.5452 (Forecasting Loss:0.2233 + XiCon Loss:3.2197 x Lambda(0.1)), Vali MSE Loss: 0.1764 Test MSE Loss: 0.1165
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5069503
	speed: 0.0399s/iter; left time: 943.3537s
	iters: 200, epoch: 11 | loss: 0.5525811
	speed: 0.0377s/iter; left time: 889.0583s
Epoch: 11 cost time: 10.17149806022644
Epoch: 11, Steps: 264 Train Loss: 0.5451 (Forecasting Loss:0.2231 + XiCon Loss:3.2202 x Lambda(0.1)), Vali MSE Loss: 0.1763 Test MSE Loss: 0.1165
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5538417
	speed: 0.0401s/iter; left time: 938.1268s
	iters: 200, epoch: 12 | loss: 0.5258433
	speed: 0.0380s/iter; left time: 885.5032s
Epoch: 12 cost time: 10.169995307922363
Epoch: 12, Steps: 264 Train Loss: 0.5449 (Forecasting Loss:0.2233 + XiCon Loss:3.2165 x Lambda(0.1)), Vali MSE Loss: 0.1762 Test MSE Loss: 0.1164
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5350060
	speed: 0.0399s/iter; left time: 923.3575s
	iters: 200, epoch: 13 | loss: 0.5516989
	speed: 0.0382s/iter; left time: 880.3605s
Epoch: 13 cost time: 10.233904600143433
Epoch: 13, Steps: 264 Train Loss: 0.5452 (Forecasting Loss:0.2230 + XiCon Loss:3.2214 x Lambda(0.1)), Vali MSE Loss: 0.1762 Test MSE Loss: 0.1164
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5380532
	speed: 0.0396s/iter; left time: 904.6336s
	iters: 200, epoch: 14 | loss: 0.5314269
	speed: 0.0379s/iter; left time: 863.8299s
Epoch: 14 cost time: 10.160000801086426
Epoch: 14, Steps: 264 Train Loss: 0.5450 (Forecasting Loss:0.2230 + XiCon Loss:3.2203 x Lambda(0.1)), Vali MSE Loss: 0.1764 Test MSE Loss: 0.1165
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05433208495378494, mae:0.17522409558296204, mape:0.13675503432750702, mspe:0.03349880501627922 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.9049
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5922841
	speed: 0.0372s/iter; left time: 977.4148s
	iters: 200, epoch: 1 | loss: 0.5479026
	speed: 0.0342s/iter; left time: 895.0632s
Epoch: 1 cost time: 9.331084966659546
Epoch: 1, Steps: 264 Train Loss: 0.5796 (Forecasting Loss:0.2382 + XiCon Loss:3.4145 x Lambda(0.1)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1150
Validation loss decreased (inf --> 0.172440).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5525825
	speed: 0.0405s/iter; left time: 1053.7081s
	iters: 200, epoch: 2 | loss: 0.5684652
	speed: 0.0377s/iter; left time: 978.5598s
Epoch: 2 cost time: 10.265923500061035
Epoch: 2, Steps: 264 Train Loss: 0.5721 (Forecasting Loss:0.2429 + XiCon Loss:3.2924 x Lambda(0.1)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1188
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5474010
	speed: 0.0406s/iter; left time: 1046.4481s
	iters: 200, epoch: 3 | loss: 0.5518329
	speed: 0.0367s/iter; left time: 940.9164s
Epoch: 3 cost time: 10.110992908477783
Epoch: 3, Steps: 264 Train Loss: 0.5630 (Forecasting Loss:0.2337 + XiCon Loss:3.2933 x Lambda(0.1)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1132
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5335643
	speed: 0.0392s/iter; left time: 998.9009s
	iters: 200, epoch: 4 | loss: 0.5655863
	speed: 0.0372s/iter; left time: 946.4251s
Epoch: 4 cost time: 10.015623807907104
Epoch: 4, Steps: 264 Train Loss: 0.5550 (Forecasting Loss:0.2298 + XiCon Loss:3.2521 x Lambda(0.1)), Vali MSE Loss: 0.1732 Test MSE Loss: 0.1133
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5370383
	speed: 0.0391s/iter; left time: 987.2948s
	iters: 200, epoch: 5 | loss: 0.5295855
	speed: 0.0372s/iter; left time: 935.8482s
Epoch: 5 cost time: 10.021559238433838
Epoch: 5, Steps: 264 Train Loss: 0.5520 (Forecasting Loss:0.2277 + XiCon Loss:3.2427 x Lambda(0.1)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1116
Validation loss decreased (0.172440 --> 0.171644).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5403982
	speed: 0.0395s/iter; left time: 985.7842s
	iters: 200, epoch: 6 | loss: 0.5438495
	speed: 0.0368s/iter; left time: 914.5908s
Epoch: 6 cost time: 9.97098994255066
Epoch: 6, Steps: 264 Train Loss: 0.5509 (Forecasting Loss:0.2269 + XiCon Loss:3.2399 x Lambda(0.1)), Vali MSE Loss: 0.1712 Test MSE Loss: 0.1110
Validation loss decreased (0.171644 --> 0.171229).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5692345
	speed: 0.0389s/iter; left time: 960.2609s
	iters: 200, epoch: 7 | loss: 0.5576063
	speed: 0.0370s/iter; left time: 910.5505s
Epoch: 7 cost time: 10.058155059814453
Epoch: 7, Steps: 264 Train Loss: 0.5495 (Forecasting Loss:0.2264 + XiCon Loss:3.2314 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1105
Validation loss decreased (0.171229 --> 0.170763).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5421922
	speed: 0.0393s/iter; left time: 960.7827s
	iters: 200, epoch: 8 | loss: 0.5510513
	speed: 0.0373s/iter; left time: 907.7355s
Epoch: 8 cost time: 10.026362419128418
Epoch: 8, Steps: 264 Train Loss: 0.5492 (Forecasting Loss:0.2261 + XiCon Loss:3.2308 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1107
Validation loss decreased (0.170763 --> 0.170744).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5504058
	speed: 0.0393s/iter; left time: 949.5284s
	iters: 200, epoch: 9 | loss: 0.5403941
	speed: 0.0363s/iter; left time: 875.3811s
Epoch: 9 cost time: 9.956147909164429
Epoch: 9, Steps: 264 Train Loss: 0.5490 (Forecasting Loss:0.2260 + XiCon Loss:3.2307 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1109
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5472332
	speed: 0.0395s/iter; left time: 944.6432s
	iters: 200, epoch: 10 | loss: 0.5582750
	speed: 0.0377s/iter; left time: 898.9316s
Epoch: 10 cost time: 10.12024974822998
Epoch: 10, Steps: 264 Train Loss: 0.5490 (Forecasting Loss:0.2258 + XiCon Loss:3.2319 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5559478
	speed: 0.0383s/iter; left time: 907.3458s
	iters: 200, epoch: 11 | loss: 0.5492750
	speed: 0.0377s/iter; left time: 887.8587s
Epoch: 11 cost time: 10.058184385299683
Epoch: 11, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2258 + XiCon Loss:3.2270 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1109
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5762960
	speed: 0.0388s/iter; left time: 908.3458s
	iters: 200, epoch: 12 | loss: 0.5617142
	speed: 0.0370s/iter; left time: 861.3238s
Epoch: 12 cost time: 9.987221002578735
Epoch: 12, Steps: 264 Train Loss: 0.5483 (Forecasting Loss:0.2257 + XiCon Loss:3.2263 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5653805
	speed: 0.0391s/iter; left time: 905.6460s
	iters: 200, epoch: 13 | loss: 0.5323386
	speed: 0.0367s/iter; left time: 846.2827s
Epoch: 13 cost time: 9.936900854110718
Epoch: 13, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2257 + XiCon Loss:3.2306 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5716810
	speed: 0.0390s/iter; left time: 892.4396s
	iters: 200, epoch: 14 | loss: 0.5388870
	speed: 0.0363s/iter; left time: 827.0789s
Epoch: 14 cost time: 9.966031312942505
Epoch: 14, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2256 + XiCon Loss:3.2293 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5342270
	speed: 0.0390s/iter; left time: 881.4179s
	iters: 200, epoch: 15 | loss: 0.5408800
	speed: 0.0369s/iter; left time: 831.0858s
Epoch: 15 cost time: 9.979893922805786
Epoch: 15, Steps: 264 Train Loss: 0.5488 (Forecasting Loss:0.2257 + XiCon Loss:3.2306 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5509219
	speed: 0.0396s/iter; left time: 883.7177s
	iters: 200, epoch: 16 | loss: 0.5578218
	speed: 0.0367s/iter; left time: 816.1261s
Epoch: 16 cost time: 10.0429048538208
Epoch: 16, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2256 + XiCon Loss:3.2288 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1108
Validation loss decreased (0.170744 --> 0.170739).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5534181
	speed: 0.0394s/iter; left time: 870.9058s
	iters: 200, epoch: 17 | loss: 0.5617756
	speed: 0.0368s/iter; left time: 809.6916s
Epoch: 17 cost time: 10.051853895187378
Epoch: 17, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2257 + XiCon Loss:3.2297 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1108
Validation loss decreased (0.170739 --> 0.170732).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5346516
	speed: 0.0392s/iter; left time: 854.2928s
	iters: 200, epoch: 18 | loss: 0.5438324
	speed: 0.0364s/iter; left time: 790.4521s
Epoch: 18 cost time: 9.959892272949219
Epoch: 18, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2256 + XiCon Loss:3.2292 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5568240
	speed: 0.0394s/iter; left time: 849.1772s
	iters: 200, epoch: 19 | loss: 0.5542694
	speed: 0.0373s/iter; left time: 800.5103s
Epoch: 19 cost time: 10.078772783279419
Epoch: 19, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2258 + XiCon Loss:3.2293 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5866260
	speed: 0.0389s/iter; left time: 827.5665s
	iters: 200, epoch: 20 | loss: 0.5716119
	speed: 0.0372s/iter; left time: 787.6790s
Epoch: 20 cost time: 9.912123680114746
Epoch: 20, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2257 + XiCon Loss:3.2295 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5411757
	speed: 0.0396s/iter; left time: 833.3224s
	iters: 200, epoch: 21 | loss: 0.5978146
	speed: 0.0361s/iter; left time: 754.7420s
Epoch: 21 cost time: 9.991815567016602
Epoch: 21, Steps: 264 Train Loss: 0.5484 (Forecasting Loss:0.2257 + XiCon Loss:3.2277 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 0.5253752
	speed: 0.0385s/iter; left time: 799.7181s
	iters: 200, epoch: 22 | loss: 0.5349838
	speed: 0.0369s/iter; left time: 762.8668s
Epoch: 22 cost time: 9.917691469192505
Epoch: 22, Steps: 264 Train Loss: 0.5484 (Forecasting Loss:0.2257 + XiCon Loss:3.2269 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 0.5189959
	speed: 0.0396s/iter; left time: 810.8155s
	iters: 200, epoch: 23 | loss: 0.5905445
	speed: 0.0371s/iter; left time: 756.1129s
Epoch: 23 cost time: 10.027222633361816
Epoch: 23, Steps: 264 Train Loss: 0.5488 (Forecasting Loss:0.2257 + XiCon Loss:3.2309 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 0.5882193
	speed: 0.0399s/iter; left time: 806.8743s
	iters: 200, epoch: 24 | loss: 0.5216200
	speed: 0.0373s/iter; left time: 750.8697s
Epoch: 24 cost time: 10.110013246536255
Epoch: 24, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2258 + XiCon Loss:3.2295 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1108
Validation loss decreased (0.170732 --> 0.170712).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 0.5413069
	speed: 0.0394s/iter; left time: 786.9655s
	iters: 200, epoch: 25 | loss: 0.5647434
	speed: 0.0376s/iter; left time: 747.0035s
Epoch: 25 cost time: 10.11293649673462
Epoch: 25, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2257 + XiCon Loss:3.2298 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 0.5385944
	speed: 0.0395s/iter; left time: 779.0789s
	iters: 200, epoch: 26 | loss: 0.5647585
	speed: 0.0375s/iter; left time: 734.9462s
Epoch: 26 cost time: 10.162364721298218
Epoch: 26, Steps: 264 Train Loss: 0.5488 (Forecasting Loss:0.2257 + XiCon Loss:3.2310 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1108
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 0.5323239
	speed: 0.0403s/iter; left time: 783.3356s
	iters: 200, epoch: 27 | loss: 0.5194977
	speed: 0.0376s/iter; left time: 727.5160s
Epoch: 27 cost time: 10.231948375701904
Epoch: 27, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2256 + XiCon Loss:3.2290 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 0.5477472
	speed: 0.0410s/iter; left time: 785.4662s
	iters: 200, epoch: 28 | loss: 0.5407184
	speed: 0.0378s/iter; left time: 720.7388s
Epoch: 28 cost time: 10.266579151153564
Epoch: 28, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2257 + XiCon Loss:3.2291 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 0.5706036
	speed: 0.0384s/iter; left time: 726.3127s
	iters: 200, epoch: 29 | loss: 0.5521417
	speed: 0.0365s/iter; left time: 686.2034s
Epoch: 29 cost time: 9.89820384979248
Epoch: 29, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2257 + XiCon Loss:3.2288 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 0.5705314
	speed: 0.0394s/iter; left time: 735.5287s
	iters: 200, epoch: 30 | loss: 0.5497829
	speed: 0.0374s/iter; left time: 692.7292s
Epoch: 30 cost time: 10.093064785003662
Epoch: 30, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2257 + XiCon Loss:3.2288 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 0.5351011
	speed: 0.0398s/iter; left time: 730.9015s
	iters: 200, epoch: 31 | loss: 0.5597242
	speed: 0.0371s/iter; left time: 679.0752s
Epoch: 31 cost time: 10.116284608840942
Epoch: 31, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2257 + XiCon Loss:3.2303 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1108
Validation loss decreased (0.170712 --> 0.170674).  Saving model ...
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 0.5689501
	speed: 0.0389s/iter; left time: 704.3501s
	iters: 200, epoch: 32 | loss: 0.5526063
	speed: 0.0375s/iter; left time: 675.6439s
Epoch: 32 cost time: 10.06243109703064
Epoch: 32, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2258 + XiCon Loss:3.2285 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 0.5245075
	speed: 0.0398s/iter; left time: 711.2350s
	iters: 200, epoch: 33 | loss: 0.5423074
	speed: 0.0366s/iter; left time: 649.5122s
Epoch: 33 cost time: 10.074798822402954
Epoch: 33, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2256 + XiCon Loss:3.2301 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 0.5485224
	speed: 0.0398s/iter; left time: 699.3094s
	iters: 200, epoch: 34 | loss: 0.5417420
	speed: 0.0368s/iter; left time: 644.4133s
Epoch: 34 cost time: 10.033611059188843
Epoch: 34, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2257 + XiCon Loss:3.2285 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 0.5671457
	speed: 0.0393s/iter; left time: 681.5520s
	iters: 200, epoch: 35 | loss: 0.5313757
	speed: 0.0372s/iter; left time: 640.5019s
Epoch: 35 cost time: 10.037476539611816
Epoch: 35, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2257 + XiCon Loss:3.2299 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 0.5282286
	speed: 0.0385s/iter; left time: 657.6670s
	iters: 200, epoch: 36 | loss: 0.5337551
	speed: 0.0366s/iter; left time: 621.1054s
Epoch: 36 cost time: 9.954169750213623
Epoch: 36, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2257 + XiCon Loss:3.2281 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 0.5379707
	speed: 0.0390s/iter; left time: 654.6559s
	iters: 200, epoch: 37 | loss: 0.5136388
	speed: 0.0368s/iter; left time: 614.9386s
Epoch: 37 cost time: 10.007578611373901
Epoch: 37, Steps: 264 Train Loss: 0.5485 (Forecasting Loss:0.2257 + XiCon Loss:3.2280 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.1108
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 0.5314996
	speed: 0.0394s/iter; left time: 650.6452s
	iters: 200, epoch: 38 | loss: 0.5558112
	speed: 0.0374s/iter; left time: 614.9896s
Epoch: 38 cost time: 10.091396570205688
Epoch: 38, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2256 + XiCon Loss:3.2303 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 39 | loss: 0.5301445
	speed: 0.0398s/iter; left time: 646.7411s
	iters: 200, epoch: 39 | loss: 0.5377140
	speed: 0.0380s/iter; left time: 614.1173s
Epoch: 39 cost time: 10.22404670715332
Epoch: 39, Steps: 264 Train Loss: 0.5486 (Forecasting Loss:0.2257 + XiCon Loss:3.2291 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1108
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 40 | loss: 0.5678055
	speed: 0.0396s/iter; left time: 633.9039s
	iters: 200, epoch: 40 | loss: 0.5460970
	speed: 0.0368s/iter; left time: 586.0500s
Epoch: 40 cost time: 10.042484045028687
Epoch: 40, Steps: 264 Train Loss: 0.5488 (Forecasting Loss:0.2257 + XiCon Loss:3.2317 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 41 | loss: 0.5274513
	speed: 0.0399s/iter; left time: 627.7159s
	iters: 200, epoch: 41 | loss: 0.5490906
	speed: 0.0376s/iter; left time: 587.4979s
Epoch: 41 cost time: 10.186936616897583
Epoch: 41, Steps: 264 Train Loss: 0.5487 (Forecasting Loss:0.2257 + XiCon Loss:3.2295 x Lambda(0.1)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1108
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05096057057380676, mae:0.17068034410476685, mape:0.13411889970302582, mspe:0.032343871891498566 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6431
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5682926
	speed: 0.0378s/iter; left time: 994.6867s
	iters: 200, epoch: 1 | loss: 0.5598704
	speed: 0.0339s/iter; left time: 887.4428s
Epoch: 1 cost time: 9.346233606338501
Epoch: 1, Steps: 264 Train Loss: 0.5819 (Forecasting Loss:0.2361 + XiCon Loss:3.4580 x Lambda(0.1)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1143
Validation loss decreased (inf --> 0.173667).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5540704
	speed: 0.0424s/iter; left time: 1104.3581s
	iters: 200, epoch: 2 | loss: 0.5598272
	speed: 0.0378s/iter; left time: 980.5493s
Epoch: 2 cost time: 10.427535772323608
Epoch: 2, Steps: 264 Train Loss: 0.5806 (Forecasting Loss:0.2431 + XiCon Loss:3.3759 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1209
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5622427
	speed: 0.0399s/iter; left time: 1028.0025s
	iters: 200, epoch: 3 | loss: 0.5824971
	speed: 0.0383s/iter; left time: 982.1711s
Epoch: 3 cost time: 10.265737295150757
Epoch: 3, Steps: 264 Train Loss: 0.5608 (Forecasting Loss:0.2339 + XiCon Loss:3.2688 x Lambda(0.1)), Vali MSE Loss: 0.1729 Test MSE Loss: 0.1140
Validation loss decreased (0.173667 --> 0.172867).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5583441
	speed: 0.0399s/iter; left time: 1016.8193s
	iters: 200, epoch: 4 | loss: 0.5751680
	speed: 0.0376s/iter; left time: 955.7253s
Epoch: 4 cost time: 10.159172058105469
Epoch: 4, Steps: 264 Train Loss: 0.5536 (Forecasting Loss:0.2298 + XiCon Loss:3.2380 x Lambda(0.1)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5893574
	speed: 0.0400s/iter; left time: 1008.7910s
	iters: 200, epoch: 5 | loss: 0.5434031
	speed: 0.0375s/iter; left time: 942.5654s
Epoch: 5 cost time: 10.195027589797974
Epoch: 5, Steps: 264 Train Loss: 0.5507 (Forecasting Loss:0.2282 + XiCon Loss:3.2255 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1135
Validation loss decreased (0.172867 --> 0.170227).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5456464
	speed: 0.0402s/iter; left time: 1004.4662s
	iters: 200, epoch: 6 | loss: 0.5544759
	speed: 0.0372s/iter; left time: 924.8313s
Epoch: 6 cost time: 10.261356115341187
Epoch: 6, Steps: 264 Train Loss: 0.5490 (Forecasting Loss:0.2270 + XiCon Loss:3.2196 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1133
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5301378
	speed: 0.0392s/iter; left time: 969.7950s
	iters: 200, epoch: 7 | loss: 0.5567917
	speed: 0.0373s/iter; left time: 918.3267s
Epoch: 7 cost time: 10.041038274765015
Epoch: 7, Steps: 264 Train Loss: 0.5483 (Forecasting Loss:0.2265 + XiCon Loss:3.2174 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1134
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5249640
	speed: 0.0402s/iter; left time: 984.0460s
	iters: 200, epoch: 8 | loss: 0.5479017
	speed: 0.0376s/iter; left time: 914.5011s
Epoch: 8 cost time: 10.260567426681519
Epoch: 8, Steps: 264 Train Loss: 0.5478 (Forecasting Loss:0.2261 + XiCon Loss:3.2167 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1134
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5545760
	speed: 0.0401s/iter; left time: 970.5592s
	iters: 200, epoch: 9 | loss: 0.5373360
	speed: 0.0377s/iter; left time: 909.3276s
Epoch: 9 cost time: 10.206799030303955
Epoch: 9, Steps: 264 Train Loss: 0.5478 (Forecasting Loss:0.2259 + XiCon Loss:3.2190 x Lambda(0.1)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1133
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5423483
	speed: 0.0393s/iter; left time: 939.3106s
	iters: 200, epoch: 10 | loss: 0.5488766
	speed: 0.0384s/iter; left time: 915.1663s
Epoch: 10 cost time: 10.228841781616211
Epoch: 10, Steps: 264 Train Loss: 0.5475 (Forecasting Loss:0.2259 + XiCon Loss:3.2163 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5313345
	speed: 0.0396s/iter; left time: 937.0707s
	iters: 200, epoch: 11 | loss: 0.5447066
	speed: 0.0377s/iter; left time: 888.7236s
Epoch: 11 cost time: 10.157930374145508
Epoch: 11, Steps: 264 Train Loss: 0.5477 (Forecasting Loss:0.2258 + XiCon Loss:3.2188 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1133
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5217711
	speed: 0.0402s/iter; left time: 941.7054s
	iters: 200, epoch: 12 | loss: 0.5413851
	speed: 0.0377s/iter; left time: 877.9740s
Epoch: 12 cost time: 10.217108964920044
Epoch: 12, Steps: 264 Train Loss: 0.5474 (Forecasting Loss:0.2257 + XiCon Loss:3.2168 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5290928
	speed: 0.0394s/iter; left time: 911.2017s
	iters: 200, epoch: 13 | loss: 0.5371479
	speed: 0.0375s/iter; left time: 863.6349s
Epoch: 13 cost time: 10.091600894927979
Epoch: 13, Steps: 264 Train Loss: 0.5474 (Forecasting Loss:0.2256 + XiCon Loss:3.2185 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1133
Validation loss decreased (0.170227 --> 0.170219).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5544672
	speed: 0.0394s/iter; left time: 900.7505s
	iters: 200, epoch: 14 | loss: 0.5543929
	speed: 0.0380s/iter; left time: 865.7503s
Epoch: 14 cost time: 10.158416748046875
Epoch: 14, Steps: 264 Train Loss: 0.5476 (Forecasting Loss:0.2257 + XiCon Loss:3.2186 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5428290
	speed: 0.0398s/iter; left time: 898.6914s
	iters: 200, epoch: 15 | loss: 0.5223854
	speed: 0.0377s/iter; left time: 848.9194s
Epoch: 15 cost time: 10.161994218826294
Epoch: 15, Steps: 264 Train Loss: 0.5472 (Forecasting Loss:0.2256 + XiCon Loss:3.2156 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1133
Validation loss decreased (0.170219 --> 0.170183).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5504644
	speed: 0.0402s/iter; left time: 897.6091s
	iters: 200, epoch: 16 | loss: 0.5279736
	speed: 0.0380s/iter; left time: 845.4418s
Epoch: 16 cost time: 10.215880393981934
Epoch: 16, Steps: 264 Train Loss: 0.5473 (Forecasting Loss:0.2257 + XiCon Loss:3.2158 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1133
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5330150
	speed: 0.0400s/iter; left time: 883.4447s
	iters: 200, epoch: 17 | loss: 0.5599956
	speed: 0.0375s/iter; left time: 825.0741s
Epoch: 17 cost time: 10.146513223648071
Epoch: 17, Steps: 264 Train Loss: 0.5473 (Forecasting Loss:0.2257 + XiCon Loss:3.2163 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5524414
	speed: 0.0397s/iter; left time: 866.0349s
	iters: 200, epoch: 18 | loss: 0.5681986
	speed: 0.0379s/iter; left time: 823.6668s
Epoch: 18 cost time: 10.243099689483643
Epoch: 18, Steps: 264 Train Loss: 0.5473 (Forecasting Loss:0.2257 + XiCon Loss:3.2158 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1133
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5494834
	speed: 0.0392s/iter; left time: 845.1514s
	iters: 200, epoch: 19 | loss: 0.5339646
	speed: 0.0377s/iter; left time: 807.9651s
Epoch: 19 cost time: 10.13206148147583
Epoch: 19, Steps: 264 Train Loss: 0.5475 (Forecasting Loss:0.2257 + XiCon Loss:3.2182 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1133
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5668761
	speed: 0.0401s/iter; left time: 853.4013s
	iters: 200, epoch: 20 | loss: 0.5623949
	speed: 0.0379s/iter; left time: 803.6293s
Epoch: 20 cost time: 10.195939540863037
Epoch: 20, Steps: 264 Train Loss: 0.5473 (Forecasting Loss:0.2257 + XiCon Loss:3.2161 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5434730
	speed: 0.0390s/iter; left time: 820.0545s
	iters: 200, epoch: 21 | loss: 0.5497620
	speed: 0.0376s/iter; left time: 787.4889s
Epoch: 21 cost time: 10.09179973602295
Epoch: 21, Steps: 264 Train Loss: 0.5471 (Forecasting Loss:0.2256 + XiCon Loss:3.2152 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1133
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 0.5610597
	speed: 0.0398s/iter; left time: 825.5330s
	iters: 200, epoch: 22 | loss: 0.5538442
	speed: 0.0373s/iter; left time: 770.5790s
Epoch: 22 cost time: 10.208722352981567
Epoch: 22, Steps: 264 Train Loss: 0.5476 (Forecasting Loss:0.2257 + XiCon Loss:3.2184 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1133
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 0.5563717
	speed: 0.0403s/iter; left time: 826.4515s
	iters: 200, epoch: 23 | loss: 0.5882313
	speed: 0.0374s/iter; left time: 762.5692s
Epoch: 23 cost time: 10.170815229415894
Epoch: 23, Steps: 264 Train Loss: 0.5472 (Forecasting Loss:0.2257 + XiCon Loss:3.2143 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 0.5297008
	speed: 0.0398s/iter; left time: 804.7956s
	iters: 200, epoch: 24 | loss: 0.5432701
	speed: 0.0382s/iter; left time: 767.9885s
Epoch: 24 cost time: 10.129399299621582
Epoch: 24, Steps: 264 Train Loss: 0.5471 (Forecasting Loss:0.2255 + XiCon Loss:3.2165 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 0.5510064
	speed: 0.0398s/iter; left time: 795.1949s
	iters: 200, epoch: 25 | loss: 0.5619277
	speed: 0.0378s/iter; left time: 751.8726s
Epoch: 25 cost time: 10.212280511856079
Epoch: 25, Steps: 264 Train Loss: 0.5473 (Forecasting Loss:0.2256 + XiCon Loss:3.2164 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1133
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.0530228316783905, mae:0.1736115664243698, mape:0.13549570739269257, mspe:0.032528553158044815 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0528+-0.00150, MAE:0.1729+-0.00206, MAPE:0.1351+-0.00130, MSPE:0.0326+-0.00066, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.4218
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 36.0083389
	speed: 0.0409s/iter; left time: 1064.2457s
	iters: 200, epoch: 1 | loss: 35.6131401
	speed: 0.0341s/iter; left time: 883.4495s
Epoch: 1 cost time: 9.585777044296265
Epoch: 1, Steps: 261 Train Loss: 35.8184 (Forecasting Loss:0.2771 + XiCon Loss:3.5541 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
Validation loss decreased (inf --> 0.200686).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.0568581
	speed: 0.0419s/iter; left time: 1079.2333s
	iters: 200, epoch: 2 | loss: 31.4593964
	speed: 0.0398s/iter; left time: 1020.5951s
Epoch: 2 cost time: 10.677659749984741
Epoch: 2, Steps: 261 Train Loss: 32.7461 (Forecasting Loss:0.2748 + XiCon Loss:3.2471 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1404
Validation loss decreased (0.200686 --> 0.198648).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.5620060
	speed: 0.0426s/iter; left time: 1084.9912s
	iters: 200, epoch: 3 | loss: 31.0051022
	speed: 0.0403s/iter; left time: 1024.0011s
Epoch: 3 cost time: 10.731197834014893
Epoch: 3, Steps: 261 Train Loss: 31.4757 (Forecasting Loss:0.2691 + XiCon Loss:3.1207 x Lambda(10.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1408
Validation loss decreased (0.198648 --> 0.197967).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2486610
	speed: 0.0422s/iter; left time: 1063.2905s
	iters: 200, epoch: 4 | loss: 31.0492744
	speed: 0.0396s/iter; left time: 993.5072s
Epoch: 4 cost time: 10.664227485656738
Epoch: 4, Steps: 261 Train Loss: 31.2697 (Forecasting Loss:0.2671 + XiCon Loss:3.1003 x Lambda(10.0)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1409
Validation loss decreased (0.197967 --> 0.196500).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.1591606
	speed: 0.0479s/iter; left time: 1196.0886s
	iters: 200, epoch: 5 | loss: 31.0342083
	speed: 0.0405s/iter; left time: 1005.6496s
Epoch: 5 cost time: 11.416963338851929
Epoch: 5, Steps: 261 Train Loss: 31.1922 (Forecasting Loss:0.2660 + XiCon Loss:3.0926 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1398
Validation loss decreased (0.196500 --> 0.195700).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.0981274
	speed: 0.0437s/iter; left time: 1078.8463s
	iters: 200, epoch: 6 | loss: 31.1704826
	speed: 0.0410s/iter; left time: 1008.0451s
Epoch: 6 cost time: 10.993155002593994
Epoch: 6, Steps: 261 Train Loss: 31.1642 (Forecasting Loss:0.2652 + XiCon Loss:3.0899 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1393
Validation loss decreased (0.195700 --> 0.195502).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0861130
	speed: 0.0420s/iter; left time: 1025.8799s
	iters: 200, epoch: 7 | loss: 31.1607304
	speed: 0.0401s/iter; left time: 974.9843s
Epoch: 7 cost time: 10.662981510162354
Epoch: 7, Steps: 261 Train Loss: 31.1232 (Forecasting Loss:0.2650 + XiCon Loss:3.0858 x Lambda(10.0)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1393
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1207180
	speed: 0.0424s/iter; left time: 1026.0694s
	iters: 200, epoch: 8 | loss: 30.9669952
	speed: 0.0397s/iter; left time: 956.3382s
Epoch: 8 cost time: 10.723647356033325
Epoch: 8, Steps: 261 Train Loss: 31.1395 (Forecasting Loss:0.2650 + XiCon Loss:3.0875 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1393
Validation loss decreased (0.195502 --> 0.195269).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.4893227
	speed: 0.0421s/iter; left time: 1007.3626s
	iters: 200, epoch: 9 | loss: 31.2018681
	speed: 0.0402s/iter; left time: 958.3349s
Epoch: 9 cost time: 10.720280170440674
Epoch: 9, Steps: 261 Train Loss: 31.1303 (Forecasting Loss:0.2648 + XiCon Loss:3.0866 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7330151
	speed: 0.0423s/iter; left time: 999.6807s
	iters: 200, epoch: 10 | loss: 31.2193336
	speed: 0.0407s/iter; left time: 958.5896s
Epoch: 10 cost time: 10.770177602767944
Epoch: 10, Steps: 261 Train Loss: 31.1240 (Forecasting Loss:0.2647 + XiCon Loss:3.0859 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1393
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.5312214
	speed: 0.0420s/iter; left time: 981.5157s
	iters: 200, epoch: 11 | loss: 31.0555916
	speed: 0.0401s/iter; left time: 933.1134s
Epoch: 11 cost time: 10.72662615776062
Epoch: 11, Steps: 261 Train Loss: 31.1335 (Forecasting Loss:0.2647 + XiCon Loss:3.0869 x Lambda(10.0)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.1392
Validation loss decreased (0.195269 --> 0.195234).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7140503
	speed: 0.0458s/iter; left time: 1058.4979s
	iters: 200, epoch: 12 | loss: 31.4747372
	speed: 0.0402s/iter; left time: 925.4890s
Epoch: 12 cost time: 11.073219060897827
Epoch: 12, Steps: 261 Train Loss: 31.1290 (Forecasting Loss:0.2647 + XiCon Loss:3.0864 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.2079754
	speed: 0.0423s/iter; left time: 967.8138s
	iters: 200, epoch: 13 | loss: 30.8982105
	speed: 0.0408s/iter; left time: 929.3614s
Epoch: 13 cost time: 10.785942554473877
Epoch: 13, Steps: 261 Train Loss: 31.1272 (Forecasting Loss:0.2647 + XiCon Loss:3.0863 x Lambda(10.0)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.1392
Validation loss decreased (0.195234 --> 0.195162).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.0920296
	speed: 0.0419s/iter; left time: 946.3017s
	iters: 200, epoch: 14 | loss: 31.0492687
	speed: 0.0405s/iter; left time: 911.2622s
Epoch: 14 cost time: 10.80729055404663
Epoch: 14, Steps: 261 Train Loss: 31.1178 (Forecasting Loss:0.2646 + XiCon Loss:3.0853 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.8440266
	speed: 0.0437s/iter; left time: 976.0216s
	iters: 200, epoch: 15 | loss: 30.8393173
	speed: 0.0412s/iter; left time: 916.0837s
Epoch: 15 cost time: 11.05741810798645
Epoch: 15, Steps: 261 Train Loss: 31.1130 (Forecasting Loss:0.2647 + XiCon Loss:3.0848 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.2353992
	speed: 0.0430s/iter; left time: 950.2280s
	iters: 200, epoch: 16 | loss: 31.4284115
	speed: 0.0406s/iter; left time: 892.2222s
Epoch: 16 cost time: 10.807862758636475
Epoch: 16, Steps: 261 Train Loss: 31.1228 (Forecasting Loss:0.2647 + XiCon Loss:3.0858 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.1295967
	speed: 0.0428s/iter; left time: 934.1727s
	iters: 200, epoch: 17 | loss: 31.0824871
	speed: 0.0399s/iter; left time: 866.8220s
Epoch: 17 cost time: 10.742787599563599
Epoch: 17, Steps: 261 Train Loss: 31.1368 (Forecasting Loss:0.2648 + XiCon Loss:3.0872 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.4541759
	speed: 0.0420s/iter; left time: 905.3627s
	iters: 200, epoch: 18 | loss: 30.8267117
	speed: 0.0401s/iter; left time: 859.6455s
Epoch: 18 cost time: 10.650165319442749
Epoch: 18, Steps: 261 Train Loss: 31.1365 (Forecasting Loss:0.2646 + XiCon Loss:3.0872 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1392
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.0280628
	speed: 0.0424s/iter; left time: 903.3134s
	iters: 200, epoch: 19 | loss: 31.1877174
	speed: 0.0408s/iter; left time: 864.4263s
Epoch: 19 cost time: 10.739664554595947
Epoch: 19, Steps: 261 Train Loss: 31.1406 (Forecasting Loss:0.2647 + XiCon Loss:3.0876 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.9313278
	speed: 0.0427s/iter; left time: 897.7794s
	iters: 200, epoch: 20 | loss: 31.3916893
	speed: 0.0407s/iter; left time: 852.5800s
Epoch: 20 cost time: 10.887155294418335
Epoch: 20, Steps: 261 Train Loss: 31.1285 (Forecasting Loss:0.2647 + XiCon Loss:3.0864 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.0605068
	speed: 0.0421s/iter; left time: 874.0815s
	iters: 200, epoch: 21 | loss: 30.9915695
	speed: 0.0397s/iter; left time: 821.9167s
Epoch: 21 cost time: 10.657930135726929
Epoch: 21, Steps: 261 Train Loss: 31.1253 (Forecasting Loss:0.2647 + XiCon Loss:3.0861 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.1247902
	speed: 0.0423s/iter; left time: 868.1899s
	iters: 200, epoch: 22 | loss: 31.3920155
	speed: 0.0396s/iter; left time: 807.7048s
Epoch: 22 cost time: 10.627575159072876
Epoch: 22, Steps: 261 Train Loss: 31.1195 (Forecasting Loss:0.2646 + XiCon Loss:3.0855 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1392
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.7539539
	speed: 0.0425s/iter; left time: 861.0008s
	iters: 200, epoch: 23 | loss: 30.9489784
	speed: 0.0405s/iter; left time: 816.5701s
Epoch: 23 cost time: 10.780354738235474
Epoch: 23, Steps: 261 Train Loss: 31.1348 (Forecasting Loss:0.2646 + XiCon Loss:3.0870 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1392
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0733199417591095, mae:0.20514710247516632, mape:0.1539667844772339, mspe:0.03934387490153313 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4412
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 35.6369667
	speed: 0.0334s/iter; left time: 869.6736s
	iters: 200, epoch: 1 | loss: 35.5617447
	speed: 0.0302s/iter; left time: 783.0345s
Epoch: 1 cost time: 8.224246263504028
Epoch: 1, Steps: 261 Train Loss: 35.6283 (Forecasting Loss:0.2758 + XiCon Loss:3.5352 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1411
Validation loss decreased (inf --> 0.197729).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.3460236
	speed: 0.0362s/iter; left time: 932.3183s
	iters: 200, epoch: 2 | loss: 33.3367920
	speed: 0.0333s/iter; left time: 854.1767s
Epoch: 2 cost time: 9.046438932418823
Epoch: 2, Steps: 261 Train Loss: 33.4582 (Forecasting Loss:0.2746 + XiCon Loss:3.3184 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1419
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.2164154
	speed: 0.0363s/iter; left time: 924.8785s
	iters: 200, epoch: 3 | loss: 33.2302628
	speed: 0.0331s/iter; left time: 839.5412s
Epoch: 3 cost time: 9.050565481185913
Epoch: 3, Steps: 261 Train Loss: 33.1630 (Forecasting Loss:0.2695 + XiCon Loss:3.2893 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.0337524
	speed: 0.0374s/iter; left time: 944.1450s
	iters: 200, epoch: 4 | loss: 33.9625626
	speed: 0.0343s/iter; left time: 862.6494s
Epoch: 4 cost time: 9.290886402130127
Epoch: 4, Steps: 261 Train Loss: 33.4409 (Forecasting Loss:0.2673 + XiCon Loss:3.3174 x Lambda(10.0)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1399
Validation loss decreased (0.197729 --> 0.196880).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 34.4108276
	speed: 0.0362s/iter; left time: 903.4490s
	iters: 200, epoch: 5 | loss: 33.7222633
	speed: 0.0335s/iter; left time: 833.4346s
Epoch: 5 cost time: 9.004579544067383
Epoch: 5, Steps: 261 Train Loss: 33.7943 (Forecasting Loss:0.2662 + XiCon Loss:3.3528 x Lambda(10.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1403
Validation loss decreased (0.196880 --> 0.196419).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 34.3862648
	speed: 0.0358s/iter; left time: 884.5337s
	iters: 200, epoch: 6 | loss: 33.5181198
	speed: 0.0337s/iter; left time: 827.7042s
Epoch: 6 cost time: 8.98787784576416
Epoch: 6, Steps: 261 Train Loss: 33.7426 (Forecasting Loss:0.2654 + XiCon Loss:3.3477 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1398
Validation loss decreased (0.196419 --> 0.196144).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.2708626
	speed: 0.0359s/iter; left time: 878.1333s
	iters: 200, epoch: 7 | loss: 33.0014648
	speed: 0.0332s/iter; left time: 807.1540s
Epoch: 7 cost time: 8.955239057540894
Epoch: 7, Steps: 261 Train Loss: 33.6955 (Forecasting Loss:0.2650 + XiCon Loss:3.3431 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1406
Validation loss decreased (0.196144 --> 0.196074).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.8072166
	speed: 0.0357s/iter; left time: 863.6929s
	iters: 200, epoch: 8 | loss: 33.8884087
	speed: 0.0331s/iter; left time: 796.2125s
Epoch: 8 cost time: 8.981269836425781
Epoch: 8, Steps: 261 Train Loss: 33.6735 (Forecasting Loss:0.2646 + XiCon Loss:3.3409 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1401
Validation loss decreased (0.196074 --> 0.195962).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 34.4462204
	speed: 0.0361s/iter; left time: 864.1677s
	iters: 200, epoch: 9 | loss: 33.5411377
	speed: 0.0336s/iter; left time: 799.8816s
Epoch: 9 cost time: 9.1105318069458
Epoch: 9, Steps: 261 Train Loss: 33.6642 (Forecasting Loss:0.2646 + XiCon Loss:3.3400 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.3711052
	speed: 0.0360s/iter; left time: 851.7189s
	iters: 200, epoch: 10 | loss: 33.6977310
	speed: 0.0331s/iter; left time: 780.2786s
Epoch: 10 cost time: 9.007810592651367
Epoch: 10, Steps: 261 Train Loss: 33.6519 (Forecasting Loss:0.2646 + XiCon Loss:3.3387 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1402
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.0461044
	speed: 0.0358s/iter; left time: 838.5489s
	iters: 200, epoch: 11 | loss: 33.5494766
	speed: 0.0334s/iter; left time: 778.9243s
Epoch: 11 cost time: 9.010798215866089
Epoch: 11, Steps: 261 Train Loss: 33.6591 (Forecasting Loss:0.2645 + XiCon Loss:3.3395 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1403
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.1215439
	speed: 0.0357s/iter; left time: 824.9381s
	iters: 200, epoch: 12 | loss: 33.6171341
	speed: 0.0331s/iter; left time: 762.0126s
Epoch: 12 cost time: 8.892317295074463
Epoch: 12, Steps: 261 Train Loss: 33.6453 (Forecasting Loss:0.2645 + XiCon Loss:3.3381 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1403
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.5928421
	speed: 0.0356s/iter; left time: 814.9612s
	iters: 200, epoch: 13 | loss: 33.3893700
	speed: 0.0331s/iter; left time: 753.9347s
Epoch: 13 cost time: 8.934390306472778
Epoch: 13, Steps: 261 Train Loss: 33.6791 (Forecasting Loss:0.2646 + XiCon Loss:3.3415 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1403
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.3323593
	speed: 0.0368s/iter; left time: 832.1090s
	iters: 200, epoch: 14 | loss: 33.2830772
	speed: 0.0330s/iter; left time: 742.0597s
Epoch: 14 cost time: 9.009308576583862
Epoch: 14, Steps: 261 Train Loss: 33.6546 (Forecasting Loss:0.2645 + XiCon Loss:3.3390 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1403
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.6184044
	speed: 0.0355s/iter; left time: 794.2993s
	iters: 200, epoch: 15 | loss: 32.9514923
	speed: 0.0329s/iter; left time: 731.2056s
Epoch: 15 cost time: 8.887067079544067
Epoch: 15, Steps: 261 Train Loss: 33.6090 (Forecasting Loss:0.2645 + XiCon Loss:3.3345 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1403
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.1712952
	speed: 0.0362s/iter; left time: 799.7317s
	iters: 200, epoch: 16 | loss: 33.2923393
	speed: 0.0332s/iter; left time: 729.8813s
Epoch: 16 cost time: 8.995879888534546
Epoch: 16, Steps: 261 Train Loss: 33.6377 (Forecasting Loss:0.2645 + XiCon Loss:3.3373 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1403
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.9600945
	speed: 0.0356s/iter; left time: 776.9352s
	iters: 200, epoch: 17 | loss: 33.6428947
	speed: 0.0333s/iter; left time: 724.1761s
Epoch: 17 cost time: 8.94530439376831
Epoch: 17, Steps: 261 Train Loss: 33.6271 (Forecasting Loss:0.2645 + XiCon Loss:3.3363 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1403
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.9221573
	speed: 0.0359s/iter; left time: 774.1628s
	iters: 200, epoch: 18 | loss: 33.8295021
	speed: 0.0333s/iter; left time: 715.3356s
Epoch: 18 cost time: 8.971887111663818
Epoch: 18, Steps: 261 Train Loss: 33.6546 (Forecasting Loss:0.2645 + XiCon Loss:3.3390 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1403
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07380438596010208, mae:0.20636780560016632, mape:0.15500278770923615, mspe:0.03978271782398224 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6135
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 35.8474236
	speed: 0.0332s/iter; left time: 862.1808s
	iters: 200, epoch: 1 | loss: 35.4271011
	speed: 0.0298s/iter; left time: 772.8834s
Epoch: 1 cost time: 8.119412899017334
Epoch: 1, Steps: 261 Train Loss: 35.6962 (Forecasting Loss:0.2767 + XiCon Loss:3.5420 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1414
Validation loss decreased (inf --> 0.199854).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.2259216
	speed: 0.0361s/iter; left time: 929.1077s
	iters: 200, epoch: 2 | loss: 32.0432281
	speed: 0.0337s/iter; left time: 864.1882s
Epoch: 2 cost time: 9.070341110229492
Epoch: 2, Steps: 261 Train Loss: 32.9155 (Forecasting Loss:0.2741 + XiCon Loss:3.2641 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1409
Validation loss decreased (0.199854 --> 0.199178).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.3193684
	speed: 0.0362s/iter; left time: 921.9189s
	iters: 200, epoch: 3 | loss: 31.7673073
	speed: 0.0337s/iter; left time: 855.8823s
Epoch: 3 cost time: 9.070785522460938
Epoch: 3, Steps: 261 Train Loss: 31.3148 (Forecasting Loss:0.2697 + XiCon Loss:3.1045 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1414
Validation loss decreased (0.199178 --> 0.198437).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.0935555
	speed: 0.0359s/iter; left time: 904.5575s
	iters: 200, epoch: 4 | loss: 31.8604393
	speed: 0.0330s/iter; left time: 827.7784s
Epoch: 4 cost time: 8.961292028427124
Epoch: 4, Steps: 261 Train Loss: 31.7474 (Forecasting Loss:0.2666 + XiCon Loss:3.1481 x Lambda(10.0)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1398
Validation loss decreased (0.198437 --> 0.196851).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.2794933
	speed: 0.0354s/iter; left time: 884.2446s
	iters: 200, epoch: 5 | loss: 31.6925049
	speed: 0.0332s/iter; left time: 824.9593s
Epoch: 5 cost time: 8.920413255691528
Epoch: 5, Steps: 261 Train Loss: 31.4221 (Forecasting Loss:0.2655 + XiCon Loss:3.1157 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1400
Validation loss decreased (0.196851 --> 0.195424).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.1670647
	speed: 0.0361s/iter; left time: 892.6413s
	iters: 200, epoch: 6 | loss: 31.3996677
	speed: 0.0328s/iter; left time: 805.9210s
Epoch: 6 cost time: 8.930601596832275
Epoch: 6, Steps: 261 Train Loss: 31.3640 (Forecasting Loss:0.2646 + XiCon Loss:3.1099 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1405
Validation loss decreased (0.195424 --> 0.195383).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2547321
	speed: 0.0358s/iter; left time: 874.3487s
	iters: 200, epoch: 7 | loss: 31.5323391
	speed: 0.0332s/iter; left time: 808.8332s
Epoch: 7 cost time: 8.954952001571655
Epoch: 7, Steps: 261 Train Loss: 31.3026 (Forecasting Loss:0.2642 + XiCon Loss:3.1038 x Lambda(10.0)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.3213043
	speed: 0.0357s/iter; left time: 862.7723s
	iters: 200, epoch: 8 | loss: 31.2827873
	speed: 0.0332s/iter; left time: 800.2418s
Epoch: 8 cost time: 8.965094327926636
Epoch: 8, Steps: 261 Train Loss: 31.2899 (Forecasting Loss:0.2641 + XiCon Loss:3.1026 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1400
Validation loss decreased (0.195383 --> 0.195123).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.3799286
	speed: 0.0358s/iter; left time: 857.0799s
	iters: 200, epoch: 9 | loss: 31.4878883
	speed: 0.0332s/iter; left time: 790.8222s
Epoch: 9 cost time: 8.953466653823853
Epoch: 9, Steps: 261 Train Loss: 31.2706 (Forecasting Loss:0.2639 + XiCon Loss:3.1007 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1397
Validation loss decreased (0.195123 --> 0.195029).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3053722
	speed: 0.0362s/iter; left time: 856.6011s
	iters: 200, epoch: 10 | loss: 31.2155075
	speed: 0.0331s/iter; left time: 778.4188s
Epoch: 10 cost time: 8.96485161781311
Epoch: 10, Steps: 261 Train Loss: 31.2781 (Forecasting Loss:0.2638 + XiCon Loss:3.1014 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1399
Validation loss decreased (0.195029 --> 0.194991).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.3542156
	speed: 0.0362s/iter; left time: 845.7195s
	iters: 200, epoch: 11 | loss: 31.6036224
	speed: 0.0335s/iter; left time: 781.0574s
Epoch: 11 cost time: 9.043965339660645
Epoch: 11, Steps: 261 Train Loss: 31.2920 (Forecasting Loss:0.2638 + XiCon Loss:3.1028 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1398
Validation loss decreased (0.194991 --> 0.194975).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.3930435
	speed: 0.0362s/iter; left time: 836.5600s
	iters: 200, epoch: 12 | loss: 31.6642361
	speed: 0.0328s/iter; left time: 754.5934s
Epoch: 12 cost time: 8.969330072402954
Epoch: 12, Steps: 261 Train Loss: 31.2625 (Forecasting Loss:0.2638 + XiCon Loss:3.0999 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1398
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.9798222
	speed: 0.0360s/iter; left time: 823.7682s
	iters: 200, epoch: 13 | loss: 31.0537186
	speed: 0.0331s/iter; left time: 754.1751s
Epoch: 13 cost time: 8.970419645309448
Epoch: 13, Steps: 261 Train Loss: 31.2789 (Forecasting Loss:0.2638 + XiCon Loss:3.1015 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1398
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.3979263
	speed: 0.0360s/iter; left time: 814.2465s
	iters: 200, epoch: 14 | loss: 31.4220200
	speed: 0.0335s/iter; left time: 754.9150s
Epoch: 14 cost time: 9.061291933059692
Epoch: 14, Steps: 261 Train Loss: 31.2614 (Forecasting Loss:0.2638 + XiCon Loss:3.0998 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1398
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.4423275
	speed: 0.0368s/iter; left time: 821.6732s
	iters: 200, epoch: 15 | loss: 31.4842720
	speed: 0.0336s/iter; left time: 746.9332s
Epoch: 15 cost time: 9.061622619628906
Epoch: 15, Steps: 261 Train Loss: 31.2810 (Forecasting Loss:0.2639 + XiCon Loss:3.1017 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1398
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.4190388
	speed: 0.0359s/iter; left time: 793.2943s
	iters: 200, epoch: 16 | loss: 30.8073559
	speed: 0.0336s/iter; left time: 738.8469s
Epoch: 16 cost time: 8.993962526321411
Epoch: 16, Steps: 261 Train Loss: 31.2751 (Forecasting Loss:0.2638 + XiCon Loss:3.1011 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1398
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.2383194
	speed: 0.0357s/iter; left time: 778.8137s
	iters: 200, epoch: 17 | loss: 31.4023972
	speed: 0.0331s/iter; left time: 719.8196s
Epoch: 17 cost time: 8.93315315246582
Epoch: 17, Steps: 261 Train Loss: 31.2758 (Forecasting Loss:0.2637 + XiCon Loss:3.1012 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1398
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.5695534
	speed: 0.0358s/iter; left time: 772.8879s
	iters: 200, epoch: 18 | loss: 31.2864914
	speed: 0.0335s/iter; left time: 719.7751s
Epoch: 18 cost time: 9.031828880310059
Epoch: 18, Steps: 261 Train Loss: 31.2891 (Forecasting Loss:0.2637 + XiCon Loss:3.1025 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1398
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.5168629
	speed: 0.0356s/iter; left time: 757.9026s
	iters: 200, epoch: 19 | loss: 31.5140076
	speed: 0.0332s/iter; left time: 703.5083s
Epoch: 19 cost time: 8.9193696975708
Epoch: 19, Steps: 261 Train Loss: 31.2676 (Forecasting Loss:0.2638 + XiCon Loss:3.1004 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1398
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.1357784
	speed: 0.0356s/iter; left time: 748.2965s
	iters: 200, epoch: 20 | loss: 31.4163513
	speed: 0.0339s/iter; left time: 710.9164s
Epoch: 20 cost time: 9.021275520324707
Epoch: 20, Steps: 261 Train Loss: 31.2808 (Forecasting Loss:0.2637 + XiCon Loss:3.1017 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.1398
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.3974323
	speed: 0.0357s/iter; left time: 742.1368s
	iters: 200, epoch: 21 | loss: 31.3052559
	speed: 0.0335s/iter; left time: 692.7285s
Epoch: 21 cost time: 8.98028302192688
Epoch: 21, Steps: 261 Train Loss: 31.2781 (Forecasting Loss:0.2638 + XiCon Loss:3.1014 x Lambda(10.0)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1398
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07347112894058228, mae:0.2061092108488083, mape:0.15493646264076233, mspe:0.039728499948978424 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4252
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 35.8925285
	speed: 0.0390s/iter; left time: 1013.6471s
	iters: 200, epoch: 1 | loss: 35.6778908
	speed: 0.0349s/iter; left time: 904.2321s
Epoch: 1 cost time: 9.539267539978027
Epoch: 1, Steps: 261 Train Loss: 35.8339 (Forecasting Loss:0.2782 + XiCon Loss:3.5556 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1423
Validation loss decreased (inf --> 0.199019).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.5581017
	speed: 0.0413s/iter; left time: 1063.4897s
	iters: 200, epoch: 2 | loss: 33.3194962
	speed: 0.0395s/iter; left time: 1013.9892s
Epoch: 2 cost time: 10.551878929138184
Epoch: 2, Steps: 261 Train Loss: 33.5968 (Forecasting Loss:0.2746 + XiCon Loss:3.3322 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1423
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.1121483
	speed: 0.0426s/iter; left time: 1084.8079s
	iters: 200, epoch: 3 | loss: 34.0617447
	speed: 0.0421s/iter; left time: 1069.6577s
Epoch: 3 cost time: 11.007487773895264
Epoch: 3, Steps: 261 Train Loss: 33.5946 (Forecasting Loss:0.2691 + XiCon Loss:3.3326 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1444
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.6945190
	speed: 0.0441s/iter; left time: 1112.5854s
	iters: 200, epoch: 4 | loss: 32.6949158
	speed: 0.0411s/iter; left time: 1032.0353s
Epoch: 4 cost time: 11.092887163162231
Epoch: 4, Steps: 261 Train Loss: 33.2287 (Forecasting Loss:0.2667 + XiCon Loss:3.2962 x Lambda(10.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1399
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.0768700
	speed: 0.0440s/iter; left time: 1097.4723s
	iters: 200, epoch: 5 | loss: 32.6259804
	speed: 0.0412s/iter; left time: 1022.9603s
Epoch: 5 cost time: 11.051197290420532
Epoch: 5, Steps: 261 Train Loss: 33.1050 (Forecasting Loss:0.2639 + XiCon Loss:3.2841 x Lambda(10.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1400
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.7279472
	speed: 0.0445s/iter; left time: 1099.1011s
	iters: 200, epoch: 6 | loss: 32.9232140
	speed: 0.0413s/iter; left time: 1015.5552s
Epoch: 6 cost time: 11.130205631256104
Epoch: 6, Steps: 261 Train Loss: 33.0643 (Forecasting Loss:0.2629 + XiCon Loss:3.2801 x Lambda(10.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1399
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.3355026
	speed: 0.0429s/iter; left time: 1049.2063s
	iters: 200, epoch: 7 | loss: 33.1528244
	speed: 0.0413s/iter; left time: 1004.3785s
Epoch: 7 cost time: 10.997612953186035
Epoch: 7, Steps: 261 Train Loss: 33.0285 (Forecasting Loss:0.2623 + XiCon Loss:3.2766 x Lambda(10.0)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.1403
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.5907593
	speed: 0.0433s/iter; left time: 1047.1247s
	iters: 200, epoch: 8 | loss: 32.7287064
	speed: 0.0410s/iter; left time: 986.0744s
Epoch: 8 cost time: 10.980841875076294
Epoch: 8, Steps: 261 Train Loss: 33.0495 (Forecasting Loss:0.2621 + XiCon Loss:3.2787 x Lambda(10.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1399
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.9199791
	speed: 0.0432s/iter; left time: 1033.4552s
	iters: 200, epoch: 9 | loss: 32.7289925
	speed: 0.0407s/iter; left time: 968.3687s
Epoch: 9 cost time: 10.94674038887024
Epoch: 9, Steps: 261 Train Loss: 33.0419 (Forecasting Loss:0.2619 + XiCon Loss:3.2780 x Lambda(10.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1399
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.9544525
	speed: 0.0434s/iter; left time: 1025.9510s
	iters: 200, epoch: 10 | loss: 33.2378311
	speed: 0.0455s/iter; left time: 1071.0412s
Epoch: 10 cost time: 11.452463150024414
Epoch: 10, Steps: 261 Train Loss: 33.0578 (Forecasting Loss:0.2618 + XiCon Loss:3.2796 x Lambda(10.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1399
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.8108368
	speed: 0.0440s/iter; left time: 1029.1496s
	iters: 200, epoch: 11 | loss: 32.7049446
	speed: 0.0408s/iter; left time: 949.6590s
Epoch: 11 cost time: 11.018102407455444
Epoch: 11, Steps: 261 Train Loss: 33.0027 (Forecasting Loss:0.2617 + XiCon Loss:3.2741 x Lambda(10.0)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1399
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07531820982694626, mae:0.20929467678070068, mape:0.1571100950241089, mspe:0.040674276649951935 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6346
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 36.0041466
	speed: 0.0383s/iter; left time: 996.1631s
	iters: 200, epoch: 1 | loss: 35.4329910
	speed: 0.0338s/iter; left time: 875.6817s
Epoch: 1 cost time: 9.29913330078125
Epoch: 1, Steps: 261 Train Loss: 35.7404 (Forecasting Loss:0.2784 + XiCon Loss:3.5462 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1418
Validation loss decreased (inf --> 0.197638).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.3340492
	speed: 0.0409s/iter; left time: 1052.8455s
	iters: 200, epoch: 2 | loss: 33.2604599
	speed: 0.0387s/iter; left time: 991.5562s
Epoch: 2 cost time: 10.395725965499878
Epoch: 2, Steps: 261 Train Loss: 33.3852 (Forecasting Loss:0.2742 + XiCon Loss:3.3111 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1435
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.1660881
	speed: 0.0410s/iter; left time: 1044.0649s
	iters: 200, epoch: 3 | loss: 33.3389397
	speed: 0.0392s/iter; left time: 994.3125s
Epoch: 3 cost time: 10.463613033294678
Epoch: 3, Steps: 261 Train Loss: 33.1995 (Forecasting Loss:0.2696 + XiCon Loss:3.2930 x Lambda(10.0)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1417
Validation loss decreased (0.197638 --> 0.197494).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.1357307
	speed: 0.0417s/iter; left time: 1051.4118s
	iters: 200, epoch: 4 | loss: 33.1462936
	speed: 0.0392s/iter; left time: 983.4914s
Epoch: 4 cost time: 10.480843544006348
Epoch: 4, Steps: 261 Train Loss: 33.1927 (Forecasting Loss:0.2671 + XiCon Loss:3.2926 x Lambda(10.0)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1408
Validation loss decreased (0.197494 --> 0.196801).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.1468925
	speed: 0.0413s/iter; left time: 1031.2583s
	iters: 200, epoch: 5 | loss: 33.1714668
	speed: 0.0388s/iter; left time: 963.3759s
Epoch: 5 cost time: 10.451878547668457
Epoch: 5, Steps: 261 Train Loss: 33.1883 (Forecasting Loss:0.2659 + XiCon Loss:3.2922 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1405
Validation loss decreased (0.196801 --> 0.196149).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.1792450
	speed: 0.0416s/iter; left time: 1028.5878s
	iters: 200, epoch: 6 | loss: 33.1410599
	speed: 0.0399s/iter; left time: 981.7945s
Epoch: 6 cost time: 10.670433759689331
Epoch: 6, Steps: 261 Train Loss: 33.1813 (Forecasting Loss:0.2655 + XiCon Loss:3.2916 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1405
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.1821365
	speed: 0.0429s/iter; left time: 1049.3913s
	iters: 200, epoch: 7 | loss: 33.1530685
	speed: 0.0394s/iter; left time: 958.1135s
Epoch: 7 cost time: 10.630934953689575
Epoch: 7, Steps: 261 Train Loss: 33.1811 (Forecasting Loss:0.2651 + XiCon Loss:3.2916 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1400
Validation loss decreased (0.196149 --> 0.195993).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.1763153
	speed: 0.0413s/iter; left time: 998.2786s
	iters: 200, epoch: 8 | loss: 33.2327995
	speed: 0.0395s/iter; left time: 952.0179s
Epoch: 8 cost time: 10.517653942108154
Epoch: 8, Steps: 261 Train Loss: 33.1803 (Forecasting Loss:0.2649 + XiCon Loss:3.2915 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
Validation loss decreased (0.195993 --> 0.195875).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.1775589
	speed: 0.0422s/iter; left time: 1008.9494s
	iters: 200, epoch: 9 | loss: 33.2398033
	speed: 0.0399s/iter; left time: 949.1181s
Epoch: 9 cost time: 10.670627355575562
Epoch: 9, Steps: 261 Train Loss: 33.1733 (Forecasting Loss:0.2649 + XiCon Loss:3.2908 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1403
Validation loss decreased (0.195875 --> 0.195734).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.2485275
	speed: 0.0412s/iter; left time: 973.9687s
	iters: 200, epoch: 10 | loss: 33.1225128
	speed: 0.0396s/iter; left time: 933.2139s
Epoch: 10 cost time: 10.52239179611206
Epoch: 10, Steps: 261 Train Loss: 33.1731 (Forecasting Loss:0.2648 + XiCon Loss:3.2908 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.2173080
	speed: 0.0410s/iter; left time: 959.8402s
	iters: 200, epoch: 11 | loss: 33.1540451
	speed: 0.0388s/iter; left time: 904.2214s
Epoch: 11 cost time: 10.457766056060791
Epoch: 11, Steps: 261 Train Loss: 33.1781 (Forecasting Loss:0.2649 + XiCon Loss:3.2913 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.0609589
	speed: 0.0421s/iter; left time: 973.4854s
	iters: 200, epoch: 12 | loss: 33.3205070
	speed: 0.0400s/iter; left time: 921.9341s
Epoch: 12 cost time: 10.61549162864685
Epoch: 12, Steps: 261 Train Loss: 33.1791 (Forecasting Loss:0.2648 + XiCon Loss:3.2914 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.0342941
	speed: 0.0430s/iter; left time: 982.8642s
	iters: 200, epoch: 13 | loss: 33.1479301
	speed: 0.0393s/iter; left time: 895.2439s
Epoch: 13 cost time: 10.656525611877441
Epoch: 13, Steps: 261 Train Loss: 33.1785 (Forecasting Loss:0.2647 + XiCon Loss:3.2914 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195734 --> 0.195683).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.0965347
	speed: 0.0419s/iter; left time: 948.4042s
	iters: 200, epoch: 14 | loss: 33.0476990
	speed: 0.0393s/iter; left time: 884.9200s
Epoch: 14 cost time: 10.59213376045227
Epoch: 14, Steps: 261 Train Loss: 33.1796 (Forecasting Loss:0.2648 + XiCon Loss:3.2915 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.1537743
	speed: 0.0415s/iter; left time: 926.7582s
	iters: 200, epoch: 15 | loss: 33.2176628
	speed: 0.0389s/iter; left time: 865.2504s
Epoch: 15 cost time: 10.482721090316772
Epoch: 15, Steps: 261 Train Loss: 33.1795 (Forecasting Loss:0.2647 + XiCon Loss:3.2915 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.1436844
	speed: 0.0416s/iter; left time: 919.0139s
	iters: 200, epoch: 16 | loss: 33.0632324
	speed: 0.0397s/iter; left time: 872.0036s
Epoch: 16 cost time: 10.520207643508911
Epoch: 16, Steps: 261 Train Loss: 33.1780 (Forecasting Loss:0.2648 + XiCon Loss:3.2913 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.1740494
	speed: 0.0418s/iter; left time: 911.5172s
	iters: 200, epoch: 17 | loss: 33.1769638
	speed: 0.0396s/iter; left time: 859.9614s
Epoch: 17 cost time: 10.546777963638306
Epoch: 17, Steps: 261 Train Loss: 33.1825 (Forecasting Loss:0.2648 + XiCon Loss:3.2918 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 33.1523666
	speed: 0.0416s/iter; left time: 897.8093s
	iters: 200, epoch: 18 | loss: 33.1216393
	speed: 0.0402s/iter; left time: 862.3523s
Epoch: 18 cost time: 10.587747812271118
Epoch: 18, Steps: 261 Train Loss: 33.1795 (Forecasting Loss:0.2647 + XiCon Loss:3.2915 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.1077843
	speed: 0.0415s/iter; left time: 883.5581s
	iters: 200, epoch: 19 | loss: 33.1896057
	speed: 0.0392s/iter; left time: 832.1881s
Epoch: 19 cost time: 10.51963496208191
Epoch: 19, Steps: 261 Train Loss: 33.1786 (Forecasting Loss:0.2648 + XiCon Loss:3.2914 x Lambda(10.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1401
Validation loss decreased (0.195683 --> 0.195640).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.2352219
	speed: 0.0418s/iter; left time: 879.8133s
	iters: 200, epoch: 20 | loss: 33.0546417
	speed: 0.0396s/iter; left time: 830.1773s
Epoch: 20 cost time: 10.53300404548645
Epoch: 20, Steps: 261 Train Loss: 33.1767 (Forecasting Loss:0.2648 + XiCon Loss:3.2912 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 33.1660919
	speed: 0.0418s/iter; left time: 869.6157s
	iters: 200, epoch: 21 | loss: 33.2098846
	speed: 0.0391s/iter; left time: 808.6909s
Epoch: 21 cost time: 10.484740257263184
Epoch: 21, Steps: 261 Train Loss: 33.1786 (Forecasting Loss:0.2649 + XiCon Loss:3.2914 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.2126541
	speed: 0.0414s/iter; left time: 850.2210s
	iters: 200, epoch: 22 | loss: 33.1275787
	speed: 0.0393s/iter; left time: 802.9869s
Epoch: 22 cost time: 10.510190486907959
Epoch: 22, Steps: 261 Train Loss: 33.1755 (Forecasting Loss:0.2648 + XiCon Loss:3.2911 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 33.1463242
	speed: 0.0427s/iter; left time: 864.1247s
	iters: 200, epoch: 23 | loss: 33.1488037
	speed: 0.0389s/iter; left time: 784.5841s
Epoch: 23 cost time: 10.592045068740845
Epoch: 23, Steps: 261 Train Loss: 33.1788 (Forecasting Loss:0.2648 + XiCon Loss:3.2914 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 33.1853371
	speed: 0.0414s/iter; left time: 827.2540s
	iters: 200, epoch: 24 | loss: 33.1582222
	speed: 0.0387s/iter; left time: 770.7067s
Epoch: 24 cost time: 10.373552799224854
Epoch: 24, Steps: 261 Train Loss: 33.1754 (Forecasting Loss:0.2646 + XiCon Loss:3.2911 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 33.1423531
	speed: 0.0414s/iter; left time: 817.0367s
	iters: 200, epoch: 25 | loss: 33.0982895
	speed: 0.0388s/iter; left time: 761.9791s
Epoch: 25 cost time: 10.426828145980835
Epoch: 25, Steps: 261 Train Loss: 33.1819 (Forecasting Loss:0.2648 + XiCon Loss:3.2917 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 33.3005981
	speed: 0.0420s/iter; left time: 817.3702s
	iters: 200, epoch: 26 | loss: 33.1430511
	speed: 0.0391s/iter; left time: 757.2434s
Epoch: 26 cost time: 10.56915831565857
Epoch: 26, Steps: 261 Train Loss: 33.1759 (Forecasting Loss:0.2647 + XiCon Loss:3.2911 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 33.1706238
	speed: 0.0418s/iter; left time: 803.0750s
	iters: 200, epoch: 27 | loss: 33.2759094
	speed: 0.0400s/iter; left time: 764.7019s
Epoch: 27 cost time: 10.627177715301514
Epoch: 27, Steps: 261 Train Loss: 33.1798 (Forecasting Loss:0.2648 + XiCon Loss:3.2915 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 33.1463623
	speed: 0.0413s/iter; left time: 783.5240s
	iters: 200, epoch: 28 | loss: 33.1277390
	speed: 0.0397s/iter; left time: 748.0436s
Epoch: 28 cost time: 10.52371597290039
Epoch: 28, Steps: 261 Train Loss: 33.1756 (Forecasting Loss:0.2647 + XiCon Loss:3.2911 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 33.1630287
	speed: 0.0416s/iter; left time: 776.8367s
	iters: 200, epoch: 29 | loss: 33.2317848
	speed: 0.0386s/iter; left time: 717.6667s
Epoch: 29 cost time: 10.379835367202759
Epoch: 29, Steps: 261 Train Loss: 33.1791 (Forecasting Loss:0.2648 + XiCon Loss:3.2914 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07386244833469391, mae:0.20637111365795135, mape:0.15485259890556335, mspe:0.03965781629085541 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0740+-0.00099, MAE:0.2067+-0.00193, MAPE:0.1552+-0.00144, MSPE:0.0398+-0.00062, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9360
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 34.7093468
	speed: 0.0356s/iter; left time: 943.0083s
	iters: 200, epoch: 1 | loss: 33.8936043
	speed: 0.0299s/iter; left time: 788.7898s
Epoch: 1 cost time: 8.640480041503906
Epoch: 1, Steps: 266 Train Loss: 34.4433 (Forecasting Loss:0.1871 + XiCon Loss:3.4256 x Lambda(10.0)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1380
Validation loss decreased (inf --> 0.158634).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.8804016
	speed: 0.0320s/iter; left time: 838.5748s
	iters: 200, epoch: 2 | loss: 32.7365532
	speed: 0.0284s/iter; left time: 741.6987s
Epoch: 2 cost time: 7.876773834228516
Epoch: 2, Steps: 266 Train Loss: 33.0702 (Forecasting Loss:0.1588 + XiCon Loss:3.2911 x Lambda(10.0)), Vali MSE Loss: 0.1570 Test MSE Loss: 0.1328
Validation loss decreased (0.158634 --> 0.156967).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7809181
	speed: 0.0303s/iter; left time: 788.1213s
	iters: 200, epoch: 3 | loss: 31.8288250
	speed: 0.0281s/iter; left time: 727.1540s
Epoch: 3 cost time: 7.752084016799927
Epoch: 3, Steps: 266 Train Loss: 32.1435 (Forecasting Loss:0.1522 + XiCon Loss:3.1991 x Lambda(10.0)), Vali MSE Loss: 0.1484 Test MSE Loss: 0.1295
Validation loss decreased (0.156967 --> 0.148441).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7392864
	speed: 0.0300s/iter; left time: 770.2104s
	iters: 200, epoch: 4 | loss: 31.7543774
	speed: 0.0282s/iter; left time: 720.7868s
Epoch: 4 cost time: 7.676984786987305
Epoch: 4, Steps: 266 Train Loss: 32.0294 (Forecasting Loss:0.1497 + XiCon Loss:3.1880 x Lambda(10.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.1277
Validation loss decreased (0.148441 --> 0.145977).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.1917915
	speed: 0.0301s/iter; left time: 765.0080s
	iters: 200, epoch: 5 | loss: 32.1950188
	speed: 0.0286s/iter; left time: 725.2996s
Epoch: 5 cost time: 7.756375789642334
Epoch: 5, Steps: 266 Train Loss: 31.9740 (Forecasting Loss:0.1481 + XiCon Loss:3.1826 x Lambda(10.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.1259
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.0131111
	speed: 0.0305s/iter; left time: 766.5924s
	iters: 200, epoch: 6 | loss: 31.8595257
	speed: 0.0284s/iter; left time: 711.4422s
Epoch: 6 cost time: 7.7770373821258545
Epoch: 6, Steps: 266 Train Loss: 31.9783 (Forecasting Loss:0.1475 + XiCon Loss:3.1831 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1246
Validation loss decreased (0.145977 --> 0.144566).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.8800163
	speed: 0.0314s/iter; left time: 782.5172s
	iters: 200, epoch: 7 | loss: 31.6470032
	speed: 0.0285s/iter; left time: 707.4058s
Epoch: 7 cost time: 7.932880640029907
Epoch: 7, Steps: 266 Train Loss: 31.9615 (Forecasting Loss:0.1472 + XiCon Loss:3.1814 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144566 --> 0.144405).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.7632084
	speed: 0.0305s/iter; left time: 752.0833s
	iters: 200, epoch: 8 | loss: 31.8456020
	speed: 0.0281s/iter; left time: 690.7319s
Epoch: 8 cost time: 7.713873863220215
Epoch: 8, Steps: 266 Train Loss: 31.9392 (Forecasting Loss:0.1470 + XiCon Loss:3.1792 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1247
Validation loss decreased (0.144405 --> 0.144172).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0615349
	speed: 0.0309s/iter; left time: 753.4248s
	iters: 200, epoch: 9 | loss: 32.1443558
	speed: 0.0282s/iter; left time: 684.2062s
Epoch: 9 cost time: 7.750280857086182
Epoch: 9, Steps: 266 Train Loss: 31.9708 (Forecasting Loss:0.1470 + XiCon Loss:3.1824 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.8063812
	speed: 0.0314s/iter; left time: 755.7586s
	iters: 200, epoch: 10 | loss: 32.2798958
	speed: 0.0294s/iter; left time: 705.6715s
Epoch: 10 cost time: 8.01360034942627
Epoch: 10, Steps: 266 Train Loss: 31.9683 (Forecasting Loss:0.1469 + XiCon Loss:3.1821 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.8393459
	speed: 0.0314s/iter; left time: 748.7695s
	iters: 200, epoch: 11 | loss: 31.8204784
	speed: 0.0273s/iter; left time: 649.2163s
Epoch: 11 cost time: 7.716004133224487
Epoch: 11, Steps: 266 Train Loss: 31.9602 (Forecasting Loss:0.1469 + XiCon Loss:3.1813 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.4114494
	speed: 0.0304s/iter; left time: 716.5400s
	iters: 200, epoch: 12 | loss: 31.8502655
	speed: 0.0276s/iter; left time: 647.9172s
Epoch: 12 cost time: 7.697490215301514
Epoch: 12, Steps: 266 Train Loss: 31.9488 (Forecasting Loss:0.1469 + XiCon Loss:3.1802 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.5827904
	speed: 0.0303s/iter; left time: 707.3106s
	iters: 200, epoch: 13 | loss: 32.5332375
	speed: 0.0283s/iter; left time: 656.5813s
Epoch: 13 cost time: 7.740702867507935
Epoch: 13, Steps: 266 Train Loss: 31.9233 (Forecasting Loss:0.1468 + XiCon Loss:3.1776 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
Validation loss decreased (0.144172 --> 0.144005).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.1335182
	speed: 0.0314s/iter; left time: 723.1963s
	iters: 200, epoch: 14 | loss: 31.6982193
	speed: 0.0278s/iter; left time: 637.5554s
Epoch: 14 cost time: 7.753458499908447
Epoch: 14, Steps: 266 Train Loss: 31.9730 (Forecasting Loss:0.1468 + XiCon Loss:3.1826 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.4759407
	speed: 0.0307s/iter; left time: 699.8533s
	iters: 200, epoch: 15 | loss: 31.5855923
	speed: 0.0278s/iter; left time: 631.2875s
Epoch: 15 cost time: 7.7214391231536865
Epoch: 15, Steps: 266 Train Loss: 31.9491 (Forecasting Loss:0.1468 + XiCon Loss:3.1802 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.0564537
	speed: 0.0303s/iter; left time: 682.1930s
	iters: 200, epoch: 16 | loss: 31.5828209
	speed: 0.0279s/iter; left time: 625.7669s
Epoch: 16 cost time: 7.664676666259766
Epoch: 16, Steps: 266 Train Loss: 31.9515 (Forecasting Loss:0.1468 + XiCon Loss:3.1805 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.1740646
	speed: 0.0310s/iter; left time: 688.8453s
	iters: 200, epoch: 17 | loss: 31.8219090
	speed: 0.0275s/iter; left time: 609.2355s
Epoch: 17 cost time: 7.721200227737427
Epoch: 17, Steps: 266 Train Loss: 31.9586 (Forecasting Loss:0.1468 + XiCon Loss:3.1812 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.1352844
	speed: 0.0304s/iter; left time: 669.2383s
	iters: 200, epoch: 18 | loss: 31.6098576
	speed: 0.0290s/iter; left time: 634.3510s
Epoch: 18 cost time: 7.816407680511475
Epoch: 18, Steps: 266 Train Loss: 31.9342 (Forecasting Loss:0.1468 + XiCon Loss:3.1787 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.7618980
	speed: 0.0302s/iter; left time: 655.8881s
	iters: 200, epoch: 19 | loss: 31.6406918
	speed: 0.0278s/iter; left time: 600.4809s
Epoch: 19 cost time: 7.71666955947876
Epoch: 19, Steps: 266 Train Loss: 31.9594 (Forecasting Loss:0.1469 + XiCon Loss:3.1813 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.0370979
	speed: 0.0308s/iter; left time: 661.5477s
	iters: 200, epoch: 20 | loss: 31.8032799
	speed: 0.0274s/iter; left time: 585.2004s
Epoch: 20 cost time: 7.676516771316528
Epoch: 20, Steps: 266 Train Loss: 31.9605 (Forecasting Loss:0.1468 + XiCon Loss:3.1814 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.2749634
	speed: 0.0298s/iter; left time: 631.6529s
	iters: 200, epoch: 21 | loss: 31.7073650
	speed: 0.0294s/iter; left time: 620.7601s
Epoch: 21 cost time: 7.7845752239227295
Epoch: 21, Steps: 266 Train Loss: 31.9460 (Forecasting Loss:0.1468 + XiCon Loss:3.1799 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.6812000
	speed: 0.0315s/iter; left time: 659.5353s
	iters: 200, epoch: 22 | loss: 32.2739410
	speed: 0.0286s/iter; left time: 595.9178s
Epoch: 22 cost time: 7.889551162719727
Epoch: 22, Steps: 266 Train Loss: 31.9493 (Forecasting Loss:0.1469 + XiCon Loss:3.1802 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.6953011
	speed: 0.0304s/iter; left time: 626.9315s
	iters: 200, epoch: 23 | loss: 32.0516357
	speed: 0.0280s/iter; left time: 574.8548s
Epoch: 23 cost time: 7.689290761947632
Epoch: 23, Steps: 266 Train Loss: 31.9677 (Forecasting Loss:0.1468 + XiCon Loss:3.1821 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06465640664100647, mae:0.18431386351585388, mape:0.4484842121601105, mspe:8.125188827514648 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5987
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 34.7517128
	speed: 0.0332s/iter; left time: 881.0070s
	iters: 200, epoch: 1 | loss: 33.9304962
	speed: 0.0306s/iter; left time: 807.0373s
Epoch: 1 cost time: 8.403785228729248
Epoch: 1, Steps: 266 Train Loss: 34.5353 (Forecasting Loss:0.1857 + XiCon Loss:3.4350 x Lambda(10.0)), Vali MSE Loss: 0.1585 Test MSE Loss: 0.1358
Validation loss decreased (inf --> 0.158471).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.7529106
	speed: 0.0306s/iter; left time: 801.5770s
	iters: 200, epoch: 2 | loss: 32.7700958
	speed: 0.0288s/iter; left time: 753.6209s
Epoch: 2 cost time: 7.776908874511719
Epoch: 2, Steps: 266 Train Loss: 33.6955 (Forecasting Loss:0.1590 + XiCon Loss:3.3536 x Lambda(10.0)), Vali MSE Loss: 0.1527 Test MSE Loss: 0.1319
Validation loss decreased (0.158471 --> 0.152653).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.8239632
	speed: 0.0310s/iter; left time: 804.9377s
	iters: 200, epoch: 3 | loss: 32.4787941
	speed: 0.0285s/iter; left time: 738.3683s
Epoch: 3 cost time: 7.830795049667358
Epoch: 3, Steps: 266 Train Loss: 32.6505 (Forecasting Loss:0.1517 + XiCon Loss:3.2499 x Lambda(10.0)), Vali MSE Loss: 0.1487 Test MSE Loss: 0.1281
Validation loss decreased (0.152653 --> 0.148707).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.1232185
	speed: 0.0309s/iter; left time: 795.4554s
	iters: 200, epoch: 4 | loss: 32.4220352
	speed: 0.0287s/iter; left time: 735.2207s
Epoch: 4 cost time: 7.93752121925354
Epoch: 4, Steps: 266 Train Loss: 32.4715 (Forecasting Loss:0.1496 + XiCon Loss:3.2322 x Lambda(10.0)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.1257
Validation loss decreased (0.148707 --> 0.147005).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.6578827
	speed: 0.0305s/iter; left time: 776.0594s
	iters: 200, epoch: 5 | loss: 32.5252914
	speed: 0.0284s/iter; left time: 719.1433s
Epoch: 5 cost time: 7.821873426437378
Epoch: 5, Steps: 266 Train Loss: 32.3448 (Forecasting Loss:0.1481 + XiCon Loss:3.2197 x Lambda(10.0)), Vali MSE Loss: 0.1450 Test MSE Loss: 0.1255
Validation loss decreased (0.147005 --> 0.144972).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.5019684
	speed: 0.0309s/iter; left time: 776.7277s
	iters: 200, epoch: 6 | loss: 32.0373268
	speed: 0.0280s/iter; left time: 701.3830s
Epoch: 6 cost time: 7.712098121643066
Epoch: 6, Steps: 266 Train Loss: 32.3370 (Forecasting Loss:0.1475 + XiCon Loss:3.2189 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1247
Validation loss decreased (0.144972 --> 0.144649).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.7958527
	speed: 0.0298s/iter; left time: 743.0766s
	iters: 200, epoch: 7 | loss: 32.8171005
	speed: 0.0286s/iter; left time: 709.7109s
Epoch: 7 cost time: 7.806423902511597
Epoch: 7, Steps: 266 Train Loss: 32.3495 (Forecasting Loss:0.1473 + XiCon Loss:3.2202 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1248
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.7612228
	speed: 0.0305s/iter; left time: 752.3967s
	iters: 200, epoch: 8 | loss: 32.6665916
	speed: 0.0285s/iter; left time: 698.8686s
Epoch: 8 cost time: 7.770642518997192
Epoch: 8, Steps: 266 Train Loss: 32.3094 (Forecasting Loss:0.1471 + XiCon Loss:3.2162 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1247
Validation loss decreased (0.144649 --> 0.144500).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.1452179
	speed: 0.0308s/iter; left time: 751.3974s
	iters: 200, epoch: 9 | loss: 32.4167137
	speed: 0.0288s/iter; left time: 698.6668s
Epoch: 9 cost time: 7.850615978240967
Epoch: 9, Steps: 266 Train Loss: 32.3025 (Forecasting Loss:0.1470 + XiCon Loss:3.2155 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
Validation loss decreased (0.144500 --> 0.144343).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.0313530
	speed: 0.0316s/iter; left time: 761.0969s
	iters: 200, epoch: 10 | loss: 32.4639931
	speed: 0.0287s/iter; left time: 689.7815s
Epoch: 10 cost time: 8.031152963638306
Epoch: 10, Steps: 266 Train Loss: 32.3015 (Forecasting Loss:0.1470 + XiCon Loss:3.2155 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
Validation loss decreased (0.144343 --> 0.144316).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.5233307
	speed: 0.0305s/iter; left time: 728.1223s
	iters: 200, epoch: 11 | loss: 32.4968338
	speed: 0.0283s/iter; left time: 672.4157s
Epoch: 11 cost time: 7.81209135055542
Epoch: 11, Steps: 266 Train Loss: 32.3152 (Forecasting Loss:0.1470 + XiCon Loss:3.2168 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.0845947
	speed: 0.0305s/iter; left time: 717.9848s
	iters: 200, epoch: 12 | loss: 31.9771404
	speed: 0.0283s/iter; left time: 663.7309s
Epoch: 12 cost time: 7.822498798370361
Epoch: 12, Steps: 266 Train Loss: 32.3095 (Forecasting Loss:0.1469 + XiCon Loss:3.2163 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
Validation loss decreased (0.144316 --> 0.144197).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.5069351
	speed: 0.0296s/iter; left time: 691.0360s
	iters: 200, epoch: 13 | loss: 32.0537376
	speed: 0.0289s/iter; left time: 671.5646s
Epoch: 13 cost time: 7.717420816421509
Epoch: 13, Steps: 266 Train Loss: 32.3113 (Forecasting Loss:0.1468 + XiCon Loss:3.2165 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.9039726
	speed: 0.0309s/iter; left time: 712.1811s
	iters: 200, epoch: 14 | loss: 32.1348267
	speed: 0.0278s/iter; left time: 637.4701s
Epoch: 14 cost time: 7.7352681159973145
Epoch: 14, Steps: 266 Train Loss: 32.3211 (Forecasting Loss:0.1469 + XiCon Loss:3.2174 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.7479820
	speed: 0.0304s/iter; left time: 693.1253s
	iters: 200, epoch: 15 | loss: 32.5403366
	speed: 0.0285s/iter; left time: 645.6678s
Epoch: 15 cost time: 7.744551181793213
Epoch: 15, Steps: 266 Train Loss: 32.3149 (Forecasting Loss:0.1469 + XiCon Loss:3.2168 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.0720253
	speed: 0.0310s/iter; left time: 698.7792s
	iters: 200, epoch: 16 | loss: 32.6747131
	speed: 0.0285s/iter; left time: 637.6845s
Epoch: 16 cost time: 7.816733360290527
Epoch: 16, Steps: 266 Train Loss: 32.3187 (Forecasting Loss:0.1468 + XiCon Loss:3.2172 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
Validation loss decreased (0.144197 --> 0.144161).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.6187248
	speed: 0.0313s/iter; left time: 697.2026s
	iters: 200, epoch: 17 | loss: 31.9755650
	speed: 0.0293s/iter; left time: 648.8062s
Epoch: 17 cost time: 7.93330979347229
Epoch: 17, Steps: 266 Train Loss: 32.2944 (Forecasting Loss:0.1469 + XiCon Loss:3.2148 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.0020103
	speed: 0.0302s/iter; left time: 664.4796s
	iters: 200, epoch: 18 | loss: 32.3830910
	speed: 0.0285s/iter; left time: 624.3766s
Epoch: 18 cost time: 7.737644910812378
Epoch: 18, Steps: 266 Train Loss: 32.3167 (Forecasting Loss:0.1468 + XiCon Loss:3.2170 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
Validation loss decreased (0.144161 --> 0.144105).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.3168602
	speed: 0.0306s/iter; left time: 664.0489s
	iters: 200, epoch: 19 | loss: 32.1835251
	speed: 0.0280s/iter; left time: 604.8324s
Epoch: 19 cost time: 7.742986440658569
Epoch: 19, Steps: 266 Train Loss: 32.3258 (Forecasting Loss:0.1468 + XiCon Loss:3.2179 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.8267097
	speed: 0.0309s/iter; left time: 662.7423s
	iters: 200, epoch: 20 | loss: 32.9319038
	speed: 0.0273s/iter; left time: 582.8816s
Epoch: 20 cost time: 7.710333585739136
Epoch: 20, Steps: 266 Train Loss: 32.3137 (Forecasting Loss:0.1470 + XiCon Loss:3.2167 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.8771191
	speed: 0.0305s/iter; left time: 646.6943s
	iters: 200, epoch: 21 | loss: 32.1922035
	speed: 0.0287s/iter; left time: 604.9021s
Epoch: 21 cost time: 7.759779691696167
Epoch: 21, Steps: 266 Train Loss: 32.3192 (Forecasting Loss:0.1469 + XiCon Loss:3.2172 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.5888100
	speed: 0.0307s/iter; left time: 641.6828s
	iters: 200, epoch: 22 | loss: 32.8296547
	speed: 0.0278s/iter; left time: 578.6904s
Epoch: 22 cost time: 7.779876232147217
Epoch: 22, Steps: 266 Train Loss: 32.3159 (Forecasting Loss:0.1469 + XiCon Loss:3.2169 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.0805626
	speed: 0.0304s/iter; left time: 627.3033s
	iters: 200, epoch: 23 | loss: 32.0293236
	speed: 0.0279s/iter; left time: 572.5411s
Epoch: 23 cost time: 7.7137534618377686
Epoch: 23, Steps: 266 Train Loss: 32.2991 (Forecasting Loss:0.1469 + XiCon Loss:3.2152 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.0450363
	speed: 0.0303s/iter; left time: 617.2987s
	iters: 200, epoch: 24 | loss: 32.1217422
	speed: 0.0283s/iter; left time: 574.2804s
Epoch: 24 cost time: 7.8190836906433105
Epoch: 24, Steps: 266 Train Loss: 32.3034 (Forecasting Loss:0.1469 + XiCon Loss:3.2156 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.6570511
	speed: 0.0321s/iter; left time: 645.6445s
	iters: 200, epoch: 25 | loss: 32.1683464
	speed: 0.0283s/iter; left time: 565.4804s
Epoch: 25 cost time: 7.964569330215454
Epoch: 25, Steps: 266 Train Loss: 32.3168 (Forecasting Loss:0.1469 + XiCon Loss:3.2170 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.5159569
	speed: 0.0311s/iter; left time: 617.4517s
	iters: 200, epoch: 26 | loss: 32.1308212
	speed: 0.0287s/iter; left time: 567.6226s
Epoch: 26 cost time: 7.874607563018799
Epoch: 26, Steps: 266 Train Loss: 32.3199 (Forecasting Loss:0.1470 + XiCon Loss:3.2173 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 32.3523026
	speed: 0.0307s/iter; left time: 601.0831s
	iters: 200, epoch: 27 | loss: 32.4361076
	speed: 0.0298s/iter; left time: 580.7246s
Epoch: 27 cost time: 7.943626165390015
Epoch: 27, Steps: 266 Train Loss: 32.2998 (Forecasting Loss:0.1469 + XiCon Loss:3.2153 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 32.5264473
	speed: 0.0309s/iter; left time: 597.7057s
	iters: 200, epoch: 28 | loss: 33.1099205
	speed: 0.0292s/iter; left time: 561.5606s
Epoch: 28 cost time: 7.953709363937378
Epoch: 28, Steps: 266 Train Loss: 32.3187 (Forecasting Loss:0.1469 + XiCon Loss:3.2172 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.0645657554268837, mae:0.184289813041687, mape:0.44929039478302, mspe:8.173274993896484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3088
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 34.6258087
	speed: 0.0331s/iter; left time: 878.3367s
	iters: 200, epoch: 1 | loss: 33.8231049
	speed: 0.0302s/iter; left time: 796.5676s
Epoch: 1 cost time: 8.291502237319946
Epoch: 1, Steps: 266 Train Loss: 34.4029 (Forecasting Loss:0.1832 + XiCon Loss:3.4220 x Lambda(10.0)), Vali MSE Loss: 0.1578 Test MSE Loss: 0.1364
Validation loss decreased (inf --> 0.157833).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.9085808
	speed: 0.0316s/iter; left time: 828.3714s
	iters: 200, epoch: 2 | loss: 32.8449287
	speed: 0.0280s/iter; left time: 732.7432s
Epoch: 2 cost time: 7.849693536758423
Epoch: 2, Steps: 266 Train Loss: 33.5142 (Forecasting Loss:0.1596 + XiCon Loss:3.3355 x Lambda(10.0)), Vali MSE Loss: 0.1504 Test MSE Loss: 0.1303
Validation loss decreased (0.157833 --> 0.150382).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.1770554
	speed: 0.0303s/iter; left time: 787.9680s
	iters: 200, epoch: 3 | loss: 32.1194801
	speed: 0.0288s/iter; left time: 744.5056s
Epoch: 3 cost time: 7.862535715103149
Epoch: 3, Steps: 266 Train Loss: 32.5514 (Forecasting Loss:0.1511 + XiCon Loss:3.2400 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1303
Validation loss decreased (0.150382 --> 0.148601).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.1578751
	speed: 0.0447s/iter; left time: 1147.7433s
	iters: 200, epoch: 4 | loss: 32.0703430
	speed: 0.0438s/iter; left time: 1121.6574s
Epoch: 4 cost time: 11.661105632781982
Epoch: 4, Steps: 266 Train Loss: 32.4250 (Forecasting Loss:0.1494 + XiCon Loss:3.2276 x Lambda(10.0)), Vali MSE Loss: 0.1453 Test MSE Loss: 0.1259
Validation loss decreased (0.148601 --> 0.145300).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.2026672
	speed: 0.0454s/iter; left time: 1153.7426s
	iters: 200, epoch: 5 | loss: 32.5081215
	speed: 0.0457s/iter; left time: 1158.8823s
Epoch: 5 cost time: 11.926512002944946
Epoch: 5, Steps: 266 Train Loss: 32.4085 (Forecasting Loss:0.1482 + XiCon Loss:3.2260 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.1255
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.0689850
	speed: 0.0328s/iter; left time: 826.4659s
	iters: 200, epoch: 6 | loss: 32.1816216
	speed: 0.0297s/iter; left time: 744.9953s
Epoch: 6 cost time: 8.266541481018066
Epoch: 6, Steps: 266 Train Loss: 32.3843 (Forecasting Loss:0.1475 + XiCon Loss:3.2237 x Lambda(10.0)), Vali MSE Loss: 0.1449 Test MSE Loss: 0.1247
Validation loss decreased (0.145300 --> 0.144868).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.4432335
	speed: 0.0297s/iter; left time: 740.1130s
	iters: 200, epoch: 7 | loss: 32.1729927
	speed: 0.0294s/iter; left time: 729.9280s
Epoch: 7 cost time: 7.790949583053589
Epoch: 7, Steps: 266 Train Loss: 32.3455 (Forecasting Loss:0.1471 + XiCon Loss:3.2198 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1243
Validation loss decreased (0.144868 --> 0.144179).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.2434654
	speed: 0.0297s/iter; left time: 731.3652s
	iters: 200, epoch: 8 | loss: 32.6732979
	speed: 0.0291s/iter; left time: 714.2414s
Epoch: 8 cost time: 7.7406182289123535
Epoch: 8, Steps: 266 Train Loss: 32.3333 (Forecasting Loss:0.1469 + XiCon Loss:3.2186 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0816345
	speed: 0.0313s/iter; left time: 762.4189s
	iters: 200, epoch: 9 | loss: 32.6863022
	speed: 0.0276s/iter; left time: 669.9419s
Epoch: 9 cost time: 7.768843650817871
Epoch: 9, Steps: 266 Train Loss: 32.3788 (Forecasting Loss:0.1469 + XiCon Loss:3.2232 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1242
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.1383820
	speed: 0.0306s/iter; left time: 737.7648s
	iters: 200, epoch: 10 | loss: 32.6731110
	speed: 0.0280s/iter; left time: 672.0016s
Epoch: 10 cost time: 7.769934415817261
Epoch: 10, Steps: 266 Train Loss: 32.3578 (Forecasting Loss:0.1468 + XiCon Loss:3.2211 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1242
Validation loss decreased (0.144179 --> 0.143989).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.7751541
	speed: 0.0300s/iter; left time: 714.3532s
	iters: 200, epoch: 11 | loss: 32.6441307
	speed: 0.0284s/iter; left time: 674.9949s
Epoch: 11 cost time: 7.786490440368652
Epoch: 11, Steps: 266 Train Loss: 32.3551 (Forecasting Loss:0.1468 + XiCon Loss:3.2208 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.8064499
	speed: 0.0310s/iter; left time: 730.9179s
	iters: 200, epoch: 12 | loss: 32.1261940
	speed: 0.0278s/iter; left time: 652.7599s
Epoch: 12 cost time: 7.774316787719727
Epoch: 12, Steps: 266 Train Loss: 32.3735 (Forecasting Loss:0.1467 + XiCon Loss:3.2227 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.7368813
	speed: 0.0316s/iter; left time: 736.1720s
	iters: 200, epoch: 13 | loss: 33.0549316
	speed: 0.0284s/iter; left time: 658.6989s
Epoch: 13 cost time: 7.903365850448608
Epoch: 13, Steps: 266 Train Loss: 32.3656 (Forecasting Loss:0.1467 + XiCon Loss:3.2219 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.3395081
	speed: 0.0307s/iter; left time: 706.5252s
	iters: 200, epoch: 14 | loss: 32.2086411
	speed: 0.0284s/iter; left time: 652.0617s
Epoch: 14 cost time: 7.832197904586792
Epoch: 14, Steps: 266 Train Loss: 32.3567 (Forecasting Loss:0.1468 + XiCon Loss:3.2210 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.6741028
	speed: 0.0294s/iter; left time: 668.6418s
	iters: 200, epoch: 15 | loss: 32.1515999
	speed: 0.0285s/iter; left time: 645.6821s
Epoch: 15 cost time: 7.645129203796387
Epoch: 15, Steps: 266 Train Loss: 32.3691 (Forecasting Loss:0.1467 + XiCon Loss:3.2222 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.5297050
	speed: 0.0305s/iter; left time: 686.4863s
	iters: 200, epoch: 16 | loss: 32.8376236
	speed: 0.0281s/iter; left time: 628.8321s
Epoch: 16 cost time: 7.812664270401001
Epoch: 16, Steps: 266 Train Loss: 32.3559 (Forecasting Loss:0.1467 + XiCon Loss:3.2209 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1242
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.4369583
	speed: 0.0311s/iter; left time: 691.7458s
	iters: 200, epoch: 17 | loss: 32.3941116
	speed: 0.0286s/iter; left time: 632.2670s
Epoch: 17 cost time: 7.844083786010742
Epoch: 17, Steps: 266 Train Loss: 32.3597 (Forecasting Loss:0.1467 + XiCon Loss:3.2213 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.1047440
	speed: 0.0302s/iter; left time: 663.0088s
	iters: 200, epoch: 18 | loss: 32.6403847
	speed: 0.0281s/iter; left time: 615.2083s
Epoch: 18 cost time: 7.750419855117798
Epoch: 18, Steps: 266 Train Loss: 32.3381 (Forecasting Loss:0.1468 + XiCon Loss:3.2191 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.1613159
	speed: 0.0307s/iter; left time: 666.0041s
	iters: 200, epoch: 19 | loss: 31.9578896
	speed: 0.0287s/iter; left time: 619.3887s
Epoch: 19 cost time: 7.896098852157593
Epoch: 19, Steps: 266 Train Loss: 32.3721 (Forecasting Loss:0.1467 + XiCon Loss:3.2225 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1242
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.4998055
	speed: 0.0299s/iter; left time: 641.5503s
	iters: 200, epoch: 20 | loss: 32.0158386
	speed: 0.0277s/iter; left time: 591.0799s
Epoch: 20 cost time: 7.582975387573242
Epoch: 20, Steps: 266 Train Loss: 32.3732 (Forecasting Loss:0.1466 + XiCon Loss:3.2227 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1242
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06434694677591324, mae:0.18397672474384308, mape:0.4480897784233093, mspe:8.138826370239258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.6668
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 34.5048370
	speed: 0.0327s/iter; left time: 867.3834s
	iters: 200, epoch: 1 | loss: 33.7526321
	speed: 0.0301s/iter; left time: 795.9722s
Epoch: 1 cost time: 8.323183059692383
Epoch: 1, Steps: 266 Train Loss: 34.3496 (Forecasting Loss:0.1866 + XiCon Loss:3.4163 x Lambda(10.0)), Vali MSE Loss: 0.1569 Test MSE Loss: 0.1368
Validation loss decreased (inf --> 0.156887).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.6126289
	speed: 0.0309s/iter; left time: 809.4105s
	iters: 200, epoch: 2 | loss: 33.2230301
	speed: 0.0278s/iter; left time: 726.8358s
Epoch: 2 cost time: 7.705061674118042
Epoch: 2, Steps: 266 Train Loss: 33.3844 (Forecasting Loss:0.1598 + XiCon Loss:3.3225 x Lambda(10.0)), Vali MSE Loss: 0.1616 Test MSE Loss: 0.1380
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.1572800
	speed: 0.0297s/iter; left time: 772.3498s
	iters: 200, epoch: 3 | loss: 32.0798683
	speed: 0.0275s/iter; left time: 710.7751s
Epoch: 3 cost time: 7.618991136550903
Epoch: 3, Steps: 266 Train Loss: 32.6671 (Forecasting Loss:0.1524 + XiCon Loss:3.2515 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.1280
Validation loss decreased (0.156887 --> 0.148349).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.9699802
	speed: 0.0304s/iter; left time: 781.6816s
	iters: 200, epoch: 4 | loss: 32.0354156
	speed: 0.0275s/iter; left time: 704.4348s
Epoch: 4 cost time: 7.697482585906982
Epoch: 4, Steps: 266 Train Loss: 32.2411 (Forecasting Loss:0.1496 + XiCon Loss:3.2092 x Lambda(10.0)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.1273
Validation loss decreased (0.148349 --> 0.147585).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.0098648
	speed: 0.0306s/iter; left time: 777.9518s
	iters: 200, epoch: 5 | loss: 33.1195335
	speed: 0.0286s/iter; left time: 725.1017s
Epoch: 5 cost time: 7.761896371841431
Epoch: 5, Steps: 266 Train Loss: 32.2407 (Forecasting Loss:0.1481 + XiCon Loss:3.2093 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1252
Validation loss decreased (0.147585 --> 0.144299).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.0194550
	speed: 0.0304s/iter; left time: 765.9585s
	iters: 200, epoch: 6 | loss: 31.8876915
	speed: 0.0285s/iter; left time: 714.3517s
Epoch: 6 cost time: 7.824455976486206
Epoch: 6, Steps: 266 Train Loss: 32.2031 (Forecasting Loss:0.1475 + XiCon Loss:3.2056 x Lambda(10.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.0500069
	speed: 0.0307s/iter; left time: 765.3283s
	iters: 200, epoch: 7 | loss: 31.9449940
	speed: 0.0279s/iter; left time: 692.1782s
Epoch: 7 cost time: 7.761134386062622
Epoch: 7, Steps: 266 Train Loss: 32.1760 (Forecasting Loss:0.1472 + XiCon Loss:3.2029 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1249
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.0786400
	speed: 0.0304s/iter; left time: 749.8689s
	iters: 200, epoch: 8 | loss: 32.4550285
	speed: 0.0287s/iter; left time: 704.2451s
Epoch: 8 cost time: 7.8181986808776855
Epoch: 8, Steps: 266 Train Loss: 32.1624 (Forecasting Loss:0.1470 + XiCon Loss:3.2015 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1246
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0591202
	speed: 0.0304s/iter; left time: 741.0455s
	iters: 200, epoch: 9 | loss: 31.8805447
	speed: 0.0288s/iter; left time: 700.2066s
Epoch: 9 cost time: 7.884148597717285
Epoch: 9, Steps: 266 Train Loss: 32.1885 (Forecasting Loss:0.1471 + XiCon Loss:3.2041 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
Validation loss decreased (0.144299 --> 0.144181).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.5470467
	speed: 0.0303s/iter; left time: 730.3901s
	iters: 200, epoch: 10 | loss: 31.7996864
	speed: 0.0280s/iter; left time: 671.2023s
Epoch: 10 cost time: 7.733766078948975
Epoch: 10, Steps: 266 Train Loss: 32.1929 (Forecasting Loss:0.1469 + XiCon Loss:3.2046 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.4085808
	speed: 0.0310s/iter; left time: 739.9782s
	iters: 200, epoch: 11 | loss: 31.7537899
	speed: 0.0289s/iter; left time: 685.4900s
Epoch: 11 cost time: 7.921430587768555
Epoch: 11, Steps: 266 Train Loss: 32.2019 (Forecasting Loss:0.1469 + XiCon Loss:3.2055 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.9387302
	speed: 0.0308s/iter; left time: 725.2552s
	iters: 200, epoch: 12 | loss: 32.0971298
	speed: 0.0288s/iter; left time: 676.2338s
Epoch: 12 cost time: 7.895449638366699
Epoch: 12, Steps: 266 Train Loss: 32.1786 (Forecasting Loss:0.1469 + XiCon Loss:3.2032 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.4794884
	speed: 0.0309s/iter; left time: 720.4417s
	iters: 200, epoch: 13 | loss: 31.8036232
	speed: 0.0282s/iter; left time: 655.4180s
Epoch: 13 cost time: 7.853951454162598
Epoch: 13, Steps: 266 Train Loss: 32.1817 (Forecasting Loss:0.1468 + XiCon Loss:3.2035 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.4084473
	speed: 0.0304s/iter; left time: 701.6015s
	iters: 200, epoch: 14 | loss: 32.9900131
	speed: 0.0292s/iter; left time: 669.5530s
Epoch: 14 cost time: 7.892293214797974
Epoch: 14, Steps: 266 Train Loss: 32.1941 (Forecasting Loss:0.1469 + XiCon Loss:3.2047 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
Validation loss decreased (0.144181 --> 0.144148).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.9758701
	speed: 0.0311s/iter; left time: 707.8807s
	iters: 200, epoch: 15 | loss: 31.8749352
	speed: 0.0275s/iter; left time: 622.7262s
Epoch: 15 cost time: 7.703277826309204
Epoch: 15, Steps: 266 Train Loss: 32.1822 (Forecasting Loss:0.1469 + XiCon Loss:3.2035 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4253502
	speed: 0.0304s/iter; left time: 684.3741s
	iters: 200, epoch: 16 | loss: 32.5525742
	speed: 0.0284s/iter; left time: 636.2507s
Epoch: 16 cost time: 7.805814743041992
Epoch: 16, Steps: 266 Train Loss: 32.1871 (Forecasting Loss:0.1468 + XiCon Loss:3.2040 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.8721924
	speed: 0.0304s/iter; left time: 676.7895s
	iters: 200, epoch: 17 | loss: 32.3490524
	speed: 0.0294s/iter; left time: 652.1026s
Epoch: 17 cost time: 7.909245014190674
Epoch: 17, Steps: 266 Train Loss: 32.2134 (Forecasting Loss:0.1469 + XiCon Loss:3.2067 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.8207436
	speed: 0.0305s/iter; left time: 669.2919s
	iters: 200, epoch: 18 | loss: 31.9807549
	speed: 0.0292s/iter; left time: 637.8779s
Epoch: 18 cost time: 7.872001647949219
Epoch: 18, Steps: 266 Train Loss: 32.1931 (Forecasting Loss:0.1469 + XiCon Loss:3.2046 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.9173965
	speed: 0.0309s/iter; left time: 671.5710s
	iters: 200, epoch: 19 | loss: 31.9319038
	speed: 0.0284s/iter; left time: 614.1056s
Epoch: 19 cost time: 7.836481094360352
Epoch: 19, Steps: 266 Train Loss: 32.1908 (Forecasting Loss:0.1469 + XiCon Loss:3.2044 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
Validation loss decreased (0.144148 --> 0.144122).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.5546951
	speed: 0.0305s/iter; left time: 653.3219s
	iters: 200, epoch: 20 | loss: 31.8103790
	speed: 0.0288s/iter; left time: 614.2434s
Epoch: 20 cost time: 7.7587010860443115
Epoch: 20, Steps: 266 Train Loss: 32.2245 (Forecasting Loss:0.1468 + XiCon Loss:3.2078 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
Validation loss decreased (0.144122 --> 0.144086).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.3365517
	speed: 0.0305s/iter; left time: 645.4329s
	iters: 200, epoch: 21 | loss: 32.2656059
	speed: 0.0292s/iter; left time: 616.2315s
Epoch: 21 cost time: 7.87866473197937
Epoch: 21, Steps: 266 Train Loss: 32.1820 (Forecasting Loss:0.1468 + XiCon Loss:3.2035 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.8770847
	speed: 0.0308s/iter; left time: 644.2066s
	iters: 200, epoch: 22 | loss: 33.1046677
	speed: 0.0279s/iter; left time: 580.6622s
Epoch: 22 cost time: 7.760155916213989
Epoch: 22, Steps: 266 Train Loss: 32.1792 (Forecasting Loss:0.1469 + XiCon Loss:3.2032 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
Validation loss decreased (0.144086 --> 0.144069).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.4351654
	speed: 0.0294s/iter; left time: 607.6295s
	iters: 200, epoch: 23 | loss: 32.3856354
	speed: 0.0282s/iter; left time: 579.9333s
Epoch: 23 cost time: 7.636209487915039
Epoch: 23, Steps: 266 Train Loss: 32.1607 (Forecasting Loss:0.1468 + XiCon Loss:3.2014 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.8513451
	speed: 0.0310s/iter; left time: 632.0432s
	iters: 200, epoch: 24 | loss: 31.8718624
	speed: 0.0282s/iter; left time: 571.6815s
Epoch: 24 cost time: 7.8836445808410645
Epoch: 24, Steps: 266 Train Loss: 32.1785 (Forecasting Loss:0.1469 + XiCon Loss:3.2032 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.0676155
	speed: 0.0303s/iter; left time: 608.6963s
	iters: 200, epoch: 25 | loss: 32.0727730
	speed: 0.0277s/iter; left time: 553.9784s
Epoch: 25 cost time: 7.677776336669922
Epoch: 25, Steps: 266 Train Loss: 32.2152 (Forecasting Loss:0.1469 + XiCon Loss:3.2068 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 32.3497162
	speed: 0.0304s/iter; left time: 603.7157s
	iters: 200, epoch: 26 | loss: 32.0755348
	speed: 0.0290s/iter; left time: 573.3293s
Epoch: 26 cost time: 7.855116844177246
Epoch: 26, Steps: 266 Train Loss: 32.1975 (Forecasting Loss:0.1468 + XiCon Loss:3.2051 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.9417534
	speed: 0.0306s/iter; left time: 600.1494s
	iters: 200, epoch: 27 | loss: 32.6196518
	speed: 0.0280s/iter; left time: 544.9058s
Epoch: 27 cost time: 7.792964458465576
Epoch: 27, Steps: 266 Train Loss: 32.1623 (Forecasting Loss:0.1468 + XiCon Loss:3.2015 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 31.8389072
	speed: 0.0306s/iter; left time: 591.2145s
	iters: 200, epoch: 28 | loss: 31.8641911
	speed: 0.0279s/iter; left time: 535.8079s
Epoch: 28 cost time: 7.701575756072998
Epoch: 28, Steps: 266 Train Loss: 32.1813 (Forecasting Loss:0.1468 + XiCon Loss:3.2034 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 31.8062744
	speed: 0.0307s/iter; left time: 584.3177s
	iters: 200, epoch: 29 | loss: 31.8131714
	speed: 0.0285s/iter; left time: 540.5356s
Epoch: 29 cost time: 7.83126974105835
Epoch: 29, Steps: 266 Train Loss: 32.2070 (Forecasting Loss:0.1468 + XiCon Loss:3.2060 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 31.8527412
	speed: 0.0312s/iter; left time: 586.0651s
	iters: 200, epoch: 30 | loss: 32.0066490
	speed: 0.0293s/iter; left time: 547.6059s
Epoch: 30 cost time: 7.907487630844116
Epoch: 30, Steps: 266 Train Loss: 32.1572 (Forecasting Loss:0.1469 + XiCon Loss:3.2010 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 32.1076813
	speed: 0.0302s/iter; left time: 559.4163s
	iters: 200, epoch: 31 | loss: 31.8482685
	speed: 0.0289s/iter; left time: 531.8795s
Epoch: 31 cost time: 7.808831453323364
Epoch: 31, Steps: 266 Train Loss: 32.1827 (Forecasting Loss:0.1468 + XiCon Loss:3.2036 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 32.0042763
	speed: 0.0312s/iter; left time: 570.2018s
	iters: 200, epoch: 32 | loss: 32.0947609
	speed: 0.0280s/iter; left time: 508.5739s
Epoch: 32 cost time: 7.82442045211792
Epoch: 32, Steps: 266 Train Loss: 32.2217 (Forecasting Loss:0.1469 + XiCon Loss:3.2075 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06463481485843658, mae:0.18432053923606873, mape:0.44892993569374084, mspe:8.154252052307129 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.2510
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 34.9428062
	speed: 0.0305s/iter; left time: 809.2584s
	iters: 200, epoch: 1 | loss: 33.9736938
	speed: 0.0293s/iter; left time: 773.4015s
Epoch: 1 cost time: 7.86513090133667
Epoch: 1, Steps: 266 Train Loss: 34.6031 (Forecasting Loss:0.1900 + XiCon Loss:3.4413 x Lambda(10.0)), Vali MSE Loss: 0.1612 Test MSE Loss: 0.1376
Validation loss decreased (inf --> 0.161174).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.6633492
	speed: 0.0307s/iter; left time: 806.6374s
	iters: 200, epoch: 2 | loss: 33.3830338
	speed: 0.0289s/iter; left time: 755.8109s
Epoch: 2 cost time: 7.823320627212524
Epoch: 2, Steps: 266 Train Loss: 33.3886 (Forecasting Loss:0.1587 + XiCon Loss:3.3230 x Lambda(10.0)), Vali MSE Loss: 0.1502 Test MSE Loss: 0.1316
Validation loss decreased (0.161174 --> 0.150181).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.7405434
	speed: 0.0301s/iter; left time: 782.6460s
	iters: 200, epoch: 3 | loss: 31.8312531
	speed: 0.0279s/iter; left time: 720.6806s
Epoch: 3 cost time: 7.7561681270599365
Epoch: 3, Steps: 266 Train Loss: 32.3151 (Forecasting Loss:0.1522 + XiCon Loss:3.2163 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.1264
Validation loss decreased (0.150181 --> 0.147889).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.1502266
	speed: 0.0306s/iter; left time: 787.7832s
	iters: 200, epoch: 4 | loss: 32.4153252
	speed: 0.0280s/iter; left time: 718.1214s
Epoch: 4 cost time: 7.786644220352173
Epoch: 4, Steps: 266 Train Loss: 32.2425 (Forecasting Loss:0.1495 + XiCon Loss:3.2093 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.1267
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.0854950
	speed: 0.0301s/iter; left time: 766.5302s
	iters: 200, epoch: 5 | loss: 31.7054443
	speed: 0.0275s/iter; left time: 697.8186s
Epoch: 5 cost time: 7.611459493637085
Epoch: 5, Steps: 266 Train Loss: 32.2013 (Forecasting Loss:0.1480 + XiCon Loss:3.2053 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.1250
Validation loss decreased (0.147889 --> 0.146499).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.9457855
	speed: 0.0321s/iter; left time: 809.0010s
	iters: 200, epoch: 6 | loss: 32.9632111
	speed: 0.0295s/iter; left time: 739.6686s
Epoch: 6 cost time: 8.264526605606079
Epoch: 6, Steps: 266 Train Loss: 32.1463 (Forecasting Loss:0.1477 + XiCon Loss:3.1999 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1251
Validation loss decreased (0.146499 --> 0.144017).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.0041733
	speed: 0.0314s/iter; left time: 781.1892s
	iters: 200, epoch: 7 | loss: 32.5077744
	speed: 0.0283s/iter; left time: 702.3470s
Epoch: 7 cost time: 7.840279579162598
Epoch: 7, Steps: 266 Train Loss: 32.1699 (Forecasting Loss:0.1473 + XiCon Loss:3.2023 x Lambda(10.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.4785652
	speed: 0.0302s/iter; left time: 744.4503s
	iters: 200, epoch: 8 | loss: 32.0773315
	speed: 0.0284s/iter; left time: 695.9993s
Epoch: 8 cost time: 7.7705042362213135
Epoch: 8, Steps: 266 Train Loss: 32.1989 (Forecasting Loss:0.1471 + XiCon Loss:3.2052 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1247
Validation loss decreased (0.144017 --> 0.144016).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.9938049
	speed: 0.0307s/iter; left time: 747.3102s
	iters: 200, epoch: 9 | loss: 33.0075073
	speed: 0.0274s/iter; left time: 665.2377s
Epoch: 9 cost time: 7.639541387557983
Epoch: 9, Steps: 266 Train Loss: 32.1783 (Forecasting Loss:0.1470 + XiCon Loss:3.2031 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.5927124
	speed: 0.0303s/iter; left time: 730.0406s
	iters: 200, epoch: 10 | loss: 31.8088512
	speed: 0.0288s/iter; left time: 691.1890s
Epoch: 10 cost time: 7.789847373962402
Epoch: 10, Steps: 266 Train Loss: 32.1678 (Forecasting Loss:0.1469 + XiCon Loss:3.2021 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.1608086
	speed: 0.0303s/iter; left time: 723.2986s
	iters: 200, epoch: 11 | loss: 31.8623791
	speed: 0.0293s/iter; left time: 694.7717s
Epoch: 11 cost time: 7.958745241165161
Epoch: 11, Steps: 266 Train Loss: 32.1513 (Forecasting Loss:0.1469 + XiCon Loss:3.2004 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.6865540
	speed: 0.0308s/iter; left time: 725.0255s
	iters: 200, epoch: 12 | loss: 31.9172516
	speed: 0.0284s/iter; left time: 666.8165s
Epoch: 12 cost time: 7.879939794540405
Epoch: 12, Steps: 266 Train Loss: 32.1615 (Forecasting Loss:0.1470 + XiCon Loss:3.2014 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.4564934
	speed: 0.0305s/iter; left time: 710.5930s
	iters: 200, epoch: 13 | loss: 31.8428211
	speed: 0.0282s/iter; left time: 654.9802s
Epoch: 13 cost time: 7.720264196395874
Epoch: 13, Steps: 266 Train Loss: 32.1662 (Forecasting Loss:0.1469 + XiCon Loss:3.2019 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.6408272
	speed: 0.0309s/iter; left time: 710.8848s
	iters: 200, epoch: 14 | loss: 31.9734001
	speed: 0.0291s/iter; left time: 666.9578s
Epoch: 14 cost time: 7.950669050216675
Epoch: 14, Steps: 266 Train Loss: 32.1841 (Forecasting Loss:0.1469 + XiCon Loss:3.2037 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.5714951
	speed: 0.0308s/iter; left time: 701.9591s
	iters: 200, epoch: 15 | loss: 31.8201599
	speed: 0.0283s/iter; left time: 641.5529s
Epoch: 15 cost time: 7.746999502182007
Epoch: 15, Steps: 266 Train Loss: 32.1584 (Forecasting Loss:0.1469 + XiCon Loss:3.2012 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4515572
	speed: 0.0317s/iter; left time: 713.7898s
	iters: 200, epoch: 16 | loss: 32.3755455
	speed: 0.0280s/iter; left time: 628.0965s
Epoch: 16 cost time: 7.861398220062256
Epoch: 16, Steps: 266 Train Loss: 32.2002 (Forecasting Loss:0.1470 + XiCon Loss:3.2053 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.4511223
	speed: 0.0301s/iter; left time: 668.9970s
	iters: 200, epoch: 17 | loss: 31.8692493
	speed: 0.0286s/iter; left time: 634.0392s
Epoch: 17 cost time: 7.704766035079956
Epoch: 17, Steps: 266 Train Loss: 32.1670 (Forecasting Loss:0.1469 + XiCon Loss:3.2020 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.6671257
	speed: 0.0303s/iter; left time: 665.9665s
	iters: 200, epoch: 18 | loss: 31.7104168
	speed: 0.0281s/iter; left time: 614.9785s
Epoch: 18 cost time: 7.779468059539795
Epoch: 18, Steps: 266 Train Loss: 32.2053 (Forecasting Loss:0.1469 + XiCon Loss:3.2058 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06481454521417618, mae:0.18467524647712708, mape:0.4498024880886078, mspe:8.118873596191406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0646+-0.00021, MAE:0.1843+-0.00031, MAPE:0.4489+-0.00083, MSPE:8.1421+-0.02746, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.3963
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.9023747
	speed: 0.0356s/iter; left time: 938.7803s
	iters: 200, epoch: 1 | loss: 3.8932095
	speed: 0.0311s/iter; left time: 816.7738s
Epoch: 1 cost time: 8.597289085388184
Epoch: 1, Steps: 265 Train Loss: 3.8858 (Forecasting Loss:0.3531 + XiCon Loss:3.5327 x Lambda(1.0)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.2776
Validation loss decreased (inf --> 0.336488).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.7074342
	speed: 0.0321s/iter; left time: 838.8513s
	iters: 200, epoch: 2 | loss: 3.7033143
	speed: 0.0300s/iter; left time: 781.8084s
Epoch: 2 cost time: 8.119707107543945
Epoch: 2, Steps: 265 Train Loss: 3.7124 (Forecasting Loss:0.2415 + XiCon Loss:3.4709 x Lambda(1.0)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1739
Validation loss decreased (0.336488 --> 0.216691).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5671687
	speed: 0.0327s/iter; left time: 845.2090s
	iters: 200, epoch: 3 | loss: 3.5644515
	speed: 0.0299s/iter; left time: 771.3425s
Epoch: 3 cost time: 8.144449472427368
Epoch: 3, Steps: 265 Train Loss: 3.5840 (Forecasting Loss:0.2145 + XiCon Loss:3.3695 x Lambda(1.0)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1708
Validation loss decreased (0.216691 --> 0.212107).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5177126
	speed: 0.0309s/iter; left time: 791.8351s
	iters: 200, epoch: 4 | loss: 3.5394373
	speed: 0.0302s/iter; left time: 770.2996s
Epoch: 4 cost time: 8.063047647476196
Epoch: 4, Steps: 265 Train Loss: 3.5455 (Forecasting Loss:0.2113 + XiCon Loss:3.3342 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1699
Validation loss decreased (0.212107 --> 0.211124).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5301013
	speed: 0.0317s/iter; left time: 803.2335s
	iters: 200, epoch: 5 | loss: 3.5272939
	speed: 0.0285s/iter; left time: 719.5127s
Epoch: 5 cost time: 7.914669036865234
Epoch: 5, Steps: 265 Train Loss: 3.5284 (Forecasting Loss:0.2101 + XiCon Loss:3.3183 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1695
Validation loss decreased (0.211124 --> 0.210758).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5435469
	speed: 0.0315s/iter; left time: 788.8235s
	iters: 200, epoch: 6 | loss: 3.5056250
	speed: 0.0302s/iter; left time: 753.4238s
Epoch: 6 cost time: 8.163238525390625
Epoch: 6, Steps: 265 Train Loss: 3.5191 (Forecasting Loss:0.2097 + XiCon Loss:3.3094 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5069313
	speed: 0.0309s/iter; left time: 767.8662s
	iters: 200, epoch: 7 | loss: 3.5405707
	speed: 0.0290s/iter; left time: 715.7310s
Epoch: 7 cost time: 7.90768837928772
Epoch: 7, Steps: 265 Train Loss: 3.5143 (Forecasting Loss:0.2097 + XiCon Loss:3.3047 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1691
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5272439
	speed: 0.0316s/iter; left time: 775.2011s
	iters: 200, epoch: 8 | loss: 3.5385327
	speed: 0.0291s/iter; left time: 712.3095s
Epoch: 8 cost time: 8.037733316421509
Epoch: 8, Steps: 265 Train Loss: 3.5120 (Forecasting Loss:0.2095 + XiCon Loss:3.3026 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1691
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.5264447
	speed: 0.0336s/iter; left time: 815.0769s
	iters: 200, epoch: 9 | loss: 3.4915252
	speed: 0.0285s/iter; left time: 689.9893s
Epoch: 9 cost time: 8.107951879501343
Epoch: 9, Steps: 265 Train Loss: 3.5109 (Forecasting Loss:0.2093 + XiCon Loss:3.3016 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1691
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.5177145
	speed: 0.0319s/iter; left time: 767.1056s
	iters: 200, epoch: 10 | loss: 3.5039911
	speed: 0.0289s/iter; left time: 692.0200s
Epoch: 10 cost time: 8.022451400756836
Epoch: 10, Steps: 265 Train Loss: 3.5097 (Forecasting Loss:0.2094 + XiCon Loss:3.3003 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1691
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.5041811
	speed: 0.0318s/iter; left time: 754.4547s
	iters: 200, epoch: 11 | loss: 3.4811583
	speed: 0.0310s/iter; left time: 733.0880s
Epoch: 11 cost time: 8.258925676345825
Epoch: 11, Steps: 265 Train Loss: 3.5109 (Forecasting Loss:0.2094 + XiCon Loss:3.3015 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1691
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5188699
	speed: 0.0313s/iter; left time: 735.7290s
	iters: 200, epoch: 12 | loss: 3.5063286
	speed: 0.0289s/iter; left time: 677.0084s
Epoch: 12 cost time: 7.977669954299927
Epoch: 12, Steps: 265 Train Loss: 3.5115 (Forecasting Loss:0.2093 + XiCon Loss:3.3022 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1691
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.5155780
	speed: 0.0320s/iter; left time: 743.5305s
	iters: 200, epoch: 13 | loss: 3.4727421
	speed: 0.0301s/iter; left time: 696.0672s
Epoch: 13 cost time: 8.10266900062561
Epoch: 13, Steps: 265 Train Loss: 3.5101 (Forecasting Loss:0.2093 + XiCon Loss:3.3009 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1690
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.5158901
	speed: 0.0308s/iter; left time: 706.1555s
	iters: 200, epoch: 14 | loss: 3.5078378
	speed: 0.0286s/iter; left time: 654.6944s
Epoch: 14 cost time: 7.831171274185181
Epoch: 14, Steps: 265 Train Loss: 3.5096 (Forecasting Loss:0.2093 + XiCon Loss:3.3003 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1690
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.5340405
	speed: 0.0310s/iter; left time: 703.3837s
	iters: 200, epoch: 15 | loss: 3.4960504
	speed: 0.0288s/iter; left time: 650.3395s
Epoch: 15 cost time: 7.954014778137207
Epoch: 15, Steps: 265 Train Loss: 3.5102 (Forecasting Loss:0.2092 + XiCon Loss:3.3010 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1690
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0989973396062851, mae:0.23991255462169647, mape:0.5692495107650757, mspe:11.827034950256348 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5635
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.9299169
	speed: 0.0345s/iter; left time: 911.8525s
	iters: 200, epoch: 1 | loss: 3.8727601
	speed: 0.0319s/iter; left time: 839.8854s
Epoch: 1 cost time: 8.758557558059692
Epoch: 1, Steps: 265 Train Loss: 3.8994 (Forecasting Loss:0.3548 + XiCon Loss:3.5446 x Lambda(1.0)), Vali MSE Loss: 0.3334 Test MSE Loss: 0.2761
Validation loss decreased (inf --> 0.333437).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.7273121
	speed: 0.0315s/iter; left time: 823.6959s
	iters: 200, epoch: 2 | loss: 3.6921093
	speed: 0.0288s/iter; left time: 749.2244s
Epoch: 2 cost time: 7.9394190311431885
Epoch: 2, Steps: 265 Train Loss: 3.7337 (Forecasting Loss:0.2408 + XiCon Loss:3.4928 x Lambda(1.0)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.1728
Validation loss decreased (0.333437 --> 0.220243).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.6229117
	speed: 0.0314s/iter; left time: 811.9323s
	iters: 200, epoch: 3 | loss: 3.5788412
	speed: 0.0287s/iter; left time: 738.4179s
Epoch: 3 cost time: 7.930830240249634
Epoch: 3, Steps: 265 Train Loss: 3.6120 (Forecasting Loss:0.2131 + XiCon Loss:3.3989 x Lambda(1.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.1693
Validation loss decreased (0.220243 --> 0.215519).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5600805
	speed: 0.0314s/iter; left time: 804.9125s
	iters: 200, epoch: 4 | loss: 3.5753646
	speed: 0.0292s/iter; left time: 744.5804s
Epoch: 4 cost time: 7.941148519515991
Epoch: 4, Steps: 265 Train Loss: 3.5730 (Forecasting Loss:0.2102 + XiCon Loss:3.3628 x Lambda(1.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1688
Validation loss decreased (0.215519 --> 0.214307).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5788715
	speed: 0.0315s/iter; left time: 798.8684s
	iters: 200, epoch: 5 | loss: 3.5416610
	speed: 0.0292s/iter; left time: 737.9231s
Epoch: 5 cost time: 8.078717947006226
Epoch: 5, Steps: 265 Train Loss: 3.5634 (Forecasting Loss:0.2093 + XiCon Loss:3.3541 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1687
Validation loss decreased (0.214307 --> 0.214250).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5605357
	speed: 0.0304s/iter; left time: 763.3722s
	iters: 200, epoch: 6 | loss: 3.5519152
	speed: 0.0291s/iter; left time: 727.4808s
Epoch: 6 cost time: 7.861522436141968
Epoch: 6, Steps: 265 Train Loss: 3.5587 (Forecasting Loss:0.2087 + XiCon Loss:3.3500 x Lambda(1.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1686
Validation loss decreased (0.214250 --> 0.213755).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5785930
	speed: 0.0314s/iter; left time: 779.3830s
	iters: 200, epoch: 7 | loss: 3.5573533
	speed: 0.0305s/iter; left time: 754.0585s
Epoch: 7 cost time: 8.082423210144043
Epoch: 7, Steps: 265 Train Loss: 3.5568 (Forecasting Loss:0.2085 + XiCon Loss:3.3483 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1683
Validation loss decreased (0.213755 --> 0.213629).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5787606
	speed: 0.0314s/iter; left time: 769.9922s
	iters: 200, epoch: 8 | loss: 3.5273314
	speed: 0.0294s/iter; left time: 718.7431s
Epoch: 8 cost time: 7.992672681808472
Epoch: 8, Steps: 265 Train Loss: 3.5551 (Forecasting Loss:0.2084 + XiCon Loss:3.3467 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1684
Validation loss decreased (0.213629 --> 0.213617).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.5568302
	speed: 0.0316s/iter; left time: 767.4110s
	iters: 200, epoch: 9 | loss: 3.5558252
	speed: 0.0291s/iter; left time: 702.5100s
Epoch: 9 cost time: 7.982400417327881
Epoch: 9, Steps: 265 Train Loss: 3.5541 (Forecasting Loss:0.2083 + XiCon Loss:3.3458 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1684
Validation loss decreased (0.213617 --> 0.213524).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.5387115
	speed: 0.0319s/iter; left time: 766.2250s
	iters: 200, epoch: 10 | loss: 3.5587399
	speed: 0.0309s/iter; left time: 738.0251s
Epoch: 10 cost time: 8.24758005142212
Epoch: 10, Steps: 265 Train Loss: 3.5544 (Forecasting Loss:0.2082 + XiCon Loss:3.3462 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1684
Validation loss decreased (0.213524 --> 0.213398).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.5643411
	speed: 0.0317s/iter; left time: 753.6447s
	iters: 200, epoch: 11 | loss: 3.5721488
	speed: 0.0300s/iter; left time: 709.7568s
Epoch: 11 cost time: 8.049798488616943
Epoch: 11, Steps: 265 Train Loss: 3.5539 (Forecasting Loss:0.2083 + XiCon Loss:3.3456 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5508728
	speed: 0.0318s/iter; left time: 746.8519s
	iters: 200, epoch: 12 | loss: 3.5523534
	speed: 0.0293s/iter; left time: 685.9790s
Epoch: 12 cost time: 8.0559983253479
Epoch: 12, Steps: 265 Train Loss: 3.5538 (Forecasting Loss:0.2083 + XiCon Loss:3.3455 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1683
Validation loss decreased (0.213398 --> 0.213267).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.5360591
	speed: 0.0309s/iter; left time: 717.7170s
	iters: 200, epoch: 13 | loss: 3.5678024
	speed: 0.0300s/iter; left time: 693.4223s
Epoch: 13 cost time: 8.020453214645386
Epoch: 13, Steps: 265 Train Loss: 3.5542 (Forecasting Loss:0.2084 + XiCon Loss:3.3458 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1683
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.5440960
	speed: 0.0313s/iter; left time: 718.4129s
	iters: 200, epoch: 14 | loss: 3.5385571
	speed: 0.0293s/iter; left time: 669.6675s
Epoch: 14 cost time: 7.933786630630493
Epoch: 14, Steps: 265 Train Loss: 3.5546 (Forecasting Loss:0.2084 + XiCon Loss:3.3462 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.5562854
	speed: 0.0321s/iter; left time: 729.0867s
	iters: 200, epoch: 15 | loss: 3.5477002
	speed: 0.0310s/iter; left time: 699.5315s
Epoch: 15 cost time: 8.391977787017822
Epoch: 15, Steps: 265 Train Loss: 3.5543 (Forecasting Loss:0.2084 + XiCon Loss:3.3459 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1683
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.5456464
	speed: 0.0320s/iter; left time: 717.2673s
	iters: 200, epoch: 16 | loss: 3.5517242
	speed: 0.0294s/iter; left time: 655.4506s
Epoch: 16 cost time: 8.104806900024414
Epoch: 16, Steps: 265 Train Loss: 3.5541 (Forecasting Loss:0.2082 + XiCon Loss:3.3459 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1683
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.5689683
	speed: 0.0326s/iter; left time: 721.8030s
	iters: 200, epoch: 17 | loss: 3.5389736
	speed: 0.0299s/iter; left time: 659.5741s
Epoch: 17 cost time: 8.192927598953247
Epoch: 17, Steps: 265 Train Loss: 3.5541 (Forecasting Loss:0.2082 + XiCon Loss:3.3459 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.5556049
	speed: 0.0316s/iter; left time: 690.9870s
	iters: 200, epoch: 18 | loss: 3.5482273
	speed: 0.0294s/iter; left time: 640.6749s
Epoch: 18 cost time: 8.023881673812866
Epoch: 18, Steps: 265 Train Loss: 3.5541 (Forecasting Loss:0.2082 + XiCon Loss:3.3460 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1683
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.5866046
	speed: 0.0313s/iter; left time: 677.1156s
	iters: 200, epoch: 19 | loss: 3.5626354
	speed: 0.0297s/iter; left time: 639.8024s
Epoch: 19 cost time: 7.9530556201934814
Epoch: 19, Steps: 265 Train Loss: 3.5542 (Forecasting Loss:0.2081 + XiCon Loss:3.3461 x Lambda(1.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1683
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.5416603
	speed: 0.0317s/iter; left time: 677.7888s
	iters: 200, epoch: 20 | loss: 3.5496032
	speed: 0.0314s/iter; left time: 667.8982s
Epoch: 20 cost time: 8.423864126205444
Epoch: 20, Steps: 265 Train Loss: 3.5538 (Forecasting Loss:0.2082 + XiCon Loss:3.3456 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.5512378
	speed: 0.0325s/iter; left time: 685.3670s
	iters: 200, epoch: 21 | loss: 3.5500288
	speed: 0.0297s/iter; left time: 622.8168s
Epoch: 21 cost time: 8.22834300994873
Epoch: 21, Steps: 265 Train Loss: 3.5540 (Forecasting Loss:0.2083 + XiCon Loss:3.3458 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1683
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.5332787
	speed: 0.0316s/iter; left time: 659.1071s
	iters: 200, epoch: 22 | loss: 3.5275147
	speed: 0.0304s/iter; left time: 630.5091s
Epoch: 22 cost time: 8.075475931167603
Epoch: 22, Steps: 265 Train Loss: 3.5546 (Forecasting Loss:0.2083 + XiCon Loss:3.3463 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0986042395234108, mae:0.23808926343917847, mape:0.5694072842597961, mspe:11.613960266113281 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.1510
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.9058809
	speed: 0.0323s/iter; left time: 853.4785s
	iters: 200, epoch: 1 | loss: 3.9117355
	speed: 0.0299s/iter; left time: 787.6690s
Epoch: 1 cost time: 8.253959655761719
Epoch: 1, Steps: 265 Train Loss: 3.8938 (Forecasting Loss:0.3567 + XiCon Loss:3.5371 x Lambda(1.0)), Vali MSE Loss: 0.3406 Test MSE Loss: 0.2831
Validation loss decreased (inf --> 0.340608).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.7148385
	speed: 0.0316s/iter; left time: 826.3541s
	iters: 200, epoch: 2 | loss: 3.6429205
	speed: 0.0292s/iter; left time: 760.3024s
Epoch: 2 cost time: 8.037506341934204
Epoch: 2, Steps: 265 Train Loss: 3.7055 (Forecasting Loss:0.2426 + XiCon Loss:3.4629 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1734
Validation loss decreased (0.340608 --> 0.219445).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5859346
	speed: 0.0322s/iter; left time: 832.5278s
	iters: 200, epoch: 3 | loss: 3.5339401
	speed: 0.0297s/iter; left time: 765.8554s
Epoch: 3 cost time: 8.244918584823608
Epoch: 3, Steps: 265 Train Loss: 3.5698 (Forecasting Loss:0.2142 + XiCon Loss:3.3557 x Lambda(1.0)), Vali MSE Loss: 0.2155 Test MSE Loss: 0.1699
Validation loss decreased (0.219445 --> 0.215452).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5588903
	speed: 0.0320s/iter; left time: 818.2588s
	iters: 200, epoch: 4 | loss: 3.5509081
	speed: 0.0285s/iter; left time: 728.0831s
Epoch: 4 cost time: 8.021759510040283
Epoch: 4, Steps: 265 Train Loss: 3.5351 (Forecasting Loss:0.2115 + XiCon Loss:3.3236 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.1694
Validation loss decreased (0.215452 --> 0.214952).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5471594
	speed: 0.0318s/iter; left time: 804.7489s
	iters: 200, epoch: 5 | loss: 3.5370178
	speed: 0.0296s/iter; left time: 745.9931s
Epoch: 5 cost time: 8.040612936019897
Epoch: 5, Steps: 265 Train Loss: 3.5211 (Forecasting Loss:0.2103 + XiCon Loss:3.3108 x Lambda(1.0)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.1687
Validation loss decreased (0.214952 --> 0.213946).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5310595
	speed: 0.0323s/iter; left time: 810.3590s
	iters: 200, epoch: 6 | loss: 3.5068974
	speed: 0.0306s/iter; left time: 763.9478s
Epoch: 6 cost time: 8.283626794815063
Epoch: 6, Steps: 265 Train Loss: 3.5128 (Forecasting Loss:0.2098 + XiCon Loss:3.3030 x Lambda(1.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1685
Validation loss decreased (0.213946 --> 0.213671).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5189795
	speed: 0.0323s/iter; left time: 801.0709s
	iters: 200, epoch: 7 | loss: 3.5155523
	speed: 0.0299s/iter; left time: 737.8526s
Epoch: 7 cost time: 8.176359176635742
Epoch: 7, Steps: 265 Train Loss: 3.5094 (Forecasting Loss:0.2096 + XiCon Loss:3.2998 x Lambda(1.0)), Vali MSE Loss: 0.2137 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5267131
	speed: 0.0325s/iter; left time: 798.7347s
	iters: 200, epoch: 8 | loss: 3.5255461
	speed: 0.0293s/iter; left time: 716.8495s
Epoch: 8 cost time: 8.089428186416626
Epoch: 8, Steps: 265 Train Loss: 3.5075 (Forecasting Loss:0.2092 + XiCon Loss:3.2983 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
Validation loss decreased (0.213671 --> 0.213534).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.5102086
	speed: 0.0317s/iter; left time: 769.9548s
	iters: 200, epoch: 9 | loss: 3.4971170
	speed: 0.0295s/iter; left time: 714.0390s
Epoch: 9 cost time: 8.048408269882202
Epoch: 9, Steps: 265 Train Loss: 3.5078 (Forecasting Loss:0.2093 + XiCon Loss:3.2985 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1683
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4957480
	speed: 0.0318s/iter; left time: 764.4267s
	iters: 200, epoch: 10 | loss: 3.4956911
	speed: 0.0292s/iter; left time: 699.2366s
Epoch: 10 cost time: 8.006355285644531
Epoch: 10, Steps: 265 Train Loss: 3.5065 (Forecasting Loss:0.2093 + XiCon Loss:3.2972 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1683
Validation loss decreased (0.213534 --> 0.213461).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.4742224
	speed: 0.0313s/iter; left time: 743.4508s
	iters: 200, epoch: 11 | loss: 3.5021594
	speed: 0.0306s/iter; left time: 723.9486s
Epoch: 11 cost time: 8.199183464050293
Epoch: 11, Steps: 265 Train Loss: 3.5067 (Forecasting Loss:0.2092 + XiCon Loss:3.2974 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
Validation loss decreased (0.213461 --> 0.213380).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5141239
	speed: 0.0324s/iter; left time: 760.6886s
	iters: 200, epoch: 12 | loss: 3.4787803
	speed: 0.0291s/iter; left time: 681.5337s
Epoch: 12 cost time: 8.132174253463745
Epoch: 12, Steps: 265 Train Loss: 3.5072 (Forecasting Loss:0.2091 + XiCon Loss:3.2981 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.4955790
	speed: 0.0311s/iter; left time: 722.2104s
	iters: 200, epoch: 13 | loss: 3.4958279
	speed: 0.0300s/iter; left time: 692.9886s
Epoch: 13 cost time: 8.031742811203003
Epoch: 13, Steps: 265 Train Loss: 3.5065 (Forecasting Loss:0.2091 + XiCon Loss:3.2973 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.4959021
	speed: 0.0321s/iter; left time: 736.8228s
	iters: 200, epoch: 14 | loss: 3.4892619
	speed: 0.0296s/iter; left time: 675.4196s
Epoch: 14 cost time: 8.106777667999268
Epoch: 14, Steps: 265 Train Loss: 3.5058 (Forecasting Loss:0.2093 + XiCon Loss:3.2965 x Lambda(1.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1682
Validation loss decreased (0.213380 --> 0.213205).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4894180
	speed: 0.0312s/iter; left time: 707.7458s
	iters: 200, epoch: 15 | loss: 3.5020630
	speed: 0.0297s/iter; left time: 671.9052s
Epoch: 15 cost time: 7.964349031448364
Epoch: 15, Steps: 265 Train Loss: 3.5059 (Forecasting Loss:0.2092 + XiCon Loss:3.2966 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.4808517
	speed: 0.0313s/iter; left time: 701.4753s
	iters: 200, epoch: 16 | loss: 3.5235796
	speed: 0.0308s/iter; left time: 688.2574s
Epoch: 16 cost time: 8.271411180496216
Epoch: 16, Steps: 265 Train Loss: 3.5066 (Forecasting Loss:0.2092 + XiCon Loss:3.2975 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1682
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.4965899
	speed: 0.0317s/iter; left time: 702.8955s
	iters: 200, epoch: 17 | loss: 3.4959538
	speed: 0.0293s/iter; left time: 646.6853s
Epoch: 17 cost time: 7.98667573928833
Epoch: 17, Steps: 265 Train Loss: 3.5065 (Forecasting Loss:0.2092 + XiCon Loss:3.2973 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.5035315
	speed: 0.0324s/iter; left time: 708.5045s
	iters: 200, epoch: 18 | loss: 3.5004842
	speed: 0.0291s/iter; left time: 634.0885s
Epoch: 18 cost time: 8.152602910995483
Epoch: 18, Steps: 265 Train Loss: 3.5056 (Forecasting Loss:0.2092 + XiCon Loss:3.2965 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.4807441
	speed: 0.0315s/iter; left time: 680.9787s
	iters: 200, epoch: 19 | loss: 3.5122044
	speed: 0.0293s/iter; left time: 631.5336s
Epoch: 19 cost time: 8.067426919937134
Epoch: 19, Steps: 265 Train Loss: 3.5064 (Forecasting Loss:0.2092 + XiCon Loss:3.2973 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.4914591
	speed: 0.0315s/iter; left time: 672.8499s
	iters: 200, epoch: 20 | loss: 3.4832296
	speed: 0.0300s/iter; left time: 638.5944s
Epoch: 20 cost time: 8.157349109649658
Epoch: 20, Steps: 265 Train Loss: 3.5067 (Forecasting Loss:0.2093 + XiCon Loss:3.2974 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1682
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.4818997
	speed: 0.0319s/iter; left time: 672.4511s
	iters: 200, epoch: 21 | loss: 3.5095813
	speed: 0.0300s/iter; left time: 629.4377s
Epoch: 21 cost time: 8.105693340301514
Epoch: 21, Steps: 265 Train Loss: 3.5071 (Forecasting Loss:0.2093 + XiCon Loss:3.2978 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1682
Validation loss decreased (0.213205 --> 0.213122).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.5341868
	speed: 0.0314s/iter; left time: 655.2159s
	iters: 200, epoch: 22 | loss: 3.5130236
	speed: 0.0290s/iter; left time: 601.8998s
Epoch: 22 cost time: 7.956418514251709
Epoch: 22, Steps: 265 Train Loss: 3.5061 (Forecasting Loss:0.2092 + XiCon Loss:3.2969 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1682
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.4959962
	speed: 0.0322s/iter; left time: 661.9842s
	iters: 200, epoch: 23 | loss: 3.4966917
	speed: 0.0296s/iter; left time: 605.4114s
Epoch: 23 cost time: 8.115132570266724
Epoch: 23, Steps: 265 Train Loss: 3.5071 (Forecasting Loss:0.2092 + XiCon Loss:3.2979 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1682
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.4943075
	speed: 0.0320s/iter; left time: 650.6054s
	iters: 200, epoch: 24 | loss: 3.5228245
	speed: 0.0303s/iter; left time: 611.8066s
Epoch: 24 cost time: 8.171319961547852
Epoch: 24, Steps: 265 Train Loss: 3.5065 (Forecasting Loss:0.2092 + XiCon Loss:3.2972 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1682
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.5168507
	speed: 0.0317s/iter; left time: 636.0607s
	iters: 200, epoch: 25 | loss: 3.5428979
	speed: 0.0295s/iter; left time: 587.8611s
Epoch: 25 cost time: 8.119598150253296
Epoch: 25, Steps: 265 Train Loss: 3.5063 (Forecasting Loss:0.2092 + XiCon Loss:3.2971 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.5302083
	speed: 0.0317s/iter; left time: 627.2706s
	iters: 200, epoch: 26 | loss: 3.4985228
	speed: 0.0308s/iter; left time: 606.8685s
Epoch: 26 cost time: 8.295780420303345
Epoch: 26, Steps: 265 Train Loss: 3.5065 (Forecasting Loss:0.2092 + XiCon Loss:3.2973 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1682
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.5052347
	speed: 0.0312s/iter; left time: 609.2478s
	iters: 200, epoch: 27 | loss: 3.5054193
	speed: 0.0290s/iter; left time: 561.9707s
Epoch: 27 cost time: 7.995939016342163
Epoch: 27, Steps: 265 Train Loss: 3.5062 (Forecasting Loss:0.2091 + XiCon Loss:3.2971 x Lambda(1.0)), Vali MSE Loss: 0.2133 Test MSE Loss: 0.1682
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.5195982
	speed: 0.0317s/iter; left time: 610.9196s
	iters: 200, epoch: 28 | loss: 3.4926088
	speed: 0.0289s/iter; left time: 553.2069s
Epoch: 28 cost time: 8.04542875289917
Epoch: 28, Steps: 265 Train Loss: 3.5064 (Forecasting Loss:0.2091 + XiCon Loss:3.2973 x Lambda(1.0)), Vali MSE Loss: 0.2134 Test MSE Loss: 0.1682
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.4961519
	speed: 0.0315s/iter; left time: 598.2761s
	iters: 200, epoch: 29 | loss: 3.4844494
	speed: 0.0300s/iter; left time: 567.2773s
Epoch: 29 cost time: 8.076133489608765
Epoch: 29, Steps: 265 Train Loss: 3.5065 (Forecasting Loss:0.2093 + XiCon Loss:3.2972 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1682
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.5197625
	speed: 0.0315s/iter; left time: 588.8920s
	iters: 200, epoch: 30 | loss: 3.5062640
	speed: 0.0296s/iter; left time: 550.9977s
Epoch: 30 cost time: 8.097199201583862
Epoch: 30, Steps: 265 Train Loss: 3.5062 (Forecasting Loss:0.2092 + XiCon Loss:3.2970 x Lambda(1.0)), Vali MSE Loss: 0.2135 Test MSE Loss: 0.1682
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 3.4843068
	speed: 0.0318s/iter; left time: 586.4969s
	iters: 200, epoch: 31 | loss: 3.4950709
	speed: 0.0303s/iter; left time: 555.7158s
Epoch: 31 cost time: 8.259696245193481
Epoch: 31, Steps: 265 Train Loss: 3.5067 (Forecasting Loss:0.2092 + XiCon Loss:3.2975 x Lambda(1.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1682
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09841430187225342, mae:0.23805876076221466, mape:0.5668953061103821, mspe:11.526318550109863 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5191
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.9208837
	speed: 0.0318s/iter; left time: 839.8130s
	iters: 200, epoch: 1 | loss: 3.9001787
	speed: 0.0293s/iter; left time: 771.1510s
Epoch: 1 cost time: 8.08278775215149
Epoch: 1, Steps: 265 Train Loss: 3.8933 (Forecasting Loss:0.3585 + XiCon Loss:3.5348 x Lambda(1.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.2813
Validation loss decreased (inf --> 0.338533).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.7242429
	speed: 0.0326s/iter; left time: 852.2022s
	iters: 200, epoch: 2 | loss: 3.6147506
	speed: 0.0304s/iter; left time: 792.3161s
Epoch: 2 cost time: 8.34426474571228
Epoch: 2, Steps: 265 Train Loss: 3.6922 (Forecasting Loss:0.2430 + XiCon Loss:3.4491 x Lambda(1.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.1728
Validation loss decreased (0.338533 --> 0.219940).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5641897
	speed: 0.0321s/iter; left time: 831.6856s
	iters: 200, epoch: 3 | loss: 3.5680041
	speed: 0.0307s/iter; left time: 792.0854s
Epoch: 3 cost time: 8.252603769302368
Epoch: 3, Steps: 265 Train Loss: 3.5642 (Forecasting Loss:0.2144 + XiCon Loss:3.3498 x Lambda(1.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1699
Validation loss decreased (0.219940 --> 0.214339).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5272918
	speed: 0.0317s/iter; left time: 810.9400s
	iters: 200, epoch: 4 | loss: 3.5316789
	speed: 0.0291s/iter; left time: 741.4886s
Epoch: 4 cost time: 7.9895031452178955
Epoch: 4, Steps: 265 Train Loss: 3.5409 (Forecasting Loss:0.2107 + XiCon Loss:3.3302 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1691
Validation loss decreased (0.214339 --> 0.212856).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5434499
	speed: 0.0306s/iter; left time: 775.9176s
	iters: 200, epoch: 5 | loss: 3.5490730
	speed: 0.0297s/iter; left time: 750.3882s
Epoch: 5 cost time: 7.988446235656738
Epoch: 5, Steps: 265 Train Loss: 3.5321 (Forecasting Loss:0.2092 + XiCon Loss:3.3229 x Lambda(1.0)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1690
Validation loss decreased (0.212856 --> 0.212168).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5531356
	speed: 0.0313s/iter; left time: 784.3955s
	iters: 200, epoch: 6 | loss: 3.5666776
	speed: 0.0294s/iter; left time: 733.4346s
Epoch: 6 cost time: 7.9644341468811035
Epoch: 6, Steps: 265 Train Loss: 3.5282 (Forecasting Loss:0.2084 + XiCon Loss:3.3198 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1686
Validation loss decreased (0.212168 --> 0.211193).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5459452
	speed: 0.0325s/iter; left time: 806.0802s
	iters: 200, epoch: 7 | loss: 3.5429688
	speed: 0.0297s/iter; left time: 734.0081s
Epoch: 7 cost time: 8.123685836791992
Epoch: 7, Steps: 265 Train Loss: 3.5270 (Forecasting Loss:0.2081 + XiCon Loss:3.3189 x Lambda(1.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1685
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5422647
	speed: 0.0311s/iter; left time: 762.8605s
	iters: 200, epoch: 8 | loss: 3.4896038
	speed: 0.0311s/iter; left time: 760.3123s
Epoch: 8 cost time: 8.226498126983643
Epoch: 8, Steps: 265 Train Loss: 3.5261 (Forecasting Loss:0.2081 + XiCon Loss:3.3180 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
Validation loss decreased (0.211193 --> 0.211015).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.5274024
	speed: 0.0322s/iter; left time: 782.0181s
	iters: 200, epoch: 9 | loss: 3.5072188
	speed: 0.0303s/iter; left time: 733.5450s
Epoch: 9 cost time: 8.244723558425903
Epoch: 9, Steps: 265 Train Loss: 3.5256 (Forecasting Loss:0.2078 + XiCon Loss:3.3178 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.5184712
	speed: 0.0317s/iter; left time: 761.2725s
	iters: 200, epoch: 10 | loss: 3.5397692
	speed: 0.0300s/iter; left time: 716.4799s
Epoch: 10 cost time: 8.077474117279053
Epoch: 10, Steps: 265 Train Loss: 3.5248 (Forecasting Loss:0.2078 + XiCon Loss:3.3170 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1684
Validation loss decreased (0.211015 --> 0.210917).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.5626359
	speed: 0.0322s/iter; left time: 763.6050s
	iters: 200, epoch: 11 | loss: 3.5068443
	speed: 0.0299s/iter; left time: 708.3248s
Epoch: 11 cost time: 8.184522867202759
Epoch: 11, Steps: 265 Train Loss: 3.5252 (Forecasting Loss:0.2078 + XiCon Loss:3.3174 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5279162
	speed: 0.0323s/iter; left time: 757.4638s
	iters: 200, epoch: 12 | loss: 3.5625417
	speed: 0.0287s/iter; left time: 670.3152s
Epoch: 12 cost time: 8.082404613494873
Epoch: 12, Steps: 265 Train Loss: 3.5249 (Forecasting Loss:0.2078 + XiCon Loss:3.3171 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.5247767
	speed: 0.0320s/iter; left time: 744.1755s
	iters: 200, epoch: 13 | loss: 3.5484478
	speed: 0.0305s/iter; left time: 706.0206s
Epoch: 13 cost time: 8.281655073165894
Epoch: 13, Steps: 265 Train Loss: 3.5244 (Forecasting Loss:0.2079 + XiCon Loss:3.3164 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.5178471
	speed: 0.0314s/iter; left time: 721.1942s
	iters: 200, epoch: 14 | loss: 3.5162172
	speed: 0.0294s/iter; left time: 670.8993s
Epoch: 14 cost time: 7.990788698196411
Epoch: 14, Steps: 265 Train Loss: 3.5240 (Forecasting Loss:0.2078 + XiCon Loss:3.3162 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1684
Validation loss decreased (0.210917 --> 0.210878).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.5056119
	speed: 0.0316s/iter; left time: 716.8113s
	iters: 200, epoch: 15 | loss: 3.5319576
	speed: 0.0297s/iter; left time: 670.9132s
Epoch: 15 cost time: 8.048545598983765
Epoch: 15, Steps: 265 Train Loss: 3.5253 (Forecasting Loss:0.2078 + XiCon Loss:3.3175 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.5198977
	speed: 0.0319s/iter; left time: 716.4609s
	iters: 200, epoch: 16 | loss: 3.5072634
	speed: 0.0297s/iter; left time: 663.6199s
Epoch: 16 cost time: 8.09475302696228
Epoch: 16, Steps: 265 Train Loss: 3.5247 (Forecasting Loss:0.2078 + XiCon Loss:3.3169 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.5024247
	speed: 0.0322s/iter; left time: 713.5164s
	iters: 200, epoch: 17 | loss: 3.5471828
	speed: 0.0296s/iter; left time: 653.0275s
Epoch: 17 cost time: 8.106239557266235
Epoch: 17, Steps: 265 Train Loss: 3.5250 (Forecasting Loss:0.2078 + XiCon Loss:3.3173 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1684
Validation loss decreased (0.210878 --> 0.210834).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.5333936
	speed: 0.0315s/iter; left time: 689.9242s
	iters: 200, epoch: 18 | loss: 3.4898813
	speed: 0.0309s/iter; left time: 672.5001s
Epoch: 18 cost time: 8.228264093399048
Epoch: 18, Steps: 265 Train Loss: 3.5242 (Forecasting Loss:0.2078 + XiCon Loss:3.3163 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.5362222
	speed: 0.0324s/iter; left time: 700.9881s
	iters: 200, epoch: 19 | loss: 3.5284629
	speed: 0.0290s/iter; left time: 624.4508s
Epoch: 19 cost time: 8.076202154159546
Epoch: 19, Steps: 265 Train Loss: 3.5245 (Forecasting Loss:0.2077 + XiCon Loss:3.3168 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.5183001
	speed: 0.0324s/iter; left time: 693.0687s
	iters: 200, epoch: 20 | loss: 3.5167859
	speed: 0.0292s/iter; left time: 620.0028s
Epoch: 20 cost time: 8.115668058395386
Epoch: 20, Steps: 265 Train Loss: 3.5248 (Forecasting Loss:0.2078 + XiCon Loss:3.3170 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1684
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.5235102
	speed: 0.0324s/iter; left time: 682.6495s
	iters: 200, epoch: 21 | loss: 3.5331209
	speed: 0.0298s/iter; left time: 625.8113s
Epoch: 21 cost time: 8.123282432556152
Epoch: 21, Steps: 265 Train Loss: 3.5244 (Forecasting Loss:0.2078 + XiCon Loss:3.3166 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1684
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.5128119
	speed: 0.0329s/iter; left time: 686.2796s
	iters: 200, epoch: 22 | loss: 3.5283890
	speed: 0.0294s/iter; left time: 610.3648s
Epoch: 22 cost time: 8.102869033813477
Epoch: 22, Steps: 265 Train Loss: 3.5246 (Forecasting Loss:0.2078 + XiCon Loss:3.3168 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.5149877
	speed: 0.0325s/iter; left time: 669.4486s
	iters: 200, epoch: 23 | loss: 3.5333896
	speed: 0.0311s/iter; left time: 637.2085s
Epoch: 23 cost time: 8.362125158309937
Epoch: 23, Steps: 265 Train Loss: 3.5247 (Forecasting Loss:0.2077 + XiCon Loss:3.3170 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1684
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.5435963
	speed: 0.0309s/iter; left time: 628.4007s
	iters: 200, epoch: 24 | loss: 3.4999807
	speed: 0.0298s/iter; left time: 601.7985s
Epoch: 24 cost time: 7.9915549755096436
Epoch: 24, Steps: 265 Train Loss: 3.5243 (Forecasting Loss:0.2078 + XiCon Loss:3.3165 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.5303512
	speed: 0.0315s/iter; left time: 631.4976s
	iters: 200, epoch: 25 | loss: 3.5233037
	speed: 0.0300s/iter; left time: 598.9632s
Epoch: 25 cost time: 8.049819469451904
Epoch: 25, Steps: 265 Train Loss: 3.5239 (Forecasting Loss:0.2077 + XiCon Loss:3.3161 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.5264831
	speed: 0.0309s/iter; left time: 611.3763s
	iters: 200, epoch: 26 | loss: 3.5489485
	speed: 0.0295s/iter; left time: 580.7262s
Epoch: 26 cost time: 7.952958106994629
Epoch: 26, Steps: 265 Train Loss: 3.5254 (Forecasting Loss:0.2078 + XiCon Loss:3.3176 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1684
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.5364995
	speed: 0.0313s/iter; left time: 610.7682s
	iters: 200, epoch: 27 | loss: 3.5500383
	speed: 0.0303s/iter; left time: 587.8311s
Epoch: 27 cost time: 8.092170000076294
Epoch: 27, Steps: 265 Train Loss: 3.5244 (Forecasting Loss:0.2077 + XiCon Loss:3.3167 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09804558753967285, mae:0.23871831595897675, mape:0.5699353218078613, mspe:11.6978759765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.8693
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.9081647
	speed: 0.0341s/iter; left time: 901.0416s
	iters: 200, epoch: 1 | loss: 3.8433311
	speed: 0.0320s/iter; left time: 841.1671s
Epoch: 1 cost time: 8.640217781066895
Epoch: 1, Steps: 265 Train Loss: 3.8967 (Forecasting Loss:0.3585 + XiCon Loss:3.5382 x Lambda(1.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2814
Validation loss decreased (inf --> 0.336813).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.7131782
	speed: 0.0318s/iter; left time: 830.0995s
	iters: 200, epoch: 2 | loss: 3.6304963
	speed: 0.0286s/iter; left time: 744.8030s
Epoch: 2 cost time: 7.9748640060424805
Epoch: 2, Steps: 265 Train Loss: 3.6990 (Forecasting Loss:0.2414 + XiCon Loss:3.4576 x Lambda(1.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.1745
Validation loss decreased (0.336813 --> 0.218655).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.6163690
	speed: 0.0315s/iter; left time: 815.7104s
	iters: 200, epoch: 3 | loss: 3.5381730
	speed: 0.0296s/iter; left time: 763.7589s
Epoch: 3 cost time: 8.100534439086914
Epoch: 3, Steps: 265 Train Loss: 3.5730 (Forecasting Loss:0.2136 + XiCon Loss:3.3595 x Lambda(1.0)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1715
Validation loss decreased (0.218655 --> 0.213804).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5231493
	speed: 0.0321s/iter; left time: 822.7381s
	iters: 200, epoch: 4 | loss: 3.5056992
	speed: 0.0293s/iter; left time: 748.4719s
Epoch: 4 cost time: 7.993896007537842
Epoch: 4, Steps: 265 Train Loss: 3.5466 (Forecasting Loss:0.2092 + XiCon Loss:3.3374 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1707
Validation loss decreased (0.213804 --> 0.212572).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5489619
	speed: 0.0317s/iter; left time: 802.3390s
	iters: 200, epoch: 5 | loss: 3.5110612
	speed: 0.0303s/iter; left time: 764.9794s
Epoch: 5 cost time: 8.118337869644165
Epoch: 5, Steps: 265 Train Loss: 3.5385 (Forecasting Loss:0.2077 + XiCon Loss:3.3308 x Lambda(1.0)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1703
Validation loss decreased (0.212572 --> 0.212239).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5365756
	speed: 0.0308s/iter; left time: 773.4338s
	iters: 200, epoch: 6 | loss: 3.5146527
	speed: 0.0289s/iter; left time: 723.0538s
Epoch: 6 cost time: 7.843191146850586
Epoch: 6, Steps: 265 Train Loss: 3.5342 (Forecasting Loss:0.2071 + XiCon Loss:3.3271 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1701
Validation loss decreased (0.212239 --> 0.211927).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5171778
	speed: 0.0309s/iter; left time: 766.1894s
	iters: 200, epoch: 7 | loss: 3.5523922
	speed: 0.0302s/iter; left time: 747.2495s
Epoch: 7 cost time: 8.068285703659058
Epoch: 7, Steps: 265 Train Loss: 3.5332 (Forecasting Loss:0.2068 + XiCon Loss:3.3264 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1699
Validation loss decreased (0.211927 --> 0.211635).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5350182
	speed: 0.0315s/iter; left time: 774.1137s
	iters: 200, epoch: 8 | loss: 3.5406625
	speed: 0.0295s/iter; left time: 721.3077s
Epoch: 8 cost time: 8.059884309768677
Epoch: 8, Steps: 265 Train Loss: 3.5327 (Forecasting Loss:0.2066 + XiCon Loss:3.3261 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1699
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.5434659
	speed: 0.0307s/iter; left time: 746.2744s
	iters: 200, epoch: 9 | loss: 3.5154929
	speed: 0.0290s/iter; left time: 701.1236s
Epoch: 9 cost time: 7.85966420173645
Epoch: 9, Steps: 265 Train Loss: 3.5325 (Forecasting Loss:0.2065 + XiCon Loss:3.3259 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.5015666
	speed: 0.0314s/iter; left time: 753.1467s
	iters: 200, epoch: 10 | loss: 3.5542831
	speed: 0.0295s/iter; left time: 704.8867s
Epoch: 10 cost time: 8.050158739089966
Epoch: 10, Steps: 265 Train Loss: 3.5317 (Forecasting Loss:0.2066 + XiCon Loss:3.3251 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1699
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.5308635
	speed: 0.0318s/iter; left time: 755.3811s
	iters: 200, epoch: 11 | loss: 3.5341682
	speed: 0.0300s/iter; left time: 709.5211s
Epoch: 11 cost time: 8.127394914627075
Epoch: 11, Steps: 265 Train Loss: 3.5317 (Forecasting Loss:0.2066 + XiCon Loss:3.3252 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1699
Validation loss decreased (0.211635 --> 0.211579).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5322337
	speed: 0.0315s/iter; left time: 740.1237s
	iters: 200, epoch: 12 | loss: 3.5362992
	speed: 0.0291s/iter; left time: 680.0938s
Epoch: 12 cost time: 7.99402928352356
Epoch: 12, Steps: 265 Train Loss: 3.5314 (Forecasting Loss:0.2065 + XiCon Loss:3.3249 x Lambda(1.0)), Vali MSE Loss: 0.2119 Test MSE Loss: 0.1698
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.5086348
	speed: 0.0317s/iter; left time: 735.2143s
	iters: 200, epoch: 13 | loss: 3.5387571
	speed: 0.0296s/iter; left time: 684.2819s
Epoch: 13 cost time: 8.133527755737305
Epoch: 13, Steps: 265 Train Loss: 3.5310 (Forecasting Loss:0.2066 + XiCon Loss:3.3244 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1698
Validation loss decreased (0.211579 --> 0.211476).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.5491529
	speed: 0.0316s/iter; left time: 725.1877s
	iters: 200, epoch: 14 | loss: 3.5228810
	speed: 0.0298s/iter; left time: 681.9224s
Epoch: 14 cost time: 8.180526733398438
Epoch: 14, Steps: 265 Train Loss: 3.5309 (Forecasting Loss:0.2065 + XiCon Loss:3.3244 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1698
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.5243521
	speed: 0.0320s/iter; left time: 725.0182s
	iters: 200, epoch: 15 | loss: 3.5427055
	speed: 0.0297s/iter; left time: 670.9099s
Epoch: 15 cost time: 8.134318351745605
Epoch: 15, Steps: 265 Train Loss: 3.5320 (Forecasting Loss:0.2066 + XiCon Loss:3.3254 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1698
Validation loss decreased (0.211476 --> 0.211137).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.5319221
	speed: 0.0319s/iter; left time: 715.1344s
	iters: 200, epoch: 16 | loss: 3.5202508
	speed: 0.0298s/iter; left time: 665.0318s
Epoch: 16 cost time: 8.110881805419922
Epoch: 16, Steps: 265 Train Loss: 3.5314 (Forecasting Loss:0.2064 + XiCon Loss:3.3250 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1698
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.5237677
	speed: 0.0317s/iter; left time: 702.6132s
	iters: 200, epoch: 17 | loss: 3.5170419
	speed: 0.0295s/iter; left time: 649.7094s
Epoch: 17 cost time: 8.035824537277222
Epoch: 17, Steps: 265 Train Loss: 3.5309 (Forecasting Loss:0.2066 + XiCon Loss:3.3242 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1698
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.5281572
	speed: 0.0321s/iter; left time: 703.3523s
	iters: 200, epoch: 18 | loss: 3.5175545
	speed: 0.0299s/iter; left time: 652.5971s
Epoch: 18 cost time: 8.153207063674927
Epoch: 18, Steps: 265 Train Loss: 3.5309 (Forecasting Loss:0.2066 + XiCon Loss:3.3243 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1698
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.5247908
	speed: 0.0309s/iter; left time: 669.2453s
	iters: 200, epoch: 19 | loss: 3.5330126
	speed: 0.0291s/iter; left time: 626.2421s
Epoch: 19 cost time: 7.9089577198028564
Epoch: 19, Steps: 265 Train Loss: 3.5318 (Forecasting Loss:0.2065 + XiCon Loss:3.3253 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.5351636
	speed: 0.0313s/iter; left time: 667.9185s
	iters: 200, epoch: 20 | loss: 3.5325699
	speed: 0.0309s/iter; left time: 657.8876s
Epoch: 20 cost time: 8.193453788757324
Epoch: 20, Steps: 265 Train Loss: 3.5319 (Forecasting Loss:0.2064 + XiCon Loss:3.3255 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.5208755
	speed: 0.0311s/iter; left time: 656.0617s
	iters: 200, epoch: 21 | loss: 3.5292521
	speed: 0.0298s/iter; left time: 626.8792s
Epoch: 21 cost time: 8.018148422241211
Epoch: 21, Steps: 265 Train Loss: 3.5310 (Forecasting Loss:0.2066 + XiCon Loss:3.3244 x Lambda(1.0)), Vali MSE Loss: 0.2117 Test MSE Loss: 0.1698
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.5477581
	speed: 0.0317s/iter; left time: 661.5223s
	iters: 200, epoch: 22 | loss: 3.5379729
	speed: 0.0295s/iter; left time: 611.3319s
Epoch: 22 cost time: 8.11229920387268
Epoch: 22, Steps: 265 Train Loss: 3.5313 (Forecasting Loss:0.2065 + XiCon Loss:3.3249 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1698
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.5543237
	speed: 0.0321s/iter; left time: 659.4916s
	iters: 200, epoch: 23 | loss: 3.5240805
	speed: 0.0290s/iter; left time: 594.5425s
Epoch: 23 cost time: 8.057742834091187
Epoch: 23, Steps: 265 Train Loss: 3.5318 (Forecasting Loss:0.2064 + XiCon Loss:3.3254 x Lambda(1.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1698
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.5091414
	speed: 0.0322s/iter; left time: 654.7877s
	iters: 200, epoch: 24 | loss: 3.5389810
	speed: 0.0296s/iter; left time: 597.4984s
Epoch: 24 cost time: 8.079602241516113
Epoch: 24, Steps: 265 Train Loss: 3.5316 (Forecasting Loss:0.2066 + XiCon Loss:3.3250 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1698
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.5435152
	speed: 0.0316s/iter; left time: 633.6269s
	iters: 200, epoch: 25 | loss: 3.5235689
	speed: 0.0304s/iter; left time: 606.3392s
Epoch: 25 cost time: 8.263336420059204
Epoch: 25, Steps: 265 Train Loss: 3.5310 (Forecasting Loss:0.2064 + XiCon Loss:3.3246 x Lambda(1.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1698
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09936590492725372, mae:0.2403237521648407, mape:0.5811194777488708, mspe:12.507009506225586 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0987+-0.00064, MAE:0.2390+-0.00130, MAPE:0.5713+-0.00695, MSPE:11.8344+-0.48671, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.7496
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.8823619
	speed: 0.0370s/iter; left time: 972.8773s
	iters: 200, epoch: 1 | loss: 3.8088491
	speed: 0.0319s/iter; left time: 836.1972s
Epoch: 1 cost time: 8.964115858078003
Epoch: 1, Steps: 264 Train Loss: 3.8580 (Forecasting Loss:0.3356 + XiCon Loss:3.5224 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2337
Validation loss decreased (inf --> 0.296816).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5586607
	speed: 0.0341s/iter; left time: 888.7006s
	iters: 200, epoch: 2 | loss: 3.6766636
	speed: 0.0320s/iter; left time: 829.3803s
Epoch: 2 cost time: 8.637173652648926
Epoch: 2, Steps: 264 Train Loss: 3.6321 (Forecasting Loss:0.2530 + XiCon Loss:3.3791 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.1941
Validation loss decreased (0.296816 --> 0.250430).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6260424
	speed: 0.0342s/iter; left time: 882.0705s
	iters: 200, epoch: 3 | loss: 3.5615385
	speed: 0.0328s/iter; left time: 842.5019s
Epoch: 3 cost time: 8.764248609542847
Epoch: 3, Steps: 264 Train Loss: 3.6081 (Forecasting Loss:0.2447 + XiCon Loss:3.3634 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.1927
Validation loss decreased (0.250430 --> 0.249547).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6043496
	speed: 0.0336s/iter; left time: 857.7261s
	iters: 200, epoch: 4 | loss: 3.6077471
	speed: 0.0317s/iter; left time: 804.4553s
Epoch: 4 cost time: 8.616590976715088
Epoch: 4, Steps: 264 Train Loss: 3.5817 (Forecasting Loss:0.2425 + XiCon Loss:3.3391 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1930
Validation loss decreased (0.249547 --> 0.248504).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5819356
	speed: 0.0338s/iter; left time: 854.2018s
	iters: 200, epoch: 5 | loss: 3.5108218
	speed: 0.0319s/iter; left time: 801.5266s
Epoch: 5 cost time: 8.587238073348999
Epoch: 5, Steps: 264 Train Loss: 3.5696 (Forecasting Loss:0.2414 + XiCon Loss:3.3282 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1933
Validation loss decreased (0.248504 --> 0.247677).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6037681
	speed: 0.0342s/iter; left time: 854.0402s
	iters: 200, epoch: 6 | loss: 3.5282276
	speed: 0.0322s/iter; left time: 801.3068s
Epoch: 6 cost time: 8.697879314422607
Epoch: 6, Steps: 264 Train Loss: 3.5605 (Forecasting Loss:0.2409 + XiCon Loss:3.3196 x Lambda(1.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.1933
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5655448
	speed: 0.0347s/iter; left time: 857.3814s
	iters: 200, epoch: 7 | loss: 3.5302539
	speed: 0.0319s/iter; left time: 785.9473s
Epoch: 7 cost time: 8.689627647399902
Epoch: 7, Steps: 264 Train Loss: 3.5612 (Forecasting Loss:0.2405 + XiCon Loss:3.3208 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1934
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5485861
	speed: 0.0351s/iter; left time: 857.2375s
	iters: 200, epoch: 8 | loss: 3.5104980
	speed: 0.0331s/iter; left time: 806.8910s
Epoch: 8 cost time: 8.884772777557373
Epoch: 8, Steps: 264 Train Loss: 3.5570 (Forecasting Loss:0.2404 + XiCon Loss:3.3166 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1934
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5503354
	speed: 0.0337s/iter; left time: 815.0249s
	iters: 200, epoch: 9 | loss: 3.5797465
	speed: 0.0313s/iter; left time: 754.1314s
Epoch: 9 cost time: 8.596975088119507
Epoch: 9, Steps: 264 Train Loss: 3.5603 (Forecasting Loss:0.2404 + XiCon Loss:3.3199 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1935
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6052527
	speed: 0.0341s/iter; left time: 814.7206s
	iters: 200, epoch: 10 | loss: 3.5732279
	speed: 0.0323s/iter; left time: 770.0941s
Epoch: 10 cost time: 8.755481481552124
Epoch: 10, Steps: 264 Train Loss: 3.5559 (Forecasting Loss:0.2403 + XiCon Loss:3.3156 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1935
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5784960
	speed: 0.0340s/iter; left time: 803.6016s
	iters: 200, epoch: 11 | loss: 3.5064948
	speed: 0.0316s/iter; left time: 744.1446s
Epoch: 11 cost time: 8.605190515518188
Epoch: 11, Steps: 264 Train Loss: 3.5587 (Forecasting Loss:0.2405 + XiCon Loss:3.3182 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1935
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5491056
	speed: 0.0342s/iter; left time: 801.2683s
	iters: 200, epoch: 12 | loss: 3.5187023
	speed: 0.0316s/iter; left time: 736.9806s
Epoch: 12 cost time: 8.622864723205566
Epoch: 12, Steps: 264 Train Loss: 3.5561 (Forecasting Loss:0.2400 + XiCon Loss:3.3160 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1935
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5645657
	speed: 0.0344s/iter; left time: 794.8640s
	iters: 200, epoch: 13 | loss: 3.5576358
	speed: 0.0319s/iter; left time: 734.5193s
Epoch: 13 cost time: 8.741243839263916
Epoch: 13, Steps: 264 Train Loss: 3.5567 (Forecasting Loss:0.2401 + XiCon Loss:3.3166 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1935
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6203554
	speed: 0.0345s/iter; left time: 788.3474s
	iters: 200, epoch: 14 | loss: 3.5431218
	speed: 0.0322s/iter; left time: 732.9987s
Epoch: 14 cost time: 8.693410873413086
Epoch: 14, Steps: 264 Train Loss: 3.5551 (Forecasting Loss:0.2401 + XiCon Loss:3.3150 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1935
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5412800
	speed: 0.0349s/iter; left time: 789.9208s
	iters: 200, epoch: 15 | loss: 3.5215888
	speed: 0.0320s/iter; left time: 720.2515s
Epoch: 15 cost time: 8.783997535705566
Epoch: 15, Steps: 264 Train Loss: 3.5566 (Forecasting Loss:0.2402 + XiCon Loss:3.3165 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1935
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12204848974943161, mae:0.26460206508636475, mape:0.6339389085769653, mspe:14.545797348022461 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.8316
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.8573177
	speed: 0.0367s/iter; left time: 965.8379s
	iters: 200, epoch: 1 | loss: 3.8198636
	speed: 0.0323s/iter; left time: 847.4395s
Epoch: 1 cost time: 8.964584827423096
Epoch: 1, Steps: 264 Train Loss: 3.8657 (Forecasting Loss:0.3350 + XiCon Loss:3.5307 x Lambda(1.0)), Vali MSE Loss: 0.2973 Test MSE Loss: 0.2335
Validation loss decreased (inf --> 0.297350).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6215327
	speed: 0.0341s/iter; left time: 887.1001s
	iters: 200, epoch: 2 | loss: 3.5271206
	speed: 0.0320s/iter; left time: 829.9564s
Epoch: 2 cost time: 8.66858196258545
Epoch: 2, Steps: 264 Train Loss: 3.6032 (Forecasting Loss:0.2524 + XiCon Loss:3.3508 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1951
Validation loss decreased (0.297350 --> 0.251623).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6798787
	speed: 0.0341s/iter; left time: 878.2793s
	iters: 200, epoch: 3 | loss: 3.6879201
	speed: 0.0322s/iter; left time: 826.5296s
Epoch: 3 cost time: 8.703424453735352
Epoch: 3, Steps: 264 Train Loss: 3.6042 (Forecasting Loss:0.2453 + XiCon Loss:3.3589 x Lambda(1.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1926
Validation loss decreased (0.251623 --> 0.250752).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5834205
	speed: 0.0332s/iter; left time: 846.2590s
	iters: 200, epoch: 4 | loss: 3.5514317
	speed: 0.0317s/iter; left time: 804.3136s
Epoch: 4 cost time: 8.567455530166626
Epoch: 4, Steps: 264 Train Loss: 3.6322 (Forecasting Loss:0.2438 + XiCon Loss:3.3884 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1933
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5800118
	speed: 0.0346s/iter; left time: 872.4407s
	iters: 200, epoch: 5 | loss: 3.6411698
	speed: 0.0323s/iter; left time: 812.4578s
Epoch: 5 cost time: 8.693851947784424
Epoch: 5, Steps: 264 Train Loss: 3.6258 (Forecasting Loss:0.2431 + XiCon Loss:3.3827 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1928
Validation loss decreased (0.250752 --> 0.250673).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6443403
	speed: 0.0348s/iter; left time: 868.2652s
	iters: 200, epoch: 6 | loss: 3.6806164
	speed: 0.0320s/iter; left time: 795.3671s
Epoch: 6 cost time: 8.77322006225586
Epoch: 6, Steps: 264 Train Loss: 3.6254 (Forecasting Loss:0.2429 + XiCon Loss:3.3825 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1924
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6614687
	speed: 0.0343s/iter; left time: 847.4550s
	iters: 200, epoch: 7 | loss: 3.6559374
	speed: 0.0319s/iter; left time: 785.8113s
Epoch: 7 cost time: 8.642424583435059
Epoch: 7, Steps: 264 Train Loss: 3.6213 (Forecasting Loss:0.2427 + XiCon Loss:3.3786 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1922
Validation loss decreased (0.250673 --> 0.250155).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6057484
	speed: 0.0339s/iter; left time: 829.9950s
	iters: 200, epoch: 8 | loss: 3.5447173
	speed: 0.0325s/iter; left time: 790.5405s
Epoch: 8 cost time: 8.692430019378662
Epoch: 8, Steps: 264 Train Loss: 3.6198 (Forecasting Loss:0.2424 + XiCon Loss:3.3774 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
Validation loss decreased (0.250155 --> 0.250137).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6372821
	speed: 0.0348s/iter; left time: 842.6121s
	iters: 200, epoch: 9 | loss: 3.6552792
	speed: 0.0322s/iter; left time: 774.4632s
Epoch: 9 cost time: 8.747532367706299
Epoch: 9, Steps: 264 Train Loss: 3.6206 (Forecasting Loss:0.2424 + XiCon Loss:3.3782 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
Validation loss decreased (0.250137 --> 0.249949).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5938094
	speed: 0.0341s/iter; left time: 816.3546s
	iters: 200, epoch: 10 | loss: 3.6225240
	speed: 0.0321s/iter; left time: 764.3464s
Epoch: 10 cost time: 8.680965185165405
Epoch: 10, Steps: 264 Train Loss: 3.6173 (Forecasting Loss:0.2424 + XiCon Loss:3.3750 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
Validation loss decreased (0.249949 --> 0.249935).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6726258
	speed: 0.0344s/iter; left time: 814.0343s
	iters: 200, epoch: 11 | loss: 3.6660748
	speed: 0.0325s/iter; left time: 765.3190s
Epoch: 11 cost time: 8.771950721740723
Epoch: 11, Steps: 264 Train Loss: 3.6125 (Forecasting Loss:0.2424 + XiCon Loss:3.3701 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6423049
	speed: 0.0343s/iter; left time: 803.4922s
	iters: 200, epoch: 12 | loss: 3.6008668
	speed: 0.0320s/iter; left time: 745.3055s
Epoch: 12 cost time: 8.713459730148315
Epoch: 12, Steps: 264 Train Loss: 3.6179 (Forecasting Loss:0.2425 + XiCon Loss:3.3754 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5799792
	speed: 0.0340s/iter; left time: 785.4760s
	iters: 200, epoch: 13 | loss: 3.6123173
	speed: 0.0318s/iter; left time: 733.3177s
Epoch: 13 cost time: 8.685980319976807
Epoch: 13, Steps: 264 Train Loss: 3.6164 (Forecasting Loss:0.2424 + XiCon Loss:3.3741 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5907080
	speed: 0.0341s/iter; left time: 779.0602s
	iters: 200, epoch: 14 | loss: 3.6379657
	speed: 0.0316s/iter; left time: 720.4495s
Epoch: 14 cost time: 8.645112752914429
Epoch: 14, Steps: 264 Train Loss: 3.6149 (Forecasting Loss:0.2423 + XiCon Loss:3.3726 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5759022
	speed: 0.0344s/iter; left time: 776.9853s
	iters: 200, epoch: 15 | loss: 3.5849094
	speed: 0.0319s/iter; left time: 718.9952s
Epoch: 15 cost time: 8.713252305984497
Epoch: 15, Steps: 264 Train Loss: 3.6171 (Forecasting Loss:0.2425 + XiCon Loss:3.3747 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
Validation loss decreased (0.249935 --> 0.249912).  Saving model ...
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6040759
	speed: 0.0343s/iter; left time: 765.6806s
	iters: 200, epoch: 16 | loss: 3.5889499
	speed: 0.0321s/iter; left time: 714.5551s
Epoch: 16 cost time: 8.774916648864746
Epoch: 16, Steps: 264 Train Loss: 3.6139 (Forecasting Loss:0.2422 + XiCon Loss:3.3716 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6377454
	speed: 0.0345s/iter; left time: 760.5915s
	iters: 200, epoch: 17 | loss: 3.5813751
	speed: 0.0316s/iter; left time: 694.6747s
Epoch: 17 cost time: 8.662182331085205
Epoch: 17, Steps: 264 Train Loss: 3.6170 (Forecasting Loss:0.2423 + XiCon Loss:3.3747 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6170497
	speed: 0.0348s/iter; left time: 758.9844s
	iters: 200, epoch: 18 | loss: 3.6500955
	speed: 0.0322s/iter; left time: 698.3710s
Epoch: 18 cost time: 8.7890043258667
Epoch: 18, Steps: 264 Train Loss: 3.6177 (Forecasting Loss:0.2424 + XiCon Loss:3.3753 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6357338
	speed: 0.0354s/iter; left time: 763.3178s
	iters: 200, epoch: 19 | loss: 3.6295021
	speed: 0.0320s/iter; left time: 687.3163s
Epoch: 19 cost time: 8.825786590576172
Epoch: 19, Steps: 264 Train Loss: 3.6212 (Forecasting Loss:0.2424 + XiCon Loss:3.3788 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.6348565
	speed: 0.0344s/iter; left time: 733.1886s
	iters: 200, epoch: 20 | loss: 3.6643622
	speed: 0.0323s/iter; left time: 685.0680s
Epoch: 20 cost time: 8.77187204360962
Epoch: 20, Steps: 264 Train Loss: 3.6196 (Forecasting Loss:0.2423 + XiCon Loss:3.3773 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
Validation loss decreased (0.249912 --> 0.249891).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6680264
	speed: 0.0347s/iter; left time: 728.5571s
	iters: 200, epoch: 21 | loss: 3.6639869
	speed: 0.0319s/iter; left time: 668.2847s
Epoch: 21 cost time: 8.698839902877808
Epoch: 21, Steps: 264 Train Loss: 3.6160 (Forecasting Loss:0.2424 + XiCon Loss:3.3737 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.5528886
	speed: 0.0338s/iter; left time: 702.3105s
	iters: 200, epoch: 22 | loss: 3.6193810
	speed: 0.0319s/iter; left time: 659.0563s
Epoch: 22 cost time: 8.667152643203735
Epoch: 22, Steps: 264 Train Loss: 3.6172 (Forecasting Loss:0.2423 + XiCon Loss:3.3749 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.5830262
	speed: 0.0345s/iter; left time: 707.2941s
	iters: 200, epoch: 23 | loss: 3.7085505
	speed: 0.0320s/iter; left time: 652.7620s
Epoch: 23 cost time: 8.743509769439697
Epoch: 23, Steps: 264 Train Loss: 3.6185 (Forecasting Loss:0.2424 + XiCon Loss:3.3761 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1920
Validation loss decreased (0.249891 --> 0.249847).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.5982985
	speed: 0.0341s/iter; left time: 690.1119s
	iters: 200, epoch: 24 | loss: 3.6415250
	speed: 0.0330s/iter; left time: 664.4978s
Epoch: 24 cost time: 8.769132375717163
Epoch: 24, Steps: 264 Train Loss: 3.6161 (Forecasting Loss:0.2424 + XiCon Loss:3.3738 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.5458193
	speed: 0.0347s/iter; left time: 693.2863s
	iters: 200, epoch: 25 | loss: 3.5864472
	speed: 0.0321s/iter; left time: 637.4085s
Epoch: 25 cost time: 8.749231815338135
Epoch: 25, Steps: 264 Train Loss: 3.6173 (Forecasting Loss:0.2424 + XiCon Loss:3.3749 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.1920
Validation loss decreased (0.249847 --> 0.249654).  Saving model ...
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.6695430
	speed: 0.0345s/iter; left time: 678.7759s
	iters: 200, epoch: 26 | loss: 3.6395922
	speed: 0.0329s/iter; left time: 645.2837s
Epoch: 26 cost time: 8.750115633010864
Epoch: 26, Steps: 264 Train Loss: 3.6187 (Forecasting Loss:0.2423 + XiCon Loss:3.3764 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1920
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.6045692
	speed: 0.0349s/iter; left time: 677.4662s
	iters: 200, epoch: 27 | loss: 3.6180611
	speed: 0.0322s/iter; left time: 623.5098s
Epoch: 27 cost time: 8.787221670150757
Epoch: 27, Steps: 264 Train Loss: 3.6164 (Forecasting Loss:0.2423 + XiCon Loss:3.3741 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.6702204
	speed: 0.0343s/iter; left time: 657.1663s
	iters: 200, epoch: 28 | loss: 3.6578622
	speed: 0.0318s/iter; left time: 607.3856s
Epoch: 28 cost time: 8.665464401245117
Epoch: 28, Steps: 264 Train Loss: 3.6163 (Forecasting Loss:0.2423 + XiCon Loss:3.3740 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.5924714
	speed: 0.0346s/iter; left time: 655.0105s
	iters: 200, epoch: 29 | loss: 3.6106334
	speed: 0.0317s/iter; left time: 595.7305s
Epoch: 29 cost time: 8.677809000015259
Epoch: 29, Steps: 264 Train Loss: 3.6175 (Forecasting Loss:0.2425 + XiCon Loss:3.3749 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.6432076
	speed: 0.0351s/iter; left time: 653.5791s
	iters: 200, epoch: 30 | loss: 3.6015244
	speed: 0.0317s/iter; left time: 587.8855s
Epoch: 30 cost time: 8.727564334869385
Epoch: 30, Steps: 264 Train Loss: 3.6197 (Forecasting Loss:0.2424 + XiCon Loss:3.3773 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.7098870
	speed: 0.0344s/iter; left time: 632.0669s
	iters: 200, epoch: 31 | loss: 3.5983295
	speed: 0.0318s/iter; left time: 581.6559s
Epoch: 31 cost time: 8.63804841041565
Epoch: 31, Steps: 264 Train Loss: 3.6196 (Forecasting Loss:0.2423 + XiCon Loss:3.3772 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.5941463
	speed: 0.0344s/iter; left time: 622.7293s
	iters: 200, epoch: 32 | loss: 3.6607220
	speed: 0.0325s/iter; left time: 586.0510s
Epoch: 32 cost time: 8.746901035308838
Epoch: 32, Steps: 264 Train Loss: 3.6172 (Forecasting Loss:0.2424 + XiCon Loss:3.3749 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1920
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.5751257
	speed: 0.0343s/iter; left time: 612.7309s
	iters: 200, epoch: 33 | loss: 3.6463995
	speed: 0.0321s/iter; left time: 570.5262s
Epoch: 33 cost time: 8.713499546051025
Epoch: 33, Steps: 264 Train Loss: 3.6166 (Forecasting Loss:0.2423 + XiCon Loss:3.3743 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1920
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 34 | loss: 3.6800756
	speed: 0.0338s/iter; left time: 593.7552s
	iters: 200, epoch: 34 | loss: 3.6728532
	speed: 0.0320s/iter; left time: 560.3396s
Epoch: 34 cost time: 8.634953260421753
Epoch: 34, Steps: 264 Train Loss: 3.6214 (Forecasting Loss:0.2424 + XiCon Loss:3.3790 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1920
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 35 | loss: 3.6137509
	speed: 0.0343s/iter; left time: 594.5787s
	iters: 200, epoch: 35 | loss: 3.6819959
	speed: 0.0315s/iter; left time: 542.4738s
Epoch: 35 cost time: 8.66393494606018
Epoch: 35, Steps: 264 Train Loss: 3.6175 (Forecasting Loss:0.2424 + XiCon Loss:3.3751 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1920
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12019339203834534, mae:0.26383763551712036, mape:0.6304671764373779, mspe:14.434354782104492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.6082
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.8626044
	speed: 0.0356s/iter; left time: 936.2317s
	iters: 200, epoch: 1 | loss: 3.8263843
	speed: 0.0322s/iter; left time: 843.8534s
Epoch: 1 cost time: 8.818359613418579
Epoch: 1, Steps: 264 Train Loss: 3.8592 (Forecasting Loss:0.3340 + XiCon Loss:3.5253 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.296838).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5566235
	speed: 0.0341s/iter; left time: 888.7043s
	iters: 200, epoch: 2 | loss: 3.6070321
	speed: 0.0321s/iter; left time: 832.9836s
Epoch: 2 cost time: 8.670501232147217
Epoch: 2, Steps: 264 Train Loss: 3.6096 (Forecasting Loss:0.2530 + XiCon Loss:3.3566 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1938
Validation loss decreased (0.296838 --> 0.250640).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5575902
	speed: 0.0344s/iter; left time: 885.3647s
	iters: 200, epoch: 3 | loss: 3.6263692
	speed: 0.0319s/iter; left time: 819.2190s
Epoch: 3 cost time: 8.722310304641724
Epoch: 3, Steps: 264 Train Loss: 3.5789 (Forecasting Loss:0.2452 + XiCon Loss:3.3337 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.1936
Validation loss decreased (0.250640 --> 0.249904).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5121815
	speed: 0.0341s/iter; left time: 868.6376s
	iters: 200, epoch: 4 | loss: 3.5365407
	speed: 0.0319s/iter; left time: 810.3547s
Epoch: 4 cost time: 8.621941328048706
Epoch: 4, Steps: 264 Train Loss: 3.5512 (Forecasting Loss:0.2434 + XiCon Loss:3.3078 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1928
Validation loss decreased (0.249904 --> 0.245785).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4983835
	speed: 0.0348s/iter; left time: 878.3144s
	iters: 200, epoch: 5 | loss: 3.4943280
	speed: 0.0314s/iter; left time: 789.1692s
Epoch: 5 cost time: 8.72390341758728
Epoch: 5, Steps: 264 Train Loss: 3.5384 (Forecasting Loss:0.2431 + XiCon Loss:3.2953 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1922
Validation loss decreased (0.245785 --> 0.245457).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5972543
	speed: 0.0337s/iter; left time: 841.5652s
	iters: 200, epoch: 6 | loss: 3.5419080
	speed: 0.0324s/iter; left time: 807.3718s
Epoch: 6 cost time: 8.731644868850708
Epoch: 6, Steps: 264 Train Loss: 3.5333 (Forecasting Loss:0.2424 + XiCon Loss:3.2909 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1923
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4734600
	speed: 0.0340s/iter; left time: 839.5564s
	iters: 200, epoch: 7 | loss: 3.5511880
	speed: 0.0320s/iter; left time: 786.9320s
Epoch: 7 cost time: 8.661114931106567
Epoch: 7, Steps: 264 Train Loss: 3.5291 (Forecasting Loss:0.2420 + XiCon Loss:3.2871 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1925
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5287516
	speed: 0.0335s/iter; left time: 819.5905s
	iters: 200, epoch: 8 | loss: 3.5308073
	speed: 0.0326s/iter; left time: 793.0370s
Epoch: 8 cost time: 8.674939155578613
Epoch: 8, Steps: 264 Train Loss: 3.5311 (Forecasting Loss:0.2416 + XiCon Loss:3.2894 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1925
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5378385
	speed: 0.0342s/iter; left time: 826.3764s
	iters: 200, epoch: 9 | loss: 3.5829439
	speed: 0.0319s/iter; left time: 769.4666s
Epoch: 9 cost time: 8.692870855331421
Epoch: 9, Steps: 264 Train Loss: 3.5294 (Forecasting Loss:0.2418 + XiCon Loss:3.2876 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1925
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5647521
	speed: 0.0346s/iter; left time: 827.3002s
	iters: 200, epoch: 10 | loss: 3.5428655
	speed: 0.0326s/iter; left time: 776.1151s
Epoch: 10 cost time: 8.779370546340942
Epoch: 10, Steps: 264 Train Loss: 3.5293 (Forecasting Loss:0.2417 + XiCon Loss:3.2876 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1925
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4761012
	speed: 0.0346s/iter; left time: 817.7049s
	iters: 200, epoch: 11 | loss: 3.5068903
	speed: 0.0317s/iter; left time: 747.0431s
Epoch: 11 cost time: 8.639126777648926
Epoch: 11, Steps: 264 Train Loss: 3.5307 (Forecasting Loss:0.2417 + XiCon Loss:3.2890 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1925
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4912610
	speed: 0.0344s/iter; left time: 804.3316s
	iters: 200, epoch: 12 | loss: 3.5110605
	speed: 0.0325s/iter; left time: 757.4760s
Epoch: 12 cost time: 8.777021408081055
Epoch: 12, Steps: 264 Train Loss: 3.5300 (Forecasting Loss:0.2416 + XiCon Loss:3.2883 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1925
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4721439
	speed: 0.0347s/iter; left time: 803.1082s
	iters: 200, epoch: 13 | loss: 3.4807155
	speed: 0.0318s/iter; left time: 732.0787s
Epoch: 13 cost time: 8.722578525543213
Epoch: 13, Steps: 264 Train Loss: 3.5282 (Forecasting Loss:0.2418 + XiCon Loss:3.2864 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1925
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5880265
	speed: 0.0340s/iter; left time: 776.5562s
	iters: 200, epoch: 14 | loss: 3.5242221
	speed: 0.0317s/iter; left time: 721.1992s
Epoch: 14 cost time: 8.656532287597656
Epoch: 14, Steps: 264 Train Loss: 3.5274 (Forecasting Loss:0.2417 + XiCon Loss:3.2857 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1925
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5000243
	speed: 0.0339s/iter; left time: 766.1346s
	iters: 200, epoch: 15 | loss: 3.5222144
	speed: 0.0325s/iter; left time: 730.7946s
Epoch: 15 cost time: 8.687251091003418
Epoch: 15, Steps: 264 Train Loss: 3.5288 (Forecasting Loss:0.2417 + XiCon Loss:3.2871 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1925
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12044773250818253, mae:0.26402002573013306, mape:0.6381897330284119, mspe:14.899954795837402 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5064
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.8755364
	speed: 0.0369s/iter; left time: 970.1112s
	iters: 200, epoch: 1 | loss: 3.8637531
	speed: 0.0330s/iter; left time: 864.0156s
Epoch: 1 cost time: 9.023282527923584
Epoch: 1, Steps: 264 Train Loss: 3.8754 (Forecasting Loss:0.3354 + XiCon Loss:3.5400 x Lambda(1.0)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.2351
Validation loss decreased (inf --> 0.300026).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5979614
	speed: 0.0345s/iter; left time: 897.3253s
	iters: 200, epoch: 2 | loss: 3.5628707
	speed: 0.0319s/iter; left time: 827.5589s
Epoch: 2 cost time: 8.758818864822388
Epoch: 2, Steps: 264 Train Loss: 3.6182 (Forecasting Loss:0.2519 + XiCon Loss:3.3664 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1949
Validation loss decreased (0.300026 --> 0.252768).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.7291331
	speed: 0.0353s/iter; left time: 909.8045s
	iters: 200, epoch: 3 | loss: 3.5940604
	speed: 0.0320s/iter; left time: 821.6142s
Epoch: 3 cost time: 8.776495456695557
Epoch: 3, Steps: 264 Train Loss: 3.6350 (Forecasting Loss:0.2425 + XiCon Loss:3.3925 x Lambda(1.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1954
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6642618
	speed: 0.0337s/iter; left time: 859.8874s
	iters: 200, epoch: 4 | loss: 3.6369033
	speed: 0.0316s/iter; left time: 802.5385s
Epoch: 4 cost time: 8.606803894042969
Epoch: 4, Steps: 264 Train Loss: 3.6151 (Forecasting Loss:0.2413 + XiCon Loss:3.3738 x Lambda(1.0)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.1956
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5810854
	speed: 0.0346s/iter; left time: 872.6538s
	iters: 200, epoch: 5 | loss: 3.6351912
	speed: 0.0319s/iter; left time: 802.6389s
Epoch: 5 cost time: 8.717284679412842
Epoch: 5, Steps: 264 Train Loss: 3.6048 (Forecasting Loss:0.2409 + XiCon Loss:3.3639 x Lambda(1.0)), Vali MSE Loss: 0.2530 Test MSE Loss: 0.1952
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6201956
	speed: 0.0349s/iter; left time: 870.6994s
	iters: 200, epoch: 6 | loss: 3.5758598
	speed: 0.0321s/iter; left time: 798.3420s
Epoch: 6 cost time: 8.74942660331726
Epoch: 6, Steps: 264 Train Loss: 3.6007 (Forecasting Loss:0.2402 + XiCon Loss:3.3604 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1956
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6373088
	speed: 0.0350s/iter; left time: 866.0247s
	iters: 200, epoch: 7 | loss: 3.6024380
	speed: 0.0323s/iter; left time: 794.8591s
Epoch: 7 cost time: 8.800382137298584
Epoch: 7, Steps: 264 Train Loss: 3.5955 (Forecasting Loss:0.2402 + XiCon Loss:3.3553 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5855551
	speed: 0.0347s/iter; left time: 848.6563s
	iters: 200, epoch: 8 | loss: 3.6825755
	speed: 0.0325s/iter; left time: 790.3535s
Epoch: 8 cost time: 8.831455707550049
Epoch: 8, Steps: 264 Train Loss: 3.5928 (Forecasting Loss:0.2401 + XiCon Loss:3.3527 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
Validation loss decreased (0.252768 --> 0.252699).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5639825
	speed: 0.0354s/iter; left time: 855.4855s
	iters: 200, epoch: 9 | loss: 3.6058276
	speed: 0.0441s/iter; left time: 1061.9421s
Epoch: 9 cost time: 10.71939206123352
Epoch: 9, Steps: 264 Train Loss: 3.5948 (Forecasting Loss:0.2400 + XiCon Loss:3.3549 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
Validation loss decreased (0.252699 --> 0.252640).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6005068
	speed: 0.0377s/iter; left time: 901.3749s
	iters: 200, epoch: 10 | loss: 3.6244032
	speed: 0.0322s/iter; left time: 767.9478s
Epoch: 10 cost time: 9.062235116958618
Epoch: 10, Steps: 264 Train Loss: 3.5931 (Forecasting Loss:0.2399 + XiCon Loss:3.3532 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1955
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6283736
	speed: 0.0344s/iter; left time: 813.0316s
	iters: 200, epoch: 11 | loss: 3.5595169
	speed: 0.0321s/iter; left time: 756.2854s
Epoch: 11 cost time: 9.505370140075684
Epoch: 11, Steps: 264 Train Loss: 3.5943 (Forecasting Loss:0.2398 + XiCon Loss:3.3545 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1954
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5698936
	speed: 0.0457s/iter; left time: 1070.0623s
	iters: 200, epoch: 12 | loss: 3.5889268
	speed: 0.0427s/iter; left time: 993.9162s
Epoch: 12 cost time: 11.614389419555664
Epoch: 12, Steps: 264 Train Loss: 3.5915 (Forecasting Loss:0.2400 + XiCon Loss:3.3515 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5673888
	speed: 0.0434s/iter; left time: 1003.7131s
	iters: 200, epoch: 13 | loss: 3.5934861
	speed: 0.0410s/iter; left time: 944.8344s
Epoch: 13 cost time: 11.094122648239136
Epoch: 13, Steps: 264 Train Loss: 3.5959 (Forecasting Loss:0.2400 + XiCon Loss:3.3559 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5863986
	speed: 0.0443s/iter; left time: 1012.4618s
	iters: 200, epoch: 14 | loss: 3.5538559
	speed: 0.0406s/iter; left time: 925.1262s
Epoch: 14 cost time: 11.115806102752686
Epoch: 14, Steps: 264 Train Loss: 3.5944 (Forecasting Loss:0.2400 + XiCon Loss:3.3544 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5591712
	speed: 0.0452s/iter; left time: 1021.6130s
	iters: 200, epoch: 15 | loss: 3.5864890
	speed: 0.0437s/iter; left time: 983.8419s
Epoch: 15 cost time: 11.637377262115479
Epoch: 15, Steps: 264 Train Loss: 3.5931 (Forecasting Loss:0.2400 + XiCon Loss:3.3531 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.5962124
	speed: 0.0452s/iter; left time: 1009.2343s
	iters: 200, epoch: 16 | loss: 3.6067376
	speed: 0.0425s/iter; left time: 944.1384s
Epoch: 16 cost time: 11.502137422561646
Epoch: 16, Steps: 264 Train Loss: 3.5936 (Forecasting Loss:0.2400 + XiCon Loss:3.3536 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6293702
	speed: 0.0449s/iter; left time: 990.8406s
	iters: 200, epoch: 17 | loss: 3.5721073
	speed: 0.0411s/iter; left time: 903.9937s
Epoch: 17 cost time: 11.233590126037598
Epoch: 17, Steps: 264 Train Loss: 3.5931 (Forecasting Loss:0.2401 + XiCon Loss:3.3529 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.5620623
	speed: 0.0464s/iter; left time: 1012.4830s
	iters: 200, epoch: 18 | loss: 3.5230243
	speed: 0.0414s/iter; left time: 899.2975s
Epoch: 18 cost time: 11.520939350128174
Epoch: 18, Steps: 264 Train Loss: 3.5934 (Forecasting Loss:0.2399 + XiCon Loss:3.3535 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.5767732
	speed: 0.0456s/iter; left time: 983.3662s
	iters: 200, epoch: 19 | loss: 3.5821147
	speed: 0.0439s/iter; left time: 941.1622s
Epoch: 19 cost time: 11.869776010513306
Epoch: 19, Steps: 264 Train Loss: 3.5935 (Forecasting Loss:0.2399 + XiCon Loss:3.3535 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
Validation loss decreased (0.252640 --> 0.252628).  Saving model ...
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.5944729
	speed: 0.0459s/iter; left time: 976.4304s
	iters: 200, epoch: 20 | loss: 3.6423039
	speed: 0.0415s/iter; left time: 880.0007s
Epoch: 20 cost time: 11.519566535949707
Epoch: 20, Steps: 264 Train Loss: 3.5964 (Forecasting Loss:0.2398 + XiCon Loss:3.3566 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
Validation loss decreased (0.252628 --> 0.252553).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.6106963
	speed: 0.0450s/iter; left time: 945.7130s
	iters: 200, epoch: 21 | loss: 3.5506866
	speed: 0.0423s/iter; left time: 884.5187s
Epoch: 21 cost time: 11.340174198150635
Epoch: 21, Steps: 264 Train Loss: 3.5931 (Forecasting Loss:0.2399 + XiCon Loss:3.3532 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.6018808
	speed: 0.0448s/iter; left time: 930.8996s
	iters: 200, epoch: 22 | loss: 3.5768330
	speed: 0.0418s/iter; left time: 862.4574s
Epoch: 22 cost time: 11.35673189163208
Epoch: 22, Steps: 264 Train Loss: 3.5930 (Forecasting Loss:0.2398 + XiCon Loss:3.3532 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.5984464
	speed: 0.0387s/iter; left time: 792.2337s
	iters: 200, epoch: 23 | loss: 3.5758259
	speed: 0.0341s/iter; left time: 695.0954s
Epoch: 23 cost time: 9.421521425247192
Epoch: 23, Steps: 264 Train Loss: 3.5901 (Forecasting Loss:0.2401 + XiCon Loss:3.3500 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.5463943
	speed: 0.0412s/iter; left time: 834.3536s
	iters: 200, epoch: 24 | loss: 3.6026797
	speed: 0.0388s/iter; left time: 781.0655s
Epoch: 24 cost time: 10.64411449432373
Epoch: 24, Steps: 264 Train Loss: 3.5944 (Forecasting Loss:0.2398 + XiCon Loss:3.3546 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.5773067
	speed: 0.0430s/iter; left time: 858.3006s
	iters: 200, epoch: 25 | loss: 3.5548453
	speed: 0.0408s/iter; left time: 810.7045s
Epoch: 25 cost time: 10.946640968322754
Epoch: 25, Steps: 264 Train Loss: 3.5940 (Forecasting Loss:0.2400 + XiCon Loss:3.3540 x Lambda(1.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1954
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.6384239
	speed: 0.0444s/iter; left time: 873.8560s
	iters: 200, epoch: 26 | loss: 3.5930858
	speed: 0.0418s/iter; left time: 818.8701s
Epoch: 26 cost time: 11.299604415893555
Epoch: 26, Steps: 264 Train Loss: 3.5925 (Forecasting Loss:0.2399 + XiCon Loss:3.3526 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.1954
Validation loss decreased (0.252553 --> 0.252422).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.6159940
	speed: 0.0439s/iter; left time: 853.6350s
	iters: 200, epoch: 27 | loss: 3.6536114
	speed: 0.0401s/iter; left time: 775.6390s
Epoch: 27 cost time: 11.129866361618042
Epoch: 27, Steps: 264 Train Loss: 3.5949 (Forecasting Loss:0.2399 + XiCon Loss:3.3551 x Lambda(1.0)), Vali MSE Loss: 0.2525 Test MSE Loss: 0.1954
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.6253033
	speed: 0.0425s/iter; left time: 815.5529s
	iters: 200, epoch: 28 | loss: 3.6732862
	speed: 0.0423s/iter; left time: 807.5464s
Epoch: 28 cost time: 11.088624477386475
Epoch: 28, Steps: 264 Train Loss: 3.5913 (Forecasting Loss:0.2399 + XiCon Loss:3.3513 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.6205828
	speed: 0.0551s/iter; left time: 1041.5855s
	iters: 200, epoch: 29 | loss: 3.6217949
	speed: 0.0506s/iter; left time: 951.6721s
Epoch: 29 cost time: 13.782416582107544
Epoch: 29, Steps: 264 Train Loss: 3.5944 (Forecasting Loss:0.2398 + XiCon Loss:3.3546 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.5509815
	speed: 0.0436s/iter; left time: 812.1424s
	iters: 200, epoch: 30 | loss: 3.5879457
	speed: 0.0422s/iter; left time: 781.9543s
Epoch: 30 cost time: 11.87379002571106
Epoch: 30, Steps: 264 Train Loss: 3.5924 (Forecasting Loss:0.2401 + XiCon Loss:3.3523 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.6155334
	speed: 0.0582s/iter; left time: 1070.5061s
	iters: 200, epoch: 31 | loss: 3.6499381
	speed: 0.0512s/iter; left time: 936.5032s
Epoch: 31 cost time: 13.493355751037598
Epoch: 31, Steps: 264 Train Loss: 3.5954 (Forecasting Loss:0.2398 + XiCon Loss:3.3555 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.6084943
	speed: 0.0426s/iter; left time: 772.0996s
	iters: 200, epoch: 32 | loss: 3.5668950
	speed: 0.0415s/iter; left time: 747.1850s
Epoch: 32 cost time: 11.147103309631348
Epoch: 32, Steps: 264 Train Loss: 3.5958 (Forecasting Loss:0.2400 + XiCon Loss:3.3558 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.5441763
	speed: 0.0468s/iter; left time: 835.4135s
	iters: 200, epoch: 33 | loss: 3.5763314
	speed: 0.0419s/iter; left time: 743.9224s
Epoch: 33 cost time: 11.569168329238892
Epoch: 33, Steps: 264 Train Loss: 3.5913 (Forecasting Loss:0.2399 + XiCon Loss:3.3513 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 34 | loss: 3.6482782
	speed: 0.0461s/iter; left time: 810.6555s
	iters: 200, epoch: 34 | loss: 3.5688457
	speed: 0.0427s/iter; left time: 746.5576s
Epoch: 34 cost time: 11.699567556381226
Epoch: 34, Steps: 264 Train Loss: 3.5916 (Forecasting Loss:0.2401 + XiCon Loss:3.3515 x Lambda(1.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1954
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 35 | loss: 3.5578651
	speed: 0.0427s/iter; left time: 739.9073s
	iters: 200, epoch: 35 | loss: 3.5323410
	speed: 0.0441s/iter; left time: 758.8204s
Epoch: 35 cost time: 11.282124280929565
Epoch: 35, Steps: 264 Train Loss: 3.5927 (Forecasting Loss:0.2400 + XiCon Loss:3.3527 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 36 | loss: 3.5415332
	speed: 0.0434s/iter; left time: 739.9711s
	iters: 200, epoch: 36 | loss: 3.6716695
	speed: 0.0407s/iter; left time: 689.8835s
Epoch: 36 cost time: 11.08349347114563
Epoch: 36, Steps: 264 Train Loss: 3.5916 (Forecasting Loss:0.2398 + XiCon Loss:3.3518 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1954
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12343030422925949, mae:0.2674373686313629, mape:0.6440696120262146, mspe:14.921793937683105 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.4191
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.8678677
	speed: 0.0436s/iter; left time: 1146.1910s
	iters: 200, epoch: 1 | loss: 3.8244901
	speed: 0.0394s/iter; left time: 1031.8354s
Epoch: 1 cost time: 10.92674207687378
Epoch: 1, Steps: 264 Train Loss: 3.8643 (Forecasting Loss:0.3434 + XiCon Loss:3.5209 x Lambda(1.0)), Vali MSE Loss: 0.2933 Test MSE Loss: 0.2366
Validation loss decreased (inf --> 0.293254).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5436969
	speed: 0.0430s/iter; left time: 1118.8456s
	iters: 200, epoch: 2 | loss: 3.5441618
	speed: 0.0397s/iter; left time: 1030.2529s
Epoch: 2 cost time: 10.881232023239136
Epoch: 2, Steps: 264 Train Loss: 3.5924 (Forecasting Loss:0.2540 + XiCon Loss:3.3383 x Lambda(1.0)), Vali MSE Loss: 0.2443 Test MSE Loss: 0.1954
Validation loss decreased (0.293254 --> 0.244326).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5359139
	speed: 0.0468s/iter; left time: 1206.7269s
	iters: 200, epoch: 3 | loss: 3.5899537
	speed: 0.0689s/iter; left time: 1768.6186s
Epoch: 3 cost time: 15.452787637710571
Epoch: 3, Steps: 264 Train Loss: 3.6145 (Forecasting Loss:0.2456 + XiCon Loss:3.3689 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.1922
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6176004
	speed: 0.0435s/iter; left time: 1109.5135s
	iters: 200, epoch: 4 | loss: 3.6273808
	speed: 0.0412s/iter; left time: 1047.0383s
Epoch: 4 cost time: 11.189335107803345
Epoch: 4, Steps: 264 Train Loss: 3.5839 (Forecasting Loss:0.2444 + XiCon Loss:3.3395 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1921
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6172678
	speed: 0.0769s/iter; left time: 1940.9386s
	iters: 200, epoch: 5 | loss: 3.4689369
	speed: 0.0535s/iter; left time: 1346.3768s
Epoch: 5 cost time: 16.23855209350586
Epoch: 5, Steps: 264 Train Loss: 3.5715 (Forecasting Loss:0.2434 + XiCon Loss:3.3281 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1915
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6253467
	speed: 0.0438s/iter; left time: 1093.0550s
	iters: 200, epoch: 6 | loss: 3.6052678
	speed: 0.0397s/iter; left time: 988.0976s
Epoch: 6 cost time: 11.030205488204956
Epoch: 6, Steps: 264 Train Loss: 3.5664 (Forecasting Loss:0.2430 + XiCon Loss:3.3234 x Lambda(1.0)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.1913
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5435555
	speed: 0.0425s/iter; left time: 1049.8044s
	iters: 200, epoch: 7 | loss: 3.5727069
	speed: 0.0432s/iter; left time: 1063.5105s
Epoch: 7 cost time: 11.235933303833008
Epoch: 7, Steps: 264 Train Loss: 3.5602 (Forecasting Loss:0.2427 + XiCon Loss:3.3175 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.1912
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4760923
	speed: 0.0448s/iter; left time: 1095.5347s
	iters: 200, epoch: 8 | loss: 3.5529473
	speed: 0.0424s/iter; left time: 1033.7703s
Epoch: 8 cost time: 11.553206443786621
Epoch: 8, Steps: 264 Train Loss: 3.5574 (Forecasting Loss:0.2428 + XiCon Loss:3.3146 x Lambda(1.0)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.1912
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6208990
	speed: 0.0443s/iter; left time: 1071.1529s
	iters: 200, epoch: 9 | loss: 3.5589130
	speed: 0.0419s/iter; left time: 1009.3838s
Epoch: 9 cost time: 11.441163063049316
Epoch: 9, Steps: 264 Train Loss: 3.5629 (Forecasting Loss:0.2428 + XiCon Loss:3.3201 x Lambda(1.0)), Vali MSE Loss: 0.2448 Test MSE Loss: 0.1912
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5169845
	speed: 0.0619s/iter; left time: 1481.7835s
	iters: 200, epoch: 10 | loss: 3.5673454
	speed: 0.0766s/iter; left time: 1825.5419s
Epoch: 10 cost time: 18.76278042793274
Epoch: 10, Steps: 264 Train Loss: 3.5590 (Forecasting Loss:0.2426 + XiCon Loss:3.3164 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.1912
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5927701
	speed: 0.0481s/iter; left time: 1137.3289s
	iters: 200, epoch: 11 | loss: 3.6224899
	speed: 0.0426s/iter; left time: 1003.1876s
Epoch: 11 cost time: 11.809393882751465
Epoch: 11, Steps: 264 Train Loss: 3.5601 (Forecasting Loss:0.2425 + XiCon Loss:3.3176 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.1912
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5517354
	speed: 0.0460s/iter; left time: 1076.5067s
	iters: 200, epoch: 12 | loss: 3.5495844
	speed: 0.0415s/iter; left time: 967.8910s
Epoch: 12 cost time: 11.435321807861328
Epoch: 12, Steps: 264 Train Loss: 3.5594 (Forecasting Loss:0.2426 + XiCon Loss:3.3168 x Lambda(1.0)), Vali MSE Loss: 0.2448 Test MSE Loss: 0.1912
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12267237901687622, mae:0.2680772542953491, mape:0.6519503593444824, mspe:15.537995338439941 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1218+-0.00174, MAE:0.2656+-0.00249, MAPE:0.6397+-0.01057, MSPE:14.8680+-0.53574, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.99, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 22.4923
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.9028404
	speed: 0.0943s/iter; left time: 2452.8513s
	iters: 200, epoch: 1 | loss: 3.8414266
	speed: 0.0606s/iter; left time: 1569.4866s
Epoch: 1 cost time: 18.358315229415894
Epoch: 1, Steps: 261 Train Loss: 3.8966 (Forecasting Loss:0.3722 + XiCon Loss:3.5244 x Lambda(1.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.324161).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6082540
	speed: 0.0554s/iter; left time: 1426.9581s
	iters: 200, epoch: 2 | loss: 3.6124403
	speed: 0.0545s/iter; left time: 1398.0905s
Epoch: 2 cost time: 14.248814821243286
Epoch: 2, Steps: 261 Train Loss: 3.6679 (Forecasting Loss:0.3001 + XiCon Loss:3.3679 x Lambda(1.0)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.2511
Validation loss decreased (0.324161 --> 0.293833).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6210661
	speed: 0.0556s/iter; left time: 1416.8143s
	iters: 200, epoch: 3 | loss: 3.7112446
	speed: 0.0541s/iter; left time: 1374.1318s
Epoch: 3 cost time: 14.228152990341187
Epoch: 3, Steps: 261 Train Loss: 3.6463 (Forecasting Loss:0.2925 + XiCon Loss:3.3537 x Lambda(1.0)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.2450
Validation loss decreased (0.293833 --> 0.280149).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5783257
	speed: 0.0811s/iter; left time: 2044.7480s
	iters: 200, epoch: 4 | loss: 3.6195800
	speed: 0.0842s/iter; left time: 2114.3893s
Epoch: 4 cost time: 21.52491855621338
Epoch: 4, Steps: 261 Train Loss: 3.6263 (Forecasting Loss:0.2893 + XiCon Loss:3.3370 x Lambda(1.0)), Vali MSE Loss: 0.2834 Test MSE Loss: 0.2443
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6452479
	speed: 0.0864s/iter; left time: 2155.8665s
	iters: 200, epoch: 5 | loss: 3.6256063
	speed: 0.0827s/iter; left time: 2055.8913s
Epoch: 5 cost time: 21.95144271850586
Epoch: 5, Steps: 261 Train Loss: 3.6151 (Forecasting Loss:0.2886 + XiCon Loss:3.3265 x Lambda(1.0)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.2444
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6194220
	speed: 0.0853s/iter; left time: 2106.0350s
	iters: 200, epoch: 6 | loss: 3.5852342
	speed: 0.0846s/iter; left time: 2079.9309s
Epoch: 6 cost time: 22.42181897163391
Epoch: 6, Steps: 261 Train Loss: 3.6093 (Forecasting Loss:0.2878 + XiCon Loss:3.3215 x Lambda(1.0)), Vali MSE Loss: 0.2809 Test MSE Loss: 0.2440
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6034915
	speed: 0.0893s/iter; left time: 2181.1033s
	iters: 200, epoch: 7 | loss: 3.5559776
	speed: 0.0818s/iter; left time: 1990.4968s
Epoch: 7 cost time: 22.030514001846313
Epoch: 7, Steps: 261 Train Loss: 3.6060 (Forecasting Loss:0.2880 + XiCon Loss:3.3180 x Lambda(1.0)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2441
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6167529
	speed: 0.0861s/iter; left time: 2082.4093s
	iters: 200, epoch: 8 | loss: 3.6568906
	speed: 0.0827s/iter; left time: 1991.6383s
Epoch: 8 cost time: 22.14703679084778
Epoch: 8, Steps: 261 Train Loss: 3.6037 (Forecasting Loss:0.2882 + XiCon Loss:3.3155 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2443
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5459356
	speed: 0.0829s/iter; left time: 1981.5143s
	iters: 200, epoch: 9 | loss: 3.5717258
	speed: 0.0825s/iter; left time: 1964.7133s
Epoch: 9 cost time: 20.66044330596924
Epoch: 9, Steps: 261 Train Loss: 3.6066 (Forecasting Loss:0.2882 + XiCon Loss:3.3184 x Lambda(1.0)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.2443
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6375370
	speed: 0.0858s/iter; left time: 2030.0436s
	iters: 200, epoch: 10 | loss: 3.6226242
	speed: 0.0857s/iter; left time: 2018.9731s
Epoch: 10 cost time: 21.999274492263794
Epoch: 10, Steps: 261 Train Loss: 3.6028 (Forecasting Loss:0.2879 + XiCon Loss:3.3150 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2443
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6301367
	speed: 0.0871s/iter; left time: 2037.2801s
	iters: 200, epoch: 11 | loss: 3.5769243
	speed: 0.0808s/iter; left time: 1882.2057s
Epoch: 11 cost time: 21.748465299606323
Epoch: 11, Steps: 261 Train Loss: 3.6041 (Forecasting Loss:0.2880 + XiCon Loss:3.3161 x Lambda(1.0)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.2443
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5971973
	speed: 0.0928s/iter; left time: 2145.4605s
	iters: 200, epoch: 12 | loss: 3.5815644
	speed: 0.0856s/iter; left time: 1972.4245s
Epoch: 12 cost time: 22.969871997833252
Epoch: 12, Steps: 261 Train Loss: 3.6046 (Forecasting Loss:0.2879 + XiCon Loss:3.3168 x Lambda(1.0)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.2443
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6422358
	speed: 0.0736s/iter; left time: 1683.8942s
	iters: 200, epoch: 13 | loss: 3.6072257
	speed: 0.0787s/iter; left time: 1792.5589s
Epoch: 13 cost time: 20.519055128097534
Epoch: 13, Steps: 261 Train Loss: 3.6056 (Forecasting Loss:0.2879 + XiCon Loss:3.3176 x Lambda(1.0)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.2443
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17014358937740326, mae:0.3198140561580658, mape:0.7285764217376709, mspe:20.556299209594727 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.9720
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.9280016
	speed: 0.0833s/iter; left time: 2165.1163s
	iters: 200, epoch: 1 | loss: 3.8607192
	speed: 0.0804s/iter; left time: 2081.5090s
Epoch: 1 cost time: 21.68591284751892
Epoch: 1, Steps: 261 Train Loss: 3.9133 (Forecasting Loss:0.3712 + XiCon Loss:3.5421 x Lambda(1.0)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2809
Validation loss decreased (inf --> 0.323954).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6291492
	speed: 0.0882s/iter; left time: 2271.4667s
	iters: 200, epoch: 2 | loss: 3.5861306
	speed: 0.0725s/iter; left time: 1858.8963s
Epoch: 2 cost time: 21.066059827804565
Epoch: 2, Steps: 261 Train Loss: 3.6513 (Forecasting Loss:0.2992 + XiCon Loss:3.3520 x Lambda(1.0)), Vali MSE Loss: 0.2842 Test MSE Loss: 0.2513
Validation loss decreased (0.323954 --> 0.284248).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6533248
	speed: 0.0920s/iter; left time: 2345.3033s
	iters: 200, epoch: 3 | loss: 3.7214437
	speed: 0.0864s/iter; left time: 2192.7934s
Epoch: 3 cost time: 23.266207456588745
Epoch: 3, Steps: 261 Train Loss: 3.6797 (Forecasting Loss:0.2916 + XiCon Loss:3.3881 x Lambda(1.0)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.2483
Validation loss decreased (0.284248 --> 0.271139).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6485674
	speed: 0.0924s/iter; left time: 2329.2757s
	iters: 200, epoch: 4 | loss: 3.5935683
	speed: 0.0893s/iter; left time: 2244.0069s
Epoch: 4 cost time: 23.757617712020874
Epoch: 4, Steps: 261 Train Loss: 3.6452 (Forecasting Loss:0.2898 + XiCon Loss:3.3554 x Lambda(1.0)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.2483
Validation loss decreased (0.271139 --> 0.268718).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6274984
	speed: 0.0930s/iter; left time: 2321.2904s
	iters: 200, epoch: 5 | loss: 3.6341832
	speed: 0.0850s/iter; left time: 2113.1637s
Epoch: 5 cost time: 23.35688090324402
Epoch: 5, Steps: 261 Train Loss: 3.6328 (Forecasting Loss:0.2889 + XiCon Loss:3.3439 x Lambda(1.0)), Vali MSE Loss: 0.2698 Test MSE Loss: 0.2470
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5972166
	speed: 0.0902s/iter; left time: 2226.7644s
	iters: 200, epoch: 6 | loss: 3.6244872
	speed: 0.0855s/iter; left time: 2103.9428s
Epoch: 6 cost time: 22.959689140319824
Epoch: 6, Steps: 261 Train Loss: 3.6269 (Forecasting Loss:0.2885 + XiCon Loss:3.3384 x Lambda(1.0)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.2478
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6614857
	speed: 0.0944s/iter; left time: 2305.7521s
	iters: 200, epoch: 7 | loss: 3.6671958
	speed: 0.0933s/iter; left time: 2270.4632s
Epoch: 7 cost time: 23.986164331436157
Epoch: 7, Steps: 261 Train Loss: 3.6226 (Forecasting Loss:0.2881 + XiCon Loss:3.3345 x Lambda(1.0)), Vali MSE Loss: 0.2691 Test MSE Loss: 0.2474
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6304522
	speed: 0.0970s/iter; left time: 2343.9304s
	iters: 200, epoch: 8 | loss: 3.5901196
	speed: 0.0896s/iter; left time: 2156.1663s
Epoch: 8 cost time: 24.101039171218872
Epoch: 8, Steps: 261 Train Loss: 3.6216 (Forecasting Loss:0.2881 + XiCon Loss:3.3335 x Lambda(1.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2471
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6574318
	speed: 0.0780s/iter; left time: 1866.3216s
	iters: 200, epoch: 9 | loss: 3.5858436
	speed: 0.0939s/iter; left time: 2236.1603s
Epoch: 9 cost time: 22.9789822101593
Epoch: 9, Steps: 261 Train Loss: 3.6205 (Forecasting Loss:0.2880 + XiCon Loss:3.3325 x Lambda(1.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2473
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6018763
	speed: 0.0938s/iter; left time: 2217.5081s
	iters: 200, epoch: 10 | loss: 3.6692994
	speed: 0.0912s/iter; left time: 2147.8661s
Epoch: 10 cost time: 24.171085834503174
Epoch: 10, Steps: 261 Train Loss: 3.6233 (Forecasting Loss:0.2881 + XiCon Loss:3.3352 x Lambda(1.0)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.2472
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6284392
	speed: 0.0976s/iter; left time: 2283.1357s
	iters: 200, epoch: 11 | loss: 3.6916015
	speed: 0.0901s/iter; left time: 2098.3364s
Epoch: 11 cost time: 24.087806224822998
Epoch: 11, Steps: 261 Train Loss: 3.6198 (Forecasting Loss:0.2882 + XiCon Loss:3.3316 x Lambda(1.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2472
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6433399
	speed: 0.0935s/iter; left time: 2163.0463s
	iters: 200, epoch: 12 | loss: 3.6489069
	speed: 0.0810s/iter; left time: 1865.7515s
Epoch: 12 cost time: 22.09593391418457
Epoch: 12, Steps: 261 Train Loss: 3.6239 (Forecasting Loss:0.2882 + XiCon Loss:3.3357 x Lambda(1.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2472
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6113610
	speed: 0.0908s/iter; left time: 2077.6269s
	iters: 200, epoch: 13 | loss: 3.5911682
	speed: 0.0848s/iter; left time: 1931.1512s
Epoch: 13 cost time: 23.097564935684204
Epoch: 13, Steps: 261 Train Loss: 3.6192 (Forecasting Loss:0.2881 + XiCon Loss:3.3311 x Lambda(1.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.2472
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5645516
	speed: 0.0900s/iter; left time: 2035.8006s
	iters: 200, epoch: 14 | loss: 3.6444266
	speed: 0.0891s/iter; left time: 2005.9249s
Epoch: 14 cost time: 23.404383420944214
Epoch: 14, Steps: 261 Train Loss: 3.6188 (Forecasting Loss:0.2879 + XiCon Loss:3.3308 x Lambda(1.0)), Vali MSE Loss: 0.2692 Test MSE Loss: 0.2472
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17434760928153992, mae:0.3221973180770874, mape:0.700972318649292, mspe:18.620283126831055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.6724
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.9122527
	speed: 0.0851s/iter; left time: 2213.6744s
	iters: 200, epoch: 1 | loss: 3.8368132
	speed: 0.0843s/iter; left time: 2183.1162s
Epoch: 1 cost time: 22.225164651870728
Epoch: 1, Steps: 261 Train Loss: 3.8963 (Forecasting Loss:0.3714 + XiCon Loss:3.5249 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2794
Validation loss decreased (inf --> 0.321158).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6324329
	speed: 0.0849s/iter; left time: 2185.9053s
	iters: 200, epoch: 2 | loss: 3.7074380
	speed: 0.0886s/iter; left time: 2271.5578s
Epoch: 2 cost time: 22.968953132629395
Epoch: 2, Steps: 261 Train Loss: 3.7017 (Forecasting Loss:0.3006 + XiCon Loss:3.4011 x Lambda(1.0)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.2511
Validation loss decreased (0.321158 --> 0.292175).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.8181040
	speed: 0.1001s/iter; left time: 2549.9893s
	iters: 200, epoch: 3 | loss: 3.8032899
	speed: 0.0834s/iter; left time: 2116.7372s
Epoch: 3 cost time: 23.44655418395996
Epoch: 3, Steps: 261 Train Loss: 3.7829 (Forecasting Loss:0.2932 + XiCon Loss:3.4897 x Lambda(1.0)), Vali MSE Loss: 0.2918 Test MSE Loss: 0.2517
Validation loss decreased (0.292175 --> 0.291805).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.8015177
	speed: 0.0810s/iter; left time: 2042.4788s
	iters: 200, epoch: 4 | loss: 3.9458203
	speed: 0.0905s/iter; left time: 2273.7328s
Epoch: 4 cost time: 22.58097004890442
Epoch: 4, Steps: 261 Train Loss: 3.8246 (Forecasting Loss:0.2908 + XiCon Loss:3.5337 x Lambda(1.0)), Vali MSE Loss: 0.2913 Test MSE Loss: 0.2518
Validation loss decreased (0.291805 --> 0.291340).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.8747842
	speed: 0.0943s/iter; left time: 2354.5018s
	iters: 200, epoch: 5 | loss: 3.8158753
	speed: 0.0859s/iter; left time: 2135.3049s
Epoch: 5 cost time: 23.54792022705078
Epoch: 5, Steps: 261 Train Loss: 3.8219 (Forecasting Loss:0.2900 + XiCon Loss:3.5319 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2519
Validation loss decreased (0.291340 --> 0.289939).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.7421279
	speed: 0.0907s/iter; left time: 2239.6967s
	iters: 200, epoch: 6 | loss: 3.7336886
	speed: 0.0879s/iter; left time: 2161.4283s
Epoch: 6 cost time: 23.15648913383484
Epoch: 6, Steps: 261 Train Loss: 3.8307 (Forecasting Loss:0.2896 + XiCon Loss:3.5411 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2519
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.8585150
	speed: 0.0916s/iter; left time: 2238.9412s
	iters: 200, epoch: 7 | loss: 3.8455980
	speed: 0.0888s/iter; left time: 2159.9386s
Epoch: 7 cost time: 23.450781106948853
Epoch: 7, Steps: 261 Train Loss: 3.8375 (Forecasting Loss:0.2894 + XiCon Loss:3.5481 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2518
Validation loss decreased (0.289939 --> 0.289704).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.7953558
	speed: 0.0907s/iter; left time: 2191.8189s
	iters: 200, epoch: 8 | loss: 3.9579084
	speed: 0.0844s/iter; left time: 2031.6681s
Epoch: 8 cost time: 23.06929302215576
Epoch: 8, Steps: 261 Train Loss: 3.8383 (Forecasting Loss:0.2893 + XiCon Loss:3.5490 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2518
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.8561413
	speed: 0.0935s/iter; left time: 2236.5260s
	iters: 200, epoch: 9 | loss: 3.8304121
	speed: 0.0854s/iter; left time: 2033.4158s
Epoch: 9 cost time: 22.900397062301636
Epoch: 9, Steps: 261 Train Loss: 3.8438 (Forecasting Loss:0.2892 + XiCon Loss:3.5547 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2517
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 4.0108213
	speed: 0.0895s/iter; left time: 2116.0316s
	iters: 200, epoch: 10 | loss: 3.8427477
	speed: 0.0897s/iter; left time: 2112.7738s
Epoch: 10 cost time: 23.294580459594727
Epoch: 10, Steps: 261 Train Loss: 3.8360 (Forecasting Loss:0.2891 + XiCon Loss:3.5469 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2517
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.8953834
	speed: 0.0789s/iter; left time: 1845.0199s
	iters: 200, epoch: 11 | loss: 3.9362359
	speed: 0.0846s/iter; left time: 1970.3992s
Epoch: 11 cost time: 21.90190815925598
Epoch: 11, Steps: 261 Train Loss: 3.8445 (Forecasting Loss:0.2891 + XiCon Loss:3.5554 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2517
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.8159282
	speed: 0.0960s/iter; left time: 2221.5772s
	iters: 200, epoch: 12 | loss: 3.8011615
	speed: 0.0927s/iter; left time: 2135.0694s
Epoch: 12 cost time: 24.392419576644897
Epoch: 12, Steps: 261 Train Loss: 3.8439 (Forecasting Loss:0.2891 + XiCon Loss:3.5548 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2517
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.8007705
	speed: 0.0913s/iter; left time: 2088.0400s
	iters: 200, epoch: 13 | loss: 3.7874808
	speed: 0.0868s/iter; left time: 1976.2886s
Epoch: 13 cost time: 23.462641954421997
Epoch: 13, Steps: 261 Train Loss: 3.8444 (Forecasting Loss:0.2890 + XiCon Loss:3.5554 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2517
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.8480892
	speed: 0.0913s/iter; left time: 2063.8451s
	iters: 200, epoch: 14 | loss: 3.9974716
	speed: 0.0898s/iter; left time: 2020.9218s
Epoch: 14 cost time: 23.63027024269104
Epoch: 14, Steps: 261 Train Loss: 3.8418 (Forecasting Loss:0.2890 + XiCon Loss:3.5528 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2517
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.8697071
	speed: 0.0923s/iter; left time: 2063.0336s
	iters: 200, epoch: 15 | loss: 3.9028406
	speed: 0.0883s/iter; left time: 1963.4294s
Epoch: 15 cost time: 23.367778301239014
Epoch: 15, Steps: 261 Train Loss: 3.8391 (Forecasting Loss:0.2891 + XiCon Loss:3.5500 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2517
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.8987687
	speed: 0.0952s/iter; left time: 2103.2984s
	iters: 200, epoch: 16 | loss: 3.7810950
	speed: 0.0808s/iter; left time: 1776.5404s
Epoch: 16 cost time: 22.13934826850891
Epoch: 16, Steps: 261 Train Loss: 3.8382 (Forecasting Loss:0.2891 + XiCon Loss:3.5491 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2517
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.9055972
	speed: 0.0916s/iter; left time: 1999.0517s
	iters: 200, epoch: 17 | loss: 3.9117870
	speed: 0.0905s/iter; left time: 1967.1284s
Epoch: 17 cost time: 23.6320960521698
Epoch: 17, Steps: 261 Train Loss: 3.8410 (Forecasting Loss:0.2889 + XiCon Loss:3.5521 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2517
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17692886292934418, mae:0.32670098543167114, mape:0.6940865516662598, mspe:17.801828384399414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.9650
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.8823173
	speed: 0.0671s/iter; left time: 1743.8649s
	iters: 200, epoch: 1 | loss: 3.8533664
	speed: 0.0740s/iter; left time: 1915.3944s
Epoch: 1 cost time: 18.958261013031006
Epoch: 1, Steps: 261 Train Loss: 3.8999 (Forecasting Loss:0.3697 + XiCon Loss:3.5302 x Lambda(1.0)), Vali MSE Loss: 0.3242 Test MSE Loss: 0.2797
Validation loss decreased (inf --> 0.324240).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6564968
	speed: 0.0814s/iter; left time: 2095.9922s
	iters: 200, epoch: 2 | loss: 3.5858054
	speed: 0.0830s/iter; left time: 2129.0079s
Epoch: 2 cost time: 21.654926538467407
Epoch: 2, Steps: 261 Train Loss: 3.6522 (Forecasting Loss:0.2955 + XiCon Loss:3.3567 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2527
Validation loss decreased (0.324240 --> 0.290681).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6356473
	speed: 0.0843s/iter; left time: 2146.7715s
	iters: 200, epoch: 3 | loss: 3.7752309
	speed: 0.0759s/iter; left time: 1925.8288s
Epoch: 3 cost time: 20.808855056762695
Epoch: 3, Steps: 261 Train Loss: 3.6677 (Forecasting Loss:0.2900 + XiCon Loss:3.3777 x Lambda(1.0)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2585
Validation loss decreased (0.290681 --> 0.279192).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7161250
	speed: 0.0679s/iter; left time: 1713.2724s
	iters: 200, epoch: 4 | loss: 3.7457652
	speed: 0.0839s/iter; left time: 2106.8414s
Epoch: 4 cost time: 18.911994218826294
Epoch: 4, Steps: 261 Train Loss: 3.7158 (Forecasting Loss:0.2868 + XiCon Loss:3.4290 x Lambda(1.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2566
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6715662
	speed: 0.0693s/iter; left time: 1730.3123s
	iters: 200, epoch: 5 | loss: 3.6436868
	speed: 0.0827s/iter; left time: 2054.7427s
Epoch: 5 cost time: 19.60741901397705
Epoch: 5, Steps: 261 Train Loss: 3.6943 (Forecasting Loss:0.2856 + XiCon Loss:3.4087 x Lambda(1.0)), Vali MSE Loss: 0.2783 Test MSE Loss: 0.2556
Validation loss decreased (0.279192 --> 0.278288).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.7078178
	speed: 0.0899s/iter; left time: 2220.9675s
	iters: 200, epoch: 6 | loss: 3.7422628
	speed: 0.0666s/iter; left time: 1638.3403s
Epoch: 6 cost time: 21.135563373565674
Epoch: 6, Steps: 261 Train Loss: 3.6850 (Forecasting Loss:0.2853 + XiCon Loss:3.3998 x Lambda(1.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.2552
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.7580364
	speed: 0.0790s/iter; left time: 1929.4348s
	iters: 200, epoch: 7 | loss: 3.7423248
	speed: 0.0660s/iter; left time: 1606.1764s
Epoch: 7 cost time: 19.276081323623657
Epoch: 7, Steps: 261 Train Loss: 3.6817 (Forecasting Loss:0.2849 + XiCon Loss:3.3968 x Lambda(1.0)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2549
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6496975
	speed: 0.0671s/iter; left time: 1623.2606s
	iters: 200, epoch: 8 | loss: 3.6879525
	speed: 0.0840s/iter; left time: 2022.5172s
Epoch: 8 cost time: 19.296425580978394
Epoch: 8, Steps: 261 Train Loss: 3.6785 (Forecasting Loss:0.2849 + XiCon Loss:3.3936 x Lambda(1.0)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2550
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.7562575
	speed: 0.0636s/iter; left time: 1521.6222s
	iters: 200, epoch: 9 | loss: 3.6194744
	speed: 0.0609s/iter; left time: 1449.6446s
Epoch: 9 cost time: 16.108266353607178
Epoch: 9, Steps: 261 Train Loss: 3.6769 (Forecasting Loss:0.2851 + XiCon Loss:3.3918 x Lambda(1.0)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2549
Validation loss decreased (0.278288 --> 0.278239).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.7015243
	speed: 0.0580s/iter; left time: 1372.4956s
	iters: 200, epoch: 10 | loss: 3.6482048
	speed: 0.0584s/iter; left time: 1374.8297s
Epoch: 10 cost time: 15.12749171257019
Epoch: 10, Steps: 261 Train Loss: 3.6787 (Forecasting Loss:0.2849 + XiCon Loss:3.3938 x Lambda(1.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.2548
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.7163839
	speed: 0.0898s/iter; left time: 2101.3995s
	iters: 200, epoch: 11 | loss: 3.6951966
	speed: 0.0599s/iter; left time: 1394.8032s
Epoch: 11 cost time: 18.780120849609375
Epoch: 11, Steps: 261 Train Loss: 3.6750 (Forecasting Loss:0.2849 + XiCon Loss:3.3901 x Lambda(1.0)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2548
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6702893
	speed: 0.0786s/iter; left time: 1817.7932s
	iters: 200, epoch: 12 | loss: 3.6946940
	speed: 0.0599s/iter; left time: 1378.8787s
Epoch: 12 cost time: 18.79373288154602
Epoch: 12, Steps: 261 Train Loss: 3.6744 (Forecasting Loss:0.2849 + XiCon Loss:3.3895 x Lambda(1.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2548
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6833577
	speed: 0.0683s/iter; left time: 1562.9504s
	iters: 200, epoch: 13 | loss: 3.6593640
	speed: 0.0484s/iter; left time: 1101.5983s
Epoch: 13 cost time: 14.881099224090576
Epoch: 13, Steps: 261 Train Loss: 3.6741 (Forecasting Loss:0.2847 + XiCon Loss:3.3894 x Lambda(1.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2548
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6423435
	speed: 0.0621s/iter; left time: 1404.5744s
	iters: 200, epoch: 14 | loss: 3.6037836
	speed: 0.0606s/iter; left time: 1363.7919s
Epoch: 14 cost time: 17.457721948623657
Epoch: 14, Steps: 261 Train Loss: 3.6743 (Forecasting Loss:0.2847 + XiCon Loss:3.3897 x Lambda(1.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.2548
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6333721
	speed: 0.0607s/iter; left time: 1355.8949s
	iters: 200, epoch: 15 | loss: 3.6776593
	speed: 0.0787s/iter; left time: 1750.6787s
Epoch: 15 cost time: 18.299565076828003
Epoch: 15, Steps: 261 Train Loss: 3.6776 (Forecasting Loss:0.2849 + XiCon Loss:3.3927 x Lambda(1.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2548
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6384077
	speed: 0.0677s/iter; left time: 1495.2531s
	iters: 200, epoch: 16 | loss: 3.7193673
	speed: 0.0771s/iter; left time: 1695.0046s
Epoch: 16 cost time: 17.973172664642334
Epoch: 16, Steps: 261 Train Loss: 3.6773 (Forecasting Loss:0.2848 + XiCon Loss:3.3925 x Lambda(1.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2548
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6410196
	speed: 0.0609s/iter; left time: 1330.1321s
	iters: 200, epoch: 17 | loss: 3.6532278
	speed: 0.0599s/iter; left time: 1300.9966s
Epoch: 17 cost time: 15.608948945999146
Epoch: 17, Steps: 261 Train Loss: 3.6775 (Forecasting Loss:0.2847 + XiCon Loss:3.3928 x Lambda(1.0)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.2548
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6661239
	speed: 0.0530s/iter; left time: 1143.8296s
	iters: 200, epoch: 18 | loss: 3.7140846
	speed: 0.0497s/iter; left time: 1066.9065s
Epoch: 18 cost time: 13.304407596588135
Epoch: 18, Steps: 261 Train Loss: 3.6756 (Forecasting Loss:0.2848 + XiCon Loss:3.3908 x Lambda(1.0)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.2548
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.7462795
	speed: 0.0531s/iter; left time: 1130.6000s
	iters: 200, epoch: 19 | loss: 3.6831737
	speed: 0.0506s/iter; left time: 1073.8772s
Epoch: 19 cost time: 13.483242988586426
Epoch: 19, Steps: 261 Train Loss: 3.6758 (Forecasting Loss:0.2848 + XiCon Loss:3.3910 x Lambda(1.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.2548
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17999862134456635, mae:0.32973602414131165, mape:0.7169455289840698, mspe:19.09053611755371 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 20.6825
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.9164729
	speed: 0.0577s/iter; left time: 1499.5472s
	iters: 200, epoch: 1 | loss: 3.8369107
	speed: 0.0548s/iter; left time: 1419.9273s
Epoch: 1 cost time: 14.524230003356934
Epoch: 1, Steps: 261 Train Loss: 3.8942 (Forecasting Loss:0.3756 + XiCon Loss:3.5186 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2820
Validation loss decreased (inf --> 0.319247).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5993276
	speed: 0.0578s/iter; left time: 1486.5299s
	iters: 200, epoch: 2 | loss: 3.5214281
	speed: 0.0533s/iter; left time: 1366.6657s
Epoch: 2 cost time: 14.385643482208252
Epoch: 2, Steps: 261 Train Loss: 3.6334 (Forecasting Loss:0.3015 + XiCon Loss:3.3319 x Lambda(1.0)), Vali MSE Loss: 0.2855 Test MSE Loss: 0.2486
Validation loss decreased (0.319247 --> 0.285461).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.7202673
	speed: 0.0562s/iter; left time: 1432.2055s
	iters: 200, epoch: 3 | loss: 3.8146000
	speed: 0.0539s/iter; left time: 1367.7970s
Epoch: 3 cost time: 14.49492359161377
Epoch: 3, Steps: 261 Train Loss: 3.7112 (Forecasting Loss:0.2944 + XiCon Loss:3.4168 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2490
Validation loss decreased (0.285461 --> 0.281614).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6590004
	speed: 0.0579s/iter; left time: 1459.1493s
	iters: 200, epoch: 4 | loss: 3.7409027
	speed: 0.0539s/iter; left time: 1354.0226s
Epoch: 4 cost time: 14.418316841125488
Epoch: 4, Steps: 261 Train Loss: 3.6836 (Forecasting Loss:0.2911 + XiCon Loss:3.3926 x Lambda(1.0)), Vali MSE Loss: 0.2788 Test MSE Loss: 0.2480
Validation loss decreased (0.281614 --> 0.278798).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.7116904
	speed: 0.0580s/iter; left time: 1448.5051s
	iters: 200, epoch: 5 | loss: 3.6653838
	speed: 0.0547s/iter; left time: 1360.9050s
Epoch: 5 cost time: 14.617671489715576
Epoch: 5, Steps: 261 Train Loss: 3.6680 (Forecasting Loss:0.2897 + XiCon Loss:3.3783 x Lambda(1.0)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2481
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6572740
	speed: 0.0570s/iter; left time: 1407.6737s
	iters: 200, epoch: 6 | loss: 3.5780330
	speed: 0.0558s/iter; left time: 1373.0920s
Epoch: 6 cost time: 14.690822124481201
Epoch: 6, Steps: 261 Train Loss: 3.6603 (Forecasting Loss:0.2893 + XiCon Loss:3.3711 x Lambda(1.0)), Vali MSE Loss: 0.2776 Test MSE Loss: 0.2471
Validation loss decreased (0.278798 --> 0.277619).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6522844
	speed: 0.0536s/iter; left time: 1308.9304s
	iters: 200, epoch: 7 | loss: 3.6214318
	speed: 0.0907s/iter; left time: 2207.6824s
Epoch: 7 cost time: 19.027112245559692
Epoch: 7, Steps: 261 Train Loss: 3.6557 (Forecasting Loss:0.2890 + XiCon Loss:3.3667 x Lambda(1.0)), Vali MSE Loss: 0.2775 Test MSE Loss: 0.2474
Validation loss decreased (0.277619 --> 0.277521).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6290157
	speed: 0.0502s/iter; left time: 1212.6699s
	iters: 200, epoch: 8 | loss: 3.5943689
	speed: 0.0530s/iter; left time: 1276.7201s
Epoch: 8 cost time: 13.498396873474121
Epoch: 8, Steps: 261 Train Loss: 3.6530 (Forecasting Loss:0.2887 + XiCon Loss:3.3643 x Lambda(1.0)), Vali MSE Loss: 0.2781 Test MSE Loss: 0.2472
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6267700
	speed: 0.0557s/iter; left time: 1331.7930s
	iters: 200, epoch: 9 | loss: 3.6269751
	speed: 0.0527s/iter; left time: 1254.4070s
Epoch: 9 cost time: 14.121873378753662
Epoch: 9, Steps: 261 Train Loss: 3.6541 (Forecasting Loss:0.2887 + XiCon Loss:3.3654 x Lambda(1.0)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.2472
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6592293
	speed: 0.0551s/iter; left time: 1303.2329s
	iters: 200, epoch: 10 | loss: 3.6470127
	speed: 0.0548s/iter; left time: 1289.7242s
Epoch: 10 cost time: 14.359283924102783
Epoch: 10, Steps: 261 Train Loss: 3.6535 (Forecasting Loss:0.2888 + XiCon Loss:3.3647 x Lambda(1.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2473
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6415813
	speed: 0.0574s/iter; left time: 1343.4281s
	iters: 200, epoch: 11 | loss: 3.6052649
	speed: 0.0536s/iter; left time: 1247.2950s
Epoch: 11 cost time: 14.237670183181763
Epoch: 11, Steps: 261 Train Loss: 3.6521 (Forecasting Loss:0.2886 + XiCon Loss:3.3635 x Lambda(1.0)), Vali MSE Loss: 0.2778 Test MSE Loss: 0.2473
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6758559
	speed: 0.0564s/iter; left time: 1305.2070s
	iters: 200, epoch: 12 | loss: 3.6269655
	speed: 0.0515s/iter; left time: 1186.9104s
Epoch: 12 cost time: 14.03675627708435
Epoch: 12, Steps: 261 Train Loss: 3.6524 (Forecasting Loss:0.2888 + XiCon Loss:3.3635 x Lambda(1.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2473
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6221924
	speed: 0.0560s/iter; left time: 1280.8435s
	iters: 200, epoch: 13 | loss: 3.5841196
	speed: 0.0530s/iter; left time: 1206.6585s
Epoch: 13 cost time: 14.21383547782898
Epoch: 13, Steps: 261 Train Loss: 3.6471 (Forecasting Loss:0.2888 + XiCon Loss:3.3583 x Lambda(1.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2473
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6355968
	speed: 0.0560s/iter; left time: 1267.1160s
	iters: 200, epoch: 14 | loss: 3.7032576
	speed: 0.0537s/iter; left time: 1208.7563s
Epoch: 14 cost time: 14.304299592971802
Epoch: 14, Steps: 261 Train Loss: 3.6522 (Forecasting Loss:0.2886 + XiCon Loss:3.3637 x Lambda(1.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2473
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6206808
	speed: 0.0568s/iter; left time: 1269.9745s
	iters: 200, epoch: 15 | loss: 3.6186628
	speed: 0.0547s/iter; left time: 1217.5469s
Epoch: 15 cost time: 14.32198691368103
Epoch: 15, Steps: 261 Train Loss: 3.6516 (Forecasting Loss:0.2887 + XiCon Loss:3.3629 x Lambda(1.0)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.2473
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6752417
	speed: 0.0579s/iter; left time: 1279.0794s
	iters: 200, epoch: 16 | loss: 3.6199636
	speed: 0.0526s/iter; left time: 1156.6697s
Epoch: 16 cost time: 14.333845376968384
Epoch: 16, Steps: 261 Train Loss: 3.6549 (Forecasting Loss:0.2886 + XiCon Loss:3.3663 x Lambda(1.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.2473
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6398199
	speed: 0.0565s/iter; left time: 1234.0387s
	iters: 200, epoch: 17 | loss: 3.6426852
	speed: 0.0544s/iter; left time: 1181.1371s
Epoch: 17 cost time: 14.372567892074585
Epoch: 17, Steps: 261 Train Loss: 3.6486 (Forecasting Loss:0.2887 + XiCon Loss:3.3600 x Lambda(1.0)), Vali MSE Loss: 0.2780 Test MSE Loss: 0.2473
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17207126319408417, mae:0.32265037298202515, mape:0.7284731268882751, mspe:20.465911865234375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1747+-0.00484, MAE:0.3242+-0.00491, MAPE:0.7138+-0.01960, MSPE:19.3070+-1.48063, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
