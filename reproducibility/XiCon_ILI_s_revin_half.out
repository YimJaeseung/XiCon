Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[14], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=14, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3653
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 1.0967810153961182
Epoch: 1, Steps: 38 Train Loss: 2.0329 (Forecasting Loss:0.4215 + XiCon Loss:1.6114 x Lambda(1.0)), Vali MSE Loss: 0.2643 Test MSE Loss: 1.0816
Validation loss decreased (inf --> 0.264314).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.786569356918335
Epoch: 2, Steps: 38 Train Loss: 1.8103 (Forecasting Loss:0.2602 + XiCon Loss:1.5501 x Lambda(1.0)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.5721
Validation loss decreased (0.264314 --> 0.166899).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7106270790100098
Epoch: 3, Steps: 38 Train Loss: 1.6383 (Forecasting Loss:0.1680 + XiCon Loss:1.4703 x Lambda(1.0)), Vali MSE Loss: 0.1206 Test MSE Loss: 0.6192
Validation loss decreased (0.166899 --> 0.120568).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6958029270172119
Epoch: 4, Steps: 38 Train Loss: 1.6023 (Forecasting Loss:0.1351 + XiCon Loss:1.4672 x Lambda(1.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.5853
Validation loss decreased (0.120568 --> 0.109074).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7916064262390137
Epoch: 5, Steps: 38 Train Loss: 1.5859 (Forecasting Loss:0.1297 + XiCon Loss:1.4561 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.5989
Validation loss decreased (0.109074 --> 0.105535).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.8089063167572021
Epoch: 6, Steps: 38 Train Loss: 1.5885 (Forecasting Loss:0.1264 + XiCon Loss:1.4621 x Lambda(1.0)), Vali MSE Loss: 0.1045 Test MSE Loss: 0.5938
Validation loss decreased (0.105535 --> 0.104534).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7821741104125977
Epoch: 7, Steps: 38 Train Loss: 1.5833 (Forecasting Loss:0.1263 + XiCon Loss:1.4570 x Lambda(1.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5902
Validation loss decreased (0.104534 --> 0.104216).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7615766525268555
Epoch: 8, Steps: 38 Train Loss: 1.5682 (Forecasting Loss:0.1248 + XiCon Loss:1.4434 x Lambda(1.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.5896
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7354834079742432
Epoch: 9, Steps: 38 Train Loss: 1.5766 (Forecasting Loss:0.1255 + XiCon Loss:1.4511 x Lambda(1.0)), Vali MSE Loss: 0.1044 Test MSE Loss: 0.5895
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7486476898193359
Epoch: 10, Steps: 38 Train Loss: 1.5651 (Forecasting Loss:0.1253 + XiCon Loss:1.4398 x Lambda(1.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5895
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7599754333496094
Epoch: 11, Steps: 38 Train Loss: 1.5750 (Forecasting Loss:0.1248 + XiCon Loss:1.4502 x Lambda(1.0)), Vali MSE Loss: 0.1031 Test MSE Loss: 0.5893
Validation loss decreased (0.104216 --> 0.103103).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7385492324829102
Epoch: 12, Steps: 38 Train Loss: 1.5769 (Forecasting Loss:0.1242 + XiCon Loss:1.4527 x Lambda(1.0)), Vali MSE Loss: 0.1035 Test MSE Loss: 0.5893
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.727654218673706
Epoch: 13, Steps: 38 Train Loss: 1.5634 (Forecasting Loss:0.1248 + XiCon Loss:1.4386 x Lambda(1.0)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.5893
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7255189418792725
Epoch: 14, Steps: 38 Train Loss: 1.5708 (Forecasting Loss:0.1247 + XiCon Loss:1.4461 x Lambda(1.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5893
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7906558513641357
Epoch: 15, Steps: 38 Train Loss: 1.5768 (Forecasting Loss:0.1250 + XiCon Loss:1.4518 x Lambda(1.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.5893
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7574310302734375
Epoch: 16, Steps: 38 Train Loss: 1.5773 (Forecasting Loss:0.1248 + XiCon Loss:1.4525 x Lambda(1.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.5893
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.767507791519165
Epoch: 17, Steps: 38 Train Loss: 1.5778 (Forecasting Loss:0.1244 + XiCon Loss:1.4534 x Lambda(1.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.5893
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7622923851013184
Epoch: 18, Steps: 38 Train Loss: 1.5736 (Forecasting Loss:0.1238 + XiCon Loss:1.4498 x Lambda(1.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5893
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7070596218109131
Epoch: 19, Steps: 38 Train Loss: 1.5680 (Forecasting Loss:0.1241 + XiCon Loss:1.4439 x Lambda(1.0)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.5893
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7269680500030518
Epoch: 20, Steps: 38 Train Loss: 1.5658 (Forecasting Loss:0.1249 + XiCon Loss:1.4408 x Lambda(1.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.5893
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.773465633392334
Epoch: 21, Steps: 38 Train Loss: 1.5782 (Forecasting Loss:0.1250 + XiCon Loss:1.4532 x Lambda(1.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.5893
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6349667906761169, mae:0.5436818599700928, mape:0.21262887120246887, mspe:0.1787790060043335 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4381
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7141263484954834
Epoch: 1, Steps: 38 Train Loss: 2.1036 (Forecasting Loss:0.4884 + XiCon Loss:1.6152 x Lambda(1.0)), Vali MSE Loss: 0.3031 Test MSE Loss: 1.2880
Validation loss decreased (inf --> 0.303077).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.732231616973877
Epoch: 2, Steps: 38 Train Loss: 1.8353 (Forecasting Loss:0.2648 + XiCon Loss:1.5705 x Lambda(1.0)), Vali MSE Loss: 0.1546 Test MSE Loss: 0.6398
Validation loss decreased (0.303077 --> 0.154564).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7529048919677734
Epoch: 3, Steps: 38 Train Loss: 1.6567 (Forecasting Loss:0.1647 + XiCon Loss:1.4920 x Lambda(1.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6419
Validation loss decreased (0.154564 --> 0.115598).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7272968292236328
Epoch: 4, Steps: 38 Train Loss: 1.5925 (Forecasting Loss:0.1342 + XiCon Loss:1.4584 x Lambda(1.0)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.5995
Validation loss decreased (0.115598 --> 0.110917).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7408463954925537
Epoch: 5, Steps: 38 Train Loss: 1.5812 (Forecasting Loss:0.1271 + XiCon Loss:1.4541 x Lambda(1.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6057
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7256581783294678
Epoch: 6, Steps: 38 Train Loss: 1.5698 (Forecasting Loss:0.1226 + XiCon Loss:1.4472 x Lambda(1.0)), Vali MSE Loss: 0.1093 Test MSE Loss: 0.6104
Validation loss decreased (0.110917 --> 0.109256).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7589983940124512
Epoch: 7, Steps: 38 Train Loss: 1.5715 (Forecasting Loss:0.1231 + XiCon Loss:1.4484 x Lambda(1.0)), Vali MSE Loss: 0.1116 Test MSE Loss: 0.6105
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7480723857879639
Epoch: 8, Steps: 38 Train Loss: 1.5598 (Forecasting Loss:0.1219 + XiCon Loss:1.4379 x Lambda(1.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6102
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7596676349639893
Epoch: 9, Steps: 38 Train Loss: 1.5684 (Forecasting Loss:0.1197 + XiCon Loss:1.4487 x Lambda(1.0)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6114
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7197959423065186
Epoch: 10, Steps: 38 Train Loss: 1.5583 (Forecasting Loss:0.1205 + XiCon Loss:1.4377 x Lambda(1.0)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.6116
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7226569652557373
Epoch: 11, Steps: 38 Train Loss: 1.5572 (Forecasting Loss:0.1215 + XiCon Loss:1.4357 x Lambda(1.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6117
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7102832794189453
Epoch: 12, Steps: 38 Train Loss: 1.5675 (Forecasting Loss:0.1207 + XiCon Loss:1.4468 x Lambda(1.0)), Vali MSE Loss: 0.1102 Test MSE Loss: 0.6119
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7007322311401367
Epoch: 13, Steps: 38 Train Loss: 1.5612 (Forecasting Loss:0.1205 + XiCon Loss:1.4407 x Lambda(1.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.6120
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7433319091796875
Epoch: 14, Steps: 38 Train Loss: 1.5643 (Forecasting Loss:0.1203 + XiCon Loss:1.4441 x Lambda(1.0)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.6120
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7190260887145996
Epoch: 15, Steps: 38 Train Loss: 1.5606 (Forecasting Loss:0.1210 + XiCon Loss:1.4396 x Lambda(1.0)), Vali MSE Loss: 0.1104 Test MSE Loss: 0.6120
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7323379516601562
Epoch: 16, Steps: 38 Train Loss: 1.5641 (Forecasting Loss:0.1197 + XiCon Loss:1.4444 x Lambda(1.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6120
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6763611435890198, mae:0.5444934964179993, mape:0.215544655919075, mspe:0.1946294903755188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4520
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7638998031616211
Epoch: 1, Steps: 38 Train Loss: 2.1024 (Forecasting Loss:0.5018 + XiCon Loss:1.6006 x Lambda(1.0)), Vali MSE Loss: 0.2987 Test MSE Loss: 1.4078
Validation loss decreased (inf --> 0.298749).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7311909198760986
Epoch: 2, Steps: 38 Train Loss: 1.8295 (Forecasting Loss:0.2749 + XiCon Loss:1.5545 x Lambda(1.0)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.6302
Validation loss decreased (0.298749 --> 0.165658).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7495508193969727
Epoch: 3, Steps: 38 Train Loss: 1.6412 (Forecasting Loss:0.1646 + XiCon Loss:1.4766 x Lambda(1.0)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.5757
Validation loss decreased (0.165658 --> 0.116652).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7562086582183838
Epoch: 4, Steps: 38 Train Loss: 1.6027 (Forecasting Loss:0.1364 + XiCon Loss:1.4663 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.6022
Validation loss decreased (0.116652 --> 0.109640).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7139265537261963
Epoch: 5, Steps: 38 Train Loss: 1.5993 (Forecasting Loss:0.1288 + XiCon Loss:1.4705 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6137
Validation loss decreased (0.109640 --> 0.106262).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6888189315795898
Epoch: 6, Steps: 38 Train Loss: 1.5794 (Forecasting Loss:0.1255 + XiCon Loss:1.4539 x Lambda(1.0)), Vali MSE Loss: 0.1063 Test MSE Loss: 0.6029
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7393250465393066
Epoch: 7, Steps: 38 Train Loss: 1.5824 (Forecasting Loss:0.1232 + XiCon Loss:1.4592 x Lambda(1.0)), Vali MSE Loss: 0.1064 Test MSE Loss: 0.6028
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7928812503814697
Epoch: 8, Steps: 38 Train Loss: 1.5793 (Forecasting Loss:0.1224 + XiCon Loss:1.4569 x Lambda(1.0)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.6026
Validation loss decreased (0.106262 --> 0.106160).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7922191619873047
Epoch: 9, Steps: 38 Train Loss: 1.5751 (Forecasting Loss:0.1227 + XiCon Loss:1.4524 x Lambda(1.0)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6035
Validation loss decreased (0.106160 --> 0.105925).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.782360315322876
Epoch: 10, Steps: 38 Train Loss: 1.5825 (Forecasting Loss:0.1220 + XiCon Loss:1.4606 x Lambda(1.0)), Vali MSE Loss: 0.1057 Test MSE Loss: 0.6035
Validation loss decreased (0.105925 --> 0.105655).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.738112211227417
Epoch: 11, Steps: 38 Train Loss: 1.5755 (Forecasting Loss:0.1222 + XiCon Loss:1.4533 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6036
Validation loss decreased (0.105655 --> 0.105543).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7838199138641357
Epoch: 12, Steps: 38 Train Loss: 1.5724 (Forecasting Loss:0.1218 + XiCon Loss:1.4507 x Lambda(1.0)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6037
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7341833114624023
Epoch: 13, Steps: 38 Train Loss: 1.5717 (Forecasting Loss:0.1220 + XiCon Loss:1.4497 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
Validation loss decreased (0.105543 --> 0.105536).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6583998203277588
Epoch: 14, Steps: 38 Train Loss: 1.5911 (Forecasting Loss:0.1218 + XiCon Loss:1.4692 x Lambda(1.0)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.6037
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7333033084869385
Epoch: 15, Steps: 38 Train Loss: 1.5688 (Forecasting Loss:0.1208 + XiCon Loss:1.4480 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
Validation loss decreased (0.105536 --> 0.105519).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.8229546546936035
Epoch: 16, Steps: 38 Train Loss: 1.5755 (Forecasting Loss:0.1217 + XiCon Loss:1.4538 x Lambda(1.0)), Vali MSE Loss: 0.1053 Test MSE Loss: 0.6037
Validation loss decreased (0.105519 --> 0.105309).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7594361305236816
Epoch: 17, Steps: 38 Train Loss: 1.5716 (Forecasting Loss:0.1213 + XiCon Loss:1.4503 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7558817863464355
Epoch: 18, Steps: 38 Train Loss: 1.5669 (Forecasting Loss:0.1221 + XiCon Loss:1.4448 x Lambda(1.0)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.6037
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7466022968292236
Epoch: 19, Steps: 38 Train Loss: 1.5872 (Forecasting Loss:0.1221 + XiCon Loss:1.4651 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7609922885894775
Epoch: 20, Steps: 38 Train Loss: 1.5723 (Forecasting Loss:0.1218 + XiCon Loss:1.4505 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7363276481628418
Epoch: 21, Steps: 38 Train Loss: 1.5622 (Forecasting Loss:0.1217 + XiCon Loss:1.4404 x Lambda(1.0)), Vali MSE Loss: 0.1054 Test MSE Loss: 0.6037
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6684505939483643
Epoch: 22, Steps: 38 Train Loss: 1.5665 (Forecasting Loss:0.1218 + XiCon Loss:1.4447 x Lambda(1.0)), Vali MSE Loss: 0.1060 Test MSE Loss: 0.6037
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7364225387573242
Epoch: 23, Steps: 38 Train Loss: 1.5741 (Forecasting Loss:0.1222 + XiCon Loss:1.4519 x Lambda(1.0)), Vali MSE Loss: 0.1056 Test MSE Loss: 0.6037
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7465226650238037
Epoch: 24, Steps: 38 Train Loss: 1.5787 (Forecasting Loss:0.1221 + XiCon Loss:1.4566 x Lambda(1.0)), Vali MSE Loss: 0.1049 Test MSE Loss: 0.6037
Validation loss decreased (0.105309 --> 0.104905).  Saving model ...
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7942750453948975
Epoch: 25, Steps: 38 Train Loss: 1.5718 (Forecasting Loss:0.1216 + XiCon Loss:1.4502 x Lambda(1.0)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6037
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7659502029418945
Epoch: 26, Steps: 38 Train Loss: 1.5673 (Forecasting Loss:0.1209 + XiCon Loss:1.4464 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7643804550170898
Epoch: 27, Steps: 38 Train Loss: 1.5772 (Forecasting Loss:0.1213 + XiCon Loss:1.4559 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6037
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7391018867492676
Epoch: 28, Steps: 38 Train Loss: 1.5806 (Forecasting Loss:0.1224 + XiCon Loss:1.4582 x Lambda(1.0)), Vali MSE Loss: 0.1056 Test MSE Loss: 0.6037
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7683835029602051
Epoch: 29, Steps: 38 Train Loss: 1.5738 (Forecasting Loss:0.1215 + XiCon Loss:1.4523 x Lambda(1.0)), Vali MSE Loss: 0.1052 Test MSE Loss: 0.6037
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7783024311065674
Epoch: 30, Steps: 38 Train Loss: 1.5730 (Forecasting Loss:0.1217 + XiCon Loss:1.4513 x Lambda(1.0)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6037
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7193050384521484
Epoch: 31, Steps: 38 Train Loss: 1.5649 (Forecasting Loss:0.1214 + XiCon Loss:1.4435 x Lambda(1.0)), Vali MSE Loss: 0.1053 Test MSE Loss: 0.6037
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.7632400989532471
Epoch: 32, Steps: 38 Train Loss: 1.5906 (Forecasting Loss:0.1217 + XiCon Loss:1.4690 x Lambda(1.0)), Vali MSE Loss: 0.1057 Test MSE Loss: 0.6037
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.7736392021179199
Epoch: 33, Steps: 38 Train Loss: 1.5764 (Forecasting Loss:0.1219 + XiCon Loss:1.4545 x Lambda(1.0)), Vali MSE Loss: 0.1059 Test MSE Loss: 0.6037
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.820775032043457
Epoch: 34, Steps: 38 Train Loss: 1.5760 (Forecasting Loss:0.1208 + XiCon Loss:1.4551 x Lambda(1.0)), Vali MSE Loss: 0.1054 Test MSE Loss: 0.6037
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6566457152366638, mae:0.5507864356040955, mape:0.2157619446516037, mspe:0.18300631642341614 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4766
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7975659370422363
Epoch: 1, Steps: 38 Train Loss: 2.1412 (Forecasting Loss:0.5306 + XiCon Loss:1.6106 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 1.3653
Validation loss decreased (inf --> 0.331648).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.8593864440917969
Epoch: 2, Steps: 38 Train Loss: 1.8336 (Forecasting Loss:0.2768 + XiCon Loss:1.5568 x Lambda(1.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.6031
Validation loss decreased (0.331648 --> 0.161972).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6487259864807129
Epoch: 3, Steps: 38 Train Loss: 1.6203 (Forecasting Loss:0.1666 + XiCon Loss:1.4536 x Lambda(1.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6216
Validation loss decreased (0.161972 --> 0.114792).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7634541988372803
Epoch: 4, Steps: 38 Train Loss: 1.5793 (Forecasting Loss:0.1357 + XiCon Loss:1.4436 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.6083
Validation loss decreased (0.114792 --> 0.108379).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7705264091491699
Epoch: 5, Steps: 38 Train Loss: 1.5785 (Forecasting Loss:0.1284 + XiCon Loss:1.4500 x Lambda(1.0)), Vali MSE Loss: 0.1061 Test MSE Loss: 0.6170
Validation loss decreased (0.108379 --> 0.106106).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7430636882781982
Epoch: 6, Steps: 38 Train Loss: 1.5630 (Forecasting Loss:0.1257 + XiCon Loss:1.4373 x Lambda(1.0)), Vali MSE Loss: 0.1056 Test MSE Loss: 0.6157
Validation loss decreased (0.106106 --> 0.105561).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7436873912811279
Epoch: 7, Steps: 38 Train Loss: 1.5697 (Forecasting Loss:0.1239 + XiCon Loss:1.4459 x Lambda(1.0)), Vali MSE Loss: 0.1055 Test MSE Loss: 0.6082
Validation loss decreased (0.105561 --> 0.105471).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7665081024169922
Epoch: 8, Steps: 38 Train Loss: 1.5550 (Forecasting Loss:0.1236 + XiCon Loss:1.4313 x Lambda(1.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.6089
Validation loss decreased (0.105471 --> 0.104840).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7843747138977051
Epoch: 9, Steps: 38 Train Loss: 1.5550 (Forecasting Loss:0.1236 + XiCon Loss:1.4315 x Lambda(1.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.6091
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7754521369934082
Epoch: 10, Steps: 38 Train Loss: 1.5627 (Forecasting Loss:0.1224 + XiCon Loss:1.4403 x Lambda(1.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.6090
Validation loss decreased (0.104840 --> 0.104830).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7339529991149902
Epoch: 11, Steps: 38 Train Loss: 1.5637 (Forecasting Loss:0.1220 + XiCon Loss:1.4418 x Lambda(1.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.6095
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7547285556793213
Epoch: 12, Steps: 38 Train Loss: 1.5624 (Forecasting Loss:0.1230 + XiCon Loss:1.4394 x Lambda(1.0)), Vali MSE Loss: 0.1047 Test MSE Loss: 0.6096
Validation loss decreased (0.104830 --> 0.104697).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7719008922576904
Epoch: 13, Steps: 38 Train Loss: 1.5696 (Forecasting Loss:0.1229 + XiCon Loss:1.4467 x Lambda(1.0)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.6097
Validation loss decreased (0.104697 --> 0.103981).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7640867233276367
Epoch: 14, Steps: 38 Train Loss: 1.5662 (Forecasting Loss:0.1221 + XiCon Loss:1.4441 x Lambda(1.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.6097
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.8015828132629395
Epoch: 15, Steps: 38 Train Loss: 1.5597 (Forecasting Loss:0.1231 + XiCon Loss:1.4366 x Lambda(1.0)), Vali MSE Loss: 0.1049 Test MSE Loss: 0.6097
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7442800998687744
Epoch: 16, Steps: 38 Train Loss: 1.5589 (Forecasting Loss:0.1216 + XiCon Loss:1.4373 x Lambda(1.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.6097
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7716567516326904
Epoch: 17, Steps: 38 Train Loss: 1.5683 (Forecasting Loss:0.1211 + XiCon Loss:1.4472 x Lambda(1.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.6097
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7496826648712158
Epoch: 18, Steps: 38 Train Loss: 1.5555 (Forecasting Loss:0.1226 + XiCon Loss:1.4329 x Lambda(1.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6097
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.771209716796875
Epoch: 19, Steps: 38 Train Loss: 1.5699 (Forecasting Loss:0.1233 + XiCon Loss:1.4466 x Lambda(1.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.6097
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6870138645172119
Epoch: 20, Steps: 38 Train Loss: 1.5613 (Forecasting Loss:0.1218 + XiCon Loss:1.4395 x Lambda(1.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.6097
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7948198318481445
Epoch: 21, Steps: 38 Train Loss: 1.5577 (Forecasting Loss:0.1225 + XiCon Loss:1.4353 x Lambda(1.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.6097
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7587032318115234
Epoch: 22, Steps: 38 Train Loss: 1.5591 (Forecasting Loss:0.1229 + XiCon Loss:1.4362 x Lambda(1.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6097
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7365624904632568
Epoch: 23, Steps: 38 Train Loss: 1.5625 (Forecasting Loss:0.1234 + XiCon Loss:1.4391 x Lambda(1.0)), Vali MSE Loss: 0.1046 Test MSE Loss: 0.6097
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.670746922492981, mae:0.5485600829124451, mape:0.21499495208263397, mspe:0.1879100203514099 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4389
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7436389923095703
Epoch: 1, Steps: 38 Train Loss: 2.0983 (Forecasting Loss:0.4972 + XiCon Loss:1.6011 x Lambda(1.0)), Vali MSE Loss: 0.2770 Test MSE Loss: 1.4598
Validation loss decreased (inf --> 0.277033).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7606432437896729
Epoch: 2, Steps: 38 Train Loss: 1.8088 (Forecasting Loss:0.2603 + XiCon Loss:1.5485 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.6344
Validation loss decreased (0.277033 --> 0.144243).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7451670169830322
Epoch: 3, Steps: 38 Train Loss: 1.6312 (Forecasting Loss:0.1549 + XiCon Loss:1.4762 x Lambda(1.0)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.6274
Validation loss decreased (0.144243 --> 0.123629).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7487242221832275
Epoch: 4, Steps: 38 Train Loss: 1.5717 (Forecasting Loss:0.1259 + XiCon Loss:1.4458 x Lambda(1.0)), Vali MSE Loss: 0.1185 Test MSE Loss: 0.6575
Validation loss decreased (0.123629 --> 0.118523).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7585811614990234
Epoch: 5, Steps: 38 Train Loss: 1.5485 (Forecasting Loss:0.1184 + XiCon Loss:1.4301 x Lambda(1.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6367
Validation loss decreased (0.118523 --> 0.114816).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7974872589111328
Epoch: 6, Steps: 38 Train Loss: 1.5399 (Forecasting Loss:0.1160 + XiCon Loss:1.4240 x Lambda(1.0)), Vali MSE Loss: 0.1127 Test MSE Loss: 0.6429
Validation loss decreased (0.114816 --> 0.112664).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7742767333984375
Epoch: 7, Steps: 38 Train Loss: 1.5450 (Forecasting Loss:0.1134 + XiCon Loss:1.4316 x Lambda(1.0)), Vali MSE Loss: 0.1155 Test MSE Loss: 0.6429
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.8266386985778809
Epoch: 8, Steps: 38 Train Loss: 1.5258 (Forecasting Loss:0.1119 + XiCon Loss:1.4139 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6436
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7539205551147461
Epoch: 9, Steps: 38 Train Loss: 1.5229 (Forecasting Loss:0.1111 + XiCon Loss:1.4118 x Lambda(1.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6443
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.8062939643859863
Epoch: 10, Steps: 38 Train Loss: 1.5321 (Forecasting Loss:0.1111 + XiCon Loss:1.4210 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6445
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7654552459716797
Epoch: 11, Steps: 38 Train Loss: 1.5197 (Forecasting Loss:0.1112 + XiCon Loss:1.4085 x Lambda(1.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6451
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7269577980041504
Epoch: 12, Steps: 38 Train Loss: 1.5209 (Forecasting Loss:0.1094 + XiCon Loss:1.4115 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6451
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7421965599060059
Epoch: 13, Steps: 38 Train Loss: 1.5272 (Forecasting Loss:0.1096 + XiCon Loss:1.4176 x Lambda(1.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6450
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7425076961517334
Epoch: 14, Steps: 38 Train Loss: 1.5280 (Forecasting Loss:0.1100 + XiCon Loss:1.4180 x Lambda(1.0)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.6450
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7551310062408447
Epoch: 15, Steps: 38 Train Loss: 1.5377 (Forecasting Loss:0.1097 + XiCon Loss:1.4280 x Lambda(1.0)), Vali MSE Loss: 0.1150 Test MSE Loss: 0.6450
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7431559562683105
Epoch: 16, Steps: 38 Train Loss: 1.5255 (Forecasting Loss:0.1101 + XiCon Loss:1.4155 x Lambda(1.0)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.6450
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.7224503755569458, mae:0.5633664727210999, mape:0.21802659332752228, mspe:0.19155770540237427 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6722+-0.04010, MAE:0.5502+-0.00984, MAPE:0.2154+-0.00240, MSPE:0.1872+-0.00793, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[28], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=28, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2986
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 1.047057867050171
Epoch: 1, Steps: 37 Train Loss: 16.5932 (Forecasting Loss:0.4943 + XiCon Loss:1.6099 x Lambda(10.0)), Vali MSE Loss: 0.3095 Test MSE Loss: 1.2471
Validation loss decreased (inf --> 0.309475).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7327892780303955
Epoch: 2, Steps: 37 Train Loss: 15.6535 (Forecasting Loss:0.3076 + XiCon Loss:1.5346 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.7379
Validation loss decreased (0.309475 --> 0.202261).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7518267631530762
Epoch: 3, Steps: 37 Train Loss: 14.8317 (Forecasting Loss:0.2017 + XiCon Loss:1.4630 x Lambda(10.0)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.7464
Validation loss decreased (0.202261 --> 0.123476).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7562274932861328
Epoch: 4, Steps: 37 Train Loss: 14.7541 (Forecasting Loss:0.1554 + XiCon Loss:1.4599 x Lambda(10.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6796
Validation loss decreased (0.123476 --> 0.115715).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7251768112182617
Epoch: 5, Steps: 37 Train Loss: 14.7778 (Forecasting Loss:0.1477 + XiCon Loss:1.4630 x Lambda(10.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6716
Validation loss decreased (0.115715 --> 0.115705).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7569928169250488
Epoch: 6, Steps: 37 Train Loss: 14.6584 (Forecasting Loss:0.1454 + XiCon Loss:1.4513 x Lambda(10.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6633
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.753117561340332
Epoch: 7, Steps: 37 Train Loss: 14.6217 (Forecasting Loss:0.1432 + XiCon Loss:1.4479 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6682
Validation loss decreased (0.115705 --> 0.113169).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.750312089920044
Epoch: 8, Steps: 37 Train Loss: 14.6503 (Forecasting Loss:0.1442 + XiCon Loss:1.4506 x Lambda(10.0)), Vali MSE Loss: 0.1131 Test MSE Loss: 0.6709
Validation loss decreased (0.113169 --> 0.113105).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7183241844177246
Epoch: 9, Steps: 37 Train Loss: 14.5945 (Forecasting Loss:0.1429 + XiCon Loss:1.4452 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6712
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7282543182373047
Epoch: 10, Steps: 37 Train Loss: 14.6393 (Forecasting Loss:0.1433 + XiCon Loss:1.4496 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6718
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7499701976776123
Epoch: 11, Steps: 37 Train Loss: 14.6047 (Forecasting Loss:0.1428 + XiCon Loss:1.4462 x Lambda(10.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6720
Validation loss decreased (0.113105 --> 0.112973).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7346985340118408
Epoch: 12, Steps: 37 Train Loss: 14.6192 (Forecasting Loss:0.1434 + XiCon Loss:1.4476 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7337815761566162
Epoch: 13, Steps: 37 Train Loss: 14.5901 (Forecasting Loss:0.1422 + XiCon Loss:1.4448 x Lambda(10.0)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.6720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7892239093780518
Epoch: 14, Steps: 37 Train Loss: 14.6801 (Forecasting Loss:0.1428 + XiCon Loss:1.4537 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6721
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7475972175598145
Epoch: 15, Steps: 37 Train Loss: 14.6422 (Forecasting Loss:0.1434 + XiCon Loss:1.4499 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6721
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7436022758483887
Epoch: 16, Steps: 37 Train Loss: 14.6448 (Forecasting Loss:0.1416 + XiCon Loss:1.4503 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6721
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7273209095001221
Epoch: 17, Steps: 37 Train Loss: 14.6124 (Forecasting Loss:0.1418 + XiCon Loss:1.4471 x Lambda(10.0)), Vali MSE Loss: 0.1138 Test MSE Loss: 0.6721
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.744879961013794
Epoch: 18, Steps: 37 Train Loss: 14.6005 (Forecasting Loss:0.1439 + XiCon Loss:1.4457 x Lambda(10.0)), Vali MSE Loss: 0.1116 Test MSE Loss: 0.6721
Validation loss decreased (0.112973 --> 0.111628).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7629060745239258
Epoch: 19, Steps: 37 Train Loss: 14.6175 (Forecasting Loss:0.1435 + XiCon Loss:1.4474 x Lambda(10.0)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.6721
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7677211761474609
Epoch: 20, Steps: 37 Train Loss: 14.5845 (Forecasting Loss:0.1435 + XiCon Loss:1.4441 x Lambda(10.0)), Vali MSE Loss: 0.1154 Test MSE Loss: 0.6721
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7719399929046631
Epoch: 21, Steps: 37 Train Loss: 14.7520 (Forecasting Loss:0.1429 + XiCon Loss:1.4609 x Lambda(10.0)), Vali MSE Loss: 0.1146 Test MSE Loss: 0.6721
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7457301616668701
Epoch: 22, Steps: 37 Train Loss: 14.6389 (Forecasting Loss:0.1432 + XiCon Loss:1.4496 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6721
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7506527900695801
Epoch: 23, Steps: 37 Train Loss: 14.6688 (Forecasting Loss:0.1436 + XiCon Loss:1.4525 x Lambda(10.0)), Vali MSE Loss: 0.1123 Test MSE Loss: 0.6721
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7154331207275391
Epoch: 24, Steps: 37 Train Loss: 14.6398 (Forecasting Loss:0.1433 + XiCon Loss:1.4496 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6721
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6516506671905518
Epoch: 25, Steps: 37 Train Loss: 14.6109 (Forecasting Loss:0.1422 + XiCon Loss:1.4469 x Lambda(10.0)), Vali MSE Loss: 0.1129 Test MSE Loss: 0.6721
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7382361888885498
Epoch: 26, Steps: 37 Train Loss: 14.6120 (Forecasting Loss:0.1430 + XiCon Loss:1.4469 x Lambda(10.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6721
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7656707763671875
Epoch: 27, Steps: 37 Train Loss: 14.6600 (Forecasting Loss:0.1428 + XiCon Loss:1.4517 x Lambda(10.0)), Vali MSE Loss: 0.1126 Test MSE Loss: 0.6721
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7041823863983154
Epoch: 28, Steps: 37 Train Loss: 14.6482 (Forecasting Loss:0.1432 + XiCon Loss:1.4505 x Lambda(10.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6721
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7264130711555481, mae:0.6177353858947754, mape:0.24357235431671143, mspe:0.20397381484508514 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4911
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7758276462554932
Epoch: 1, Steps: 37 Train Loss: 16.4562 (Forecasting Loss:0.4602 + XiCon Loss:1.5996 x Lambda(10.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 1.2219
Validation loss decreased (inf --> 0.296758).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7521588802337646
Epoch: 2, Steps: 37 Train Loss: 15.6108 (Forecasting Loss:0.2974 + XiCon Loss:1.5313 x Lambda(10.0)), Vali MSE Loss: 0.1626 Test MSE Loss: 0.7222
Validation loss decreased (0.296758 --> 0.162598).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7089765071868896
Epoch: 3, Steps: 37 Train Loss: 14.9343 (Forecasting Loss:0.1783 + XiCon Loss:1.4756 x Lambda(10.0)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.7081
Validation loss decreased (0.162598 --> 0.123562).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7693264484405518
Epoch: 4, Steps: 37 Train Loss: 14.8003 (Forecasting Loss:0.1521 + XiCon Loss:1.4648 x Lambda(10.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6557
Validation loss decreased (0.123562 --> 0.117921).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7405624389648438
Epoch: 5, Steps: 37 Train Loss: 14.6247 (Forecasting Loss:0.1476 + XiCon Loss:1.4477 x Lambda(10.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6654
Validation loss decreased (0.117921 --> 0.114879).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7182962894439697
Epoch: 6, Steps: 37 Train Loss: 14.6550 (Forecasting Loss:0.1439 + XiCon Loss:1.4511 x Lambda(10.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6694
Validation loss decreased (0.114879 --> 0.114487).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7122583389282227
Epoch: 7, Steps: 37 Train Loss: 14.7087 (Forecasting Loss:0.1440 + XiCon Loss:1.4565 x Lambda(10.0)), Vali MSE Loss: 0.1122 Test MSE Loss: 0.6683
Validation loss decreased (0.114487 --> 0.112243).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7277014255523682
Epoch: 8, Steps: 37 Train Loss: 14.6607 (Forecasting Loss:0.1429 + XiCon Loss:1.4518 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6686
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7333145141601562
Epoch: 9, Steps: 37 Train Loss: 14.6356 (Forecasting Loss:0.1421 + XiCon Loss:1.4494 x Lambda(10.0)), Vali MSE Loss: 0.1115 Test MSE Loss: 0.6685
Validation loss decreased (0.112243 --> 0.111547).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7672417163848877
Epoch: 10, Steps: 37 Train Loss: 14.6612 (Forecasting Loss:0.1426 + XiCon Loss:1.4519 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6688
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7802696228027344
Epoch: 11, Steps: 37 Train Loss: 14.5663 (Forecasting Loss:0.1430 + XiCon Loss:1.4423 x Lambda(10.0)), Vali MSE Loss: 0.1131 Test MSE Loss: 0.6691
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7189254760742188
Epoch: 12, Steps: 37 Train Loss: 14.6087 (Forecasting Loss:0.1423 + XiCon Loss:1.4466 x Lambda(10.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6690
Validation loss decreased (0.111547 --> 0.110656).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7346940040588379
Epoch: 13, Steps: 37 Train Loss: 14.5632 (Forecasting Loss:0.1422 + XiCon Loss:1.4421 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7301025390625
Epoch: 14, Steps: 37 Train Loss: 14.6034 (Forecasting Loss:0.1423 + XiCon Loss:1.4461 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6690
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7673699855804443
Epoch: 15, Steps: 37 Train Loss: 14.6467 (Forecasting Loss:0.1425 + XiCon Loss:1.4504 x Lambda(10.0)), Vali MSE Loss: 0.1120 Test MSE Loss: 0.6690
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7406291961669922
Epoch: 16, Steps: 37 Train Loss: 14.7425 (Forecasting Loss:0.1404 + XiCon Loss:1.4602 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6690
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7686328887939453
Epoch: 17, Steps: 37 Train Loss: 14.6298 (Forecasting Loss:0.1432 + XiCon Loss:1.4487 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6690
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7482671737670898
Epoch: 18, Steps: 37 Train Loss: 14.7179 (Forecasting Loss:0.1431 + XiCon Loss:1.4575 x Lambda(10.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6690
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7097563743591309
Epoch: 19, Steps: 37 Train Loss: 14.7319 (Forecasting Loss:0.1431 + XiCon Loss:1.4589 x Lambda(10.0)), Vali MSE Loss: 0.1129 Test MSE Loss: 0.6690
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7589795589447021
Epoch: 20, Steps: 37 Train Loss: 14.6617 (Forecasting Loss:0.1429 + XiCon Loss:1.4519 x Lambda(10.0)), Vali MSE Loss: 0.1134 Test MSE Loss: 0.6690
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6855032444000244
Epoch: 21, Steps: 37 Train Loss: 14.6905 (Forecasting Loss:0.1429 + XiCon Loss:1.4548 x Lambda(10.0)), Vali MSE Loss: 0.1125 Test MSE Loss: 0.6690
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7471375465393066
Epoch: 22, Steps: 37 Train Loss: 14.6217 (Forecasting Loss:0.1428 + XiCon Loss:1.4479 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6690
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7180222272872925, mae:0.6199744939804077, mape:0.24472461640834808, mspe:0.20540879666805267 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4669
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7339260578155518
Epoch: 1, Steps: 37 Train Loss: 16.5649 (Forecasting Loss:0.5340 + XiCon Loss:1.6031 x Lambda(10.0)), Vali MSE Loss: 0.3161 Test MSE Loss: 1.3993
Validation loss decreased (inf --> 0.316147).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7605433464050293
Epoch: 2, Steps: 37 Train Loss: 15.8406 (Forecasting Loss:0.3283 + XiCon Loss:1.5512 x Lambda(10.0)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.6876
Validation loss decreased (0.316147 --> 0.186871).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7572886943817139
Epoch: 3, Steps: 37 Train Loss: 14.6237 (Forecasting Loss:0.1899 + XiCon Loss:1.4434 x Lambda(10.0)), Vali MSE Loss: 0.1316 Test MSE Loss: 0.7205
Validation loss decreased (0.186871 --> 0.131597).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.789811372756958
Epoch: 4, Steps: 37 Train Loss: 14.2712 (Forecasting Loss:0.1587 + XiCon Loss:1.4112 x Lambda(10.0)), Vali MSE Loss: 0.1241 Test MSE Loss: 0.6379
Validation loss decreased (0.131597 --> 0.124141).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7787609100341797
Epoch: 5, Steps: 37 Train Loss: 14.0674 (Forecasting Loss:0.1503 + XiCon Loss:1.3917 x Lambda(10.0)), Vali MSE Loss: 0.1201 Test MSE Loss: 0.6548
Validation loss decreased (0.124141 --> 0.120114).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7374224662780762
Epoch: 6, Steps: 37 Train Loss: 13.9784 (Forecasting Loss:0.1479 + XiCon Loss:1.3831 x Lambda(10.0)), Vali MSE Loss: 0.1173 Test MSE Loss: 0.6747
Validation loss decreased (0.120114 --> 0.117327).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6882953643798828
Epoch: 7, Steps: 37 Train Loss: 13.8340 (Forecasting Loss:0.1454 + XiCon Loss:1.3689 x Lambda(10.0)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6708
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7463340759277344
Epoch: 8, Steps: 37 Train Loss: 13.8902 (Forecasting Loss:0.1451 + XiCon Loss:1.3745 x Lambda(10.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6688
Validation loss decreased (0.117327 --> 0.115277).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7926585674285889
Epoch: 9, Steps: 37 Train Loss: 13.8562 (Forecasting Loss:0.1462 + XiCon Loss:1.3710 x Lambda(10.0)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6680
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7293045520782471
Epoch: 10, Steps: 37 Train Loss: 13.9196 (Forecasting Loss:0.1425 + XiCon Loss:1.3777 x Lambda(10.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7506115436553955
Epoch: 11, Steps: 37 Train Loss: 13.9216 (Forecasting Loss:0.1456 + XiCon Loss:1.3776 x Lambda(10.0)), Vali MSE Loss: 0.1175 Test MSE Loss: 0.6673
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7630751132965088
Epoch: 12, Steps: 37 Train Loss: 13.9518 (Forecasting Loss:0.1435 + XiCon Loss:1.3808 x Lambda(10.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6671
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7946712970733643
Epoch: 13, Steps: 37 Train Loss: 13.9479 (Forecasting Loss:0.1446 + XiCon Loss:1.3803 x Lambda(10.0)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.6670
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7577328681945801
Epoch: 14, Steps: 37 Train Loss: 13.8875 (Forecasting Loss:0.1433 + XiCon Loss:1.3744 x Lambda(10.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6669
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.674830436706543
Epoch: 15, Steps: 37 Train Loss: 13.8665 (Forecasting Loss:0.1446 + XiCon Loss:1.3722 x Lambda(10.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6669
Validation loss decreased (0.115277 --> 0.115087).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7158560752868652
Epoch: 16, Steps: 37 Train Loss: 13.9210 (Forecasting Loss:0.1438 + XiCon Loss:1.3777 x Lambda(10.0)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.6669
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.9668159484863281
Epoch: 17, Steps: 37 Train Loss: 13.9512 (Forecasting Loss:0.1440 + XiCon Loss:1.3807 x Lambda(10.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6669
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.8176519870758057
Epoch: 18, Steps: 37 Train Loss: 13.8712 (Forecasting Loss:0.1449 + XiCon Loss:1.3726 x Lambda(10.0)), Vali MSE Loss: 0.1182 Test MSE Loss: 0.6669
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 1.2274835109710693
Epoch: 19, Steps: 37 Train Loss: 13.9448 (Forecasting Loss:0.1445 + XiCon Loss:1.3800 x Lambda(10.0)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6669
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 1.0084762573242188
Epoch: 20, Steps: 37 Train Loss: 13.9509 (Forecasting Loss:0.1443 + XiCon Loss:1.3807 x Lambda(10.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6669
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.8946177959442139
Epoch: 21, Steps: 37 Train Loss: 13.9326 (Forecasting Loss:0.1439 + XiCon Loss:1.3789 x Lambda(10.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6669
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.9056487083435059
Epoch: 22, Steps: 37 Train Loss: 13.9715 (Forecasting Loss:0.1437 + XiCon Loss:1.3828 x Lambda(10.0)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6669
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.9000544548034668
Epoch: 23, Steps: 37 Train Loss: 13.9828 (Forecasting Loss:0.1443 + XiCon Loss:1.3839 x Lambda(10.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6669
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.8496432304382324
Epoch: 24, Steps: 37 Train Loss: 13.9186 (Forecasting Loss:0.1434 + XiCon Loss:1.3775 x Lambda(10.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6669
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7411015033721924
Epoch: 25, Steps: 37 Train Loss: 13.8934 (Forecasting Loss:0.1441 + XiCon Loss:1.3749 x Lambda(10.0)), Vali MSE Loss: 0.1168 Test MSE Loss: 0.6669
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7219395041465759, mae:0.6119228601455688, mape:0.24260924756526947, mspe:0.20815257728099823 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4059
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7264235019683838
Epoch: 1, Steps: 37 Train Loss: 16.4952 (Forecasting Loss:0.5384 + XiCon Loss:1.5957 x Lambda(10.0)), Vali MSE Loss: 0.3176 Test MSE Loss: 1.4634
Validation loss decreased (inf --> 0.317635).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6598765850067139
Epoch: 2, Steps: 37 Train Loss: 15.5198 (Forecasting Loss:0.3210 + XiCon Loss:1.5199 x Lambda(10.0)), Vali MSE Loss: 0.1766 Test MSE Loss: 0.7465
Validation loss decreased (0.317635 --> 0.176640).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.9564809799194336
Epoch: 3, Steps: 37 Train Loss: 14.8320 (Forecasting Loss:0.1903 + XiCon Loss:1.4642 x Lambda(10.0)), Vali MSE Loss: 0.1320 Test MSE Loss: 0.6736
Validation loss decreased (0.176640 --> 0.131997).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.855025053024292
Epoch: 4, Steps: 37 Train Loss: 14.5012 (Forecasting Loss:0.1574 + XiCon Loss:1.4344 x Lambda(10.0)), Vali MSE Loss: 0.1185 Test MSE Loss: 0.6687
Validation loss decreased (0.131997 --> 0.118465).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7755715847015381
Epoch: 5, Steps: 37 Train Loss: 14.4299 (Forecasting Loss:0.1491 + XiCon Loss:1.4281 x Lambda(10.0)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6590
Validation loss decreased (0.118465 --> 0.116141).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.742603063583374
Epoch: 6, Steps: 37 Train Loss: 14.2828 (Forecasting Loss:0.1440 + XiCon Loss:1.4139 x Lambda(10.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7347996234893799
Epoch: 7, Steps: 37 Train Loss: 14.3631 (Forecasting Loss:0.1437 + XiCon Loss:1.4219 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6572
Validation loss decreased (0.116141 --> 0.114005).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7450165748596191
Epoch: 8, Steps: 37 Train Loss: 14.2673 (Forecasting Loss:0.1435 + XiCon Loss:1.4124 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6647
Validation loss decreased (0.114005 --> 0.113212).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7826502323150635
Epoch: 9, Steps: 37 Train Loss: 14.3730 (Forecasting Loss:0.1424 + XiCon Loss:1.4231 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6631
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7807002067565918
Epoch: 10, Steps: 37 Train Loss: 14.1602 (Forecasting Loss:0.1422 + XiCon Loss:1.4018 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6620
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7329957485198975
Epoch: 11, Steps: 37 Train Loss: 14.2015 (Forecasting Loss:0.1414 + XiCon Loss:1.4060 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6622
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7013649940490723
Epoch: 12, Steps: 37 Train Loss: 14.2302 (Forecasting Loss:0.1424 + XiCon Loss:1.4088 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6619
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7291061878204346
Epoch: 13, Steps: 37 Train Loss: 14.2435 (Forecasting Loss:0.1409 + XiCon Loss:1.4103 x Lambda(10.0)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.6618
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7757575511932373
Epoch: 14, Steps: 37 Train Loss: 14.2876 (Forecasting Loss:0.1417 + XiCon Loss:1.4146 x Lambda(10.0)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.6618
Validation loss decreased (0.113212 --> 0.111693).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7833676338195801
Epoch: 15, Steps: 37 Train Loss: 14.2747 (Forecasting Loss:0.1420 + XiCon Loss:1.4133 x Lambda(10.0)), Vali MSE Loss: 0.1121 Test MSE Loss: 0.6619
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7755768299102783
Epoch: 16, Steps: 37 Train Loss: 14.1564 (Forecasting Loss:0.1415 + XiCon Loss:1.4015 x Lambda(10.0)), Vali MSE Loss: 0.1120 Test MSE Loss: 0.6619
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7292366027832031
Epoch: 17, Steps: 37 Train Loss: 14.2610 (Forecasting Loss:0.1421 + XiCon Loss:1.4119 x Lambda(10.0)), Vali MSE Loss: 0.1128 Test MSE Loss: 0.6619
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7210648059844971
Epoch: 18, Steps: 37 Train Loss: 14.1966 (Forecasting Loss:0.1419 + XiCon Loss:1.4055 x Lambda(10.0)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6619
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7720592021942139
Epoch: 19, Steps: 37 Train Loss: 14.1886 (Forecasting Loss:0.1429 + XiCon Loss:1.4046 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6619
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.736722469329834
Epoch: 20, Steps: 37 Train Loss: 14.2002 (Forecasting Loss:0.1414 + XiCon Loss:1.4059 x Lambda(10.0)), Vali MSE Loss: 0.1134 Test MSE Loss: 0.6619
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7184960842132568
Epoch: 21, Steps: 37 Train Loss: 14.1871 (Forecasting Loss:0.1425 + XiCon Loss:1.4045 x Lambda(10.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6619
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7542669773101807
Epoch: 22, Steps: 37 Train Loss: 14.3326 (Forecasting Loss:0.1426 + XiCon Loss:1.4190 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6619
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7271473407745361
Epoch: 23, Steps: 37 Train Loss: 14.2393 (Forecasting Loss:0.1420 + XiCon Loss:1.4097 x Lambda(10.0)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.6619
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.739898681640625
Epoch: 24, Steps: 37 Train Loss: 14.1825 (Forecasting Loss:0.1416 + XiCon Loss:1.4041 x Lambda(10.0)), Vali MSE Loss: 0.1122 Test MSE Loss: 0.6619
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7170374393463135, mae:0.6066598296165466, mape:0.24115721881389618, mspe:0.20860326290130615 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4788
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7772343158721924
Epoch: 1, Steps: 37 Train Loss: 16.5740 (Forecasting Loss:0.5092 + XiCon Loss:1.6065 x Lambda(10.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 1.3193
Validation loss decreased (inf --> 0.313219).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7461912631988525
Epoch: 2, Steps: 37 Train Loss: 15.7031 (Forecasting Loss:0.2915 + XiCon Loss:1.5412 x Lambda(10.0)), Vali MSE Loss: 0.1832 Test MSE Loss: 0.8475
Validation loss decreased (0.313219 --> 0.183240).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7334189414978027
Epoch: 3, Steps: 37 Train Loss: 14.9179 (Forecasting Loss:0.2022 + XiCon Loss:1.4716 x Lambda(10.0)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.6940
Validation loss decreased (0.183240 --> 0.146780).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7423028945922852
Epoch: 4, Steps: 37 Train Loss: 14.4787 (Forecasting Loss:0.1635 + XiCon Loss:1.4315 x Lambda(10.0)), Vali MSE Loss: 0.1294 Test MSE Loss: 0.6459
Validation loss decreased (0.146780 --> 0.129407).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7562432289123535
Epoch: 5, Steps: 37 Train Loss: 14.2024 (Forecasting Loss:0.1572 + XiCon Loss:1.4045 x Lambda(10.0)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.6669
Validation loss decreased (0.129407 --> 0.123361).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7567882537841797
Epoch: 6, Steps: 37 Train Loss: 14.1596 (Forecasting Loss:0.1516 + XiCon Loss:1.4008 x Lambda(10.0)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.6376
Validation loss decreased (0.123361 --> 0.123179).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7432646751403809
Epoch: 7, Steps: 37 Train Loss: 14.0186 (Forecasting Loss:0.1510 + XiCon Loss:1.3868 x Lambda(10.0)), Vali MSE Loss: 0.1211 Test MSE Loss: 0.6578
Validation loss decreased (0.123179 --> 0.121051).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.745734691619873
Epoch: 8, Steps: 37 Train Loss: 14.1413 (Forecasting Loss:0.1494 + XiCon Loss:1.3992 x Lambda(10.0)), Vali MSE Loss: 0.1209 Test MSE Loss: 0.6551
Validation loss decreased (0.121051 --> 0.120909).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7933638095855713
Epoch: 9, Steps: 37 Train Loss: 14.1310 (Forecasting Loss:0.1503 + XiCon Loss:1.3981 x Lambda(10.0)), Vali MSE Loss: 0.1201 Test MSE Loss: 0.6536
Validation loss decreased (0.120909 --> 0.120134).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7842748165130615
Epoch: 10, Steps: 37 Train Loss: 14.0517 (Forecasting Loss:0.1486 + XiCon Loss:1.3903 x Lambda(10.0)), Vali MSE Loss: 0.1192 Test MSE Loss: 0.6500
Validation loss decreased (0.120134 --> 0.119159).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7373332977294922
Epoch: 11, Steps: 37 Train Loss: 14.1271 (Forecasting Loss:0.1517 + XiCon Loss:1.3975 x Lambda(10.0)), Vali MSE Loss: 0.1184 Test MSE Loss: 0.6492
Validation loss decreased (0.119159 --> 0.118378).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7300405502319336
Epoch: 12, Steps: 37 Train Loss: 14.0898 (Forecasting Loss:0.1501 + XiCon Loss:1.3940 x Lambda(10.0)), Vali MSE Loss: 0.1193 Test MSE Loss: 0.6487
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7051498889923096
Epoch: 13, Steps: 37 Train Loss: 14.0950 (Forecasting Loss:0.1487 + XiCon Loss:1.3946 x Lambda(10.0)), Vali MSE Loss: 0.1206 Test MSE Loss: 0.6482
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7393534183502197
Epoch: 14, Steps: 37 Train Loss: 14.0837 (Forecasting Loss:0.1512 + XiCon Loss:1.3933 x Lambda(10.0)), Vali MSE Loss: 0.1203 Test MSE Loss: 0.6480
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.726660966873169
Epoch: 15, Steps: 37 Train Loss: 13.9934 (Forecasting Loss:0.1517 + XiCon Loss:1.3842 x Lambda(10.0)), Vali MSE Loss: 0.1195 Test MSE Loss: 0.6481
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.734494686126709
Epoch: 16, Steps: 37 Train Loss: 14.0013 (Forecasting Loss:0.1492 + XiCon Loss:1.3852 x Lambda(10.0)), Vali MSE Loss: 0.1208 Test MSE Loss: 0.6481
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7537837028503418
Epoch: 17, Steps: 37 Train Loss: 13.9648 (Forecasting Loss:0.1516 + XiCon Loss:1.3813 x Lambda(10.0)), Vali MSE Loss: 0.1191 Test MSE Loss: 0.6480
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7202019691467285
Epoch: 18, Steps: 37 Train Loss: 14.1032 (Forecasting Loss:0.1475 + XiCon Loss:1.3956 x Lambda(10.0)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.6480
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7378451824188232
Epoch: 19, Steps: 37 Train Loss: 14.1382 (Forecasting Loss:0.1488 + XiCon Loss:1.3989 x Lambda(10.0)), Vali MSE Loss: 0.1196 Test MSE Loss: 0.6480
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7952766418457031
Epoch: 20, Steps: 37 Train Loss: 14.1649 (Forecasting Loss:0.1500 + XiCon Loss:1.4015 x Lambda(10.0)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.6480
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6895675659179688
Epoch: 21, Steps: 37 Train Loss: 13.9393 (Forecasting Loss:0.1473 + XiCon Loss:1.3792 x Lambda(10.0)), Vali MSE Loss: 0.1203 Test MSE Loss: 0.6480
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.6867856979370117, mae:0.6116408705711365, mape:0.24295435845851898, mspe:0.199598491191864 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7140+-0.01947, MAE:0.6136+-0.00659, MAPE:0.2430+-0.00163, MSPE:0.2051+-0.00453, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[56], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=56, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3803
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 1.0306270122528076
Epoch: 1, Steps: 35 Train Loss: 0.4880 (Forecasting Loss:0.4718 + XiCon Loss:1.6190 x Lambda(0.01)), Vali MSE Loss: 0.3099 Test MSE Loss: 1.1656
Validation loss decreased (inf --> 0.309923).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7106311321258545
Epoch: 2, Steps: 35 Train Loss: 0.3404 (Forecasting Loss:0.3241 + XiCon Loss:1.6377 x Lambda(0.01)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.7209
Validation loss decreased (0.309923 --> 0.184796).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7325410842895508
Epoch: 3, Steps: 35 Train Loss: 0.2352 (Forecasting Loss:0.2187 + XiCon Loss:1.6494 x Lambda(0.01)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.7113
Validation loss decreased (0.184796 --> 0.142542).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7463512420654297
Epoch: 4, Steps: 35 Train Loss: 0.2052 (Forecasting Loss:0.1887 + XiCon Loss:1.6568 x Lambda(0.01)), Vali MSE Loss: 0.1326 Test MSE Loss: 0.6813
Validation loss decreased (0.142542 --> 0.132578).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6656928062438965
Epoch: 5, Steps: 35 Train Loss: 0.1963 (Forecasting Loss:0.1797 + XiCon Loss:1.6561 x Lambda(0.01)), Vali MSE Loss: 0.1318 Test MSE Loss: 0.6714
Validation loss decreased (0.132578 --> 0.131845).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6202178001403809
Epoch: 6, Steps: 35 Train Loss: 0.1933 (Forecasting Loss:0.1768 + XiCon Loss:1.6545 x Lambda(0.01)), Vali MSE Loss: 0.1300 Test MSE Loss: 0.6803
Validation loss decreased (0.131845 --> 0.130006).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7263948917388916
Epoch: 7, Steps: 35 Train Loss: 0.1919 (Forecasting Loss:0.1753 + XiCon Loss:1.6563 x Lambda(0.01)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6770
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7130296230316162
Epoch: 8, Steps: 35 Train Loss: 0.1912 (Forecasting Loss:0.1747 + XiCon Loss:1.6526 x Lambda(0.01)), Vali MSE Loss: 0.1305 Test MSE Loss: 0.6776
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.694331169128418
Epoch: 9, Steps: 35 Train Loss: 0.1909 (Forecasting Loss:0.1744 + XiCon Loss:1.6549 x Lambda(0.01)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6782
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.728550910949707
Epoch: 10, Steps: 35 Train Loss: 0.1908 (Forecasting Loss:0.1742 + XiCon Loss:1.6584 x Lambda(0.01)), Vali MSE Loss: 0.1300 Test MSE Loss: 0.6778
Validation loss decreased (0.130006 --> 0.129981).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6993961334228516
Epoch: 11, Steps: 35 Train Loss: 0.1907 (Forecasting Loss:0.1741 + XiCon Loss:1.6551 x Lambda(0.01)), Vali MSE Loss: 0.1303 Test MSE Loss: 0.6777
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6827361583709717
Epoch: 12, Steps: 35 Train Loss: 0.1907 (Forecasting Loss:0.1741 + XiCon Loss:1.6549 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6777
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7342736721038818
Epoch: 13, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6498 x Lambda(0.01)), Vali MSE Loss: 0.1304 Test MSE Loss: 0.6776
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6751928329467773
Epoch: 14, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6568 x Lambda(0.01)), Vali MSE Loss: 0.1295 Test MSE Loss: 0.6776
Validation loss decreased (0.129981 --> 0.129464).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.5943002700805664
Epoch: 15, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6565 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6776
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6978886127471924
Epoch: 16, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6512 x Lambda(0.01)), Vali MSE Loss: 0.1308 Test MSE Loss: 0.6776
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6964025497436523
Epoch: 17, Steps: 35 Train Loss: 0.1905 (Forecasting Loss:0.1740 + XiCon Loss:1.6499 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6776
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.9499320983886719
Epoch: 18, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6525 x Lambda(0.01)), Vali MSE Loss: 0.1303 Test MSE Loss: 0.6776
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7352542877197266
Epoch: 19, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6531 x Lambda(0.01)), Vali MSE Loss: 0.1293 Test MSE Loss: 0.6776
Validation loss decreased (0.129464 --> 0.129252).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7422382831573486
Epoch: 20, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6514 x Lambda(0.01)), Vali MSE Loss: 0.1292 Test MSE Loss: 0.6776
Validation loss decreased (0.129252 --> 0.129218).  Saving model ...
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7049391269683838
Epoch: 21, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6573 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6776
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7014064788818359
Epoch: 22, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6560 x Lambda(0.01)), Vali MSE Loss: 0.1304 Test MSE Loss: 0.6776
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.697396993637085
Epoch: 23, Steps: 35 Train Loss: 0.1905 (Forecasting Loss:0.1741 + XiCon Loss:1.6496 x Lambda(0.01)), Vali MSE Loss: 0.1311 Test MSE Loss: 0.6776
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.5974617004394531
Epoch: 24, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6535 x Lambda(0.01)), Vali MSE Loss: 0.1310 Test MSE Loss: 0.6776
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7229077816009521
Epoch: 25, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6520 x Lambda(0.01)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.6776
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.6978030204772949
Epoch: 26, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6601 x Lambda(0.01)), Vali MSE Loss: 0.1291 Test MSE Loss: 0.6776
Validation loss decreased (0.129218 --> 0.129074).  Saving model ...
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7602448463439941
Epoch: 27, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6551 x Lambda(0.01)), Vali MSE Loss: 0.1294 Test MSE Loss: 0.6776
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.6815338134765625
Epoch: 28, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6543 x Lambda(0.01)), Vali MSE Loss: 0.1312 Test MSE Loss: 0.6776
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.6912047863006592
Epoch: 29, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6529 x Lambda(0.01)), Vali MSE Loss: 0.1314 Test MSE Loss: 0.6776
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7206296920776367
Epoch: 30, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6533 x Lambda(0.01)), Vali MSE Loss: 0.1300 Test MSE Loss: 0.6776
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7342832088470459
Epoch: 31, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6542 x Lambda(0.01)), Vali MSE Loss: 0.1287 Test MSE Loss: 0.6776
Validation loss decreased (0.129074 --> 0.128682).  Saving model ...
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.6858386993408203
Epoch: 32, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6578 x Lambda(0.01)), Vali MSE Loss: 0.1314 Test MSE Loss: 0.6776
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.6732404232025146
Epoch: 33, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1740 + XiCon Loss:1.6539 x Lambda(0.01)), Vali MSE Loss: 0.1292 Test MSE Loss: 0.6776
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.7106037139892578
Epoch: 34, Steps: 35 Train Loss: 0.1907 (Forecasting Loss:0.1741 + XiCon Loss:1.6587 x Lambda(0.01)), Vali MSE Loss: 0.1297 Test MSE Loss: 0.6776
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-13
Epoch: 35 cost time: 0.7067573070526123
Epoch: 35, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6547 x Lambda(0.01)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6776
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-13
Epoch: 36 cost time: 0.6968827247619629
Epoch: 36, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6537 x Lambda(0.01)), Vali MSE Loss: 0.1307 Test MSE Loss: 0.6776
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-13
Epoch: 37 cost time: 0.7339293956756592
Epoch: 37, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6555 x Lambda(0.01)), Vali MSE Loss: 0.1316 Test MSE Loss: 0.6776
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-14
Epoch: 38 cost time: 0.6855785846710205
Epoch: 38, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6564 x Lambda(0.01)), Vali MSE Loss: 0.1302 Test MSE Loss: 0.6776
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-14
Epoch: 39 cost time: 0.6958045959472656
Epoch: 39, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6505 x Lambda(0.01)), Vali MSE Loss: 0.1300 Test MSE Loss: 0.6776
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-14
Epoch: 40 cost time: 0.7261619567871094
Epoch: 40, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6516 x Lambda(0.01)), Vali MSE Loss: 0.1309 Test MSE Loss: 0.6776
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-15
Epoch: 41 cost time: 0.6749420166015625
Epoch: 41, Steps: 35 Train Loss: 0.1906 (Forecasting Loss:0.1741 + XiCon Loss:1.6553 x Lambda(0.01)), Vali MSE Loss: 0.1300 Test MSE Loss: 0.6776
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6933211088180542, mae:0.6619104146957397, mape:0.25810930132865906, mspe:0.18787536025047302 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3880
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7246990203857422
Epoch: 1, Steps: 35 Train Loss: 0.4882 (Forecasting Loss:0.4721 + XiCon Loss:1.6105 x Lambda(0.01)), Vali MSE Loss: 0.3299 Test MSE Loss: 0.9759
Validation loss decreased (inf --> 0.329899).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6909785270690918
Epoch: 2, Steps: 35 Train Loss: 0.3550 (Forecasting Loss:0.3388 + XiCon Loss:1.6267 x Lambda(0.01)), Vali MSE Loss: 0.1801 Test MSE Loss: 0.7196
Validation loss decreased (0.329899 --> 0.180128).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6898860931396484
Epoch: 3, Steps: 35 Train Loss: 0.2210 (Forecasting Loss:0.2045 + XiCon Loss:1.6468 x Lambda(0.01)), Vali MSE Loss: 0.1462 Test MSE Loss: 0.7495
Validation loss decreased (0.180128 --> 0.146186).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7063090801239014
Epoch: 4, Steps: 35 Train Loss: 0.1788 (Forecasting Loss:0.1623 + XiCon Loss:1.6444 x Lambda(0.01)), Vali MSE Loss: 0.1401 Test MSE Loss: 0.6486
Validation loss decreased (0.146186 --> 0.140124).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6910464763641357
Epoch: 5, Steps: 35 Train Loss: 0.1662 (Forecasting Loss:0.1498 + XiCon Loss:1.6419 x Lambda(0.01)), Vali MSE Loss: 0.1498 Test MSE Loss: 0.6176
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6870706081390381
Epoch: 6, Steps: 35 Train Loss: 0.1532 (Forecasting Loss:0.1368 + XiCon Loss:1.6377 x Lambda(0.01)), Vali MSE Loss: 0.1482 Test MSE Loss: 0.6777
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6661725044250488
Epoch: 7, Steps: 35 Train Loss: 0.1477 (Forecasting Loss:0.1313 + XiCon Loss:1.6382 x Lambda(0.01)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.7682
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7001368999481201
Epoch: 8, Steps: 35 Train Loss: 0.1458 (Forecasting Loss:0.1295 + XiCon Loss:1.6331 x Lambda(0.01)), Vali MSE Loss: 0.1452 Test MSE Loss: 0.7293
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6687614917755127
Epoch: 9, Steps: 35 Train Loss: 0.1439 (Forecasting Loss:0.1275 + XiCon Loss:1.6380 x Lambda(0.01)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.7270
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7025876045227051
Epoch: 10, Steps: 35 Train Loss: 0.1422 (Forecasting Loss:0.1260 + XiCon Loss:1.6291 x Lambda(0.01)), Vali MSE Loss: 0.1466 Test MSE Loss: 0.7311
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6957688331604004
Epoch: 11, Steps: 35 Train Loss: 0.1426 (Forecasting Loss:0.1263 + XiCon Loss:1.6335 x Lambda(0.01)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.7291
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7111945152282715
Epoch: 12, Steps: 35 Train Loss: 0.1425 (Forecasting Loss:0.1261 + XiCon Loss:1.6355 x Lambda(0.01)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.7279
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6532702445983887
Epoch: 13, Steps: 35 Train Loss: 0.1415 (Forecasting Loss:0.1252 + XiCon Loss:1.6342 x Lambda(0.01)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.7280
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7080650329589844
Epoch: 14, Steps: 35 Train Loss: 0.1430 (Forecasting Loss:0.1267 + XiCon Loss:1.6368 x Lambda(0.01)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.7287
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6763007640838623, mae:0.6209549903869629, mape:0.24440106749534607, mspe:0.1925823986530304 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4042
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6815989017486572
Epoch: 1, Steps: 35 Train Loss: 0.5057 (Forecasting Loss:0.4895 + XiCon Loss:1.6220 x Lambda(0.01)), Vali MSE Loss: 0.3387 Test MSE Loss: 1.1528
Validation loss decreased (inf --> 0.338696).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7070679664611816
Epoch: 2, Steps: 35 Train Loss: 0.3482 (Forecasting Loss:0.3318 + XiCon Loss:1.6383 x Lambda(0.01)), Vali MSE Loss: 0.1854 Test MSE Loss: 0.7513
Validation loss decreased (0.338696 --> 0.185368).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6234879493713379
Epoch: 3, Steps: 35 Train Loss: 0.2211 (Forecasting Loss:0.2048 + XiCon Loss:1.6258 x Lambda(0.01)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.6989
Validation loss decreased (0.185368 --> 0.166891).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.665302038192749
Epoch: 4, Steps: 35 Train Loss: 0.1757 (Forecasting Loss:0.1594 + XiCon Loss:1.6293 x Lambda(0.01)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.7558
Validation loss decreased (0.166891 --> 0.130132).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7173426151275635
Epoch: 5, Steps: 35 Train Loss: 0.1538 (Forecasting Loss:0.1375 + XiCon Loss:1.6260 x Lambda(0.01)), Vali MSE Loss: 0.1390 Test MSE Loss: 0.6675
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7273452281951904
Epoch: 6, Steps: 35 Train Loss: 0.1430 (Forecasting Loss:0.1267 + XiCon Loss:1.6295 x Lambda(0.01)), Vali MSE Loss: 0.1377 Test MSE Loss: 0.7209
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6823756694793701
Epoch: 7, Steps: 35 Train Loss: 0.1364 (Forecasting Loss:0.1201 + XiCon Loss:1.6207 x Lambda(0.01)), Vali MSE Loss: 0.1347 Test MSE Loss: 0.7235
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7007694244384766
Epoch: 8, Steps: 35 Train Loss: 0.1339 (Forecasting Loss:0.1176 + XiCon Loss:1.6269 x Lambda(0.01)), Vali MSE Loss: 0.1348 Test MSE Loss: 0.7531
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6795799732208252
Epoch: 9, Steps: 35 Train Loss: 0.1324 (Forecasting Loss:0.1162 + XiCon Loss:1.6212 x Lambda(0.01)), Vali MSE Loss: 0.1388 Test MSE Loss: 0.7514
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7047431468963623
Epoch: 10, Steps: 35 Train Loss: 0.1321 (Forecasting Loss:0.1159 + XiCon Loss:1.6214 x Lambda(0.01)), Vali MSE Loss: 0.1387 Test MSE Loss: 0.7533
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7076711654663086
Epoch: 11, Steps: 35 Train Loss: 0.1320 (Forecasting Loss:0.1158 + XiCon Loss:1.6207 x Lambda(0.01)), Vali MSE Loss: 0.1379 Test MSE Loss: 0.7541
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6685497760772705
Epoch: 12, Steps: 35 Train Loss: 0.1314 (Forecasting Loss:0.1152 + XiCon Loss:1.6188 x Lambda(0.01)), Vali MSE Loss: 0.1382 Test MSE Loss: 0.7521
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.622861385345459
Epoch: 13, Steps: 35 Train Loss: 0.1314 (Forecasting Loss:0.1152 + XiCon Loss:1.6192 x Lambda(0.01)), Vali MSE Loss: 0.1388 Test MSE Loss: 0.7519
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7111690044403076
Epoch: 14, Steps: 35 Train Loss: 0.1310 (Forecasting Loss:0.1148 + XiCon Loss:1.6246 x Lambda(0.01)), Vali MSE Loss: 0.1371 Test MSE Loss: 0.7528
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.797662079334259, mae:0.7139732837677002, mape:0.27222201228141785, mspe:0.20060613751411438 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4354
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6681270599365234
Epoch: 1, Steps: 35 Train Loss: 0.5279 (Forecasting Loss:0.5117 + XiCon Loss:1.6203 x Lambda(0.01)), Vali MSE Loss: 0.3147 Test MSE Loss: 1.1022
Validation loss decreased (inf --> 0.314653).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7302684783935547
Epoch: 2, Steps: 35 Train Loss: 0.3634 (Forecasting Loss:0.3468 + XiCon Loss:1.6535 x Lambda(0.01)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.7077
Validation loss decreased (0.314653 --> 0.186548).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6871893405914307
Epoch: 3, Steps: 35 Train Loss: 0.2403 (Forecasting Loss:0.2237 + XiCon Loss:1.6542 x Lambda(0.01)), Vali MSE Loss: 0.1370 Test MSE Loss: 0.7107
Validation loss decreased (0.186548 --> 0.136981).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.692312479019165
Epoch: 4, Steps: 35 Train Loss: 0.2077 (Forecasting Loss:0.1912 + XiCon Loss:1.6542 x Lambda(0.01)), Vali MSE Loss: 0.1267 Test MSE Loss: 0.6872
Validation loss decreased (0.136981 --> 0.126713).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7144219875335693
Epoch: 5, Steps: 35 Train Loss: 0.1982 (Forecasting Loss:0.1817 + XiCon Loss:1.6521 x Lambda(0.01)), Vali MSE Loss: 0.1275 Test MSE Loss: 0.6785
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.719050407409668
Epoch: 6, Steps: 35 Train Loss: 0.1951 (Forecasting Loss:0.1786 + XiCon Loss:1.6538 x Lambda(0.01)), Vali MSE Loss: 0.1262 Test MSE Loss: 0.6812
Validation loss decreased (0.126713 --> 0.126211).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6585516929626465
Epoch: 7, Steps: 35 Train Loss: 0.1938 (Forecasting Loss:0.1773 + XiCon Loss:1.6513 x Lambda(0.01)), Vali MSE Loss: 0.1243 Test MSE Loss: 0.6790
Validation loss decreased (0.126211 --> 0.124295).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7098557949066162
Epoch: 8, Steps: 35 Train Loss: 0.1932 (Forecasting Loss:0.1767 + XiCon Loss:1.6548 x Lambda(0.01)), Vali MSE Loss: 0.1247 Test MSE Loss: 0.6799
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6742660999298096
Epoch: 9, Steps: 35 Train Loss: 0.1928 (Forecasting Loss:0.1763 + XiCon Loss:1.6521 x Lambda(0.01)), Vali MSE Loss: 0.1256 Test MSE Loss: 0.6792
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6980476379394531
Epoch: 10, Steps: 35 Train Loss: 0.1927 (Forecasting Loss:0.1762 + XiCon Loss:1.6532 x Lambda(0.01)), Vali MSE Loss: 0.1251 Test MSE Loss: 0.6790
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6900119781494141
Epoch: 11, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1761 + XiCon Loss:1.6477 x Lambda(0.01)), Vali MSE Loss: 0.1246 Test MSE Loss: 0.6790
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6868700981140137
Epoch: 12, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6511 x Lambda(0.01)), Vali MSE Loss: 0.1245 Test MSE Loss: 0.6789
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.660975456237793
Epoch: 13, Steps: 35 Train Loss: 0.1926 (Forecasting Loss:0.1760 + XiCon Loss:1.6569 x Lambda(0.01)), Vali MSE Loss: 0.1256 Test MSE Loss: 0.6789
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7266213893890381
Epoch: 14, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6532 x Lambda(0.01)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.6789
Validation loss decreased (0.124295 --> 0.123395).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6810941696166992
Epoch: 15, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6524 x Lambda(0.01)), Vali MSE Loss: 0.1252 Test MSE Loss: 0.6789
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6436963081359863
Epoch: 16, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6522 x Lambda(0.01)), Vali MSE Loss: 0.1245 Test MSE Loss: 0.6789
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.73927903175354
Epoch: 17, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6476 x Lambda(0.01)), Vali MSE Loss: 0.1246 Test MSE Loss: 0.6789
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7190353870391846
Epoch: 18, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6509 x Lambda(0.01)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.6789
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6795473098754883
Epoch: 19, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6524 x Lambda(0.01)), Vali MSE Loss: 0.1244 Test MSE Loss: 0.6789
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6893560886383057
Epoch: 20, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6508 x Lambda(0.01)), Vali MSE Loss: 0.1256 Test MSE Loss: 0.6789
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7062656879425049
Epoch: 21, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6532 x Lambda(0.01)), Vali MSE Loss: 0.1251 Test MSE Loss: 0.6789
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6817476749420166
Epoch: 22, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6544 x Lambda(0.01)), Vali MSE Loss: 0.1251 Test MSE Loss: 0.6789
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.712446928024292
Epoch: 23, Steps: 35 Train Loss: 0.1924 (Forecasting Loss:0.1760 + XiCon Loss:1.6456 x Lambda(0.01)), Vali MSE Loss: 0.1249 Test MSE Loss: 0.6789
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7040643692016602
Epoch: 24, Steps: 35 Train Loss: 0.1925 (Forecasting Loss:0.1760 + XiCon Loss:1.6488 x Lambda(0.01)), Vali MSE Loss: 0.1251 Test MSE Loss: 0.6789
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.6989356875419617, mae:0.6588428020477295, mape:0.25798967480659485, mspe:0.1911221146583557 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3817
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.7578928470611572
Epoch: 1, Steps: 35 Train Loss: 0.4791 (Forecasting Loss:0.4630 + XiCon Loss:1.6163 x Lambda(0.01)), Vali MSE Loss: 0.3212 Test MSE Loss: 1.1850
Validation loss decreased (inf --> 0.321172).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6993234157562256
Epoch: 2, Steps: 35 Train Loss: 0.3334 (Forecasting Loss:0.3173 + XiCon Loss:1.6122 x Lambda(0.01)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.7613
Validation loss decreased (0.321172 --> 0.174217).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6497061252593994
Epoch: 3, Steps: 35 Train Loss: 0.2233 (Forecasting Loss:0.2070 + XiCon Loss:1.6292 x Lambda(0.01)), Vali MSE Loss: 0.1518 Test MSE Loss: 0.6532
Validation loss decreased (0.174217 --> 0.151799).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6847434043884277
Epoch: 4, Steps: 35 Train Loss: 0.1932 (Forecasting Loss:0.1770 + XiCon Loss:1.6178 x Lambda(0.01)), Vali MSE Loss: 0.1529 Test MSE Loss: 0.6912
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6914770603179932
Epoch: 5, Steps: 35 Train Loss: 0.1779 (Forecasting Loss:0.1618 + XiCon Loss:1.6138 x Lambda(0.01)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.6829
Validation loss decreased (0.151799 --> 0.147711).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6837048530578613
Epoch: 6, Steps: 35 Train Loss: 0.1719 (Forecasting Loss:0.1558 + XiCon Loss:1.6087 x Lambda(0.01)), Vali MSE Loss: 0.1428 Test MSE Loss: 0.6935
Validation loss decreased (0.147711 --> 0.142846).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7047557830810547
Epoch: 7, Steps: 35 Train Loss: 0.1668 (Forecasting Loss:0.1508 + XiCon Loss:1.6010 x Lambda(0.01)), Vali MSE Loss: 0.1481 Test MSE Loss: 0.6840
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7027328014373779
Epoch: 8, Steps: 35 Train Loss: 0.1640 (Forecasting Loss:0.1480 + XiCon Loss:1.5993 x Lambda(0.01)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.6950
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6644783020019531
Epoch: 9, Steps: 35 Train Loss: 0.1630 (Forecasting Loss:0.1471 + XiCon Loss:1.5969 x Lambda(0.01)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.6834
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6562047004699707
Epoch: 10, Steps: 35 Train Loss: 0.1620 (Forecasting Loss:0.1460 + XiCon Loss:1.5984 x Lambda(0.01)), Vali MSE Loss: 0.1496 Test MSE Loss: 0.6807
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6886980533599854
Epoch: 11, Steps: 35 Train Loss: 0.1618 (Forecasting Loss:0.1458 + XiCon Loss:1.5966 x Lambda(0.01)), Vali MSE Loss: 0.1485 Test MSE Loss: 0.6804
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7267918586730957
Epoch: 12, Steps: 35 Train Loss: 0.1624 (Forecasting Loss:0.1464 + XiCon Loss:1.6007 x Lambda(0.01)), Vali MSE Loss: 0.1487 Test MSE Loss: 0.6812
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7080786228179932
Epoch: 13, Steps: 35 Train Loss: 0.1613 (Forecasting Loss:0.1453 + XiCon Loss:1.5939 x Lambda(0.01)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.6807
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7180671691894531
Epoch: 14, Steps: 35 Train Loss: 0.1615 (Forecasting Loss:0.1454 + XiCon Loss:1.6084 x Lambda(0.01)), Vali MSE Loss: 0.1489 Test MSE Loss: 0.6809
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6866400241851807
Epoch: 15, Steps: 35 Train Loss: 0.1618 (Forecasting Loss:0.1458 + XiCon Loss:1.6011 x Lambda(0.01)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.6808
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.698277473449707
Epoch: 16, Steps: 35 Train Loss: 0.1614 (Forecasting Loss:0.1454 + XiCon Loss:1.6005 x Lambda(0.01)), Vali MSE Loss: 0.1467 Test MSE Loss: 0.6809
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7075365781784058, mae:0.6794705986976624, mape:0.2597670257091522, mspe:0.1781735122203827 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7148+-0.05927, MAE:0.6670+-0.04199, MAPE:0.2585+-0.01225, MSPE:0.1901+-0.01010, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[112], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=112, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3454
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.9370589256286621
Epoch: 1, Steps: 30 Train Loss: 0.7975 (Forecasting Loss:0.6349 + XiCon Loss:1.6256 x Lambda(0.1)), Vali MSE Loss: 0.4251 Test MSE Loss: 1.5887
Validation loss decreased (inf --> 0.425128).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6487267017364502
Epoch: 2, Steps: 30 Train Loss: 0.5846 (Forecasting Loss:0.4275 + XiCon Loss:1.5701 x Lambda(0.1)), Vali MSE Loss: 0.3487 Test MSE Loss: 1.0718
Validation loss decreased (0.425128 --> 0.348730).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6227295398712158
Epoch: 3, Steps: 30 Train Loss: 0.4079 (Forecasting Loss:0.2573 + XiCon Loss:1.5054 x Lambda(0.1)), Vali MSE Loss: 0.2999 Test MSE Loss: 1.1356
Validation loss decreased (0.348730 --> 0.299920).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6494259834289551
Epoch: 4, Steps: 30 Train Loss: 0.3592 (Forecasting Loss:0.2127 + XiCon Loss:1.4647 x Lambda(0.1)), Vali MSE Loss: 0.3176 Test MSE Loss: 1.1101
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6563513278961182
Epoch: 5, Steps: 30 Train Loss: 0.3343 (Forecasting Loss:0.1901 + XiCon Loss:1.4413 x Lambda(0.1)), Vali MSE Loss: 0.4038 Test MSE Loss: 0.9210
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6627709865570068
Epoch: 6, Steps: 30 Train Loss: 0.3267 (Forecasting Loss:0.1824 + XiCon Loss:1.4430 x Lambda(0.1)), Vali MSE Loss: 0.4051 Test MSE Loss: 0.9015
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6265487670898438
Epoch: 7, Steps: 30 Train Loss: 0.3229 (Forecasting Loss:0.1780 + XiCon Loss:1.4489 x Lambda(0.1)), Vali MSE Loss: 0.3298 Test MSE Loss: 1.0228
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6051549911499023
Epoch: 8, Steps: 30 Train Loss: 0.3193 (Forecasting Loss:0.1738 + XiCon Loss:1.4550 x Lambda(0.1)), Vali MSE Loss: 0.3609 Test MSE Loss: 0.9888
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6240932941436768
Epoch: 9, Steps: 30 Train Loss: 0.3193 (Forecasting Loss:0.1736 + XiCon Loss:1.4570 x Lambda(0.1)), Vali MSE Loss: 0.3573 Test MSE Loss: 0.9907
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6552114486694336
Epoch: 10, Steps: 30 Train Loss: 0.3156 (Forecasting Loss:0.1715 + XiCon Loss:1.4408 x Lambda(0.1)), Vali MSE Loss: 0.3610 Test MSE Loss: 0.9947
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.646446704864502
Epoch: 11, Steps: 30 Train Loss: 0.3175 (Forecasting Loss:0.1725 + XiCon Loss:1.4499 x Lambda(0.1)), Vali MSE Loss: 0.3545 Test MSE Loss: 0.9999
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6424083709716797
Epoch: 12, Steps: 30 Train Loss: 0.3160 (Forecasting Loss:0.1711 + XiCon Loss:1.4487 x Lambda(0.1)), Vali MSE Loss: 0.3548 Test MSE Loss: 0.9969
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6257717609405518
Epoch: 13, Steps: 30 Train Loss: 0.3156 (Forecasting Loss:0.1714 + XiCon Loss:1.4417 x Lambda(0.1)), Vali MSE Loss: 0.3506 Test MSE Loss: 0.9969
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.2811211347579956, mae:0.990108072757721, mape:0.31868404150009155, mspe:0.13989046216011047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4507
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6132423877716064
Epoch: 1, Steps: 30 Train Loss: 0.7351 (Forecasting Loss:0.5727 + XiCon Loss:1.6242 x Lambda(0.1)), Vali MSE Loss: 0.3362 Test MSE Loss: 1.7700
Validation loss decreased (inf --> 0.336250).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6155533790588379
Epoch: 2, Steps: 30 Train Loss: 0.5644 (Forecasting Loss:0.4054 + XiCon Loss:1.5898 x Lambda(0.1)), Vali MSE Loss: 0.4726 Test MSE Loss: 0.9413
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6419529914855957
Epoch: 3, Steps: 30 Train Loss: 0.3860 (Forecasting Loss:0.2303 + XiCon Loss:1.5572 x Lambda(0.1)), Vali MSE Loss: 0.4696 Test MSE Loss: 0.9114
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.580571174621582
Epoch: 4, Steps: 30 Train Loss: 0.3424 (Forecasting Loss:0.1923 + XiCon Loss:1.5009 x Lambda(0.1)), Vali MSE Loss: 0.2956 Test MSE Loss: 1.0711
Validation loss decreased (0.336250 --> 0.295557).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.64422607421875
Epoch: 5, Steps: 30 Train Loss: 0.3135 (Forecasting Loss:0.1665 + XiCon Loss:1.4699 x Lambda(0.1)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.9254
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6297967433929443
Epoch: 6, Steps: 30 Train Loss: 0.3009 (Forecasting Loss:0.1562 + XiCon Loss:1.4469 x Lambda(0.1)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.9573
Validation loss decreased (0.295557 --> 0.276545).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5890393257141113
Epoch: 7, Steps: 30 Train Loss: 0.2951 (Forecasting Loss:0.1504 + XiCon Loss:1.4463 x Lambda(0.1)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.9698
Validation loss decreased (0.276545 --> 0.265545).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6257574558258057
Epoch: 8, Steps: 30 Train Loss: 0.2911 (Forecasting Loss:0.1471 + XiCon Loss:1.4403 x Lambda(0.1)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.9813
Validation loss decreased (0.265545 --> 0.257842).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6249508857727051
Epoch: 9, Steps: 30 Train Loss: 0.2890 (Forecasting Loss:0.1453 + XiCon Loss:1.4368 x Lambda(0.1)), Vali MSE Loss: 0.2641 Test MSE Loss: 0.9641
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6323237419128418
Epoch: 10, Steps: 30 Train Loss: 0.2881 (Forecasting Loss:0.1437 + XiCon Loss:1.4441 x Lambda(0.1)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.9661
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6602053642272949
Epoch: 11, Steps: 30 Train Loss: 0.2873 (Forecasting Loss:0.1428 + XiCon Loss:1.4447 x Lambda(0.1)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.9747
Validation loss decreased (0.257842 --> 0.252194).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.631638765335083
Epoch: 12, Steps: 30 Train Loss: 0.2884 (Forecasting Loss:0.1435 + XiCon Loss:1.4490 x Lambda(0.1)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.9702
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5954174995422363
Epoch: 13, Steps: 30 Train Loss: 0.2874 (Forecasting Loss:0.1434 + XiCon Loss:1.4406 x Lambda(0.1)), Vali MSE Loss: 0.2624 Test MSE Loss: 0.9696
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6114010810852051
Epoch: 14, Steps: 30 Train Loss: 0.2882 (Forecasting Loss:0.1432 + XiCon Loss:1.4492 x Lambda(0.1)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.9689
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.642423152923584
Epoch: 15, Steps: 30 Train Loss: 0.2890 (Forecasting Loss:0.1438 + XiCon Loss:1.4518 x Lambda(0.1)), Vali MSE Loss: 0.2630 Test MSE Loss: 0.9687
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6576797962188721
Epoch: 16, Steps: 30 Train Loss: 0.2858 (Forecasting Loss:0.1430 + XiCon Loss:1.4279 x Lambda(0.1)), Vali MSE Loss: 0.2621 Test MSE Loss: 0.9687
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6313784122467041
Epoch: 17, Steps: 30 Train Loss: 0.2886 (Forecasting Loss:0.1438 + XiCon Loss:1.4473 x Lambda(0.1)), Vali MSE Loss: 0.2657 Test MSE Loss: 0.9688
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6386923789978027
Epoch: 18, Steps: 30 Train Loss: 0.2891 (Forecasting Loss:0.1439 + XiCon Loss:1.4524 x Lambda(0.1)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.9688
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6296341419219971
Epoch: 19, Steps: 30 Train Loss: 0.2880 (Forecasting Loss:0.1430 + XiCon Loss:1.4493 x Lambda(0.1)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.9688
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6205666065216064
Epoch: 20, Steps: 30 Train Loss: 0.2873 (Forecasting Loss:0.1433 + XiCon Loss:1.4403 x Lambda(0.1)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.9688
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6845061779022217
Epoch: 21, Steps: 30 Train Loss: 0.2882 (Forecasting Loss:0.1437 + XiCon Loss:1.4452 x Lambda(0.1)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.9688
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.0559849739074707, mae:0.8933460712432861, mape:0.2951609194278717, mspe:0.13904066383838654 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4201
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.5802502632141113
Epoch: 1, Steps: 30 Train Loss: 0.7718 (Forecasting Loss:0.6083 + XiCon Loss:1.6355 x Lambda(0.1)), Vali MSE Loss: 0.3644 Test MSE Loss: 1.7582
Validation loss decreased (inf --> 0.364373).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6217172145843506
Epoch: 2, Steps: 30 Train Loss: 0.5764 (Forecasting Loss:0.4142 + XiCon Loss:1.6215 x Lambda(0.1)), Vali MSE Loss: 0.3171 Test MSE Loss: 1.0976
Validation loss decreased (0.364373 --> 0.317135).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6227633953094482
Epoch: 3, Steps: 30 Train Loss: 0.4014 (Forecasting Loss:0.2396 + XiCon Loss:1.6180 x Lambda(0.1)), Vali MSE Loss: 0.2284 Test MSE Loss: 1.0940
Validation loss decreased (0.317135 --> 0.228442).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6006343364715576
Epoch: 4, Steps: 30 Train Loss: 0.3349 (Forecasting Loss:0.1763 + XiCon Loss:1.5860 x Lambda(0.1)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.9141
Validation loss decreased (0.228442 --> 0.219601).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6366565227508545
Epoch: 5, Steps: 30 Train Loss: 0.3071 (Forecasting Loss:0.1510 + XiCon Loss:1.5604 x Lambda(0.1)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.9693
Validation loss decreased (0.219601 --> 0.186413).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6615049839019775
Epoch: 6, Steps: 30 Train Loss: 0.2941 (Forecasting Loss:0.1407 + XiCon Loss:1.5342 x Lambda(0.1)), Vali MSE Loss: 0.1744 Test MSE Loss: 0.9736
Validation loss decreased (0.186413 --> 0.174425).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6171669960021973
Epoch: 7, Steps: 30 Train Loss: 0.2870 (Forecasting Loss:0.1345 + XiCon Loss:1.5242 x Lambda(0.1)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.9979
Validation loss decreased (0.174425 --> 0.172622).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6227519512176514
Epoch: 8, Steps: 30 Train Loss: 0.2848 (Forecasting Loss:0.1336 + XiCon Loss:1.5125 x Lambda(0.1)), Vali MSE Loss: 0.1707 Test MSE Loss: 0.9985
Validation loss decreased (0.172622 --> 0.170702).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6275205612182617
Epoch: 9, Steps: 30 Train Loss: 0.2831 (Forecasting Loss:0.1316 + XiCon Loss:1.5151 x Lambda(0.1)), Vali MSE Loss: 0.1824 Test MSE Loss: 0.9700
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6344394683837891
Epoch: 10, Steps: 30 Train Loss: 0.2815 (Forecasting Loss:0.1305 + XiCon Loss:1.5101 x Lambda(0.1)), Vali MSE Loss: 0.1838 Test MSE Loss: 0.9693
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6474566459655762
Epoch: 11, Steps: 30 Train Loss: 0.2826 (Forecasting Loss:0.1316 + XiCon Loss:1.5098 x Lambda(0.1)), Vali MSE Loss: 0.1853 Test MSE Loss: 0.9709
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5767107009887695
Epoch: 12, Steps: 30 Train Loss: 0.2813 (Forecasting Loss:0.1305 + XiCon Loss:1.5070 x Lambda(0.1)), Vali MSE Loss: 0.1827 Test MSE Loss: 0.9732
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6236064434051514
Epoch: 13, Steps: 30 Train Loss: 0.2815 (Forecasting Loss:0.1304 + XiCon Loss:1.5106 x Lambda(0.1)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.9715
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6393122673034668
Epoch: 14, Steps: 30 Train Loss: 0.2804 (Forecasting Loss:0.1301 + XiCon Loss:1.5023 x Lambda(0.1)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.9711
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6585190296173096
Epoch: 15, Steps: 30 Train Loss: 0.2806 (Forecasting Loss:0.1299 + XiCon Loss:1.5066 x Lambda(0.1)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.9700
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6437366008758545
Epoch: 16, Steps: 30 Train Loss: 0.2803 (Forecasting Loss:0.1303 + XiCon Loss:1.5006 x Lambda(0.1)), Vali MSE Loss: 0.1838 Test MSE Loss: 0.9696
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.626568078994751
Epoch: 17, Steps: 30 Train Loss: 0.2816 (Forecasting Loss:0.1308 + XiCon Loss:1.5079 x Lambda(0.1)), Vali MSE Loss: 0.1860 Test MSE Loss: 0.9695
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6567895412445068
Epoch: 18, Steps: 30 Train Loss: 0.2806 (Forecasting Loss:0.1303 + XiCon Loss:1.5028 x Lambda(0.1)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.9695
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.1121419668197632, mae:0.8849155306816101, mape:0.2921546697616577, mspe:0.14170493185520172 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.4598
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6188273429870605
Epoch: 1, Steps: 30 Train Loss: 0.8123 (Forecasting Loss:0.6496 + XiCon Loss:1.6273 x Lambda(0.1)), Vali MSE Loss: 0.3345 Test MSE Loss: 1.8885
Validation loss decreased (inf --> 0.334547).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6136023998260498
Epoch: 2, Steps: 30 Train Loss: 0.5670 (Forecasting Loss:0.4035 + XiCon Loss:1.6350 x Lambda(0.1)), Vali MSE Loss: 0.3120 Test MSE Loss: 1.1323
Validation loss decreased (0.334547 --> 0.312035).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5833773612976074
Epoch: 3, Steps: 30 Train Loss: 0.3932 (Forecasting Loss:0.2317 + XiCon Loss:1.6145 x Lambda(0.1)), Vali MSE Loss: 0.3650 Test MSE Loss: 1.1332
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.609154224395752
Epoch: 4, Steps: 30 Train Loss: 0.3333 (Forecasting Loss:0.1726 + XiCon Loss:1.6072 x Lambda(0.1)), Vali MSE Loss: 0.3370 Test MSE Loss: 1.1544
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6457521915435791
Epoch: 5, Steps: 30 Train Loss: 0.3081 (Forecasting Loss:0.1479 + XiCon Loss:1.6015 x Lambda(0.1)), Vali MSE Loss: 0.2934 Test MSE Loss: 1.1586
Validation loss decreased (0.312035 --> 0.293399).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6186890602111816
Epoch: 6, Steps: 30 Train Loss: 0.3003 (Forecasting Loss:0.1406 + XiCon Loss:1.5969 x Lambda(0.1)), Vali MSE Loss: 0.3224 Test MSE Loss: 1.0222
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6979122161865234
Epoch: 7, Steps: 30 Train Loss: 0.2917 (Forecasting Loss:0.1318 + XiCon Loss:1.5989 x Lambda(0.1)), Vali MSE Loss: 0.3409 Test MSE Loss: 0.9907
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6412966251373291
Epoch: 8, Steps: 30 Train Loss: 0.2892 (Forecasting Loss:0.1297 + XiCon Loss:1.5951 x Lambda(0.1)), Vali MSE Loss: 0.3350 Test MSE Loss: 0.9553
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.61651611328125
Epoch: 9, Steps: 30 Train Loss: 0.2884 (Forecasting Loss:0.1288 + XiCon Loss:1.5959 x Lambda(0.1)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.9461
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6648507118225098
Epoch: 10, Steps: 30 Train Loss: 0.2873 (Forecasting Loss:0.1277 + XiCon Loss:1.5952 x Lambda(0.1)), Vali MSE Loss: 0.3415 Test MSE Loss: 0.9512
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6443817615509033
Epoch: 11, Steps: 30 Train Loss: 0.2862 (Forecasting Loss:0.1270 + XiCon Loss:1.5922 x Lambda(0.1)), Vali MSE Loss: 0.3496 Test MSE Loss: 0.9469
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6188380718231201
Epoch: 12, Steps: 30 Train Loss: 0.2872 (Forecasting Loss:0.1277 + XiCon Loss:1.5947 x Lambda(0.1)), Vali MSE Loss: 0.3448 Test MSE Loss: 0.9452
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6057047843933105
Epoch: 13, Steps: 30 Train Loss: 0.2868 (Forecasting Loss:0.1273 + XiCon Loss:1.5946 x Lambda(0.1)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.9434
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6156649589538574
Epoch: 14, Steps: 30 Train Loss: 0.2863 (Forecasting Loss:0.1267 + XiCon Loss:1.5959 x Lambda(0.1)), Vali MSE Loss: 0.3415 Test MSE Loss: 0.9432
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6578333377838135
Epoch: 15, Steps: 30 Train Loss: 0.2866 (Forecasting Loss:0.1272 + XiCon Loss:1.5936 x Lambda(0.1)), Vali MSE Loss: 0.3295 Test MSE Loss: 0.9430
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.3304306268692017, mae:0.9867907762527466, mape:0.3094129264354706, mspe:0.1306554675102234 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3938
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6503324508666992
Epoch: 1, Steps: 30 Train Loss: 0.7913 (Forecasting Loss:0.6279 + XiCon Loss:1.6339 x Lambda(0.1)), Vali MSE Loss: 0.3401 Test MSE Loss: 1.8944
Validation loss decreased (inf --> 0.340065).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6514081954956055
Epoch: 2, Steps: 30 Train Loss: 0.5778 (Forecasting Loss:0.4158 + XiCon Loss:1.6201 x Lambda(0.1)), Vali MSE Loss: 0.2439 Test MSE Loss: 1.1869
Validation loss decreased (0.340065 --> 0.243918).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6594643592834473
Epoch: 3, Steps: 30 Train Loss: 0.4235 (Forecasting Loss:0.2616 + XiCon Loss:1.6188 x Lambda(0.1)), Vali MSE Loss: 0.3483 Test MSE Loss: 1.0546
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6544172763824463
Epoch: 4, Steps: 30 Train Loss: 0.3498 (Forecasting Loss:0.1884 + XiCon Loss:1.6133 x Lambda(0.1)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.9211
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6446495056152344
Epoch: 5, Steps: 30 Train Loss: 0.3169 (Forecasting Loss:0.1561 + XiCon Loss:1.6081 x Lambda(0.1)), Vali MSE Loss: 0.3014 Test MSE Loss: 0.9219
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6327269077301025
Epoch: 6, Steps: 30 Train Loss: 0.3086 (Forecasting Loss:0.1481 + XiCon Loss:1.6047 x Lambda(0.1)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.9108
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5929977893829346
Epoch: 7, Steps: 30 Train Loss: 0.3008 (Forecasting Loss:0.1412 + XiCon Loss:1.5960 x Lambda(0.1)), Vali MSE Loss: 0.3391 Test MSE Loss: 0.8906
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6141777038574219
Epoch: 8, Steps: 30 Train Loss: 0.2967 (Forecasting Loss:0.1370 + XiCon Loss:1.5974 x Lambda(0.1)), Vali MSE Loss: 0.2963 Test MSE Loss: 0.8948
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6348230838775635
Epoch: 9, Steps: 30 Train Loss: 0.2957 (Forecasting Loss:0.1364 + XiCon Loss:1.5935 x Lambda(0.1)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.9128
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6194779872894287
Epoch: 10, Steps: 30 Train Loss: 0.2961 (Forecasting Loss:0.1360 + XiCon Loss:1.6012 x Lambda(0.1)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.9071
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6548795700073242
Epoch: 11, Steps: 30 Train Loss: 0.2953 (Forecasting Loss:0.1353 + XiCon Loss:1.5998 x Lambda(0.1)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.9032
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6278815269470215
Epoch: 12, Steps: 30 Train Loss: 0.2944 (Forecasting Loss:0.1350 + XiCon Loss:1.5940 x Lambda(0.1)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.9021
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.3763309717178345, mae:0.9975349307060242, mape:0.321733683347702, mspe:0.15711787343025208 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.2312+-0.17370, MAE:0.9505+-0.06987, MAPE:0.3074+-0.01665, MSPE:0.1417+-0.01194, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
