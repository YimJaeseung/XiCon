Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6309
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.1220686435699463
Epoch: 1, Steps: 69 Train Loss: 18.4951 (Forecasting Loss:0.1324 + XiCon Loss:1.8363 x Lambda(10.0)), Vali MSE Loss: 0.2851 Test MSE Loss: 0.1492
Validation loss decreased (inf --> 0.285132).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.7933268547058105
Epoch: 2, Steps: 69 Train Loss: 18.4065 (Forecasting Loss:0.1114 + XiCon Loss:1.8295 x Lambda(10.0)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1225
Validation loss decreased (0.285132 --> 0.214385).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.7713196277618408
Epoch: 3, Steps: 69 Train Loss: 18.4122 (Forecasting Loss:0.1028 + XiCon Loss:1.8309 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1206
Validation loss decreased (0.214385 --> 0.210208).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.7724072933197021
Epoch: 4, Steps: 69 Train Loss: 18.2830 (Forecasting Loss:0.1012 + XiCon Loss:1.8182 x Lambda(10.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1196
Validation loss decreased (0.210208 --> 0.208876).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8384504318237305
Epoch: 5, Steps: 69 Train Loss: 18.2735 (Forecasting Loss:0.1006 + XiCon Loss:1.8173 x Lambda(10.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1189
Validation loss decreased (0.208876 --> 0.208303).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7797904014587402
Epoch: 6, Steps: 69 Train Loss: 18.2294 (Forecasting Loss:0.1004 + XiCon Loss:1.8129 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1185
Validation loss decreased (0.208303 --> 0.208101).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.7806856632232666
Epoch: 7, Steps: 69 Train Loss: 18.3085 (Forecasting Loss:0.1003 + XiCon Loss:1.8208 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1183
Validation loss decreased (0.208101 --> 0.208003).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8102262020111084
Epoch: 8, Steps: 69 Train Loss: 18.1931 (Forecasting Loss:0.1004 + XiCon Loss:1.8093 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1182
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8039414882659912
Epoch: 9, Steps: 69 Train Loss: 18.1879 (Forecasting Loss:0.1004 + XiCon Loss:1.8087 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.208003 --> 0.207977).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.7945258617401123
Epoch: 10, Steps: 69 Train Loss: 18.2662 (Forecasting Loss:0.1004 + XiCon Loss:1.8166 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207977 --> 0.207966).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.795609712600708
Epoch: 11, Steps: 69 Train Loss: 18.2665 (Forecasting Loss:0.1003 + XiCon Loss:1.8166 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207966 --> 0.207961).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.7768938541412354
Epoch: 12, Steps: 69 Train Loss: 18.2094 (Forecasting Loss:0.1000 + XiCon Loss:1.8109 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207961 --> 0.207956).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.7575600147247314
Epoch: 13, Steps: 69 Train Loss: 18.2430 (Forecasting Loss:0.1002 + XiCon Loss:1.8143 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207956 --> 0.207953).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9526546001434326
Epoch: 14, Steps: 69 Train Loss: 18.2368 (Forecasting Loss:0.1003 + XiCon Loss:1.8136 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207953 --> 0.207952).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.82578444480896
Epoch: 15, Steps: 69 Train Loss: 18.2419 (Forecasting Loss:0.1003 + XiCon Loss:1.8142 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207952 --> 0.207951).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.838371992111206
Epoch: 16, Steps: 69 Train Loss: 18.2303 (Forecasting Loss:0.1002 + XiCon Loss:1.8130 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207951 --> 0.207950).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9145503044128418
Epoch: 17, Steps: 69 Train Loss: 18.1927 (Forecasting Loss:0.1002 + XiCon Loss:1.8092 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8740448951721191
Epoch: 18, Steps: 69 Train Loss: 18.2248 (Forecasting Loss:0.1002 + XiCon Loss:1.8125 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8391141891479492
Epoch: 19, Steps: 69 Train Loss: 18.2018 (Forecasting Loss:0.1001 + XiCon Loss:1.8102 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9030497074127197
Epoch: 20, Steps: 69 Train Loss: 18.2582 (Forecasting Loss:0.1005 + XiCon Loss:1.8158 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8671526908874512
Epoch: 21, Steps: 69 Train Loss: 18.1910 (Forecasting Loss:0.1003 + XiCon Loss:1.8091 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8902125358581543
Epoch: 22, Steps: 69 Train Loss: 18.1741 (Forecasting Loss:0.1003 + XiCon Loss:1.8074 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8372552394866943
Epoch: 23, Steps: 69 Train Loss: 18.2260 (Forecasting Loss:0.1004 + XiCon Loss:1.8126 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.7988319396972656
Epoch: 24, Steps: 69 Train Loss: 18.2090 (Forecasting Loss:0.0999 + XiCon Loss:1.8109 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.7972455024719238
Epoch: 25, Steps: 69 Train Loss: 18.2618 (Forecasting Loss:0.1003 + XiCon Loss:1.8162 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8772919178009033
Epoch: 26, Steps: 69 Train Loss: 18.2264 (Forecasting Loss:0.1001 + XiCon Loss:1.8126 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8847556114196777
Epoch: 27, Steps: 69 Train Loss: 18.2171 (Forecasting Loss:0.1004 + XiCon Loss:1.8117 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8187415599822998
Epoch: 28, Steps: 69 Train Loss: 18.2398 (Forecasting Loss:0.1002 + XiCon Loss:1.8140 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8681855201721191
Epoch: 29, Steps: 69 Train Loss: 18.2003 (Forecasting Loss:0.1002 + XiCon Loss:1.8100 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.815964937210083
Epoch: 30, Steps: 69 Train Loss: 18.2056 (Forecasting Loss:0.1003 + XiCon Loss:1.8105 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8332724571228027
Epoch: 31, Steps: 69 Train Loss: 18.1988 (Forecasting Loss:0.1002 + XiCon Loss:1.8099 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8971514701843262
Epoch: 32, Steps: 69 Train Loss: 18.2241 (Forecasting Loss:0.1005 + XiCon Loss:1.8124 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
Validation loss decreased (0.207950 --> 0.207950).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.7963066101074219
Epoch: 33, Steps: 69 Train Loss: 18.2080 (Forecasting Loss:0.1003 + XiCon Loss:1.8108 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.7810103893280029
Epoch: 34, Steps: 69 Train Loss: 18.2008 (Forecasting Loss:0.1001 + XiCon Loss:1.8101 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8842854499816895
Epoch: 35, Steps: 69 Train Loss: 18.2364 (Forecasting Loss:0.1004 + XiCon Loss:1.8136 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8344039916992188
Epoch: 36, Steps: 69 Train Loss: 18.1675 (Forecasting Loss:0.1003 + XiCon Loss:1.8067 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.7883667945861816
Epoch: 37, Steps: 69 Train Loss: 18.2406 (Forecasting Loss:0.1003 + XiCon Loss:1.8140 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8961174488067627
Epoch: 38, Steps: 69 Train Loss: 18.2342 (Forecasting Loss:0.1002 + XiCon Loss:1.8134 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8168888092041016
Epoch: 39, Steps: 69 Train Loss: 18.2297 (Forecasting Loss:0.1004 + XiCon Loss:1.8129 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9585328102111816
Epoch: 40, Steps: 69 Train Loss: 18.2101 (Forecasting Loss:0.1001 + XiCon Loss:1.8110 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.876112699508667
Epoch: 41, Steps: 69 Train Loss: 18.2086 (Forecasting Loss:0.1003 + XiCon Loss:1.8108 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8287861347198486
Epoch: 42, Steps: 69 Train Loss: 18.2202 (Forecasting Loss:0.1000 + XiCon Loss:1.8120 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.055782776325941086, mae:0.18037612736225128, mape:0.12634290754795074, mspe:0.03750639781355858 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6189
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9460594654083252
Epoch: 1, Steps: 69 Train Loss: 18.4600 (Forecasting Loss:0.1303 + XiCon Loss:1.8330 x Lambda(10.0)), Vali MSE Loss: 0.2799 Test MSE Loss: 0.1452
Validation loss decreased (inf --> 0.279905).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8534379005432129
Epoch: 2, Steps: 69 Train Loss: 18.4362 (Forecasting Loss:0.1110 + XiCon Loss:1.8325 x Lambda(10.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1209
Validation loss decreased (0.279905 --> 0.214189).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.868816614151001
Epoch: 3, Steps: 69 Train Loss: 18.2344 (Forecasting Loss:0.1023 + XiCon Loss:1.8132 x Lambda(10.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1199
Validation loss decreased (0.214189 --> 0.210110).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8543894290924072
Epoch: 4, Steps: 69 Train Loss: 18.3908 (Forecasting Loss:0.1006 + XiCon Loss:1.8290 x Lambda(10.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1197
Validation loss decreased (0.210110 --> 0.208710).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.7870919704437256
Epoch: 5, Steps: 69 Train Loss: 18.5922 (Forecasting Loss:0.1003 + XiCon Loss:1.8492 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1197
Validation loss decreased (0.208710 --> 0.207492).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8871781826019287
Epoch: 6, Steps: 69 Train Loss: 18.6743 (Forecasting Loss:0.1000 + XiCon Loss:1.8574 x Lambda(10.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1197
Validation loss decreased (0.207492 --> 0.206869).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8785812854766846
Epoch: 7, Steps: 69 Train Loss: 18.7772 (Forecasting Loss:0.0999 + XiCon Loss:1.8677 x Lambda(10.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1196
Validation loss decreased (0.206869 --> 0.206687).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8290679454803467
Epoch: 8, Steps: 69 Train Loss: 18.6743 (Forecasting Loss:0.0997 + XiCon Loss:1.8575 x Lambda(10.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1196
Validation loss decreased (0.206687 --> 0.206601).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9147465229034424
Epoch: 9, Steps: 69 Train Loss: 18.7101 (Forecasting Loss:0.0997 + XiCon Loss:1.8610 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1196
Validation loss decreased (0.206601 --> 0.206533).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8965504169464111
Epoch: 10, Steps: 69 Train Loss: 18.6479 (Forecasting Loss:0.0999 + XiCon Loss:1.8548 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206533 --> 0.206507).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9184591770172119
Epoch: 11, Steps: 69 Train Loss: 18.7759 (Forecasting Loss:0.0993 + XiCon Loss:1.8677 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206507 --> 0.206495).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9157023429870605
Epoch: 12, Steps: 69 Train Loss: 18.7311 (Forecasting Loss:0.0996 + XiCon Loss:1.8632 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206495 --> 0.206488).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8249921798706055
Epoch: 13, Steps: 69 Train Loss: 18.6775 (Forecasting Loss:0.0997 + XiCon Loss:1.8578 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206488 --> 0.206484).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8404932022094727
Epoch: 14, Steps: 69 Train Loss: 18.7276 (Forecasting Loss:0.0997 + XiCon Loss:1.8628 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206484 --> 0.206482).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8887124061584473
Epoch: 15, Steps: 69 Train Loss: 18.7416 (Forecasting Loss:0.0997 + XiCon Loss:1.8642 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206482 --> 0.206481).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.7997217178344727
Epoch: 16, Steps: 69 Train Loss: 18.6491 (Forecasting Loss:0.0996 + XiCon Loss:1.8549 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206481 --> 0.206480).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8886501789093018
Epoch: 17, Steps: 69 Train Loss: 18.7143 (Forecasting Loss:0.0996 + XiCon Loss:1.8615 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9064569473266602
Epoch: 18, Steps: 69 Train Loss: 18.7295 (Forecasting Loss:0.0996 + XiCon Loss:1.8630 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.7903738021850586
Epoch: 19, Steps: 69 Train Loss: 18.6813 (Forecasting Loss:0.0999 + XiCon Loss:1.8581 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8689744472503662
Epoch: 20, Steps: 69 Train Loss: 18.7127 (Forecasting Loss:0.0996 + XiCon Loss:1.8613 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8738012313842773
Epoch: 21, Steps: 69 Train Loss: 18.6819 (Forecasting Loss:0.0998 + XiCon Loss:1.8582 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8452126979827881
Epoch: 22, Steps: 69 Train Loss: 18.7213 (Forecasting Loss:0.0994 + XiCon Loss:1.8622 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9342353343963623
Epoch: 23, Steps: 69 Train Loss: 18.7329 (Forecasting Loss:0.0997 + XiCon Loss:1.8633 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8844015598297119
Epoch: 24, Steps: 69 Train Loss: 18.7388 (Forecasting Loss:0.0995 + XiCon Loss:1.8639 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9006500244140625
Epoch: 25, Steps: 69 Train Loss: 18.7086 (Forecasting Loss:0.0996 + XiCon Loss:1.8609 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8580334186553955
Epoch: 26, Steps: 69 Train Loss: 18.7251 (Forecasting Loss:0.0996 + XiCon Loss:1.8625 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8184058666229248
Epoch: 27, Steps: 69 Train Loss: 18.7180 (Forecasting Loss:0.0996 + XiCon Loss:1.8618 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
Validation loss decreased (0.206480 --> 0.206480).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.860400915145874
Epoch: 28, Steps: 69 Train Loss: 18.6990 (Forecasting Loss:0.0995 + XiCon Loss:1.8600 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8220653533935547
Epoch: 29, Steps: 69 Train Loss: 18.7663 (Forecasting Loss:0.0992 + XiCon Loss:1.8667 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8565552234649658
Epoch: 30, Steps: 69 Train Loss: 18.5963 (Forecasting Loss:0.0996 + XiCon Loss:1.8497 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8513319492340088
Epoch: 31, Steps: 69 Train Loss: 18.6749 (Forecasting Loss:0.0995 + XiCon Loss:1.8575 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.824429988861084
Epoch: 32, Steps: 69 Train Loss: 18.6548 (Forecasting Loss:0.0998 + XiCon Loss:1.8555 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8272643089294434
Epoch: 33, Steps: 69 Train Loss: 18.6448 (Forecasting Loss:0.0998 + XiCon Loss:1.8545 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9452099800109863
Epoch: 34, Steps: 69 Train Loss: 18.6891 (Forecasting Loss:0.0996 + XiCon Loss:1.8590 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8836362361907959
Epoch: 35, Steps: 69 Train Loss: 18.7134 (Forecasting Loss:0.0996 + XiCon Loss:1.8614 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.851515531539917
Epoch: 36, Steps: 69 Train Loss: 18.6849 (Forecasting Loss:0.0996 + XiCon Loss:1.8585 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8100438117980957
Epoch: 37, Steps: 69 Train Loss: 18.7120 (Forecasting Loss:0.0998 + XiCon Loss:1.8612 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1195
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05691155418753624, mae:0.18217535316944122, mape:0.12768587470054626, mspe:0.03834650665521622 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5717
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.862990140914917
Epoch: 1, Steps: 69 Train Loss: 18.4604 (Forecasting Loss:0.1309 + XiCon Loss:1.8329 x Lambda(10.0)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.282058).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8908870220184326
Epoch: 2, Steps: 69 Train Loss: 18.4393 (Forecasting Loss:0.1115 + XiCon Loss:1.8328 x Lambda(10.0)), Vali MSE Loss: 0.2146 Test MSE Loss: 0.1228
Validation loss decreased (0.282058 --> 0.214621).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9487788677215576
Epoch: 3, Steps: 69 Train Loss: 18.3592 (Forecasting Loss:0.1028 + XiCon Loss:1.8256 x Lambda(10.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1202
Validation loss decreased (0.214621 --> 0.210256).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8867335319519043
Epoch: 4, Steps: 69 Train Loss: 18.2810 (Forecasting Loss:0.1012 + XiCon Loss:1.8180 x Lambda(10.0)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1191
Validation loss decreased (0.210256 --> 0.207984).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8428170680999756
Epoch: 5, Steps: 69 Train Loss: 18.2254 (Forecasting Loss:0.1004 + XiCon Loss:1.8125 x Lambda(10.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.1189
Validation loss decreased (0.207984 --> 0.206931).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9253053665161133
Epoch: 6, Steps: 69 Train Loss: 18.2524 (Forecasting Loss:0.1002 + XiCon Loss:1.8152 x Lambda(10.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1185
Validation loss decreased (0.206931 --> 0.206421).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8117859363555908
Epoch: 7, Steps: 69 Train Loss: 18.2029 (Forecasting Loss:0.0997 + XiCon Loss:1.8103 x Lambda(10.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1184
Validation loss decreased (0.206421 --> 0.206168).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9888412952423096
Epoch: 8, Steps: 69 Train Loss: 18.2406 (Forecasting Loss:0.0999 + XiCon Loss:1.8141 x Lambda(10.0)), Vali MSE Loss: 0.2061 Test MSE Loss: 0.1183
Validation loss decreased (0.206168 --> 0.206080).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8842325210571289
Epoch: 9, Steps: 69 Train Loss: 18.2441 (Forecasting Loss:0.0997 + XiCon Loss:1.8144 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206080 --> 0.206046).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8054702281951904
Epoch: 10, Steps: 69 Train Loss: 18.1681 (Forecasting Loss:0.0998 + XiCon Loss:1.8068 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206046 --> 0.206023).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8441469669342041
Epoch: 11, Steps: 69 Train Loss: 18.1991 (Forecasting Loss:0.0996 + XiCon Loss:1.8099 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206023 --> 0.206012).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8253977298736572
Epoch: 12, Steps: 69 Train Loss: 18.2017 (Forecasting Loss:0.0996 + XiCon Loss:1.8102 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206012 --> 0.206008).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8977415561676025
Epoch: 13, Steps: 69 Train Loss: 18.1908 (Forecasting Loss:0.0999 + XiCon Loss:1.8091 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206008 --> 0.206004).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9439237117767334
Epoch: 14, Steps: 69 Train Loss: 18.2155 (Forecasting Loss:0.0999 + XiCon Loss:1.8116 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206004 --> 0.206002).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8583164215087891
Epoch: 15, Steps: 69 Train Loss: 18.2003 (Forecasting Loss:0.0999 + XiCon Loss:1.8100 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206002 --> 0.206001).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8570764064788818
Epoch: 16, Steps: 69 Train Loss: 18.2069 (Forecasting Loss:0.0998 + XiCon Loss:1.8107 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206001 --> 0.206001).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8681824207305908
Epoch: 17, Steps: 69 Train Loss: 18.2211 (Forecasting Loss:0.0995 + XiCon Loss:1.8122 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206001 --> 0.206001).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9488968849182129
Epoch: 18, Steps: 69 Train Loss: 18.1975 (Forecasting Loss:0.0998 + XiCon Loss:1.8098 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206001 --> 0.206000).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8609614372253418
Epoch: 19, Steps: 69 Train Loss: 18.2348 (Forecasting Loss:0.0997 + XiCon Loss:1.8135 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8586075305938721
Epoch: 20, Steps: 69 Train Loss: 18.2387 (Forecasting Loss:0.0997 + XiCon Loss:1.8139 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8589410781860352
Epoch: 21, Steps: 69 Train Loss: 18.2130 (Forecasting Loss:0.0999 + XiCon Loss:1.8113 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8584158420562744
Epoch: 22, Steps: 69 Train Loss: 18.1676 (Forecasting Loss:0.0997 + XiCon Loss:1.8068 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8119266033172607
Epoch: 23, Steps: 69 Train Loss: 18.1488 (Forecasting Loss:0.0996 + XiCon Loss:1.8049 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.869713544845581
Epoch: 24, Steps: 69 Train Loss: 18.1938 (Forecasting Loss:0.0999 + XiCon Loss:1.8094 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9181044101715088
Epoch: 25, Steps: 69 Train Loss: 18.2122 (Forecasting Loss:0.0998 + XiCon Loss:1.8112 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8180177211761475
Epoch: 26, Steps: 69 Train Loss: 18.2022 (Forecasting Loss:0.0997 + XiCon Loss:1.8102 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9379069805145264
Epoch: 27, Steps: 69 Train Loss: 18.1818 (Forecasting Loss:0.0997 + XiCon Loss:1.8082 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8723490238189697
Epoch: 28, Steps: 69 Train Loss: 18.2006 (Forecasting Loss:0.0999 + XiCon Loss:1.8101 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.897855281829834
Epoch: 29, Steps: 69 Train Loss: 18.1934 (Forecasting Loss:0.0998 + XiCon Loss:1.8094 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.9088113307952881
Epoch: 30, Steps: 69 Train Loss: 18.1841 (Forecasting Loss:0.0998 + XiCon Loss:1.8084 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8856005668640137
Epoch: 31, Steps: 69 Train Loss: 18.2206 (Forecasting Loss:0.0998 + XiCon Loss:1.8121 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8972337245941162
Epoch: 32, Steps: 69 Train Loss: 18.2051 (Forecasting Loss:0.0997 + XiCon Loss:1.8105 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9258091449737549
Epoch: 33, Steps: 69 Train Loss: 18.2399 (Forecasting Loss:0.0996 + XiCon Loss:1.8140 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8393387794494629
Epoch: 34, Steps: 69 Train Loss: 18.2382 (Forecasting Loss:0.0996 + XiCon Loss:1.8139 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.9180130958557129
Epoch: 35, Steps: 69 Train Loss: 18.2232 (Forecasting Loss:0.1000 + XiCon Loss:1.8123 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 1.3621022701263428
Epoch: 36, Steps: 69 Train Loss: 18.1854 (Forecasting Loss:0.0999 + XiCon Loss:1.8085 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8361096382141113
Epoch: 37, Steps: 69 Train Loss: 18.1922 (Forecasting Loss:0.0995 + XiCon Loss:1.8093 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.836165189743042
Epoch: 38, Steps: 69 Train Loss: 18.2203 (Forecasting Loss:0.0999 + XiCon Loss:1.8120 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8758065700531006
Epoch: 39, Steps: 69 Train Loss: 18.2348 (Forecasting Loss:0.0999 + XiCon Loss:1.8135 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.818711519241333
Epoch: 40, Steps: 69 Train Loss: 18.2248 (Forecasting Loss:0.0997 + XiCon Loss:1.8125 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8441731929779053
Epoch: 41, Steps: 69 Train Loss: 18.2125 (Forecasting Loss:0.0998 + XiCon Loss:1.8113 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8426535129547119
Epoch: 42, Steps: 69 Train Loss: 18.2030 (Forecasting Loss:0.0998 + XiCon Loss:1.8103 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.829399824142456
Epoch: 43, Steps: 69 Train Loss: 18.2414 (Forecasting Loss:0.0996 + XiCon Loss:1.8142 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.9187135696411133
Epoch: 44, Steps: 69 Train Loss: 18.2347 (Forecasting Loss:0.0999 + XiCon Loss:1.8135 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8278577327728271
Epoch: 45, Steps: 69 Train Loss: 18.2186 (Forecasting Loss:0.0999 + XiCon Loss:1.8119 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8427298069000244
Epoch: 46, Steps: 69 Train Loss: 18.2225 (Forecasting Loss:0.0997 + XiCon Loss:1.8123 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8105170726776123
Epoch: 47, Steps: 69 Train Loss: 18.1775 (Forecasting Loss:0.0996 + XiCon Loss:1.8078 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8468124866485596
Epoch: 48, Steps: 69 Train Loss: 18.2587 (Forecasting Loss:0.0999 + XiCon Loss:1.8159 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.9037249088287354
Epoch: 49, Steps: 69 Train Loss: 18.1724 (Forecasting Loss:0.0996 + XiCon Loss:1.8073 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.9220538139343262
Epoch: 50, Steps: 69 Train Loss: 18.1737 (Forecasting Loss:0.0997 + XiCon Loss:1.8074 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.9179623126983643
Epoch: 51, Steps: 69 Train Loss: 18.2082 (Forecasting Loss:0.0998 + XiCon Loss:1.8108 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.7946960926055908
Epoch: 52, Steps: 69 Train Loss: 18.2517 (Forecasting Loss:0.0997 + XiCon Loss:1.8152 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.9054911136627197
Epoch: 53, Steps: 69 Train Loss: 18.2172 (Forecasting Loss:0.0996 + XiCon Loss:1.8118 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8240082263946533
Epoch: 54, Steps: 69 Train Loss: 18.1999 (Forecasting Loss:0.0999 + XiCon Loss:1.8100 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.910869836807251
Epoch: 55, Steps: 69 Train Loss: 18.2533 (Forecasting Loss:0.0996 + XiCon Loss:1.8154 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8676226139068604
Epoch: 56, Steps: 69 Train Loss: 18.2336 (Forecasting Loss:0.0996 + XiCon Loss:1.8134 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.8513908386230469
Epoch: 57, Steps: 69 Train Loss: 18.2366 (Forecasting Loss:0.0999 + XiCon Loss:1.8137 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.8518788814544678
Epoch: 58, Steps: 69 Train Loss: 18.1854 (Forecasting Loss:0.0994 + XiCon Loss:1.8086 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.9045505523681641
Epoch: 59, Steps: 69 Train Loss: 18.2210 (Forecasting Loss:0.0999 + XiCon Loss:1.8121 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.88797926902771
Epoch: 60, Steps: 69 Train Loss: 18.2552 (Forecasting Loss:0.0997 + XiCon Loss:1.8156 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.8361735343933105
Epoch: 61, Steps: 69 Train Loss: 18.1926 (Forecasting Loss:0.0997 + XiCon Loss:1.8093 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 1.0123684406280518
Epoch: 62, Steps: 69 Train Loss: 18.2383 (Forecasting Loss:0.0999 + XiCon Loss:1.8138 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.889545202255249
Epoch: 63, Steps: 69 Train Loss: 18.1963 (Forecasting Loss:0.0997 + XiCon Loss:1.8097 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.817589521408081
Epoch: 64, Steps: 69 Train Loss: 18.2201 (Forecasting Loss:0.0994 + XiCon Loss:1.8121 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.8603730201721191
Epoch: 65, Steps: 69 Train Loss: 18.2363 (Forecasting Loss:0.1000 + XiCon Loss:1.8136 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.9292407035827637
Epoch: 66, Steps: 69 Train Loss: 18.2242 (Forecasting Loss:0.0998 + XiCon Loss:1.8124 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.9047274589538574
Epoch: 67, Steps: 69 Train Loss: 18.2064 (Forecasting Loss:0.0997 + XiCon Loss:1.8107 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.8061361312866211
Epoch: 68, Steps: 69 Train Loss: 18.2233 (Forecasting Loss:0.0999 + XiCon Loss:1.8123 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.8581092357635498
Epoch: 69, Steps: 69 Train Loss: 18.1963 (Forecasting Loss:0.0998 + XiCon Loss:1.8097 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.8814206123352051
Epoch: 70, Steps: 69 Train Loss: 18.2247 (Forecasting Loss:0.0996 + XiCon Loss:1.8125 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 0.9244194030761719
Epoch: 71, Steps: 69 Train Loss: 18.2411 (Forecasting Loss:0.0996 + XiCon Loss:1.8142 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.8390085697174072
Epoch: 72, Steps: 69 Train Loss: 18.2029 (Forecasting Loss:0.1000 + XiCon Loss:1.8103 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.8099277019500732
Epoch: 73, Steps: 69 Train Loss: 18.2241 (Forecasting Loss:0.0999 + XiCon Loss:1.8124 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.8899710178375244
Epoch: 74, Steps: 69 Train Loss: 18.2456 (Forecasting Loss:0.0997 + XiCon Loss:1.8146 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
Validation loss decreased (0.206000 --> 0.206000).  Saving model ...
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.8871450424194336
Epoch: 75, Steps: 69 Train Loss: 18.2514 (Forecasting Loss:0.0998 + XiCon Loss:1.8152 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.8964836597442627
Epoch: 76, Steps: 69 Train Loss: 18.2341 (Forecasting Loss:0.0996 + XiCon Loss:1.8135 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.8691070079803467
Epoch: 77, Steps: 69 Train Loss: 18.2277 (Forecasting Loss:0.0998 + XiCon Loss:1.8128 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 0.8995726108551025
Epoch: 78, Steps: 69 Train Loss: 18.1871 (Forecasting Loss:0.0995 + XiCon Loss:1.8088 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.8875808715820312
Epoch: 79, Steps: 69 Train Loss: 18.2122 (Forecasting Loss:0.0997 + XiCon Loss:1.8112 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 0.928037166595459
Epoch: 80, Steps: 69 Train Loss: 18.1898 (Forecasting Loss:0.0996 + XiCon Loss:1.8090 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.8333492279052734
Epoch: 81, Steps: 69 Train Loss: 18.2083 (Forecasting Loss:0.0995 + XiCon Loss:1.8109 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 7 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.8722543716430664
Epoch: 82, Steps: 69 Train Loss: 18.2118 (Forecasting Loss:0.0997 + XiCon Loss:1.8112 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.8280131816864014
Epoch: 83, Steps: 69 Train Loss: 18.2159 (Forecasting Loss:0.0996 + XiCon Loss:1.8116 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 0.8740408420562744
Epoch: 84, Steps: 69 Train Loss: 18.2042 (Forecasting Loss:0.0997 + XiCon Loss:1.8104 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1183
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.056262578815221786, mae:0.18027082085609436, mape:0.12658876180648804, mspe:0.03822847828269005 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5532
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8537158966064453
Epoch: 1, Steps: 69 Train Loss: 18.4990 (Forecasting Loss:0.1348 + XiCon Loss:1.8364 x Lambda(10.0)), Vali MSE Loss: 0.2912 Test MSE Loss: 0.1522
Validation loss decreased (inf --> 0.291229).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8575150966644287
Epoch: 2, Steps: 69 Train Loss: 18.4470 (Forecasting Loss:0.1129 + XiCon Loss:1.8334 x Lambda(10.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1223
Validation loss decreased (0.291229 --> 0.214212).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.8051719665527344
Epoch: 3, Steps: 69 Train Loss: 18.3899 (Forecasting Loss:0.1027 + XiCon Loss:1.8287 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1198
Validation loss decreased (0.214212 --> 0.209836).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9014759063720703
Epoch: 4, Steps: 69 Train Loss: 18.2645 (Forecasting Loss:0.1013 + XiCon Loss:1.8163 x Lambda(10.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1199
Validation loss decreased (0.209836 --> 0.208478).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8131604194641113
Epoch: 5, Steps: 69 Train Loss: 18.3458 (Forecasting Loss:0.1006 + XiCon Loss:1.8245 x Lambda(10.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1195
Validation loss decreased (0.208478 --> 0.206636).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8381409645080566
Epoch: 6, Steps: 69 Train Loss: 18.5290 (Forecasting Loss:0.1004 + XiCon Loss:1.8429 x Lambda(10.0)), Vali MSE Loss: 0.2062 Test MSE Loss: 0.1190
Validation loss decreased (0.206636 --> 0.206151).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8646109104156494
Epoch: 7, Steps: 69 Train Loss: 18.5918 (Forecasting Loss:0.1003 + XiCon Loss:1.8492 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1189
Validation loss decreased (0.206151 --> 0.206028).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9291515350341797
Epoch: 8, Steps: 69 Train Loss: 18.6352 (Forecasting Loss:0.1003 + XiCon Loss:1.8535 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1188
Validation loss decreased (0.206028 --> 0.206021).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8755724430084229
Epoch: 9, Steps: 69 Train Loss: 18.6656 (Forecasting Loss:0.1004 + XiCon Loss:1.8565 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1188
Validation loss decreased (0.206021 --> 0.205996).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.7988193035125732
Epoch: 10, Steps: 69 Train Loss: 18.6823 (Forecasting Loss:0.1000 + XiCon Loss:1.8582 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8895900249481201
Epoch: 11, Steps: 69 Train Loss: 18.7365 (Forecasting Loss:0.1001 + XiCon Loss:1.8636 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205996 --> 0.205995).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.7997288703918457
Epoch: 12, Steps: 69 Train Loss: 18.6701 (Forecasting Loss:0.1000 + XiCon Loss:1.8570 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8561408519744873
Epoch: 13, Steps: 69 Train Loss: 18.7389 (Forecasting Loss:0.1001 + XiCon Loss:1.8639 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205995 --> 0.205994).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8534543514251709
Epoch: 14, Steps: 69 Train Loss: 18.6976 (Forecasting Loss:0.1001 + XiCon Loss:1.8598 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.7925772666931152
Epoch: 15, Steps: 69 Train Loss: 18.7466 (Forecasting Loss:0.1001 + XiCon Loss:1.8647 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9410481452941895
Epoch: 16, Steps: 69 Train Loss: 18.6961 (Forecasting Loss:0.1002 + XiCon Loss:1.8596 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.7804162502288818
Epoch: 17, Steps: 69 Train Loss: 18.6570 (Forecasting Loss:0.1002 + XiCon Loss:1.8557 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.8427557945251465
Epoch: 18, Steps: 69 Train Loss: 18.6723 (Forecasting Loss:0.1001 + XiCon Loss:1.8572 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.809898853302002
Epoch: 19, Steps: 69 Train Loss: 18.7522 (Forecasting Loss:0.0999 + XiCon Loss:1.8652 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8366239070892334
Epoch: 20, Steps: 69 Train Loss: 18.6010 (Forecasting Loss:0.1000 + XiCon Loss:1.8501 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8062617778778076
Epoch: 21, Steps: 69 Train Loss: 18.6905 (Forecasting Loss:0.1000 + XiCon Loss:1.8591 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8603143692016602
Epoch: 22, Steps: 69 Train Loss: 18.6239 (Forecasting Loss:0.1002 + XiCon Loss:1.8524 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9006500244140625
Epoch: 23, Steps: 69 Train Loss: 18.7479 (Forecasting Loss:0.1000 + XiCon Loss:1.8648 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.7943789958953857
Epoch: 24, Steps: 69 Train Loss: 18.6887 (Forecasting Loss:0.0998 + XiCon Loss:1.8589 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8327212333679199
Epoch: 25, Steps: 69 Train Loss: 18.6279 (Forecasting Loss:0.1001 + XiCon Loss:1.8528 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.7724535465240479
Epoch: 26, Steps: 69 Train Loss: 18.7239 (Forecasting Loss:0.1000 + XiCon Loss:1.8624 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.7749960422515869
Epoch: 27, Steps: 69 Train Loss: 18.7504 (Forecasting Loss:0.1000 + XiCon Loss:1.8650 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.7660398483276367
Epoch: 28, Steps: 69 Train Loss: 18.6720 (Forecasting Loss:0.1001 + XiCon Loss:1.8572 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8368864059448242
Epoch: 29, Steps: 69 Train Loss: 18.7674 (Forecasting Loss:0.1000 + XiCon Loss:1.8667 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8217337131500244
Epoch: 30, Steps: 69 Train Loss: 18.6959 (Forecasting Loss:0.1001 + XiCon Loss:1.8596 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8437404632568359
Epoch: 31, Steps: 69 Train Loss: 18.6905 (Forecasting Loss:0.0998 + XiCon Loss:1.8591 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.7777352333068848
Epoch: 32, Steps: 69 Train Loss: 18.6441 (Forecasting Loss:0.1002 + XiCon Loss:1.8544 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8223090171813965
Epoch: 33, Steps: 69 Train Loss: 18.7103 (Forecasting Loss:0.1001 + XiCon Loss:1.8610 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
Validation loss decreased (0.205994 --> 0.205994).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8104925155639648
Epoch: 34, Steps: 69 Train Loss: 18.6599 (Forecasting Loss:0.1001 + XiCon Loss:1.8560 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.7821905612945557
Epoch: 35, Steps: 69 Train Loss: 18.7498 (Forecasting Loss:0.1000 + XiCon Loss:1.8650 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.7960896492004395
Epoch: 36, Steps: 69 Train Loss: 18.6842 (Forecasting Loss:0.1001 + XiCon Loss:1.8584 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8436934947967529
Epoch: 37, Steps: 69 Train Loss: 18.6535 (Forecasting Loss:0.1001 + XiCon Loss:1.8553 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.7692813873291016
Epoch: 38, Steps: 69 Train Loss: 18.7180 (Forecasting Loss:0.1001 + XiCon Loss:1.8618 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.7629873752593994
Epoch: 39, Steps: 69 Train Loss: 18.7045 (Forecasting Loss:0.1001 + XiCon Loss:1.8604 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.7634792327880859
Epoch: 40, Steps: 69 Train Loss: 18.6999 (Forecasting Loss:0.1002 + XiCon Loss:1.8600 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.7492105960845947
Epoch: 41, Steps: 69 Train Loss: 18.6614 (Forecasting Loss:0.0998 + XiCon Loss:1.8562 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8154654502868652
Epoch: 42, Steps: 69 Train Loss: 18.6636 (Forecasting Loss:0.1002 + XiCon Loss:1.8563 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9454154968261719
Epoch: 43, Steps: 69 Train Loss: 18.6113 (Forecasting Loss:0.1003 + XiCon Loss:1.8511 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1187
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.056684643030166626, mae:0.18076404929161072, mape:0.12737764418125153, mspe:0.038870494812726974 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6139
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8125572204589844
Epoch: 1, Steps: 69 Train Loss: 18.4640 (Forecasting Loss:0.1344 + XiCon Loss:1.8330 x Lambda(10.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.1527
Validation loss decreased (inf --> 0.288525).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9046931266784668
Epoch: 2, Steps: 69 Train Loss: 18.4071 (Forecasting Loss:0.1131 + XiCon Loss:1.8294 x Lambda(10.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1238
Validation loss decreased (0.288525 --> 0.216630).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.84908127784729
Epoch: 3, Steps: 69 Train Loss: 18.8131 (Forecasting Loss:0.1039 + XiCon Loss:1.8709 x Lambda(10.0)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1212
Validation loss decreased (0.216630 --> 0.211848).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8083975315093994
Epoch: 4, Steps: 69 Train Loss: 19.0262 (Forecasting Loss:0.1022 + XiCon Loss:1.8924 x Lambda(10.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1204
Validation loss decreased (0.211848 --> 0.209806).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.8949754238128662
Epoch: 5, Steps: 69 Train Loss: 19.1472 (Forecasting Loss:0.1014 + XiCon Loss:1.9046 x Lambda(10.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1200
Validation loss decreased (0.209806 --> 0.208958).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8387975692749023
Epoch: 6, Steps: 69 Train Loss: 19.2632 (Forecasting Loss:0.1011 + XiCon Loss:1.9162 x Lambda(10.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1198
Validation loss decreased (0.208958 --> 0.208508).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.7728786468505859
Epoch: 7, Steps: 69 Train Loss: 19.2533 (Forecasting Loss:0.1010 + XiCon Loss:1.9152 x Lambda(10.0)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1197
Validation loss decreased (0.208508 --> 0.208328).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8078982830047607
Epoch: 8, Steps: 69 Train Loss: 19.2473 (Forecasting Loss:0.1010 + XiCon Loss:1.9146 x Lambda(10.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1197
Validation loss decreased (0.208328 --> 0.208199).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9223477840423584
Epoch: 9, Steps: 69 Train Loss: 19.3125 (Forecasting Loss:0.1008 + XiCon Loss:1.9212 x Lambda(10.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1197
Validation loss decreased (0.208199 --> 0.208150).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.8744375705718994
Epoch: 10, Steps: 69 Train Loss: 19.1832 (Forecasting Loss:0.1011 + XiCon Loss:1.9082 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1197
Validation loss decreased (0.208150 --> 0.208122).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9275550842285156
Epoch: 11, Steps: 69 Train Loss: 19.1800 (Forecasting Loss:0.1010 + XiCon Loss:1.9079 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1197
Validation loss decreased (0.208122 --> 0.208102).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8574562072753906
Epoch: 12, Steps: 69 Train Loss: 19.2896 (Forecasting Loss:0.1009 + XiCon Loss:1.9189 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208102 --> 0.208095).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8031258583068848
Epoch: 13, Steps: 69 Train Loss: 19.2982 (Forecasting Loss:0.1010 + XiCon Loss:1.9197 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208095 --> 0.208091).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.910820722579956
Epoch: 14, Steps: 69 Train Loss: 19.1732 (Forecasting Loss:0.1009 + XiCon Loss:1.9072 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208091 --> 0.208090).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8661332130432129
Epoch: 15, Steps: 69 Train Loss: 19.2127 (Forecasting Loss:0.1008 + XiCon Loss:1.9112 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208090 --> 0.208088).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9783282279968262
Epoch: 16, Steps: 69 Train Loss: 19.2250 (Forecasting Loss:0.1009 + XiCon Loss:1.9124 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208088 --> 0.208088).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8706307411193848
Epoch: 17, Steps: 69 Train Loss: 19.2892 (Forecasting Loss:0.1008 + XiCon Loss:1.9188 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208088 --> 0.208088).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.807692289352417
Epoch: 18, Steps: 69 Train Loss: 19.1504 (Forecasting Loss:0.1008 + XiCon Loss:1.9050 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208088 --> 0.208087).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8870210647583008
Epoch: 19, Steps: 69 Train Loss: 19.2999 (Forecasting Loss:0.1005 + XiCon Loss:1.9199 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8615601062774658
Epoch: 20, Steps: 69 Train Loss: 19.3362 (Forecasting Loss:0.1009 + XiCon Loss:1.9235 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9323079586029053
Epoch: 21, Steps: 69 Train Loss: 19.3084 (Forecasting Loss:0.1010 + XiCon Loss:1.9207 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8280768394470215
Epoch: 22, Steps: 69 Train Loss: 19.2120 (Forecasting Loss:0.1009 + XiCon Loss:1.9111 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8278839588165283
Epoch: 23, Steps: 69 Train Loss: 19.2068 (Forecasting Loss:0.1008 + XiCon Loss:1.9106 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8511559963226318
Epoch: 24, Steps: 69 Train Loss: 19.1865 (Forecasting Loss:0.1008 + XiCon Loss:1.9086 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8711929321289062
Epoch: 25, Steps: 69 Train Loss: 19.2504 (Forecasting Loss:0.1009 + XiCon Loss:1.9150 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8019585609436035
Epoch: 26, Steps: 69 Train Loss: 19.2640 (Forecasting Loss:0.1008 + XiCon Loss:1.9163 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8792941570281982
Epoch: 27, Steps: 69 Train Loss: 19.2696 (Forecasting Loss:0.1006 + XiCon Loss:1.9169 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8482608795166016
Epoch: 28, Steps: 69 Train Loss: 19.2563 (Forecasting Loss:0.1008 + XiCon Loss:1.9155 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8030366897583008
Epoch: 29, Steps: 69 Train Loss: 19.3256 (Forecasting Loss:0.1009 + XiCon Loss:1.9225 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8790109157562256
Epoch: 30, Steps: 69 Train Loss: 19.2631 (Forecasting Loss:0.1010 + XiCon Loss:1.9162 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.840045690536499
Epoch: 31, Steps: 69 Train Loss: 19.3678 (Forecasting Loss:0.1007 + XiCon Loss:1.9267 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9522900581359863
Epoch: 32, Steps: 69 Train Loss: 19.3243 (Forecasting Loss:0.1010 + XiCon Loss:1.9223 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8610978126525879
Epoch: 33, Steps: 69 Train Loss: 19.2394 (Forecasting Loss:0.1009 + XiCon Loss:1.9139 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9066298007965088
Epoch: 34, Steps: 69 Train Loss: 19.1883 (Forecasting Loss:0.1007 + XiCon Loss:1.9088 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.916839599609375
Epoch: 35, Steps: 69 Train Loss: 19.2962 (Forecasting Loss:0.1007 + XiCon Loss:1.9196 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.862220048904419
Epoch: 36, Steps: 69 Train Loss: 19.2248 (Forecasting Loss:0.1008 + XiCon Loss:1.9124 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8455359935760498
Epoch: 37, Steps: 69 Train Loss: 19.2631 (Forecasting Loss:0.1008 + XiCon Loss:1.9162 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.879819393157959
Epoch: 38, Steps: 69 Train Loss: 19.3052 (Forecasting Loss:0.1008 + XiCon Loss:1.9204 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8685359954833984
Epoch: 39, Steps: 69 Train Loss: 19.2159 (Forecasting Loss:0.1010 + XiCon Loss:1.9115 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
Validation loss decreased (0.208087 --> 0.208087).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9180598258972168
Epoch: 40, Steps: 69 Train Loss: 19.3340 (Forecasting Loss:0.1008 + XiCon Loss:1.9233 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8568780422210693
Epoch: 41, Steps: 69 Train Loss: 19.2653 (Forecasting Loss:0.1010 + XiCon Loss:1.9164 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.862445592880249
Epoch: 42, Steps: 69 Train Loss: 19.2401 (Forecasting Loss:0.1009 + XiCon Loss:1.9139 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9171459674835205
Epoch: 43, Steps: 69 Train Loss: 19.2054 (Forecasting Loss:0.1011 + XiCon Loss:1.9104 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.952721118927002
Epoch: 44, Steps: 69 Train Loss: 19.2382 (Forecasting Loss:0.1008 + XiCon Loss:1.9137 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.9033463001251221
Epoch: 45, Steps: 69 Train Loss: 19.2459 (Forecasting Loss:0.1009 + XiCon Loss:1.9145 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8887596130371094
Epoch: 46, Steps: 69 Train Loss: 19.2558 (Forecasting Loss:0.1007 + XiCon Loss:1.9155 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8357951641082764
Epoch: 47, Steps: 69 Train Loss: 19.2062 (Forecasting Loss:0.1008 + XiCon Loss:1.9105 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.899000883102417
Epoch: 48, Steps: 69 Train Loss: 19.1819 (Forecasting Loss:0.1010 + XiCon Loss:1.9081 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8632993698120117
Epoch: 49, Steps: 69 Train Loss: 19.2813 (Forecasting Loss:0.1005 + XiCon Loss:1.9181 x Lambda(10.0)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1196
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05719120427966118, mae:0.18209733068943024, mape:0.12807334959506989, mspe:0.03891525790095329 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0566+-0.00069, MAE:0.1811+-0.00116, MAPE:0.1272+-0.00091, MSPE:0.0384+-0.00071, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6508
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.3102617263793945
Epoch: 1, Steps: 64 Train Loss: 19.9252 (Forecasting Loss:0.5016 + XiCon Loss:1.9424 x Lambda(10.0)), Vali MSE Loss: 0.9639 Test MSE Loss: 0.5135
Validation loss decreased (inf --> 0.963855).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9166533946990967
Epoch: 2, Steps: 64 Train Loss: 19.9103 (Forecasting Loss:0.4974 + XiCon Loss:1.9413 x Lambda(10.0)), Vali MSE Loss: 0.9529 Test MSE Loss: 0.5068
Validation loss decreased (0.963855 --> 0.952946).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9273853302001953
Epoch: 3, Steps: 64 Train Loss: 19.9017 (Forecasting Loss:0.4909 + XiCon Loss:1.9411 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.5042
Validation loss decreased (0.952946 --> 0.942599).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9728162288665771
Epoch: 4, Steps: 64 Train Loss: 19.8747 (Forecasting Loss:0.4890 + XiCon Loss:1.9386 x Lambda(10.0)), Vali MSE Loss: 0.9451 Test MSE Loss: 0.5029
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.96488356590271
Epoch: 5, Steps: 64 Train Loss: 19.8835 (Forecasting Loss:0.4864 + XiCon Loss:1.9397 x Lambda(10.0)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5023
Validation loss decreased (0.942599 --> 0.938758).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9029958248138428
Epoch: 6, Steps: 64 Train Loss: 19.8848 (Forecasting Loss:0.4857 + XiCon Loss:1.9399 x Lambda(10.0)), Vali MSE Loss: 0.9389 Test MSE Loss: 0.5020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9203004837036133
Epoch: 7, Steps: 64 Train Loss: 19.8836 (Forecasting Loss:0.4858 + XiCon Loss:1.9398 x Lambda(10.0)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.5019
Validation loss decreased (0.938758 --> 0.936983).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8663694858551025
Epoch: 8, Steps: 64 Train Loss: 19.8974 (Forecasting Loss:0.4855 + XiCon Loss:1.9412 x Lambda(10.0)), Vali MSE Loss: 0.9368 Test MSE Loss: 0.5018
Validation loss decreased (0.936983 --> 0.936768).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9387106895446777
Epoch: 9, Steps: 64 Train Loss: 19.8871 (Forecasting Loss:0.4848 + XiCon Loss:1.9402 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5018
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9125099182128906
Epoch: 10, Steps: 64 Train Loss: 19.8802 (Forecasting Loss:0.4844 + XiCon Loss:1.9396 x Lambda(10.0)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9399135112762451
Epoch: 11, Steps: 64 Train Loss: 19.8738 (Forecasting Loss:0.4856 + XiCon Loss:1.9388 x Lambda(10.0)), Vali MSE Loss: 0.9385 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.89988112449646
Epoch: 12, Steps: 64 Train Loss: 19.9108 (Forecasting Loss:0.4852 + XiCon Loss:1.9426 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.87019944190979
Epoch: 13, Steps: 64 Train Loss: 19.8713 (Forecasting Loss:0.4855 + XiCon Loss:1.9386 x Lambda(10.0)), Vali MSE Loss: 0.9397 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9460806846618652
Epoch: 14, Steps: 64 Train Loss: 19.8822 (Forecasting Loss:0.4847 + XiCon Loss:1.9398 x Lambda(10.0)), Vali MSE Loss: 0.9387 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.998337984085083
Epoch: 15, Steps: 64 Train Loss: 19.8701 (Forecasting Loss:0.4859 + XiCon Loss:1.9384 x Lambda(10.0)), Vali MSE Loss: 0.9419 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9570355415344238
Epoch: 16, Steps: 64 Train Loss: 19.8663 (Forecasting Loss:0.4849 + XiCon Loss:1.9381 x Lambda(10.0)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9115562438964844
Epoch: 17, Steps: 64 Train Loss: 19.8877 (Forecasting Loss:0.4858 + XiCon Loss:1.9402 x Lambda(10.0)), Vali MSE Loss: 0.9358 Test MSE Loss: 0.5017
Validation loss decreased (0.936768 --> 0.935774).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.0064733028411865
Epoch: 18, Steps: 64 Train Loss: 19.8795 (Forecasting Loss:0.4857 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9111394882202148
Epoch: 19, Steps: 64 Train Loss: 19.8831 (Forecasting Loss:0.4857 + XiCon Loss:1.9397 x Lambda(10.0)), Vali MSE Loss: 0.9390 Test MSE Loss: 0.5017
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9368159770965576
Epoch: 20, Steps: 64 Train Loss: 19.8690 (Forecasting Loss:0.4852 + XiCon Loss:1.9384 x Lambda(10.0)), Vali MSE Loss: 0.9392 Test MSE Loss: 0.5017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9062511920928955
Epoch: 21, Steps: 64 Train Loss: 19.8878 (Forecasting Loss:0.4847 + XiCon Loss:1.9403 x Lambda(10.0)), Vali MSE Loss: 0.9366 Test MSE Loss: 0.5017
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9417688846588135
Epoch: 22, Steps: 64 Train Loss: 19.9046 (Forecasting Loss:0.4847 + XiCon Loss:1.9420 x Lambda(10.0)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5017
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.918971061706543
Epoch: 23, Steps: 64 Train Loss: 19.8822 (Forecasting Loss:0.4845 + XiCon Loss:1.9398 x Lambda(10.0)), Vali MSE Loss: 0.9373 Test MSE Loss: 0.5017
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.8603434562683105
Epoch: 24, Steps: 64 Train Loss: 19.8665 (Forecasting Loss:0.4857 + XiCon Loss:1.9381 x Lambda(10.0)), Vali MSE Loss: 0.9394 Test MSE Loss: 0.5017
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9720721244812012
Epoch: 25, Steps: 64 Train Loss: 19.8865 (Forecasting Loss:0.4846 + XiCon Loss:1.9402 x Lambda(10.0)), Vali MSE Loss: 0.9402 Test MSE Loss: 0.5017
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8939313888549805
Epoch: 26, Steps: 64 Train Loss: 19.8982 (Forecasting Loss:0.4845 + XiCon Loss:1.9414 x Lambda(10.0)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5017
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9182305335998535
Epoch: 27, Steps: 64 Train Loss: 19.8774 (Forecasting Loss:0.4851 + XiCon Loss:1.9392 x Lambda(10.0)), Vali MSE Loss: 0.9399 Test MSE Loss: 0.5017
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4701686501502991, mae:0.5332624316215515, mape:0.44959333539009094, mspe:0.5999889969825745 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6064
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9198808670043945
Epoch: 1, Steps: 64 Train Loss: 19.8776 (Forecasting Loss:0.4928 + XiCon Loss:1.9385 x Lambda(10.0)), Vali MSE Loss: 0.9330 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932956).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9025118350982666
Epoch: 2, Steps: 64 Train Loss: 19.8661 (Forecasting Loss:0.4901 + XiCon Loss:1.9376 x Lambda(10.0)), Vali MSE Loss: 0.9151 Test MSE Loss: 0.5154
Validation loss decreased (0.932956 --> 0.915082).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.898015022277832
Epoch: 3, Steps: 64 Train Loss: 19.8617 (Forecasting Loss:0.4837 + XiCon Loss:1.9378 x Lambda(10.0)), Vali MSE Loss: 0.9128 Test MSE Loss: 0.5130
Validation loss decreased (0.915082 --> 0.912766).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.021144151687622
Epoch: 4, Steps: 64 Train Loss: 19.8796 (Forecasting Loss:0.4808 + XiCon Loss:1.9399 x Lambda(10.0)), Vali MSE Loss: 0.9097 Test MSE Loss: 0.5118
Validation loss decreased (0.912766 --> 0.909692).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9553985595703125
Epoch: 5, Steps: 64 Train Loss: 19.8747 (Forecasting Loss:0.4798 + XiCon Loss:1.9395 x Lambda(10.0)), Vali MSE Loss: 0.9071 Test MSE Loss: 0.5113
Validation loss decreased (0.909692 --> 0.907146).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8954329490661621
Epoch: 6, Steps: 64 Train Loss: 19.8476 (Forecasting Loss:0.4799 + XiCon Loss:1.9368 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5110
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9816217422485352
Epoch: 7, Steps: 64 Train Loss: 19.8478 (Forecasting Loss:0.4789 + XiCon Loss:1.9369 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5109
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9920198917388916
Epoch: 8, Steps: 64 Train Loss: 19.8567 (Forecasting Loss:0.4784 + XiCon Loss:1.9378 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5108
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9320573806762695
Epoch: 9, Steps: 64 Train Loss: 19.8682 (Forecasting Loss:0.4793 + XiCon Loss:1.9389 x Lambda(10.0)), Vali MSE Loss: 0.9080 Test MSE Loss: 0.5108
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9311695098876953
Epoch: 10, Steps: 64 Train Loss: 19.8799 (Forecasting Loss:0.4788 + XiCon Loss:1.9401 x Lambda(10.0)), Vali MSE Loss: 0.9077 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.0046336650848389
Epoch: 11, Steps: 64 Train Loss: 19.8686 (Forecasting Loss:0.4778 + XiCon Loss:1.9391 x Lambda(10.0)), Vali MSE Loss: 0.9085 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.8960249423980713
Epoch: 12, Steps: 64 Train Loss: 19.8443 (Forecasting Loss:0.4791 + XiCon Loss:1.9365 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
Validation loss decreased (0.907146 --> 0.906438).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.0132288932800293
Epoch: 13, Steps: 64 Train Loss: 19.8536 (Forecasting Loss:0.4778 + XiCon Loss:1.9376 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906438 --> 0.906220).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9267096519470215
Epoch: 14, Steps: 64 Train Loss: 19.8658 (Forecasting Loss:0.4780 + XiCon Loss:1.9388 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9484460353851318
Epoch: 15, Steps: 64 Train Loss: 19.8461 (Forecasting Loss:0.4801 + XiCon Loss:1.9366 x Lambda(10.0)), Vali MSE Loss: 0.9095 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.879368782043457
Epoch: 16, Steps: 64 Train Loss: 19.8532 (Forecasting Loss:0.4790 + XiCon Loss:1.9374 x Lambda(10.0)), Vali MSE Loss: 0.9062 Test MSE Loss: 0.5107
Validation loss decreased (0.906220 --> 0.906192).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.8589789867401123
Epoch: 17, Steps: 64 Train Loss: 19.8626 (Forecasting Loss:0.4784 + XiCon Loss:1.9384 x Lambda(10.0)), Vali MSE Loss: 0.9035 Test MSE Loss: 0.5107
Validation loss decreased (0.906192 --> 0.903499).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9816794395446777
Epoch: 18, Steps: 64 Train Loss: 19.8715 (Forecasting Loss:0.4780 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9271843433380127
Epoch: 19, Steps: 64 Train Loss: 19.8587 (Forecasting Loss:0.4789 + XiCon Loss:1.9380 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9244630336761475
Epoch: 20, Steps: 64 Train Loss: 19.8490 (Forecasting Loss:0.4784 + XiCon Loss:1.9371 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.891639232635498
Epoch: 21, Steps: 64 Train Loss: 19.8649 (Forecasting Loss:0.4780 + XiCon Loss:1.9387 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.000544548034668
Epoch: 22, Steps: 64 Train Loss: 19.8518 (Forecasting Loss:0.4784 + XiCon Loss:1.9373 x Lambda(10.0)), Vali MSE Loss: 0.9012 Test MSE Loss: 0.5107
Validation loss decreased (0.903499 --> 0.901205).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9202771186828613
Epoch: 23, Steps: 64 Train Loss: 19.8601 (Forecasting Loss:0.4781 + XiCon Loss:1.9382 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9625306129455566
Epoch: 24, Steps: 64 Train Loss: 19.8554 (Forecasting Loss:0.4786 + XiCon Loss:1.9377 x Lambda(10.0)), Vali MSE Loss: 0.9064 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9876720905303955
Epoch: 25, Steps: 64 Train Loss: 19.8569 (Forecasting Loss:0.4777 + XiCon Loss:1.9379 x Lambda(10.0)), Vali MSE Loss: 0.9028 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9194035530090332
Epoch: 26, Steps: 64 Train Loss: 19.8590 (Forecasting Loss:0.4798 + XiCon Loss:1.9379 x Lambda(10.0)), Vali MSE Loss: 0.9050 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.8984799385070801
Epoch: 27, Steps: 64 Train Loss: 19.8592 (Forecasting Loss:0.4790 + XiCon Loss:1.9380 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.9978787899017334
Epoch: 28, Steps: 64 Train Loss: 19.8547 (Forecasting Loss:0.4782 + XiCon Loss:1.9377 x Lambda(10.0)), Vali MSE Loss: 0.9074 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 0.871556282043457
Epoch: 29, Steps: 64 Train Loss: 19.8623 (Forecasting Loss:0.4786 + XiCon Loss:1.9384 x Lambda(10.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5107
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 1.0316381454467773
Epoch: 30, Steps: 64 Train Loss: 19.8548 (Forecasting Loss:0.4779 + XiCon Loss:1.9377 x Lambda(10.0)), Vali MSE Loss: 0.9104 Test MSE Loss: 0.5107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 1.001075267791748
Epoch: 31, Steps: 64 Train Loss: 19.8666 (Forecasting Loss:0.4793 + XiCon Loss:1.9387 x Lambda(10.0)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 0.9269206523895264
Epoch: 32, Steps: 64 Train Loss: 19.8503 (Forecasting Loss:0.4787 + XiCon Loss:1.9372 x Lambda(10.0)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5107
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.48464083671569824, mae:0.5368222594261169, mape:0.45702794194221497, mspe:0.6300187110900879 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5718
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9713070392608643
Epoch: 1, Steps: 64 Train Loss: 19.9094 (Forecasting Loss:0.5013 + XiCon Loss:1.9408 x Lambda(10.0)), Vali MSE Loss: 0.9739 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973866).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9609558582305908
Epoch: 2, Steps: 64 Train Loss: 19.9379 (Forecasting Loss:0.4983 + XiCon Loss:1.9440 x Lambda(10.0)), Vali MSE Loss: 0.9577 Test MSE Loss: 0.5002
Validation loss decreased (0.973866 --> 0.957698).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9444119930267334
Epoch: 3, Steps: 64 Train Loss: 19.8922 (Forecasting Loss:0.4914 + XiCon Loss:1.9401 x Lambda(10.0)), Vali MSE Loss: 0.9526 Test MSE Loss: 0.4981
Validation loss decreased (0.957698 --> 0.952623).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9572513103485107
Epoch: 4, Steps: 64 Train Loss: 19.9105 (Forecasting Loss:0.4903 + XiCon Loss:1.9420 x Lambda(10.0)), Vali MSE Loss: 0.9508 Test MSE Loss: 0.4972
Validation loss decreased (0.952623 --> 0.950827).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9173362255096436
Epoch: 5, Steps: 64 Train Loss: 19.8903 (Forecasting Loss:0.4878 + XiCon Loss:1.9402 x Lambda(10.0)), Vali MSE Loss: 0.9474 Test MSE Loss: 0.4968
Validation loss decreased (0.950827 --> 0.947363).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9721400737762451
Epoch: 6, Steps: 64 Train Loss: 19.8921 (Forecasting Loss:0.4877 + XiCon Loss:1.9404 x Lambda(10.0)), Vali MSE Loss: 0.9504 Test MSE Loss: 0.4966
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9065749645233154
Epoch: 7, Steps: 64 Train Loss: 19.8961 (Forecasting Loss:0.4863 + XiCon Loss:1.9410 x Lambda(10.0)), Vali MSE Loss: 0.9440 Test MSE Loss: 0.4965
Validation loss decreased (0.947363 --> 0.944028).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9426820278167725
Epoch: 8, Steps: 64 Train Loss: 19.8874 (Forecasting Loss:0.4872 + XiCon Loss:1.9400 x Lambda(10.0)), Vali MSE Loss: 0.9462 Test MSE Loss: 0.4965
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9441580772399902
Epoch: 9, Steps: 64 Train Loss: 19.9021 (Forecasting Loss:0.4860 + XiCon Loss:1.9416 x Lambda(10.0)), Vali MSE Loss: 0.9503 Test MSE Loss: 0.4965
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.001685619354248
Epoch: 10, Steps: 64 Train Loss: 19.8801 (Forecasting Loss:0.4859 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.9426 Test MSE Loss: 0.4964
Validation loss decreased (0.944028 --> 0.942632).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9358160495758057
Epoch: 11, Steps: 64 Train Loss: 19.8973 (Forecasting Loss:0.4865 + XiCon Loss:1.9411 x Lambda(10.0)), Vali MSE Loss: 0.9441 Test MSE Loss: 0.4964
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9540047645568848
Epoch: 12, Steps: 64 Train Loss: 19.9192 (Forecasting Loss:0.4871 + XiCon Loss:1.9432 x Lambda(10.0)), Vali MSE Loss: 0.9508 Test MSE Loss: 0.4964
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.869415283203125
Epoch: 13, Steps: 64 Train Loss: 19.8752 (Forecasting Loss:0.4871 + XiCon Loss:1.9388 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.935034990310669
Epoch: 14, Steps: 64 Train Loss: 19.9153 (Forecasting Loss:0.4868 + XiCon Loss:1.9429 x Lambda(10.0)), Vali MSE Loss: 0.9449 Test MSE Loss: 0.4964
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9189038276672363
Epoch: 15, Steps: 64 Train Loss: 19.9155 (Forecasting Loss:0.4862 + XiCon Loss:1.9429 x Lambda(10.0)), Vali MSE Loss: 0.9466 Test MSE Loss: 0.4964
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.8939440250396729
Epoch: 16, Steps: 64 Train Loss: 19.9007 (Forecasting Loss:0.4870 + XiCon Loss:1.9414 x Lambda(10.0)), Vali MSE Loss: 0.9486 Test MSE Loss: 0.4964
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9870164394378662
Epoch: 17, Steps: 64 Train Loss: 19.8930 (Forecasting Loss:0.4873 + XiCon Loss:1.9406 x Lambda(10.0)), Vali MSE Loss: 0.9468 Test MSE Loss: 0.4964
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9167227745056152
Epoch: 18, Steps: 64 Train Loss: 19.8737 (Forecasting Loss:0.4859 + XiCon Loss:1.9388 x Lambda(10.0)), Vali MSE Loss: 0.9480 Test MSE Loss: 0.4964
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8996381759643555
Epoch: 19, Steps: 64 Train Loss: 19.8942 (Forecasting Loss:0.4860 + XiCon Loss:1.9408 x Lambda(10.0)), Vali MSE Loss: 0.9446 Test MSE Loss: 0.4964
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9825315475463867
Epoch: 20, Steps: 64 Train Loss: 19.9277 (Forecasting Loss:0.4859 + XiCon Loss:1.9442 x Lambda(10.0)), Vali MSE Loss: 0.9427 Test MSE Loss: 0.4964
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.462708979845047, mae:0.5301684737205505, mape:0.4449203312397003, mspe:0.5856634974479675 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7136
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9272561073303223
Epoch: 1, Steps: 64 Train Loss: 19.8932 (Forecasting Loss:0.4951 + XiCon Loss:1.9398 x Lambda(10.0)), Vali MSE Loss: 0.9334 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933434).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9314446449279785
Epoch: 2, Steps: 64 Train Loss: 19.8689 (Forecasting Loss:0.4905 + XiCon Loss:1.9378 x Lambda(10.0)), Vali MSE Loss: 0.9194 Test MSE Loss: 0.5152
Validation loss decreased (0.933434 --> 0.919420).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.923391580581665
Epoch: 3, Steps: 64 Train Loss: 19.8884 (Forecasting Loss:0.4821 + XiCon Loss:1.9406 x Lambda(10.0)), Vali MSE Loss: 0.9156 Test MSE Loss: 0.5120
Validation loss decreased (0.919420 --> 0.915644).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9212708473205566
Epoch: 4, Steps: 64 Train Loss: 19.8791 (Forecasting Loss:0.4807 + XiCon Loss:1.9398 x Lambda(10.0)), Vali MSE Loss: 0.9115 Test MSE Loss: 0.5105
Validation loss decreased (0.915644 --> 0.911518).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.0020761489868164
Epoch: 5, Steps: 64 Train Loss: 19.9026 (Forecasting Loss:0.4796 + XiCon Loss:1.9423 x Lambda(10.0)), Vali MSE Loss: 0.9066 Test MSE Loss: 0.5099
Validation loss decreased (0.911518 --> 0.906595).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8954095840454102
Epoch: 6, Steps: 64 Train Loss: 19.8675 (Forecasting Loss:0.4798 + XiCon Loss:1.9388 x Lambda(10.0)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5095
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9285080432891846
Epoch: 7, Steps: 64 Train Loss: 19.8899 (Forecasting Loss:0.4792 + XiCon Loss:1.9411 x Lambda(10.0)), Vali MSE Loss: 0.9099 Test MSE Loss: 0.5093
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.96333909034729
Epoch: 8, Steps: 64 Train Loss: 19.8734 (Forecasting Loss:0.4781 + XiCon Loss:1.9395 x Lambda(10.0)), Vali MSE Loss: 0.9096 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9329326152801514
Epoch: 9, Steps: 64 Train Loss: 19.8690 (Forecasting Loss:0.4773 + XiCon Loss:1.9392 x Lambda(10.0)), Vali MSE Loss: 0.9047 Test MSE Loss: 0.5092
Validation loss decreased (0.906595 --> 0.904678).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9771740436553955
Epoch: 10, Steps: 64 Train Loss: 19.8577 (Forecasting Loss:0.4784 + XiCon Loss:1.9379 x Lambda(10.0)), Vali MSE Loss: 0.9078 Test MSE Loss: 0.5092
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.0254433155059814
Epoch: 11, Steps: 64 Train Loss: 19.8793 (Forecasting Loss:0.4783 + XiCon Loss:1.9401 x Lambda(10.0)), Vali MSE Loss: 0.9072 Test MSE Loss: 0.5092
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9079265594482422
Epoch: 12, Steps: 64 Train Loss: 19.8708 (Forecasting Loss:0.4784 + XiCon Loss:1.9392 x Lambda(10.0)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5092
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8942677974700928
Epoch: 13, Steps: 64 Train Loss: 19.9075 (Forecasting Loss:0.4783 + XiCon Loss:1.9429 x Lambda(10.0)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5092
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9132442474365234
Epoch: 14, Steps: 64 Train Loss: 19.8748 (Forecasting Loss:0.4780 + XiCon Loss:1.9397 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5092
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9106667041778564
Epoch: 15, Steps: 64 Train Loss: 19.8651 (Forecasting Loss:0.4787 + XiCon Loss:1.9386 x Lambda(10.0)), Vali MSE Loss: 0.9094 Test MSE Loss: 0.5091
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 0.9609317779541016
Epoch: 16, Steps: 64 Train Loss: 19.8709 (Forecasting Loss:0.4777 + XiCon Loss:1.9393 x Lambda(10.0)), Vali MSE Loss: 0.9022 Test MSE Loss: 0.5091
Validation loss decreased (0.904678 --> 0.902190).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9292864799499512
Epoch: 17, Steps: 64 Train Loss: 19.8855 (Forecasting Loss:0.4779 + XiCon Loss:1.9408 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5091
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9634370803833008
Epoch: 18, Steps: 64 Train Loss: 19.8734 (Forecasting Loss:0.4792 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.9070 Test MSE Loss: 0.5091
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.8744070529937744
Epoch: 19, Steps: 64 Train Loss: 19.8830 (Forecasting Loss:0.4789 + XiCon Loss:1.9404 x Lambda(10.0)), Vali MSE Loss: 0.9088 Test MSE Loss: 0.5091
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.8934597969055176
Epoch: 20, Steps: 64 Train Loss: 19.8531 (Forecasting Loss:0.4776 + XiCon Loss:1.9375 x Lambda(10.0)), Vali MSE Loss: 0.9075 Test MSE Loss: 0.5091
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.940284013748169
Epoch: 21, Steps: 64 Train Loss: 19.8704 (Forecasting Loss:0.4787 + XiCon Loss:1.9392 x Lambda(10.0)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5091
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.975975751876831
Epoch: 22, Steps: 64 Train Loss: 19.8541 (Forecasting Loss:0.4784 + XiCon Loss:1.9376 x Lambda(10.0)), Vali MSE Loss: 0.9070 Test MSE Loss: 0.5091
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.8995170593261719
Epoch: 23, Steps: 64 Train Loss: 19.8599 (Forecasting Loss:0.4779 + XiCon Loss:1.9382 x Lambda(10.0)), Vali MSE Loss: 0.9053 Test MSE Loss: 0.5091
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9063165187835693
Epoch: 24, Steps: 64 Train Loss: 19.8802 (Forecasting Loss:0.4779 + XiCon Loss:1.9402 x Lambda(10.0)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5091
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9449112415313721
Epoch: 25, Steps: 64 Train Loss: 19.8813 (Forecasting Loss:0.4779 + XiCon Loss:1.9403 x Lambda(10.0)), Vali MSE Loss: 0.9055 Test MSE Loss: 0.5091
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.8918519020080566
Epoch: 26, Steps: 64 Train Loss: 19.8555 (Forecasting Loss:0.4778 + XiCon Loss:1.9378 x Lambda(10.0)), Vali MSE Loss: 0.9090 Test MSE Loss: 0.5091
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.48270660638809204, mae:0.5355926752090454, mape:0.45603203773498535, mspe:0.6265960931777954 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5761
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.915968656539917
Epoch: 1, Steps: 64 Train Loss: 19.8925 (Forecasting Loss:0.4949 + XiCon Loss:1.9398 x Lambda(10.0)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908222).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9184043407440186
Epoch: 2, Steps: 64 Train Loss: 19.8852 (Forecasting Loss:0.4914 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.8924 Test MSE Loss: 0.5398
Validation loss decreased (0.908222 --> 0.892418).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9297618865966797
Epoch: 3, Steps: 64 Train Loss: 19.8815 (Forecasting Loss:0.4865 + XiCon Loss:1.9395 x Lambda(10.0)), Vali MSE Loss: 0.8930 Test MSE Loss: 0.5365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8787567615509033
Epoch: 4, Steps: 64 Train Loss: 19.8608 (Forecasting Loss:0.4827 + XiCon Loss:1.9378 x Lambda(10.0)), Vali MSE Loss: 0.8856 Test MSE Loss: 0.5349
Validation loss decreased (0.892418 --> 0.885595).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.0320632457733154
Epoch: 5, Steps: 64 Train Loss: 19.8639 (Forecasting Loss:0.4819 + XiCon Loss:1.9382 x Lambda(10.0)), Vali MSE Loss: 0.8841 Test MSE Loss: 0.5341
Validation loss decreased (0.885595 --> 0.884079).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.8918325901031494
Epoch: 6, Steps: 64 Train Loss: 19.8642 (Forecasting Loss:0.4802 + XiCon Loss:1.9384 x Lambda(10.0)), Vali MSE Loss: 0.8865 Test MSE Loss: 0.5337
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.886516809463501
Epoch: 7, Steps: 64 Train Loss: 19.8873 (Forecasting Loss:0.4804 + XiCon Loss:1.9407 x Lambda(10.0)), Vali MSE Loss: 0.8883 Test MSE Loss: 0.5335
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8354294300079346
Epoch: 8, Steps: 64 Train Loss: 19.8732 (Forecasting Loss:0.4828 + XiCon Loss:1.9390 x Lambda(10.0)), Vali MSE Loss: 0.8900 Test MSE Loss: 0.5334
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.8606112003326416
Epoch: 9, Steps: 64 Train Loss: 19.8704 (Forecasting Loss:0.4791 + XiCon Loss:1.9391 x Lambda(10.0)), Vali MSE Loss: 0.8859 Test MSE Loss: 0.5334
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.8568978309631348
Epoch: 10, Steps: 64 Train Loss: 19.8606 (Forecasting Loss:0.4807 + XiCon Loss:1.9380 x Lambda(10.0)), Vali MSE Loss: 0.8857 Test MSE Loss: 0.5334
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8399453163146973
Epoch: 11, Steps: 64 Train Loss: 19.8894 (Forecasting Loss:0.4812 + XiCon Loss:1.9408 x Lambda(10.0)), Vali MSE Loss: 0.8845 Test MSE Loss: 0.5334
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.84541916847229
Epoch: 12, Steps: 64 Train Loss: 19.8734 (Forecasting Loss:0.4796 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.8855 Test MSE Loss: 0.5334
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8996326923370361
Epoch: 13, Steps: 64 Train Loss: 19.8665 (Forecasting Loss:0.4812 + XiCon Loss:1.9385 x Lambda(10.0)), Vali MSE Loss: 0.8868 Test MSE Loss: 0.5334
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9021029472351074
Epoch: 14, Steps: 64 Train Loss: 19.8814 (Forecasting Loss:0.4805 + XiCon Loss:1.9401 x Lambda(10.0)), Vali MSE Loss: 0.8851 Test MSE Loss: 0.5334
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.8195497989654541
Epoch: 15, Steps: 64 Train Loss: 19.8705 (Forecasting Loss:0.4812 + XiCon Loss:1.9389 x Lambda(10.0)), Vali MSE Loss: 0.8854 Test MSE Loss: 0.5334
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5174535512924194, mae:0.5507440567016602, mape:0.47553789615631104, mspe:0.6888545155525208 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4835+-0.02608, MAE:0.5373+-0.00984, MAPE:0.4566+-0.01449, MSPE:0.6262+-0.04916, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6913
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.5621285438537598
Epoch: 1, Steps: 59 Train Loss: 19.0875 (Forecasting Loss:0.9906 + XiCon Loss:1.8097 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248621).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1725764274597168
Epoch: 2, Steps: 59 Train Loss: 19.0703 (Forecasting Loss:0.9903 + XiCon Loss:1.8080 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9825
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1554152965545654
Epoch: 3, Steps: 59 Train Loss: 19.0994 (Forecasting Loss:0.9892 + XiCon Loss:1.8110 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1826767921447754
Epoch: 4, Steps: 59 Train Loss: 19.0594 (Forecasting Loss:0.9890 + XiCon Loss:1.8070 x Lambda(10.0)), Vali MSE Loss: 1.2469 Test MSE Loss: 0.9822
Validation loss decreased (1.248621 --> 1.246888).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.168649435043335
Epoch: 5, Steps: 59 Train Loss: 19.1029 (Forecasting Loss:0.9890 + XiCon Loss:1.8114 x Lambda(10.0)), Vali MSE Loss: 1.2510 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.1713433265686035
Epoch: 6, Steps: 59 Train Loss: 19.0612 (Forecasting Loss:0.9899 + XiCon Loss:1.8071 x Lambda(10.0)), Vali MSE Loss: 1.2460 Test MSE Loss: 0.9822
Validation loss decreased (1.246888 --> 1.246025).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.182849645614624
Epoch: 7, Steps: 59 Train Loss: 19.0828 (Forecasting Loss:0.9887 + XiCon Loss:1.8094 x Lambda(10.0)), Vali MSE Loss: 1.2450 Test MSE Loss: 0.9822
Validation loss decreased (1.246025 --> 1.244972).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1538667678833008
Epoch: 8, Steps: 59 Train Loss: 19.1271 (Forecasting Loss:0.9881 + XiCon Loss:1.8139 x Lambda(10.0)), Vali MSE Loss: 1.2479 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1336402893066406
Epoch: 9, Steps: 59 Train Loss: 19.0815 (Forecasting Loss:0.9890 + XiCon Loss:1.8093 x Lambda(10.0)), Vali MSE Loss: 1.2444 Test MSE Loss: 0.9822
Validation loss decreased (1.244972 --> 1.244433).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.1252310276031494
Epoch: 10, Steps: 59 Train Loss: 19.0899 (Forecasting Loss:0.9889 + XiCon Loss:1.8101 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.261289119720459
Epoch: 11, Steps: 59 Train Loss: 19.0720 (Forecasting Loss:0.9878 + XiCon Loss:1.8084 x Lambda(10.0)), Vali MSE Loss: 1.2446 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2547218799591064
Epoch: 12, Steps: 59 Train Loss: 19.1445 (Forecasting Loss:0.9887 + XiCon Loss:1.8156 x Lambda(10.0)), Vali MSE Loss: 1.2523 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1879887580871582
Epoch: 13, Steps: 59 Train Loss: 19.0701 (Forecasting Loss:0.9890 + XiCon Loss:1.8081 x Lambda(10.0)), Vali MSE Loss: 1.2456 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.3396403789520264
Epoch: 14, Steps: 59 Train Loss: 19.0583 (Forecasting Loss:0.9889 + XiCon Loss:1.8069 x Lambda(10.0)), Vali MSE Loss: 1.2449 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.2480006217956543
Epoch: 15, Steps: 59 Train Loss: 19.0987 (Forecasting Loss:0.9888 + XiCon Loss:1.8110 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.2107622623443604
Epoch: 16, Steps: 59 Train Loss: 19.0892 (Forecasting Loss:0.9894 + XiCon Loss:1.8100 x Lambda(10.0)), Vali MSE Loss: 1.2490 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.2081270217895508
Epoch: 17, Steps: 59 Train Loss: 19.1167 (Forecasting Loss:0.9889 + XiCon Loss:1.8128 x Lambda(10.0)), Vali MSE Loss: 1.2554 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.2540063858032227
Epoch: 18, Steps: 59 Train Loss: 19.0754 (Forecasting Loss:0.9896 + XiCon Loss:1.8086 x Lambda(10.0)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.2515842914581299
Epoch: 19, Steps: 59 Train Loss: 19.1480 (Forecasting Loss:0.9895 + XiCon Loss:1.8159 x Lambda(10.0)), Vali MSE Loss: 1.2416 Test MSE Loss: 0.9822
Validation loss decreased (1.244433 --> 1.241621).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.2389357089996338
Epoch: 20, Steps: 59 Train Loss: 19.1218 (Forecasting Loss:0.9888 + XiCon Loss:1.8133 x Lambda(10.0)), Vali MSE Loss: 1.2439 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.2306435108184814
Epoch: 21, Steps: 59 Train Loss: 19.1049 (Forecasting Loss:0.9898 + XiCon Loss:1.8115 x Lambda(10.0)), Vali MSE Loss: 1.2514 Test MSE Loss: 0.9822
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.2172167301177979
Epoch: 22, Steps: 59 Train Loss: 19.0473 (Forecasting Loss:0.9903 + XiCon Loss:1.8057 x Lambda(10.0)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9822
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.2810962200164795
Epoch: 23, Steps: 59 Train Loss: 19.1240 (Forecasting Loss:0.9880 + XiCon Loss:1.8136 x Lambda(10.0)), Vali MSE Loss: 1.2496 Test MSE Loss: 0.9822
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.2176685333251953
Epoch: 24, Steps: 59 Train Loss: 19.0731 (Forecasting Loss:0.9893 + XiCon Loss:1.8084 x Lambda(10.0)), Vali MSE Loss: 1.2547 Test MSE Loss: 0.9822
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.2376899719238281
Epoch: 25, Steps: 59 Train Loss: 19.0579 (Forecasting Loss:0.9890 + XiCon Loss:1.8069 x Lambda(10.0)), Vali MSE Loss: 1.2521 Test MSE Loss: 0.9822
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.2578487396240234
Epoch: 26, Steps: 59 Train Loss: 19.0610 (Forecasting Loss:0.9891 + XiCon Loss:1.8072 x Lambda(10.0)), Vali MSE Loss: 1.2574 Test MSE Loss: 0.9822
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.2570157051086426
Epoch: 27, Steps: 59 Train Loss: 19.1066 (Forecasting Loss:0.9887 + XiCon Loss:1.8118 x Lambda(10.0)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9822
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.195075273513794
Epoch: 28, Steps: 59 Train Loss: 19.0437 (Forecasting Loss:0.9901 + XiCon Loss:1.8054 x Lambda(10.0)), Vali MSE Loss: 1.2508 Test MSE Loss: 0.9822
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.2457053661346436
Epoch: 29, Steps: 59 Train Loss: 19.0879 (Forecasting Loss:0.9886 + XiCon Loss:1.8099 x Lambda(10.0)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9822
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.145627737045288, mae:0.8187289237976074, mape:0.7821676731109619, mspe:1.830514907836914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5801
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2257323265075684
Epoch: 1, Steps: 59 Train Loss: 19.0500 (Forecasting Loss:0.9892 + XiCon Loss:1.8061 x Lambda(10.0)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236818).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2211344242095947
Epoch: 2, Steps: 59 Train Loss: 19.0910 (Forecasting Loss:0.9886 + XiCon Loss:1.8102 x Lambda(10.0)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9931
Validation loss decreased (1.236818 --> 1.234319).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2596819400787354
Epoch: 3, Steps: 59 Train Loss: 19.0246 (Forecasting Loss:0.9873 + XiCon Loss:1.8037 x Lambda(10.0)), Vali MSE Loss: 1.2391 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2784669399261475
Epoch: 4, Steps: 59 Train Loss: 19.1416 (Forecasting Loss:0.9879 + XiCon Loss:1.8154 x Lambda(10.0)), Vali MSE Loss: 1.2406 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.250847339630127
Epoch: 5, Steps: 59 Train Loss: 19.0458 (Forecasting Loss:0.9886 + XiCon Loss:1.8057 x Lambda(10.0)), Vali MSE Loss: 1.2296 Test MSE Loss: 0.9929
Validation loss decreased (1.234319 --> 1.229630).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2402105331420898
Epoch: 6, Steps: 59 Train Loss: 19.0834 (Forecasting Loss:0.9885 + XiCon Loss:1.8095 x Lambda(10.0)), Vali MSE Loss: 1.2381 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.210768222808838
Epoch: 7, Steps: 59 Train Loss: 19.0968 (Forecasting Loss:0.9858 + XiCon Loss:1.8111 x Lambda(10.0)), Vali MSE Loss: 1.2340 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2174303531646729
Epoch: 8, Steps: 59 Train Loss: 19.1154 (Forecasting Loss:0.9868 + XiCon Loss:1.8129 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1803481578826904
Epoch: 9, Steps: 59 Train Loss: 19.0951 (Forecasting Loss:0.9868 + XiCon Loss:1.8108 x Lambda(10.0)), Vali MSE Loss: 1.2312 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2641644477844238
Epoch: 10, Steps: 59 Train Loss: 19.0369 (Forecasting Loss:0.9879 + XiCon Loss:1.8049 x Lambda(10.0)), Vali MSE Loss: 1.2337 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2335131168365479
Epoch: 11, Steps: 59 Train Loss: 19.0662 (Forecasting Loss:0.9873 + XiCon Loss:1.8079 x Lambda(10.0)), Vali MSE Loss: 1.2398 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.240635871887207
Epoch: 12, Steps: 59 Train Loss: 19.0774 (Forecasting Loss:0.9877 + XiCon Loss:1.8090 x Lambda(10.0)), Vali MSE Loss: 1.2262 Test MSE Loss: 0.9928
Validation loss decreased (1.229630 --> 1.226227).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1987764835357666
Epoch: 13, Steps: 59 Train Loss: 19.1228 (Forecasting Loss:0.9882 + XiCon Loss:1.8135 x Lambda(10.0)), Vali MSE Loss: 1.2306 Test MSE Loss: 0.9928
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.2257359027862549
Epoch: 14, Steps: 59 Train Loss: 19.1059 (Forecasting Loss:0.9877 + XiCon Loss:1.8118 x Lambda(10.0)), Vali MSE Loss: 1.2352 Test MSE Loss: 0.9928
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.189460039138794
Epoch: 15, Steps: 59 Train Loss: 19.0928 (Forecasting Loss:0.9883 + XiCon Loss:1.8105 x Lambda(10.0)), Vali MSE Loss: 1.2265 Test MSE Loss: 0.9928
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.2503447532653809
Epoch: 16, Steps: 59 Train Loss: 19.0916 (Forecasting Loss:0.9869 + XiCon Loss:1.8105 x Lambda(10.0)), Vali MSE Loss: 1.2418 Test MSE Loss: 0.9928
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.2769415378570557
Epoch: 17, Steps: 59 Train Loss: 19.1005 (Forecasting Loss:0.9875 + XiCon Loss:1.8113 x Lambda(10.0)), Vali MSE Loss: 1.2282 Test MSE Loss: 0.9928
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.1765906810760498
Epoch: 18, Steps: 59 Train Loss: 19.0677 (Forecasting Loss:0.9880 + XiCon Loss:1.8080 x Lambda(10.0)), Vali MSE Loss: 1.2301 Test MSE Loss: 0.9928
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.2307713031768799
Epoch: 19, Steps: 59 Train Loss: 19.0944 (Forecasting Loss:0.9874 + XiCon Loss:1.8107 x Lambda(10.0)), Vali MSE Loss: 1.2360 Test MSE Loss: 0.9928
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.252640724182129
Epoch: 20, Steps: 59 Train Loss: 19.0516 (Forecasting Loss:0.9875 + XiCon Loss:1.8064 x Lambda(10.0)), Vali MSE Loss: 1.2332 Test MSE Loss: 0.9928
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.207834243774414
Epoch: 21, Steps: 59 Train Loss: 19.0328 (Forecasting Loss:0.9875 + XiCon Loss:1.8045 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9928
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.203310489654541
Epoch: 22, Steps: 59 Train Loss: 19.0968 (Forecasting Loss:0.9885 + XiCon Loss:1.8108 x Lambda(10.0)), Vali MSE Loss: 1.2299 Test MSE Loss: 0.9928
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1612201929092407, mae:0.8244372010231018, mape:0.7876439690589905, mspe:1.8507227897644043 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5737
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.3022656440734863
Epoch: 1, Steps: 59 Train Loss: 19.0176 (Forecasting Loss:0.9902 + XiCon Loss:1.8027 x Lambda(10.0)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247579).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2639884948730469
Epoch: 2, Steps: 59 Train Loss: 19.1148 (Forecasting Loss:0.9906 + XiCon Loss:1.8124 x Lambda(10.0)), Vali MSE Loss: 1.2355 Test MSE Loss: 0.9844
Validation loss decreased (1.247579 --> 1.235482).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2496895790100098
Epoch: 3, Steps: 59 Train Loss: 19.0139 (Forecasting Loss:0.9899 + XiCon Loss:1.8024 x Lambda(10.0)), Vali MSE Loss: 1.2347 Test MSE Loss: 0.9842
Validation loss decreased (1.235482 --> 1.234667).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2382090091705322
Epoch: 4, Steps: 59 Train Loss: 19.0756 (Forecasting Loss:0.9884 + XiCon Loss:1.8087 x Lambda(10.0)), Vali MSE Loss: 1.2540 Test MSE Loss: 0.9842
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2325518131256104
Epoch: 5, Steps: 59 Train Loss: 19.0524 (Forecasting Loss:0.9886 + XiCon Loss:1.8064 x Lambda(10.0)), Vali MSE Loss: 1.2454 Test MSE Loss: 0.9842
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.275357723236084
Epoch: 6, Steps: 59 Train Loss: 19.1193 (Forecasting Loss:0.9894 + XiCon Loss:1.8130 x Lambda(10.0)), Vali MSE Loss: 1.2441 Test MSE Loss: 0.9841
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.1923260688781738
Epoch: 7, Steps: 59 Train Loss: 19.0378 (Forecasting Loss:0.9893 + XiCon Loss:1.8048 x Lambda(10.0)), Vali MSE Loss: 1.2497 Test MSE Loss: 0.9841
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.231870412826538
Epoch: 8, Steps: 59 Train Loss: 19.0549 (Forecasting Loss:0.9882 + XiCon Loss:1.8067 x Lambda(10.0)), Vali MSE Loss: 1.2581 Test MSE Loss: 0.9841
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2233920097351074
Epoch: 9, Steps: 59 Train Loss: 19.1008 (Forecasting Loss:0.9876 + XiCon Loss:1.8113 x Lambda(10.0)), Vali MSE Loss: 1.2505 Test MSE Loss: 0.9841
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.3192551136016846
Epoch: 10, Steps: 59 Train Loss: 19.0811 (Forecasting Loss:0.9892 + XiCon Loss:1.8092 x Lambda(10.0)), Vali MSE Loss: 1.2537 Test MSE Loss: 0.9841
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2153680324554443
Epoch: 11, Steps: 59 Train Loss: 19.1041 (Forecasting Loss:0.9878 + XiCon Loss:1.8116 x Lambda(10.0)), Vali MSE Loss: 1.2474 Test MSE Loss: 0.9841
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2389800548553467
Epoch: 12, Steps: 59 Train Loss: 19.0065 (Forecasting Loss:0.9884 + XiCon Loss:1.8018 x Lambda(10.0)), Vali MSE Loss: 1.2410 Test MSE Loss: 0.9841
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.198638916015625
Epoch: 13, Steps: 59 Train Loss: 19.0450 (Forecasting Loss:0.9889 + XiCon Loss:1.8056 x Lambda(10.0)), Vali MSE Loss: 1.2571 Test MSE Loss: 0.9841
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1480369567871094, mae:0.8204628229141235, mape:0.7830783128738403, mspe:1.8314380645751953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5657
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.295454978942871
Epoch: 1, Steps: 59 Train Loss: 19.0914 (Forecasting Loss:0.9890 + XiCon Loss:1.8102 x Lambda(10.0)), Vali MSE Loss: 1.2401 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240053).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1881835460662842
Epoch: 2, Steps: 59 Train Loss: 19.0771 (Forecasting Loss:0.9898 + XiCon Loss:1.8087 x Lambda(10.0)), Vali MSE Loss: 1.2226 Test MSE Loss: 0.9957
Validation loss decreased (1.240053 --> 1.222585).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2050626277923584
Epoch: 3, Steps: 59 Train Loss: 19.0648 (Forecasting Loss:0.9878 + XiCon Loss:1.8077 x Lambda(10.0)), Vali MSE Loss: 1.2322 Test MSE Loss: 0.9957
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2311108112335205
Epoch: 4, Steps: 59 Train Loss: 19.0669 (Forecasting Loss:0.9888 + XiCon Loss:1.8078 x Lambda(10.0)), Vali MSE Loss: 1.2315 Test MSE Loss: 0.9956
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2167425155639648
Epoch: 5, Steps: 59 Train Loss: 19.0823 (Forecasting Loss:0.9883 + XiCon Loss:1.8094 x Lambda(10.0)), Vali MSE Loss: 1.2234 Test MSE Loss: 0.9956
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2114834785461426
Epoch: 6, Steps: 59 Train Loss: 19.0979 (Forecasting Loss:0.9890 + XiCon Loss:1.8109 x Lambda(10.0)), Vali MSE Loss: 1.2342 Test MSE Loss: 0.9956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2463812828063965
Epoch: 7, Steps: 59 Train Loss: 19.1037 (Forecasting Loss:0.9881 + XiCon Loss:1.8116 x Lambda(10.0)), Vali MSE Loss: 1.2252 Test MSE Loss: 0.9956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2578556537628174
Epoch: 8, Steps: 59 Train Loss: 19.1337 (Forecasting Loss:0.9873 + XiCon Loss:1.8146 x Lambda(10.0)), Vali MSE Loss: 1.2240 Test MSE Loss: 0.9956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2058110237121582
Epoch: 9, Steps: 59 Train Loss: 19.0912 (Forecasting Loss:0.9874 + XiCon Loss:1.8104 x Lambda(10.0)), Vali MSE Loss: 1.2348 Test MSE Loss: 0.9956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2039203643798828
Epoch: 10, Steps: 59 Train Loss: 19.0349 (Forecasting Loss:0.9883 + XiCon Loss:1.8047 x Lambda(10.0)), Vali MSE Loss: 1.2329 Test MSE Loss: 0.9956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.247107744216919
Epoch: 11, Steps: 59 Train Loss: 19.1022 (Forecasting Loss:0.9864 + XiCon Loss:1.8116 x Lambda(10.0)), Vali MSE Loss: 1.2319 Test MSE Loss: 0.9956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.21002197265625
Epoch: 12, Steps: 59 Train Loss: 19.1049 (Forecasting Loss:0.9881 + XiCon Loss:1.8117 x Lambda(10.0)), Vali MSE Loss: 1.2323 Test MSE Loss: 0.9956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1653865575790405, mae:0.8261122107505798, mape:0.7890905737876892, mspe:1.8549649715423584 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7315
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2726666927337646
Epoch: 1, Steps: 59 Train Loss: 19.0490 (Forecasting Loss:0.9941 + XiCon Loss:1.8055 x Lambda(10.0)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275613).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2312555313110352
Epoch: 2, Steps: 59 Train Loss: 19.0867 (Forecasting Loss:0.9928 + XiCon Loss:1.8094 x Lambda(10.0)), Vali MSE Loss: 1.2745 Test MSE Loss: 0.9658
Validation loss decreased (1.275613 --> 1.274493).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.286715030670166
Epoch: 3, Steps: 59 Train Loss: 19.0818 (Forecasting Loss:0.9934 + XiCon Loss:1.8088 x Lambda(10.0)), Vali MSE Loss: 1.2849 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.1712234020233154
Epoch: 4, Steps: 59 Train Loss: 19.0176 (Forecasting Loss:0.9923 + XiCon Loss:1.8025 x Lambda(10.0)), Vali MSE Loss: 1.2803 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.256772756576538
Epoch: 5, Steps: 59 Train Loss: 19.0784 (Forecasting Loss:0.9928 + XiCon Loss:1.8086 x Lambda(10.0)), Vali MSE Loss: 1.2743 Test MSE Loss: 0.9657
Validation loss decreased (1.274493 --> 1.274269).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2435379028320312
Epoch: 6, Steps: 59 Train Loss: 19.0665 (Forecasting Loss:0.9935 + XiCon Loss:1.8073 x Lambda(10.0)), Vali MSE Loss: 1.2845 Test MSE Loss: 0.9657
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2129096984863281
Epoch: 7, Steps: 59 Train Loss: 19.0568 (Forecasting Loss:0.9924 + XiCon Loss:1.8064 x Lambda(10.0)), Vali MSE Loss: 1.2775 Test MSE Loss: 0.9657
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2287054061889648
Epoch: 8, Steps: 59 Train Loss: 19.0411 (Forecasting Loss:0.9921 + XiCon Loss:1.8049 x Lambda(10.0)), Vali MSE Loss: 1.2825 Test MSE Loss: 0.9657
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1855804920196533
Epoch: 9, Steps: 59 Train Loss: 19.0723 (Forecasting Loss:0.9931 + XiCon Loss:1.8079 x Lambda(10.0)), Vali MSE Loss: 1.2886 Test MSE Loss: 0.9657
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2614350318908691
Epoch: 10, Steps: 59 Train Loss: 19.0309 (Forecasting Loss:0.9923 + XiCon Loss:1.8039 x Lambda(10.0)), Vali MSE Loss: 1.2792 Test MSE Loss: 0.9657
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.251446008682251
Epoch: 11, Steps: 59 Train Loss: 19.0823 (Forecasting Loss:0.9928 + XiCon Loss:1.8089 x Lambda(10.0)), Vali MSE Loss: 1.2748 Test MSE Loss: 0.9657
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2381954193115234
Epoch: 12, Steps: 59 Train Loss: 18.9747 (Forecasting Loss:0.9934 + XiCon Loss:1.7981 x Lambda(10.0)), Vali MSE Loss: 1.2767 Test MSE Loss: 0.9657
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2265243530273438
Epoch: 13, Steps: 59 Train Loss: 19.0545 (Forecasting Loss:0.9922 + XiCon Loss:1.8062 x Lambda(10.0)), Vali MSE Loss: 1.2820 Test MSE Loss: 0.9657
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.2444252967834473
Epoch: 14, Steps: 59 Train Loss: 19.1377 (Forecasting Loss:0.9917 + XiCon Loss:1.8146 x Lambda(10.0)), Vali MSE Loss: 1.2818 Test MSE Loss: 0.9657
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.2505850791931152
Epoch: 15, Steps: 59 Train Loss: 19.0205 (Forecasting Loss:0.9928 + XiCon Loss:1.8028 x Lambda(10.0)), Vali MSE Loss: 1.2801 Test MSE Loss: 0.9657
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1206096410751343, mae:0.8108487725257874, mape:0.7731265425682068, mspe:1.7925664186477661 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02180, MAE:0.8201+-0.00741, MAPE:0.7830+-0.00778, MSPE:1.8320+-0.03064, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6848
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.9763381481170654
Epoch: 1, Steps: 53 Train Loss: 19.7623 (Forecasting Loss:1.4862 + XiCon Loss:1.8276 x Lambda(10.0)), Vali MSE Loss: 1.8589 Test MSE Loss: 0.9062
Validation loss decreased (inf --> 1.858871).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6063895225524902
Epoch: 2, Steps: 53 Train Loss: 19.7088 (Forecasting Loss:1.4800 + XiCon Loss:1.8229 x Lambda(10.0)), Vali MSE Loss: 1.8424 Test MSE Loss: 0.9176
Validation loss decreased (1.858871 --> 1.842408).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5675675868988037
Epoch: 3, Steps: 53 Train Loss: 19.7091 (Forecasting Loss:1.4740 + XiCon Loss:1.8235 x Lambda(10.0)), Vali MSE Loss: 1.8454 Test MSE Loss: 0.9223
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5672321319580078
Epoch: 4, Steps: 53 Train Loss: 19.7287 (Forecasting Loss:1.4723 + XiCon Loss:1.8256 x Lambda(10.0)), Vali MSE Loss: 1.8423 Test MSE Loss: 0.9245
Validation loss decreased (1.842408 --> 1.842285).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6459670066833496
Epoch: 5, Steps: 53 Train Loss: 19.7489 (Forecasting Loss:1.4681 + XiCon Loss:1.8281 x Lambda(10.0)), Vali MSE Loss: 1.8225 Test MSE Loss: 0.9256
Validation loss decreased (1.842285 --> 1.822510).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6108920574188232
Epoch: 6, Steps: 53 Train Loss: 19.7109 (Forecasting Loss:1.4709 + XiCon Loss:1.8240 x Lambda(10.0)), Vali MSE Loss: 1.8255 Test MSE Loss: 0.9261
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6096477508544922
Epoch: 7, Steps: 53 Train Loss: 19.6977 (Forecasting Loss:1.4677 + XiCon Loss:1.8230 x Lambda(10.0)), Vali MSE Loss: 1.7958 Test MSE Loss: 0.9264
Validation loss decreased (1.822510 --> 1.795782).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6358933448791504
Epoch: 8, Steps: 53 Train Loss: 19.6484 (Forecasting Loss:1.4666 + XiCon Loss:1.8182 x Lambda(10.0)), Vali MSE Loss: 1.8513 Test MSE Loss: 0.9265
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6149423122406006
Epoch: 9, Steps: 53 Train Loss: 19.6525 (Forecasting Loss:1.4676 + XiCon Loss:1.8185 x Lambda(10.0)), Vali MSE Loss: 1.8149 Test MSE Loss: 0.9266
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.552567481994629
Epoch: 10, Steps: 53 Train Loss: 19.7050 (Forecasting Loss:1.4692 + XiCon Loss:1.8236 x Lambda(10.0)), Vali MSE Loss: 1.8535 Test MSE Loss: 0.9266
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5544641017913818
Epoch: 11, Steps: 53 Train Loss: 19.6981 (Forecasting Loss:1.4659 + XiCon Loss:1.8232 x Lambda(10.0)), Vali MSE Loss: 1.8363 Test MSE Loss: 0.9267
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5949909687042236
Epoch: 12, Steps: 53 Train Loss: 19.6672 (Forecasting Loss:1.4669 + XiCon Loss:1.8200 x Lambda(10.0)), Vali MSE Loss: 1.8121 Test MSE Loss: 0.9267
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.617774248123169
Epoch: 13, Steps: 53 Train Loss: 19.7539 (Forecasting Loss:1.4677 + XiCon Loss:1.8286 x Lambda(10.0)), Vali MSE Loss: 1.8489 Test MSE Loss: 0.9267
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.6117756366729736
Epoch: 14, Steps: 53 Train Loss: 19.6975 (Forecasting Loss:1.4688 + XiCon Loss:1.8229 x Lambda(10.0)), Vali MSE Loss: 1.8037 Test MSE Loss: 0.9267
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.586383581161499
Epoch: 15, Steps: 53 Train Loss: 19.6840 (Forecasting Loss:1.4657 + XiCon Loss:1.8218 x Lambda(10.0)), Vali MSE Loss: 1.8458 Test MSE Loss: 0.9267
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.6035315990447998
Epoch: 16, Steps: 53 Train Loss: 19.6454 (Forecasting Loss:1.4664 + XiCon Loss:1.8179 x Lambda(10.0)), Vali MSE Loss: 1.8258 Test MSE Loss: 0.9267
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5323748588562012
Epoch: 17, Steps: 53 Train Loss: 19.6614 (Forecasting Loss:1.4682 + XiCon Loss:1.8193 x Lambda(10.0)), Vali MSE Loss: 1.8430 Test MSE Loss: 0.9267
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0575448274612427, mae:0.7952808737754822, mape:0.7946537733078003, mspe:1.7958734035491943 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6033
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5639457702636719
Epoch: 1, Steps: 53 Train Loss: 19.7378 (Forecasting Loss:1.4830 + XiCon Loss:1.8255 x Lambda(10.0)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828230).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.6195077896118164
Epoch: 2, Steps: 53 Train Loss: 19.7284 (Forecasting Loss:1.4788 + XiCon Loss:1.8250 x Lambda(10.0)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9332
Validation loss decreased (1.828230 --> 1.821658).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.6198687553405762
Epoch: 3, Steps: 53 Train Loss: 19.7414 (Forecasting Loss:1.4731 + XiCon Loss:1.8268 x Lambda(10.0)), Vali MSE Loss: 1.7984 Test MSE Loss: 0.9350
Validation loss decreased (1.821658 --> 1.798448).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.6122817993164062
Epoch: 4, Steps: 53 Train Loss: 19.8204 (Forecasting Loss:1.4715 + XiCon Loss:1.8349 x Lambda(10.0)), Vali MSE Loss: 1.7998 Test MSE Loss: 0.9358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6500580310821533
Epoch: 5, Steps: 53 Train Loss: 19.7544 (Forecasting Loss:1.4744 + XiCon Loss:1.8280 x Lambda(10.0)), Vali MSE Loss: 1.8206 Test MSE Loss: 0.9363
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5497088432312012
Epoch: 6, Steps: 53 Train Loss: 19.7425 (Forecasting Loss:1.4694 + XiCon Loss:1.8273 x Lambda(10.0)), Vali MSE Loss: 1.8073 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5883092880249023
Epoch: 7, Steps: 53 Train Loss: 19.7508 (Forecasting Loss:1.4681 + XiCon Loss:1.8283 x Lambda(10.0)), Vali MSE Loss: 1.7816 Test MSE Loss: 0.9367
Validation loss decreased (1.798448 --> 1.781595).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5964500904083252
Epoch: 8, Steps: 53 Train Loss: 19.7685 (Forecasting Loss:1.4694 + XiCon Loss:1.8299 x Lambda(10.0)), Vali MSE Loss: 1.8240 Test MSE Loss: 0.9367
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.621396541595459
Epoch: 9, Steps: 53 Train Loss: 19.7120 (Forecasting Loss:1.4655 + XiCon Loss:1.8246 x Lambda(10.0)), Vali MSE Loss: 1.8211 Test MSE Loss: 0.9367
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5621988773345947
Epoch: 10, Steps: 53 Train Loss: 19.7611 (Forecasting Loss:1.4709 + XiCon Loss:1.8290 x Lambda(10.0)), Vali MSE Loss: 1.8315 Test MSE Loss: 0.9368
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5784525871276855
Epoch: 11, Steps: 53 Train Loss: 19.7222 (Forecasting Loss:1.4698 + XiCon Loss:1.8252 x Lambda(10.0)), Vali MSE Loss: 1.8394 Test MSE Loss: 0.9368
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.605949878692627
Epoch: 12, Steps: 53 Train Loss: 19.7952 (Forecasting Loss:1.4692 + XiCon Loss:1.8326 x Lambda(10.0)), Vali MSE Loss: 1.7649 Test MSE Loss: 0.9368
Validation loss decreased (1.781595 --> 1.764914).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6627485752105713
Epoch: 13, Steps: 53 Train Loss: 19.7789 (Forecasting Loss:1.4701 + XiCon Loss:1.8309 x Lambda(10.0)), Vali MSE Loss: 1.8078 Test MSE Loss: 0.9368
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.6176507472991943
Epoch: 14, Steps: 53 Train Loss: 19.7235 (Forecasting Loss:1.4707 + XiCon Loss:1.8253 x Lambda(10.0)), Vali MSE Loss: 1.8027 Test MSE Loss: 0.9368
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6447274684906006
Epoch: 15, Steps: 53 Train Loss: 19.7218 (Forecasting Loss:1.4673 + XiCon Loss:1.8255 x Lambda(10.0)), Vali MSE Loss: 1.7966 Test MSE Loss: 0.9368
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5791077613830566
Epoch: 16, Steps: 53 Train Loss: 19.7414 (Forecasting Loss:1.4709 + XiCon Loss:1.8270 x Lambda(10.0)), Vali MSE Loss: 1.7897 Test MSE Loss: 0.9368
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.617781162261963
Epoch: 17, Steps: 53 Train Loss: 19.7463 (Forecasting Loss:1.4683 + XiCon Loss:1.8278 x Lambda(10.0)), Vali MSE Loss: 1.8286 Test MSE Loss: 0.9368
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.6360034942626953
Epoch: 18, Steps: 53 Train Loss: 19.7565 (Forecasting Loss:1.4688 + XiCon Loss:1.8288 x Lambda(10.0)), Vali MSE Loss: 1.8223 Test MSE Loss: 0.9368
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.6098225116729736
Epoch: 19, Steps: 53 Train Loss: 19.7641 (Forecasting Loss:1.4720 + XiCon Loss:1.8292 x Lambda(10.0)), Vali MSE Loss: 1.8116 Test MSE Loss: 0.9368
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.606309175491333
Epoch: 20, Steps: 53 Train Loss: 19.7293 (Forecasting Loss:1.4679 + XiCon Loss:1.8261 x Lambda(10.0)), Vali MSE Loss: 1.8104 Test MSE Loss: 0.9368
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.6821799278259277
Epoch: 21, Steps: 53 Train Loss: 19.7219 (Forecasting Loss:1.4692 + XiCon Loss:1.8253 x Lambda(10.0)), Vali MSE Loss: 1.8068 Test MSE Loss: 0.9368
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.7271428108215332
Epoch: 22, Steps: 53 Train Loss: 19.7591 (Forecasting Loss:1.4708 + XiCon Loss:1.8288 x Lambda(10.0)), Vali MSE Loss: 1.8211 Test MSE Loss: 0.9368
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0734130144119263, mae:0.8001258373260498, mape:0.8007029294967651, mspe:1.8218870162963867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5952
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6595077514648438
Epoch: 1, Steps: 53 Train Loss: 19.7862 (Forecasting Loss:1.4859 + XiCon Loss:1.8300 x Lambda(10.0)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899233).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5894262790679932
Epoch: 2, Steps: 53 Train Loss: 19.7761 (Forecasting Loss:1.4837 + XiCon Loss:1.8292 x Lambda(10.0)), Vali MSE Loss: 1.8449 Test MSE Loss: 0.9160
Validation loss decreased (1.899233 --> 1.844914).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5697433948516846
Epoch: 3, Steps: 53 Train Loss: 19.7214 (Forecasting Loss:1.4807 + XiCon Loss:1.8241 x Lambda(10.0)), Vali MSE Loss: 1.8758 Test MSE Loss: 0.9184
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5287694931030273
Epoch: 4, Steps: 53 Train Loss: 19.7714 (Forecasting Loss:1.4689 + XiCon Loss:1.8303 x Lambda(10.0)), Vali MSE Loss: 1.8570 Test MSE Loss: 0.9196
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5500621795654297
Epoch: 5, Steps: 53 Train Loss: 19.7519 (Forecasting Loss:1.4732 + XiCon Loss:1.8279 x Lambda(10.0)), Vali MSE Loss: 1.8096 Test MSE Loss: 0.9202
Validation loss decreased (1.844914 --> 1.809621).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6110661029815674
Epoch: 6, Steps: 53 Train Loss: 19.7411 (Forecasting Loss:1.4736 + XiCon Loss:1.8268 x Lambda(10.0)), Vali MSE Loss: 1.8723 Test MSE Loss: 0.9206
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5683791637420654
Epoch: 7, Steps: 53 Train Loss: 19.7852 (Forecasting Loss:1.4750 + XiCon Loss:1.8310 x Lambda(10.0)), Vali MSE Loss: 1.8681 Test MSE Loss: 0.9207
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5231459140777588
Epoch: 8, Steps: 53 Train Loss: 19.7126 (Forecasting Loss:1.4730 + XiCon Loss:1.8240 x Lambda(10.0)), Vali MSE Loss: 1.8527 Test MSE Loss: 0.9208
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6344373226165771
Epoch: 9, Steps: 53 Train Loss: 19.7102 (Forecasting Loss:1.4725 + XiCon Loss:1.8238 x Lambda(10.0)), Vali MSE Loss: 1.8347 Test MSE Loss: 0.9209
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.640723466873169
Epoch: 10, Steps: 53 Train Loss: 19.7828 (Forecasting Loss:1.4688 + XiCon Loss:1.8314 x Lambda(10.0)), Vali MSE Loss: 1.8593 Test MSE Loss: 0.9209
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5556731224060059
Epoch: 11, Steps: 53 Train Loss: 19.7721 (Forecasting Loss:1.4736 + XiCon Loss:1.8299 x Lambda(10.0)), Vali MSE Loss: 1.8454 Test MSE Loss: 0.9209
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5391268730163574
Epoch: 12, Steps: 53 Train Loss: 19.7191 (Forecasting Loss:1.4695 + XiCon Loss:1.8250 x Lambda(10.0)), Vali MSE Loss: 1.8320 Test MSE Loss: 0.9209
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5193665027618408
Epoch: 13, Steps: 53 Train Loss: 19.7577 (Forecasting Loss:1.4688 + XiCon Loss:1.8289 x Lambda(10.0)), Vali MSE Loss: 1.8591 Test MSE Loss: 0.9209
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5389173030853271
Epoch: 14, Steps: 53 Train Loss: 19.7702 (Forecasting Loss:1.4696 + XiCon Loss:1.8301 x Lambda(10.0)), Vali MSE Loss: 1.8343 Test MSE Loss: 0.9209
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.5237281322479248
Epoch: 15, Steps: 53 Train Loss: 19.7214 (Forecasting Loss:1.4700 + XiCon Loss:1.8251 x Lambda(10.0)), Vali MSE Loss: 1.8915 Test MSE Loss: 0.9209
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0483555793762207, mae:0.7921298742294312, mape:0.7909323573112488, mspe:1.7791972160339355 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5776
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.586904525756836
Epoch: 1, Steps: 53 Train Loss: 19.7803 (Forecasting Loss:1.4999 + XiCon Loss:1.8280 x Lambda(10.0)), Vali MSE Loss: 1.9956 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995557).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.520155429840088
Epoch: 2, Steps: 53 Train Loss: 19.8280 (Forecasting Loss:1.4974 + XiCon Loss:1.8331 x Lambda(10.0)), Vali MSE Loss: 1.9563 Test MSE Loss: 0.8732
Validation loss decreased (1.995557 --> 1.956340).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5144007205963135
Epoch: 3, Steps: 53 Train Loss: 19.7801 (Forecasting Loss:1.4913 + XiCon Loss:1.8289 x Lambda(10.0)), Vali MSE Loss: 1.9786 Test MSE Loss: 0.8790
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.6316251754760742
Epoch: 4, Steps: 53 Train Loss: 19.7518 (Forecasting Loss:1.4838 + XiCon Loss:1.8268 x Lambda(10.0)), Vali MSE Loss: 1.9694 Test MSE Loss: 0.8823
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.64996337890625
Epoch: 5, Steps: 53 Train Loss: 19.7453 (Forecasting Loss:1.4785 + XiCon Loss:1.8267 x Lambda(10.0)), Vali MSE Loss: 1.9357 Test MSE Loss: 0.8840
Validation loss decreased (1.956340 --> 1.935710).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6646637916564941
Epoch: 6, Steps: 53 Train Loss: 19.7384 (Forecasting Loss:1.4798 + XiCon Loss:1.8259 x Lambda(10.0)), Vali MSE Loss: 1.9824 Test MSE Loss: 0.8849
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6011943817138672
Epoch: 7, Steps: 53 Train Loss: 19.8252 (Forecasting Loss:1.4825 + XiCon Loss:1.8343 x Lambda(10.0)), Vali MSE Loss: 1.9323 Test MSE Loss: 0.8854
Validation loss decreased (1.935710 --> 1.932279).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6232879161834717
Epoch: 8, Steps: 53 Train Loss: 19.7656 (Forecasting Loss:1.4786 + XiCon Loss:1.8287 x Lambda(10.0)), Vali MSE Loss: 1.9429 Test MSE Loss: 0.8856
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5859451293945312
Epoch: 9, Steps: 53 Train Loss: 19.7633 (Forecasting Loss:1.4788 + XiCon Loss:1.8284 x Lambda(10.0)), Vali MSE Loss: 1.9468 Test MSE Loss: 0.8857
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.6171271800994873
Epoch: 10, Steps: 53 Train Loss: 19.7888 (Forecasting Loss:1.4800 + XiCon Loss:1.8309 x Lambda(10.0)), Vali MSE Loss: 1.9217 Test MSE Loss: 0.8857
Validation loss decreased (1.932279 --> 1.921718).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.6124281883239746
Epoch: 11, Steps: 53 Train Loss: 19.7318 (Forecasting Loss:1.4796 + XiCon Loss:1.8252 x Lambda(10.0)), Vali MSE Loss: 1.9361 Test MSE Loss: 0.8858
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.7032511234283447
Epoch: 12, Steps: 53 Train Loss: 19.7215 (Forecasting Loss:1.4790 + XiCon Loss:1.8242 x Lambda(10.0)), Vali MSE Loss: 1.9020 Test MSE Loss: 0.8858
Validation loss decreased (1.921718 --> 1.902011).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6009976863861084
Epoch: 13, Steps: 53 Train Loss: 19.7944 (Forecasting Loss:1.4800 + XiCon Loss:1.8314 x Lambda(10.0)), Vali MSE Loss: 1.9355 Test MSE Loss: 0.8858
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5990512371063232
Epoch: 14, Steps: 53 Train Loss: 19.7319 (Forecasting Loss:1.4818 + XiCon Loss:1.8250 x Lambda(10.0)), Vali MSE Loss: 1.9394 Test MSE Loss: 0.8858
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6830849647521973
Epoch: 15, Steps: 53 Train Loss: 19.7488 (Forecasting Loss:1.4818 + XiCon Loss:1.8267 x Lambda(10.0)), Vali MSE Loss: 1.9384 Test MSE Loss: 0.8858
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5749800205230713
Epoch: 16, Steps: 53 Train Loss: 19.7423 (Forecasting Loss:1.4787 + XiCon Loss:1.8264 x Lambda(10.0)), Vali MSE Loss: 1.9285 Test MSE Loss: 0.8858
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.594357967376709
Epoch: 17, Steps: 53 Train Loss: 19.7330 (Forecasting Loss:1.4774 + XiCon Loss:1.8256 x Lambda(10.0)), Vali MSE Loss: 1.9489 Test MSE Loss: 0.8858
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.6046805381774902
Epoch: 18, Steps: 53 Train Loss: 19.8234 (Forecasting Loss:1.4782 + XiCon Loss:1.8345 x Lambda(10.0)), Vali MSE Loss: 1.9650 Test MSE Loss: 0.8858
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.6074621677398682
Epoch: 19, Steps: 53 Train Loss: 19.8054 (Forecasting Loss:1.4752 + XiCon Loss:1.8330 x Lambda(10.0)), Vali MSE Loss: 1.9274 Test MSE Loss: 0.8858
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.6490395069122314
Epoch: 20, Steps: 53 Train Loss: 19.7597 (Forecasting Loss:1.4814 + XiCon Loss:1.8278 x Lambda(10.0)), Vali MSE Loss: 1.9460 Test MSE Loss: 0.8858
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.575448751449585
Epoch: 21, Steps: 53 Train Loss: 19.7940 (Forecasting Loss:1.4781 + XiCon Loss:1.8316 x Lambda(10.0)), Vali MSE Loss: 1.9105 Test MSE Loss: 0.8858
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.7767994403839111
Epoch: 22, Steps: 53 Train Loss: 19.7994 (Forecasting Loss:1.4804 + XiCon Loss:1.8319 x Lambda(10.0)), Vali MSE Loss: 1.9387 Test MSE Loss: 0.8858
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:0.9963484406471252, mae:0.7752093076705933, mape:0.7698046565055847, mspe:1.6928356885910034 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6006
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5823261737823486
Epoch: 1, Steps: 53 Train Loss: 19.7368 (Forecasting Loss:1.4764 + XiCon Loss:1.8260 x Lambda(10.0)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740654).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.622941255569458
Epoch: 2, Steps: 53 Train Loss: 19.7524 (Forecasting Loss:1.4733 + XiCon Loss:1.8279 x Lambda(10.0)), Vali MSE Loss: 1.7213 Test MSE Loss: 0.9604
Validation loss decreased (1.740654 --> 1.721298).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.641517162322998
Epoch: 3, Steps: 53 Train Loss: 19.7020 (Forecasting Loss:1.4666 + XiCon Loss:1.8235 x Lambda(10.0)), Vali MSE Loss: 1.7425 Test MSE Loss: 0.9633
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.655076026916504
Epoch: 4, Steps: 53 Train Loss: 19.7311 (Forecasting Loss:1.4648 + XiCon Loss:1.8266 x Lambda(10.0)), Vali MSE Loss: 1.7449 Test MSE Loss: 0.9647
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6761887073516846
Epoch: 5, Steps: 53 Train Loss: 19.7629 (Forecasting Loss:1.4635 + XiCon Loss:1.8299 x Lambda(10.0)), Vali MSE Loss: 1.7469 Test MSE Loss: 0.9655
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.7333149909973145
Epoch: 6, Steps: 53 Train Loss: 19.7440 (Forecasting Loss:1.4636 + XiCon Loss:1.8280 x Lambda(10.0)), Vali MSE Loss: 1.7563 Test MSE Loss: 0.9658
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6045308113098145
Epoch: 7, Steps: 53 Train Loss: 19.6987 (Forecasting Loss:1.4651 + XiCon Loss:1.8234 x Lambda(10.0)), Vali MSE Loss: 1.7564 Test MSE Loss: 0.9660
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6115009784698486
Epoch: 8, Steps: 53 Train Loss: 19.7201 (Forecasting Loss:1.4624 + XiCon Loss:1.8258 x Lambda(10.0)), Vali MSE Loss: 1.7272 Test MSE Loss: 0.9661
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6455326080322266
Epoch: 9, Steps: 53 Train Loss: 19.7512 (Forecasting Loss:1.4640 + XiCon Loss:1.8287 x Lambda(10.0)), Vali MSE Loss: 1.7720 Test MSE Loss: 0.9662
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.7297933101654053
Epoch: 10, Steps: 53 Train Loss: 19.7155 (Forecasting Loss:1.4613 + XiCon Loss:1.8254 x Lambda(10.0)), Vali MSE Loss: 1.7481 Test MSE Loss: 0.9662
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.6240191459655762
Epoch: 11, Steps: 53 Train Loss: 19.7629 (Forecasting Loss:1.4639 + XiCon Loss:1.8299 x Lambda(10.0)), Vali MSE Loss: 1.7544 Test MSE Loss: 0.9662
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.6030008792877197
Epoch: 12, Steps: 53 Train Loss: 19.8315 (Forecasting Loss:1.4604 + XiCon Loss:1.8371 x Lambda(10.0)), Vali MSE Loss: 1.7537 Test MSE Loss: 0.9662
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.108416199684143, mae:0.8123033046722412, mape:0.8142781853675842, mspe:1.8776724338531494 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0568+-0.05069, MAE:0.7950+-0.01672, MAPE:0.7941+-0.02013, MSPE:1.7935+-0.08383, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8854
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 25.7726860
	speed: 0.0187s/iter; left time: 906.8285s
	iters: 200, epoch: 1 | loss: 26.6681023
	speed: 0.0139s/iter; left time: 674.5132s
	iters: 300, epoch: 1 | loss: 25.8660450
	speed: 0.0141s/iter; left time: 681.8723s
	iters: 400, epoch: 1 | loss: 25.2575283
	speed: 0.0149s/iter; left time: 722.0967s
Epoch: 1 cost time: 7.355548143386841
Epoch: 1, Steps: 487 Train Loss: 25.6391 (Forecasting Loss:0.7418 + XiCon Loss:2.4897 x Lambda(10.0)), Vali MSE Loss: 1.0369 Test MSE Loss: 0.6311
Validation loss decreased (inf --> 1.036933).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 25.0595703
	speed: 0.0150s/iter; left time: 721.4912s
	iters: 200, epoch: 2 | loss: 25.3142166
	speed: 0.0133s/iter; left time: 638.4604s
	iters: 300, epoch: 2 | loss: 25.0710831
	speed: 0.0139s/iter; left time: 668.0689s
	iters: 400, epoch: 2 | loss: 25.3867798
	speed: 0.0157s/iter; left time: 749.6675s
Epoch: 2 cost time: 7.076885223388672
Epoch: 2, Steps: 487 Train Loss: 25.0687 (Forecasting Loss:0.4347 + XiCon Loss:2.4634 x Lambda(10.0)), Vali MSE Loss: 0.7453 Test MSE Loss: 0.5253
Validation loss decreased (1.036933 --> 0.745315).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 25.7113628
	speed: 0.0162s/iter; left time: 771.7138s
	iters: 200, epoch: 3 | loss: 24.1037884
	speed: 0.0142s/iter; left time: 673.5423s
	iters: 300, epoch: 3 | loss: 24.7702885
	speed: 0.0132s/iter; left time: 627.0147s
	iters: 400, epoch: 3 | loss: 23.6497402
	speed: 0.0141s/iter; left time: 668.1771s
Epoch: 3 cost time: 7.1277689933776855
Epoch: 3, Steps: 487 Train Loss: 24.7477 (Forecasting Loss:0.4050 + XiCon Loss:2.4343 x Lambda(10.0)), Vali MSE Loss: 0.7352 Test MSE Loss: 0.5174
Validation loss decreased (0.745315 --> 0.735244).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 24.9390907
	speed: 0.0169s/iter; left time: 795.4332s
	iters: 200, epoch: 4 | loss: 24.8459415
	speed: 0.0133s/iter; left time: 626.2930s
	iters: 300, epoch: 4 | loss: 23.9022713
	speed: 0.0152s/iter; left time: 712.3340s
	iters: 400, epoch: 4 | loss: 25.6001987
	speed: 0.0138s/iter; left time: 647.5330s
Epoch: 4 cost time: 7.172570466995239
Epoch: 4, Steps: 487 Train Loss: 24.6872 (Forecasting Loss:0.3997 + XiCon Loss:2.4287 x Lambda(10.0)), Vali MSE Loss: 0.7276 Test MSE Loss: 0.5127
Validation loss decreased (0.735244 --> 0.727624).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 24.7045898
	speed: 0.0159s/iter; left time: 743.8842s
	iters: 200, epoch: 5 | loss: 24.2129631
	speed: 0.0139s/iter; left time: 645.8267s
	iters: 300, epoch: 5 | loss: 24.8744049
	speed: 0.0132s/iter; left time: 611.3386s
	iters: 400, epoch: 5 | loss: 25.6980476
	speed: 0.0131s/iter; left time: 606.6568s
Epoch: 5 cost time: 6.941996812820435
Epoch: 5, Steps: 487 Train Loss: 24.6487 (Forecasting Loss:0.3976 + XiCon Loss:2.4251 x Lambda(10.0)), Vali MSE Loss: 0.7255 Test MSE Loss: 0.5089
Validation loss decreased (0.727624 --> 0.725478).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 24.3903980
	speed: 0.0174s/iter; left time: 803.4974s
	iters: 200, epoch: 6 | loss: 24.7499008
	speed: 0.0130s/iter; left time: 600.8716s
	iters: 300, epoch: 6 | loss: 24.1581287
	speed: 0.0155s/iter; left time: 713.4148s
	iters: 400, epoch: 6 | loss: 23.7791672
	speed: 0.0145s/iter; left time: 665.3962s
Epoch: 6 cost time: 7.2435142993927
Epoch: 6, Steps: 487 Train Loss: 24.6175 (Forecasting Loss:0.3966 + XiCon Loss:2.4221 x Lambda(10.0)), Vali MSE Loss: 0.7260 Test MSE Loss: 0.5109
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 24.9269218
	speed: 0.0167s/iter; left time: 763.5408s
	iters: 200, epoch: 7 | loss: 24.5026302
	speed: 0.0134s/iter; left time: 610.9861s
	iters: 300, epoch: 7 | loss: 25.3030529
	speed: 0.0136s/iter; left time: 619.5616s
	iters: 400, epoch: 7 | loss: 24.8468494
	speed: 0.0154s/iter; left time: 699.3867s
Epoch: 7 cost time: 7.12859845161438
Epoch: 7, Steps: 487 Train Loss: 24.6017 (Forecasting Loss:0.3961 + XiCon Loss:2.4206 x Lambda(10.0)), Vali MSE Loss: 0.7250 Test MSE Loss: 0.5101
Validation loss decreased (0.725478 --> 0.725022).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 23.4043179
	speed: 0.0163s/iter; left time: 738.5184s
	iters: 200, epoch: 8 | loss: 24.3513107
	speed: 0.0140s/iter; left time: 632.8741s
	iters: 300, epoch: 8 | loss: 24.3006516
	speed: 0.0139s/iter; left time: 627.3518s
	iters: 400, epoch: 8 | loss: 25.1738319
	speed: 0.0148s/iter; left time: 666.4992s
Epoch: 8 cost time: 7.2433741092681885
Epoch: 8, Steps: 487 Train Loss: 24.6102 (Forecasting Loss:0.3958 + XiCon Loss:2.4214 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5099
Validation loss decreased (0.725022 --> 0.724893).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 24.7078724
	speed: 0.0146s/iter; left time: 654.6976s
	iters: 200, epoch: 9 | loss: 24.2126293
	speed: 0.0132s/iter; left time: 586.7664s
	iters: 300, epoch: 9 | loss: 24.2551117
	speed: 0.0146s/iter; left time: 651.9295s
	iters: 400, epoch: 9 | loss: 25.3428020
	speed: 0.0141s/iter; left time: 628.1585s
Epoch: 9 cost time: 6.9663286209106445
Epoch: 9, Steps: 487 Train Loss: 24.6307 (Forecasting Loss:0.3955 + XiCon Loss:2.4235 x Lambda(10.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5098
Validation loss decreased (0.724893 --> 0.724567).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 23.8988075
	speed: 0.0149s/iter; left time: 658.5166s
	iters: 200, epoch: 10 | loss: 24.0334034
	speed: 0.0134s/iter; left time: 590.9198s
	iters: 300, epoch: 10 | loss: 24.2352905
	speed: 0.0118s/iter; left time: 518.9205s
	iters: 400, epoch: 10 | loss: 23.6260948
	speed: 0.0118s/iter; left time: 519.8488s
Epoch: 10 cost time: 6.293093681335449
Epoch: 10, Steps: 487 Train Loss: 24.6363 (Forecasting Loss:0.3955 + XiCon Loss:2.4241 x Lambda(10.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5097
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 23.7650928
	speed: 0.0157s/iter; left time: 685.8226s
	iters: 200, epoch: 11 | loss: 24.2900162
	speed: 0.0132s/iter; left time: 576.4624s
	iters: 300, epoch: 11 | loss: 24.8412724
	speed: 0.0135s/iter; left time: 588.6641s
	iters: 400, epoch: 11 | loss: 24.0671539
	speed: 0.0144s/iter; left time: 623.8996s
Epoch: 11 cost time: 6.935985088348389
Epoch: 11, Steps: 487 Train Loss: 24.6266 (Forecasting Loss:0.3955 + XiCon Loss:2.4231 x Lambda(10.0)), Vali MSE Loss: 0.7243 Test MSE Loss: 0.5097
Validation loss decreased (0.724567 --> 0.724274).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 25.7895012
	speed: 0.0154s/iter; left time: 664.6693s
	iters: 200, epoch: 12 | loss: 24.1154442
	speed: 0.0154s/iter; left time: 665.6890s
	iters: 300, epoch: 12 | loss: 25.6663666
	speed: 0.0126s/iter; left time: 540.9252s
	iters: 400, epoch: 12 | loss: 24.1594868
	speed: 0.0138s/iter; left time: 594.6825s
Epoch: 12 cost time: 6.965050458908081
Epoch: 12, Steps: 487 Train Loss: 24.6076 (Forecasting Loss:0.3954 + XiCon Loss:2.4212 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5097
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 24.1264820
	speed: 0.0152s/iter; left time: 648.8476s
	iters: 200, epoch: 13 | loss: 25.6343079
	speed: 0.0144s/iter; left time: 613.3916s
	iters: 300, epoch: 13 | loss: 24.8206139
	speed: 0.0141s/iter; left time: 600.2797s
	iters: 400, epoch: 13 | loss: 24.9567451
	speed: 0.0152s/iter; left time: 643.2338s
Epoch: 13 cost time: 7.12492823600769
Epoch: 13, Steps: 487 Train Loss: 24.6009 (Forecasting Loss:0.3953 + XiCon Loss:2.4206 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5097
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 24.8962135
	speed: 0.0151s/iter; left time: 639.7391s
	iters: 200, epoch: 14 | loss: 25.1105366
	speed: 0.0142s/iter; left time: 600.0833s
	iters: 300, epoch: 14 | loss: 24.2784061
	speed: 0.0134s/iter; left time: 564.5134s
	iters: 400, epoch: 14 | loss: 26.1929169
	speed: 0.0138s/iter; left time: 581.1331s
Epoch: 14 cost time: 6.991671085357666
Epoch: 14, Steps: 487 Train Loss: 24.6250 (Forecasting Loss:0.3955 + XiCon Loss:2.4229 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5097
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 25.1336079
	speed: 0.0163s/iter; left time: 680.1620s
	iters: 200, epoch: 15 | loss: 24.3944054
	speed: 0.0140s/iter; left time: 582.7202s
	iters: 300, epoch: 15 | loss: 24.6769180
	speed: 0.0134s/iter; left time: 557.5441s
	iters: 400, epoch: 15 | loss: 24.4414997
	speed: 0.0121s/iter; left time: 503.9336s
Epoch: 15 cost time: 6.625015020370483
Epoch: 15, Steps: 487 Train Loss: 24.6225 (Forecasting Loss:0.3954 + XiCon Loss:2.4227 x Lambda(10.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5097
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 24.9418240
	speed: 0.0167s/iter; left time: 688.6048s
	iters: 200, epoch: 16 | loss: 24.8774872
	speed: 0.0138s/iter; left time: 570.2845s
	iters: 300, epoch: 16 | loss: 24.4210014
	speed: 0.0137s/iter; left time: 565.0433s
	iters: 400, epoch: 16 | loss: 24.5547047
	speed: 0.0154s/iter; left time: 630.2933s
Epoch: 16 cost time: 7.220056772232056
Epoch: 16, Steps: 487 Train Loss: 24.5745 (Forecasting Loss:0.3955 + XiCon Loss:2.4179 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5097
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 25.3206902
	speed: 0.0149s/iter; left time: 607.8568s
	iters: 200, epoch: 17 | loss: 24.4446621
	speed: 0.0131s/iter; left time: 534.5751s
	iters: 300, epoch: 17 | loss: 24.8676548
	speed: 0.0139s/iter; left time: 562.7030s
	iters: 400, epoch: 17 | loss: 23.6440945
	speed: 0.0140s/iter; left time: 567.8389s
Epoch: 17 cost time: 6.844828367233276
Epoch: 17, Steps: 487 Train Loss: 24.6186 (Forecasting Loss:0.3954 + XiCon Loss:2.4223 x Lambda(10.0)), Vali MSE Loss: 0.7244 Test MSE Loss: 0.5097
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 24.7387657
	speed: 0.0151s/iter; left time: 610.8413s
	iters: 200, epoch: 18 | loss: 25.1011810
	speed: 0.0130s/iter; left time: 521.8082s
	iters: 300, epoch: 18 | loss: 24.6190510
	speed: 0.0140s/iter; left time: 559.7808s
	iters: 400, epoch: 18 | loss: 24.8049946
	speed: 0.0133s/iter; left time: 532.8031s
Epoch: 18 cost time: 6.757737398147583
Epoch: 18, Steps: 487 Train Loss: 24.6345 (Forecasting Loss:0.3952 + XiCon Loss:2.4239 x Lambda(10.0)), Vali MSE Loss: 0.7241 Test MSE Loss: 0.5097
Validation loss decreased (0.724274 --> 0.724126).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 25.0849895
	speed: 0.0164s/iter; left time: 653.2364s
	iters: 200, epoch: 19 | loss: 25.3102875
	speed: 0.0124s/iter; left time: 492.5818s
	iters: 300, epoch: 19 | loss: 24.1986027
	speed: 0.0140s/iter; left time: 555.6115s
	iters: 400, epoch: 19 | loss: 26.5748844
	speed: 0.0151s/iter; left time: 597.5533s
Epoch: 19 cost time: 7.033762216567993
Epoch: 19, Steps: 487 Train Loss: 24.5971 (Forecasting Loss:0.3953 + XiCon Loss:2.4202 x Lambda(10.0)), Vali MSE Loss: 0.7242 Test MSE Loss: 0.5097
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 24.1418133
	speed: 0.0142s/iter; left time: 558.3456s
	iters: 200, epoch: 20 | loss: 23.7883625
	speed: 0.0127s/iter; left time: 499.1350s
	iters: 300, epoch: 20 | loss: 23.7423954
	speed: 0.0130s/iter; left time: 507.4849s
	iters: 400, epoch: 20 | loss: 25.6847191
	speed: 0.0133s/iter; left time: 520.3358s
Epoch: 20 cost time: 6.5836310386657715
Epoch: 20, Steps: 487 Train Loss: 24.6472 (Forecasting Loss:0.3956 + XiCon Loss:2.4252 x Lambda(10.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5097
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 24.2819061
	speed: 0.0154s/iter; left time: 597.7846s
	iters: 200, epoch: 21 | loss: 25.2285767
	speed: 0.0125s/iter; left time: 483.7835s
	iters: 300, epoch: 21 | loss: 24.4302216
	speed: 0.0126s/iter; left time: 488.5564s
	iters: 400, epoch: 21 | loss: 25.1928635
	speed: 0.0143s/iter; left time: 550.4558s
Epoch: 21 cost time: 6.741781949996948
Epoch: 21, Steps: 487 Train Loss: 24.6039 (Forecasting Loss:0.3956 + XiCon Loss:2.4208 x Lambda(10.0)), Vali MSE Loss: 0.7248 Test MSE Loss: 0.5097
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 24.8102551
	speed: 0.0139s/iter; left time: 532.9359s
	iters: 200, epoch: 22 | loss: 23.3382988
	speed: 0.0133s/iter; left time: 509.9308s
	iters: 300, epoch: 22 | loss: 25.0948277
	speed: 0.0123s/iter; left time: 467.6437s
	iters: 400, epoch: 22 | loss: 24.9002190
	speed: 0.0137s/iter; left time: 520.0275s
Epoch: 22 cost time: 6.57667088508606
Epoch: 22, Steps: 487 Train Loss: 24.6549 (Forecasting Loss:0.3956 + XiCon Loss:2.4259 x Lambda(10.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5097
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 24.3320560
	speed: 0.0150s/iter; left time: 567.9122s
	iters: 200, epoch: 23 | loss: 25.0210476
	speed: 0.0131s/iter; left time: 496.6693s
	iters: 300, epoch: 23 | loss: 24.2482338
	speed: 0.0126s/iter; left time: 473.6123s
	iters: 400, epoch: 23 | loss: 23.5937767
	speed: 0.0134s/iter; left time: 505.4486s
Epoch: 23 cost time: 6.573490858078003
Epoch: 23, Steps: 487 Train Loss: 24.5936 (Forecasting Loss:0.3953 + XiCon Loss:2.4198 x Lambda(10.0)), Vali MSE Loss: 0.7245 Test MSE Loss: 0.5097
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 24.3949642
	speed: 0.0169s/iter; left time: 630.7255s
	iters: 200, epoch: 24 | loss: 25.1605587
	speed: 0.0143s/iter; left time: 531.6738s
	iters: 300, epoch: 24 | loss: 23.8695755
	speed: 0.0144s/iter; left time: 537.1915s
	iters: 400, epoch: 24 | loss: 23.7068844
	speed: 0.0139s/iter; left time: 516.7091s
Epoch: 24 cost time: 7.155019283294678
Epoch: 24, Steps: 487 Train Loss: 24.6312 (Forecasting Loss:0.3954 + XiCon Loss:2.4236 x Lambda(10.0)), Vali MSE Loss: 0.7248 Test MSE Loss: 0.5097
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 24.1133633
	speed: 0.0153s/iter; left time: 563.6339s
	iters: 200, epoch: 25 | loss: 24.8205338
	speed: 0.0133s/iter; left time: 489.0859s
	iters: 300, epoch: 25 | loss: 24.8273926
	speed: 0.0122s/iter; left time: 447.5803s
	iters: 400, epoch: 25 | loss: 24.9345703
	speed: 0.0117s/iter; left time: 428.6635s
Epoch: 25 cost time: 6.375728130340576
Epoch: 25, Steps: 487 Train Loss: 24.6081 (Forecasting Loss:0.3954 + XiCon Loss:2.4213 x Lambda(10.0)), Vali MSE Loss: 0.7240 Test MSE Loss: 0.5097
Validation loss decreased (0.724126 --> 0.724049).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 24.6131592
	speed: 0.0146s/iter; left time: 530.7447s
	iters: 200, epoch: 26 | loss: 24.2924805
	speed: 0.0139s/iter; left time: 505.1929s
	iters: 300, epoch: 26 | loss: 24.0452671
	speed: 0.0129s/iter; left time: 466.5343s
	iters: 400, epoch: 26 | loss: 23.3527527
	speed: 0.0134s/iter; left time: 485.0149s
Epoch: 26 cost time: 6.743672132492065
Epoch: 26, Steps: 487 Train Loss: 24.6357 (Forecasting Loss:0.3955 + XiCon Loss:2.4240 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5097
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 24.9231987
	speed: 0.0156s/iter; left time: 560.1339s
	iters: 200, epoch: 27 | loss: 25.9095116
	speed: 0.0124s/iter; left time: 443.3312s
	iters: 300, epoch: 27 | loss: 24.7566910
	speed: 0.0122s/iter; left time: 435.8638s
	iters: 400, epoch: 27 | loss: 23.8628483
	speed: 0.0133s/iter; left time: 475.0691s
Epoch: 27 cost time: 6.418063640594482
Epoch: 27, Steps: 487 Train Loss: 24.6090 (Forecasting Loss:0.3956 + XiCon Loss:2.4213 x Lambda(10.0)), Vali MSE Loss: 0.7245 Test MSE Loss: 0.5097
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 25.1376762
	speed: 0.0148s/iter; left time: 524.8817s
	iters: 200, epoch: 28 | loss: 23.6874199
	speed: 0.0134s/iter; left time: 472.0810s
	iters: 300, epoch: 28 | loss: 24.4335957
	speed: 0.0143s/iter; left time: 503.0679s
	iters: 400, epoch: 28 | loss: 25.5993996
	speed: 0.0139s/iter; left time: 490.2086s
Epoch: 28 cost time: 6.999730825424194
Epoch: 28, Steps: 487 Train Loss: 24.6082 (Forecasting Loss:0.3953 + XiCon Loss:2.4213 x Lambda(10.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5097
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 24.8105736
	speed: 0.0150s/iter; left time: 523.9690s
	iters: 200, epoch: 29 | loss: 25.7046585
	speed: 0.0129s/iter; left time: 450.5712s
	iters: 300, epoch: 29 | loss: 24.0815353
	speed: 0.0138s/iter; left time: 478.5838s
	iters: 400, epoch: 29 | loss: 24.9307785
	speed: 0.0133s/iter; left time: 460.8312s
Epoch: 29 cost time: 6.821708679199219
Epoch: 29, Steps: 487 Train Loss: 24.6285 (Forecasting Loss:0.3955 + XiCon Loss:2.4233 x Lambda(10.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5097
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 24.7662086
	speed: 0.0155s/iter; left time: 532.9672s
	iters: 200, epoch: 30 | loss: 25.4440479
	speed: 0.0132s/iter; left time: 455.3966s
	iters: 300, epoch: 30 | loss: 26.5266037
	speed: 0.0128s/iter; left time: 440.3520s
	iters: 400, epoch: 30 | loss: 24.7116737
	speed: 0.0141s/iter; left time: 481.8838s
Epoch: 30 cost time: 6.980222225189209
Epoch: 30, Steps: 487 Train Loss: 24.6444 (Forecasting Loss:0.3953 + XiCon Loss:2.4249 x Lambda(10.0)), Vali MSE Loss: 0.7249 Test MSE Loss: 0.5097
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 24.5215893
	speed: 0.0161s/iter; left time: 545.8521s
	iters: 200, epoch: 31 | loss: 25.2278633
	speed: 0.0133s/iter; left time: 450.6273s
	iters: 300, epoch: 31 | loss: 24.5381432
	speed: 0.0137s/iter; left time: 461.5220s
	iters: 400, epoch: 31 | loss: 25.0825996
	speed: 0.0140s/iter; left time: 471.5156s
Epoch: 31 cost time: 6.9945080280303955
Epoch: 31, Steps: 487 Train Loss: 24.6221 (Forecasting Loss:0.3954 + XiCon Loss:2.4227 x Lambda(10.0)), Vali MSE Loss: 0.7241 Test MSE Loss: 0.5097
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 24.5445137
	speed: 0.0160s/iter; left time: 534.5809s
	iters: 200, epoch: 32 | loss: 24.0751038
	speed: 0.0134s/iter; left time: 449.0321s
	iters: 300, epoch: 32 | loss: 24.0934868
	speed: 0.0133s/iter; left time: 442.6367s
	iters: 400, epoch: 32 | loss: 24.5816479
	speed: 0.0148s/iter; left time: 491.5213s
Epoch: 32 cost time: 7.0089333057403564
Epoch: 32, Steps: 487 Train Loss: 24.6066 (Forecasting Loss:0.3952 + XiCon Loss:2.4211 x Lambda(10.0)), Vali MSE Loss: 0.7246 Test MSE Loss: 0.5097
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 24.6748466
	speed: 0.0164s/iter; left time: 539.9428s
	iters: 200, epoch: 33 | loss: 25.0390720
	speed: 0.0129s/iter; left time: 424.3796s
	iters: 300, epoch: 33 | loss: 24.0956345
	speed: 0.0143s/iter; left time: 469.7077s
	iters: 400, epoch: 33 | loss: 24.4897137
	speed: 0.0143s/iter; left time: 467.7865s
Epoch: 33 cost time: 7.0963966846466064
Epoch: 33, Steps: 487 Train Loss: 24.6219 (Forecasting Loss:0.3954 + XiCon Loss:2.4226 x Lambda(10.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5097
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 24.1793346
	speed: 0.0154s/iter; left time: 500.5645s
	iters: 200, epoch: 34 | loss: 25.2853985
	speed: 0.0134s/iter; left time: 433.9074s
	iters: 300, epoch: 34 | loss: 24.3796158
	speed: 0.0146s/iter; left time: 470.8212s
	iters: 400, epoch: 34 | loss: 25.3883457
	speed: 0.0145s/iter; left time: 467.7575s
Epoch: 34 cost time: 7.0340416431427
Epoch: 34, Steps: 487 Train Loss: 24.6052 (Forecasting Loss:0.3952 + XiCon Loss:2.4210 x Lambda(10.0)), Vali MSE Loss: 0.7241 Test MSE Loss: 0.5097
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 24.7951622
	speed: 0.0161s/iter; left time: 516.3562s
	iters: 200, epoch: 35 | loss: 24.6831284
	speed: 0.0146s/iter; left time: 465.3292s
	iters: 300, epoch: 35 | loss: 23.8618469
	speed: 0.0137s/iter; left time: 437.5387s
	iters: 400, epoch: 35 | loss: 23.5148754
	speed: 0.0141s/iter; left time: 446.7825s
Epoch: 35 cost time: 7.121272325515747
Epoch: 35, Steps: 487 Train Loss: 24.6424 (Forecasting Loss:0.3953 + XiCon Loss:2.4247 x Lambda(10.0)), Vali MSE Loss: 0.7247 Test MSE Loss: 0.5097
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5154513120651245, mae:0.5038628578186035, mape:3.483440637588501, mspe:1134.11376953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7584
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 25.2845173
	speed: 0.0153s/iter; left time: 744.0467s
	iters: 200, epoch: 1 | loss: 26.2117481
	speed: 0.0121s/iter; left time: 588.3442s
	iters: 300, epoch: 1 | loss: 24.8819580
	speed: 0.0126s/iter; left time: 610.0984s
	iters: 400, epoch: 1 | loss: 25.5546780
	speed: 0.0125s/iter; left time: 602.0757s
Epoch: 1 cost time: 6.360623598098755
Epoch: 1, Steps: 487 Train Loss: 25.5160 (Forecasting Loss:0.7351 + XiCon Loss:2.4781 x Lambda(10.0)), Vali MSE Loss: 1.0316 Test MSE Loss: 0.6262
Validation loss decreased (inf --> 1.031648).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 24.5412655
	speed: 0.0141s/iter; left time: 676.3498s
	iters: 200, epoch: 2 | loss: 25.1916733
	speed: 0.0127s/iter; left time: 609.0956s
	iters: 300, epoch: 2 | loss: 26.0041943
	speed: 0.0124s/iter; left time: 593.6412s
	iters: 400, epoch: 2 | loss: 25.5070953
	speed: 0.0127s/iter; left time: 606.1465s
Epoch: 2 cost time: 6.366536378860474
Epoch: 2, Steps: 487 Train Loss: 25.0397 (Forecasting Loss:0.4386 + XiCon Loss:2.4601 x Lambda(10.0)), Vali MSE Loss: 0.7333 Test MSE Loss: 0.5318
Validation loss decreased (1.031648 --> 0.733314).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 24.8497410
	speed: 0.0156s/iter; left time: 742.1617s
	iters: 200, epoch: 3 | loss: 24.1599808
	speed: 0.0132s/iter; left time: 628.4439s
	iters: 300, epoch: 3 | loss: 25.5083485
	speed: 0.0120s/iter; left time: 571.3029s
	iters: 400, epoch: 3 | loss: 24.9598141
	speed: 0.0130s/iter; left time: 613.3686s
Epoch: 3 cost time: 6.560096263885498
Epoch: 3, Steps: 487 Train Loss: 24.6643 (Forecasting Loss:0.4061 + XiCon Loss:2.4258 x Lambda(10.0)), Vali MSE Loss: 0.7169 Test MSE Loss: 0.5238
Validation loss decreased (0.733314 --> 0.716927).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 24.9921913
	speed: 0.0161s/iter; left time: 757.4051s
	iters: 200, epoch: 4 | loss: 24.7164574
	speed: 0.0144s/iter; left time: 678.3391s
	iters: 300, epoch: 4 | loss: 24.3765564
	speed: 0.0147s/iter; left time: 691.9687s
	iters: 400, epoch: 4 | loss: 25.5745354
	speed: 0.0143s/iter; left time: 672.0001s
Epoch: 4 cost time: 7.2371320724487305
Epoch: 4, Steps: 487 Train Loss: 24.5525 (Forecasting Loss:0.4006 + XiCon Loss:2.4152 x Lambda(10.0)), Vali MSE Loss: 0.7116 Test MSE Loss: 0.5222
Validation loss decreased (0.716927 --> 0.711630).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 25.4294758
	speed: 0.0157s/iter; left time: 731.4712s
	iters: 200, epoch: 5 | loss: 24.3803577
	speed: 0.0127s/iter; left time: 590.5778s
	iters: 300, epoch: 5 | loss: 25.0564651
	speed: 0.0129s/iter; left time: 601.1026s
	iters: 400, epoch: 5 | loss: 24.7561245
	speed: 0.0120s/iter; left time: 555.9479s
Epoch: 5 cost time: 6.454956531524658
Epoch: 5, Steps: 487 Train Loss: 24.5670 (Forecasting Loss:0.3983 + XiCon Loss:2.4169 x Lambda(10.0)), Vali MSE Loss: 0.7086 Test MSE Loss: 0.5197
Validation loss decreased (0.711630 --> 0.708645).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 24.4953365
	speed: 0.0153s/iter; left time: 708.0915s
	iters: 200, epoch: 6 | loss: 23.8770370
	speed: 0.0118s/iter; left time: 541.5672s
	iters: 300, epoch: 6 | loss: 25.2629566
	speed: 0.0128s/iter; left time: 587.2647s
	iters: 400, epoch: 6 | loss: 23.9102554
	speed: 0.0128s/iter; left time: 588.2701s
Epoch: 6 cost time: 6.394279718399048
Epoch: 6, Steps: 487 Train Loss: 24.5747 (Forecasting Loss:0.3972 + XiCon Loss:2.4177 x Lambda(10.0)), Vali MSE Loss: 0.7064 Test MSE Loss: 0.5188
Validation loss decreased (0.708645 --> 0.706375).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 25.8790989
	speed: 0.0155s/iter; left time: 706.2949s
	iters: 200, epoch: 7 | loss: 24.1386356
	speed: 0.0125s/iter; left time: 570.0532s
	iters: 300, epoch: 7 | loss: 23.9325886
	speed: 0.0143s/iter; left time: 650.5723s
	iters: 400, epoch: 7 | loss: 23.6995773
	speed: 0.0130s/iter; left time: 588.1230s
Epoch: 7 cost time: 6.5964391231536865
Epoch: 7, Steps: 487 Train Loss: 24.5020 (Forecasting Loss:0.3966 + XiCon Loss:2.4105 x Lambda(10.0)), Vali MSE Loss: 0.7064 Test MSE Loss: 0.5191
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 24.5193539
	speed: 0.0146s/iter; left time: 659.3737s
	iters: 200, epoch: 8 | loss: 25.1461773
	speed: 0.0124s/iter; left time: 560.6759s
	iters: 300, epoch: 8 | loss: 24.3196869
	speed: 0.0128s/iter; left time: 575.5699s
	iters: 400, epoch: 8 | loss: 24.0857029
	speed: 0.0119s/iter; left time: 534.3543s
Epoch: 8 cost time: 6.267383575439453
Epoch: 8, Steps: 487 Train Loss: 24.4895 (Forecasting Loss:0.3962 + XiCon Loss:2.4093 x Lambda(10.0)), Vali MSE Loss: 0.7059 Test MSE Loss: 0.5187
Validation loss decreased (0.706375 --> 0.705946).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 25.1406898
	speed: 0.0150s/iter; left time: 671.6529s
	iters: 200, epoch: 9 | loss: 24.9492970
	speed: 0.0131s/iter; left time: 582.9023s
	iters: 300, epoch: 9 | loss: 23.4915581
	speed: 0.0122s/iter; left time: 544.5932s
	iters: 400, epoch: 9 | loss: 25.2686558
	speed: 0.0119s/iter; left time: 527.2004s
Epoch: 9 cost time: 6.433669805526733
Epoch: 9, Steps: 487 Train Loss: 24.4884 (Forecasting Loss:0.3959 + XiCon Loss:2.4092 x Lambda(10.0)), Vali MSE Loss: 0.7051 Test MSE Loss: 0.5184
Validation loss decreased (0.705946 --> 0.705095).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 24.5018845
	speed: 0.0146s/iter; left time: 643.6444s
	iters: 200, epoch: 10 | loss: 24.5448246
	speed: 0.0139s/iter; left time: 612.7252s
	iters: 300, epoch: 10 | loss: 24.2016430
	speed: 0.0121s/iter; left time: 534.4924s
	iters: 400, epoch: 10 | loss: 23.3887215
	speed: 0.0124s/iter; left time: 546.7692s
Epoch: 10 cost time: 6.424398183822632
Epoch: 10, Steps: 487 Train Loss: 24.4880 (Forecasting Loss:0.3961 + XiCon Loss:2.4092 x Lambda(10.0)), Vali MSE Loss: 0.7059 Test MSE Loss: 0.5184
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 24.3489647
	speed: 0.0144s/iter; left time: 628.5913s
	iters: 200, epoch: 11 | loss: 24.5758572
	speed: 0.0122s/iter; left time: 531.5849s
	iters: 300, epoch: 11 | loss: 24.0268307
	speed: 0.0121s/iter; left time: 525.2948s
	iters: 400, epoch: 11 | loss: 25.2397423
	speed: 0.0119s/iter; left time: 515.3565s
Epoch: 11 cost time: 6.146513223648071
Epoch: 11, Steps: 487 Train Loss: 24.4199 (Forecasting Loss:0.3958 + XiCon Loss:2.4024 x Lambda(10.0)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5184
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 24.6522617
	speed: 0.0142s/iter; left time: 613.1187s
	iters: 200, epoch: 12 | loss: 24.3928261
	speed: 0.0129s/iter; left time: 558.2621s
	iters: 300, epoch: 12 | loss: 23.5753059
	speed: 0.0121s/iter; left time: 520.4755s
	iters: 400, epoch: 12 | loss: 23.6762047
	speed: 0.0120s/iter; left time: 513.2699s
Epoch: 12 cost time: 6.155918121337891
Epoch: 12, Steps: 487 Train Loss: 24.4834 (Forecasting Loss:0.3959 + XiCon Loss:2.4087 x Lambda(10.0)), Vali MSE Loss: 0.7059 Test MSE Loss: 0.5184
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 23.7649307
	speed: 0.0147s/iter; left time: 627.7069s
	iters: 200, epoch: 13 | loss: 25.0545807
	speed: 0.0131s/iter; left time: 558.9128s
	iters: 300, epoch: 13 | loss: 24.8867226
	speed: 0.0128s/iter; left time: 544.9399s
	iters: 400, epoch: 13 | loss: 25.0850754
	speed: 0.0121s/iter; left time: 515.0134s
Epoch: 13 cost time: 6.433382272720337
Epoch: 13, Steps: 487 Train Loss: 24.5299 (Forecasting Loss:0.3961 + XiCon Loss:2.4134 x Lambda(10.0)), Vali MSE Loss: 0.7057 Test MSE Loss: 0.5184
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 25.9766426
	speed: 0.0148s/iter; left time: 626.7198s
	iters: 200, epoch: 14 | loss: 24.0963135
	speed: 0.0125s/iter; left time: 529.0924s
	iters: 300, epoch: 14 | loss: 24.1580009
	speed: 0.0117s/iter; left time: 492.8337s
	iters: 400, epoch: 14 | loss: 25.0176849
	speed: 0.0123s/iter; left time: 515.9938s
Epoch: 14 cost time: 6.145800352096558
Epoch: 14, Steps: 487 Train Loss: 24.5066 (Forecasting Loss:0.3958 + XiCon Loss:2.4111 x Lambda(10.0)), Vali MSE Loss: 0.7058 Test MSE Loss: 0.5184
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 25.5392704
	speed: 0.0148s/iter; left time: 616.8954s
	iters: 200, epoch: 15 | loss: 24.4475613
	speed: 0.0146s/iter; left time: 609.7345s
	iters: 300, epoch: 15 | loss: 24.2626858
	speed: 0.0117s/iter; left time: 486.3958s
	iters: 400, epoch: 15 | loss: 23.7970219
	speed: 0.0119s/iter; left time: 494.0077s
Epoch: 15 cost time: 6.431865215301514
Epoch: 15, Steps: 487 Train Loss: 24.4472 (Forecasting Loss:0.3957 + XiCon Loss:2.4051 x Lambda(10.0)), Vali MSE Loss: 0.7057 Test MSE Loss: 0.5184
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 24.1373081
	speed: 0.0140s/iter; left time: 579.1210s
	iters: 200, epoch: 16 | loss: 24.1466408
	speed: 0.0121s/iter; left time: 496.6593s
	iters: 300, epoch: 16 | loss: 25.0558643
	speed: 0.0117s/iter; left time: 479.0625s
	iters: 400, epoch: 16 | loss: 24.1715088
	speed: 0.0125s/iter; left time: 513.5474s
Epoch: 16 cost time: 6.074596405029297
Epoch: 16, Steps: 487 Train Loss: 24.4797 (Forecasting Loss:0.3958 + XiCon Loss:2.4084 x Lambda(10.0)), Vali MSE Loss: 0.7059 Test MSE Loss: 0.5184
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 23.5708218
	speed: 0.0156s/iter; left time: 635.2875s
	iters: 200, epoch: 17 | loss: 24.2644310
	speed: 0.0130s/iter; left time: 528.1208s
	iters: 300, epoch: 17 | loss: 24.0176868
	speed: 0.0139s/iter; left time: 563.0111s
	iters: 400, epoch: 17 | loss: 24.8288345
	speed: 0.0133s/iter; left time: 537.2958s
Epoch: 17 cost time: 6.66400933265686
Epoch: 17, Steps: 487 Train Loss: 24.4991 (Forecasting Loss:0.3959 + XiCon Loss:2.4103 x Lambda(10.0)), Vali MSE Loss: 0.7057 Test MSE Loss: 0.5184
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 23.5368938
	speed: 0.0138s/iter; left time: 557.0696s
	iters: 200, epoch: 18 | loss: 24.0229549
	speed: 0.0114s/iter; left time: 458.8262s
	iters: 300, epoch: 18 | loss: 24.8008251
	speed: 0.0122s/iter; left time: 489.9363s
	iters: 400, epoch: 18 | loss: 25.1194592
	speed: 0.0115s/iter; left time: 459.6515s
Epoch: 18 cost time: 5.9438090324401855
Epoch: 18, Steps: 487 Train Loss: 24.4673 (Forecasting Loss:0.3957 + XiCon Loss:2.4072 x Lambda(10.0)), Vali MSE Loss: 0.7054 Test MSE Loss: 0.5184
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 24.5850220
	speed: 0.0148s/iter; left time: 587.5885s
	iters: 200, epoch: 19 | loss: 24.8400135
	speed: 0.0119s/iter; left time: 474.4183s
	iters: 300, epoch: 19 | loss: 24.1523628
	speed: 0.0110s/iter; left time: 437.8043s
	iters: 400, epoch: 19 | loss: 23.3171749
	speed: 0.0113s/iter; left time: 445.0028s
Epoch: 19 cost time: 5.977743625640869
Epoch: 19, Steps: 487 Train Loss: 24.4873 (Forecasting Loss:0.3960 + XiCon Loss:2.4091 x Lambda(10.0)), Vali MSE Loss: 0.7060 Test MSE Loss: 0.5184
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5267763137817383, mae:0.5100976824760437, mape:3.5135276317596436, mspe:1139.7252197265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.2097
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 26.3442764
	speed: 0.0150s/iter; left time: 726.7305s
	iters: 200, epoch: 1 | loss: 25.5393753
	speed: 0.0160s/iter; left time: 776.2224s
	iters: 300, epoch: 1 | loss: 26.5900612
	speed: 0.0143s/iter; left time: 692.2458s
	iters: 400, epoch: 1 | loss: 25.6855431
	speed: 0.0136s/iter; left time: 656.0362s
Epoch: 1 cost time: 7.14293098449707
Epoch: 1, Steps: 487 Train Loss: 25.7884 (Forecasting Loss:0.8412 + XiCon Loss:2.4947 x Lambda(10.0)), Vali MSE Loss: 1.1916 Test MSE Loss: 0.6742
Validation loss decreased (inf --> 1.191600).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 24.2902050
	speed: 0.0156s/iter; left time: 749.9798s
	iters: 200, epoch: 2 | loss: 24.8417358
	speed: 0.0137s/iter; left time: 656.7561s
	iters: 300, epoch: 2 | loss: 24.9955215
	speed: 0.0142s/iter; left time: 678.2077s
	iters: 400, epoch: 2 | loss: 24.9257927
	speed: 0.0139s/iter; left time: 662.5791s
Epoch: 2 cost time: 6.973111867904663
Epoch: 2, Steps: 487 Train Loss: 24.9331 (Forecasting Loss:0.4565 + XiCon Loss:2.4477 x Lambda(10.0)), Vali MSE Loss: 0.7485 Test MSE Loss: 0.5357
Validation loss decreased (1.191600 --> 0.748489).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 24.0391636
	speed: 0.0167s/iter; left time: 794.3440s
	iters: 200, epoch: 3 | loss: 23.6440086
	speed: 0.0142s/iter; left time: 675.7226s
	iters: 300, epoch: 3 | loss: 23.7453270
	speed: 0.0134s/iter; left time: 637.8865s
	iters: 400, epoch: 3 | loss: 23.6500874
	speed: 0.0145s/iter; left time: 686.1832s
Epoch: 3 cost time: 7.212070941925049
Epoch: 3, Steps: 487 Train Loss: 24.6408 (Forecasting Loss:0.4109 + XiCon Loss:2.4230 x Lambda(10.0)), Vali MSE Loss: 0.7332 Test MSE Loss: 0.5292
Validation loss decreased (0.748489 --> 0.733207).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 24.3929691
	speed: 0.0170s/iter; left time: 799.4729s
	iters: 200, epoch: 4 | loss: 23.3190098
	speed: 0.0139s/iter; left time: 655.7354s
	iters: 300, epoch: 4 | loss: 23.6648636
	speed: 0.0145s/iter; left time: 679.1128s
	iters: 400, epoch: 4 | loss: 23.5537205
	speed: 0.0147s/iter; left time: 690.4147s
Epoch: 4 cost time: 7.307583332061768
Epoch: 4, Steps: 487 Train Loss: 24.5043 (Forecasting Loss:0.4078 + XiCon Loss:2.4097 x Lambda(10.0)), Vali MSE Loss: 0.7268 Test MSE Loss: 0.5233
Validation loss decreased (0.733207 --> 0.726802).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 23.8062172
	speed: 0.0158s/iter; left time: 737.9448s
	iters: 200, epoch: 5 | loss: 24.6051826
	speed: 0.0145s/iter; left time: 674.3464s
	iters: 300, epoch: 5 | loss: 25.2687912
	speed: 0.0144s/iter; left time: 670.1732s
	iters: 400, epoch: 5 | loss: 24.3438015
	speed: 0.0149s/iter; left time: 691.7438s
Epoch: 5 cost time: 7.269046783447266
Epoch: 5, Steps: 487 Train Loss: 24.4966 (Forecasting Loss:0.4067 + XiCon Loss:2.4090 x Lambda(10.0)), Vali MSE Loss: 0.7242 Test MSE Loss: 0.5203
Validation loss decreased (0.726802 --> 0.724202).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 24.7255039
	speed: 0.0158s/iter; left time: 730.7622s
	iters: 200, epoch: 6 | loss: 23.7119255
	speed: 0.0138s/iter; left time: 634.9717s
	iters: 300, epoch: 6 | loss: 24.3788166
	speed: 0.0153s/iter; left time: 704.6406s
	iters: 400, epoch: 6 | loss: 23.8297195
	speed: 0.0137s/iter; left time: 628.5070s
Epoch: 6 cost time: 7.096228361129761
Epoch: 6, Steps: 487 Train Loss: 24.4683 (Forecasting Loss:0.4053 + XiCon Loss:2.4063 x Lambda(10.0)), Vali MSE Loss: 0.7209 Test MSE Loss: 0.5188
Validation loss decreased (0.724202 --> 0.720929).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 24.0503807
	speed: 0.0156s/iter; left time: 710.8591s
	iters: 200, epoch: 7 | loss: 23.9615440
	speed: 0.0143s/iter; left time: 652.3941s
	iters: 300, epoch: 7 | loss: 24.9139061
	speed: 0.0136s/iter; left time: 619.2897s
	iters: 400, epoch: 7 | loss: 24.7793407
	speed: 0.0144s/iter; left time: 652.5820s
Epoch: 7 cost time: 7.1782310009002686
Epoch: 7, Steps: 487 Train Loss: 24.4903 (Forecasting Loss:0.4054 + XiCon Loss:2.4085 x Lambda(10.0)), Vali MSE Loss: 0.7203 Test MSE Loss: 0.5181
Validation loss decreased (0.720929 --> 0.720254).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 24.3468361
	speed: 0.0169s/iter; left time: 764.9844s
	iters: 200, epoch: 8 | loss: 24.2293282
	speed: 0.0154s/iter; left time: 694.8876s
	iters: 300, epoch: 8 | loss: 24.2094116
	speed: 0.0135s/iter; left time: 606.2831s
	iters: 400, epoch: 8 | loss: 23.4833336
	speed: 0.0136s/iter; left time: 612.1981s
Epoch: 8 cost time: 7.198580026626587
Epoch: 8, Steps: 487 Train Loss: 24.4535 (Forecasting Loss:0.4054 + XiCon Loss:2.4048 x Lambda(10.0)), Vali MSE Loss: 0.7204 Test MSE Loss: 0.5177
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 24.1961803
	speed: 0.0167s/iter; left time: 746.3632s
	iters: 200, epoch: 9 | loss: 24.6509876
	speed: 0.0149s/iter; left time: 662.5436s
	iters: 300, epoch: 9 | loss: 25.0691719
	speed: 0.0145s/iter; left time: 645.9244s
	iters: 400, epoch: 9 | loss: 24.4117107
	speed: 0.0153s/iter; left time: 679.1749s
Epoch: 9 cost time: 7.381466627120972
Epoch: 9, Steps: 487 Train Loss: 24.4679 (Forecasting Loss:0.4052 + XiCon Loss:2.4063 x Lambda(10.0)), Vali MSE Loss: 0.7199 Test MSE Loss: 0.5176
Validation loss decreased (0.720254 --> 0.719948).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 24.3532429
	speed: 0.0159s/iter; left time: 702.1483s
	iters: 200, epoch: 10 | loss: 25.0212555
	speed: 0.0143s/iter; left time: 632.1627s
	iters: 300, epoch: 10 | loss: 24.1139488
	speed: 0.0138s/iter; left time: 609.6152s
	iters: 400, epoch: 10 | loss: 24.4292583
	speed: 0.0145s/iter; left time: 636.9279s
Epoch: 10 cost time: 7.1068713665008545
Epoch: 10, Steps: 487 Train Loss: 24.4427 (Forecasting Loss:0.4049 + XiCon Loss:2.4038 x Lambda(10.0)), Vali MSE Loss: 0.7198 Test MSE Loss: 0.5175
Validation loss decreased (0.719948 --> 0.719812).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 23.6303024
	speed: 0.0168s/iter; left time: 734.7573s
	iters: 200, epoch: 11 | loss: 24.0263805
	speed: 0.0140s/iter; left time: 610.6849s
	iters: 300, epoch: 11 | loss: 24.6829090
	speed: 0.0149s/iter; left time: 647.1463s
	iters: 400, epoch: 11 | loss: 24.5925770
	speed: 0.0153s/iter; left time: 662.8157s
Epoch: 11 cost time: 7.3422322273254395
Epoch: 11, Steps: 487 Train Loss: 24.4549 (Forecasting Loss:0.4053 + XiCon Loss:2.4050 x Lambda(10.0)), Vali MSE Loss: 0.7199 Test MSE Loss: 0.5175
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 24.5603752
	speed: 0.0157s/iter; left time: 680.0215s
	iters: 200, epoch: 12 | loss: 24.1577797
	speed: 0.0134s/iter; left time: 577.3428s
	iters: 300, epoch: 12 | loss: 25.0523224
	speed: 0.0158s/iter; left time: 679.8982s
	iters: 400, epoch: 12 | loss: 23.8359070
	speed: 0.0156s/iter; left time: 667.8570s
Epoch: 12 cost time: 7.446919918060303
Epoch: 12, Steps: 487 Train Loss: 24.4462 (Forecasting Loss:0.4055 + XiCon Loss:2.4041 x Lambda(10.0)), Vali MSE Loss: 0.7197 Test MSE Loss: 0.5174
Validation loss decreased (0.719812 --> 0.719707).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 24.0824566
	speed: 0.0154s/iter; left time: 659.5813s
	iters: 200, epoch: 13 | loss: 23.7217407
	speed: 0.0137s/iter; left time: 586.2135s
	iters: 300, epoch: 13 | loss: 24.6013432
	speed: 0.0138s/iter; left time: 585.4426s
	iters: 400, epoch: 13 | loss: 25.1391659
	speed: 0.0142s/iter; left time: 600.9135s
Epoch: 13 cost time: 6.936874628067017
Epoch: 13, Steps: 487 Train Loss: 24.4387 (Forecasting Loss:0.4052 + XiCon Loss:2.4034 x Lambda(10.0)), Vali MSE Loss: 0.7198 Test MSE Loss: 0.5174
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 23.5026150
	speed: 0.0162s/iter; left time: 683.0200s
	iters: 200, epoch: 14 | loss: 25.7574215
	speed: 0.0141s/iter; left time: 594.4021s
	iters: 300, epoch: 14 | loss: 24.8906441
	speed: 0.0140s/iter; left time: 590.3615s
	iters: 400, epoch: 14 | loss: 24.7298584
	speed: 0.0142s/iter; left time: 594.6834s
Epoch: 14 cost time: 7.251494646072388
Epoch: 14, Steps: 487 Train Loss: 24.4112 (Forecasting Loss:0.4049 + XiCon Loss:2.4006 x Lambda(10.0)), Vali MSE Loss: 0.7193 Test MSE Loss: 0.5174
Validation loss decreased (0.719707 --> 0.719293).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 24.6869450
	speed: 0.0158s/iter; left time: 661.6941s
	iters: 200, epoch: 15 | loss: 24.1789818
	speed: 0.0151s/iter; left time: 629.7481s
	iters: 300, epoch: 15 | loss: 23.7294083
	speed: 0.0140s/iter; left time: 580.5693s
	iters: 400, epoch: 15 | loss: 24.1484890
	speed: 0.0151s/iter; left time: 625.8227s
Epoch: 15 cost time: 7.276026010513306
Epoch: 15, Steps: 487 Train Loss: 24.4329 (Forecasting Loss:0.4052 + XiCon Loss:2.4028 x Lambda(10.0)), Vali MSE Loss: 0.7195 Test MSE Loss: 0.5174
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 24.4309692
	speed: 0.0170s/iter; left time: 700.3834s
	iters: 200, epoch: 16 | loss: 24.8162193
	speed: 0.0150s/iter; left time: 616.6932s
	iters: 300, epoch: 16 | loss: 24.6751366
	speed: 0.0132s/iter; left time: 543.8561s
	iters: 400, epoch: 16 | loss: 24.2162800
	speed: 0.0143s/iter; left time: 587.3114s
Epoch: 16 cost time: 7.292269468307495
Epoch: 16, Steps: 487 Train Loss: 24.4690 (Forecasting Loss:0.4052 + XiCon Loss:2.4064 x Lambda(10.0)), Vali MSE Loss: 0.7198 Test MSE Loss: 0.5174
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 24.6764183
	speed: 0.0165s/iter; left time: 671.5002s
	iters: 200, epoch: 17 | loss: 23.8428955
	speed: 0.0135s/iter; left time: 548.4184s
	iters: 300, epoch: 17 | loss: 24.4061470
	speed: 0.0146s/iter; left time: 593.5204s
	iters: 400, epoch: 17 | loss: 23.8444099
	speed: 0.0142s/iter; left time: 573.7118s
Epoch: 17 cost time: 7.095526456832886
Epoch: 17, Steps: 487 Train Loss: 24.4746 (Forecasting Loss:0.4056 + XiCon Loss:2.4069 x Lambda(10.0)), Vali MSE Loss: 0.7200 Test MSE Loss: 0.5174
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 24.0326405
	speed: 0.0159s/iter; left time: 642.8880s
	iters: 200, epoch: 18 | loss: 24.4801178
	speed: 0.0134s/iter; left time: 537.5438s
	iters: 300, epoch: 18 | loss: 23.3262291
	speed: 0.0156s/iter; left time: 626.9924s
	iters: 400, epoch: 18 | loss: 24.6069679
	speed: 0.0148s/iter; left time: 594.1292s
Epoch: 18 cost time: 7.199916124343872
Epoch: 18, Steps: 487 Train Loss: 24.4158 (Forecasting Loss:0.4044 + XiCon Loss:2.4011 x Lambda(10.0)), Vali MSE Loss: 0.7197 Test MSE Loss: 0.5174
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 24.7964535
	speed: 0.0168s/iter; left time: 667.7920s
	iters: 200, epoch: 19 | loss: 24.4060631
	speed: 0.0136s/iter; left time: 540.6858s
	iters: 300, epoch: 19 | loss: 24.6321735
	speed: 0.0137s/iter; left time: 544.8218s
	iters: 400, epoch: 19 | loss: 23.7052841
	speed: 0.0147s/iter; left time: 580.1591s
Epoch: 19 cost time: 7.153652906417847
Epoch: 19, Steps: 487 Train Loss: 24.4179 (Forecasting Loss:0.4052 + XiCon Loss:2.4013 x Lambda(10.0)), Vali MSE Loss: 0.7202 Test MSE Loss: 0.5174
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 23.7070541
	speed: 0.0174s/iter; left time: 685.5079s
	iters: 200, epoch: 20 | loss: 24.2080631
	speed: 0.0135s/iter; left time: 529.6335s
	iters: 300, epoch: 20 | loss: 24.6278210
	speed: 0.0147s/iter; left time: 575.5023s
	iters: 400, epoch: 20 | loss: 24.9732895
	speed: 0.0140s/iter; left time: 548.5088s
Epoch: 20 cost time: 7.314092397689819
Epoch: 20, Steps: 487 Train Loss: 24.4608 (Forecasting Loss:0.4049 + XiCon Loss:2.4056 x Lambda(10.0)), Vali MSE Loss: 0.7197 Test MSE Loss: 0.5174
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 24.0904980
	speed: 0.0167s/iter; left time: 647.7217s
	iters: 200, epoch: 21 | loss: 24.4258270
	speed: 0.0145s/iter; left time: 561.4463s
	iters: 300, epoch: 21 | loss: 23.6010456
	speed: 0.0142s/iter; left time: 550.5086s
	iters: 400, epoch: 21 | loss: 25.4546394
	speed: 0.0150s/iter; left time: 577.7484s
Epoch: 21 cost time: 7.379815340042114
Epoch: 21, Steps: 487 Train Loss: 24.4735 (Forecasting Loss:0.4042 + XiCon Loss:2.4069 x Lambda(10.0)), Vali MSE Loss: 0.7200 Test MSE Loss: 0.5174
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 24.4449730
	speed: 0.0158s/iter; left time: 604.4528s
	iters: 200, epoch: 22 | loss: 25.7195034
	speed: 0.0143s/iter; left time: 546.1611s
	iters: 300, epoch: 22 | loss: 24.1906891
	speed: 0.0134s/iter; left time: 510.7235s
	iters: 400, epoch: 22 | loss: 24.7186718
	speed: 0.0136s/iter; left time: 517.5858s
Epoch: 22 cost time: 7.073872327804565
Epoch: 22, Steps: 487 Train Loss: 24.4589 (Forecasting Loss:0.4051 + XiCon Loss:2.4054 x Lambda(10.0)), Vali MSE Loss: 0.7192 Test MSE Loss: 0.5174
Validation loss decreased (0.719293 --> 0.719167).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 24.9114799
	speed: 0.0164s/iter; left time: 622.7528s
	iters: 200, epoch: 23 | loss: 23.8340168
	speed: 0.0147s/iter; left time: 555.3006s
	iters: 300, epoch: 23 | loss: 25.0453377
	speed: 0.0149s/iter; left time: 563.3553s
	iters: 400, epoch: 23 | loss: 23.7169418
	speed: 0.0146s/iter; left time: 550.5983s
Epoch: 23 cost time: 7.33555269241333
Epoch: 23, Steps: 487 Train Loss: 24.4974 (Forecasting Loss:0.4052 + XiCon Loss:2.4092 x Lambda(10.0)), Vali MSE Loss: 0.7199 Test MSE Loss: 0.5174
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 24.6056252
	speed: 0.0169s/iter; left time: 630.7317s
	iters: 200, epoch: 24 | loss: 23.8274002
	speed: 0.0138s/iter; left time: 515.7686s
	iters: 300, epoch: 24 | loss: 23.4988155
	speed: 0.0141s/iter; left time: 525.7264s
	iters: 400, epoch: 24 | loss: 25.5137386
	speed: 0.0159s/iter; left time: 591.0773s
Epoch: 24 cost time: 7.299618482589722
Epoch: 24, Steps: 487 Train Loss: 24.4645 (Forecasting Loss:0.4050 + XiCon Loss:2.4059 x Lambda(10.0)), Vali MSE Loss: 0.7201 Test MSE Loss: 0.5174
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 24.4158840
	speed: 0.0169s/iter; left time: 624.3545s
	iters: 200, epoch: 25 | loss: 22.1883545
	speed: 0.0152s/iter; left time: 558.8242s
	iters: 300, epoch: 25 | loss: 24.1787758
	speed: 0.0143s/iter; left time: 523.4719s
	iters: 400, epoch: 25 | loss: 23.7326088
	speed: 0.0145s/iter; left time: 531.9545s
Epoch: 25 cost time: 7.603666305541992
Epoch: 25, Steps: 487 Train Loss: 24.4557 (Forecasting Loss:0.4051 + XiCon Loss:2.4051 x Lambda(10.0)), Vali MSE Loss: 0.7200 Test MSE Loss: 0.5174
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 25.5206051
	speed: 0.0167s/iter; left time: 608.3605s
	iters: 200, epoch: 26 | loss: 23.7003822
	speed: 0.0140s/iter; left time: 508.6854s
	iters: 300, epoch: 26 | loss: 24.6724834
	speed: 0.0136s/iter; left time: 493.3554s
	iters: 400, epoch: 26 | loss: 24.2869091
	speed: 0.0139s/iter; left time: 502.3621s
Epoch: 26 cost time: 7.122075319290161
Epoch: 26, Steps: 487 Train Loss: 24.4986 (Forecasting Loss:0.4053 + XiCon Loss:2.4093 x Lambda(10.0)), Vali MSE Loss: 0.7193 Test MSE Loss: 0.5174
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 24.1241169
	speed: 0.0155s/iter; left time: 556.4706s
	iters: 200, epoch: 27 | loss: 23.8229523
	speed: 0.0147s/iter; left time: 525.1864s
	iters: 300, epoch: 27 | loss: 24.6544399
	speed: 0.0136s/iter; left time: 486.0539s
	iters: 400, epoch: 27 | loss: 24.0070419
	speed: 0.0142s/iter; left time: 507.4081s
Epoch: 27 cost time: 7.171267747879028
Epoch: 27, Steps: 487 Train Loss: 24.4343 (Forecasting Loss:0.4046 + XiCon Loss:2.4030 x Lambda(10.0)), Vali MSE Loss: 0.7196 Test MSE Loss: 0.5174
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 24.8108101
	speed: 0.0167s/iter; left time: 590.6713s
	iters: 200, epoch: 28 | loss: 24.6486855
	speed: 0.0142s/iter; left time: 502.5478s
	iters: 300, epoch: 28 | loss: 25.3747807
	speed: 0.0145s/iter; left time: 510.6129s
	iters: 400, epoch: 28 | loss: 24.8002319
	speed: 0.0144s/iter; left time: 506.2724s
Epoch: 28 cost time: 7.2030720710754395
Epoch: 28, Steps: 487 Train Loss: 24.4990 (Forecasting Loss:0.4052 + XiCon Loss:2.4094 x Lambda(10.0)), Vali MSE Loss: 0.7197 Test MSE Loss: 0.5174
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 24.7603092
	speed: 0.0167s/iter; left time: 583.3596s
	iters: 200, epoch: 29 | loss: 24.8295193
	speed: 0.0154s/iter; left time: 538.3122s
	iters: 300, epoch: 29 | loss: 24.5512047
	speed: 0.0133s/iter; left time: 461.8971s
	iters: 400, epoch: 29 | loss: 24.5204296
	speed: 0.0138s/iter; left time: 477.9621s
Epoch: 29 cost time: 7.160008668899536
Epoch: 29, Steps: 487 Train Loss: 24.4623 (Forecasting Loss:0.4055 + XiCon Loss:2.4057 x Lambda(10.0)), Vali MSE Loss: 0.7195 Test MSE Loss: 0.5174
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 25.3803825
	speed: 0.0159s/iter; left time: 547.9416s
	iters: 200, epoch: 30 | loss: 24.6601677
	speed: 0.0131s/iter; left time: 449.7543s
	iters: 300, epoch: 30 | loss: 25.1429100
	speed: 0.0134s/iter; left time: 460.8083s
	iters: 400, epoch: 30 | loss: 23.6682091
	speed: 0.0133s/iter; left time: 455.1976s
Epoch: 30 cost time: 6.729038715362549
Epoch: 30, Steps: 487 Train Loss: 24.4039 (Forecasting Loss:0.4055 + XiCon Loss:2.3998 x Lambda(10.0)), Vali MSE Loss: 0.7193 Test MSE Loss: 0.5174
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 24.4030609
	speed: 0.0150s/iter; left time: 510.7816s
	iters: 200, epoch: 31 | loss: 24.2995186
	speed: 0.0136s/iter; left time: 460.7253s
	iters: 300, epoch: 31 | loss: 25.3097076
	speed: 0.0130s/iter; left time: 440.7049s
	iters: 400, epoch: 31 | loss: 23.9206104
	speed: 0.0159s/iter; left time: 535.1641s
Epoch: 31 cost time: 7.108463287353516
Epoch: 31, Steps: 487 Train Loss: 24.4975 (Forecasting Loss:0.4050 + XiCon Loss:2.4092 x Lambda(10.0)), Vali MSE Loss: 0.7190 Test MSE Loss: 0.5174
Validation loss decreased (0.719167 --> 0.718953).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 22.7244129
	speed: 0.0152s/iter; left time: 508.2516s
	iters: 200, epoch: 32 | loss: 24.1495628
	speed: 0.0136s/iter; left time: 455.6978s
	iters: 300, epoch: 32 | loss: 24.9052944
	speed: 0.0135s/iter; left time: 449.2213s
	iters: 400, epoch: 32 | loss: 25.0015621
	speed: 0.0134s/iter; left time: 443.9827s
Epoch: 32 cost time: 6.85639762878418
Epoch: 32, Steps: 487 Train Loss: 24.3775 (Forecasting Loss:0.4055 + XiCon Loss:2.3972 x Lambda(10.0)), Vali MSE Loss: 0.7201 Test MSE Loss: 0.5174
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 24.4515839
	speed: 0.0156s/iter; left time: 513.5703s
	iters: 200, epoch: 33 | loss: 26.0993195
	speed: 0.0134s/iter; left time: 442.2643s
	iters: 300, epoch: 33 | loss: 24.5845013
	speed: 0.0129s/iter; left time: 422.9331s
	iters: 400, epoch: 33 | loss: 24.3097801
	speed: 0.0132s/iter; left time: 430.3900s
Epoch: 33 cost time: 6.88667368888855
Epoch: 33, Steps: 487 Train Loss: 24.4511 (Forecasting Loss:0.4048 + XiCon Loss:2.4046 x Lambda(10.0)), Vali MSE Loss: 0.7201 Test MSE Loss: 0.5174
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 25.3447685
	speed: 0.0162s/iter; left time: 528.1706s
	iters: 200, epoch: 34 | loss: 24.5134754
	speed: 0.0136s/iter; left time: 441.8088s
	iters: 300, epoch: 34 | loss: 24.3717384
	speed: 0.0135s/iter; left time: 435.6385s
	iters: 400, epoch: 34 | loss: 23.7295189
	speed: 0.0136s/iter; left time: 437.7873s
Epoch: 34 cost time: 7.009841203689575
Epoch: 34, Steps: 487 Train Loss: 24.4772 (Forecasting Loss:0.4048 + XiCon Loss:2.4072 x Lambda(10.0)), Vali MSE Loss: 0.7202 Test MSE Loss: 0.5174
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 24.7971935
	speed: 0.0161s/iter; left time: 516.8962s
	iters: 200, epoch: 35 | loss: 23.2488174
	speed: 0.0142s/iter; left time: 455.1556s
	iters: 300, epoch: 35 | loss: 24.9286270
	speed: 0.0144s/iter; left time: 458.4455s
	iters: 400, epoch: 35 | loss: 25.6891308
	speed: 0.0138s/iter; left time: 437.8595s
Epoch: 35 cost time: 7.0970447063446045
Epoch: 35, Steps: 487 Train Loss: 24.4688 (Forecasting Loss:0.4047 + XiCon Loss:2.4064 x Lambda(10.0)), Vali MSE Loss: 0.7194 Test MSE Loss: 0.5174
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 25.5014153
	speed: 0.0159s/iter; left time: 503.1132s
	iters: 200, epoch: 36 | loss: 24.6769753
	speed: 0.0140s/iter; left time: 441.7038s
	iters: 300, epoch: 36 | loss: 25.0752201
	speed: 0.0138s/iter; left time: 433.0713s
	iters: 400, epoch: 36 | loss: 24.4104290
	speed: 0.0140s/iter; left time: 436.1598s
Epoch: 36 cost time: 7.0063018798828125
Epoch: 36, Steps: 487 Train Loss: 24.4433 (Forecasting Loss:0.4052 + XiCon Loss:2.4038 x Lambda(10.0)), Vali MSE Loss: 0.7198 Test MSE Loss: 0.5174
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 24.8720131
	speed: 0.0156s/iter; left time: 485.9491s
	iters: 200, epoch: 37 | loss: 24.0061302
	speed: 0.0159s/iter; left time: 491.3384s
	iters: 300, epoch: 37 | loss: 24.6541271
	speed: 0.0140s/iter; left time: 433.4627s
	iters: 400, epoch: 37 | loss: 25.2969666
	speed: 0.0147s/iter; left time: 452.1008s
Epoch: 37 cost time: 7.3522117137908936
Epoch: 37, Steps: 487 Train Loss: 24.4734 (Forecasting Loss:0.4055 + XiCon Loss:2.4068 x Lambda(10.0)), Vali MSE Loss: 0.7196 Test MSE Loss: 0.5174
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 24.8499775
	speed: 0.0172s/iter; left time: 526.9086s
	iters: 200, epoch: 38 | loss: 24.7319736
	speed: 0.0140s/iter; left time: 428.2623s
	iters: 300, epoch: 38 | loss: 23.7926254
	speed: 0.0150s/iter; left time: 456.8783s
	iters: 400, epoch: 38 | loss: 25.3651180
	speed: 0.0156s/iter; left time: 471.7885s
Epoch: 38 cost time: 7.4207987785339355
Epoch: 38, Steps: 487 Train Loss: 24.4876 (Forecasting Loss:0.4050 + XiCon Loss:2.4083 x Lambda(10.0)), Vali MSE Loss: 0.7197 Test MSE Loss: 0.5174
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 25.5508251
	speed: 0.0155s/iter; left time: 467.4322s
	iters: 200, epoch: 39 | loss: 24.0361252
	speed: 0.0147s/iter; left time: 439.6385s
	iters: 300, epoch: 39 | loss: 24.6766033
	speed: 0.0155s/iter; left time: 463.9554s
	iters: 400, epoch: 39 | loss: 25.3161259
	speed: 0.0144s/iter; left time: 430.0921s
Epoch: 39 cost time: 7.260915756225586
Epoch: 39, Steps: 487 Train Loss: 24.4159 (Forecasting Loss:0.4043 + XiCon Loss:2.4012 x Lambda(10.0)), Vali MSE Loss: 0.7196 Test MSE Loss: 0.5174
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 26.0262947
	speed: 0.0157s/iter; left time: 465.5178s
	iters: 200, epoch: 40 | loss: 23.2303581
	speed: 0.0146s/iter; left time: 431.1414s
	iters: 300, epoch: 40 | loss: 23.7619553
	speed: 0.0143s/iter; left time: 420.8071s
	iters: 400, epoch: 40 | loss: 24.2741680
	speed: 0.0145s/iter; left time: 424.0970s
Epoch: 40 cost time: 7.154597282409668
Epoch: 40, Steps: 487 Train Loss: 24.4256 (Forecasting Loss:0.4052 + XiCon Loss:2.4020 x Lambda(10.0)), Vali MSE Loss: 0.7197 Test MSE Loss: 0.5174
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 25.5822086
	speed: 0.0153s/iter; left time: 446.8407s
	iters: 200, epoch: 41 | loss: 23.2078209
	speed: 0.0140s/iter; left time: 406.5517s
	iters: 300, epoch: 41 | loss: 24.6958961
	speed: 0.0144s/iter; left time: 415.1713s
	iters: 400, epoch: 41 | loss: 24.4530315
	speed: 0.0153s/iter; left time: 442.0583s
Epoch: 41 cost time: 7.123394012451172
Epoch: 41, Steps: 487 Train Loss: 24.4276 (Forecasting Loss:0.4050 + XiCon Loss:2.4023 x Lambda(10.0)), Vali MSE Loss: 0.7198 Test MSE Loss: 0.5174
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5247127413749695, mae:0.5101137161254883, mape:3.6543428897857666, mspe:1259.045654296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.4509
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 25.9498367
	speed: 0.0165s/iter; left time: 800.1101s
	iters: 200, epoch: 1 | loss: 24.1500587
	speed: 0.0145s/iter; left time: 701.3907s
	iters: 300, epoch: 1 | loss: 25.4818039
	speed: 0.0138s/iter; left time: 666.3579s
	iters: 400, epoch: 1 | loss: 24.4755898
	speed: 0.0147s/iter; left time: 708.8031s
Epoch: 1 cost time: 6.937267303466797
Epoch: 1, Steps: 487 Train Loss: 25.3099 (Forecasting Loss:0.8053 + XiCon Loss:2.4505 x Lambda(10.0)), Vali MSE Loss: 1.1209 Test MSE Loss: 0.6653
Validation loss decreased (inf --> 1.120858).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 25.0680771
	speed: 0.0164s/iter; left time: 789.6496s
	iters: 200, epoch: 2 | loss: 25.4533978
	speed: 0.0142s/iter; left time: 680.4757s
	iters: 300, epoch: 2 | loss: 23.8541889
	speed: 0.0142s/iter; left time: 679.0269s
	iters: 400, epoch: 2 | loss: 23.1799850
	speed: 0.0152s/iter; left time: 725.1882s
Epoch: 2 cost time: 7.226357936859131
Epoch: 2, Steps: 487 Train Loss: 24.7056 (Forecasting Loss:0.4378 + XiCon Loss:2.4268 x Lambda(10.0)), Vali MSE Loss: 0.7472 Test MSE Loss: 0.5119
Validation loss decreased (1.120858 --> 0.747246).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 25.6695061
	speed: 0.0158s/iter; left time: 750.4253s
	iters: 200, epoch: 3 | loss: 24.6577835
	speed: 0.0137s/iter; left time: 650.8972s
	iters: 300, epoch: 3 | loss: 24.1956100
	speed: 0.0139s/iter; left time: 657.0701s
	iters: 400, epoch: 3 | loss: 25.0720825
	speed: 0.0138s/iter; left time: 652.8962s
Epoch: 3 cost time: 6.9832751750946045
Epoch: 3, Steps: 487 Train Loss: 24.5270 (Forecasting Loss:0.4036 + XiCon Loss:2.4123 x Lambda(10.0)), Vali MSE Loss: 0.7407 Test MSE Loss: 0.5085
Validation loss decreased (0.747246 --> 0.740659).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 25.1347828
	speed: 0.0161s/iter; left time: 757.5875s
	iters: 200, epoch: 4 | loss: 24.2863255
	speed: 0.0139s/iter; left time: 655.7393s
	iters: 300, epoch: 4 | loss: 25.0479736
	speed: 0.0135s/iter; left time: 635.0295s
	iters: 400, epoch: 4 | loss: 24.4215107
	speed: 0.0150s/iter; left time: 701.0807s
Epoch: 4 cost time: 7.1243555545806885
Epoch: 4, Steps: 487 Train Loss: 24.4809 (Forecasting Loss:0.3993 + XiCon Loss:2.4082 x Lambda(10.0)), Vali MSE Loss: 0.7337 Test MSE Loss: 0.5085
Validation loss decreased (0.740659 --> 0.733679).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 25.0498161
	speed: 0.0167s/iter; left time: 780.5026s
	iters: 200, epoch: 5 | loss: 25.5240707
	speed: 0.0138s/iter; left time: 643.6519s
	iters: 300, epoch: 5 | loss: 24.7184410
	speed: 0.0140s/iter; left time: 649.7090s
	iters: 400, epoch: 5 | loss: 23.9983635
	speed: 0.0142s/iter; left time: 657.3895s
Epoch: 5 cost time: 7.223829507827759
Epoch: 5, Steps: 487 Train Loss: 24.4638 (Forecasting Loss:0.3973 + XiCon Loss:2.4067 x Lambda(10.0)), Vali MSE Loss: 0.7322 Test MSE Loss: 0.5083
Validation loss decreased (0.733679 --> 0.732182).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 23.7966614
	speed: 0.0164s/iter; left time: 757.9095s
	iters: 200, epoch: 6 | loss: 24.2128315
	speed: 0.0141s/iter; left time: 647.3440s
	iters: 300, epoch: 6 | loss: 23.7378864
	speed: 0.0141s/iter; left time: 648.2196s
	iters: 400, epoch: 6 | loss: 25.2169533
	speed: 0.0139s/iter; left time: 638.7365s
Epoch: 6 cost time: 7.205065727233887
Epoch: 6, Steps: 487 Train Loss: 24.4240 (Forecasting Loss:0.3963 + XiCon Loss:2.4028 x Lambda(10.0)), Vali MSE Loss: 0.7310 Test MSE Loss: 0.5084
Validation loss decreased (0.732182 --> 0.731046).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 24.5078487
	speed: 0.0176s/iter; left time: 801.7189s
	iters: 200, epoch: 7 | loss: 23.0895958
	speed: 0.0136s/iter; left time: 618.5489s
	iters: 300, epoch: 7 | loss: 24.4614124
	speed: 0.0143s/iter; left time: 652.0468s
	iters: 400, epoch: 7 | loss: 23.7187691
	speed: 0.0150s/iter; left time: 679.2943s
Epoch: 7 cost time: 7.3487865924835205
Epoch: 7, Steps: 487 Train Loss: 24.3591 (Forecasting Loss:0.3960 + XiCon Loss:2.3963 x Lambda(10.0)), Vali MSE Loss: 0.7313 Test MSE Loss: 0.5080
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 24.3017769
	speed: 0.0160s/iter; left time: 721.1863s
	iters: 200, epoch: 8 | loss: 24.9870186
	speed: 0.0150s/iter; left time: 675.7462s
	iters: 300, epoch: 8 | loss: 24.3241901
	speed: 0.0148s/iter; left time: 667.5089s
	iters: 400, epoch: 8 | loss: 23.4490414
	speed: 0.0142s/iter; left time: 637.2629s
Epoch: 8 cost time: 7.268085479736328
Epoch: 8, Steps: 487 Train Loss: 24.3604 (Forecasting Loss:0.3958 + XiCon Loss:2.3965 x Lambda(10.0)), Vali MSE Loss: 0.7306 Test MSE Loss: 0.5079
Validation loss decreased (0.731046 --> 0.730604).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 24.7414608
	speed: 0.0172s/iter; left time: 771.0666s
	iters: 200, epoch: 9 | loss: 23.1192722
	speed: 0.0133s/iter; left time: 591.7593s
	iters: 300, epoch: 9 | loss: 24.3662128
	speed: 0.0152s/iter; left time: 674.7228s
	iters: 400, epoch: 9 | loss: 23.2065296
	speed: 0.0155s/iter; left time: 689.9244s
Epoch: 9 cost time: 7.488320827484131
Epoch: 9, Steps: 487 Train Loss: 24.4010 (Forecasting Loss:0.3957 + XiCon Loss:2.4005 x Lambda(10.0)), Vali MSE Loss: 0.7307 Test MSE Loss: 0.5079
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 24.4546204
	speed: 0.0171s/iter; left time: 758.1786s
	iters: 200, epoch: 10 | loss: 25.2813530
	speed: 0.0137s/iter; left time: 604.6107s
	iters: 300, epoch: 10 | loss: 25.0589733
	speed: 0.0149s/iter; left time: 654.9695s
	iters: 400, epoch: 10 | loss: 24.6884689
	speed: 0.0144s/iter; left time: 631.1684s
Epoch: 10 cost time: 7.313955545425415
Epoch: 10, Steps: 487 Train Loss: 24.3622 (Forecasting Loss:0.3956 + XiCon Loss:2.3967 x Lambda(10.0)), Vali MSE Loss: 0.7306 Test MSE Loss: 0.5078
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 23.8144512
	speed: 0.0163s/iter; left time: 712.4829s
	iters: 200, epoch: 11 | loss: 24.8665962
	speed: 0.0144s/iter; left time: 629.4231s
	iters: 300, epoch: 11 | loss: 23.4940434
	speed: 0.0135s/iter; left time: 587.8025s
	iters: 400, epoch: 11 | loss: 25.0060844
	speed: 0.0150s/iter; left time: 649.7400s
Epoch: 11 cost time: 7.282236814498901
Epoch: 11, Steps: 487 Train Loss: 24.3659 (Forecasting Loss:0.3957 + XiCon Loss:2.3970 x Lambda(10.0)), Vali MSE Loss: 0.7304 Test MSE Loss: 0.5078
Validation loss decreased (0.730604 --> 0.730417).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 24.9143219
	speed: 0.0164s/iter; left time: 707.2594s
	iters: 200, epoch: 12 | loss: 23.3767681
	speed: 0.0134s/iter; left time: 578.1021s
	iters: 300, epoch: 12 | loss: 22.6870003
	speed: 0.0145s/iter; left time: 624.7008s
	iters: 400, epoch: 12 | loss: 23.8966923
	speed: 0.0147s/iter; left time: 632.6674s
Epoch: 12 cost time: 7.202637434005737
Epoch: 12, Steps: 487 Train Loss: 24.4159 (Forecasting Loss:0.3957 + XiCon Loss:2.4020 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 24.2224693
	speed: 0.0161s/iter; left time: 687.2894s
	iters: 200, epoch: 13 | loss: 24.2571220
	speed: 0.0145s/iter; left time: 618.3464s
	iters: 300, epoch: 13 | loss: 23.4968147
	speed: 0.0147s/iter; left time: 624.4098s
	iters: 400, epoch: 13 | loss: 23.7300358
	speed: 0.0148s/iter; left time: 628.0222s
Epoch: 13 cost time: 7.213170528411865
Epoch: 13, Steps: 487 Train Loss: 24.3619 (Forecasting Loss:0.3954 + XiCon Loss:2.3966 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 24.6053658
	speed: 0.0164s/iter; left time: 694.3425s
	iters: 200, epoch: 14 | loss: 25.2316608
	speed: 0.0145s/iter; left time: 611.5351s
	iters: 300, epoch: 14 | loss: 24.0620327
	speed: 0.0150s/iter; left time: 632.4985s
	iters: 400, epoch: 14 | loss: 23.8651905
	speed: 0.0140s/iter; left time: 586.7933s
Epoch: 14 cost time: 7.26988673210144
Epoch: 14, Steps: 487 Train Loss: 24.3684 (Forecasting Loss:0.3953 + XiCon Loss:2.3973 x Lambda(10.0)), Vali MSE Loss: 0.7306 Test MSE Loss: 0.5078
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 23.9608135
	speed: 0.0158s/iter; left time: 659.4056s
	iters: 200, epoch: 15 | loss: 24.4391346
	speed: 0.0138s/iter; left time: 574.9087s
	iters: 300, epoch: 15 | loss: 24.6113911
	speed: 0.0149s/iter; left time: 621.2125s
	iters: 400, epoch: 15 | loss: 25.6369190
	speed: 0.0159s/iter; left time: 657.6575s
Epoch: 15 cost time: 7.398589611053467
Epoch: 15, Steps: 487 Train Loss: 24.3453 (Forecasting Loss:0.3957 + XiCon Loss:2.3950 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 23.8051262
	speed: 0.0173s/iter; left time: 712.7350s
	iters: 200, epoch: 16 | loss: 23.6704865
	speed: 0.0142s/iter; left time: 583.4354s
	iters: 300, epoch: 16 | loss: 23.6670837
	speed: 0.0140s/iter; left time: 576.9653s
	iters: 400, epoch: 16 | loss: 23.3633862
	speed: 0.0149s/iter; left time: 610.3844s
Epoch: 16 cost time: 7.307153701782227
Epoch: 16, Steps: 487 Train Loss: 24.3274 (Forecasting Loss:0.3957 + XiCon Loss:2.3932 x Lambda(10.0)), Vali MSE Loss: 0.7309 Test MSE Loss: 0.5078
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 24.6449661
	speed: 0.0164s/iter; left time: 670.1867s
	iters: 200, epoch: 17 | loss: 24.6997604
	speed: 0.0140s/iter; left time: 569.1483s
	iters: 300, epoch: 17 | loss: 23.7905350
	speed: 0.0151s/iter; left time: 612.1503s
	iters: 400, epoch: 17 | loss: 24.9054070
	speed: 0.0152s/iter; left time: 613.7249s
Epoch: 17 cost time: 7.275192499160767
Epoch: 17, Steps: 487 Train Loss: 24.4317 (Forecasting Loss:0.3953 + XiCon Loss:2.4036 x Lambda(10.0)), Vali MSE Loss: 0.7306 Test MSE Loss: 0.5078
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 24.3572845
	speed: 0.0165s/iter; left time: 664.4343s
	iters: 200, epoch: 18 | loss: 24.4216232
	speed: 0.0138s/iter; left time: 555.7594s
	iters: 300, epoch: 18 | loss: 24.2915192
	speed: 0.0139s/iter; left time: 558.5119s
	iters: 400, epoch: 18 | loss: 25.3238640
	speed: 0.0149s/iter; left time: 597.8556s
Epoch: 18 cost time: 7.172870874404907
Epoch: 18, Steps: 487 Train Loss: 24.3822 (Forecasting Loss:0.3955 + XiCon Loss:2.3987 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 24.2330513
	speed: 0.0152s/iter; left time: 603.8904s
	iters: 200, epoch: 19 | loss: 23.3980408
	speed: 0.0129s/iter; left time: 511.1195s
	iters: 300, epoch: 19 | loss: 23.8399963
	speed: 0.0137s/iter; left time: 542.6622s
	iters: 400, epoch: 19 | loss: 25.8980885
	speed: 0.0136s/iter; left time: 538.5210s
Epoch: 19 cost time: 6.754603385925293
Epoch: 19, Steps: 487 Train Loss: 24.3991 (Forecasting Loss:0.3957 + XiCon Loss:2.4003 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 24.6437702
	speed: 0.0157s/iter; left time: 618.9876s
	iters: 200, epoch: 20 | loss: 24.8191719
	speed: 0.0133s/iter; left time: 520.6462s
	iters: 300, epoch: 20 | loss: 23.2459812
	speed: 0.0134s/iter; left time: 525.0750s
	iters: 400, epoch: 20 | loss: 25.0929565
	speed: 0.0132s/iter; left time: 513.8365s
Epoch: 20 cost time: 6.7615227699279785
Epoch: 20, Steps: 487 Train Loss: 24.3856 (Forecasting Loss:0.3957 + XiCon Loss:2.3990 x Lambda(10.0)), Vali MSE Loss: 0.7304 Test MSE Loss: 0.5078
Validation loss decreased (0.730417 --> 0.730366).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 25.1656895
	speed: 0.0167s/iter; left time: 649.6830s
	iters: 200, epoch: 21 | loss: 22.7809277
	speed: 0.0147s/iter; left time: 568.1721s
	iters: 300, epoch: 21 | loss: 24.4956226
	speed: 0.0137s/iter; left time: 529.2947s
	iters: 400, epoch: 21 | loss: 24.8354645
	speed: 0.0140s/iter; left time: 539.9279s
Epoch: 21 cost time: 7.110297441482544
Epoch: 21, Steps: 487 Train Loss: 24.4285 (Forecasting Loss:0.3955 + XiCon Loss:2.4033 x Lambda(10.0)), Vali MSE Loss: 0.7309 Test MSE Loss: 0.5078
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 23.5991802
	speed: 0.0155s/iter; left time: 595.3485s
	iters: 200, epoch: 22 | loss: 24.1224766
	speed: 0.0137s/iter; left time: 523.0955s
	iters: 300, epoch: 22 | loss: 25.1780453
	speed: 0.0138s/iter; left time: 526.3845s
	iters: 400, epoch: 22 | loss: 24.3106518
	speed: 0.0149s/iter; left time: 566.0273s
Epoch: 22 cost time: 7.038604021072388
Epoch: 22, Steps: 487 Train Loss: 24.4123 (Forecasting Loss:0.3954 + XiCon Loss:2.4017 x Lambda(10.0)), Vali MSE Loss: 0.7306 Test MSE Loss: 0.5078
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 24.4041195
	speed: 0.0158s/iter; left time: 598.2666s
	iters: 200, epoch: 23 | loss: 23.6235943
	speed: 0.0144s/iter; left time: 543.5609s
	iters: 300, epoch: 23 | loss: 23.9139862
	speed: 0.0150s/iter; left time: 565.5526s
	iters: 400, epoch: 23 | loss: 25.3841438
	speed: 0.0135s/iter; left time: 506.3902s
Epoch: 23 cost time: 7.035226345062256
Epoch: 23, Steps: 487 Train Loss: 24.3934 (Forecasting Loss:0.3956 + XiCon Loss:2.3998 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 24.2738495
	speed: 0.0152s/iter; left time: 568.4701s
	iters: 200, epoch: 24 | loss: 24.8416405
	speed: 0.0134s/iter; left time: 500.9204s
	iters: 300, epoch: 24 | loss: 24.3267784
	speed: 0.0131s/iter; left time: 487.5350s
	iters: 400, epoch: 24 | loss: 24.5928822
	speed: 0.0139s/iter; left time: 515.8357s
Epoch: 24 cost time: 6.742874383926392
Epoch: 24, Steps: 487 Train Loss: 24.3526 (Forecasting Loss:0.3956 + XiCon Loss:2.3957 x Lambda(10.0)), Vali MSE Loss: 0.7307 Test MSE Loss: 0.5078
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 24.1678104
	speed: 0.0148s/iter; left time: 547.4952s
	iters: 200, epoch: 25 | loss: 24.3626461
	speed: 0.0126s/iter; left time: 465.1013s
	iters: 300, epoch: 25 | loss: 24.8157253
	speed: 0.0132s/iter; left time: 483.9040s
	iters: 400, epoch: 25 | loss: 24.4614506
	speed: 0.0148s/iter; left time: 541.0764s
Epoch: 25 cost time: 6.873945474624634
Epoch: 25, Steps: 487 Train Loss: 24.4114 (Forecasting Loss:0.3954 + XiCon Loss:2.4016 x Lambda(10.0)), Vali MSE Loss: 0.7301 Test MSE Loss: 0.5078
Validation loss decreased (0.730366 --> 0.730108).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 23.9142151
	speed: 0.0150s/iter; left time: 544.6570s
	iters: 200, epoch: 26 | loss: 24.3401222
	speed: 0.0137s/iter; left time: 496.4597s
	iters: 300, epoch: 26 | loss: 24.8678436
	speed: 0.0131s/iter; left time: 473.3505s
	iters: 400, epoch: 26 | loss: 25.2400990
	speed: 0.0350s/iter; left time: 1264.3603s
Epoch: 26 cost time: 13.18441104888916
Epoch: 26, Steps: 487 Train Loss: 24.3626 (Forecasting Loss:0.3952 + XiCon Loss:2.3967 x Lambda(10.0)), Vali MSE Loss: 0.7309 Test MSE Loss: 0.5078
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 24.9643860
	speed: 0.0651s/iter; left time: 2340.1618s
	iters: 200, epoch: 27 | loss: 24.7782707
	speed: 0.0603s/iter; left time: 2161.4366s
	iters: 300, epoch: 27 | loss: 24.3819237
	speed: 0.0531s/iter; left time: 1898.4729s
	iters: 400, epoch: 27 | loss: 24.2607841
	speed: 0.0674s/iter; left time: 2402.9786s
Epoch: 27 cost time: 28.921265363693237
Epoch: 27, Steps: 487 Train Loss: 24.4070 (Forecasting Loss:0.3953 + XiCon Loss:2.4012 x Lambda(10.0)), Vali MSE Loss: 0.7307 Test MSE Loss: 0.5078
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 24.8792915
	speed: 0.0668s/iter; left time: 2369.6112s
	iters: 200, epoch: 28 | loss: 24.2639694
	speed: 0.0629s/iter; left time: 2225.2129s
	iters: 300, epoch: 28 | loss: 23.9978943
	speed: 0.0627s/iter; left time: 2209.4700s
	iters: 400, epoch: 28 | loss: 24.7073689
	speed: 0.0614s/iter; left time: 2158.5861s
Epoch: 28 cost time: 30.445104837417603
Epoch: 28, Steps: 487 Train Loss: 24.3735 (Forecasting Loss:0.3957 + XiCon Loss:2.3978 x Lambda(10.0)), Vali MSE Loss: 0.7300 Test MSE Loss: 0.5078
Validation loss decreased (0.730108 --> 0.730001).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 24.0508118
	speed: 0.0532s/iter; left time: 1861.8862s
	iters: 200, epoch: 29 | loss: 24.1884003
	speed: 0.0605s/iter; left time: 2108.8859s
	iters: 300, epoch: 29 | loss: 24.9405079
	speed: 0.0535s/iter; left time: 1858.9856s
	iters: 400, epoch: 29 | loss: 25.2787113
	speed: 0.0575s/iter; left time: 1994.6039s
Epoch: 29 cost time: 27.00450372695923
Epoch: 29, Steps: 487 Train Loss: 24.3819 (Forecasting Loss:0.3956 + XiCon Loss:2.3986 x Lambda(10.0)), Vali MSE Loss: 0.7302 Test MSE Loss: 0.5078
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 23.9594231
	speed: 0.0516s/iter; left time: 1779.5122s
	iters: 200, epoch: 30 | loss: 24.1951885
	speed: 0.0483s/iter; left time: 1661.5995s
	iters: 300, epoch: 30 | loss: 24.0424709
	speed: 0.0483s/iter; left time: 1655.3479s
	iters: 400, epoch: 30 | loss: 24.5647945
	speed: 0.0459s/iter; left time: 1568.3202s
Epoch: 30 cost time: 23.666138410568237
Epoch: 30, Steps: 487 Train Loss: 24.4157 (Forecasting Loss:0.3957 + XiCon Loss:2.4020 x Lambda(10.0)), Vali MSE Loss: 0.7306 Test MSE Loss: 0.5078
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 23.2819462
	speed: 0.0413s/iter; left time: 1403.0677s
	iters: 200, epoch: 31 | loss: 23.5702248
	speed: 0.0438s/iter; left time: 1485.5454s
	iters: 300, epoch: 31 | loss: 25.0421238
	speed: 0.0466s/iter; left time: 1576.2869s
	iters: 400, epoch: 31 | loss: 24.5781422
	speed: 0.0459s/iter; left time: 1546.0736s
Epoch: 31 cost time: 21.445518732070923
Epoch: 31, Steps: 487 Train Loss: 24.3774 (Forecasting Loss:0.3953 + XiCon Loss:2.3982 x Lambda(10.0)), Vali MSE Loss: 0.7307 Test MSE Loss: 0.5078
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 25.0552807
	speed: 0.0424s/iter; left time: 1420.5789s
	iters: 200, epoch: 32 | loss: 25.3644314
	speed: 0.0421s/iter; left time: 1407.4963s
	iters: 300, epoch: 32 | loss: 23.8795891
	speed: 0.0362s/iter; left time: 1205.7979s
	iters: 400, epoch: 32 | loss: 23.8576508
	speed: 0.0244s/iter; left time: 809.9947s
Epoch: 32 cost time: 16.131526231765747
Epoch: 32, Steps: 487 Train Loss: 24.3901 (Forecasting Loss:0.3956 + XiCon Loss:2.3994 x Lambda(10.0)), Vali MSE Loss: 0.7304 Test MSE Loss: 0.5078
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 24.2929344
	speed: 0.0212s/iter; left time: 699.0719s
	iters: 200, epoch: 33 | loss: 25.4022522
	speed: 0.0190s/iter; left time: 625.7080s
	iters: 300, epoch: 33 | loss: 24.9749050
	speed: 0.0249s/iter; left time: 815.5287s
	iters: 400, epoch: 33 | loss: 24.0454674
	speed: 0.0192s/iter; left time: 629.7461s
Epoch: 33 cost time: 10.21445345878601
Epoch: 33, Steps: 487 Train Loss: 24.3506 (Forecasting Loss:0.3954 + XiCon Loss:2.3955 x Lambda(10.0)), Vali MSE Loss: 0.7305 Test MSE Loss: 0.5078
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 23.5529823
	speed: 0.0206s/iter; left time: 670.0328s
	iters: 200, epoch: 34 | loss: 25.6426563
	speed: 0.0182s/iter; left time: 591.2367s
	iters: 300, epoch: 34 | loss: 24.2110786
	speed: 0.0177s/iter; left time: 571.7558s
	iters: 400, epoch: 34 | loss: 25.0395756
	speed: 0.0182s/iter; left time: 585.5209s
Epoch: 34 cost time: 9.033978939056396
Epoch: 34, Steps: 487 Train Loss: 24.3702 (Forecasting Loss:0.3956 + XiCon Loss:2.3975 x Lambda(10.0)), Vali MSE Loss: 0.7309 Test MSE Loss: 0.5078
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 24.4662247
	speed: 0.0190s/iter; left time: 609.9367s
	iters: 200, epoch: 35 | loss: 23.7915478
	speed: 0.0167s/iter; left time: 532.7669s
	iters: 300, epoch: 35 | loss: 25.1643085
	speed: 0.0167s/iter; left time: 531.1328s
	iters: 400, epoch: 35 | loss: 25.1497116
	speed: 0.0176s/iter; left time: 557.4554s
Epoch: 35 cost time: 8.524838209152222
Epoch: 35, Steps: 487 Train Loss: 24.3605 (Forecasting Loss:0.3956 + XiCon Loss:2.3965 x Lambda(10.0)), Vali MSE Loss: 0.7303 Test MSE Loss: 0.5078
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 23.9099998
	speed: 0.0182s/iter; left time: 573.7067s
	iters: 200, epoch: 36 | loss: 24.2007160
	speed: 0.0158s/iter; left time: 497.0579s
	iters: 300, epoch: 36 | loss: 23.5541611
	speed: 0.0159s/iter; left time: 498.2118s
	iters: 400, epoch: 36 | loss: 23.3680153
	speed: 0.0161s/iter; left time: 502.1898s
Epoch: 36 cost time: 7.960582733154297
Epoch: 36, Steps: 487 Train Loss: 24.3745 (Forecasting Loss:0.3953 + XiCon Loss:2.3979 x Lambda(10.0)), Vali MSE Loss: 0.7302 Test MSE Loss: 0.5078
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 22.6115837
	speed: 0.0185s/iter; left time: 573.4954s
	iters: 200, epoch: 37 | loss: 24.0628242
	speed: 0.0154s/iter; left time: 477.9363s
	iters: 300, epoch: 37 | loss: 23.6466293
	speed: 0.0158s/iter; left time: 487.2572s
	iters: 400, epoch: 37 | loss: 23.4681072
	speed: 0.0161s/iter; left time: 494.0695s
Epoch: 37 cost time: 8.028470277786255
Epoch: 37, Steps: 487 Train Loss: 24.3517 (Forecasting Loss:0.3956 + XiCon Loss:2.3956 x Lambda(10.0)), Vali MSE Loss: 0.7304 Test MSE Loss: 0.5078
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 24.3796291
	speed: 0.0174s/iter; left time: 530.7662s
	iters: 200, epoch: 38 | loss: 24.3515205
	speed: 0.0156s/iter; left time: 476.4616s
	iters: 300, epoch: 38 | loss: 24.2269974
	speed: 0.0150s/iter; left time: 454.8873s
	iters: 400, epoch: 38 | loss: 24.8634243
	speed: 0.0156s/iter; left time: 472.5091s
Epoch: 38 cost time: 7.742656707763672
Epoch: 38, Steps: 487 Train Loss: 24.4335 (Forecasting Loss:0.3956 + XiCon Loss:2.4038 x Lambda(10.0)), Vali MSE Loss: 0.7308 Test MSE Loss: 0.5078
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5112167000770569, mae:0.5044204592704773, mape:3.7000131607055664, mspe:1278.3507080078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 19.9788
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 25.6134720
	speed: 0.0189s/iter; left time: 916.2125s
	iters: 200, epoch: 1 | loss: 26.4061241
	speed: 0.0145s/iter; left time: 701.6099s
	iters: 300, epoch: 1 | loss: 25.0463791
	speed: 0.0145s/iter; left time: 700.3311s
	iters: 400, epoch: 1 | loss: 26.2439079
	speed: 0.0147s/iter; left time: 707.9566s
Epoch: 1 cost time: 7.542882442474365
Epoch: 1, Steps: 487 Train Loss: 25.6177 (Forecasting Loss:0.7535 + XiCon Loss:2.4864 x Lambda(10.0)), Vali MSE Loss: 1.0059 Test MSE Loss: 0.6211
Validation loss decreased (inf --> 1.005934).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 26.1044159
	speed: 0.0167s/iter; left time: 803.9208s
	iters: 200, epoch: 2 | loss: 24.8054237
	speed: 0.0143s/iter; left time: 688.3919s
	iters: 300, epoch: 2 | loss: 25.1082249
	speed: 0.0143s/iter; left time: 687.1394s
	iters: 400, epoch: 2 | loss: 23.3868790
	speed: 0.0141s/iter; left time: 672.7098s
Epoch: 2 cost time: 7.181886196136475
Epoch: 2, Steps: 487 Train Loss: 24.8984 (Forecasting Loss:0.4362 + XiCon Loss:2.4462 x Lambda(10.0)), Vali MSE Loss: 0.7658 Test MSE Loss: 0.5385
Validation loss decreased (1.005934 --> 0.765760).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 24.3099155
	speed: 0.0165s/iter; left time: 783.9961s
	iters: 200, epoch: 3 | loss: 24.0304680
	speed: 0.0143s/iter; left time: 681.9584s
	iters: 300, epoch: 3 | loss: 25.2247849
	speed: 0.0142s/iter; left time: 675.7265s
	iters: 400, epoch: 3 | loss: 24.0381851
	speed: 0.0139s/iter; left time: 658.1872s
Epoch: 3 cost time: 7.1448681354522705
Epoch: 3, Steps: 487 Train Loss: 24.6051 (Forecasting Loss:0.4065 + XiCon Loss:2.4199 x Lambda(10.0)), Vali MSE Loss: 0.7480 Test MSE Loss: 0.5201
Validation loss decreased (0.765760 --> 0.748019).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 25.5683765
	speed: 0.0165s/iter; left time: 777.6800s
	iters: 200, epoch: 4 | loss: 24.0354309
	speed: 0.0142s/iter; left time: 666.7365s
	iters: 300, epoch: 4 | loss: 23.8076019
	speed: 0.0144s/iter; left time: 674.5782s
	iters: 400, epoch: 4 | loss: 24.8694496
	speed: 0.0145s/iter; left time: 678.7904s
Epoch: 4 cost time: 7.180586099624634
Epoch: 4, Steps: 487 Train Loss: 24.5019 (Forecasting Loss:0.4005 + XiCon Loss:2.4101 x Lambda(10.0)), Vali MSE Loss: 0.7482 Test MSE Loss: 0.5189
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 25.3172760
	speed: 0.0157s/iter; left time: 731.6158s
	iters: 200, epoch: 5 | loss: 24.2387714
	speed: 0.0133s/iter; left time: 619.1692s
	iters: 300, epoch: 5 | loss: 25.1013775
	speed: 0.0138s/iter; left time: 639.6933s
	iters: 400, epoch: 5 | loss: 25.2579193
	speed: 0.0136s/iter; left time: 628.3570s
Epoch: 5 cost time: 6.843535900115967
Epoch: 5, Steps: 487 Train Loss: 24.4998 (Forecasting Loss:0.3985 + XiCon Loss:2.4101 x Lambda(10.0)), Vali MSE Loss: 0.7390 Test MSE Loss: 0.5141
Validation loss decreased (0.748019 --> 0.738961).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 25.2180595
	speed: 0.0158s/iter; left time: 731.2402s
	iters: 200, epoch: 6 | loss: 25.4179173
	speed: 0.0134s/iter; left time: 615.2004s
	iters: 300, epoch: 6 | loss: 24.0579414
	speed: 0.0136s/iter; left time: 627.2853s
	iters: 400, epoch: 6 | loss: 24.8067360
	speed: 0.0140s/iter; left time: 643.1505s
Epoch: 6 cost time: 6.922258138656616
Epoch: 6, Steps: 487 Train Loss: 24.5250 (Forecasting Loss:0.3974 + XiCon Loss:2.4128 x Lambda(10.0)), Vali MSE Loss: 0.7371 Test MSE Loss: 0.5132
Validation loss decreased (0.738961 --> 0.737125).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 24.2964993
	speed: 0.0151s/iter; left time: 690.6191s
	iters: 200, epoch: 7 | loss: 25.3733330
	speed: 0.0132s/iter; left time: 600.2488s
	iters: 300, epoch: 7 | loss: 23.9579258
	speed: 0.0133s/iter; left time: 602.9543s
	iters: 400, epoch: 7 | loss: 25.3281708
	speed: 0.0129s/iter; left time: 586.7200s
Epoch: 7 cost time: 6.617966175079346
Epoch: 7, Steps: 487 Train Loss: 24.4634 (Forecasting Loss:0.3969 + XiCon Loss:2.4066 x Lambda(10.0)), Vali MSE Loss: 0.7377 Test MSE Loss: 0.5142
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 24.1050358
	speed: 0.0148s/iter; left time: 668.5488s
	iters: 200, epoch: 8 | loss: 24.9901810
	speed: 0.0128s/iter; left time: 575.8955s
	iters: 300, epoch: 8 | loss: 23.8053322
	speed: 0.0131s/iter; left time: 590.7221s
	iters: 400, epoch: 8 | loss: 24.2803230
	speed: 0.0130s/iter; left time: 585.8276s
Epoch: 8 cost time: 6.542962074279785
Epoch: 8, Steps: 487 Train Loss: 24.4816 (Forecasting Loss:0.3965 + XiCon Loss:2.4085 x Lambda(10.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5133
Validation loss decreased (0.737125 --> 0.736741).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 24.3543491
	speed: 0.0154s/iter; left time: 688.4650s
	iters: 200, epoch: 9 | loss: 23.9358292
	speed: 0.0137s/iter; left time: 611.6892s
	iters: 300, epoch: 9 | loss: 25.1117573
	speed: 0.0133s/iter; left time: 592.4024s
	iters: 400, epoch: 9 | loss: 24.8161564
	speed: 0.0135s/iter; left time: 599.8917s
Epoch: 9 cost time: 6.752959728240967
Epoch: 9, Steps: 487 Train Loss: 24.4904 (Forecasting Loss:0.3963 + XiCon Loss:2.4094 x Lambda(10.0)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5135
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 24.4795818
	speed: 0.0148s/iter; left time: 655.8486s
	iters: 200, epoch: 10 | loss: 23.6351566
	speed: 0.0134s/iter; left time: 593.1177s
	iters: 300, epoch: 10 | loss: 23.1842403
	speed: 0.0133s/iter; left time: 583.9849s
	iters: 400, epoch: 10 | loss: 24.7016582
	speed: 0.0139s/iter; left time: 610.8881s
Epoch: 10 cost time: 6.690659046173096
Epoch: 10, Steps: 487 Train Loss: 24.5148 (Forecasting Loss:0.3965 + XiCon Loss:2.4118 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
Validation loss decreased (0.736741 --> 0.736601).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 24.4668522
	speed: 0.0149s/iter; left time: 652.9267s
	iters: 200, epoch: 11 | loss: 24.0952511
	speed: 0.0130s/iter; left time: 568.2043s
	iters: 300, epoch: 11 | loss: 23.7198238
	speed: 0.0133s/iter; left time: 577.9050s
	iters: 400, epoch: 11 | loss: 24.8191319
	speed: 0.0133s/iter; left time: 576.6995s
Epoch: 11 cost time: 6.647969722747803
Epoch: 11, Steps: 487 Train Loss: 24.4702 (Forecasting Loss:0.3963 + XiCon Loss:2.4074 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 24.0206184
	speed: 0.0150s/iter; left time: 650.4702s
	iters: 200, epoch: 12 | loss: 24.5928822
	speed: 0.0131s/iter; left time: 565.9269s
	iters: 300, epoch: 12 | loss: 24.2914524
	speed: 0.0136s/iter; left time: 584.3572s
	iters: 400, epoch: 12 | loss: 24.7570477
	speed: 0.0133s/iter; left time: 571.9955s
Epoch: 12 cost time: 6.8541319370269775
Epoch: 12, Steps: 487 Train Loss: 24.4384 (Forecasting Loss:0.3964 + XiCon Loss:2.4042 x Lambda(10.0)), Vali MSE Loss: 0.7362 Test MSE Loss: 0.5133
Validation loss decreased (0.736601 --> 0.736231).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 23.9925289
	speed: 0.0141s/iter; left time: 601.3051s
	iters: 200, epoch: 13 | loss: 25.1936665
	speed: 0.0128s/iter; left time: 545.9909s
	iters: 300, epoch: 13 | loss: 24.0068340
	speed: 0.0135s/iter; left time: 574.7311s
	iters: 400, epoch: 13 | loss: 23.8912067
	speed: 0.0146s/iter; left time: 618.7326s
Epoch: 13 cost time: 6.732654571533203
Epoch: 13, Steps: 487 Train Loss: 24.5022 (Forecasting Loss:0.3962 + XiCon Loss:2.4106 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 25.2108040
	speed: 0.0162s/iter; left time: 684.6519s
	iters: 200, epoch: 14 | loss: 23.9210663
	speed: 0.0130s/iter; left time: 546.4822s
	iters: 300, epoch: 14 | loss: 25.2542534
	speed: 0.0136s/iter; left time: 572.2572s
	iters: 400, epoch: 14 | loss: 24.3329067
	speed: 0.0136s/iter; left time: 570.1978s
Epoch: 14 cost time: 6.884110927581787
Epoch: 14, Steps: 487 Train Loss: 24.5006 (Forecasting Loss:0.3961 + XiCon Loss:2.4104 x Lambda(10.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5133
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 24.8916092
	speed: 0.0162s/iter; left time: 675.1213s
	iters: 200, epoch: 15 | loss: 23.9456291
	speed: 0.0130s/iter; left time: 543.2059s
	iters: 300, epoch: 15 | loss: 25.1903820
	speed: 0.0135s/iter; left time: 561.1724s
	iters: 400, epoch: 15 | loss: 25.7987423
	speed: 0.0131s/iter; left time: 543.7603s
Epoch: 15 cost time: 6.945666551589966
Epoch: 15, Steps: 487 Train Loss: 24.5208 (Forecasting Loss:0.3963 + XiCon Loss:2.4124 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 23.9750633
	speed: 0.0160s/iter; left time: 662.5773s
	iters: 200, epoch: 16 | loss: 25.0483837
	speed: 0.0137s/iter; left time: 564.7428s
	iters: 300, epoch: 16 | loss: 23.2468510
	speed: 0.0144s/iter; left time: 590.1757s
	iters: 400, epoch: 16 | loss: 24.1398602
	speed: 0.0141s/iter; left time: 578.3913s
Epoch: 16 cost time: 7.10082483291626
Epoch: 16, Steps: 487 Train Loss: 24.4627 (Forecasting Loss:0.3964 + XiCon Loss:2.4066 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 25.2907734
	speed: 0.0159s/iter; left time: 649.0659s
	iters: 200, epoch: 17 | loss: 23.8834515
	speed: 0.0130s/iter; left time: 527.3521s
	iters: 300, epoch: 17 | loss: 24.9530621
	speed: 0.0134s/iter; left time: 544.2967s
	iters: 400, epoch: 17 | loss: 23.1501865
	speed: 0.0140s/iter; left time: 567.8002s
Epoch: 17 cost time: 6.842480421066284
Epoch: 17, Steps: 487 Train Loss: 24.4576 (Forecasting Loss:0.3961 + XiCon Loss:2.4061 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 24.3037643
	speed: 0.0161s/iter; left time: 647.2996s
	iters: 200, epoch: 18 | loss: 24.1033802
	speed: 0.0130s/iter; left time: 521.1465s
	iters: 300, epoch: 18 | loss: 24.7214375
	speed: 0.0131s/iter; left time: 525.9812s
	iters: 400, epoch: 18 | loss: 23.5421200
	speed: 0.0142s/iter; left time: 566.9789s
Epoch: 18 cost time: 6.956892251968384
Epoch: 18, Steps: 487 Train Loss: 24.4863 (Forecasting Loss:0.3963 + XiCon Loss:2.4090 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 24.6235065
	speed: 0.0151s/iter; left time: 602.3164s
	iters: 200, epoch: 19 | loss: 24.6187935
	speed: 0.0132s/iter; left time: 522.7020s
	iters: 300, epoch: 19 | loss: 24.6209850
	speed: 0.0143s/iter; left time: 568.5234s
	iters: 400, epoch: 19 | loss: 24.6116943
	speed: 0.0146s/iter; left time: 578.7595s
Epoch: 19 cost time: 6.987739562988281
Epoch: 19, Steps: 487 Train Loss: 24.4673 (Forecasting Loss:0.3963 + XiCon Loss:2.4071 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 23.9502487
	speed: 0.0167s/iter; left time: 657.8733s
	iters: 200, epoch: 20 | loss: 24.0559750
	speed: 0.0139s/iter; left time: 545.8285s
	iters: 300, epoch: 20 | loss: 24.5385818
	speed: 0.0136s/iter; left time: 533.2809s
	iters: 400, epoch: 20 | loss: 24.8237495
	speed: 0.0146s/iter; left time: 568.7812s
Epoch: 20 cost time: 7.105218410491943
Epoch: 20, Steps: 487 Train Loss: 24.4908 (Forecasting Loss:0.3962 + XiCon Loss:2.4095 x Lambda(10.0)), Vali MSE Loss: 0.7359 Test MSE Loss: 0.5133
Validation loss decreased (0.736231 --> 0.735924).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 24.6652431
	speed: 0.0154s/iter; left time: 596.6684s
	iters: 200, epoch: 21 | loss: 24.2416859
	speed: 0.0138s/iter; left time: 536.1922s
	iters: 300, epoch: 21 | loss: 23.6731415
	speed: 0.0135s/iter; left time: 522.9768s
	iters: 400, epoch: 21 | loss: 24.2444286
	speed: 0.0132s/iter; left time: 510.0396s
Epoch: 21 cost time: 6.785560369491577
Epoch: 21, Steps: 487 Train Loss: 24.4774 (Forecasting Loss:0.3961 + XiCon Loss:2.4081 x Lambda(10.0)), Vali MSE Loss: 0.7368 Test MSE Loss: 0.5133
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 24.7093754
	speed: 0.0153s/iter; left time: 587.3743s
	iters: 200, epoch: 22 | loss: 24.5228386
	speed: 0.0137s/iter; left time: 523.6489s
	iters: 300, epoch: 22 | loss: 23.0784702
	speed: 0.0140s/iter; left time: 533.4613s
	iters: 400, epoch: 22 | loss: 23.3172626
	speed: 0.0143s/iter; left time: 545.2321s
Epoch: 22 cost time: 6.95347785949707
Epoch: 22, Steps: 487 Train Loss: 24.4537 (Forecasting Loss:0.3964 + XiCon Loss:2.4057 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 24.4916897
	speed: 0.0161s/iter; left time: 611.0525s
	iters: 200, epoch: 23 | loss: 24.0685978
	speed: 0.0138s/iter; left time: 521.4931s
	iters: 300, epoch: 23 | loss: 25.3345203
	speed: 0.0139s/iter; left time: 522.0017s
	iters: 400, epoch: 23 | loss: 25.2436275
	speed: 0.0142s/iter; left time: 535.0525s
Epoch: 23 cost time: 7.062401533126831
Epoch: 23, Steps: 487 Train Loss: 24.4606 (Forecasting Loss:0.3964 + XiCon Loss:2.4064 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 23.4822407
	speed: 0.0167s/iter; left time: 623.0076s
	iters: 200, epoch: 24 | loss: 24.7801189
	speed: 0.0139s/iter; left time: 517.1632s
	iters: 300, epoch: 24 | loss: 23.3915558
	speed: 0.0135s/iter; left time: 500.4505s
	iters: 400, epoch: 24 | loss: 25.3972130
	speed: 0.0137s/iter; left time: 508.7352s
Epoch: 24 cost time: 6.97086763381958
Epoch: 24, Steps: 487 Train Loss: 24.4479 (Forecasting Loss:0.3964 + XiCon Loss:2.4052 x Lambda(10.0)), Vali MSE Loss: 0.7358 Test MSE Loss: 0.5133
Validation loss decreased (0.735924 --> 0.735840).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 25.6185722
	speed: 0.0155s/iter; left time: 570.9483s
	iters: 200, epoch: 25 | loss: 25.0011749
	speed: 0.0135s/iter; left time: 498.7701s
	iters: 300, epoch: 25 | loss: 24.9343586
	speed: 0.0137s/iter; left time: 504.4378s
	iters: 400, epoch: 25 | loss: 23.9400024
	speed: 0.0140s/iter; left time: 514.0863s
Epoch: 25 cost time: 6.841741323471069
Epoch: 25, Steps: 487 Train Loss: 24.5040 (Forecasting Loss:0.3963 + XiCon Loss:2.4108 x Lambda(10.0)), Vali MSE Loss: 0.7360 Test MSE Loss: 0.5133
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 25.0379391
	speed: 0.0160s/iter; left time: 584.5426s
	iters: 200, epoch: 26 | loss: 24.5432911
	speed: 0.0141s/iter; left time: 512.0298s
	iters: 300, epoch: 26 | loss: 24.2965603
	speed: 0.0137s/iter; left time: 495.0307s
	iters: 400, epoch: 26 | loss: 25.1018276
	speed: 0.0136s/iter; left time: 490.7804s
Epoch: 26 cost time: 6.955548524856567
Epoch: 26, Steps: 487 Train Loss: 24.4724 (Forecasting Loss:0.3961 + XiCon Loss:2.4076 x Lambda(10.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5133
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 25.2293415
	speed: 0.0149s/iter; left time: 536.1678s
	iters: 200, epoch: 27 | loss: 25.9794159
	speed: 0.0131s/iter; left time: 467.9319s
	iters: 300, epoch: 27 | loss: 24.6931667
	speed: 0.0138s/iter; left time: 493.6622s
	iters: 400, epoch: 27 | loss: 23.8169270
	speed: 0.0136s/iter; left time: 483.6316s
Epoch: 27 cost time: 6.776611804962158
Epoch: 27, Steps: 487 Train Loss: 24.4725 (Forecasting Loss:0.3962 + XiCon Loss:2.4076 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 23.0113144
	speed: 0.0157s/iter; left time: 555.5883s
	iters: 200, epoch: 28 | loss: 24.6414318
	speed: 0.0139s/iter; left time: 492.0847s
	iters: 300, epoch: 28 | loss: 25.2590942
	speed: 0.0142s/iter; left time: 499.0768s
	iters: 400, epoch: 28 | loss: 26.0658875
	speed: 0.0135s/iter; left time: 476.2597s
Epoch: 28 cost time: 6.955845594406128
Epoch: 28, Steps: 487 Train Loss: 24.4641 (Forecasting Loss:0.3964 + XiCon Loss:2.4068 x Lambda(10.0)), Vali MSE Loss: 0.7360 Test MSE Loss: 0.5133
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 24.4010201
	speed: 0.0159s/iter; left time: 555.8105s
	iters: 200, epoch: 29 | loss: 24.3165932
	speed: 0.0148s/iter; left time: 516.6622s
	iters: 300, epoch: 29 | loss: 24.1478748
	speed: 0.0141s/iter; left time: 491.3390s
	iters: 400, epoch: 29 | loss: 24.7314262
	speed: 0.0134s/iter; left time: 464.5888s
Epoch: 29 cost time: 7.0345542430877686
Epoch: 29, Steps: 487 Train Loss: 24.4828 (Forecasting Loss:0.3964 + XiCon Loss:2.4086 x Lambda(10.0)), Vali MSE Loss: 0.7363 Test MSE Loss: 0.5133
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 25.1533089
	speed: 0.0155s/iter; left time: 532.8815s
	iters: 200, epoch: 30 | loss: 24.1175117
	speed: 0.0138s/iter; left time: 476.0573s
	iters: 300, epoch: 30 | loss: 23.6615028
	speed: 0.0135s/iter; left time: 462.0583s
	iters: 400, epoch: 30 | loss: 25.5310154
	speed: 0.0145s/iter; left time: 495.3290s
Epoch: 30 cost time: 6.945696115493774
Epoch: 30, Steps: 487 Train Loss: 24.5148 (Forecasting Loss:0.3960 + XiCon Loss:2.4119 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 24.8518562
	speed: 0.0160s/iter; left time: 544.2103s
	iters: 200, epoch: 31 | loss: 23.6524773
	speed: 0.0133s/iter; left time: 451.1620s
	iters: 300, epoch: 31 | loss: 24.3258095
	speed: 0.0138s/iter; left time: 464.8356s
	iters: 400, epoch: 31 | loss: 25.0333252
	speed: 0.0138s/iter; left time: 465.6950s
Epoch: 31 cost time: 7.039590835571289
Epoch: 31, Steps: 487 Train Loss: 24.5144 (Forecasting Loss:0.3961 + XiCon Loss:2.4118 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 22.7031002
	speed: 0.0156s/iter; left time: 522.9933s
	iters: 200, epoch: 32 | loss: 25.0102921
	speed: 0.0131s/iter; left time: 436.9500s
	iters: 300, epoch: 32 | loss: 24.7575550
	speed: 0.0131s/iter; left time: 435.8531s
	iters: 400, epoch: 32 | loss: 25.4864578
	speed: 0.0134s/iter; left time: 446.5705s
Epoch: 32 cost time: 6.726075172424316
Epoch: 32, Steps: 487 Train Loss: 24.5274 (Forecasting Loss:0.3962 + XiCon Loss:2.4131 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 24.6535225
	speed: 0.0150s/iter; left time: 495.6168s
	iters: 200, epoch: 33 | loss: 23.7726097
	speed: 0.0133s/iter; left time: 436.8370s
	iters: 300, epoch: 33 | loss: 24.7614269
	speed: 0.0140s/iter; left time: 458.3401s
	iters: 400, epoch: 33 | loss: 24.6069260
	speed: 0.0132s/iter; left time: 430.3847s
Epoch: 33 cost time: 6.745215654373169
Epoch: 33, Steps: 487 Train Loss: 24.4718 (Forecasting Loss:0.3963 + XiCon Loss:2.4075 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 24.1231518
	speed: 0.0163s/iter; left time: 531.4628s
	iters: 200, epoch: 34 | loss: 23.7471046
	speed: 0.0152s/iter; left time: 491.4780s
	iters: 300, epoch: 34 | loss: 24.7287807
	speed: 0.0148s/iter; left time: 479.8436s
	iters: 400, epoch: 34 | loss: 25.1144028
	speed: 0.0139s/iter; left time: 448.0676s
Epoch: 34 cost time: 7.324740171432495
Epoch: 34, Steps: 487 Train Loss: 24.4847 (Forecasting Loss:0.3961 + XiCon Loss:2.4089 x Lambda(10.0)), Vali MSE Loss: 0.7355 Test MSE Loss: 0.5133
Validation loss decreased (0.735840 --> 0.735524).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 25.0519218
	speed: 0.0150s/iter; left time: 479.5843s
	iters: 200, epoch: 35 | loss: 23.3938065
	speed: 0.0140s/iter; left time: 446.2280s
	iters: 300, epoch: 35 | loss: 25.4909019
	speed: 0.0138s/iter; left time: 438.9232s
	iters: 400, epoch: 35 | loss: 23.9164371
	speed: 0.0144s/iter; left time: 456.4633s
Epoch: 35 cost time: 6.937290906906128
Epoch: 35, Steps: 487 Train Loss: 24.5337 (Forecasting Loss:0.3961 + XiCon Loss:2.4138 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 24.8399143
	speed: 0.0156s/iter; left time: 492.4754s
	iters: 200, epoch: 36 | loss: 24.9816093
	speed: 0.0137s/iter; left time: 431.8470s
	iters: 300, epoch: 36 | loss: 24.3539333
	speed: 0.0135s/iter; left time: 423.0075s
	iters: 400, epoch: 36 | loss: 23.6022053
	speed: 0.0136s/iter; left time: 423.6968s
Epoch: 36 cost time: 6.9076409339904785
Epoch: 36, Steps: 487 Train Loss: 24.4856 (Forecasting Loss:0.3960 + XiCon Loss:2.4090 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 25.4305744
	speed: 0.0153s/iter; left time: 476.4085s
	iters: 200, epoch: 37 | loss: 25.7049103
	speed: 0.0133s/iter; left time: 411.9550s
	iters: 300, epoch: 37 | loss: 24.1617355
	speed: 0.0139s/iter; left time: 428.6844s
	iters: 400, epoch: 37 | loss: 23.9922085
	speed: 0.0135s/iter; left time: 416.1812s
Epoch: 37 cost time: 6.8447654247283936
Epoch: 37, Steps: 487 Train Loss: 24.4939 (Forecasting Loss:0.3961 + XiCon Loss:2.4098 x Lambda(10.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5133
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 24.1644821
	speed: 0.0152s/iter; left time: 465.0210s
	iters: 200, epoch: 38 | loss: 25.2925491
	speed: 0.0119s/iter; left time: 362.3825s
	iters: 300, epoch: 38 | loss: 24.3441944
	speed: 0.0113s/iter; left time: 343.9552s
	iters: 400, epoch: 38 | loss: 25.2995243
	speed: 0.0110s/iter; left time: 333.0844s
Epoch: 38 cost time: 5.965412855148315
Epoch: 38, Steps: 487 Train Loss: 24.5275 (Forecasting Loss:0.3962 + XiCon Loss:2.4131 x Lambda(10.0)), Vali MSE Loss: 0.7367 Test MSE Loss: 0.5133
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 24.0489120
	speed: 0.0153s/iter; left time: 459.5950s
	iters: 200, epoch: 39 | loss: 24.7196674
	speed: 0.0135s/iter; left time: 406.0059s
	iters: 300, epoch: 39 | loss: 25.0316391
	speed: 0.0138s/iter; left time: 413.6286s
	iters: 400, epoch: 39 | loss: 24.1812305
	speed: 0.0142s/iter; left time: 424.1132s
Epoch: 39 cost time: 6.886844873428345
Epoch: 39, Steps: 487 Train Loss: 24.4995 (Forecasting Loss:0.3963 + XiCon Loss:2.4103 x Lambda(10.0)), Vali MSE Loss: 0.7363 Test MSE Loss: 0.5133
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 25.1975002
	speed: 0.0151s/iter; left time: 445.9237s
	iters: 200, epoch: 40 | loss: 24.5659561
	speed: 0.0131s/iter; left time: 386.6449s
	iters: 300, epoch: 40 | loss: 25.3722839
	speed: 0.0111s/iter; left time: 326.9389s
	iters: 400, epoch: 40 | loss: 25.1038513
	speed: 0.0118s/iter; left time: 346.9688s
Epoch: 40 cost time: 6.17108154296875
Epoch: 40, Steps: 487 Train Loss: 24.4660 (Forecasting Loss:0.3963 + XiCon Loss:2.4070 x Lambda(10.0)), Vali MSE Loss: 0.7364 Test MSE Loss: 0.5133
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 24.8394814
	speed: 0.0160s/iter; left time: 465.5180s
	iters: 200, epoch: 41 | loss: 23.7029896
	speed: 0.0133s/iter; left time: 386.0274s
	iters: 300, epoch: 41 | loss: 24.8375912
	speed: 0.0135s/iter; left time: 391.5681s
	iters: 400, epoch: 41 | loss: 23.5904121
	speed: 0.0137s/iter; left time: 395.5068s
Epoch: 41 cost time: 6.897330045700073
Epoch: 41, Steps: 487 Train Loss: 24.4696 (Forecasting Loss:0.3962 + XiCon Loss:2.4073 x Lambda(10.0)), Vali MSE Loss: 0.7363 Test MSE Loss: 0.5133
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 24.9035892
	speed: 0.0156s/iter; left time: 445.4321s
	iters: 200, epoch: 42 | loss: 22.9352188
	speed: 0.0139s/iter; left time: 397.5095s
	iters: 300, epoch: 42 | loss: 24.2750874
	speed: 0.0139s/iter; left time: 396.1644s
	iters: 400, epoch: 42 | loss: 25.5555115
	speed: 0.0131s/iter; left time: 371.1947s
Epoch: 42 cost time: 6.871576309204102
Epoch: 42, Steps: 487 Train Loss: 24.4944 (Forecasting Loss:0.3963 + XiCon Loss:2.4098 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 25.5784473
	speed: 0.0159s/iter; left time: 446.1976s
	iters: 200, epoch: 43 | loss: 24.7551689
	speed: 0.0140s/iter; left time: 392.4678s
	iters: 300, epoch: 43 | loss: 24.0725346
	speed: 0.0142s/iter; left time: 396.6423s
	iters: 400, epoch: 43 | loss: 25.1840439
	speed: 0.0139s/iter; left time: 387.8559s
Epoch: 43 cost time: 6.993022203445435
Epoch: 43, Steps: 487 Train Loss: 24.5432 (Forecasting Loss:0.3964 + XiCon Loss:2.4147 x Lambda(10.0)), Vali MSE Loss: 0.7366 Test MSE Loss: 0.5133
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 24.2142906
	speed: 0.0157s/iter; left time: 433.2558s
	iters: 200, epoch: 44 | loss: 24.8010120
	speed: 0.0137s/iter; left time: 376.5948s
	iters: 300, epoch: 44 | loss: 24.0199318
	speed: 0.0137s/iter; left time: 377.4932s
	iters: 400, epoch: 44 | loss: 24.4633160
	speed: 0.0144s/iter; left time: 394.7136s
Epoch: 44 cost time: 7.090911626815796
Epoch: 44, Steps: 487 Train Loss: 24.4898 (Forecasting Loss:0.3960 + XiCon Loss:2.4094 x Lambda(10.0)), Vali MSE Loss: 0.7365 Test MSE Loss: 0.5133
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5205524563789368, mae:0.5059927701950073, mape:3.46221661567688, mspe:1075.0506591796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5197+-0.00800, MAE:0.5069+-0.00376, MAPE:3.5627+-0.13323, MSPE:1177.2572+-108.64637, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7618
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 27.4756050
	speed: 0.0299s/iter; left time: 708.4082s
	iters: 200, epoch: 1 | loss: 26.8821583
	speed: 0.0243s/iter; left time: 573.9984s
Epoch: 1 cost time: 6.394763708114624
Epoch: 1, Steps: 238 Train Loss: 26.8413 (Forecasting Loss:0.9803 + XiCon Loss:2.5861 x Lambda(10.0)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755402).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 26.2274227
	speed: 0.0276s/iter; left time: 646.6001s
	iters: 200, epoch: 2 | loss: 26.5350952
	speed: 0.0242s/iter; left time: 565.3677s
Epoch: 2 cost time: 6.172575950622559
Epoch: 2, Steps: 238 Train Loss: 26.4154 (Forecasting Loss:0.6170 + XiCon Loss:2.5798 x Lambda(10.0)), Vali MSE Loss: 1.0370 Test MSE Loss: 0.8577
Validation loss decreased (1.755402 --> 1.037015).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 26.4515953
	speed: 0.0252s/iter; left time: 586.4265s
	iters: 200, epoch: 3 | loss: 26.5528908
	speed: 0.0254s/iter; left time: 588.2615s
Epoch: 3 cost time: 6.009686470031738
Epoch: 3, Steps: 238 Train Loss: 26.3098 (Forecasting Loss:0.5527 + XiCon Loss:2.5757 x Lambda(10.0)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8511
Validation loss decreased (1.037015 --> 1.018104).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.5495472
	speed: 0.0269s/iter; left time: 619.3950s
	iters: 200, epoch: 4 | loss: 26.0911160
	speed: 0.0249s/iter; left time: 570.6373s
Epoch: 4 cost time: 6.151392459869385
Epoch: 4, Steps: 238 Train Loss: 26.2338 (Forecasting Loss:0.5446 + XiCon Loss:2.5689 x Lambda(10.0)), Vali MSE Loss: 1.0107 Test MSE Loss: 0.8490
Validation loss decreased (1.018104 --> 1.010724).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.5314560
	speed: 0.0262s/iter; left time: 595.4289s
	iters: 200, epoch: 5 | loss: 25.9144516
	speed: 0.0247s/iter; left time: 559.9015s
Epoch: 5 cost time: 6.086357355117798
Epoch: 5, Steps: 238 Train Loss: 26.2339 (Forecasting Loss:0.5414 + XiCon Loss:2.5692 x Lambda(10.0)), Vali MSE Loss: 1.0077 Test MSE Loss: 0.8488
Validation loss decreased (1.010724 --> 1.007735).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 26.5858669
	speed: 0.0261s/iter; left time: 586.9955s
	iters: 200, epoch: 6 | loss: 25.9117908
	speed: 0.0244s/iter; left time: 547.2064s
Epoch: 6 cost time: 5.921692371368408
Epoch: 6, Steps: 238 Train Loss: 26.1857 (Forecasting Loss:0.5400 + XiCon Loss:2.5646 x Lambda(10.0)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8485
Validation loss decreased (1.007735 --> 1.006422).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.9778366
	speed: 0.0265s/iter; left time: 591.2487s
	iters: 200, epoch: 7 | loss: 26.3950958
	speed: 0.0239s/iter; left time: 529.3206s
Epoch: 7 cost time: 6.021129369735718
Epoch: 7, Steps: 238 Train Loss: 26.2290 (Forecasting Loss:0.5392 + XiCon Loss:2.5690 x Lambda(10.0)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8484
Validation loss decreased (1.006422 --> 1.004736).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 26.2985115
	speed: 0.0248s/iter; left time: 546.7002s
	iters: 200, epoch: 8 | loss: 25.8545570
	speed: 0.0246s/iter; left time: 540.2874s
Epoch: 8 cost time: 5.830246925354004
Epoch: 8, Steps: 238 Train Loss: 26.1736 (Forecasting Loss:0.5387 + XiCon Loss:2.5635 x Lambda(10.0)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8483
Validation loss decreased (1.004736 --> 1.004669).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.5923195
	speed: 0.0270s/iter; left time: 589.2097s
	iters: 200, epoch: 9 | loss: 25.4323597
	speed: 0.0239s/iter; left time: 519.3597s
Epoch: 9 cost time: 6.067603826522827
Epoch: 9, Steps: 238 Train Loss: 26.2192 (Forecasting Loss:0.5387 + XiCon Loss:2.5681 x Lambda(10.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 26.5780220
	speed: 0.0265s/iter; left time: 571.0105s
	iters: 200, epoch: 10 | loss: 26.1510601
	speed: 0.0241s/iter; left time: 516.4541s
Epoch: 10 cost time: 6.14219856262207
Epoch: 10, Steps: 238 Train Loss: 26.2434 (Forecasting Loss:0.5385 + XiCon Loss:2.5705 x Lambda(10.0)), Vali MSE Loss: 1.0046 Test MSE Loss: 0.8483
Validation loss decreased (1.004669 --> 1.004621).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 26.3825207
	speed: 0.0249s/iter; left time: 531.5371s
	iters: 200, epoch: 11 | loss: 26.4130650
	speed: 0.0238s/iter; left time: 505.8947s
Epoch: 11 cost time: 5.843348979949951
Epoch: 11, Steps: 238 Train Loss: 26.1891 (Forecasting Loss:0.5382 + XiCon Loss:2.5651 x Lambda(10.0)), Vali MSE Loss: 1.0038 Test MSE Loss: 0.8483
Validation loss decreased (1.004621 --> 1.003837).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.0157452
	speed: 0.0252s/iter; left time: 532.2935s
	iters: 200, epoch: 12 | loss: 26.0468559
	speed: 0.0233s/iter; left time: 487.8563s
Epoch: 12 cost time: 5.763105630874634
Epoch: 12, Steps: 238 Train Loss: 26.2080 (Forecasting Loss:0.5383 + XiCon Loss:2.5670 x Lambda(10.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.3992062
	speed: 0.0259s/iter; left time: 540.5354s
	iters: 200, epoch: 13 | loss: 26.2561340
	speed: 0.0236s/iter; left time: 489.5051s
Epoch: 13 cost time: 5.858186721801758
Epoch: 13, Steps: 238 Train Loss: 26.2044 (Forecasting Loss:0.5383 + XiCon Loss:2.5666 x Lambda(10.0)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8483
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 26.3101807
	speed: 0.0256s/iter; left time: 528.1426s
	iters: 200, epoch: 14 | loss: 26.6656322
	speed: 0.0230s/iter; left time: 471.2242s
Epoch: 14 cost time: 5.776284217834473
Epoch: 14, Steps: 238 Train Loss: 26.1725 (Forecasting Loss:0.5382 + XiCon Loss:2.5634 x Lambda(10.0)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8483
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 26.1540947
	speed: 0.0251s/iter; left time: 510.8724s
	iters: 200, epoch: 15 | loss: 25.6149826
	speed: 0.0237s/iter; left time: 480.3760s
Epoch: 15 cost time: 5.815521478652954
Epoch: 15, Steps: 238 Train Loss: 26.1412 (Forecasting Loss:0.5382 + XiCon Loss:2.5603 x Lambda(10.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 26.6431179
	speed: 0.0247s/iter; left time: 497.8211s
	iters: 200, epoch: 16 | loss: 26.4278927
	speed: 0.0240s/iter; left time: 480.1691s
Epoch: 16 cost time: 5.842675685882568
Epoch: 16, Steps: 238 Train Loss: 26.1642 (Forecasting Loss:0.5385 + XiCon Loss:2.5626 x Lambda(10.0)), Vali MSE Loss: 1.0046 Test MSE Loss: 0.8483
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 25.9935265
	speed: 0.0252s/iter; left time: 501.8974s
	iters: 200, epoch: 17 | loss: 25.4919815
	speed: 0.0235s/iter; left time: 464.1604s
Epoch: 17 cost time: 5.803479433059692
Epoch: 17, Steps: 238 Train Loss: 26.2451 (Forecasting Loss:0.5380 + XiCon Loss:2.5707 x Lambda(10.0)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8483
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 25.8894730
	speed: 0.0266s/iter; left time: 522.6266s
	iters: 200, epoch: 18 | loss: 26.1542950
	speed: 0.0233s/iter; left time: 455.8352s
Epoch: 18 cost time: 5.922420501708984
Epoch: 18, Steps: 238 Train Loss: 26.1855 (Forecasting Loss:0.5382 + XiCon Loss:2.5647 x Lambda(10.0)), Vali MSE Loss: 1.0051 Test MSE Loss: 0.8483
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.5453568
	speed: 0.0264s/iter; left time: 512.0580s
	iters: 200, epoch: 19 | loss: 26.5062008
	speed: 0.0240s/iter; left time: 463.1217s
Epoch: 19 cost time: 5.978424310684204
Epoch: 19, Steps: 238 Train Loss: 26.1834 (Forecasting Loss:0.5384 + XiCon Loss:2.5645 x Lambda(10.0)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 26.1591778
	speed: 0.0270s/iter; left time: 517.0030s
	iters: 200, epoch: 20 | loss: 26.0980091
	speed: 0.0242s/iter; left time: 462.3471s
Epoch: 20 cost time: 6.057058334350586
Epoch: 20, Steps: 238 Train Loss: 26.2344 (Forecasting Loss:0.5381 + XiCon Loss:2.5696 x Lambda(10.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 26.6303673
	speed: 0.0267s/iter; left time: 505.9307s
	iters: 200, epoch: 21 | loss: 25.9218369
	speed: 0.0236s/iter; left time: 444.2911s
Epoch: 21 cost time: 6.011230707168579
Epoch: 21, Steps: 238 Train Loss: 26.2043 (Forecasting Loss:0.5384 + XiCon Loss:2.5666 x Lambda(10.0)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9774137139320374, mae:0.7191471457481384, mape:4.775559425354004, mspe:2685.9794921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5776
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 26.1568184
	speed: 0.0284s/iter; left time: 672.3023s
	iters: 200, epoch: 1 | loss: 26.5171089
	speed: 0.0272s/iter; left time: 642.1681s
Epoch: 1 cost time: 6.663841724395752
Epoch: 1, Steps: 238 Train Loss: 26.8662 (Forecasting Loss:1.0993 + XiCon Loss:2.5767 x Lambda(10.0)), Vali MSE Loss: 1.9684 Test MSE Loss: 1.0363
Validation loss decreased (inf --> 1.968407).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 26.2812538
	speed: 0.0284s/iter; left time: 667.1479s
	iters: 200, epoch: 2 | loss: 25.8996696
	speed: 0.0280s/iter; left time: 655.0381s
Epoch: 2 cost time: 6.7796406745910645
Epoch: 2, Steps: 238 Train Loss: 26.2546 (Forecasting Loss:0.6362 + XiCon Loss:2.5618 x Lambda(10.0)), Vali MSE Loss: 1.0203 Test MSE Loss: 0.8596
Validation loss decreased (1.968407 --> 1.020292).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 26.3566208
	speed: 0.0282s/iter; left time: 655.4975s
	iters: 200, epoch: 3 | loss: 26.3341980
	speed: 0.0275s/iter; left time: 636.8277s
Epoch: 3 cost time: 6.72403883934021
Epoch: 3, Steps: 238 Train Loss: 26.0623 (Forecasting Loss:0.5528 + XiCon Loss:2.5510 x Lambda(10.0)), Vali MSE Loss: 0.9989 Test MSE Loss: 0.8536
Validation loss decreased (1.020292 --> 0.998898).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 26.2239552
	speed: 0.0279s/iter; left time: 642.4131s
	iters: 200, epoch: 4 | loss: 26.8894882
	speed: 0.0273s/iter; left time: 624.8825s
Epoch: 4 cost time: 6.640295743942261
Epoch: 4, Steps: 238 Train Loss: 26.0391 (Forecasting Loss:0.5443 + XiCon Loss:2.5495 x Lambda(10.0)), Vali MSE Loss: 0.9929 Test MSE Loss: 0.8523
Validation loss decreased (0.998898 --> 0.992850).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 25.4990253
	speed: 0.0289s/iter; left time: 656.7533s
	iters: 200, epoch: 5 | loss: 25.9018726
	speed: 0.0283s/iter; left time: 641.6095s
Epoch: 5 cost time: 6.759917497634888
Epoch: 5, Steps: 238 Train Loss: 25.9809 (Forecasting Loss:0.5410 + XiCon Loss:2.5440 x Lambda(10.0)), Vali MSE Loss: 0.9881 Test MSE Loss: 0.8515
Validation loss decreased (0.992850 --> 0.988148).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 25.7638359
	speed: 0.0274s/iter; left time: 617.8845s
	iters: 200, epoch: 6 | loss: 26.7232895
	speed: 0.0292s/iter; left time: 653.6975s
Epoch: 6 cost time: 6.708162307739258
Epoch: 6, Steps: 238 Train Loss: 26.0052 (Forecasting Loss:0.5397 + XiCon Loss:2.5465 x Lambda(10.0)), Vali MSE Loss: 0.9869 Test MSE Loss: 0.8515
Validation loss decreased (0.988148 --> 0.986942).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 26.0861359
	speed: 0.0277s/iter; left time: 616.9361s
	iters: 200, epoch: 7 | loss: 25.5840378
	speed: 0.0280s/iter; left time: 621.7683s
Epoch: 7 cost time: 6.688197374343872
Epoch: 7, Steps: 238 Train Loss: 25.9677 (Forecasting Loss:0.5387 + XiCon Loss:2.5429 x Lambda(10.0)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8513
Validation loss decreased (0.986942 --> 0.986005).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 26.5513172
	speed: 0.0273s/iter; left time: 602.6116s
	iters: 200, epoch: 8 | loss: 25.6705875
	speed: 0.0284s/iter; left time: 623.1049s
Epoch: 8 cost time: 6.6772239208221436
Epoch: 8, Steps: 238 Train Loss: 25.9721 (Forecasting Loss:0.5386 + XiCon Loss:2.5433 x Lambda(10.0)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8513
Validation loss decreased (0.986005 --> 0.985997).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.2722244
	speed: 0.0279s/iter; left time: 608.8697s
	iters: 200, epoch: 9 | loss: 26.0857048
	speed: 0.0290s/iter; left time: 628.2697s
Epoch: 9 cost time: 6.827562093734741
Epoch: 9, Steps: 238 Train Loss: 25.9863 (Forecasting Loss:0.5383 + XiCon Loss:2.5448 x Lambda(10.0)), Vali MSE Loss: 0.9850 Test MSE Loss: 0.8512
Validation loss decreased (0.985997 --> 0.984951).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 25.8984051
	speed: 0.0289s/iter; left time: 623.8058s
	iters: 200, epoch: 10 | loss: 26.3495731
	speed: 0.0279s/iter; left time: 599.0156s
Epoch: 10 cost time: 6.794091463088989
Epoch: 10, Steps: 238 Train Loss: 25.9694 (Forecasting Loss:0.5381 + XiCon Loss:2.5431 x Lambda(10.0)), Vali MSE Loss: 0.9845 Test MSE Loss: 0.8512
Validation loss decreased (0.984951 --> 0.984536).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 26.4797783
	speed: 0.0288s/iter; left time: 613.1853s
	iters: 200, epoch: 11 | loss: 27.1365814
	speed: 0.0287s/iter; left time: 608.9746s
Epoch: 11 cost time: 6.843515634536743
Epoch: 11, Steps: 238 Train Loss: 25.9619 (Forecasting Loss:0.5381 + XiCon Loss:2.5424 x Lambda(10.0)), Vali MSE Loss: 0.9852 Test MSE Loss: 0.8512
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.3611698
	speed: 0.0276s/iter; left time: 581.5699s
	iters: 200, epoch: 12 | loss: 25.9513550
	speed: 0.0278s/iter; left time: 582.7836s
Epoch: 12 cost time: 6.616757392883301
Epoch: 12, Steps: 238 Train Loss: 25.9538 (Forecasting Loss:0.5379 + XiCon Loss:2.5416 x Lambda(10.0)), Vali MSE Loss: 0.9848 Test MSE Loss: 0.8512
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.3854580
	speed: 0.0264s/iter; left time: 549.3892s
	iters: 200, epoch: 13 | loss: 25.9489784
	speed: 0.0250s/iter; left time: 518.8876s
Epoch: 13 cost time: 6.097131013870239
Epoch: 13, Steps: 238 Train Loss: 25.9906 (Forecasting Loss:0.5378 + XiCon Loss:2.5453 x Lambda(10.0)), Vali MSE Loss: 0.9855 Test MSE Loss: 0.8512
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 25.8976479
	speed: 0.0277s/iter; left time: 570.4829s
	iters: 200, epoch: 14 | loss: 25.6727562
	speed: 0.0279s/iter; left time: 572.4693s
Epoch: 14 cost time: 6.67770791053772
Epoch: 14, Steps: 238 Train Loss: 26.0164 (Forecasting Loss:0.5380 + XiCon Loss:2.5478 x Lambda(10.0)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8512
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 26.2013664
	speed: 0.0288s/iter; left time: 585.9710s
	iters: 200, epoch: 15 | loss: 26.5252113
	speed: 0.0284s/iter; left time: 575.0885s
Epoch: 15 cost time: 6.800218105316162
Epoch: 15, Steps: 238 Train Loss: 25.9979 (Forecasting Loss:0.5378 + XiCon Loss:2.5460 x Lambda(10.0)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8512
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 26.0308037
	speed: 0.0261s/iter; left time: 526.1156s
	iters: 200, epoch: 16 | loss: 26.3170795
	speed: 0.0254s/iter; left time: 509.4149s
Epoch: 16 cost time: 6.093351602554321
Epoch: 16, Steps: 238 Train Loss: 25.9954 (Forecasting Loss:0.5380 + XiCon Loss:2.5457 x Lambda(10.0)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8512
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 25.4171410
	speed: 0.0292s/iter; left time: 580.3800s
	iters: 200, epoch: 17 | loss: 26.1210823
	speed: 0.0285s/iter; left time: 564.4537s
Epoch: 17 cost time: 6.883416652679443
Epoch: 17, Steps: 238 Train Loss: 25.9362 (Forecasting Loss:0.5381 + XiCon Loss:2.5398 x Lambda(10.0)), Vali MSE Loss: 0.9848 Test MSE Loss: 0.8512
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 25.4046040
	speed: 0.0293s/iter; left time: 575.0846s
	iters: 200, epoch: 18 | loss: 27.2607479
	speed: 0.0289s/iter; left time: 564.7276s
Epoch: 18 cost time: 6.905813932418823
Epoch: 18, Steps: 238 Train Loss: 25.9557 (Forecasting Loss:0.5383 + XiCon Loss:2.5417 x Lambda(10.0)), Vali MSE Loss: 0.9847 Test MSE Loss: 0.8512
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.3090630
	speed: 0.0274s/iter; left time: 532.2276s
	iters: 200, epoch: 19 | loss: 25.7892265
	speed: 0.0280s/iter; left time: 541.1432s
Epoch: 19 cost time: 6.652263641357422
Epoch: 19, Steps: 238 Train Loss: 26.0164 (Forecasting Loss:0.5380 + XiCon Loss:2.5478 x Lambda(10.0)), Vali MSE Loss: 0.9849 Test MSE Loss: 0.8512
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 25.9705524
	speed: 0.0287s/iter; left time: 549.4867s
	iters: 200, epoch: 20 | loss: 25.6227818
	speed: 0.0276s/iter; left time: 526.5986s
Epoch: 20 cost time: 6.7120490074157715
Epoch: 20, Steps: 238 Train Loss: 25.9810 (Forecasting Loss:0.5381 + XiCon Loss:2.5443 x Lambda(10.0)), Vali MSE Loss: 0.9846 Test MSE Loss: 0.8512
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9807949066162109, mae:0.7216193675994873, mape:4.749374866485596, mspe:2637.8427734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5491
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 27.1266670
	speed: 0.0264s/iter; left time: 626.1615s
	iters: 200, epoch: 1 | loss: 26.2665691
	speed: 0.0247s/iter; left time: 582.4469s
Epoch: 1 cost time: 6.019582271575928
Epoch: 1, Steps: 238 Train Loss: 26.8110 (Forecasting Loss:1.0009 + XiCon Loss:2.5810 x Lambda(10.0)), Vali MSE Loss: 1.7925 Test MSE Loss: 0.9697
Validation loss decreased (inf --> 1.792505).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 26.0120296
	speed: 0.0271s/iter; left time: 635.6530s
	iters: 200, epoch: 2 | loss: 25.7959042
	speed: 0.0241s/iter; left time: 562.5060s
Epoch: 2 cost time: 6.048931837081909
Epoch: 2, Steps: 238 Train Loss: 26.4356 (Forecasting Loss:0.6191 + XiCon Loss:2.5817 x Lambda(10.0)), Vali MSE Loss: 1.0417 Test MSE Loss: 0.8611
Validation loss decreased (1.792505 --> 1.041710).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 25.6742020
	speed: 0.0260s/iter; left time: 604.7543s
	iters: 200, epoch: 3 | loss: 26.4858303
	speed: 0.0238s/iter; left time: 550.9242s
Epoch: 3 cost time: 5.9478020668029785
Epoch: 3, Steps: 238 Train Loss: 26.1804 (Forecasting Loss:0.5526 + XiCon Loss:2.5628 x Lambda(10.0)), Vali MSE Loss: 1.0196 Test MSE Loss: 0.8554
Validation loss decreased (1.041710 --> 1.019638).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.8767357
	speed: 0.0251s/iter; left time: 577.2088s
	iters: 200, epoch: 4 | loss: 25.9921207
	speed: 0.0243s/iter; left time: 555.2382s
Epoch: 4 cost time: 5.837695360183716
Epoch: 4, Steps: 238 Train Loss: 26.2060 (Forecasting Loss:0.5443 + XiCon Loss:2.5662 x Lambda(10.0)), Vali MSE Loss: 1.0138 Test MSE Loss: 0.8539
Validation loss decreased (1.019638 --> 1.013779).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 25.8756809
	speed: 0.0262s/iter; left time: 596.4256s
	iters: 200, epoch: 5 | loss: 26.4626656
	speed: 0.0242s/iter; left time: 548.7573s
Epoch: 5 cost time: 6.01069450378418
Epoch: 5, Steps: 238 Train Loss: 26.1953 (Forecasting Loss:0.5407 + XiCon Loss:2.5655 x Lambda(10.0)), Vali MSE Loss: 1.0105 Test MSE Loss: 0.8534
Validation loss decreased (1.013779 --> 1.010465).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 26.7561283
	speed: 0.0270s/iter; left time: 607.7609s
	iters: 200, epoch: 6 | loss: 26.1819077
	speed: 0.0245s/iter; left time: 549.6923s
Epoch: 6 cost time: 6.079456329345703
Epoch: 6, Steps: 238 Train Loss: 26.1310 (Forecasting Loss:0.5395 + XiCon Loss:2.5591 x Lambda(10.0)), Vali MSE Loss: 1.0090 Test MSE Loss: 0.8531
Validation loss decreased (1.010465 --> 1.008966).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.9580441
	speed: 0.0260s/iter; left time: 579.7191s
	iters: 200, epoch: 7 | loss: 26.0094433
	speed: 0.0239s/iter; left time: 530.4800s
Epoch: 7 cost time: 5.961974859237671
Epoch: 7, Steps: 238 Train Loss: 26.1490 (Forecasting Loss:0.5387 + XiCon Loss:2.5610 x Lambda(10.0)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8530
Validation loss decreased (1.008966 --> 1.007934).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 25.9090633
	speed: 0.0279s/iter; left time: 613.9863s
	iters: 200, epoch: 8 | loss: 26.6398964
	speed: 0.0242s/iter; left time: 530.1222s
Epoch: 8 cost time: 6.2485809326171875
Epoch: 8, Steps: 238 Train Loss: 26.1888 (Forecasting Loss:0.5383 + XiCon Loss:2.5651 x Lambda(10.0)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8530
Validation loss decreased (1.007934 --> 1.007611).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.0534992
	speed: 0.0258s/iter; left time: 562.2716s
	iters: 200, epoch: 9 | loss: 25.8622437
	speed: 0.0240s/iter; left time: 520.0150s
Epoch: 9 cost time: 5.946648120880127
Epoch: 9, Steps: 238 Train Loss: 26.1700 (Forecasting Loss:0.5380 + XiCon Loss:2.5632 x Lambda(10.0)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8529
Validation loss decreased (1.007611 --> 1.007025).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 25.4680309
	speed: 0.0265s/iter; left time: 570.3310s
	iters: 200, epoch: 10 | loss: 25.4091377
	speed: 0.0242s/iter; left time: 519.7010s
Epoch: 10 cost time: 6.0573766231536865
Epoch: 10, Steps: 238 Train Loss: 26.1623 (Forecasting Loss:0.5379 + XiCon Loss:2.5624 x Lambda(10.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8529
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 26.1027069
	speed: 0.0260s/iter; left time: 555.3732s
	iters: 200, epoch: 11 | loss: 25.9143028
	speed: 0.0238s/iter; left time: 505.5236s
Epoch: 11 cost time: 5.963716268539429
Epoch: 11, Steps: 238 Train Loss: 26.1702 (Forecasting Loss:0.5379 + XiCon Loss:2.5632 x Lambda(10.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8529
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.2644558
	speed: 0.0249s/iter; left time: 524.2719s
	iters: 200, epoch: 12 | loss: 25.9361210
	speed: 0.0236s/iter; left time: 496.1751s
Epoch: 12 cost time: 5.776021718978882
Epoch: 12, Steps: 238 Train Loss: 26.1633 (Forecasting Loss:0.5376 + XiCon Loss:2.5626 x Lambda(10.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8529
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.7634964
	speed: 0.0268s/iter; left time: 557.6859s
	iters: 200, epoch: 13 | loss: 25.8600197
	speed: 0.0247s/iter; left time: 511.7311s
Epoch: 13 cost time: 6.115684509277344
Epoch: 13, Steps: 238 Train Loss: 26.1555 (Forecasting Loss:0.5378 + XiCon Loss:2.5618 x Lambda(10.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8529
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 25.9134636
	speed: 0.0261s/iter; left time: 538.7272s
	iters: 200, epoch: 14 | loss: 26.4456043
	speed: 0.0245s/iter; left time: 502.0708s
Epoch: 14 cost time: 6.006791830062866
Epoch: 14, Steps: 238 Train Loss: 26.1479 (Forecasting Loss:0.5379 + XiCon Loss:2.5610 x Lambda(10.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8529
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 26.5716553
	speed: 0.0260s/iter; left time: 530.3797s
	iters: 200, epoch: 15 | loss: 26.4723091
	speed: 0.0241s/iter; left time: 489.0869s
Epoch: 15 cost time: 5.982279300689697
Epoch: 15, Steps: 238 Train Loss: 26.1514 (Forecasting Loss:0.5380 + XiCon Loss:2.5613 x Lambda(10.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8529
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 25.5273037
	speed: 0.0263s/iter; left time: 529.2093s
	iters: 200, epoch: 16 | loss: 26.2239456
	speed: 0.0237s/iter; left time: 474.2606s
Epoch: 16 cost time: 6.000893831253052
Epoch: 16, Steps: 238 Train Loss: 26.1566 (Forecasting Loss:0.5378 + XiCon Loss:2.5619 x Lambda(10.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8529
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 26.5972290
	speed: 0.0247s/iter; left time: 491.5942s
	iters: 200, epoch: 17 | loss: 25.5760441
	speed: 0.0247s/iter; left time: 488.6396s
Epoch: 17 cost time: 5.850311994552612
Epoch: 17, Steps: 238 Train Loss: 26.1439 (Forecasting Loss:0.5378 + XiCon Loss:2.5606 x Lambda(10.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8529
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.0205021
	speed: 0.0277s/iter; left time: 544.5622s
	iters: 200, epoch: 18 | loss: 25.7621326
	speed: 0.0242s/iter; left time: 473.1659s
Epoch: 18 cost time: 6.106080532073975
Epoch: 18, Steps: 238 Train Loss: 26.1676 (Forecasting Loss:0.5377 + XiCon Loss:2.5630 x Lambda(10.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8529
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 25.7844429
	speed: 0.0268s/iter; left time: 520.5894s
	iters: 200, epoch: 19 | loss: 26.0205383
	speed: 0.0244s/iter; left time: 472.0874s
Epoch: 19 cost time: 6.094774007797241
Epoch: 19, Steps: 238 Train Loss: 26.1724 (Forecasting Loss:0.5377 + XiCon Loss:2.5635 x Lambda(10.0)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8529
Validation loss decreased (1.007025 --> 1.006949).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 25.9318829
	speed: 0.0259s/iter; left time: 496.4961s
	iters: 200, epoch: 20 | loss: 25.6142464
	speed: 0.0252s/iter; left time: 480.0293s
Epoch: 20 cost time: 6.0268166065216064
Epoch: 20, Steps: 238 Train Loss: 26.1137 (Forecasting Loss:0.5377 + XiCon Loss:2.5576 x Lambda(10.0)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8529
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 26.0450897
	speed: 0.0252s/iter; left time: 477.9959s
	iters: 200, epoch: 21 | loss: 26.0781097
	speed: 0.0232s/iter; left time: 436.2139s
Epoch: 21 cost time: 5.7723870277404785
Epoch: 21, Steps: 238 Train Loss: 26.1042 (Forecasting Loss:0.5378 + XiCon Loss:2.5566 x Lambda(10.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8529
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 26.7660751
	speed: 0.0259s/iter; left time: 484.1344s
	iters: 200, epoch: 22 | loss: 25.6075516
	speed: 0.0231s/iter; left time: 428.9890s
Epoch: 22 cost time: 5.834480285644531
Epoch: 22, Steps: 238 Train Loss: 26.0912 (Forecasting Loss:0.5378 + XiCon Loss:2.5553 x Lambda(10.0)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8529
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 26.3608894
	speed: 0.0258s/iter; left time: 476.3287s
	iters: 200, epoch: 23 | loss: 26.6421261
	speed: 0.0234s/iter; left time: 430.2938s
Epoch: 23 cost time: 5.870121479034424
Epoch: 23, Steps: 238 Train Loss: 26.1795 (Forecasting Loss:0.5378 + XiCon Loss:2.5642 x Lambda(10.0)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8529
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 26.1922035
	speed: 0.0251s/iter; left time: 457.0394s
	iters: 200, epoch: 24 | loss: 26.5192318
	speed: 0.0244s/iter; left time: 443.1750s
Epoch: 24 cost time: 5.892834424972534
Epoch: 24, Steps: 238 Train Loss: 26.1717 (Forecasting Loss:0.5379 + XiCon Loss:2.5634 x Lambda(10.0)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8529
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 26.2802658
	speed: 0.0261s/iter; left time: 469.9440s
	iters: 200, epoch: 25 | loss: 26.5309830
	speed: 0.0231s/iter; left time: 413.2991s
Epoch: 25 cost time: 5.8802268505096436
Epoch: 25, Steps: 238 Train Loss: 26.1335 (Forecasting Loss:0.5376 + XiCon Loss:2.5596 x Lambda(10.0)), Vali MSE Loss: 1.0083 Test MSE Loss: 0.8529
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 27.0063858
	speed: 0.0256s/iter; left time: 454.8630s
	iters: 200, epoch: 26 | loss: 26.1082859
	speed: 0.0236s/iter; left time: 416.9854s
Epoch: 26 cost time: 5.855486631393433
Epoch: 26, Steps: 238 Train Loss: 26.1464 (Forecasting Loss:0.5378 + XiCon Loss:2.5609 x Lambda(10.0)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8529
Validation loss decreased (1.006949 --> 1.006922).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 25.0377178
	speed: 0.0250s/iter; left time: 437.9856s
	iters: 200, epoch: 27 | loss: 26.8047428
	speed: 0.0227s/iter; left time: 395.6508s
Epoch: 27 cost time: 5.713542461395264
Epoch: 27, Steps: 238 Train Loss: 26.2042 (Forecasting Loss:0.5377 + XiCon Loss:2.5666 x Lambda(10.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8529
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 26.4077435
	speed: 0.0257s/iter; left time: 444.7951s
	iters: 200, epoch: 28 | loss: 26.0205517
	speed: 0.0235s/iter; left time: 403.1921s
Epoch: 28 cost time: 5.99865460395813
Epoch: 28, Steps: 238 Train Loss: 26.1291 (Forecasting Loss:0.5379 + XiCon Loss:2.5591 x Lambda(10.0)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8529
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 26.1500320
	speed: 0.0261s/iter; left time: 444.2135s
	iters: 200, epoch: 29 | loss: 26.0992031
	speed: 0.0234s/iter; left time: 396.3797s
Epoch: 29 cost time: 5.894901990890503
Epoch: 29, Steps: 238 Train Loss: 26.1671 (Forecasting Loss:0.5377 + XiCon Loss:2.5629 x Lambda(10.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8529
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 25.9709816
	speed: 0.0268s/iter; left time: 450.4444s
	iters: 200, epoch: 30 | loss: 26.3427219
	speed: 0.0234s/iter; left time: 390.9083s
Epoch: 30 cost time: 6.033842325210571
Epoch: 30, Steps: 238 Train Loss: 26.0961 (Forecasting Loss:0.5379 + XiCon Loss:2.5558 x Lambda(10.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8529
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 25.8889904
	speed: 0.0257s/iter; left time: 425.8637s
	iters: 200, epoch: 31 | loss: 25.6877594
	speed: 0.0250s/iter; left time: 410.9283s
Epoch: 31 cost time: 6.017749786376953
Epoch: 31, Steps: 238 Train Loss: 26.1484 (Forecasting Loss:0.5377 + XiCon Loss:2.5611 x Lambda(10.0)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8529
Validation loss decreased (1.006922 --> 1.006862).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 26.6002922
	speed: 0.0261s/iter; left time: 426.2909s
	iters: 200, epoch: 32 | loss: 26.4326344
	speed: 0.0246s/iter; left time: 399.7782s
Epoch: 32 cost time: 6.02797794342041
Epoch: 32, Steps: 238 Train Loss: 26.1199 (Forecasting Loss:0.5378 + XiCon Loss:2.5582 x Lambda(10.0)), Vali MSE Loss: 1.0080 Test MSE Loss: 0.8529
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 26.3397141
	speed: 0.0261s/iter; left time: 419.7030s
	iters: 200, epoch: 33 | loss: 25.6209736
	speed: 0.0244s/iter; left time: 389.3235s
Epoch: 33 cost time: 6.015261888504028
Epoch: 33, Steps: 238 Train Loss: 26.1646 (Forecasting Loss:0.5378 + XiCon Loss:2.5627 x Lambda(10.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8529
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 26.4634228
	speed: 0.0268s/iter; left time: 425.3709s
	iters: 200, epoch: 34 | loss: 27.3845787
	speed: 0.0256s/iter; left time: 402.9061s
Epoch: 34 cost time: 6.19758415222168
Epoch: 34, Steps: 238 Train Loss: 26.1577 (Forecasting Loss:0.5379 + XiCon Loss:2.5620 x Lambda(10.0)), Vali MSE Loss: 1.0074 Test MSE Loss: 0.8529
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 25.9702740
	speed: 0.0265s/iter; left time: 413.5189s
	iters: 200, epoch: 35 | loss: 25.4319038
	speed: 0.0244s/iter; left time: 378.6748s
Epoch: 35 cost time: 6.06508207321167
Epoch: 35, Steps: 238 Train Loss: 26.1155 (Forecasting Loss:0.5378 + XiCon Loss:2.5578 x Lambda(10.0)), Vali MSE Loss: 1.0074 Test MSE Loss: 0.8529
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 26.3581219
	speed: 0.0271s/iter; left time: 416.8442s
	iters: 200, epoch: 36 | loss: 26.7701015
	speed: 0.0242s/iter; left time: 369.6747s
Epoch: 36 cost time: 6.105962038040161
Epoch: 36, Steps: 238 Train Loss: 26.1450 (Forecasting Loss:0.5379 + XiCon Loss:2.5607 x Lambda(10.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8529
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 26.4548931
	speed: 0.0259s/iter; left time: 392.2795s
	iters: 200, epoch: 37 | loss: 26.1157551
	speed: 0.0248s/iter; left time: 373.3046s
Epoch: 37 cost time: 6.015405178070068
Epoch: 37, Steps: 238 Train Loss: 26.1518 (Forecasting Loss:0.5379 + XiCon Loss:2.5614 x Lambda(10.0)), Vali MSE Loss: 1.0077 Test MSE Loss: 0.8529
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 26.3752728
	speed: 0.0269s/iter; left time: 400.5251s
	iters: 200, epoch: 38 | loss: 25.5616302
	speed: 0.0244s/iter; left time: 361.0790s
Epoch: 38 cost time: 6.100767374038696
Epoch: 38, Steps: 238 Train Loss: 26.2150 (Forecasting Loss:0.5377 + XiCon Loss:2.5677 x Lambda(10.0)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8529
Validation loss decreased (1.006862 --> 1.006796).  Saving model ...
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 26.4951420
	speed: 0.0263s/iter; left time: 385.9730s
	iters: 200, epoch: 39 | loss: 25.8130779
	speed: 0.0237s/iter; left time: 345.0433s
Epoch: 39 cost time: 5.965966701507568
Epoch: 39, Steps: 238 Train Loss: 26.1850 (Forecasting Loss:0.5378 + XiCon Loss:2.5647 x Lambda(10.0)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8529
Validation loss decreased (1.006796 --> 1.006455).  Saving model ...
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 26.0463772
	speed: 0.0267s/iter; left time: 384.7304s
	iters: 200, epoch: 40 | loss: 26.3382645
	speed: 0.0248s/iter; left time: 354.9442s
Epoch: 40 cost time: 6.05718994140625
Epoch: 40, Steps: 238 Train Loss: 26.1650 (Forecasting Loss:0.5379 + XiCon Loss:2.5627 x Lambda(10.0)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8529
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 26.5000134
	speed: 0.0274s/iter; left time: 388.5377s
	iters: 200, epoch: 41 | loss: 26.1693878
	speed: 0.0242s/iter; left time: 340.3846s
Epoch: 41 cost time: 6.1145875453948975
Epoch: 41, Steps: 238 Train Loss: 26.1837 (Forecasting Loss:0.5379 + XiCon Loss:2.5646 x Lambda(10.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8529
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 26.4644852
	speed: 0.0264s/iter; left time: 367.4980s
	iters: 200, epoch: 42 | loss: 26.8836231
	speed: 0.0242s/iter; left time: 335.6710s
Epoch: 42 cost time: 6.024434566497803
Epoch: 42, Steps: 238 Train Loss: 26.1687 (Forecasting Loss:0.5379 + XiCon Loss:2.5631 x Lambda(10.0)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8529
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 25.6232586
	speed: 0.0257s/iter; left time: 351.5585s
	iters: 200, epoch: 43 | loss: 26.5159321
	speed: 0.0238s/iter; left time: 324.4068s
Epoch: 43 cost time: 5.95549750328064
Epoch: 43, Steps: 238 Train Loss: 26.1698 (Forecasting Loss:0.5378 + XiCon Loss:2.5632 x Lambda(10.0)), Vali MSE Loss: 1.0077 Test MSE Loss: 0.8529
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323207e-17
	iters: 100, epoch: 44 | loss: 26.2363319
	speed: 0.0265s/iter; left time: 357.2339s
	iters: 200, epoch: 44 | loss: 25.2653561
	speed: 0.0242s/iter; left time: 323.0466s
Epoch: 44 cost time: 6.082875728607178
Epoch: 44, Steps: 238 Train Loss: 26.1403 (Forecasting Loss:0.5378 + XiCon Loss:2.5603 x Lambda(10.0)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8529
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161604e-17
	iters: 100, epoch: 45 | loss: 26.4943943
	speed: 0.0251s/iter; left time: 331.8941s
	iters: 200, epoch: 45 | loss: 26.7498226
	speed: 0.0254s/iter; left time: 333.5242s
Epoch: 45 cost time: 5.955941200256348
Epoch: 45, Steps: 238 Train Loss: 26.2034 (Forecasting Loss:0.5376 + XiCon Loss:2.5666 x Lambda(10.0)), Vali MSE Loss: 1.0082 Test MSE Loss: 0.8529
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-18
	iters: 100, epoch: 46 | loss: 25.8703938
	speed: 0.0268s/iter; left time: 348.2821s
	iters: 200, epoch: 46 | loss: 26.3227997
	speed: 0.0242s/iter; left time: 312.1823s
Epoch: 46 cost time: 6.061294078826904
Epoch: 46, Steps: 238 Train Loss: 26.1763 (Forecasting Loss:0.5379 + XiCon Loss:2.5638 x Lambda(10.0)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8529
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-18
	iters: 100, epoch: 47 | loss: 26.2957172
	speed: 0.0264s/iter; left time: 337.1262s
	iters: 200, epoch: 47 | loss: 25.3434200
	speed: 0.0246s/iter; left time: 310.7943s
Epoch: 47 cost time: 6.09408974647522
Epoch: 47, Steps: 238 Train Loss: 26.1890 (Forecasting Loss:0.5379 + XiCon Loss:2.5651 x Lambda(10.0)), Vali MSE Loss: 1.0080 Test MSE Loss: 0.8529
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-18
	iters: 100, epoch: 48 | loss: 25.2940407
	speed: 0.0258s/iter; left time: 323.0599s
	iters: 200, epoch: 48 | loss: 26.5061226
	speed: 0.0254s/iter; left time: 315.6997s
Epoch: 48 cost time: 6.045640707015991
Epoch: 48, Steps: 238 Train Loss: 26.2021 (Forecasting Loss:0.5378 + XiCon Loss:2.5664 x Lambda(10.0)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8529
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-19
	iters: 100, epoch: 49 | loss: 26.0294189
	speed: 0.0264s/iter; left time: 324.6432s
	iters: 200, epoch: 49 | loss: 25.9516087
	speed: 0.0243s/iter; left time: 295.4176s
Epoch: 49 cost time: 6.059974431991577
Epoch: 49, Steps: 238 Train Loss: 26.1665 (Forecasting Loss:0.5377 + XiCon Loss:2.5629 x Lambda(10.0)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8529
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9840213656425476, mae:0.7217774987220764, mape:4.797245979309082, mspe:2737.74755859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.2191
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 27.0302563
	speed: 0.0252s/iter; left time: 596.6122s
	iters: 200, epoch: 1 | loss: 25.9945202
	speed: 0.0216s/iter; left time: 508.8010s
Epoch: 1 cost time: 5.646444797515869
Epoch: 1, Steps: 238 Train Loss: 26.7445 (Forecasting Loss:0.9872 + XiCon Loss:2.5757 x Lambda(10.0)), Vali MSE Loss: 1.7719 Test MSE Loss: 0.9677
Validation loss decreased (inf --> 1.771856).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 26.9695034
	speed: 0.0238s/iter; left time: 557.7177s
	iters: 200, epoch: 2 | loss: 26.5872440
	speed: 0.0210s/iter; left time: 490.6148s
Epoch: 2 cost time: 5.29945707321167
Epoch: 2, Steps: 238 Train Loss: 26.3022 (Forecasting Loss:0.6170 + XiCon Loss:2.5685 x Lambda(10.0)), Vali MSE Loss: 1.0395 Test MSE Loss: 0.8539
Validation loss decreased (1.771856 --> 1.039458).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 25.5765743
	speed: 0.0245s/iter; left time: 568.8529s
	iters: 200, epoch: 3 | loss: 26.2200966
	speed: 0.0220s/iter; left time: 508.0827s
Epoch: 3 cost time: 5.452059984207153
Epoch: 3, Steps: 238 Train Loss: 26.1712 (Forecasting Loss:0.5501 + XiCon Loss:2.5621 x Lambda(10.0)), Vali MSE Loss: 1.0172 Test MSE Loss: 0.8457
Validation loss decreased (1.039458 --> 1.017198).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.2111130
	speed: 0.0240s/iter; left time: 552.8184s
	iters: 200, epoch: 4 | loss: 26.6408386
	speed: 0.0212s/iter; left time: 485.8749s
Epoch: 4 cost time: 5.344071388244629
Epoch: 4, Steps: 238 Train Loss: 26.1335 (Forecasting Loss:0.5409 + XiCon Loss:2.5593 x Lambda(10.0)), Vali MSE Loss: 1.0102 Test MSE Loss: 0.8435
Validation loss decreased (1.017198 --> 1.010203).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.8003635
	speed: 0.0255s/iter; left time: 580.1998s
	iters: 200, epoch: 5 | loss: 27.2447224
	speed: 0.0211s/iter; left time: 477.1873s
Epoch: 5 cost time: 5.459397554397583
Epoch: 5, Steps: 238 Train Loss: 26.0855 (Forecasting Loss:0.5369 + XiCon Loss:2.5549 x Lambda(10.0)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8428
Validation loss decreased (1.010203 --> 1.006484).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 25.7170620
	speed: 0.0245s/iter; left time: 552.6050s
	iters: 200, epoch: 6 | loss: 26.1318226
	speed: 0.0217s/iter; left time: 485.8107s
Epoch: 6 cost time: 5.491580963134766
Epoch: 6, Steps: 238 Train Loss: 26.0224 (Forecasting Loss:0.5350 + XiCon Loss:2.5487 x Lambda(10.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8426
Validation loss decreased (1.006484 --> 1.005031).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.5892410
	speed: 0.0244s/iter; left time: 544.4867s
	iters: 200, epoch: 7 | loss: 25.9103546
	speed: 0.0214s/iter; left time: 473.5613s
Epoch: 7 cost time: 5.404350757598877
Epoch: 7, Steps: 238 Train Loss: 26.0728 (Forecasting Loss:0.5340 + XiCon Loss:2.5539 x Lambda(10.0)), Vali MSE Loss: 1.0034 Test MSE Loss: 0.8424
Validation loss decreased (1.005031 --> 1.003435).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 25.9840603
	speed: 0.0247s/iter; left time: 544.6180s
	iters: 200, epoch: 8 | loss: 26.2932434
	speed: 0.0221s/iter; left time: 485.6871s
Epoch: 8 cost time: 5.476548433303833
Epoch: 8, Steps: 238 Train Loss: 26.0985 (Forecasting Loss:0.5336 + XiCon Loss:2.5565 x Lambda(10.0)), Vali MSE Loss: 1.0037 Test MSE Loss: 0.8424
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.1933289
	speed: 0.0255s/iter; left time: 555.6309s
	iters: 200, epoch: 9 | loss: 25.3462811
	speed: 0.0209s/iter; left time: 454.3201s
Epoch: 9 cost time: 5.504067659378052
Epoch: 9, Steps: 238 Train Loss: 26.0425 (Forecasting Loss:0.5335 + XiCon Loss:2.5509 x Lambda(10.0)), Vali MSE Loss: 1.0032 Test MSE Loss: 0.8424
Validation loss decreased (1.003435 --> 1.003225).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 26.0607452
	speed: 0.0246s/iter; left time: 531.3316s
	iters: 200, epoch: 10 | loss: 25.6514912
	speed: 0.0209s/iter; left time: 448.5819s
Epoch: 10 cost time: 5.428144693374634
Epoch: 10, Steps: 238 Train Loss: 26.0649 (Forecasting Loss:0.5333 + XiCon Loss:2.5532 x Lambda(10.0)), Vali MSE Loss: 1.0034 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 25.9428082
	speed: 0.0248s/iter; left time: 528.1333s
	iters: 200, epoch: 11 | loss: 26.3659420
	speed: 0.0208s/iter; left time: 441.4688s
Epoch: 11 cost time: 5.390369415283203
Epoch: 11, Steps: 238 Train Loss: 26.1001 (Forecasting Loss:0.5333 + XiCon Loss:2.5567 x Lambda(10.0)), Vali MSE Loss: 1.0029 Test MSE Loss: 0.8423
Validation loss decreased (1.003225 --> 1.002855).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 25.8404331
	speed: 0.0241s/iter; left time: 508.4238s
	iters: 200, epoch: 12 | loss: 25.6356640
	speed: 0.0213s/iter; left time: 447.7125s
Epoch: 12 cost time: 5.3734986782073975
Epoch: 12, Steps: 238 Train Loss: 26.0692 (Forecasting Loss:0.5332 + XiCon Loss:2.5536 x Lambda(10.0)), Vali MSE Loss: 1.0024 Test MSE Loss: 0.8423
Validation loss decreased (1.002855 --> 1.002444).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.1803818
	speed: 0.0254s/iter; left time: 528.7471s
	iters: 200, epoch: 13 | loss: 25.9187775
	speed: 0.0217s/iter; left time: 450.8336s
Epoch: 13 cost time: 5.488860607147217
Epoch: 13, Steps: 238 Train Loss: 26.0749 (Forecasting Loss:0.5333 + XiCon Loss:2.5542 x Lambda(10.0)), Vali MSE Loss: 1.0030 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 26.2615223
	speed: 0.0259s/iter; left time: 533.1929s
	iters: 200, epoch: 14 | loss: 26.2110138
	speed: 0.0211s/iter; left time: 432.0637s
Epoch: 14 cost time: 5.497843980789185
Epoch: 14, Steps: 238 Train Loss: 26.0126 (Forecasting Loss:0.5334 + XiCon Loss:2.5479 x Lambda(10.0)), Vali MSE Loss: 1.0030 Test MSE Loss: 0.8423
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.9341736
	speed: 0.0249s/iter; left time: 506.7981s
	iters: 200, epoch: 15 | loss: 26.2261543
	speed: 0.0217s/iter; left time: 439.3028s
Epoch: 15 cost time: 5.583169460296631
Epoch: 15, Steps: 238 Train Loss: 26.0885 (Forecasting Loss:0.5332 + XiCon Loss:2.5555 x Lambda(10.0)), Vali MSE Loss: 1.0030 Test MSE Loss: 0.8423
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 26.1004219
	speed: 0.0244s/iter; left time: 490.5189s
	iters: 200, epoch: 16 | loss: 25.8526726
	speed: 0.0213s/iter; left time: 427.2226s
Epoch: 16 cost time: 5.39361310005188
Epoch: 16, Steps: 238 Train Loss: 26.0830 (Forecasting Loss:0.5331 + XiCon Loss:2.5550 x Lambda(10.0)), Vali MSE Loss: 1.0017 Test MSE Loss: 0.8423
Validation loss decreased (1.002444 --> 1.001749).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 26.7905197
	speed: 0.0238s/iter; left time: 473.1416s
	iters: 200, epoch: 17 | loss: 26.9192867
	speed: 0.0228s/iter; left time: 451.9444s
Epoch: 17 cost time: 5.422774314880371
Epoch: 17, Steps: 238 Train Loss: 26.0619 (Forecasting Loss:0.5331 + XiCon Loss:2.5529 x Lambda(10.0)), Vali MSE Loss: 1.0025 Test MSE Loss: 0.8423
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.4984436
	speed: 0.0256s/iter; left time: 503.1052s
	iters: 200, epoch: 18 | loss: 25.7880135
	speed: 0.0209s/iter; left time: 409.6405s
Epoch: 18 cost time: 5.486548185348511
Epoch: 18, Steps: 238 Train Loss: 26.0360 (Forecasting Loss:0.5333 + XiCon Loss:2.5503 x Lambda(10.0)), Vali MSE Loss: 1.0037 Test MSE Loss: 0.8423
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.3688812
	speed: 0.0251s/iter; left time: 486.6895s
	iters: 200, epoch: 19 | loss: 26.1715889
	speed: 0.0210s/iter; left time: 405.0782s
Epoch: 19 cost time: 5.385775804519653
Epoch: 19, Steps: 238 Train Loss: 26.1122 (Forecasting Loss:0.5334 + XiCon Loss:2.5579 x Lambda(10.0)), Vali MSE Loss: 1.0024 Test MSE Loss: 0.8423
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 25.8347549
	speed: 0.0246s/iter; left time: 472.7056s
	iters: 200, epoch: 20 | loss: 26.0820675
	speed: 0.0206s/iter; left time: 393.1841s
Epoch: 20 cost time: 5.369986057281494
Epoch: 20, Steps: 238 Train Loss: 26.0761 (Forecasting Loss:0.5333 + XiCon Loss:2.5543 x Lambda(10.0)), Vali MSE Loss: 1.0026 Test MSE Loss: 0.8423
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 25.9153843
	speed: 0.0243s/iter; left time: 460.9938s
	iters: 200, epoch: 21 | loss: 27.1917305
	speed: 0.0207s/iter; left time: 389.6657s
Epoch: 21 cost time: 5.371727705001831
Epoch: 21, Steps: 238 Train Loss: 26.1000 (Forecasting Loss:0.5333 + XiCon Loss:2.5567 x Lambda(10.0)), Vali MSE Loss: 1.0030 Test MSE Loss: 0.8423
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 25.1466656
	speed: 0.0250s/iter; left time: 468.4639s
	iters: 200, epoch: 22 | loss: 26.6375122
	speed: 0.0217s/iter; left time: 403.2122s
Epoch: 22 cost time: 5.529965400695801
Epoch: 22, Steps: 238 Train Loss: 26.0353 (Forecasting Loss:0.5334 + XiCon Loss:2.5502 x Lambda(10.0)), Vali MSE Loss: 1.0026 Test MSE Loss: 0.8423
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 25.8128757
	speed: 0.0248s/iter; left time: 458.1994s
	iters: 200, epoch: 23 | loss: 26.1807709
	speed: 0.0215s/iter; left time: 395.1240s
Epoch: 23 cost time: 5.427951812744141
Epoch: 23, Steps: 238 Train Loss: 26.0309 (Forecasting Loss:0.5332 + XiCon Loss:2.5498 x Lambda(10.0)), Vali MSE Loss: 1.0027 Test MSE Loss: 0.8423
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 25.8161488
	speed: 0.0251s/iter; left time: 457.2334s
	iters: 200, epoch: 24 | loss: 26.3595543
	speed: 0.0210s/iter; left time: 381.3983s
Epoch: 24 cost time: 5.410630464553833
Epoch: 24, Steps: 238 Train Loss: 26.0323 (Forecasting Loss:0.5335 + XiCon Loss:2.5499 x Lambda(10.0)), Vali MSE Loss: 1.0035 Test MSE Loss: 0.8423
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 25.8318233
	speed: 0.0249s/iter; left time: 447.3705s
	iters: 200, epoch: 25 | loss: 26.4847679
	speed: 0.0201s/iter; left time: 359.6127s
Epoch: 25 cost time: 5.309781789779663
Epoch: 25, Steps: 238 Train Loss: 26.0633 (Forecasting Loss:0.5332 + XiCon Loss:2.5530 x Lambda(10.0)), Vali MSE Loss: 1.0033 Test MSE Loss: 0.8423
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 25.9771137
	speed: 0.0243s/iter; left time: 430.6995s
	iters: 200, epoch: 26 | loss: 26.1473064
	speed: 0.0214s/iter; left time: 378.1033s
Epoch: 26 cost time: 5.427359104156494
Epoch: 26, Steps: 238 Train Loss: 26.0269 (Forecasting Loss:0.5334 + XiCon Loss:2.5493 x Lambda(10.0)), Vali MSE Loss: 1.0032 Test MSE Loss: 0.8423
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9684581160545349, mae:0.716198205947876, mape:4.673160076141357, mspe:2564.039794921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5180
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 26.5882015
	speed: 0.0246s/iter; left time: 583.7584s
	iters: 200, epoch: 1 | loss: 27.1189365
	speed: 0.0211s/iter; left time: 498.8883s
Epoch: 1 cost time: 5.402791976928711
Epoch: 1, Steps: 238 Train Loss: 26.7268 (Forecasting Loss:1.1895 + XiCon Loss:2.5537 x Lambda(10.0)), Vali MSE Loss: 2.1407 Test MSE Loss: 1.0914
Validation loss decreased (inf --> 2.140698).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 24.9027996
	speed: 0.0238s/iter; left time: 557.6413s
	iters: 200, epoch: 2 | loss: 25.6219730
	speed: 0.0204s/iter; left time: 477.3935s
Epoch: 2 cost time: 5.2170891761779785
Epoch: 2, Steps: 238 Train Loss: 26.1335 (Forecasting Loss:0.6515 + XiCon Loss:2.5482 x Lambda(10.0)), Vali MSE Loss: 1.0249 Test MSE Loss: 0.8632
Validation loss decreased (2.140698 --> 1.024943).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 25.5979862
	speed: 0.0246s/iter; left time: 572.2104s
	iters: 200, epoch: 3 | loss: 25.9887486
	speed: 0.0203s/iter; left time: 468.4806s
Epoch: 3 cost time: 5.307671308517456
Epoch: 3, Steps: 238 Train Loss: 26.0060 (Forecasting Loss:0.5549 + XiCon Loss:2.5451 x Lambda(10.0)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8569
Validation loss decreased (1.024943 --> 1.004984).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 25.1822720
	speed: 0.0240s/iter; left time: 552.0091s
	iters: 200, epoch: 4 | loss: 25.9103241
	speed: 0.0202s/iter; left time: 462.1020s
Epoch: 4 cost time: 5.2045207023620605
Epoch: 4, Steps: 238 Train Loss: 25.8821 (Forecasting Loss:0.5470 + XiCon Loss:2.5335 x Lambda(10.0)), Vali MSE Loss: 0.9988 Test MSE Loss: 0.8554
Validation loss decreased (1.004984 --> 0.998842).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 25.7781086
	speed: 0.0239s/iter; left time: 543.7203s
	iters: 200, epoch: 5 | loss: 25.7935963
	speed: 0.0208s/iter; left time: 470.8497s
Epoch: 5 cost time: 5.336789846420288
Epoch: 5, Steps: 238 Train Loss: 25.8983 (Forecasting Loss:0.5437 + XiCon Loss:2.5355 x Lambda(10.0)), Vali MSE Loss: 0.9940 Test MSE Loss: 0.8548
Validation loss decreased (0.998842 --> 0.993993).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 26.3265858
	speed: 0.0245s/iter; left time: 551.1744s
	iters: 200, epoch: 6 | loss: 25.3515625
	speed: 0.0199s/iter; left time: 445.6956s
Epoch: 6 cost time: 5.256616592407227
Epoch: 6, Steps: 238 Train Loss: 25.9227 (Forecasting Loss:0.5424 + XiCon Loss:2.5380 x Lambda(10.0)), Vali MSE Loss: 0.9927 Test MSE Loss: 0.8543
Validation loss decreased (0.993993 --> 0.992669).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 26.4909687
	speed: 0.0239s/iter; left time: 531.4000s
	iters: 200, epoch: 7 | loss: 25.3944588
	speed: 0.0206s/iter; left time: 456.6357s
Epoch: 7 cost time: 5.223745346069336
Epoch: 7, Steps: 238 Train Loss: 25.9581 (Forecasting Loss:0.5416 + XiCon Loss:2.5416 x Lambda(10.0)), Vali MSE Loss: 0.9933 Test MSE Loss: 0.8539
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 26.1216927
	speed: 0.0234s/iter; left time: 515.4955s
	iters: 200, epoch: 8 | loss: 25.4278316
	speed: 0.0202s/iter; left time: 442.3998s
Epoch: 8 cost time: 5.117414474487305
Epoch: 8, Steps: 238 Train Loss: 25.9282 (Forecasting Loss:0.5410 + XiCon Loss:2.5387 x Lambda(10.0)), Vali MSE Loss: 0.9918 Test MSE Loss: 0.8539
Validation loss decreased (0.992669 --> 0.991804).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.0316544
	speed: 0.0248s/iter; left time: 540.0036s
	iters: 200, epoch: 9 | loss: 25.6731777
	speed: 0.0228s/iter; left time: 493.9639s
Epoch: 9 cost time: 5.559262275695801
Epoch: 9, Steps: 238 Train Loss: 25.9232 (Forecasting Loss:0.5406 + XiCon Loss:2.5383 x Lambda(10.0)), Vali MSE Loss: 0.9922 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 25.9865379
	speed: 0.0247s/iter; left time: 531.7311s
	iters: 200, epoch: 10 | loss: 25.5601368
	speed: 0.0206s/iter; left time: 441.2190s
Epoch: 10 cost time: 5.39532208442688
Epoch: 10, Steps: 238 Train Loss: 25.9328 (Forecasting Loss:0.5410 + XiCon Loss:2.5392 x Lambda(10.0)), Vali MSE Loss: 0.9927 Test MSE Loss: 0.8538
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 25.1329136
	speed: 0.0245s/iter; left time: 521.3749s
	iters: 200, epoch: 11 | loss: 25.7387543
	speed: 0.0216s/iter; left time: 458.9434s
Epoch: 11 cost time: 5.418893575668335
Epoch: 11, Steps: 238 Train Loss: 25.9518 (Forecasting Loss:0.5408 + XiCon Loss:2.5411 x Lambda(10.0)), Vali MSE Loss: 0.9921 Test MSE Loss: 0.8538
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.3162746
	speed: 0.0251s/iter; left time: 529.0638s
	iters: 200, epoch: 12 | loss: 25.9305344
	speed: 0.0214s/iter; left time: 448.7938s
Epoch: 12 cost time: 5.448925971984863
Epoch: 12, Steps: 238 Train Loss: 25.9141 (Forecasting Loss:0.5407 + XiCon Loss:2.5373 x Lambda(10.0)), Vali MSE Loss: 0.9924 Test MSE Loss: 0.8538
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.0273495
	speed: 0.0256s/iter; left time: 533.9513s
	iters: 200, epoch: 13 | loss: 26.4186707
	speed: 0.0210s/iter; left time: 435.0621s
Epoch: 13 cost time: 5.494471788406372
Epoch: 13, Steps: 238 Train Loss: 25.9422 (Forecasting Loss:0.5411 + XiCon Loss:2.5401 x Lambda(10.0)), Vali MSE Loss: 0.9915 Test MSE Loss: 0.8538
Validation loss decreased (0.991804 --> 0.991482).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 26.8338699
	speed: 0.0250s/iter; left time: 515.5812s
	iters: 200, epoch: 14 | loss: 25.4867725
	speed: 0.0211s/iter; left time: 432.0569s
Epoch: 14 cost time: 5.4861297607421875
Epoch: 14, Steps: 238 Train Loss: 25.9427 (Forecasting Loss:0.5406 + XiCon Loss:2.5402 x Lambda(10.0)), Vali MSE Loss: 0.9918 Test MSE Loss: 0.8538
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 25.9997082
	speed: 0.0244s/iter; left time: 496.0481s
	iters: 200, epoch: 15 | loss: 25.7933846
	speed: 0.0213s/iter; left time: 431.3951s
Epoch: 15 cost time: 5.369275331497192
Epoch: 15, Steps: 238 Train Loss: 25.9163 (Forecasting Loss:0.5405 + XiCon Loss:2.5376 x Lambda(10.0)), Vali MSE Loss: 0.9918 Test MSE Loss: 0.8538
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 25.3316441
	speed: 0.0238s/iter; left time: 479.9745s
	iters: 200, epoch: 16 | loss: 25.5469952
	speed: 0.0212s/iter; left time: 425.4969s
Epoch: 16 cost time: 5.359407186508179
Epoch: 16, Steps: 238 Train Loss: 25.8736 (Forecasting Loss:0.5408 + XiCon Loss:2.5333 x Lambda(10.0)), Vali MSE Loss: 0.9918 Test MSE Loss: 0.8538
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 25.8523006
	speed: 0.0244s/iter; left time: 485.0072s
	iters: 200, epoch: 17 | loss: 26.9747906
	speed: 0.0213s/iter; left time: 421.5217s
Epoch: 17 cost time: 5.359915018081665
Epoch: 17, Steps: 238 Train Loss: 25.9213 (Forecasting Loss:0.5407 + XiCon Loss:2.5381 x Lambda(10.0)), Vali MSE Loss: 0.9918 Test MSE Loss: 0.8538
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.5188122
	speed: 0.0249s/iter; left time: 489.8835s
	iters: 200, epoch: 18 | loss: 26.2516556
	speed: 0.0209s/iter; left time: 408.6599s
Epoch: 18 cost time: 5.42528510093689
Epoch: 18, Steps: 238 Train Loss: 25.8973 (Forecasting Loss:0.5409 + XiCon Loss:2.5356 x Lambda(10.0)), Vali MSE Loss: 0.9920 Test MSE Loss: 0.8538
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 25.9745140
	speed: 0.0245s/iter; left time: 474.8394s
	iters: 200, epoch: 19 | loss: 25.5616989
	speed: 0.0213s/iter; left time: 410.5810s
Epoch: 19 cost time: 5.402709245681763
Epoch: 19, Steps: 238 Train Loss: 25.8806 (Forecasting Loss:0.5407 + XiCon Loss:2.5340 x Lambda(10.0)), Vali MSE Loss: 0.9919 Test MSE Loss: 0.8538
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 24.8960152
	speed: 0.0241s/iter; left time: 463.0449s
	iters: 200, epoch: 20 | loss: 26.1761246
	speed: 0.0203s/iter; left time: 386.3651s
Epoch: 20 cost time: 5.28296685218811
Epoch: 20, Steps: 238 Train Loss: 25.9753 (Forecasting Loss:0.5404 + XiCon Loss:2.5435 x Lambda(10.0)), Vali MSE Loss: 0.9918 Test MSE Loss: 0.8538
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 25.7934933
	speed: 0.0237s/iter; left time: 449.0783s
	iters: 200, epoch: 21 | loss: 26.4875641
	speed: 0.0227s/iter; left time: 427.0516s
Epoch: 21 cost time: 5.499736547470093
Epoch: 21, Steps: 238 Train Loss: 25.8947 (Forecasting Loss:0.5405 + XiCon Loss:2.5354 x Lambda(10.0)), Vali MSE Loss: 0.9923 Test MSE Loss: 0.8538
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 25.4868813
	speed: 0.0244s/iter; left time: 456.4826s
	iters: 200, epoch: 22 | loss: 26.4247532
	speed: 0.0216s/iter; left time: 401.1021s
Epoch: 22 cost time: 5.386913537979126
Epoch: 22, Steps: 238 Train Loss: 25.8980 (Forecasting Loss:0.5407 + XiCon Loss:2.5357 x Lambda(10.0)), Vali MSE Loss: 0.9920 Test MSE Loss: 0.8538
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 25.5957508
	speed: 0.0248s/iter; left time: 458.3091s
	iters: 200, epoch: 23 | loss: 25.7119179
	speed: 0.0214s/iter; left time: 392.2296s
Epoch: 23 cost time: 5.447677373886108
Epoch: 23, Steps: 238 Train Loss: 25.8918 (Forecasting Loss:0.5406 + XiCon Loss:2.5351 x Lambda(10.0)), Vali MSE Loss: 0.9922 Test MSE Loss: 0.8538
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9850001931190491, mae:0.7225757837295532, mape:4.7581658363342285, mspe:2647.28076171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9791+-0.00828, MAE:0.7203+-0.00324, MAPE:4.7507+-0.05842, MSPE:2654.5781+-79.58697, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.1171
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 28.9715061
	speed: 0.0360s/iter; left time: 834.3428s
	iters: 200, epoch: 1 | loss: 28.8356838
	speed: 0.0299s/iter; left time: 691.1763s
Epoch: 1 cost time: 7.574156045913696
Epoch: 1, Steps: 233 Train Loss: 29.2080 (Forecasting Loss:1.0189 + XiCon Loss:2.8189 x Lambda(10.0)), Vali MSE Loss: 1.8607 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860681).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.1684437
	speed: 0.0323s/iter; left time: 741.9889s
	iters: 200, epoch: 2 | loss: 29.2865887
	speed: 0.0291s/iter; left time: 666.1695s
Epoch: 2 cost time: 7.212917327880859
Epoch: 2, Steps: 233 Train Loss: 28.7230 (Forecasting Loss:0.6524 + XiCon Loss:2.8071 x Lambda(10.0)), Vali MSE Loss: 1.1263 Test MSE Loss: 1.1493
Validation loss decreased (1.860681 --> 1.126262).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.2539291
	speed: 0.0316s/iter; left time: 718.3627s
	iters: 200, epoch: 3 | loss: 28.2547626
	speed: 0.0300s/iter; left time: 679.5219s
Epoch: 3 cost time: 7.16555643081665
Epoch: 3, Steps: 233 Train Loss: 28.3780 (Forecasting Loss:0.5887 + XiCon Loss:2.7789 x Lambda(10.0)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1426
Validation loss decreased (1.126262 --> 1.104180).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 27.7201958
	speed: 0.0319s/iter; left time: 717.1611s
	iters: 200, epoch: 4 | loss: 28.6585388
	speed: 0.0293s/iter; left time: 656.9966s
Epoch: 4 cost time: 7.119395017623901
Epoch: 4, Steps: 233 Train Loss: 28.1064 (Forecasting Loss:0.5811 + XiCon Loss:2.7525 x Lambda(10.0)), Vali MSE Loss: 1.0971 Test MSE Loss: 1.1401
Validation loss decreased (1.104180 --> 1.097088).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 27.7685795
	speed: 0.0328s/iter; left time: 730.4679s
	iters: 200, epoch: 5 | loss: 28.2700901
	speed: 0.0296s/iter; left time: 655.9802s
Epoch: 5 cost time: 7.276489973068237
Epoch: 5, Steps: 233 Train Loss: 27.9713 (Forecasting Loss:0.5781 + XiCon Loss:2.7393 x Lambda(10.0)), Vali MSE Loss: 1.0943 Test MSE Loss: 1.1390
Validation loss decreased (1.097088 --> 1.094318).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 28.4762478
	speed: 0.0320s/iter; left time: 704.5907s
	iters: 200, epoch: 6 | loss: 28.1236496
	speed: 0.0301s/iter; left time: 660.2423s
Epoch: 6 cost time: 7.216421842575073
Epoch: 6, Steps: 233 Train Loss: 27.9194 (Forecasting Loss:0.5768 + XiCon Loss:2.7343 x Lambda(10.0)), Vali MSE Loss: 1.0927 Test MSE Loss: 1.1388
Validation loss decreased (1.094318 --> 1.092747).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 27.4424629
	speed: 0.0321s/iter; left time: 700.0862s
	iters: 200, epoch: 7 | loss: 27.6452026
	speed: 0.0296s/iter; left time: 642.5522s
Epoch: 7 cost time: 7.209897994995117
Epoch: 7, Steps: 233 Train Loss: 27.8513 (Forecasting Loss:0.5761 + XiCon Loss:2.7275 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1387
Validation loss decreased (1.092747 --> 1.092129).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.0957375
	speed: 0.0323s/iter; left time: 696.3115s
	iters: 200, epoch: 8 | loss: 27.6616707
	speed: 0.0293s/iter; left time: 629.9305s
Epoch: 8 cost time: 7.136494874954224
Epoch: 8, Steps: 233 Train Loss: 27.8708 (Forecasting Loss:0.5758 + XiCon Loss:2.7295 x Lambda(10.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1386
Validation loss decreased (1.092129 --> 1.092017).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 27.7217464
	speed: 0.0318s/iter; left time: 679.4806s
	iters: 200, epoch: 9 | loss: 27.9342575
	speed: 0.0300s/iter; left time: 637.6714s
Epoch: 9 cost time: 7.21547269821167
Epoch: 9, Steps: 233 Train Loss: 27.8756 (Forecasting Loss:0.5756 + XiCon Loss:2.7300 x Lambda(10.0)), Vali MSE Loss: 1.0916 Test MSE Loss: 1.1385
Validation loss decreased (1.092017 --> 1.091573).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 27.2298813
	speed: 0.0327s/iter; left time: 689.2238s
	iters: 200, epoch: 10 | loss: 27.7401314
	speed: 0.0292s/iter; left time: 612.7610s
Epoch: 10 cost time: 7.192995548248291
Epoch: 10, Steps: 233 Train Loss: 27.8364 (Forecasting Loss:0.5755 + XiCon Loss:2.7261 x Lambda(10.0)), Vali MSE Loss: 1.0916 Test MSE Loss: 1.1385
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 27.3183613
	speed: 0.0317s/iter; left time: 660.9342s
	iters: 200, epoch: 11 | loss: 27.4547424
	speed: 0.0292s/iter; left time: 607.0518s
Epoch: 11 cost time: 7.136571645736694
Epoch: 11, Steps: 233 Train Loss: 27.8109 (Forecasting Loss:0.5754 + XiCon Loss:2.7235 x Lambda(10.0)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1385
Validation loss decreased (1.091573 --> 1.091361).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 27.3472576
	speed: 0.0324s/iter; left time: 668.2329s
	iters: 200, epoch: 12 | loss: 28.3876534
	speed: 0.0297s/iter; left time: 610.9556s
Epoch: 12 cost time: 7.213519811630249
Epoch: 12, Steps: 233 Train Loss: 27.7994 (Forecasting Loss:0.5754 + XiCon Loss:2.7224 x Lambda(10.0)), Vali MSE Loss: 1.0912 Test MSE Loss: 1.1385
Validation loss decreased (1.091361 --> 1.091199).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 28.0339642
	speed: 0.0318s/iter; left time: 649.7016s
	iters: 200, epoch: 13 | loss: 27.6373444
	speed: 0.0295s/iter; left time: 599.5265s
Epoch: 13 cost time: 7.1515185832977295
Epoch: 13, Steps: 233 Train Loss: 27.8432 (Forecasting Loss:0.5754 + XiCon Loss:2.7268 x Lambda(10.0)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1385
Validation loss decreased (1.091199 --> 1.091136).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.1679935
	speed: 0.0318s/iter; left time: 640.5793s
	iters: 200, epoch: 14 | loss: 28.1098747
	speed: 0.0290s/iter; left time: 581.9748s
Epoch: 14 cost time: 7.097343683242798
Epoch: 14, Steps: 233 Train Loss: 27.7860 (Forecasting Loss:0.5753 + XiCon Loss:2.7211 x Lambda(10.0)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1385
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 27.8574696
	speed: 0.0315s/iter; left time: 627.3761s
	iters: 200, epoch: 15 | loss: 28.4050560
	speed: 0.0292s/iter; left time: 578.4714s
Epoch: 15 cost time: 7.06189489364624
Epoch: 15, Steps: 233 Train Loss: 27.8098 (Forecasting Loss:0.5754 + XiCon Loss:2.7234 x Lambda(10.0)), Vali MSE Loss: 1.0912 Test MSE Loss: 1.1385
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 27.8356285
	speed: 0.0319s/iter; left time: 629.0512s
	iters: 200, epoch: 16 | loss: 27.3688488
	speed: 0.0299s/iter; left time: 585.5947s
Epoch: 16 cost time: 7.164843559265137
Epoch: 16, Steps: 233 Train Loss: 27.8113 (Forecasting Loss:0.5754 + XiCon Loss:2.7236 x Lambda(10.0)), Vali MSE Loss: 1.0907 Test MSE Loss: 1.1385
Validation loss decreased (1.091136 --> 1.090747).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 26.7989597
	speed: 0.0316s/iter; left time: 616.0988s
	iters: 200, epoch: 17 | loss: 27.5889301
	speed: 0.0297s/iter; left time: 575.0631s
Epoch: 17 cost time: 7.130251407623291
Epoch: 17, Steps: 233 Train Loss: 27.7891 (Forecasting Loss:0.5753 + XiCon Loss:2.7214 x Lambda(10.0)), Vali MSE Loss: 1.0912 Test MSE Loss: 1.1385
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 28.2128277
	speed: 0.0317s/iter; left time: 609.4781s
	iters: 200, epoch: 18 | loss: 27.2981033
	speed: 0.0297s/iter; left time: 567.5693s
Epoch: 18 cost time: 7.086057186126709
Epoch: 18, Steps: 233 Train Loss: 27.8247 (Forecasting Loss:0.5753 + XiCon Loss:2.7249 x Lambda(10.0)), Vali MSE Loss: 1.0910 Test MSE Loss: 1.1385
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 27.3510742
	speed: 0.0313s/iter; left time: 594.5107s
	iters: 200, epoch: 19 | loss: 27.8995190
	speed: 0.0299s/iter; left time: 565.5156s
Epoch: 19 cost time: 7.157860994338989
Epoch: 19, Steps: 233 Train Loss: 27.8368 (Forecasting Loss:0.5754 + XiCon Loss:2.7261 x Lambda(10.0)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1385
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 27.5829964
	speed: 0.0317s/iter; left time: 595.2503s
	iters: 200, epoch: 20 | loss: 27.2299042
	speed: 0.0296s/iter; left time: 552.8058s
Epoch: 20 cost time: 7.10016942024231
Epoch: 20, Steps: 233 Train Loss: 27.8185 (Forecasting Loss:0.5753 + XiCon Loss:2.7243 x Lambda(10.0)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1385
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.6089916
	speed: 0.0312s/iter; left time: 578.1564s
	iters: 200, epoch: 21 | loss: 27.6133690
	speed: 0.0298s/iter; left time: 549.7813s
Epoch: 21 cost time: 7.198197603225708
Epoch: 21, Steps: 233 Train Loss: 27.8275 (Forecasting Loss:0.5754 + XiCon Loss:2.7252 x Lambda(10.0)), Vali MSE Loss: 1.0916 Test MSE Loss: 1.1385
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 27.7321453
	speed: 0.0315s/iter; left time: 577.0939s
	iters: 200, epoch: 22 | loss: 28.3083019
	speed: 0.0291s/iter; left time: 530.2204s
Epoch: 22 cost time: 7.112358570098877
Epoch: 22, Steps: 233 Train Loss: 27.8390 (Forecasting Loss:0.5754 + XiCon Loss:2.7264 x Lambda(10.0)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1385
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 27.5887547
	speed: 0.0318s/iter; left time: 574.2158s
	iters: 200, epoch: 23 | loss: 27.3592472
	speed: 0.0303s/iter; left time: 544.3649s
Epoch: 23 cost time: 7.282938241958618
Epoch: 23, Steps: 233 Train Loss: 27.7907 (Forecasting Loss:0.5754 + XiCon Loss:2.7215 x Lambda(10.0)), Vali MSE Loss: 1.0912 Test MSE Loss: 1.1385
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.0063457
	speed: 0.0322s/iter; left time: 575.3113s
	iters: 200, epoch: 24 | loss: 27.6652317
	speed: 0.0299s/iter; left time: 531.2889s
Epoch: 24 cost time: 7.190483331680298
Epoch: 24, Steps: 233 Train Loss: 27.8373 (Forecasting Loss:0.5753 + XiCon Loss:2.7262 x Lambda(10.0)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1385
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 27.9507790
	speed: 0.0321s/iter; left time: 565.9363s
	iters: 200, epoch: 25 | loss: 28.3274612
	speed: 0.0299s/iter; left time: 523.0211s
Epoch: 25 cost time: 7.215927839279175
Epoch: 25, Steps: 233 Train Loss: 27.8681 (Forecasting Loss:0.5754 + XiCon Loss:2.7293 x Lambda(10.0)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1385
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 27.2081299
	speed: 0.0311s/iter; left time: 540.2594s
	iters: 200, epoch: 26 | loss: 27.0804787
	speed: 0.0295s/iter; left time: 510.4252s
Epoch: 26 cost time: 7.061554431915283
Epoch: 26, Steps: 233 Train Loss: 27.7662 (Forecasting Loss:0.5754 + XiCon Loss:2.7191 x Lambda(10.0)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1385
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3974735736846924, mae:0.8795413970947266, mape:6.1598310470581055, mspe:4566.00390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.1721
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 28.9224129
	speed: 0.0290s/iter; left time: 673.5258s
	iters: 200, epoch: 1 | loss: 30.4762268
	speed: 0.0255s/iter; left time: 589.4604s
Epoch: 1 cost time: 6.307783603668213
Epoch: 1, Steps: 233 Train Loss: 29.5444 (Forecasting Loss:1.1346 + XiCon Loss:2.8410 x Lambda(10.0)), Vali MSE Loss: 2.0448 Test MSE Loss: 1.3328
Validation loss decreased (inf --> 2.044817).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 29.4700584
	speed: 0.0286s/iter; left time: 657.5558s
	iters: 200, epoch: 2 | loss: 28.5101204
	speed: 0.0248s/iter; left time: 567.2624s
Epoch: 2 cost time: 6.18804144859314
Epoch: 2, Steps: 233 Train Loss: 28.8721 (Forecasting Loss:0.6684 + XiCon Loss:2.8204 x Lambda(10.0)), Vali MSE Loss: 1.1269 Test MSE Loss: 1.1382
Validation loss decreased (2.044817 --> 1.126942).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 29.0659962
	speed: 0.0280s/iter; left time: 635.9135s
	iters: 200, epoch: 3 | loss: 28.7871113
	speed: 0.0252s/iter; left time: 570.2889s
Epoch: 3 cost time: 6.148020505905151
Epoch: 3, Steps: 233 Train Loss: 28.5929 (Forecasting Loss:0.5951 + XiCon Loss:2.7998 x Lambda(10.0)), Vali MSE Loss: 1.1116 Test MSE Loss: 1.1315
Validation loss decreased (1.126942 --> 1.111583).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 29.4971352
	speed: 0.0288s/iter; left time: 648.2536s
	iters: 200, epoch: 4 | loss: 28.5692787
	speed: 0.0261s/iter; left time: 584.4093s
Epoch: 4 cost time: 6.3397133350372314
Epoch: 4, Steps: 233 Train Loss: 28.4325 (Forecasting Loss:0.5881 + XiCon Loss:2.7844 x Lambda(10.0)), Vali MSE Loss: 1.1074 Test MSE Loss: 1.1299
Validation loss decreased (1.111583 --> 1.107357).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 28.5760136
	speed: 0.0286s/iter; left time: 637.7549s
	iters: 200, epoch: 5 | loss: 29.1502895
	speed: 0.0254s/iter; left time: 563.0634s
Epoch: 5 cost time: 6.249575614929199
Epoch: 5, Steps: 233 Train Loss: 28.4010 (Forecasting Loss:0.5854 + XiCon Loss:2.7816 x Lambda(10.0)), Vali MSE Loss: 1.1053 Test MSE Loss: 1.1293
Validation loss decreased (1.107357 --> 1.105271).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 28.2556362
	speed: 0.0280s/iter; left time: 617.4033s
	iters: 200, epoch: 6 | loss: 27.9349403
	speed: 0.0245s/iter; left time: 536.9676s
Epoch: 6 cost time: 6.1027257442474365
Epoch: 6, Steps: 233 Train Loss: 28.3630 (Forecasting Loss:0.5838 + XiCon Loss:2.7779 x Lambda(10.0)), Vali MSE Loss: 1.1043 Test MSE Loss: 1.1290
Validation loss decreased (1.105271 --> 1.104292).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.8815269
	speed: 0.0287s/iter; left time: 624.9173s
	iters: 200, epoch: 7 | loss: 27.6954441
	speed: 0.0243s/iter; left time: 526.4806s
Epoch: 7 cost time: 6.128851413726807
Epoch: 7, Steps: 233 Train Loss: 28.3091 (Forecasting Loss:0.5832 + XiCon Loss:2.7726 x Lambda(10.0)), Vali MSE Loss: 1.1037 Test MSE Loss: 1.1289
Validation loss decreased (1.104292 --> 1.103690).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.3937416
	speed: 0.0302s/iter; left time: 650.4506s
	iters: 200, epoch: 8 | loss: 27.8399429
	speed: 0.0256s/iter; left time: 550.0127s
Epoch: 8 cost time: 6.472217082977295
Epoch: 8, Steps: 233 Train Loss: 28.3008 (Forecasting Loss:0.5828 + XiCon Loss:2.7718 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
Validation loss decreased (1.103690 --> 1.103321).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 28.2858639
	speed: 0.0296s/iter; left time: 632.6087s
	iters: 200, epoch: 9 | loss: 28.3799725
	speed: 0.0259s/iter; left time: 549.6903s
Epoch: 9 cost time: 6.454940557479858
Epoch: 9, Steps: 233 Train Loss: 28.2554 (Forecasting Loss:0.5827 + XiCon Loss:2.7673 x Lambda(10.0)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1288
Validation loss decreased (1.103321 --> 1.103150).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.7893219
	speed: 0.0300s/iter; left time: 633.8369s
	iters: 200, epoch: 10 | loss: 28.5612583
	speed: 0.0266s/iter; left time: 559.5931s
Epoch: 10 cost time: 6.517045497894287
Epoch: 10, Steps: 233 Train Loss: 28.3531 (Forecasting Loss:0.5827 + XiCon Loss:2.7770 x Lambda(10.0)), Vali MSE Loss: 1.1034 Test MSE Loss: 1.1288
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 28.2024803
	speed: 0.0298s/iter; left time: 622.5054s
	iters: 200, epoch: 11 | loss: 28.0069695
	speed: 0.0260s/iter; left time: 540.4507s
Epoch: 11 cost time: 6.442349433898926
Epoch: 11, Steps: 233 Train Loss: 28.2491 (Forecasting Loss:0.5826 + XiCon Loss:2.7667 x Lambda(10.0)), Vali MSE Loss: 1.1034 Test MSE Loss: 1.1288
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 28.5271549
	speed: 0.0300s/iter; left time: 619.2469s
	iters: 200, epoch: 12 | loss: 28.5036583
	speed: 0.0270s/iter; left time: 555.3091s
Epoch: 12 cost time: 6.526068925857544
Epoch: 12, Steps: 233 Train Loss: 28.2613 (Forecasting Loss:0.5826 + XiCon Loss:2.7679 x Lambda(10.0)), Vali MSE Loss: 1.1032 Test MSE Loss: 1.1288
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 27.6186142
	speed: 0.0290s/iter; left time: 590.8271s
	iters: 200, epoch: 13 | loss: 28.2712498
	speed: 0.0258s/iter; left time: 524.5029s
Epoch: 13 cost time: 6.349751710891724
Epoch: 13, Steps: 233 Train Loss: 28.2615 (Forecasting Loss:0.5824 + XiCon Loss:2.7679 x Lambda(10.0)), Vali MSE Loss: 1.1032 Test MSE Loss: 1.1288
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.5323658
	speed: 0.0292s/iter; left time: 589.6841s
	iters: 200, epoch: 14 | loss: 28.4838848
	speed: 0.0260s/iter; left time: 521.1687s
Epoch: 14 cost time: 6.3538525104522705
Epoch: 14, Steps: 233 Train Loss: 28.2314 (Forecasting Loss:0.5826 + XiCon Loss:2.7649 x Lambda(10.0)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1288
Validation loss decreased (1.103150 --> 1.103115).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.2770119
	speed: 0.0300s/iter; left time: 597.3754s
	iters: 200, epoch: 15 | loss: 27.9649811
	speed: 0.0261s/iter; left time: 518.7385s
Epoch: 15 cost time: 6.541398763656616
Epoch: 15, Steps: 233 Train Loss: 28.2586 (Forecasting Loss:0.5825 + XiCon Loss:2.7676 x Lambda(10.0)), Vali MSE Loss: 1.1034 Test MSE Loss: 1.1288
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 28.3880863
	speed: 0.0293s/iter; left time: 577.7919s
	iters: 200, epoch: 16 | loss: 28.6263638
	speed: 0.0265s/iter; left time: 519.6908s
Epoch: 16 cost time: 6.4546959400177
Epoch: 16, Steps: 233 Train Loss: 28.2731 (Forecasting Loss:0.5825 + XiCon Loss:2.7691 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 27.9830933
	speed: 0.0289s/iter; left time: 562.2096s
	iters: 200, epoch: 17 | loss: 28.0325089
	speed: 0.0265s/iter; left time: 513.0046s
Epoch: 17 cost time: 6.385525226593018
Epoch: 17, Steps: 233 Train Loss: 28.2819 (Forecasting Loss:0.5824 + XiCon Loss:2.7699 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 28.4947701
	speed: 0.0302s/iter; left time: 580.2233s
	iters: 200, epoch: 18 | loss: 28.5509682
	speed: 0.0258s/iter; left time: 493.9904s
Epoch: 18 cost time: 6.470377683639526
Epoch: 18, Steps: 233 Train Loss: 28.2931 (Forecasting Loss:0.5826 + XiCon Loss:2.7711 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.1341610
	speed: 0.0294s/iter; left time: 558.9713s
	iters: 200, epoch: 19 | loss: 28.2554379
	speed: 0.0261s/iter; left time: 494.1680s
Epoch: 19 cost time: 6.430217266082764
Epoch: 19, Steps: 233 Train Loss: 28.2995 (Forecasting Loss:0.5825 + XiCon Loss:2.7717 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.4969482
	speed: 0.0295s/iter; left time: 553.0052s
	iters: 200, epoch: 20 | loss: 28.0425129
	speed: 0.0261s/iter; left time: 487.1965s
Epoch: 20 cost time: 6.474615573883057
Epoch: 20, Steps: 233 Train Loss: 28.2452 (Forecasting Loss:0.5824 + XiCon Loss:2.7663 x Lambda(10.0)), Vali MSE Loss: 1.1032 Test MSE Loss: 1.1288
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.4209251
	speed: 0.0310s/iter; left time: 575.5047s
	iters: 200, epoch: 21 | loss: 28.1322994
	speed: 0.0252s/iter; left time: 465.4849s
Epoch: 21 cost time: 6.563509941101074
Epoch: 21, Steps: 233 Train Loss: 28.2847 (Forecasting Loss:0.5826 + XiCon Loss:2.7702 x Lambda(10.0)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1288
Validation loss decreased (1.103115 --> 1.103061).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 27.8139763
	speed: 0.0303s/iter; left time: 554.2082s
	iters: 200, epoch: 22 | loss: 28.1387157
	speed: 0.0256s/iter; left time: 466.7660s
Epoch: 22 cost time: 6.511867046356201
Epoch: 22, Steps: 233 Train Loss: 28.2578 (Forecasting Loss:0.5825 + XiCon Loss:2.7675 x Lambda(10.0)), Vali MSE Loss: 1.1032 Test MSE Loss: 1.1288
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 28.3190842
	speed: 0.0306s/iter; left time: 552.6724s
	iters: 200, epoch: 23 | loss: 28.9771080
	speed: 0.0271s/iter; left time: 486.4657s
Epoch: 23 cost time: 6.658307790756226
Epoch: 23, Steps: 233 Train Loss: 28.2840 (Forecasting Loss:0.5827 + XiCon Loss:2.7701 x Lambda(10.0)), Vali MSE Loss: 1.1032 Test MSE Loss: 1.1288
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.4780579
	speed: 0.0309s/iter; left time: 551.5997s
	iters: 200, epoch: 24 | loss: 27.8929119
	speed: 0.0263s/iter; left time: 466.6713s
Epoch: 24 cost time: 6.627077579498291
Epoch: 24, Steps: 233 Train Loss: 28.3067 (Forecasting Loss:0.5824 + XiCon Loss:2.7724 x Lambda(10.0)), Vali MSE Loss: 1.1032 Test MSE Loss: 1.1288
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 27.9399319
	speed: 0.0300s/iter; left time: 529.1378s
	iters: 200, epoch: 25 | loss: 27.8422318
	speed: 0.0258s/iter; left time: 452.4967s
Epoch: 25 cost time: 6.492394685745239
Epoch: 25, Steps: 233 Train Loss: 28.2839 (Forecasting Loss:0.5825 + XiCon Loss:2.7701 x Lambda(10.0)), Vali MSE Loss: 1.1030 Test MSE Loss: 1.1288
Validation loss decreased (1.103061 --> 1.102950).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 28.4912071
	speed: 0.0305s/iter; left time: 529.7736s
	iters: 200, epoch: 26 | loss: 27.9769478
	speed: 0.0267s/iter; left time: 461.3439s
Epoch: 26 cost time: 6.574154615402222
Epoch: 26, Steps: 233 Train Loss: 28.2711 (Forecasting Loss:0.5825 + XiCon Loss:2.7689 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 28.5854607
	speed: 0.0300s/iter; left time: 514.9874s
	iters: 200, epoch: 27 | loss: 29.0037842
	speed: 0.0262s/iter; left time: 446.2898s
Epoch: 27 cost time: 6.453894376754761
Epoch: 27, Steps: 233 Train Loss: 28.2993 (Forecasting Loss:0.5825 + XiCon Loss:2.7717 x Lambda(10.0)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1288
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 28.0194626
	speed: 0.0305s/iter; left time: 515.9731s
	iters: 200, epoch: 28 | loss: 28.3226337
	speed: 0.0261s/iter; left time: 438.2355s
Epoch: 28 cost time: 6.50672459602356
Epoch: 28, Steps: 233 Train Loss: 28.2655 (Forecasting Loss:0.5825 + XiCon Loss:2.7683 x Lambda(10.0)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1288
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 28.3631496
	speed: 0.0303s/iter; left time: 504.7951s
	iters: 200, epoch: 29 | loss: 28.1336632
	speed: 0.0269s/iter; left time: 445.7116s
Epoch: 29 cost time: 6.6000730991363525
Epoch: 29, Steps: 233 Train Loss: 28.2958 (Forecasting Loss:0.5825 + XiCon Loss:2.7713 x Lambda(10.0)), Vali MSE Loss: 1.1036 Test MSE Loss: 1.1288
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 27.6956997
	speed: 0.0287s/iter; left time: 472.3406s
	iters: 200, epoch: 30 | loss: 29.0485973
	speed: 0.0263s/iter; left time: 430.4314s
Epoch: 30 cost time: 6.368974208831787
Epoch: 30, Steps: 233 Train Loss: 28.2636 (Forecasting Loss:0.5826 + XiCon Loss:2.7681 x Lambda(10.0)), Vali MSE Loss: 1.1030 Test MSE Loss: 1.1288
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 27.7217121
	speed: 0.0307s/iter; left time: 497.3027s
	iters: 200, epoch: 31 | loss: 27.5036335
	speed: 0.0261s/iter; left time: 420.9913s
Epoch: 31 cost time: 6.541214466094971
Epoch: 31, Steps: 233 Train Loss: 28.2680 (Forecasting Loss:0.5824 + XiCon Loss:2.7686 x Lambda(10.0)), Vali MSE Loss: 1.1035 Test MSE Loss: 1.1288
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 28.6227760
	speed: 0.0290s/iter; left time: 463.6670s
	iters: 200, epoch: 32 | loss: 28.4121246
	speed: 0.0258s/iter; left time: 409.8935s
Epoch: 32 cost time: 6.320766448974609
Epoch: 32, Steps: 233 Train Loss: 28.2702 (Forecasting Loss:0.5825 + XiCon Loss:2.7688 x Lambda(10.0)), Vali MSE Loss: 1.1033 Test MSE Loss: 1.1288
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 28.1823540
	speed: 0.0299s/iter; left time: 471.4807s
	iters: 200, epoch: 33 | loss: 27.4700089
	speed: 0.0261s/iter; left time: 408.8769s
Epoch: 33 cost time: 6.4873998165130615
Epoch: 33, Steps: 233 Train Loss: 28.2554 (Forecasting Loss:0.5826 + XiCon Loss:2.7673 x Lambda(10.0)), Vali MSE Loss: 1.1034 Test MSE Loss: 1.1288
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 28.3311424
	speed: 0.0301s/iter; left time: 466.4589s
	iters: 200, epoch: 34 | loss: 28.3549919
	speed: 0.0258s/iter; left time: 398.1254s
Epoch: 34 cost time: 6.489847421646118
Epoch: 34, Steps: 233 Train Loss: 28.2615 (Forecasting Loss:0.5826 + XiCon Loss:2.7679 x Lambda(10.0)), Vali MSE Loss: 1.1035 Test MSE Loss: 1.1288
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 28.0852795
	speed: 0.0300s/iter; left time: 459.0473s
	iters: 200, epoch: 35 | loss: 27.9551163
	speed: 0.0254s/iter; left time: 385.6862s
Epoch: 35 cost time: 6.472275495529175
Epoch: 35, Steps: 233 Train Loss: 28.2969 (Forecasting Loss:0.5823 + XiCon Loss:2.7715 x Lambda(10.0)), Vali MSE Loss: 1.1031 Test MSE Loss: 1.1288
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3845175504684448, mae:0.8730149865150452, mape:5.935974597930908, mspe:4185.18505859375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.1046
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 30.0264168
	speed: 0.0302s/iter; left time: 700.4319s
	iters: 200, epoch: 1 | loss: 29.7627869
	speed: 0.0254s/iter; left time: 587.2577s
Epoch: 1 cost time: 6.476567029953003
Epoch: 1, Steps: 233 Train Loss: 29.4862 (Forecasting Loss:1.0137 + XiCon Loss:2.8473 x Lambda(10.0)), Vali MSE Loss: 1.8334 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833390).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.7188091
	speed: 0.0296s/iter; left time: 680.6359s
	iters: 200, epoch: 2 | loss: 29.6498623
	speed: 0.0256s/iter; left time: 585.1893s
Epoch: 2 cost time: 6.419261932373047
Epoch: 2, Steps: 233 Train Loss: 28.9781 (Forecasting Loss:0.6538 + XiCon Loss:2.8324 x Lambda(10.0)), Vali MSE Loss: 1.1240 Test MSE Loss: 1.1464
Validation loss decreased (1.833390 --> 1.123998).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.0986862
	speed: 0.0292s/iter; left time: 664.0853s
	iters: 200, epoch: 3 | loss: 28.2572575
	speed: 0.0262s/iter; left time: 592.0943s
Epoch: 3 cost time: 6.429387331008911
Epoch: 3, Steps: 233 Train Loss: 28.6595 (Forecasting Loss:0.5896 + XiCon Loss:2.8070 x Lambda(10.0)), Vali MSE Loss: 1.1047 Test MSE Loss: 1.1382
Validation loss decreased (1.123998 --> 1.104669).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 28.6116714
	speed: 0.0292s/iter; left time: 655.9807s
	iters: 200, epoch: 4 | loss: 28.6526241
	speed: 0.0256s/iter; left time: 573.6595s
Epoch: 4 cost time: 6.355276346206665
Epoch: 4, Steps: 233 Train Loss: 28.5471 (Forecasting Loss:0.5817 + XiCon Loss:2.7965 x Lambda(10.0)), Vali MSE Loss: 1.0985 Test MSE Loss: 1.1361
Validation loss decreased (1.104669 --> 1.098493).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 27.9057674
	speed: 0.0289s/iter; left time: 643.6676s
	iters: 200, epoch: 5 | loss: 27.9786777
	speed: 0.0259s/iter; left time: 575.2344s
Epoch: 5 cost time: 6.3546435832977295
Epoch: 5, Steps: 233 Train Loss: 28.4520 (Forecasting Loss:0.5786 + XiCon Loss:2.7873 x Lambda(10.0)), Vali MSE Loss: 1.0953 Test MSE Loss: 1.1352
Validation loss decreased (1.098493 --> 1.095323).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.9107571
	speed: 0.0295s/iter; left time: 650.1568s
	iters: 200, epoch: 6 | loss: 28.3197384
	speed: 0.0256s/iter; left time: 562.6106s
Epoch: 6 cost time: 6.407480478286743
Epoch: 6, Steps: 233 Train Loss: 28.4664 (Forecasting Loss:0.5772 + XiCon Loss:2.7889 x Lambda(10.0)), Vali MSE Loss: 1.0940 Test MSE Loss: 1.1349
Validation loss decreased (1.095323 --> 1.093980).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.8205242
	speed: 0.0294s/iter; left time: 640.7949s
	iters: 200, epoch: 7 | loss: 28.0703316
	speed: 0.0258s/iter; left time: 560.6625s
Epoch: 7 cost time: 6.410630464553833
Epoch: 7, Steps: 233 Train Loss: 28.4005 (Forecasting Loss:0.5765 + XiCon Loss:2.7824 x Lambda(10.0)), Vali MSE Loss: 1.0932 Test MSE Loss: 1.1348
Validation loss decreased (1.093980 --> 1.093224).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.2712631
	speed: 0.0291s/iter; left time: 627.0892s
	iters: 200, epoch: 8 | loss: 28.1836128
	speed: 0.0261s/iter; left time: 560.8319s
Epoch: 8 cost time: 6.426229000091553
Epoch: 8, Steps: 233 Train Loss: 28.3841 (Forecasting Loss:0.5761 + XiCon Loss:2.7808 x Lambda(10.0)), Vali MSE Loss: 1.0928 Test MSE Loss: 1.1347
Validation loss decreased (1.093224 --> 1.092848).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 27.7567902
	speed: 0.0303s/iter; left time: 646.8733s
	iters: 200, epoch: 9 | loss: 28.5855618
	speed: 0.0259s/iter; left time: 550.0311s
Epoch: 9 cost time: 6.472075939178467
Epoch: 9, Steps: 233 Train Loss: 28.4675 (Forecasting Loss:0.5759 + XiCon Loss:2.7892 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
Validation loss decreased (1.092848 --> 1.092564).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.3605270
	speed: 0.0292s/iter; left time: 617.2493s
	iters: 200, epoch: 10 | loss: 28.5523930
	speed: 0.0257s/iter; left time: 539.2675s
Epoch: 10 cost time: 6.392838954925537
Epoch: 10, Steps: 233 Train Loss: 28.4220 (Forecasting Loss:0.5759 + XiCon Loss:2.7846 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 27.9460430
	speed: 0.0297s/iter; left time: 619.7913s
	iters: 200, epoch: 11 | loss: 28.6132946
	speed: 0.0261s/iter; left time: 542.1925s
Epoch: 11 cost time: 6.463890314102173
Epoch: 11, Steps: 233 Train Loss: 28.3743 (Forecasting Loss:0.5759 + XiCon Loss:2.7798 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
Validation loss decreased (1.092564 --> 1.092500).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 28.8677101
	speed: 0.0295s/iter; left time: 609.2036s
	iters: 200, epoch: 12 | loss: 29.4684315
	speed: 0.0256s/iter; left time: 524.8182s
Epoch: 12 cost time: 6.393392562866211
Epoch: 12, Steps: 233 Train Loss: 28.3764 (Forecasting Loss:0.5757 + XiCon Loss:2.7801 x Lambda(10.0)), Vali MSE Loss: 1.0927 Test MSE Loss: 1.1346
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 28.1707211
	speed: 0.0295s/iter; left time: 601.5938s
	iters: 200, epoch: 13 | loss: 28.0225239
	speed: 0.0256s/iter; left time: 519.0954s
Epoch: 13 cost time: 6.360230922698975
Epoch: 13, Steps: 233 Train Loss: 28.4048 (Forecasting Loss:0.5758 + XiCon Loss:2.7829 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.2253876
	speed: 0.0295s/iter; left time: 594.6063s
	iters: 200, epoch: 14 | loss: 28.9526005
	speed: 0.0272s/iter; left time: 546.4797s
Epoch: 14 cost time: 6.568437337875366
Epoch: 14, Steps: 233 Train Loss: 28.3696 (Forecasting Loss:0.5757 + XiCon Loss:2.7794 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.5690632
	speed: 0.0297s/iter; left time: 592.7606s
	iters: 200, epoch: 15 | loss: 28.2481995
	speed: 0.0267s/iter; left time: 530.2312s
Epoch: 15 cost time: 6.4729814529418945
Epoch: 15, Steps: 233 Train Loss: 28.3801 (Forecasting Loss:0.5758 + XiCon Loss:2.7804 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 28.2192574
	speed: 0.0310s/iter; left time: 610.4247s
	iters: 200, epoch: 16 | loss: 28.6620064
	speed: 0.0250s/iter; left time: 490.9074s
Epoch: 16 cost time: 6.464266061782837
Epoch: 16, Steps: 233 Train Loss: 28.4017 (Forecasting Loss:0.5758 + XiCon Loss:2.7826 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.7226315
	speed: 0.0281s/iter; left time: 547.1021s
	iters: 200, epoch: 17 | loss: 28.2826767
	speed: 0.0255s/iter; left time: 493.9136s
Epoch: 17 cost time: 6.212740182876587
Epoch: 17, Steps: 233 Train Loss: 28.4036 (Forecasting Loss:0.5758 + XiCon Loss:2.7828 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
Validation loss decreased (1.092500 --> 1.092463).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 27.7032127
	speed: 0.0289s/iter; left time: 556.5977s
	iters: 200, epoch: 18 | loss: 28.1798363
	speed: 0.0253s/iter; left time: 484.1081s
Epoch: 18 cost time: 6.270553112030029
Epoch: 18, Steps: 233 Train Loss: 28.3558 (Forecasting Loss:0.5758 + XiCon Loss:2.7780 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.7234421
	speed: 0.0280s/iter; left time: 531.8014s
	iters: 200, epoch: 19 | loss: 28.8224678
	speed: 0.0250s/iter; left time: 472.6408s
Epoch: 19 cost time: 6.152587413787842
Epoch: 19, Steps: 233 Train Loss: 28.4049 (Forecasting Loss:0.5758 + XiCon Loss:2.7829 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.1441364
	speed: 0.0280s/iter; left time: 526.4513s
	iters: 200, epoch: 20 | loss: 28.9694004
	speed: 0.0249s/iter; left time: 464.8180s
Epoch: 20 cost time: 6.160355567932129
Epoch: 20, Steps: 233 Train Loss: 28.3822 (Forecasting Loss:0.5758 + XiCon Loss:2.7806 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 29.0288029
	speed: 0.0281s/iter; left time: 520.7694s
	iters: 200, epoch: 21 | loss: 28.8852425
	speed: 0.0249s/iter; left time: 459.2477s
Epoch: 21 cost time: 6.139839172363281
Epoch: 21, Steps: 233 Train Loss: 28.4386 (Forecasting Loss:0.5757 + XiCon Loss:2.7863 x Lambda(10.0)), Vali MSE Loss: 1.0924 Test MSE Loss: 1.1346
Validation loss decreased (1.092463 --> 1.092359).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.2882462
	speed: 0.0287s/iter; left time: 525.0699s
	iters: 200, epoch: 22 | loss: 28.8605957
	speed: 0.0247s/iter; left time: 448.8605s
Epoch: 22 cost time: 6.168696165084839
Epoch: 22, Steps: 233 Train Loss: 28.4090 (Forecasting Loss:0.5757 + XiCon Loss:2.7833 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 28.7486343
	speed: 0.0279s/iter; left time: 505.1243s
	iters: 200, epoch: 23 | loss: 28.4861755
	speed: 0.0256s/iter; left time: 460.6528s
Epoch: 23 cost time: 6.359544038772583
Epoch: 23, Steps: 233 Train Loss: 28.3659 (Forecasting Loss:0.5758 + XiCon Loss:2.7790 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.2291641
	speed: 0.0287s/iter; left time: 511.6683s
	iters: 200, epoch: 24 | loss: 28.0325584
	speed: 0.0262s/iter; left time: 464.4725s
Epoch: 24 cost time: 6.414722204208374
Epoch: 24, Steps: 233 Train Loss: 28.3936 (Forecasting Loss:0.5758 + XiCon Loss:2.7818 x Lambda(10.0)), Vali MSE Loss: 1.0928 Test MSE Loss: 1.1346
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 28.0914669
	speed: 0.0291s/iter; left time: 512.8051s
	iters: 200, epoch: 25 | loss: 28.9719543
	speed: 0.0261s/iter; left time: 456.7694s
Epoch: 25 cost time: 6.418256759643555
Epoch: 25, Steps: 233 Train Loss: 28.3677 (Forecasting Loss:0.5758 + XiCon Loss:2.7792 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 27.8752995
	speed: 0.0291s/iter; left time: 506.3286s
	iters: 200, epoch: 26 | loss: 28.2275352
	speed: 0.0260s/iter; left time: 449.2054s
Epoch: 26 cost time: 6.399051666259766
Epoch: 26, Steps: 233 Train Loss: 28.3486 (Forecasting Loss:0.5758 + XiCon Loss:2.7773 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 28.2763958
	speed: 0.0304s/iter; left time: 521.8585s
	iters: 200, epoch: 27 | loss: 28.1321316
	speed: 0.0263s/iter; left time: 447.4874s
Epoch: 27 cost time: 6.557202577590942
Epoch: 27, Steps: 233 Train Loss: 28.3187 (Forecasting Loss:0.5757 + XiCon Loss:2.7743 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 27.6966209
	speed: 0.0293s/iter; left time: 496.2618s
	iters: 200, epoch: 28 | loss: 28.5004616
	speed: 0.0261s/iter; left time: 439.0180s
Epoch: 28 cost time: 6.436108112335205
Epoch: 28, Steps: 233 Train Loss: 28.4035 (Forecasting Loss:0.5758 + XiCon Loss:2.7828 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 28.1003475
	speed: 0.0293s/iter; left time: 488.0368s
	iters: 200, epoch: 29 | loss: 28.2978535
	speed: 0.0275s/iter; left time: 455.4660s
Epoch: 29 cost time: 6.601738691329956
Epoch: 29, Steps: 233 Train Loss: 28.4340 (Forecasting Loss:0.5758 + XiCon Loss:2.7858 x Lambda(10.0)), Vali MSE Loss: 1.0926 Test MSE Loss: 1.1346
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 29.1583328
	speed: 0.0301s/iter; left time: 494.9347s
	iters: 200, epoch: 30 | loss: 27.8408394
	speed: 0.0258s/iter; left time: 421.2569s
Epoch: 30 cost time: 6.574904918670654
Epoch: 30, Steps: 233 Train Loss: 28.3886 (Forecasting Loss:0.5757 + XiCon Loss:2.7813 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 28.8754463
	speed: 0.0287s/iter; left time: 465.4013s
	iters: 200, epoch: 31 | loss: 28.1097336
	speed: 0.0255s/iter; left time: 410.6969s
Epoch: 31 cost time: 6.339876413345337
Epoch: 31, Steps: 233 Train Loss: 28.3973 (Forecasting Loss:0.5758 + XiCon Loss:2.7822 x Lambda(10.0)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1346
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3919663429260254, mae:0.8772372007369995, mape:6.123174667358398, mspe:4496.677734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.3442
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 29.5990200
	speed: 0.0323s/iter; left time: 750.5127s
	iters: 200, epoch: 1 | loss: 29.1146545
	speed: 0.0293s/iter; left time: 677.3722s
Epoch: 1 cost time: 7.138179779052734
Epoch: 1, Steps: 233 Train Loss: 29.6964 (Forecasting Loss:1.0278 + XiCon Loss:2.8669 x Lambda(10.0)), Vali MSE Loss: 1.8646 Test MSE Loss: 1.2526
Validation loss decreased (inf --> 1.864636).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 28.6794319
	speed: 0.0328s/iter; left time: 753.1611s
	iters: 200, epoch: 2 | loss: 29.0727520
	speed: 0.0299s/iter; left time: 683.1464s
Epoch: 2 cost time: 7.297671318054199
Epoch: 2, Steps: 233 Train Loss: 29.1168 (Forecasting Loss:0.6549 + XiCon Loss:2.8462 x Lambda(10.0)), Vali MSE Loss: 1.1226 Test MSE Loss: 1.1474
Validation loss decreased (1.864636 --> 1.122592).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 27.9975681
	speed: 0.0330s/iter; left time: 751.0894s
	iters: 200, epoch: 3 | loss: 28.8585472
	speed: 0.0303s/iter; left time: 686.2807s
Epoch: 3 cost time: 7.34821629524231
Epoch: 3, Steps: 233 Train Loss: 28.7319 (Forecasting Loss:0.5900 + XiCon Loss:2.8142 x Lambda(10.0)), Vali MSE Loss: 1.1042 Test MSE Loss: 1.1402
Validation loss decreased (1.122592 --> 1.104165).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 28.6254139
	speed: 0.0338s/iter; left time: 759.9275s
	iters: 200, epoch: 4 | loss: 28.8458252
	speed: 0.0304s/iter; left time: 681.2771s
Epoch: 4 cost time: 7.404328107833862
Epoch: 4, Steps: 233 Train Loss: 28.4203 (Forecasting Loss:0.5822 + XiCon Loss:2.7838 x Lambda(10.0)), Vali MSE Loss: 1.0976 Test MSE Loss: 1.1380
Validation loss decreased (1.104165 --> 1.097552).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 27.3923569
	speed: 0.0319s/iter; left time: 711.0917s
	iters: 200, epoch: 5 | loss: 28.5939827
	speed: 0.0297s/iter; left time: 657.7894s
Epoch: 5 cost time: 7.19762110710144
Epoch: 5, Steps: 233 Train Loss: 28.2466 (Forecasting Loss:0.5792 + XiCon Loss:2.7667 x Lambda(10.0)), Vali MSE Loss: 1.0948 Test MSE Loss: 1.1376
Validation loss decreased (1.097552 --> 1.094841).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.9999104
	speed: 0.0322s/iter; left time: 709.4099s
	iters: 200, epoch: 6 | loss: 28.5223484
	speed: 0.0300s/iter; left time: 658.2170s
Epoch: 6 cost time: 7.1786181926727295
Epoch: 6, Steps: 233 Train Loss: 28.2173 (Forecasting Loss:0.5778 + XiCon Loss:2.7640 x Lambda(10.0)), Vali MSE Loss: 1.0936 Test MSE Loss: 1.1373
Validation loss decreased (1.094841 --> 1.093556).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.7331009
	speed: 0.0330s/iter; left time: 720.2200s
	iters: 200, epoch: 7 | loss: 28.3652115
	speed: 0.0295s/iter; left time: 639.9713s
Epoch: 7 cost time: 7.30768609046936
Epoch: 7, Steps: 233 Train Loss: 28.1252 (Forecasting Loss:0.5771 + XiCon Loss:2.7548 x Lambda(10.0)), Vali MSE Loss: 1.0928 Test MSE Loss: 1.1373
Validation loss decreased (1.093556 --> 1.092835).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 27.8459129
	speed: 0.0326s/iter; left time: 703.3084s
	iters: 200, epoch: 8 | loss: 28.7489567
	speed: 0.0296s/iter; left time: 635.4695s
Epoch: 8 cost time: 7.205225467681885
Epoch: 8, Steps: 233 Train Loss: 28.0993 (Forecasting Loss:0.5768 + XiCon Loss:2.7522 x Lambda(10.0)), Vali MSE Loss: 1.0927 Test MSE Loss: 1.1372
Validation loss decreased (1.092835 --> 1.092665).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 28.1388702
	speed: 0.0320s/iter; left time: 682.8363s
	iters: 200, epoch: 9 | loss: 28.2981701
	speed: 0.0304s/iter; left time: 645.0550s
Epoch: 9 cost time: 7.2179131507873535
Epoch: 9, Steps: 233 Train Loss: 28.0888 (Forecasting Loss:0.5765 + XiCon Loss:2.7512 x Lambda(10.0)), Vali MSE Loss: 1.0923 Test MSE Loss: 1.1372
Validation loss decreased (1.092665 --> 1.092266).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 27.9980335
	speed: 0.0326s/iter; left time: 688.5225s
	iters: 200, epoch: 10 | loss: 28.8340874
	speed: 0.0303s/iter; left time: 635.8353s
Epoch: 10 cost time: 7.294798374176025
Epoch: 10, Steps: 233 Train Loss: 28.1184 (Forecasting Loss:0.5764 + XiCon Loss:2.7542 x Lambda(10.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
Validation loss decreased (1.092266 --> 1.092160).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 27.2890072
	speed: 0.0325s/iter; left time: 677.4520s
	iters: 200, epoch: 11 | loss: 28.2908859
	speed: 0.0301s/iter; left time: 625.6081s
Epoch: 11 cost time: 7.308566570281982
Epoch: 11, Steps: 233 Train Loss: 28.1224 (Forecasting Loss:0.5763 + XiCon Loss:2.7546 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
Validation loss decreased (1.092160 --> 1.092085).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 27.6140804
	speed: 0.0327s/iter; left time: 675.0990s
	iters: 200, epoch: 12 | loss: 27.4608440
	speed: 0.0300s/iter; left time: 615.5611s
Epoch: 12 cost time: 7.250201940536499
Epoch: 12, Steps: 233 Train Loss: 28.1361 (Forecasting Loss:0.5763 + XiCon Loss:2.7560 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 27.7921791
	speed: 0.0328s/iter; left time: 668.4752s
	iters: 200, epoch: 13 | loss: 28.1735210
	speed: 0.0296s/iter; left time: 601.4505s
Epoch: 13 cost time: 7.2416746616363525
Epoch: 13, Steps: 233 Train Loss: 28.0724 (Forecasting Loss:0.5763 + XiCon Loss:2.7496 x Lambda(10.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 27.0414181
	speed: 0.0324s/iter; left time: 653.2994s
	iters: 200, epoch: 14 | loss: 28.5648632
	speed: 0.0295s/iter; left time: 591.9516s
Epoch: 14 cost time: 7.19012188911438
Epoch: 14, Steps: 233 Train Loss: 28.0983 (Forecasting Loss:0.5763 + XiCon Loss:2.7522 x Lambda(10.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 28.7459412
	speed: 0.0328s/iter; left time: 654.7651s
	iters: 200, epoch: 15 | loss: 27.9712715
	speed: 0.0296s/iter; left time: 587.1489s
Epoch: 15 cost time: 7.241042137145996
Epoch: 15, Steps: 233 Train Loss: 28.1029 (Forecasting Loss:0.5763 + XiCon Loss:2.7527 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 27.1961708
	speed: 0.0326s/iter; left time: 642.2147s
	iters: 200, epoch: 16 | loss: 27.6822491
	speed: 0.0307s/iter; left time: 602.0890s
Epoch: 16 cost time: 7.3819708824157715
Epoch: 16, Steps: 233 Train Loss: 28.1117 (Forecasting Loss:0.5763 + XiCon Loss:2.7535 x Lambda(10.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1372
Validation loss decreased (1.092085 --> 1.091851).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.1742859
	speed: 0.0321s/iter; left time: 624.1837s
	iters: 200, epoch: 17 | loss: 28.6924267
	speed: 0.0302s/iter; left time: 584.5478s
Epoch: 17 cost time: 7.173776865005493
Epoch: 17, Steps: 233 Train Loss: 28.1260 (Forecasting Loss:0.5763 + XiCon Loss:2.7550 x Lambda(10.0)), Vali MSE Loss: 1.0918 Test MSE Loss: 1.1372
Validation loss decreased (1.091851 --> 1.091835).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 27.3447838
	speed: 0.0323s/iter; left time: 621.7535s
	iters: 200, epoch: 18 | loss: 28.3042431
	speed: 0.0306s/iter; left time: 585.1104s
Epoch: 18 cost time: 7.311912298202515
Epoch: 18, Steps: 233 Train Loss: 28.1134 (Forecasting Loss:0.5763 + XiCon Loss:2.7537 x Lambda(10.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.1827812
	speed: 0.0313s/iter; left time: 594.8791s
	iters: 200, epoch: 19 | loss: 28.0766716
	speed: 0.0302s/iter; left time: 570.8157s
Epoch: 19 cost time: 7.135481595993042
Epoch: 19, Steps: 233 Train Loss: 28.1059 (Forecasting Loss:0.5763 + XiCon Loss:2.7530 x Lambda(10.0)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.8804913
	speed: 0.0319s/iter; left time: 598.4703s
	iters: 200, epoch: 20 | loss: 28.4217377
	speed: 0.0297s/iter; left time: 554.6910s
Epoch: 20 cost time: 7.171420574188232
Epoch: 20, Steps: 233 Train Loss: 28.1298 (Forecasting Loss:0.5763 + XiCon Loss:2.7554 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.9504337
	speed: 0.0324s/iter; left time: 599.9377s
	iters: 200, epoch: 21 | loss: 28.6081200
	speed: 0.0299s/iter; left time: 551.8201s
Epoch: 21 cost time: 7.255069971084595
Epoch: 21, Steps: 233 Train Loss: 28.0379 (Forecasting Loss:0.5763 + XiCon Loss:2.7462 x Lambda(10.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 27.6725254
	speed: 0.0323s/iter; left time: 590.9467s
	iters: 200, epoch: 22 | loss: 28.5280457
	speed: 0.0300s/iter; left time: 546.5202s
Epoch: 22 cost time: 7.241461753845215
Epoch: 22, Steps: 233 Train Loss: 28.0800 (Forecasting Loss:0.5763 + XiCon Loss:2.7504 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 28.5719509
	speed: 0.0340s/iter; left time: 614.1565s
	iters: 200, epoch: 23 | loss: 28.2055454
	speed: 0.0304s/iter; left time: 547.1231s
Epoch: 23 cost time: 7.485841751098633
Epoch: 23, Steps: 233 Train Loss: 28.0777 (Forecasting Loss:0.5762 + XiCon Loss:2.7501 x Lambda(10.0)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1372
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 28.3194542
	speed: 0.0339s/iter; left time: 605.2242s
	iters: 200, epoch: 24 | loss: 27.4248066
	speed: 0.0305s/iter; left time: 540.8241s
Epoch: 24 cost time: 7.443836450576782
Epoch: 24, Steps: 233 Train Loss: 28.0380 (Forecasting Loss:0.5763 + XiCon Loss:2.7462 x Lambda(10.0)), Vali MSE Loss: 1.0920 Test MSE Loss: 1.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 28.3017120
	speed: 0.0327s/iter; left time: 576.4655s
	iters: 200, epoch: 25 | loss: 28.0980072
	speed: 0.0293s/iter; left time: 513.8083s
Epoch: 25 cost time: 7.259217977523804
Epoch: 25, Steps: 233 Train Loss: 28.0987 (Forecasting Loss:0.5763 + XiCon Loss:2.7522 x Lambda(10.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 28.0778046
	speed: 0.0327s/iter; left time: 567.3764s
	iters: 200, epoch: 26 | loss: 27.8208618
	speed: 0.0300s/iter; left time: 518.8320s
Epoch: 26 cost time: 7.2917399406433105
Epoch: 26, Steps: 233 Train Loss: 28.1263 (Forecasting Loss:0.5762 + XiCon Loss:2.7550 x Lambda(10.0)), Vali MSE Loss: 1.0922 Test MSE Loss: 1.1372
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 28.3644047
	speed: 0.0326s/iter; left time: 558.7055s
	iters: 200, epoch: 27 | loss: 27.9471474
	speed: 0.0296s/iter; left time: 504.4131s
Epoch: 27 cost time: 7.251140832901001
Epoch: 27, Steps: 233 Train Loss: 28.0695 (Forecasting Loss:0.5763 + XiCon Loss:2.7493 x Lambda(10.0)), Vali MSE Loss: 1.0923 Test MSE Loss: 1.1372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3954497575759888, mae:0.8788800239562988, mape:6.141735076904297, mspe:4534.533203125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.4754
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 29.8694992
	speed: 0.0303s/iter; left time: 702.0482s
	iters: 200, epoch: 1 | loss: 30.4046097
	speed: 0.0287s/iter; left time: 661.8594s
Epoch: 1 cost time: 6.8846869468688965
Epoch: 1, Steps: 233 Train Loss: 29.4313 (Forecasting Loss:1.0269 + XiCon Loss:2.8404 x Lambda(10.0)), Vali MSE Loss: 1.8522 Test MSE Loss: 1.2640
Validation loss decreased (inf --> 1.852179).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 29.1418266
	speed: 0.0306s/iter; left time: 701.7414s
	iters: 200, epoch: 2 | loss: 28.6692963
	speed: 0.0291s/iter; left time: 664.4092s
Epoch: 2 cost time: 6.967556476593018
Epoch: 2, Steps: 233 Train Loss: 28.9675 (Forecasting Loss:0.6516 + XiCon Loss:2.8316 x Lambda(10.0)), Vali MSE Loss: 1.1136 Test MSE Loss: 1.1474
Validation loss decreased (1.852179 --> 1.113558).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 28.5417786
	speed: 0.0318s/iter; left time: 723.8377s
	iters: 200, epoch: 3 | loss: 28.8068123
	speed: 0.0284s/iter; left time: 641.9976s
Epoch: 3 cost time: 6.975123882293701
Epoch: 3, Steps: 233 Train Loss: 28.7074 (Forecasting Loss:0.5873 + XiCon Loss:2.8120 x Lambda(10.0)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1409
Validation loss decreased (1.113558 --> 1.091053).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 29.0941486
	speed: 0.0301s/iter; left time: 677.7370s
	iters: 200, epoch: 4 | loss: 28.6874771
	speed: 0.0282s/iter; left time: 632.3457s
Epoch: 4 cost time: 6.794657945632935
Epoch: 4, Steps: 233 Train Loss: 28.6149 (Forecasting Loss:0.5795 + XiCon Loss:2.8035 x Lambda(10.0)), Vali MSE Loss: 1.0831 Test MSE Loss: 1.1392
Validation loss decreased (1.091053 --> 1.083137).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 28.2496624
	speed: 0.0303s/iter; left time: 675.3378s
	iters: 200, epoch: 5 | loss: 28.1873398
	speed: 0.0280s/iter; left time: 620.1053s
Epoch: 5 cost time: 6.732132911682129
Epoch: 5, Steps: 233 Train Loss: 28.5993 (Forecasting Loss:0.5764 + XiCon Loss:2.8023 x Lambda(10.0)), Vali MSE Loss: 1.0798 Test MSE Loss: 1.1387
Validation loss decreased (1.083137 --> 1.079804).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 29.8705292
	speed: 0.0304s/iter; left time: 669.1994s
	iters: 200, epoch: 6 | loss: 28.5840740
	speed: 0.0276s/iter; left time: 604.8595s
Epoch: 6 cost time: 6.880440950393677
Epoch: 6, Steps: 233 Train Loss: 28.5769 (Forecasting Loss:0.5749 + XiCon Loss:2.8002 x Lambda(10.0)), Vali MSE Loss: 1.0782 Test MSE Loss: 1.1382
Validation loss decreased (1.079804 --> 1.078228).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 28.9205265
	speed: 0.0302s/iter; left time: 658.3490s
	iters: 200, epoch: 7 | loss: 28.5705147
	speed: 0.0285s/iter; left time: 618.1680s
Epoch: 7 cost time: 6.817652702331543
Epoch: 7, Steps: 233 Train Loss: 28.5837 (Forecasting Loss:0.5744 + XiCon Loss:2.8009 x Lambda(10.0)), Vali MSE Loss: 1.0773 Test MSE Loss: 1.1380
Validation loss decreased (1.078228 --> 1.077338).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 28.2543087
	speed: 0.0295s/iter; left time: 637.3569s
	iters: 200, epoch: 8 | loss: 28.2853527
	speed: 0.0278s/iter; left time: 597.1247s
Epoch: 8 cost time: 6.716583728790283
Epoch: 8, Steps: 233 Train Loss: 28.5418 (Forecasting Loss:0.5739 + XiCon Loss:2.7968 x Lambda(10.0)), Vali MSE Loss: 1.0769 Test MSE Loss: 1.1380
Validation loss decreased (1.077338 --> 1.076923).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 28.8981075
	speed: 0.0297s/iter; left time: 634.6766s
	iters: 200, epoch: 9 | loss: 28.1694183
	speed: 0.0276s/iter; left time: 586.7362s
Epoch: 9 cost time: 6.645932674407959
Epoch: 9, Steps: 233 Train Loss: 28.5567 (Forecasting Loss:0.5737 + XiCon Loss:2.7983 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
Validation loss decreased (1.076923 --> 1.076526).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 28.8161526
	speed: 0.0318s/iter; left time: 671.3536s
	iters: 200, epoch: 10 | loss: 28.2432842
	speed: 0.0293s/iter; left time: 616.2676s
Epoch: 10 cost time: 7.110203981399536
Epoch: 10, Steps: 233 Train Loss: 28.5413 (Forecasting Loss:0.5735 + XiCon Loss:2.7968 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 29.6974182
	speed: 0.0305s/iter; left time: 637.3564s
	iters: 200, epoch: 11 | loss: 28.3117180
	speed: 0.0289s/iter; left time: 601.2903s
Epoch: 11 cost time: 6.92072868347168
Epoch: 11, Steps: 233 Train Loss: 28.5482 (Forecasting Loss:0.5735 + XiCon Loss:2.7975 x Lambda(10.0)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1379
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 28.3680019
	speed: 0.0308s/iter; left time: 634.9786s
	iters: 200, epoch: 12 | loss: 28.3223381
	speed: 0.0290s/iter; left time: 595.5262s
Epoch: 12 cost time: 6.948442459106445
Epoch: 12, Steps: 233 Train Loss: 28.5560 (Forecasting Loss:0.5736 + XiCon Loss:2.7982 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
Validation loss decreased (1.076526 --> 1.076501).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 28.7403011
	speed: 0.0312s/iter; left time: 635.7800s
	iters: 200, epoch: 13 | loss: 28.5436935
	speed: 0.0291s/iter; left time: 589.9191s
Epoch: 13 cost time: 7.056159734725952
Epoch: 13, Steps: 233 Train Loss: 28.5003 (Forecasting Loss:0.5735 + XiCon Loss:2.7927 x Lambda(10.0)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 28.6477757
	speed: 0.0309s/iter; left time: 622.5954s
	iters: 200, epoch: 14 | loss: 28.8993568
	speed: 0.0290s/iter; left time: 582.7560s
Epoch: 14 cost time: 6.965336322784424
Epoch: 14, Steps: 233 Train Loss: 28.5904 (Forecasting Loss:0.5735 + XiCon Loss:2.8017 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
Validation loss decreased (1.076501 --> 1.076486).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 27.8388214
	speed: 0.0314s/iter; left time: 625.6588s
	iters: 200, epoch: 15 | loss: 28.2391891
	speed: 0.0284s/iter; left time: 563.5154s
Epoch: 15 cost time: 6.9860758781433105
Epoch: 15, Steps: 233 Train Loss: 28.5355 (Forecasting Loss:0.5734 + XiCon Loss:2.7962 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 28.7597733
	speed: 0.0310s/iter; left time: 610.6114s
	iters: 200, epoch: 16 | loss: 28.2386971
	speed: 0.0285s/iter; left time: 558.6751s
Epoch: 16 cost time: 6.941898345947266
Epoch: 16, Steps: 233 Train Loss: 28.5807 (Forecasting Loss:0.5735 + XiCon Loss:2.8007 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
Validation loss decreased (1.076486 --> 1.076464).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 28.7480755
	speed: 0.0314s/iter; left time: 612.2274s
	iters: 200, epoch: 17 | loss: 28.4135685
	speed: 0.0287s/iter; left time: 556.6136s
Epoch: 17 cost time: 7.050862789154053
Epoch: 17, Steps: 233 Train Loss: 28.5175 (Forecasting Loss:0.5734 + XiCon Loss:2.7944 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 28.3125877
	speed: 0.0302s/iter; left time: 580.9076s
	iters: 200, epoch: 18 | loss: 28.4194756
	speed: 0.0289s/iter; left time: 552.5856s
Epoch: 18 cost time: 6.915977478027344
Epoch: 18, Steps: 233 Train Loss: 28.5508 (Forecasting Loss:0.5735 + XiCon Loss:2.7977 x Lambda(10.0)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1379
Validation loss decreased (1.076464 --> 1.076423).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 28.8087959
	speed: 0.0315s/iter; left time: 598.3808s
	iters: 200, epoch: 19 | loss: 29.0466042
	speed: 0.0294s/iter; left time: 556.5671s
Epoch: 19 cost time: 7.025497913360596
Epoch: 19, Steps: 233 Train Loss: 28.5667 (Forecasting Loss:0.5734 + XiCon Loss:2.7993 x Lambda(10.0)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1379
Validation loss decreased (1.076423 --> 1.076353).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 28.7505455
	speed: 0.0307s/iter; left time: 576.6829s
	iters: 200, epoch: 20 | loss: 29.3140850
	speed: 0.0296s/iter; left time: 553.1559s
Epoch: 20 cost time: 7.100336790084839
Epoch: 20, Steps: 233 Train Loss: 28.5110 (Forecasting Loss:0.5734 + XiCon Loss:2.7938 x Lambda(10.0)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 28.5774174
	speed: 0.0322s/iter; left time: 596.7423s
	iters: 200, epoch: 21 | loss: 29.0507507
	speed: 0.0289s/iter; left time: 532.2417s
Epoch: 21 cost time: 7.098280668258667
Epoch: 21, Steps: 233 Train Loss: 28.5699 (Forecasting Loss:0.5734 + XiCon Loss:2.7996 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 28.0749874
	speed: 0.0308s/iter; left time: 563.6546s
	iters: 200, epoch: 22 | loss: 28.3971100
	speed: 0.0296s/iter; left time: 539.2761s
Epoch: 22 cost time: 7.051182985305786
Epoch: 22, Steps: 233 Train Loss: 28.5283 (Forecasting Loss:0.5734 + XiCon Loss:2.7955 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 29.0606461
	speed: 0.0311s/iter; left time: 562.9130s
	iters: 200, epoch: 23 | loss: 28.4204884
	speed: 0.0288s/iter; left time: 518.4960s
Epoch: 23 cost time: 7.002699136734009
Epoch: 23, Steps: 233 Train Loss: 28.5798 (Forecasting Loss:0.5735 + XiCon Loss:2.8006 x Lambda(10.0)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1379
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 29.0607529
	speed: 0.0307s/iter; left time: 547.0152s
	iters: 200, epoch: 24 | loss: 28.6496620
	speed: 0.0292s/iter; left time: 517.3388s
Epoch: 24 cost time: 6.94891881942749
Epoch: 24, Steps: 233 Train Loss: 28.5358 (Forecasting Loss:0.5735 + XiCon Loss:2.7962 x Lambda(10.0)), Vali MSE Loss: 1.0764 Test MSE Loss: 1.1379
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 29.1794586
	speed: 0.0315s/iter; left time: 554.9297s
	iters: 200, epoch: 25 | loss: 29.4614677
	speed: 0.0290s/iter; left time: 507.1273s
Epoch: 25 cost time: 7.058745384216309
Epoch: 25, Steps: 233 Train Loss: 28.5940 (Forecasting Loss:0.5734 + XiCon Loss:2.8021 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 28.5735474
	speed: 0.0314s/iter; left time: 546.3137s
	iters: 200, epoch: 26 | loss: 28.0371819
	speed: 0.0289s/iter; left time: 499.7962s
Epoch: 26 cost time: 7.0420143604278564
Epoch: 26, Steps: 233 Train Loss: 28.5677 (Forecasting Loss:0.5734 + XiCon Loss:2.7994 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 28.9852734
	speed: 0.0309s/iter; left time: 529.9046s
	iters: 200, epoch: 27 | loss: 27.8905907
	speed: 0.0290s/iter; left time: 494.5600s
Epoch: 27 cost time: 6.97852635383606
Epoch: 27, Steps: 233 Train Loss: 28.5969 (Forecasting Loss:0.5735 + XiCon Loss:2.8023 x Lambda(10.0)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1379
Validation loss decreased (1.076353 --> 1.076346).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 28.4167919
	speed: 0.0308s/iter; left time: 520.7105s
	iters: 200, epoch: 28 | loss: 27.7730007
	speed: 0.0285s/iter; left time: 478.3277s
Epoch: 28 cost time: 6.888869762420654
Epoch: 28, Steps: 233 Train Loss: 28.5773 (Forecasting Loss:0.5735 + XiCon Loss:2.8004 x Lambda(10.0)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1379
Validation loss decreased (1.076346 --> 1.076289).  Saving model ...
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 28.6263828
	speed: 0.0316s/iter; left time: 526.7993s
	iters: 200, epoch: 29 | loss: 28.6784325
	speed: 0.0290s/iter; left time: 480.2748s
Epoch: 29 cost time: 7.027408123016357
Epoch: 29, Steps: 233 Train Loss: 28.5042 (Forecasting Loss:0.5735 + XiCon Loss:2.7931 x Lambda(10.0)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 28.8892632
	speed: 0.0312s/iter; left time: 512.6064s
	iters: 200, epoch: 30 | loss: 29.0144024
	speed: 0.0283s/iter; left time: 462.6517s
Epoch: 30 cost time: 6.946210861206055
Epoch: 30, Steps: 233 Train Loss: 28.5859 (Forecasting Loss:0.5734 + XiCon Loss:2.8013 x Lambda(10.0)), Vali MSE Loss: 1.0761 Test MSE Loss: 1.1379
Validation loss decreased (1.076289 --> 1.076105).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 28.6244736
	speed: 0.0313s/iter; left time: 507.8659s
	iters: 200, epoch: 31 | loss: 28.5018444
	speed: 0.0294s/iter; left time: 473.6742s
Epoch: 31 cost time: 7.041379928588867
Epoch: 31, Steps: 233 Train Loss: 28.5393 (Forecasting Loss:0.5734 + XiCon Loss:2.7966 x Lambda(10.0)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 28.0678539
	speed: 0.0309s/iter; left time: 493.1870s
	iters: 200, epoch: 32 | loss: 29.5062370
	speed: 0.0292s/iter; left time: 464.0355s
Epoch: 32 cost time: 7.011422395706177
Epoch: 32, Steps: 233 Train Loss: 28.5392 (Forecasting Loss:0.5734 + XiCon Loss:2.7966 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 27.8387470
	speed: 0.0317s/iter; left time: 498.4006s
	iters: 200, epoch: 33 | loss: 28.6275883
	speed: 0.0286s/iter; left time: 447.4619s
Epoch: 33 cost time: 7.013315439224243
Epoch: 33, Steps: 233 Train Loss: 28.5566 (Forecasting Loss:0.5735 + XiCon Loss:2.7983 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 28.4963074
	speed: 0.0316s/iter; left time: 489.9705s
	iters: 200, epoch: 34 | loss: 28.2356453
	speed: 0.0291s/iter; left time: 448.9826s
Epoch: 34 cost time: 7.069761514663696
Epoch: 34, Steps: 233 Train Loss: 28.5608 (Forecasting Loss:0.5736 + XiCon Loss:2.7987 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 28.9114227
	speed: 0.0310s/iter; left time: 472.9084s
	iters: 200, epoch: 35 | loss: 28.1434212
	speed: 0.0286s/iter; left time: 433.3719s
Epoch: 35 cost time: 6.936663866043091
Epoch: 35, Steps: 233 Train Loss: 28.5262 (Forecasting Loss:0.5734 + XiCon Loss:2.7953 x Lambda(10.0)), Vali MSE Loss: 1.0766 Test MSE Loss: 1.1379
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 28.8894882
	speed: 0.0318s/iter; left time: 478.3374s
	iters: 200, epoch: 36 | loss: 29.5264015
	speed: 0.0290s/iter; left time: 433.9327s
Epoch: 36 cost time: 7.0371575355529785
Epoch: 36, Steps: 233 Train Loss: 28.4850 (Forecasting Loss:0.5736 + XiCon Loss:2.7911 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 28.6452904
	speed: 0.0302s/iter; left time: 447.9411s
	iters: 200, epoch: 37 | loss: 28.0532494
	speed: 0.0290s/iter; left time: 427.0640s
Epoch: 37 cost time: 6.95787501335144
Epoch: 37, Steps: 233 Train Loss: 28.5907 (Forecasting Loss:0.5735 + XiCon Loss:2.8017 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 28.6717358
	speed: 0.0308s/iter; left time: 449.5344s
	iters: 200, epoch: 38 | loss: 29.6163177
	speed: 0.0278s/iter; left time: 401.9029s
Epoch: 38 cost time: 6.887093544006348
Epoch: 38, Steps: 233 Train Loss: 28.5950 (Forecasting Loss:0.5735 + XiCon Loss:2.8022 x Lambda(10.0)), Vali MSE Loss: 1.0765 Test MSE Loss: 1.1379
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 28.3471527
	speed: 0.0307s/iter; left time: 440.9122s
	iters: 200, epoch: 39 | loss: 28.2264099
	speed: 0.0296s/iter; left time: 421.8445s
Epoch: 39 cost time: 6.965090036392212
Epoch: 39, Steps: 233 Train Loss: 28.5304 (Forecasting Loss:0.5736 + XiCon Loss:2.7957 x Lambda(10.0)), Vali MSE Loss: 1.0767 Test MSE Loss: 1.1379
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 28.7470016
	speed: 0.0305s/iter; left time: 430.6181s
	iters: 200, epoch: 40 | loss: 28.6537971
	speed: 0.0290s/iter; left time: 405.8438s
Epoch: 40 cost time: 6.955563306808472
Epoch: 40, Steps: 233 Train Loss: 28.5540 (Forecasting Loss:0.5734 + XiCon Loss:2.7981 x Lambda(10.0)), Vali MSE Loss: 1.0763 Test MSE Loss: 1.1379
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3966319561004639, mae:0.8791398406028748, mape:6.129054069519043, mspe:4517.0927734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3932+-0.00657, MAE:0.8776+-0.00334, MAPE:6.0980+-0.11378, MSPE:4459.8984+-193.27735, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.3371
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 28.9171314
	speed: 0.0539s/iter; left time: 1218.8149s
	iters: 200, epoch: 1 | loss: 27.3491859
	speed: 0.0499s/iter; left time: 1123.5145s
Epoch: 1 cost time: 11.748602151870728
Epoch: 1, Steps: 227 Train Loss: 27.9720 (Forecasting Loss:1.0262 + XiCon Loss:2.6946 x Lambda(10.0)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.936044).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 27.4748211
	speed: 0.0500s/iter; left time: 1117.9950s
	iters: 200, epoch: 2 | loss: 27.5850391
	speed: 0.0482s/iter; left time: 1074.6068s
Epoch: 2 cost time: 11.129837274551392
Epoch: 2, Steps: 227 Train Loss: 27.5037 (Forecasting Loss:0.6690 + XiCon Loss:2.6835 x Lambda(10.0)), Vali MSE Loss: 1.2115 Test MSE Loss: 1.2841
Validation loss decreased (1.936044 --> 1.211541).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 26.7613316
	speed: 0.0515s/iter; left time: 1141.2934s
	iters: 200, epoch: 3 | loss: 27.5263386
	speed: 0.0515s/iter; left time: 1136.4971s
Epoch: 3 cost time: 11.684982061386108
Epoch: 3, Steps: 227 Train Loss: 27.1523 (Forecasting Loss:0.6064 + XiCon Loss:2.6546 x Lambda(10.0)), Vali MSE Loss: 1.1895 Test MSE Loss: 1.2754
Validation loss decreased (1.211541 --> 1.189481).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 26.2128773
	speed: 0.0506s/iter; left time: 1109.3452s
	iters: 200, epoch: 4 | loss: 26.3964195
	speed: 0.0489s/iter; left time: 1067.6022s
Epoch: 4 cost time: 11.297181844711304
Epoch: 4, Steps: 227 Train Loss: 26.8744 (Forecasting Loss:0.5990 + XiCon Loss:2.6275 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2736
Validation loss decreased (1.189481 --> 1.184143).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.0409756
	speed: 0.0548s/iter; left time: 1188.9447s
	iters: 200, epoch: 5 | loss: 27.1638603
	speed: 0.0496s/iter; left time: 1070.0617s
Epoch: 5 cost time: 11.749717473983765
Epoch: 5, Steps: 227 Train Loss: 26.7343 (Forecasting Loss:0.5962 + XiCon Loss:2.6138 x Lambda(10.0)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2727
Validation loss decreased (1.184143 --> 1.181718).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 26.3769646
	speed: 0.0523s/iter; left time: 1121.8492s
	iters: 200, epoch: 6 | loss: 26.5042839
	speed: 0.0495s/iter; left time: 1058.5878s
Epoch: 6 cost time: 11.51168155670166
Epoch: 6, Steps: 227 Train Loss: 26.5871 (Forecasting Loss:0.5949 + XiCon Loss:2.5992 x Lambda(10.0)), Vali MSE Loss: 1.1802 Test MSE Loss: 1.2724
Validation loss decreased (1.181718 --> 1.180153).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 27.6245594
	speed: 0.0553s/iter; left time: 1174.2888s
	iters: 200, epoch: 7 | loss: 26.4566212
	speed: 0.0492s/iter; left time: 1039.0584s
Epoch: 7 cost time: 12.000901222229004
Epoch: 7, Steps: 227 Train Loss: 26.5940 (Forecasting Loss:0.5942 + XiCon Loss:2.6000 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2722
Validation loss decreased (1.180153 --> 1.179632).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 27.0122967
	speed: 0.0500s/iter; left time: 1051.6229s
	iters: 200, epoch: 8 | loss: 27.1026249
	speed: 0.0487s/iter; left time: 1019.2406s
Epoch: 8 cost time: 11.189242601394653
Epoch: 8, Steps: 227 Train Loss: 26.5671 (Forecasting Loss:0.5938 + XiCon Loss:2.5973 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2721
Validation loss decreased (1.179632 --> 1.178832).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.5560188
	speed: 0.0513s/iter; left time: 1067.2672s
	iters: 200, epoch: 9 | loss: 26.3028831
	speed: 0.0511s/iter; left time: 1056.7095s
Epoch: 9 cost time: 11.569814920425415
Epoch: 9, Steps: 227 Train Loss: 26.5879 (Forecasting Loss:0.5936 + XiCon Loss:2.5994 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 26.7592869
	speed: 0.0515s/iter; left time: 1057.9548s
	iters: 200, epoch: 10 | loss: 27.0775299
	speed: 0.0495s/iter; left time: 1013.2413s
Epoch: 10 cost time: 11.448745489120483
Epoch: 10, Steps: 227 Train Loss: 26.5464 (Forecasting Loss:0.5936 + XiCon Loss:2.5953 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 26.9237080
	speed: 0.0524s/iter; left time: 1065.2945s
	iters: 200, epoch: 11 | loss: 26.4046116
	speed: 0.0498s/iter; left time: 1007.0596s
Epoch: 11 cost time: 11.69231128692627
Epoch: 11, Steps: 227 Train Loss: 26.5778 (Forecasting Loss:0.5933 + XiCon Loss:2.5984 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.4888039
	speed: 0.0519s/iter; left time: 1042.8964s
	iters: 200, epoch: 12 | loss: 26.7189541
	speed: 0.0523s/iter; left time: 1045.2603s
Epoch: 12 cost time: 11.795206308364868
Epoch: 12, Steps: 227 Train Loss: 26.5530 (Forecasting Loss:0.5934 + XiCon Loss:2.5960 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
Validation loss decreased (1.178832 --> 1.178638).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.0505772
	speed: 0.0544s/iter; left time: 1081.9324s
	iters: 200, epoch: 13 | loss: 26.8151245
	speed: 0.0504s/iter; left time: 996.6553s
Epoch: 13 cost time: 11.861841678619385
Epoch: 13, Steps: 227 Train Loss: 26.5449 (Forecasting Loss:0.5936 + XiCon Loss:2.5951 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 26.6244736
	speed: 0.0505s/iter; left time: 992.1288s
	iters: 200, epoch: 14 | loss: 26.3464527
	speed: 0.0501s/iter; left time: 980.3905s
Epoch: 14 cost time: 11.515354633331299
Epoch: 14, Steps: 227 Train Loss: 26.5412 (Forecasting Loss:0.5935 + XiCon Loss:2.5948 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 27.2693634
	speed: 0.0518s/iter; left time: 1005.7346s
	iters: 200, epoch: 15 | loss: 26.6288261
	speed: 0.0498s/iter; left time: 961.5408s
Epoch: 15 cost time: 11.563574075698853
Epoch: 15, Steps: 227 Train Loss: 26.5245 (Forecasting Loss:0.5936 + XiCon Loss:2.5931 x Lambda(10.0)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 25.8360767
	speed: 0.0535s/iter; left time: 1026.7373s
	iters: 200, epoch: 16 | loss: 27.0220337
	speed: 0.0506s/iter; left time: 966.6488s
Epoch: 16 cost time: 11.979641675949097
Epoch: 16, Steps: 227 Train Loss: 26.5854 (Forecasting Loss:0.5933 + XiCon Loss:2.5992 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 27.5545731
	speed: 0.0515s/iter; left time: 976.7222s
	iters: 200, epoch: 17 | loss: 27.1461468
	speed: 0.0486s/iter; left time: 917.3161s
Epoch: 17 cost time: 11.437103271484375
Epoch: 17, Steps: 227 Train Loss: 26.5079 (Forecasting Loss:0.5934 + XiCon Loss:2.5914 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.4283485
	speed: 0.0525s/iter; left time: 984.5535s
	iters: 200, epoch: 18 | loss: 26.9205360
	speed: 0.0522s/iter; left time: 972.9588s
Epoch: 18 cost time: 11.874459981918335
Epoch: 18, Steps: 227 Train Loss: 26.5461 (Forecasting Loss:0.5935 + XiCon Loss:2.5953 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
Validation loss decreased (1.178638 --> 1.178485).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.5283661
	speed: 0.0526s/iter; left time: 973.2704s
	iters: 200, epoch: 19 | loss: 26.7675972
	speed: 0.0503s/iter; left time: 926.0228s
Epoch: 19 cost time: 11.663123607635498
Epoch: 19, Steps: 227 Train Loss: 26.5912 (Forecasting Loss:0.5934 + XiCon Loss:2.5998 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 26.2734451
	speed: 0.0514s/iter; left time: 940.7864s
	iters: 200, epoch: 20 | loss: 26.1890335
	speed: 0.0512s/iter; left time: 931.2514s
Epoch: 20 cost time: 11.635407209396362
Epoch: 20, Steps: 227 Train Loss: 26.5778 (Forecasting Loss:0.5935 + XiCon Loss:2.5984 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 26.4011478
	speed: 0.0518s/iter; left time: 935.9390s
	iters: 200, epoch: 21 | loss: 26.9630032
	speed: 0.0491s/iter; left time: 881.4643s
Epoch: 21 cost time: 11.449767351150513
Epoch: 21, Steps: 227 Train Loss: 26.5812 (Forecasting Loss:0.5935 + XiCon Loss:2.5988 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 26.5143929
	speed: 0.0541s/iter; left time: 965.4536s
	iters: 200, epoch: 22 | loss: 27.5370865
	speed: 0.0501s/iter; left time: 889.1108s
Epoch: 22 cost time: 11.818113327026367
Epoch: 22, Steps: 227 Train Loss: 26.5618 (Forecasting Loss:0.5935 + XiCon Loss:2.5968 x Lambda(10.0)), Vali MSE Loss: 1.1785 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 27.6838188
	speed: 0.0523s/iter; left time: 921.6964s
	iters: 200, epoch: 23 | loss: 26.1509399
	speed: 0.0496s/iter; left time: 868.6993s
Epoch: 23 cost time: 11.567007303237915
Epoch: 23, Steps: 227 Train Loss: 26.5936 (Forecasting Loss:0.5934 + XiCon Loss:2.6000 x Lambda(10.0)), Vali MSE Loss: 1.1789 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 26.6312180
	speed: 0.0524s/iter; left time: 911.0554s
	iters: 200, epoch: 24 | loss: 26.5229988
	speed: 0.0501s/iter; left time: 865.8373s
Epoch: 24 cost time: 11.672436475753784
Epoch: 24, Steps: 227 Train Loss: 26.5659 (Forecasting Loss:0.5936 + XiCon Loss:2.5972 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 26.3274097
	speed: 0.0514s/iter; left time: 880.8380s
	iters: 200, epoch: 25 | loss: 26.8268661
	speed: 0.0519s/iter; left time: 884.3251s
Epoch: 25 cost time: 11.712146282196045
Epoch: 25, Steps: 227 Train Loss: 26.5724 (Forecasting Loss:0.5935 + XiCon Loss:2.5979 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 26.7815075
	speed: 0.0529s/iter; left time: 894.7228s
	iters: 200, epoch: 26 | loss: 26.4149609
	speed: 0.0504s/iter; left time: 847.9088s
Epoch: 26 cost time: 11.682153701782227
Epoch: 26, Steps: 227 Train Loss: 26.5491 (Forecasting Loss:0.5933 + XiCon Loss:2.5956 x Lambda(10.0)), Vali MSE Loss: 1.1793 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 27.0830917
	speed: 0.0514s/iter; left time: 857.7607s
	iters: 200, epoch: 27 | loss: 26.5637493
	speed: 0.0512s/iter; left time: 849.5100s
Epoch: 27 cost time: 11.698462963104248
Epoch: 27, Steps: 227 Train Loss: 26.5735 (Forecasting Loss:0.5934 + XiCon Loss:2.5980 x Lambda(10.0)), Vali MSE Loss: 1.1779 Test MSE Loss: 1.2720
Validation loss decreased (1.178485 --> 1.177948).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 26.2722301
	speed: 0.0554s/iter; left time: 913.2982s
	iters: 200, epoch: 28 | loss: 27.1908531
	speed: 0.0501s/iter; left time: 821.0505s
Epoch: 28 cost time: 11.912128686904907
Epoch: 28, Steps: 227 Train Loss: 26.5893 (Forecasting Loss:0.5934 + XiCon Loss:2.5996 x Lambda(10.0)), Vali MSE Loss: 1.1786 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 27.0238628
	speed: 0.0518s/iter; left time: 842.0984s
	iters: 200, epoch: 29 | loss: 26.7184448
	speed: 0.0505s/iter; left time: 815.8338s
Epoch: 29 cost time: 11.693083047866821
Epoch: 29, Steps: 227 Train Loss: 26.5380 (Forecasting Loss:0.5936 + XiCon Loss:2.5944 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 26.2485561
	speed: 0.0542s/iter; left time: 867.3927s
	iters: 200, epoch: 30 | loss: 26.7312565
	speed: 0.0497s/iter; left time: 790.9637s
Epoch: 30 cost time: 11.748771667480469
Epoch: 30, Steps: 227 Train Loss: 26.5186 (Forecasting Loss:0.5934 + XiCon Loss:2.5925 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 26.6152363
	speed: 0.0531s/iter; left time: 838.7889s
	iters: 200, epoch: 31 | loss: 27.0474815
	speed: 0.0510s/iter; left time: 799.5173s
Epoch: 31 cost time: 11.767368078231812
Epoch: 31, Steps: 227 Train Loss: 26.5550 (Forecasting Loss:0.5936 + XiCon Loss:2.5961 x Lambda(10.0)), Vali MSE Loss: 1.1788 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 25.9595127
	speed: 0.0506s/iter; left time: 786.8947s
	iters: 200, epoch: 32 | loss: 26.8795414
	speed: 0.0492s/iter; left time: 760.1273s
Epoch: 32 cost time: 11.345743179321289
Epoch: 32, Steps: 227 Train Loss: 26.5441 (Forecasting Loss:0.5935 + XiCon Loss:2.5951 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 26.2502251
	speed: 0.0525s/iter; left time: 805.2150s
	iters: 200, epoch: 33 | loss: 26.4500961
	speed: 0.0488s/iter; left time: 743.0997s
Epoch: 33 cost time: 11.477221250534058
Epoch: 33, Steps: 227 Train Loss: 26.5411 (Forecasting Loss:0.5935 + XiCon Loss:2.5948 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 26.8482399
	speed: 0.0520s/iter; left time: 786.3028s
	iters: 200, epoch: 34 | loss: 26.1646557
	speed: 0.0523s/iter; left time: 784.9803s
Epoch: 34 cost time: 11.822931051254272
Epoch: 34, Steps: 227 Train Loss: 26.5797 (Forecasting Loss:0.5934 + XiCon Loss:2.5986 x Lambda(10.0)), Vali MSE Loss: 1.1790 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 26.5263653
	speed: 0.0514s/iter; left time: 765.5960s
	iters: 200, epoch: 35 | loss: 25.7342243
	speed: 0.0493s/iter; left time: 728.2311s
Epoch: 35 cost time: 11.507898092269897
Epoch: 35, Steps: 227 Train Loss: 26.5592 (Forecasting Loss:0.5934 + XiCon Loss:2.5966 x Lambda(10.0)), Vali MSE Loss: 1.1787 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 26.7344856
	speed: 0.0533s/iter; left time: 780.7237s
	iters: 200, epoch: 36 | loss: 27.3176270
	speed: 0.0513s/iter; left time: 746.0198s
Epoch: 36 cost time: 11.803192138671875
Epoch: 36, Steps: 227 Train Loss: 26.5792 (Forecasting Loss:0.5936 + XiCon Loss:2.5986 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 26.6293716
	speed: 0.0507s/iter; left time: 731.5073s
	iters: 200, epoch: 37 | loss: 26.4428997
	speed: 0.0475s/iter; left time: 681.1308s
Epoch: 37 cost time: 11.15841269493103
Epoch: 37, Steps: 227 Train Loss: 26.5912 (Forecasting Loss:0.5934 + XiCon Loss:2.5998 x Lambda(10.0)), Vali MSE Loss: 1.1791 Test MSE Loss: 1.2720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5892972946166992, mae:0.9546791315078735, mape:6.2661662101745605, mspe:4854.22607421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.0419
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 28.4778671
	speed: 0.0459s/iter; left time: 1037.3420s
	iters: 200, epoch: 1 | loss: 28.2969341
	speed: 0.0425s/iter; left time: 956.1258s
Epoch: 1 cost time: 10.030928373336792
Epoch: 1, Steps: 227 Train Loss: 28.1110 (Forecasting Loss:1.0243 + XiCon Loss:2.7087 x Lambda(10.0)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932089).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 27.0027885
	speed: 0.0450s/iter; left time: 1007.3030s
	iters: 200, epoch: 2 | loss: 27.7147293
	speed: 0.0439s/iter; left time: 978.1213s
Epoch: 2 cost time: 10.199875831604004
Epoch: 2, Steps: 227 Train Loss: 27.7232 (Forecasting Loss:0.6694 + XiCon Loss:2.7054 x Lambda(10.0)), Vali MSE Loss: 1.2131 Test MSE Loss: 1.2808
Validation loss decreased (1.932089 --> 1.213131).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 27.4316311
	speed: 0.0482s/iter; left time: 1068.4146s
	iters: 200, epoch: 3 | loss: 27.6779537
	speed: 0.0464s/iter; left time: 1022.3571s
Epoch: 3 cost time: 10.702107429504395
Epoch: 3, Steps: 227 Train Loss: 27.5145 (Forecasting Loss:0.6076 + XiCon Loss:2.6907 x Lambda(10.0)), Vali MSE Loss: 1.1942 Test MSE Loss: 1.2731
Validation loss decreased (1.213131 --> 1.194219).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 27.3590736
	speed: 0.0469s/iter; left time: 1028.7721s
	iters: 200, epoch: 4 | loss: 26.8653507
	speed: 0.0457s/iter; left time: 996.9733s
Epoch: 4 cost time: 10.521948337554932
Epoch: 4, Steps: 227 Train Loss: 27.4116 (Forecasting Loss:0.6004 + XiCon Loss:2.6811 x Lambda(10.0)), Vali MSE Loss: 1.1885 Test MSE Loss: 1.2712
Validation loss decreased (1.194219 --> 1.188450).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 28.0176029
	speed: 0.0499s/iter; left time: 1081.6268s
	iters: 200, epoch: 5 | loss: 27.5430298
	speed: 0.0451s/iter; left time: 974.6387s
Epoch: 5 cost time: 10.730994462966919
Epoch: 5, Steps: 227 Train Loss: 27.3714 (Forecasting Loss:0.5976 + XiCon Loss:2.6774 x Lambda(10.0)), Vali MSE Loss: 1.1858 Test MSE Loss: 1.2705
Validation loss decreased (1.188450 --> 1.185834).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.7808495
	speed: 0.0482s/iter; left time: 1035.0173s
	iters: 200, epoch: 6 | loss: 27.1428604
	speed: 0.0449s/iter; left time: 959.5739s
Epoch: 6 cost time: 10.519316911697388
Epoch: 6, Steps: 227 Train Loss: 27.3203 (Forecasting Loss:0.5962 + XiCon Loss:2.6724 x Lambda(10.0)), Vali MSE Loss: 1.1841 Test MSE Loss: 1.2701
Validation loss decreased (1.185834 --> 1.184117).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 27.0225868
	speed: 0.0512s/iter; left time: 1086.7272s
	iters: 200, epoch: 7 | loss: 27.6354675
	speed: 0.0452s/iter; left time: 954.5665s
Epoch: 7 cost time: 10.879013299942017
Epoch: 7, Steps: 227 Train Loss: 27.3467 (Forecasting Loss:0.5955 + XiCon Loss:2.6751 x Lambda(10.0)), Vali MSE Loss: 1.1838 Test MSE Loss: 1.2700
Validation loss decreased (1.184117 --> 1.183843).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 27.2380524
	speed: 0.0485s/iter; left time: 1018.2703s
	iters: 200, epoch: 8 | loss: 27.6356773
	speed: 0.0464s/iter; left time: 970.5313s
Epoch: 8 cost time: 10.759133338928223
Epoch: 8, Steps: 227 Train Loss: 27.3722 (Forecasting Loss:0.5953 + XiCon Loss:2.6777 x Lambda(10.0)), Vali MSE Loss: 1.1834 Test MSE Loss: 1.2699
Validation loss decreased (1.183843 --> 1.183421).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.7292061
	speed: 0.0493s/iter; left time: 1025.5749s
	iters: 200, epoch: 9 | loss: 26.8843136
	speed: 0.0457s/iter; left time: 945.4139s
Epoch: 9 cost time: 10.696346044540405
Epoch: 9, Steps: 227 Train Loss: 27.3133 (Forecasting Loss:0.5950 + XiCon Loss:2.6718 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2699
Validation loss decreased (1.183421 --> 1.182180).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 26.8947697
	speed: 0.0486s/iter; left time: 998.9878s
	iters: 200, epoch: 10 | loss: 27.5397224
	speed: 0.0448s/iter; left time: 915.5298s
Epoch: 10 cost time: 10.576749563217163
Epoch: 10, Steps: 227 Train Loss: 27.3520 (Forecasting Loss:0.5949 + XiCon Loss:2.6757 x Lambda(10.0)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 26.6670818
	speed: 0.0469s/iter; left time: 953.6951s
	iters: 200, epoch: 11 | loss: 28.6606445
	speed: 0.0453s/iter; left time: 916.7784s
Epoch: 11 cost time: 10.449040412902832
Epoch: 11, Steps: 227 Train Loss: 27.3289 (Forecasting Loss:0.5948 + XiCon Loss:2.6734 x Lambda(10.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 27.3261452
	speed: 0.0507s/iter; left time: 1019.9871s
	iters: 200, epoch: 12 | loss: 27.3564911
	speed: 0.0458s/iter; left time: 915.8166s
Epoch: 12 cost time: 10.873757600784302
Epoch: 12, Steps: 227 Train Loss: 27.3394 (Forecasting Loss:0.5948 + XiCon Loss:2.6745 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 27.1223335
	speed: 0.0503s/iter; left time: 1000.5581s
	iters: 200, epoch: 13 | loss: 27.1484547
	speed: 0.0446s/iter; left time: 883.0079s
Epoch: 13 cost time: 10.744338274002075
Epoch: 13, Steps: 227 Train Loss: 27.3312 (Forecasting Loss:0.5949 + XiCon Loss:2.6736 x Lambda(10.0)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 27.0166397
	speed: 0.0480s/iter; left time: 942.8792s
	iters: 200, epoch: 14 | loss: 27.8792496
	speed: 0.0444s/iter; left time: 868.2361s
Epoch: 14 cost time: 10.460803747177124
Epoch: 14, Steps: 227 Train Loss: 27.3032 (Forecasting Loss:0.5949 + XiCon Loss:2.6708 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 27.4925728
	speed: 0.0505s/iter; left time: 980.0116s
	iters: 200, epoch: 15 | loss: 28.2416611
	speed: 0.0446s/iter; left time: 861.3864s
Epoch: 15 cost time: 10.747262954711914
Epoch: 15, Steps: 227 Train Loss: 27.3470 (Forecasting Loss:0.5947 + XiCon Loss:2.6752 x Lambda(10.0)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2698
Validation loss decreased (1.182180 --> 1.181906).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 26.8164768
	speed: 0.0514s/iter; left time: 986.7084s
	iters: 200, epoch: 16 | loss: 27.3326130
	speed: 0.0455s/iter; left time: 867.9398s
Epoch: 16 cost time: 10.999993324279785
Epoch: 16, Steps: 227 Train Loss: 27.3488 (Forecasting Loss:0.5947 + XiCon Loss:2.6754 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 27.0713158
	speed: 0.0477s/iter; left time: 905.7665s
	iters: 200, epoch: 17 | loss: 27.3224525
	speed: 0.0440s/iter; left time: 831.1332s
Epoch: 17 cost time: 10.487727403640747
Epoch: 17, Steps: 227 Train Loss: 27.3485 (Forecasting Loss:0.5948 + XiCon Loss:2.6754 x Lambda(10.0)), Vali MSE Loss: 1.1828 Test MSE Loss: 1.2698
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 27.8805084
	speed: 0.0498s/iter; left time: 934.1847s
	iters: 200, epoch: 18 | loss: 26.6128044
	speed: 0.0470s/iter; left time: 877.0365s
Epoch: 18 cost time: 10.95087742805481
Epoch: 18, Steps: 227 Train Loss: 27.2998 (Forecasting Loss:0.5947 + XiCon Loss:2.6705 x Lambda(10.0)), Vali MSE Loss: 1.1831 Test MSE Loss: 1.2698
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.8050480
	speed: 0.0477s/iter; left time: 883.9320s
	iters: 200, epoch: 19 | loss: 27.1458931
	speed: 0.0450s/iter; left time: 828.5549s
Epoch: 19 cost time: 10.58792519569397
Epoch: 19, Steps: 227 Train Loss: 27.3414 (Forecasting Loss:0.5947 + XiCon Loss:2.6747 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 27.1697769
	speed: 0.0496s/iter; left time: 907.8606s
	iters: 200, epoch: 20 | loss: 27.5495892
	speed: 0.0453s/iter; left time: 824.0356s
Epoch: 20 cost time: 10.733972787857056
Epoch: 20, Steps: 227 Train Loss: 27.3557 (Forecasting Loss:0.5948 + XiCon Loss:2.6761 x Lambda(10.0)), Vali MSE Loss: 1.1833 Test MSE Loss: 1.2698
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 27.1555138
	speed: 0.0473s/iter; left time: 854.5353s
	iters: 200, epoch: 21 | loss: 26.8428612
	speed: 0.0475s/iter; left time: 852.3037s
Epoch: 21 cost time: 10.707566022872925
Epoch: 21, Steps: 227 Train Loss: 27.3144 (Forecasting Loss:0.5948 + XiCon Loss:2.6720 x Lambda(10.0)), Vali MSE Loss: 1.1827 Test MSE Loss: 1.2698
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 26.6970062
	speed: 0.0485s/iter; left time: 864.4629s
	iters: 200, epoch: 22 | loss: 27.0302811
	speed: 0.0459s/iter; left time: 814.6386s
Epoch: 22 cost time: 10.704267024993896
Epoch: 22, Steps: 227 Train Loss: 27.3479 (Forecasting Loss:0.5947 + XiCon Loss:2.6753 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 26.9730034
	speed: 0.0478s/iter; left time: 841.2725s
	iters: 200, epoch: 23 | loss: 27.2593079
	speed: 0.0445s/iter; left time: 779.8790s
Epoch: 23 cost time: 10.45197343826294
Epoch: 23, Steps: 227 Train Loss: 27.2845 (Forecasting Loss:0.5948 + XiCon Loss:2.6690 x Lambda(10.0)), Vali MSE Loss: 1.1824 Test MSE Loss: 1.2698
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 27.5572891
	speed: 0.0496s/iter; left time: 862.6099s
	iters: 200, epoch: 24 | loss: 27.9039917
	speed: 0.0446s/iter; left time: 771.0420s
Epoch: 24 cost time: 10.640002727508545
Epoch: 24, Steps: 227 Train Loss: 27.2973 (Forecasting Loss:0.5946 + XiCon Loss:2.6703 x Lambda(10.0)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2698
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 27.7023869
	speed: 0.0476s/iter; left time: 817.2804s
	iters: 200, epoch: 25 | loss: 26.7143898
	speed: 0.0484s/iter; left time: 825.8386s
Epoch: 25 cost time: 10.83852243423462
Epoch: 25, Steps: 227 Train Loss: 27.3178 (Forecasting Loss:0.5948 + XiCon Loss:2.6723 x Lambda(10.0)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2698
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5867546796798706, mae:0.9528683423995972, mape:6.2043046951293945, mspe:4736.51025390625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.6185
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 28.8009586
	speed: 0.0477s/iter; left time: 1077.4931s
	iters: 200, epoch: 1 | loss: 28.9579334
	speed: 0.0439s/iter; left time: 987.8706s
Epoch: 1 cost time: 10.364174604415894
Epoch: 1, Steps: 227 Train Loss: 28.2440 (Forecasting Loss:1.0400 + XiCon Loss:2.7204 x Lambda(10.0)), Vali MSE Loss: 1.9472 Test MSE Loss: 1.3972
Validation loss decreased (inf --> 1.947250).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 26.8685207
	speed: 0.0468s/iter; left time: 1046.2044s
	iters: 200, epoch: 2 | loss: 27.4534473
	speed: 0.0436s/iter; left time: 972.0338s
Epoch: 2 cost time: 10.302592277526855
Epoch: 2, Steps: 227 Train Loss: 27.6696 (Forecasting Loss:0.6718 + XiCon Loss:2.6998 x Lambda(10.0)), Vali MSE Loss: 1.2059 Test MSE Loss: 1.2763
Validation loss decreased (1.947250 --> 1.205865).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 26.7585449
	speed: 0.0486s/iter; left time: 1077.4170s
	iters: 200, epoch: 3 | loss: 26.1303062
	speed: 0.0454s/iter; left time: 1000.2068s
Epoch: 3 cost time: 10.620089530944824
Epoch: 3, Steps: 227 Train Loss: 27.2063 (Forecasting Loss:0.6077 + XiCon Loss:2.6599 x Lambda(10.0)), Vali MSE Loss: 1.1885 Test MSE Loss: 1.2694
Validation loss decreased (1.205865 --> 1.188472).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 26.7942085
	speed: 0.0473s/iter; left time: 1036.4850s
	iters: 200, epoch: 4 | loss: 27.3487759
	speed: 0.0431s/iter; left time: 940.3321s
Epoch: 4 cost time: 10.232756614685059
Epoch: 4, Steps: 227 Train Loss: 26.7716 (Forecasting Loss:0.6005 + XiCon Loss:2.6171 x Lambda(10.0)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2681
Validation loss decreased (1.188472 --> 1.185001).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.4651871
	speed: 0.0483s/iter; left time: 1048.1825s
	iters: 200, epoch: 5 | loss: 26.4260864
	speed: 0.0430s/iter; left time: 928.4138s
Epoch: 5 cost time: 10.325484037399292
Epoch: 5, Steps: 227 Train Loss: 26.5161 (Forecasting Loss:0.5977 + XiCon Loss:2.5918 x Lambda(10.0)), Vali MSE Loss: 1.1815 Test MSE Loss: 1.2674
Validation loss decreased (1.185001 --> 1.181511).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 26.4065208
	speed: 0.0487s/iter; left time: 1046.3103s
	iters: 200, epoch: 6 | loss: 26.0157089
	speed: 0.0428s/iter; left time: 914.4239s
Epoch: 6 cost time: 10.356648921966553
Epoch: 6, Steps: 227 Train Loss: 26.4028 (Forecasting Loss:0.5965 + XiCon Loss:2.5806 x Lambda(10.0)), Vali MSE Loss: 1.1811 Test MSE Loss: 1.2670
Validation loss decreased (1.181511 --> 1.181089).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 25.7598038
	speed: 0.0516s/iter; left time: 1095.0442s
	iters: 200, epoch: 7 | loss: 25.6820183
	speed: 0.0432s/iter; left time: 912.6897s
Epoch: 7 cost time: 10.705288410186768
Epoch: 7, Steps: 227 Train Loss: 26.3329 (Forecasting Loss:0.5958 + XiCon Loss:2.5737 x Lambda(10.0)), Vali MSE Loss: 1.1807 Test MSE Loss: 1.2668
Validation loss decreased (1.181089 --> 1.180739).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 27.1640434
	speed: 0.0495s/iter; left time: 1039.9132s
	iters: 200, epoch: 8 | loss: 25.7475929
	speed: 0.0482s/iter; left time: 1008.4405s
Epoch: 8 cost time: 11.079097509384155
Epoch: 8, Steps: 227 Train Loss: 26.2814 (Forecasting Loss:0.5955 + XiCon Loss:2.5686 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2667
Validation loss decreased (1.180739 --> 1.179957).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.2722416
	speed: 0.0492s/iter; left time: 1023.3195s
	iters: 200, epoch: 9 | loss: 25.6783619
	speed: 0.0445s/iter; left time: 921.2931s
Epoch: 9 cost time: 10.625857830047607
Epoch: 9, Steps: 227 Train Loss: 26.3052 (Forecasting Loss:0.5955 + XiCon Loss:2.5710 x Lambda(10.0)), Vali MSE Loss: 1.1802 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 25.9771385
	speed: 0.0486s/iter; left time: 998.2644s
	iters: 200, epoch: 10 | loss: 26.7321911
	speed: 0.0442s/iter; left time: 903.6193s
Epoch: 10 cost time: 10.57265043258667
Epoch: 10, Steps: 227 Train Loss: 26.2760 (Forecasting Loss:0.5953 + XiCon Loss:2.5681 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2667
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 25.9084492
	speed: 0.0494s/iter; left time: 1004.6448s
	iters: 200, epoch: 11 | loss: 26.1856327
	speed: 0.0472s/iter; left time: 955.5445s
Epoch: 11 cost time: 10.888756513595581
Epoch: 11, Steps: 227 Train Loss: 26.3237 (Forecasting Loss:0.5951 + XiCon Loss:2.5729 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2667
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 25.8054104
	speed: 0.0471s/iter; left time: 947.3966s
	iters: 200, epoch: 12 | loss: 26.0211945
	speed: 0.0451s/iter; left time: 903.0638s
Epoch: 12 cost time: 10.465914011001587
Epoch: 12, Steps: 227 Train Loss: 26.3184 (Forecasting Loss:0.5951 + XiCon Loss:2.5723 x Lambda(10.0)), Vali MSE Loss: 1.1802 Test MSE Loss: 1.2667
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 25.8580227
	speed: 0.0482s/iter; left time: 957.2663s
	iters: 200, epoch: 13 | loss: 26.0281849
	speed: 0.0441s/iter; left time: 872.2683s
Epoch: 13 cost time: 10.455709218978882
Epoch: 13, Steps: 227 Train Loss: 26.3144 (Forecasting Loss:0.5950 + XiCon Loss:2.5719 x Lambda(10.0)), Vali MSE Loss: 1.1801 Test MSE Loss: 1.2667
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 25.5014477
	speed: 0.0506s/iter; left time: 994.1657s
	iters: 200, epoch: 14 | loss: 26.1758213
	speed: 0.0441s/iter; left time: 862.6036s
Epoch: 14 cost time: 10.737224817276001
Epoch: 14, Steps: 227 Train Loss: 26.2484 (Forecasting Loss:0.5952 + XiCon Loss:2.5653 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2667
Validation loss decreased (1.179957 --> 1.179724).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 26.9690990
	speed: 0.0493s/iter; left time: 958.3300s
	iters: 200, epoch: 15 | loss: 25.7558193
	speed: 0.0449s/iter; left time: 867.8840s
Epoch: 15 cost time: 10.618430137634277
Epoch: 15, Steps: 227 Train Loss: 26.2537 (Forecasting Loss:0.5950 + XiCon Loss:2.5659 x Lambda(10.0)), Vali MSE Loss: 1.1795 Test MSE Loss: 1.2667
Validation loss decreased (1.179724 --> 1.179487).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 26.3534908
	speed: 0.0506s/iter; left time: 971.5507s
	iters: 200, epoch: 16 | loss: 26.1227551
	speed: 0.0449s/iter; left time: 858.3289s
Epoch: 16 cost time: 10.75629711151123
Epoch: 16, Steps: 227 Train Loss: 26.2933 (Forecasting Loss:0.5950 + XiCon Loss:2.5698 x Lambda(10.0)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 26.7035942
	speed: 0.0481s/iter; left time: 912.6701s
	iters: 200, epoch: 17 | loss: 26.2827587
	speed: 0.0458s/iter; left time: 863.5570s
Epoch: 17 cost time: 10.639999628067017
Epoch: 17, Steps: 227 Train Loss: 26.2831 (Forecasting Loss:0.5951 + XiCon Loss:2.5688 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2667
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.2460575
	speed: 0.0484s/iter; left time: 906.1854s
	iters: 200, epoch: 18 | loss: 26.3121662
	speed: 0.0479s/iter; left time: 892.1809s
Epoch: 18 cost time: 10.89418911933899
Epoch: 18, Steps: 227 Train Loss: 26.2449 (Forecasting Loss:0.5951 + XiCon Loss:2.5650 x Lambda(10.0)), Vali MSE Loss: 1.1794 Test MSE Loss: 1.2667
Validation loss decreased (1.179487 --> 1.179446).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.2967014
	speed: 0.0491s/iter; left time: 908.7169s
	iters: 200, epoch: 19 | loss: 26.1845455
	speed: 0.0467s/iter; left time: 859.2970s
Epoch: 19 cost time: 10.846700191497803
Epoch: 19, Steps: 227 Train Loss: 26.3081 (Forecasting Loss:0.5952 + XiCon Loss:2.5713 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 26.1266251
	speed: 0.0475s/iter; left time: 868.3536s
	iters: 200, epoch: 20 | loss: 26.5866489
	speed: 0.0446s/iter; left time: 811.2868s
Epoch: 20 cost time: 10.430978298187256
Epoch: 20, Steps: 227 Train Loss: 26.2910 (Forecasting Loss:0.5951 + XiCon Loss:2.5696 x Lambda(10.0)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2667
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 26.0610580
	speed: 0.0502s/iter; left time: 906.5819s
	iters: 200, epoch: 21 | loss: 25.5036335
	speed: 0.0446s/iter; left time: 801.1172s
Epoch: 21 cost time: 10.691082000732422
Epoch: 21, Steps: 227 Train Loss: 26.2750 (Forecasting Loss:0.5950 + XiCon Loss:2.5680 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2667
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 26.8736553
	speed: 0.0487s/iter; left time: 868.7136s
	iters: 200, epoch: 22 | loss: 26.8492374
	speed: 0.0454s/iter; left time: 805.1014s
Epoch: 22 cost time: 10.680263042449951
Epoch: 22, Steps: 227 Train Loss: 26.2694 (Forecasting Loss:0.5952 + XiCon Loss:2.5674 x Lambda(10.0)), Vali MSE Loss: 1.1800 Test MSE Loss: 1.2667
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 26.5561924
	speed: 0.0475s/iter; left time: 836.2161s
	iters: 200, epoch: 23 | loss: 26.7528820
	speed: 0.0461s/iter; left time: 807.4416s
Epoch: 23 cost time: 10.560879230499268
Epoch: 23, Steps: 227 Train Loss: 26.2858 (Forecasting Loss:0.5950 + XiCon Loss:2.5691 x Lambda(10.0)), Vali MSE Loss: 1.1798 Test MSE Loss: 1.2667
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 26.3333778
	speed: 0.0493s/iter; left time: 856.6074s
	iters: 200, epoch: 24 | loss: 26.4288921
	speed: 0.0452s/iter; left time: 780.2352s
Epoch: 24 cost time: 10.699465990066528
Epoch: 24, Steps: 227 Train Loss: 26.2763 (Forecasting Loss:0.5950 + XiCon Loss:2.5681 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2667
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 26.3623276
	speed: 0.0477s/iter; left time: 818.3329s
	iters: 200, epoch: 25 | loss: 25.7797546
	speed: 0.0438s/iter; left time: 746.7866s
Epoch: 25 cost time: 10.512301445007324
Epoch: 25, Steps: 227 Train Loss: 26.2778 (Forecasting Loss:0.5952 + XiCon Loss:2.5683 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2667
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 26.1500473
	speed: 0.0487s/iter; left time: 824.9685s
	iters: 200, epoch: 26 | loss: 26.5735550
	speed: 0.0471s/iter; left time: 792.1090s
Epoch: 26 cost time: 10.81888723373413
Epoch: 26, Steps: 227 Train Loss: 26.3019 (Forecasting Loss:0.5951 + XiCon Loss:2.5707 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2667
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 26.1768684
	speed: 0.0471s/iter; left time: 787.2043s
	iters: 200, epoch: 27 | loss: 25.8242531
	speed: 0.0454s/iter; left time: 754.2219s
Epoch: 27 cost time: 10.477932453155518
Epoch: 27, Steps: 227 Train Loss: 26.2841 (Forecasting Loss:0.5952 + XiCon Loss:2.5689 x Lambda(10.0)), Vali MSE Loss: 1.1797 Test MSE Loss: 1.2667
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 25.5216713
	speed: 0.0482s/iter; left time: 793.1342s
	iters: 200, epoch: 28 | loss: 26.1017132
	speed: 0.0468s/iter; left time: 765.5930s
Epoch: 28 cost time: 10.712284088134766
Epoch: 28, Steps: 227 Train Loss: 26.3009 (Forecasting Loss:0.5951 + XiCon Loss:2.5706 x Lambda(10.0)), Vali MSE Loss: 1.1803 Test MSE Loss: 1.2667
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5826083421707153, mae:0.950704038143158, mape:6.09912109375, mspe:4551.39013671875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.6953
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 28.0328388
	speed: 0.0509s/iter; left time: 1149.3416s
	iters: 200, epoch: 1 | loss: 27.3449383
	speed: 0.0472s/iter; left time: 1062.9944s
Epoch: 1 cost time: 11.098479747772217
Epoch: 1, Steps: 227 Train Loss: 28.0801 (Forecasting Loss:1.1623 + XiCon Loss:2.6918 x Lambda(10.0)), Vali MSE Loss: 2.2089 Test MSE Loss: 1.4658
Validation loss decreased (inf --> 2.208911).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 27.2753468
	speed: 0.0501s/iter; left time: 1121.3160s
	iters: 200, epoch: 2 | loss: 27.4595928
	speed: 0.0465s/iter; left time: 1035.7168s
Epoch: 2 cost time: 10.951451301574707
Epoch: 2, Steps: 227 Train Loss: 27.5312 (Forecasting Loss:0.7700 + XiCon Loss:2.6761 x Lambda(10.0)), Vali MSE Loss: 1.3356 Test MSE Loss: 1.3353
Validation loss decreased (2.208911 --> 1.335643).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 27.0363960
	speed: 0.0529s/iter; left time: 1171.1249s
	iters: 200, epoch: 3 | loss: 27.4388962
	speed: 0.0474s/iter; left time: 1044.9979s
Epoch: 3 cost time: 11.353585481643677
Epoch: 3, Steps: 227 Train Loss: 27.1889 (Forecasting Loss:0.6537 + XiCon Loss:2.6535 x Lambda(10.0)), Vali MSE Loss: 1.2409 Test MSE Loss: 1.3059
Validation loss decreased (1.335643 --> 1.240889).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 27.4177971
	speed: 0.0503s/iter; left time: 1101.6307s
	iters: 200, epoch: 4 | loss: 26.5177231
	speed: 0.0477s/iter; left time: 1041.2586s
Epoch: 4 cost time: 11.086642742156982
Epoch: 4, Steps: 227 Train Loss: 27.0132 (Forecasting Loss:0.6205 + XiCon Loss:2.6393 x Lambda(10.0)), Vali MSE Loss: 1.2047 Test MSE Loss: 1.2943
Validation loss decreased (1.240889 --> 1.204676).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.7555790
	speed: 0.0505s/iter; left time: 1095.7948s
	iters: 200, epoch: 5 | loss: 27.0333138
	speed: 0.0475s/iter; left time: 1025.8027s
Epoch: 5 cost time: 11.103108644485474
Epoch: 5, Steps: 227 Train Loss: 26.9020 (Forecasting Loss:0.6084 + XiCon Loss:2.6294 x Lambda(10.0)), Vali MSE Loss: 1.1942 Test MSE Loss: 1.2900
Validation loss decreased (1.204676 --> 1.194174).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.3177910
	speed: 0.0524s/iter; left time: 1125.4672s
	iters: 200, epoch: 6 | loss: 26.8546276
	speed: 0.0484s/iter; left time: 1034.4086s
Epoch: 6 cost time: 11.343177080154419
Epoch: 6, Steps: 227 Train Loss: 26.8475 (Forecasting Loss:0.6038 + XiCon Loss:2.6244 x Lambda(10.0)), Vali MSE Loss: 1.1891 Test MSE Loss: 1.2879
Validation loss decreased (1.194174 --> 1.189085).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 26.9563427
	speed: 0.0519s/iter; left time: 1102.1024s
	iters: 200, epoch: 7 | loss: 26.4515743
	speed: 0.0459s/iter; left time: 970.3934s
Epoch: 7 cost time: 11.051404476165771
Epoch: 7, Steps: 227 Train Loss: 26.8554 (Forecasting Loss:0.6016 + XiCon Loss:2.6254 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2870
Validation loss decreased (1.189085 --> 1.186802).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 26.6432972
	speed: 0.0488s/iter; left time: 1024.4175s
	iters: 200, epoch: 8 | loss: 26.8841343
	speed: 0.0463s/iter; left time: 968.8961s
Epoch: 8 cost time: 10.77866506576538
Epoch: 8, Steps: 227 Train Loss: 26.8550 (Forecasting Loss:0.6004 + XiCon Loss:2.6255 x Lambda(10.0)), Vali MSE Loss: 1.1864 Test MSE Loss: 1.2865
Validation loss decreased (1.186802 --> 1.186364).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.5066433
	speed: 0.0517s/iter; left time: 1073.8170s
	iters: 200, epoch: 9 | loss: 27.0284653
	speed: 0.0470s/iter; left time: 971.4739s
Epoch: 9 cost time: 11.184884309768677
Epoch: 9, Steps: 227 Train Loss: 26.8150 (Forecasting Loss:0.5997 + XiCon Loss:2.6215 x Lambda(10.0)), Vali MSE Loss: 1.1851 Test MSE Loss: 1.2863
Validation loss decreased (1.186364 --> 1.185105).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 27.2195339
	speed: 0.0495s/iter; left time: 1017.4966s
	iters: 200, epoch: 10 | loss: 27.2111568
	speed: 0.0457s/iter; left time: 935.9191s
Epoch: 10 cost time: 10.778005361557007
Epoch: 10, Steps: 227 Train Loss: 26.8928 (Forecasting Loss:0.5998 + XiCon Loss:2.6293 x Lambda(10.0)), Vali MSE Loss: 1.1854 Test MSE Loss: 1.2862
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 26.4404202
	speed: 0.0511s/iter; left time: 1038.9352s
	iters: 200, epoch: 11 | loss: 26.9434929
	speed: 0.0488s/iter; left time: 987.7901s
Epoch: 11 cost time: 11.361527442932129
Epoch: 11, Steps: 227 Train Loss: 26.8307 (Forecasting Loss:0.5997 + XiCon Loss:2.6231 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2861
Validation loss decreased (1.185105 --> 1.184417).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.3827038
	speed: 0.0525s/iter; left time: 1055.8525s
	iters: 200, epoch: 12 | loss: 27.2114105
	speed: 0.0472s/iter; left time: 944.0014s
Epoch: 12 cost time: 11.291361331939697
Epoch: 12, Steps: 227 Train Loss: 26.8978 (Forecasting Loss:0.5996 + XiCon Loss:2.6298 x Lambda(10.0)), Vali MSE Loss: 1.1853 Test MSE Loss: 1.2861
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.2742901
	speed: 0.0508s/iter; left time: 1010.3730s
	iters: 200, epoch: 13 | loss: 26.9032364
	speed: 0.0485s/iter; left time: 958.7306s
Epoch: 13 cost time: 11.209934949874878
Epoch: 13, Steps: 227 Train Loss: 26.8290 (Forecasting Loss:0.5995 + XiCon Loss:2.6229 x Lambda(10.0)), Vali MSE Loss: 1.1848 Test MSE Loss: 1.2861
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 26.7185192
	speed: 0.0497s/iter; left time: 977.0562s
	iters: 200, epoch: 14 | loss: 26.3211670
	speed: 0.0469s/iter; left time: 917.6613s
Epoch: 14 cost time: 10.97184944152832
Epoch: 14, Steps: 227 Train Loss: 26.8398 (Forecasting Loss:0.5996 + XiCon Loss:2.6240 x Lambda(10.0)), Vali MSE Loss: 1.1851 Test MSE Loss: 1.2861
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 27.5549107
	speed: 0.0521s/iter; left time: 1011.8603s
	iters: 200, epoch: 15 | loss: 26.7040215
	speed: 0.0495s/iter; left time: 956.7156s
Epoch: 15 cost time: 11.521163702011108
Epoch: 15, Steps: 227 Train Loss: 26.8412 (Forecasting Loss:0.5994 + XiCon Loss:2.6242 x Lambda(10.0)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2861
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 25.9590073
	speed: 0.0503s/iter; left time: 964.8809s
	iters: 200, epoch: 16 | loss: 26.6524601
	speed: 0.0473s/iter; left time: 902.4260s
Epoch: 16 cost time: 11.034525632858276
Epoch: 16, Steps: 227 Train Loss: 26.8156 (Forecasting Loss:0.5995 + XiCon Loss:2.6216 x Lambda(10.0)), Vali MSE Loss: 1.1852 Test MSE Loss: 1.2861
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 26.5951252
	speed: 0.0528s/iter; left time: 1001.0502s
	iters: 200, epoch: 17 | loss: 27.7238865
	speed: 0.0477s/iter; left time: 900.3257s
Epoch: 17 cost time: 11.333389043807983
Epoch: 17, Steps: 227 Train Loss: 26.8535 (Forecasting Loss:0.5995 + XiCon Loss:2.6254 x Lambda(10.0)), Vali MSE Loss: 1.1843 Test MSE Loss: 1.2861
Validation loss decreased (1.184417 --> 1.184329).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 27.2864494
	speed: 0.0520s/iter; left time: 975.1137s
	iters: 200, epoch: 18 | loss: 26.6945953
	speed: 0.0491s/iter; left time: 914.5921s
Epoch: 18 cost time: 11.415205955505371
Epoch: 18, Steps: 227 Train Loss: 26.8692 (Forecasting Loss:0.5997 + XiCon Loss:2.6270 x Lambda(10.0)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2861
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 27.0497570
	speed: 0.0507s/iter; left time: 939.5662s
	iters: 200, epoch: 19 | loss: 26.4358463
	speed: 0.0499s/iter; left time: 918.8812s
Epoch: 19 cost time: 11.433706998825073
Epoch: 19, Steps: 227 Train Loss: 26.8151 (Forecasting Loss:0.5994 + XiCon Loss:2.6216 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2861
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 27.1823292
	speed: 0.0511s/iter; left time: 935.1477s
	iters: 200, epoch: 20 | loss: 26.7461586
	speed: 0.0481s/iter; left time: 875.2199s
Epoch: 20 cost time: 11.20328426361084
Epoch: 20, Steps: 227 Train Loss: 26.8845 (Forecasting Loss:0.5996 + XiCon Loss:2.6285 x Lambda(10.0)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2861
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 26.0052185
	speed: 0.0499s/iter; left time: 900.6889s
	iters: 200, epoch: 21 | loss: 26.7448711
	speed: 0.0493s/iter; left time: 885.1358s
Epoch: 21 cost time: 11.289724826812744
Epoch: 21, Steps: 227 Train Loss: 26.8265 (Forecasting Loss:0.5996 + XiCon Loss:2.6227 x Lambda(10.0)), Vali MSE Loss: 1.1846 Test MSE Loss: 1.2861
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 26.9468269
	speed: 0.0524s/iter; left time: 934.1134s
	iters: 200, epoch: 22 | loss: 26.5508518
	speed: 0.0472s/iter; left time: 836.8772s
Epoch: 22 cost time: 11.298491477966309
Epoch: 22, Steps: 227 Train Loss: 26.8687 (Forecasting Loss:0.5993 + XiCon Loss:2.6269 x Lambda(10.0)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2861
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 26.9943161
	speed: 0.0520s/iter; left time: 915.8674s
	iters: 200, epoch: 23 | loss: 26.8869629
	speed: 0.0479s/iter; left time: 839.4363s
Epoch: 23 cost time: 11.2806875705719
Epoch: 23, Steps: 227 Train Loss: 26.8413 (Forecasting Loss:0.5994 + XiCon Loss:2.6242 x Lambda(10.0)), Vali MSE Loss: 1.1848 Test MSE Loss: 1.2861
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 26.7687263
	speed: 0.0511s/iter; left time: 887.9812s
	iters: 200, epoch: 24 | loss: 26.9127789
	speed: 0.0478s/iter; left time: 825.3970s
Epoch: 24 cost time: 11.141196250915527
Epoch: 24, Steps: 227 Train Loss: 26.8662 (Forecasting Loss:0.5994 + XiCon Loss:2.6267 x Lambda(10.0)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2861
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 27.2227535
	speed: 0.0507s/iter; left time: 869.2924s
	iters: 200, epoch: 25 | loss: 26.2314167
	speed: 0.0498s/iter; left time: 849.0491s
Epoch: 25 cost time: 11.355202198028564
Epoch: 25, Steps: 227 Train Loss: 26.8553 (Forecasting Loss:0.5993 + XiCon Loss:2.6256 x Lambda(10.0)), Vali MSE Loss: 1.1848 Test MSE Loss: 1.2861
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 27.2986908
	speed: 0.0518s/iter; left time: 877.2803s
	iters: 200, epoch: 26 | loss: 26.5436535
	speed: 0.0496s/iter; left time: 833.8954s
Epoch: 26 cost time: 11.422330379486084
Epoch: 26, Steps: 227 Train Loss: 26.8056 (Forecasting Loss:0.5995 + XiCon Loss:2.6206 x Lambda(10.0)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2861
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 27.0441990
	speed: 0.0511s/iter; left time: 853.0597s
	iters: 200, epoch: 27 | loss: 26.8265495
	speed: 0.0479s/iter; left time: 795.5911s
Epoch: 27 cost time: 11.200414180755615
Epoch: 27, Steps: 227 Train Loss: 26.8503 (Forecasting Loss:0.5992 + XiCon Loss:2.6251 x Lambda(10.0)), Vali MSE Loss: 1.1851 Test MSE Loss: 1.2861
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.6071760654449463, mae:0.9649483561515808, mape:6.580205917358398, mspe:5379.9423828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.1808
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 28.0969162
	speed: 0.0499s/iter; left time: 1128.3410s
	iters: 200, epoch: 1 | loss: 28.0950127
	speed: 0.0445s/iter; left time: 1001.5749s
Epoch: 1 cost time: 10.664713859558105
Epoch: 1, Steps: 227 Train Loss: 28.2565 (Forecasting Loss:1.0351 + XiCon Loss:2.7221 x Lambda(10.0)), Vali MSE Loss: 1.9647 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964685).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 27.5984707
	speed: 0.0478s/iter; left time: 1070.4587s
	iters: 200, epoch: 2 | loss: 27.5271683
	speed: 0.0447s/iter; left time: 995.1796s
Epoch: 2 cost time: 10.444509267807007
Epoch: 2, Steps: 227 Train Loss: 27.7393 (Forecasting Loss:0.6716 + XiCon Loss:2.7068 x Lambda(10.0)), Vali MSE Loss: 1.2186 Test MSE Loss: 1.2818
Validation loss decreased (1.964685 --> 1.218635).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 27.3605766
	speed: 0.0491s/iter; left time: 1087.0660s
	iters: 200, epoch: 3 | loss: 27.2572193
	speed: 0.0455s/iter; left time: 1003.9908s
Epoch: 3 cost time: 10.830171585083008
Epoch: 3, Steps: 227 Train Loss: 27.4193 (Forecasting Loss:0.6086 + XiCon Loss:2.6811 x Lambda(10.0)), Vali MSE Loss: 1.1997 Test MSE Loss: 1.2742
Validation loss decreased (1.218635 --> 1.199717).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 26.9714298
	speed: 0.0504s/iter; left time: 1103.7228s
	iters: 200, epoch: 4 | loss: 27.3070698
	speed: 0.0466s/iter; left time: 1016.4104s
Epoch: 4 cost time: 10.952717542648315
Epoch: 4, Steps: 227 Train Loss: 27.2954 (Forecasting Loss:0.6010 + XiCon Loss:2.6694 x Lambda(10.0)), Vali MSE Loss: 1.1925 Test MSE Loss: 1.2721
Validation loss decreased (1.199717 --> 1.192490).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 26.9795914
	speed: 0.0483s/iter; left time: 1048.2020s
	iters: 200, epoch: 5 | loss: 26.7217884
	speed: 0.0443s/iter; left time: 957.0692s
Epoch: 5 cost time: 10.571952104568481
Epoch: 5, Steps: 227 Train Loss: 27.2100 (Forecasting Loss:0.5980 + XiCon Loss:2.6612 x Lambda(10.0)), Vali MSE Loss: 1.1894 Test MSE Loss: 1.2712
Validation loss decreased (1.192490 --> 1.189394).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 27.0328064
	speed: 0.0487s/iter; left time: 1044.7158s
	iters: 200, epoch: 6 | loss: 27.4266834
	speed: 0.0493s/iter; left time: 1052.7774s
Epoch: 6 cost time: 11.019209861755371
Epoch: 6, Steps: 227 Train Loss: 27.1761 (Forecasting Loss:0.5968 + XiCon Loss:2.6579 x Lambda(10.0)), Vali MSE Loss: 1.1882 Test MSE Loss: 1.2707
Validation loss decreased (1.189394 --> 1.188190).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 26.8004303
	speed: 0.0499s/iter; left time: 1059.4486s
	iters: 200, epoch: 7 | loss: 27.2836113
	speed: 0.0439s/iter; left time: 928.5548s
Epoch: 7 cost time: 10.715039014816284
Epoch: 7, Steps: 227 Train Loss: 27.1638 (Forecasting Loss:0.5962 + XiCon Loss:2.6568 x Lambda(10.0)), Vali MSE Loss: 1.1872 Test MSE Loss: 1.2706
Validation loss decreased (1.188190 --> 1.187181).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 26.8310394
	speed: 0.0491s/iter; left time: 1030.8374s
	iters: 200, epoch: 8 | loss: 26.5994701
	speed: 0.0443s/iter; left time: 925.3836s
Epoch: 8 cost time: 10.579331636428833
Epoch: 8, Steps: 227 Train Loss: 27.1595 (Forecasting Loss:0.5959 + XiCon Loss:2.6564 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2705
Validation loss decreased (1.187181 --> 1.187063).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 26.6810837
	speed: 0.0487s/iter; left time: 1011.4751s
	iters: 200, epoch: 9 | loss: 27.4880104
	speed: 0.0456s/iter; left time: 943.0579s
Epoch: 9 cost time: 10.719007730484009
Epoch: 9, Steps: 227 Train Loss: 27.1365 (Forecasting Loss:0.5956 + XiCon Loss:2.6541 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2705
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 27.4903278
	speed: 0.0505s/iter; left time: 1037.4344s
	iters: 200, epoch: 10 | loss: 27.5456028
	speed: 0.0434s/iter; left time: 888.3677s
Epoch: 10 cost time: 10.594890594482422
Epoch: 10, Steps: 227 Train Loss: 27.1592 (Forecasting Loss:0.5953 + XiCon Loss:2.6564 x Lambda(10.0)), Vali MSE Loss: 1.1874 Test MSE Loss: 1.2705
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 27.0712872
	speed: 0.0493s/iter; left time: 1003.2230s
	iters: 200, epoch: 11 | loss: 26.9708252
	speed: 0.0431s/iter; left time: 872.0133s
Epoch: 11 cost time: 10.414376258850098
Epoch: 11, Steps: 227 Train Loss: 27.1160 (Forecasting Loss:0.5952 + XiCon Loss:2.6521 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2704
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 26.9860573
	speed: 0.0471s/iter; left time: 946.4862s
	iters: 200, epoch: 12 | loss: 26.8645267
	speed: 0.0438s/iter; left time: 876.6672s
Epoch: 12 cost time: 10.300158977508545
Epoch: 12, Steps: 227 Train Loss: 27.1230 (Forecasting Loss:0.5952 + XiCon Loss:2.6528 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2704
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 26.8551788
	speed: 0.0483s/iter; left time: 961.0058s
	iters: 200, epoch: 13 | loss: 27.3764019
	speed: 0.0428s/iter; left time: 845.9107s
Epoch: 13 cost time: 10.327867269515991
Epoch: 13, Steps: 227 Train Loss: 27.1349 (Forecasting Loss:0.5953 + XiCon Loss:2.6540 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2704
Validation loss decreased (1.187063 --> 1.187063).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 27.1243973
	speed: 0.0504s/iter; left time: 990.2478s
	iters: 200, epoch: 14 | loss: 26.8295288
	speed: 0.0427s/iter; left time: 835.7518s
Epoch: 14 cost time: 10.49604320526123
Epoch: 14, Steps: 227 Train Loss: 27.1573 (Forecasting Loss:0.5952 + XiCon Loss:2.6562 x Lambda(10.0)), Vali MSE Loss: 1.1863 Test MSE Loss: 1.2704
Validation loss decreased (1.187063 --> 1.186276).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 27.2729321
	speed: 0.0471s/iter; left time: 914.4729s
	iters: 200, epoch: 15 | loss: 27.4149303
	speed: 0.0424s/iter; left time: 819.6860s
Epoch: 15 cost time: 10.115594863891602
Epoch: 15, Steps: 227 Train Loss: 27.1453 (Forecasting Loss:0.5953 + XiCon Loss:2.6550 x Lambda(10.0)), Vali MSE Loss: 1.1868 Test MSE Loss: 1.2704
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 27.3346767
	speed: 0.0471s/iter; left time: 904.6154s
	iters: 200, epoch: 16 | loss: 27.1354504
	speed: 0.0459s/iter; left time: 877.0509s
Epoch: 16 cost time: 10.580596208572388
Epoch: 16, Steps: 227 Train Loss: 27.1579 (Forecasting Loss:0.5953 + XiCon Loss:2.6563 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2704
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 26.6421585
	speed: 0.0966s/iter; left time: 1832.9176s
	iters: 200, epoch: 17 | loss: 27.2502346
	speed: 0.1013s/iter; left time: 1911.4056s
Epoch: 17 cost time: 22.41531991958618
Epoch: 17, Steps: 227 Train Loss: 27.1352 (Forecasting Loss:0.5953 + XiCon Loss:2.6540 x Lambda(10.0)), Vali MSE Loss: 1.1871 Test MSE Loss: 1.2704
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 26.9699574
	speed: 0.1082s/iter; left time: 2027.9690s
	iters: 200, epoch: 18 | loss: 26.9873486
	speed: 0.1053s/iter; left time: 1963.7177s
Epoch: 18 cost time: 24.693374395370483
Epoch: 18, Steps: 227 Train Loss: 27.1316 (Forecasting Loss:0.5952 + XiCon Loss:2.6536 x Lambda(10.0)), Vali MSE Loss: 1.1870 Test MSE Loss: 1.2704
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 26.5550919
	speed: 0.1268s/iter; left time: 2347.7247s
	iters: 200, epoch: 19 | loss: 26.9914780
	speed: 0.1194s/iter; left time: 2199.5920s
Epoch: 19 cost time: 27.66744089126587
Epoch: 19, Steps: 227 Train Loss: 27.1546 (Forecasting Loss:0.5951 + XiCon Loss:2.6559 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2704
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 27.1731873
	speed: 0.1170s/iter; left time: 2139.7413s
	iters: 200, epoch: 20 | loss: 27.0239353
	speed: 0.1030s/iter; left time: 1873.7212s
Epoch: 20 cost time: 24.69225525856018
Epoch: 20, Steps: 227 Train Loss: 27.1610 (Forecasting Loss:0.5951 + XiCon Loss:2.6566 x Lambda(10.0)), Vali MSE Loss: 1.1873 Test MSE Loss: 1.2704
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 26.4502048
	speed: 0.0962s/iter; left time: 1737.1079s
	iters: 200, epoch: 21 | loss: 27.6442261
	speed: 0.0855s/iter; left time: 1535.4784s
Epoch: 21 cost time: 20.501261472702026
Epoch: 21, Steps: 227 Train Loss: 27.1408 (Forecasting Loss:0.5952 + XiCon Loss:2.6546 x Lambda(10.0)), Vali MSE Loss: 1.1872 Test MSE Loss: 1.2704
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 26.5972977
	speed: 0.0901s/iter; left time: 1606.0218s
	iters: 200, epoch: 22 | loss: 26.8798885
	speed: 0.0681s/iter; left time: 1208.1928s
Epoch: 22 cost time: 17.190070152282715
Epoch: 22, Steps: 227 Train Loss: 27.1296 (Forecasting Loss:0.5954 + XiCon Loss:2.6534 x Lambda(10.0)), Vali MSE Loss: 1.1869 Test MSE Loss: 1.2704
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 27.1458397
	speed: 0.0628s/iter; left time: 1105.0573s
	iters: 200, epoch: 23 | loss: 27.5164795
	speed: 0.0524s/iter; left time: 918.1940s
Epoch: 23 cost time: 12.905060529708862
Epoch: 23, Steps: 227 Train Loss: 27.1468 (Forecasting Loss:0.5953 + XiCon Loss:2.6551 x Lambda(10.0)), Vali MSE Loss: 1.1872 Test MSE Loss: 1.2704
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 27.0639687
	speed: 0.0488s/iter; left time: 848.7338s
	iters: 200, epoch: 24 | loss: 27.2950153
	speed: 0.0451s/iter; left time: 779.6311s
Epoch: 24 cost time: 10.66072392463684
Epoch: 24, Steps: 227 Train Loss: 27.1484 (Forecasting Loss:0.5954 + XiCon Loss:2.6553 x Lambda(10.0)), Vali MSE Loss: 1.1875 Test MSE Loss: 1.2704
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.587975025177002, mae:0.9528985023498535, mape:6.181237697601318, mspe:4709.96142578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5908+-0.01181, MAE:0.9552+-0.00698, MAPE:6.2662+-0.23026, MSPE:4846.4062+-393.84966, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
