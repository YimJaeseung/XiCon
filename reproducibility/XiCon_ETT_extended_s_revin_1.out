Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5495
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3180280
	speed: 0.0217s/iter; left time: 275.8385s
Epoch: 1 cost time: 2.6016788482666016
Epoch: 1, Steps: 128 Train Loss: 3.3407 (Forecasting Loss:0.2444 + XiCon Loss:3.0963 x Lambda(1.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173681).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1608026
	speed: 0.0191s/iter; left time: 240.6031s
Epoch: 2 cost time: 2.4310479164123535
Epoch: 2, Steps: 128 Train Loss: 3.1571 (Forecasting Loss:0.2458 + XiCon Loss:2.9113 x Lambda(1.0)), Vali MSE Loss: 0.1763 Test MSE Loss: 0.1332
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0204244
	speed: 0.0214s/iter; left time: 266.0683s
Epoch: 3 cost time: 2.6003406047821045
Epoch: 3, Steps: 128 Train Loss: 3.1467 (Forecasting Loss:0.2313 + XiCon Loss:2.9154 x Lambda(1.0)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1218
Validation loss decreased (0.173681 --> 0.168434).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0192974
	speed: 0.0196s/iter; left time: 241.8588s
Epoch: 4 cost time: 2.4437735080718994
Epoch: 4, Steps: 128 Train Loss: 3.0927 (Forecasting Loss:0.2216 + XiCon Loss:2.8711 x Lambda(1.0)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1135
Validation loss decreased (0.168434 --> 0.167975).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0043843
	speed: 0.0221s/iter; left time: 269.1146s
Epoch: 5 cost time: 2.5952980518341064
Epoch: 5, Steps: 128 Train Loss: 3.0784 (Forecasting Loss:0.2158 + XiCon Loss:2.8626 x Lambda(1.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1148
Validation loss decreased (0.167975 --> 0.165562).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 2.9991212
	speed: 0.0220s/iter; left time: 265.1317s
Epoch: 6 cost time: 2.6191940307617188
Epoch: 6, Steps: 128 Train Loss: 3.0716 (Forecasting Loss:0.2140 + XiCon Loss:2.8575 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1142
Validation loss decreased (0.165562 --> 0.164783).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0996137
	speed: 0.0186s/iter; left time: 222.4514s
Epoch: 7 cost time: 2.28580379486084
Epoch: 7, Steps: 128 Train Loss: 3.0701 (Forecasting Loss:0.2128 + XiCon Loss:2.8573 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1156
Validation loss decreased (0.164783 --> 0.163412).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0632579
	speed: 0.0189s/iter; left time: 223.1956s
Epoch: 8 cost time: 2.4038264751434326
Epoch: 8, Steps: 128 Train Loss: 3.0682 (Forecasting Loss:0.2124 + XiCon Loss:2.8558 x Lambda(1.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1697607
	speed: 0.0185s/iter; left time: 215.5289s
Epoch: 9 cost time: 2.363429069519043
Epoch: 9, Steps: 128 Train Loss: 3.0634 (Forecasting Loss:0.2120 + XiCon Loss:2.8514 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1146
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0452998
	speed: 0.0187s/iter; left time: 215.8577s
Epoch: 10 cost time: 2.2758748531341553
Epoch: 10, Steps: 128 Train Loss: 3.0645 (Forecasting Loss:0.2117 + XiCon Loss:2.8528 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1144
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0504079
	speed: 0.0177s/iter; left time: 202.4618s
Epoch: 11 cost time: 2.2248573303222656
Epoch: 11, Steps: 128 Train Loss: 3.0571 (Forecasting Loss:0.2116 + XiCon Loss:2.8456 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0621109
	speed: 0.0209s/iter; left time: 236.0078s
Epoch: 12 cost time: 2.567500114440918
Epoch: 12, Steps: 128 Train Loss: 3.0602 (Forecasting Loss:0.2114 + XiCon Loss:2.8488 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1144
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1140633
	speed: 0.0192s/iter; left time: 214.8707s
Epoch: 13 cost time: 2.344097852706909
Epoch: 13, Steps: 128 Train Loss: 3.0598 (Forecasting Loss:0.2114 + XiCon Loss:2.8484 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1229842
	speed: 0.0185s/iter; left time: 204.4149s
Epoch: 14 cost time: 2.355485200881958
Epoch: 14, Steps: 128 Train Loss: 3.0642 (Forecasting Loss:0.2116 + XiCon Loss:2.8526 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1604695
	speed: 0.0180s/iter; left time: 196.6700s
Epoch: 15 cost time: 2.1265065670013428
Epoch: 15, Steps: 128 Train Loss: 3.0687 (Forecasting Loss:0.2115 + XiCon Loss:2.8573 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1145
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 2.9847493
	speed: 0.0186s/iter; left time: 200.6176s
Epoch: 16 cost time: 2.3913726806640625
Epoch: 16, Steps: 128 Train Loss: 3.0661 (Forecasting Loss:0.2115 + XiCon Loss:2.8546 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1145
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0237262
	speed: 0.0192s/iter; left time: 204.6877s
Epoch: 17 cost time: 2.430711269378662
Epoch: 17, Steps: 128 Train Loss: 3.0584 (Forecasting Loss:0.2115 + XiCon Loss:2.8469 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05403978377580643, mae:0.17718061804771423, mape:0.14120197296142578, mspe:0.037212394177913666 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4394
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2712445
	speed: 0.0198s/iter; left time: 251.4356s
Epoch: 1 cost time: 2.3553473949432373
Epoch: 1, Steps: 128 Train Loss: 3.3167 (Forecasting Loss:0.2417 + XiCon Loss:3.0751 x Lambda(1.0)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1215
Validation loss decreased (inf --> 0.173852).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1437044
	speed: 0.0218s/iter; left time: 273.6095s
Epoch: 2 cost time: 2.675743579864502
Epoch: 2, Steps: 128 Train Loss: 3.1276 (Forecasting Loss:0.2444 + XiCon Loss:2.8832 x Lambda(1.0)), Vali MSE Loss: 0.1793 Test MSE Loss: 0.1218
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1820650
	speed: 0.0156s/iter; left time: 193.9637s
Epoch: 3 cost time: 2.0968637466430664
Epoch: 3, Steps: 128 Train Loss: 3.1618 (Forecasting Loss:0.2326 + XiCon Loss:2.9292 x Lambda(1.0)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1214
Validation loss decreased (0.173852 --> 0.168398).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1068943
	speed: 0.0160s/iter; left time: 197.1390s
Epoch: 4 cost time: 1.9001367092132568
Epoch: 4, Steps: 128 Train Loss: 3.1200 (Forecasting Loss:0.2228 + XiCon Loss:2.8972 x Lambda(1.0)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1197
Validation loss decreased (0.168398 --> 0.166857).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0595200
	speed: 0.0210s/iter; left time: 255.8847s
Epoch: 5 cost time: 2.629084825515747
Epoch: 5, Steps: 128 Train Loss: 3.0864 (Forecasting Loss:0.2177 + XiCon Loss:2.8687 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1161
Validation loss decreased (0.166857 --> 0.164842).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0739810
	speed: 0.0221s/iter; left time: 266.0125s
Epoch: 6 cost time: 2.593407392501831
Epoch: 6, Steps: 128 Train Loss: 3.0798 (Forecasting Loss:0.2156 + XiCon Loss:2.8642 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1160
Validation loss decreased (0.164842 --> 0.164324).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1166801
	speed: 0.0206s/iter; left time: 245.5699s
Epoch: 7 cost time: 2.5119893550872803
Epoch: 7, Steps: 128 Train Loss: 3.0695 (Forecasting Loss:0.2139 + XiCon Loss:2.8556 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1139
Validation loss decreased (0.164324 --> 0.163721).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1333327
	speed: 0.0182s/iter; left time: 215.2257s
Epoch: 8 cost time: 2.2601938247680664
Epoch: 8, Steps: 128 Train Loss: 3.0663 (Forecasting Loss:0.2131 + XiCon Loss:2.8532 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1143
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.1111956
	speed: 0.0196s/iter; left time: 229.0950s
Epoch: 9 cost time: 2.386604070663452
Epoch: 9, Steps: 128 Train Loss: 3.0705 (Forecasting Loss:0.2128 + XiCon Loss:2.8577 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1140
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0821452
	speed: 0.0186s/iter; left time: 214.3125s
Epoch: 10 cost time: 2.351621389389038
Epoch: 10, Steps: 128 Train Loss: 3.0683 (Forecasting Loss:0.2127 + XiCon Loss:2.8557 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1142
Validation loss decreased (0.163721 --> 0.163667).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1069791
	speed: 0.0197s/iter; left time: 225.5445s
Epoch: 11 cost time: 2.501584053039551
Epoch: 11, Steps: 128 Train Loss: 3.0656 (Forecasting Loss:0.2126 + XiCon Loss:2.8530 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1142
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 2.9938776
	speed: 0.0192s/iter; left time: 216.4888s
Epoch: 12 cost time: 2.5434036254882812
Epoch: 12, Steps: 128 Train Loss: 3.0686 (Forecasting Loss:0.2124 + XiCon Loss:2.8562 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1141
Validation loss decreased (0.163667 --> 0.163561).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0182476
	speed: 0.0181s/iter; left time: 202.2587s
Epoch: 13 cost time: 2.113105297088623
Epoch: 13, Steps: 128 Train Loss: 3.0692 (Forecasting Loss:0.2126 + XiCon Loss:2.8566 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 2.9831364
	speed: 0.0208s/iter; left time: 229.9882s
Epoch: 14 cost time: 2.477870225906372
Epoch: 14, Steps: 128 Train Loss: 3.0584 (Forecasting Loss:0.2125 + XiCon Loss:2.8459 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0671256
	speed: 0.0217s/iter; left time: 236.8339s
Epoch: 15 cost time: 2.6896331310272217
Epoch: 15, Steps: 128 Train Loss: 3.0679 (Forecasting Loss:0.2124 + XiCon Loss:2.8555 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1141
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0915649
	speed: 0.0203s/iter; left time: 218.4595s
Epoch: 16 cost time: 2.416553020477295
Epoch: 16, Steps: 128 Train Loss: 3.0670 (Forecasting Loss:0.2124 + XiCon Loss:2.8546 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1141
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0474360
	speed: 0.0167s/iter; left time: 177.6449s
Epoch: 17 cost time: 2.1198277473449707
Epoch: 17, Steps: 128 Train Loss: 3.0737 (Forecasting Loss:0.2124 + XiCon Loss:2.8613 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1141
Validation loss decreased (0.163561 --> 0.163407).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.0353277
	speed: 0.0157s/iter; left time: 165.1574s
Epoch: 18 cost time: 2.186530113220215
Epoch: 18, Steps: 128 Train Loss: 3.0627 (Forecasting Loss:0.2124 + XiCon Loss:2.8503 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0246274
	speed: 0.0183s/iter; left time: 189.9641s
Epoch: 19 cost time: 2.31471586227417
Epoch: 19, Steps: 128 Train Loss: 3.0622 (Forecasting Loss:0.2126 + XiCon Loss:2.8496 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1819015
	speed: 0.0187s/iter; left time: 192.2772s
Epoch: 20 cost time: 2.298997640609741
Epoch: 20, Steps: 128 Train Loss: 3.0608 (Forecasting Loss:0.2125 + XiCon Loss:2.8483 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1141
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0320699
	speed: 0.0192s/iter; left time: 194.2336s
Epoch: 21 cost time: 2.3429784774780273
Epoch: 21, Steps: 128 Train Loss: 3.0685 (Forecasting Loss:0.2125 + XiCon Loss:2.8560 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1141
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1625524
	speed: 0.0221s/iter; left time: 221.0611s
Epoch: 22 cost time: 2.646280288696289
Epoch: 22, Steps: 128 Train Loss: 3.0677 (Forecasting Loss:0.2125 + XiCon Loss:2.8552 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1141
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0169485
	speed: 0.0225s/iter; left time: 222.6177s
Epoch: 23 cost time: 2.7480859756469727
Epoch: 23, Steps: 128 Train Loss: 3.0652 (Forecasting Loss:0.2125 + XiCon Loss:2.8526 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1141
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0357854
	speed: 0.0198s/iter; left time: 193.3252s
Epoch: 24 cost time: 2.4650228023529053
Epoch: 24, Steps: 128 Train Loss: 3.0581 (Forecasting Loss:0.2125 + XiCon Loss:2.8457 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1141
Validation loss decreased (0.163407 --> 0.163401).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0415413
	speed: 0.0145s/iter; left time: 139.8488s
Epoch: 25 cost time: 1.9520957469940186
Epoch: 25, Steps: 128 Train Loss: 3.0679 (Forecasting Loss:0.2126 + XiCon Loss:2.8553 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1141
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0920570
	speed: 0.0194s/iter; left time: 183.9449s
Epoch: 26 cost time: 2.2406866550445557
Epoch: 26, Steps: 128 Train Loss: 3.0666 (Forecasting Loss:0.2124 + XiCon Loss:2.8542 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1141
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0493677
	speed: 0.0202s/iter; left time: 189.7151s
Epoch: 27 cost time: 2.42854642868042
Epoch: 27, Steps: 128 Train Loss: 3.0683 (Forecasting Loss:0.2125 + XiCon Loss:2.8558 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1141
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0793664
	speed: 0.0208s/iter; left time: 192.2137s
Epoch: 28 cost time: 2.54134202003479
Epoch: 28, Steps: 128 Train Loss: 3.0654 (Forecasting Loss:0.2126 + XiCon Loss:2.8528 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1141
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0410466
	speed: 0.0190s/iter; left time: 173.0582s
Epoch: 29 cost time: 2.418325662612915
Epoch: 29, Steps: 128 Train Loss: 3.0633 (Forecasting Loss:0.2125 + XiCon Loss:2.8507 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1141
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.0255742
	speed: 0.0215s/iter; left time: 192.9739s
Epoch: 30 cost time: 2.6080381870269775
Epoch: 30, Steps: 128 Train Loss: 3.0601 (Forecasting Loss:0.2124 + XiCon Loss:2.8477 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1141
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1176612
	speed: 0.0185s/iter; left time: 163.6908s
Epoch: 31 cost time: 2.256451368331909
Epoch: 31, Steps: 128 Train Loss: 3.0687 (Forecasting Loss:0.2126 + XiCon Loss:2.8562 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1141
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0758059
	speed: 0.0157s/iter; left time: 137.4816s
Epoch: 32 cost time: 1.900373935699463
Epoch: 32, Steps: 128 Train Loss: 3.0638 (Forecasting Loss:0.2124 + XiCon Loss:2.8514 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1141
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0903893
	speed: 0.0193s/iter; left time: 166.4540s
Epoch: 33 cost time: 2.326719045639038
Epoch: 33, Steps: 128 Train Loss: 3.0699 (Forecasting Loss:0.2125 + XiCon Loss:2.8575 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1141
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0443151
	speed: 0.0189s/iter; left time: 160.1280s
Epoch: 34 cost time: 2.2709968090057373
Epoch: 34, Steps: 128 Train Loss: 3.0664 (Forecasting Loss:0.2125 + XiCon Loss:2.8539 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1141
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05303815007209778, mae:0.17519135773181915, mape:0.13954371213912964, mspe:0.03658125549554825 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5011
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2466989
	speed: 0.0200s/iter; left time: 253.9484s
Epoch: 1 cost time: 2.442035436630249
Epoch: 1, Steps: 128 Train Loss: 3.2984 (Forecasting Loss:0.2446 + XiCon Loss:3.0538 x Lambda(1.0)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1204
Validation loss decreased (inf --> 0.173095).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1424744
	speed: 0.0175s/iter; left time: 220.5384s
Epoch: 2 cost time: 2.1916134357452393
Epoch: 2, Steps: 128 Train Loss: 3.1379 (Forecasting Loss:0.2445 + XiCon Loss:2.8934 x Lambda(1.0)), Vali MSE Loss: 0.1776 Test MSE Loss: 0.1271
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1624599
	speed: 0.0186s/iter; left time: 231.3192s
Epoch: 3 cost time: 2.2660956382751465
Epoch: 3, Steps: 128 Train Loss: 3.0990 (Forecasting Loss:0.2285 + XiCon Loss:2.8706 x Lambda(1.0)), Vali MSE Loss: 0.1691 Test MSE Loss: 0.1199
Validation loss decreased (0.173095 --> 0.169137).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0844138
	speed: 0.0192s/iter; left time: 236.1286s
Epoch: 4 cost time: 2.389493465423584
Epoch: 4, Steps: 128 Train Loss: 3.1454 (Forecasting Loss:0.2212 + XiCon Loss:2.9243 x Lambda(1.0)), Vali MSE Loss: 0.1664 Test MSE Loss: 0.1163
Validation loss decreased (0.169137 --> 0.166382).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.1368263
	speed: 0.0181s/iter; left time: 220.3454s
Epoch: 5 cost time: 2.3604817390441895
Epoch: 5, Steps: 128 Train Loss: 3.1119 (Forecasting Loss:0.2153 + XiCon Loss:2.8966 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1141
Validation loss decreased (0.166382 --> 0.164486).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0651309
	speed: 0.0177s/iter; left time: 213.4915s
Epoch: 6 cost time: 2.2231390476226807
Epoch: 6, Steps: 128 Train Loss: 3.0827 (Forecasting Loss:0.2119 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1175
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0932777
	speed: 0.0184s/iter; left time: 219.1661s
Epoch: 7 cost time: 2.2481701374053955
Epoch: 7, Steps: 128 Train Loss: 3.0776 (Forecasting Loss:0.2086 + XiCon Loss:2.8691 x Lambda(1.0)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1180
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0353851
	speed: 0.0187s/iter; left time: 220.7365s
Epoch: 8 cost time: 2.2966065406799316
Epoch: 8, Steps: 128 Train Loss: 3.0645 (Forecasting Loss:0.2069 + XiCon Loss:2.8577 x Lambda(1.0)), Vali MSE Loss: 0.1705 Test MSE Loss: 0.1182
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0775621
	speed: 0.0236s/iter; left time: 275.0177s
Epoch: 9 cost time: 2.791038751602173
Epoch: 9, Steps: 128 Train Loss: 3.0746 (Forecasting Loss:0.2066 + XiCon Loss:2.8680 x Lambda(1.0)), Vali MSE Loss: 0.1728 Test MSE Loss: 0.1184
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.1454809
	speed: 0.0197s/iter; left time: 227.8513s
Epoch: 10 cost time: 2.382842540740967
Epoch: 10, Steps: 128 Train Loss: 3.0707 (Forecasting Loss:0.2064 + XiCon Loss:2.8642 x Lambda(1.0)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1189
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1309938
	speed: 0.0210s/iter; left time: 239.7219s
Epoch: 11 cost time: 2.5426387786865234
Epoch: 11, Steps: 128 Train Loss: 3.0709 (Forecasting Loss:0.2064 + XiCon Loss:2.8646 x Lambda(1.0)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1188
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1101665
	speed: 0.0209s/iter; left time: 235.5743s
Epoch: 12 cost time: 2.511472225189209
Epoch: 12, Steps: 128 Train Loss: 3.0737 (Forecasting Loss:0.2057 + XiCon Loss:2.8679 x Lambda(1.0)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1188
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0246990
	speed: 0.0191s/iter; left time: 213.2301s
Epoch: 13 cost time: 2.352992057800293
Epoch: 13, Steps: 128 Train Loss: 3.0672 (Forecasting Loss:0.2057 + XiCon Loss:2.8615 x Lambda(1.0)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1187
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 2.9972420
	speed: 0.0209s/iter; left time: 230.1653s
Epoch: 14 cost time: 2.6025121212005615
Epoch: 14, Steps: 128 Train Loss: 3.0649 (Forecasting Loss:0.2059 + XiCon Loss:2.8591 x Lambda(1.0)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1187
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0753341
	speed: 0.0203s/iter; left time: 220.9173s
Epoch: 15 cost time: 2.552807331085205
Epoch: 15, Steps: 128 Train Loss: 3.0716 (Forecasting Loss:0.2061 + XiCon Loss:2.8656 x Lambda(1.0)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1187
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.053240757435560226, mae:0.17494499683380127, mape:0.14010797441005707, mspe:0.0380927212536335 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5605
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2870989
	speed: 0.0207s/iter; left time: 262.6743s
Epoch: 1 cost time: 2.503568172454834
Epoch: 1, Steps: 128 Train Loss: 3.3211 (Forecasting Loss:0.2455 + XiCon Loss:3.0756 x Lambda(1.0)), Vali MSE Loss: 0.1755 Test MSE Loss: 0.1221
Validation loss decreased (inf --> 0.175536).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.2383275
	speed: 0.0222s/iter; left time: 279.3459s
Epoch: 2 cost time: 2.609724521636963
Epoch: 2, Steps: 128 Train Loss: 3.1753 (Forecasting Loss:0.2458 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.1774 Test MSE Loss: 0.1270
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1449215
	speed: 0.0208s/iter; left time: 258.2411s
Epoch: 3 cost time: 2.527869462966919
Epoch: 3, Steps: 128 Train Loss: 3.1663 (Forecasting Loss:0.2294 + XiCon Loss:2.9370 x Lambda(1.0)), Vali MSE Loss: 0.1687 Test MSE Loss: 0.1198
Validation loss decreased (0.175536 --> 0.168714).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.2115977
	speed: 0.0195s/iter; left time: 240.5538s
Epoch: 4 cost time: 2.401386022567749
Epoch: 4, Steps: 128 Train Loss: 3.1080 (Forecasting Loss:0.2206 + XiCon Loss:2.8873 x Lambda(1.0)), Vali MSE Loss: 0.1676 Test MSE Loss: 0.1144
Validation loss decreased (0.168714 --> 0.167596).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0640645
	speed: 0.0186s/iter; left time: 226.1912s
Epoch: 5 cost time: 2.5443828105926514
Epoch: 5, Steps: 128 Train Loss: 3.0949 (Forecasting Loss:0.2175 + XiCon Loss:2.8774 x Lambda(1.0)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1135
Validation loss decreased (0.167596 --> 0.166126).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.0329483
	speed: 0.0181s/iter; left time: 218.8524s
Epoch: 6 cost time: 2.3320446014404297
Epoch: 6, Steps: 128 Train Loss: 3.0860 (Forecasting Loss:0.2150 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1166
Validation loss decreased (0.166126 --> 0.164340).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.0295966
	speed: 0.0171s/iter; left time: 203.7099s
Epoch: 7 cost time: 2.217973232269287
Epoch: 7, Steps: 128 Train Loss: 3.0740 (Forecasting Loss:0.2138 + XiCon Loss:2.8603 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1146
Validation loss decreased (0.164340 --> 0.164164).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.0563467
	speed: 0.0183s/iter; left time: 215.8133s
Epoch: 8 cost time: 2.3993945121765137
Epoch: 8, Steps: 128 Train Loss: 3.0817 (Forecasting Loss:0.2135 + XiCon Loss:2.8682 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1145
Validation loss decreased (0.164164 --> 0.163399).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0288823
	speed: 0.0171s/iter; left time: 199.2533s
Epoch: 9 cost time: 2.1682658195495605
Epoch: 9, Steps: 128 Train Loss: 3.0826 (Forecasting Loss:0.2130 + XiCon Loss:2.8696 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0981445
	speed: 0.0189s/iter; left time: 218.8406s
Epoch: 10 cost time: 2.4954586029052734
Epoch: 10, Steps: 128 Train Loss: 3.0719 (Forecasting Loss:0.2128 + XiCon Loss:2.8591 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1146
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.0375984
	speed: 0.0198s/iter; left time: 226.5536s
Epoch: 11 cost time: 2.567556142807007
Epoch: 11, Steps: 128 Train Loss: 3.0752 (Forecasting Loss:0.2128 + XiCon Loss:2.8624 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
Validation loss decreased (0.163399 --> 0.163319).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0423067
	speed: 0.0203s/iter; left time: 229.1548s
Epoch: 12 cost time: 2.602775812149048
Epoch: 12, Steps: 128 Train Loss: 3.0748 (Forecasting Loss:0.2126 + XiCon Loss:2.8623 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
Validation loss decreased (0.163319 --> 0.163032).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1061139
	speed: 0.0181s/iter; left time: 201.8192s
Epoch: 13 cost time: 2.4034838676452637
Epoch: 13, Steps: 128 Train Loss: 3.0752 (Forecasting Loss:0.2127 + XiCon Loss:2.8625 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
Validation loss decreased (0.163032 --> 0.163026).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0613959
	speed: 0.0189s/iter; left time: 209.0092s
Epoch: 14 cost time: 2.425701379776001
Epoch: 14, Steps: 128 Train Loss: 3.0736 (Forecasting Loss:0.2127 + XiCon Loss:2.8610 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0942750
	speed: 0.0196s/iter; left time: 213.6641s
Epoch: 15 cost time: 2.397955894470215
Epoch: 15, Steps: 128 Train Loss: 3.0760 (Forecasting Loss:0.2124 + XiCon Loss:2.8636 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1144109
	speed: 0.0189s/iter; left time: 203.8697s
Epoch: 16 cost time: 2.2918238639831543
Epoch: 16, Steps: 128 Train Loss: 3.0742 (Forecasting Loss:0.2125 + XiCon Loss:2.8617 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1525474
	speed: 0.0209s/iter; left time: 222.1170s
Epoch: 17 cost time: 2.5276947021484375
Epoch: 17, Steps: 128 Train Loss: 3.0765 (Forecasting Loss:0.2127 + XiCon Loss:2.8638 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.0393386
	speed: 0.0221s/iter; left time: 232.5850s
Epoch: 18 cost time: 2.618323802947998
Epoch: 18, Steps: 128 Train Loss: 3.0685 (Forecasting Loss:0.2126 + XiCon Loss:2.8558 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1085546
	speed: 0.0229s/iter; left time: 238.5364s
Epoch: 19 cost time: 2.749335289001465
Epoch: 19, Steps: 128 Train Loss: 3.0708 (Forecasting Loss:0.2127 + XiCon Loss:2.8581 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0306890
	speed: 0.0173s/iter; left time: 177.5303s
Epoch: 20 cost time: 2.102311611175537
Epoch: 20, Steps: 128 Train Loss: 3.0682 (Forecasting Loss:0.2125 + XiCon Loss:2.8557 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.0389535
	speed: 0.0191s/iter; left time: 193.9750s
Epoch: 21 cost time: 2.484339714050293
Epoch: 21, Steps: 128 Train Loss: 3.0732 (Forecasting Loss:0.2126 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0820878
	speed: 0.0170s/iter; left time: 170.2039s
Epoch: 22 cost time: 2.173344850540161
Epoch: 22, Steps: 128 Train Loss: 3.0676 (Forecasting Loss:0.2126 + XiCon Loss:2.8550 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.1090672
	speed: 0.0202s/iter; left time: 199.9533s
Epoch: 23 cost time: 2.621091842651367
Epoch: 23, Steps: 128 Train Loss: 3.0738 (Forecasting Loss:0.2127 + XiCon Loss:2.8611 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1148
Validation loss decreased (0.163026 --> 0.163018).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.0610735
	speed: 0.0172s/iter; left time: 167.9429s
Epoch: 24 cost time: 2.199674367904663
Epoch: 24, Steps: 128 Train Loss: 3.0779 (Forecasting Loss:0.2126 + XiCon Loss:2.8653 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.1395745
	speed: 0.0179s/iter; left time: 172.3945s
Epoch: 25 cost time: 2.238614797592163
Epoch: 25, Steps: 128 Train Loss: 3.0732 (Forecasting Loss:0.2126 + XiCon Loss:2.8606 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.0384250
	speed: 0.0204s/iter; left time: 193.4577s
Epoch: 26 cost time: 2.5261361598968506
Epoch: 26, Steps: 128 Train Loss: 3.0725 (Forecasting Loss:0.2126 + XiCon Loss:2.8599 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.0066891
	speed: 0.0185s/iter; left time: 173.4130s
Epoch: 27 cost time: 2.2800116539001465
Epoch: 27, Steps: 128 Train Loss: 3.0755 (Forecasting Loss:0.2126 + XiCon Loss:2.8630 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.0504608
	speed: 0.0190s/iter; left time: 175.5006s
Epoch: 28 cost time: 2.360898017883301
Epoch: 28, Steps: 128 Train Loss: 3.0743 (Forecasting Loss:0.2127 + XiCon Loss:2.8616 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.0120904
	speed: 0.0212s/iter; left time: 193.1017s
Epoch: 29 cost time: 2.627664089202881
Epoch: 29, Steps: 128 Train Loss: 3.0754 (Forecasting Loss:0.2127 + XiCon Loss:2.8627 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.0690985
	speed: 0.0228s/iter; left time: 204.6427s
Epoch: 30 cost time: 2.777801752090454
Epoch: 30, Steps: 128 Train Loss: 3.0742 (Forecasting Loss:0.2127 + XiCon Loss:2.8615 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.1083479
	speed: 0.0222s/iter; left time: 196.4573s
Epoch: 31 cost time: 2.843890905380249
Epoch: 31, Steps: 128 Train Loss: 3.0722 (Forecasting Loss:0.2125 + XiCon Loss:2.8597 x Lambda(1.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1148
Validation loss decreased (0.163018 --> 0.162801).  Saving model ...
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.0603225
	speed: 0.0244s/iter; left time: 213.3800s
Epoch: 32 cost time: 2.8556835651397705
Epoch: 32, Steps: 128 Train Loss: 3.0781 (Forecasting Loss:0.2125 + XiCon Loss:2.8656 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.0438125
	speed: 0.0206s/iter; left time: 176.8701s
Epoch: 33 cost time: 2.4928951263427734
Epoch: 33, Steps: 128 Train Loss: 3.0740 (Forecasting Loss:0.2127 + XiCon Loss:2.8613 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0904174
	speed: 0.0193s/iter; left time: 163.3874s
Epoch: 34 cost time: 2.4430291652679443
Epoch: 34, Steps: 128 Train Loss: 3.0727 (Forecasting Loss:0.2126 + XiCon Loss:2.8601 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.0557172
	speed: 0.0167s/iter; left time: 139.0484s
Epoch: 35 cost time: 2.036824941635132
Epoch: 35, Steps: 128 Train Loss: 3.0728 (Forecasting Loss:0.2126 + XiCon Loss:2.8602 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.0730166
	speed: 0.0203s/iter; left time: 166.8453s
Epoch: 36 cost time: 2.592334270477295
Epoch: 36, Steps: 128 Train Loss: 3.0704 (Forecasting Loss:0.2123 + XiCon Loss:2.8581 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.1616015
	speed: 0.0195s/iter; left time: 157.4427s
Epoch: 37 cost time: 2.488162040710449
Epoch: 37, Steps: 128 Train Loss: 3.0707 (Forecasting Loss:0.2127 + XiCon Loss:2.8580 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.0734246
	speed: 0.0183s/iter; left time: 145.4241s
Epoch: 38 cost time: 2.193881034851074
Epoch: 38, Steps: 128 Train Loss: 3.0694 (Forecasting Loss:0.2126 + XiCon Loss:2.8568 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 39 | loss: 3.1145897
	speed: 0.0198s/iter; left time: 154.7859s
Epoch: 39 cost time: 2.3746449947357178
Epoch: 39, Steps: 128 Train Loss: 3.0720 (Forecasting Loss:0.2127 + XiCon Loss:2.8593 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 40 | loss: 3.1010666
	speed: 0.0222s/iter; left time: 170.9239s
Epoch: 40 cost time: 2.765639305114746
Epoch: 40, Steps: 128 Train Loss: 3.0728 (Forecasting Loss:0.2125 + XiCon Loss:2.8603 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 41 | loss: 3.0413797
	speed: 0.0217s/iter; left time: 164.2523s
Epoch: 41 cost time: 2.567809820175171
Epoch: 41, Steps: 128 Train Loss: 3.0689 (Forecasting Loss:0.2126 + XiCon Loss:2.8563 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05384333059191704, mae:0.1757029891014099, mape:0.13970451056957245, mspe:0.03704693168401718 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6177
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3271246
	speed: 0.0186s/iter; left time: 236.1549s
Epoch: 1 cost time: 2.4253695011138916
Epoch: 1, Steps: 128 Train Loss: 3.3322 (Forecasting Loss:0.2453 + XiCon Loss:3.0869 x Lambda(1.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1239
Validation loss decreased (inf --> 0.175428).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1275601
	speed: 0.0197s/iter; left time: 247.8979s
Epoch: 2 cost time: 2.395784378051758
Epoch: 2, Steps: 128 Train Loss: 3.1760 (Forecasting Loss:0.2503 + XiCon Loss:2.9258 x Lambda(1.0)), Vali MSE Loss: 0.1760 Test MSE Loss: 0.1242
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.1951663
	speed: 0.0190s/iter; left time: 236.8080s
Epoch: 3 cost time: 2.3665120601654053
Epoch: 3, Steps: 128 Train Loss: 3.2487 (Forecasting Loss:0.2290 + XiCon Loss:3.0197 x Lambda(1.0)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1199
Validation loss decreased (0.175428 --> 0.167742).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1657169
	speed: 0.0213s/iter; left time: 262.9186s
Epoch: 4 cost time: 2.639270305633545
Epoch: 4, Steps: 128 Train Loss: 3.1978 (Forecasting Loss:0.2213 + XiCon Loss:2.9765 x Lambda(1.0)), Vali MSE Loss: 0.1676 Test MSE Loss: 0.1171
Validation loss decreased (0.167742 --> 0.167613).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0765216
	speed: 0.0200s/iter; left time: 243.7280s
Epoch: 5 cost time: 2.4753079414367676
Epoch: 5, Steps: 128 Train Loss: 3.1584 (Forecasting Loss:0.2177 + XiCon Loss:2.9407 x Lambda(1.0)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1186
Validation loss decreased (0.167613 --> 0.165255).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2990723
	speed: 0.0180s/iter; left time: 217.2480s
Epoch: 6 cost time: 2.20035719871521
Epoch: 6, Steps: 128 Train Loss: 3.1459 (Forecasting Loss:0.2153 + XiCon Loss:2.9306 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1154
Validation loss decreased (0.165255 --> 0.163523).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2182765
	speed: 0.0185s/iter; left time: 220.9343s
Epoch: 7 cost time: 2.2956840991973877
Epoch: 7, Steps: 128 Train Loss: 3.1460 (Forecasting Loss:0.2142 + XiCon Loss:2.9317 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1578870
	speed: 0.0211s/iter; left time: 249.0687s
Epoch: 8 cost time: 2.4953064918518066
Epoch: 8, Steps: 128 Train Loss: 3.1356 (Forecasting Loss:0.2137 + XiCon Loss:2.9219 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
Validation loss decreased (0.163523 --> 0.163518).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0795720
	speed: 0.0188s/iter; left time: 219.8010s
Epoch: 9 cost time: 2.5101938247680664
Epoch: 9, Steps: 128 Train Loss: 3.1340 (Forecasting Loss:0.2134 + XiCon Loss:2.9205 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
Validation loss decreased (0.163518 --> 0.163447).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0426021
	speed: 0.0209s/iter; left time: 241.8461s
Epoch: 10 cost time: 2.597989320755005
Epoch: 10, Steps: 128 Train Loss: 3.1327 (Forecasting Loss:0.2133 + XiCon Loss:2.9193 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
Validation loss decreased (0.163447 --> 0.163329).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1052146
	speed: 0.0194s/iter; left time: 221.0380s
Epoch: 11 cost time: 2.3256068229675293
Epoch: 11, Steps: 128 Train Loss: 3.1335 (Forecasting Loss:0.2133 + XiCon Loss:2.9202 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1156
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2137823
	speed: 0.0166s/iter; left time: 187.9517s
Epoch: 12 cost time: 2.200077772140503
Epoch: 12, Steps: 128 Train Loss: 3.1354 (Forecasting Loss:0.2131 + XiCon Loss:2.9223 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.1973808
	speed: 0.0184s/iter; left time: 205.0899s
Epoch: 13 cost time: 2.4722800254821777
Epoch: 13, Steps: 128 Train Loss: 3.1339 (Forecasting Loss:0.2131 + XiCon Loss:2.9207 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1860609
	speed: 0.0185s/iter; left time: 203.8837s
Epoch: 14 cost time: 2.2713379859924316
Epoch: 14, Steps: 128 Train Loss: 3.1372 (Forecasting Loss:0.2130 + XiCon Loss:2.9241 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1155
Validation loss decreased (0.163329 --> 0.163192).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0989718
	speed: 0.0178s/iter; left time: 193.8769s
Epoch: 15 cost time: 2.162975549697876
Epoch: 15, Steps: 128 Train Loss: 3.1363 (Forecasting Loss:0.2131 + XiCon Loss:2.9232 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1336055
	speed: 0.0191s/iter; left time: 205.6314s
Epoch: 16 cost time: 2.292515754699707
Epoch: 16, Steps: 128 Train Loss: 3.1269 (Forecasting Loss:0.2131 + XiCon Loss:2.9138 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1155
Validation loss decreased (0.163192 --> 0.163095).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0713933
	speed: 0.0164s/iter; left time: 174.2659s
Epoch: 17 cost time: 2.121074914932251
Epoch: 17, Steps: 128 Train Loss: 3.1335 (Forecasting Loss:0.2130 + XiCon Loss:2.9205 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1107874
	speed: 0.0183s/iter; left time: 192.2142s
Epoch: 18 cost time: 2.256328582763672
Epoch: 18, Steps: 128 Train Loss: 3.1316 (Forecasting Loss:0.2131 + XiCon Loss:2.9185 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.0684662
	speed: 0.0180s/iter; left time: 186.9028s
Epoch: 19 cost time: 2.1846518516540527
Epoch: 19, Steps: 128 Train Loss: 3.1314 (Forecasting Loss:0.2130 + XiCon Loss:2.9184 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.0455539
	speed: 0.0206s/iter; left time: 211.5417s
Epoch: 20 cost time: 2.4869067668914795
Epoch: 20, Steps: 128 Train Loss: 3.1368 (Forecasting Loss:0.2131 + XiCon Loss:2.9237 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1403315
	speed: 0.0210s/iter; left time: 213.1666s
Epoch: 21 cost time: 2.517699718475342
Epoch: 21, Steps: 128 Train Loss: 3.1383 (Forecasting Loss:0.2132 + XiCon Loss:2.9251 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1155
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.1906192
	speed: 0.0198s/iter; left time: 198.4392s
Epoch: 22 cost time: 2.5117547512054443
Epoch: 22, Steps: 128 Train Loss: 3.1336 (Forecasting Loss:0.2131 + XiCon Loss:2.9204 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2173369
	speed: 0.0191s/iter; left time: 189.1433s
Epoch: 23 cost time: 2.4992053508758545
Epoch: 23, Steps: 128 Train Loss: 3.1311 (Forecasting Loss:0.2132 + XiCon Loss:2.9179 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1155
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1495142
	speed: 0.0188s/iter; left time: 183.0087s
Epoch: 24 cost time: 2.3758842945098877
Epoch: 24, Steps: 128 Train Loss: 3.1380 (Forecasting Loss:0.2130 + XiCon Loss:2.9250 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1155
Validation loss decreased (0.163095 --> 0.162978).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.0717411
	speed: 0.0154s/iter; left time: 148.4129s
Epoch: 25 cost time: 1.982248306274414
Epoch: 25, Steps: 128 Train Loss: 3.1285 (Forecasting Loss:0.2131 + XiCon Loss:2.9154 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.1849418
	speed: 0.0187s/iter; left time: 177.6976s
Epoch: 26 cost time: 2.2976107597351074
Epoch: 26, Steps: 128 Train Loss: 3.1345 (Forecasting Loss:0.2131 + XiCon Loss:2.9214 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1146128
	speed: 0.0206s/iter; left time: 193.1596s
Epoch: 27 cost time: 2.5874099731445312
Epoch: 27, Steps: 128 Train Loss: 3.1348 (Forecasting Loss:0.2131 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1155
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1340506
	speed: 0.0189s/iter; left time: 174.8132s
Epoch: 28 cost time: 2.441652297973633
Epoch: 28, Steps: 128 Train Loss: 3.1362 (Forecasting Loss:0.2130 + XiCon Loss:2.9232 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1155
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.1428263
	speed: 0.0174s/iter; left time: 158.4693s
Epoch: 29 cost time: 2.1430256366729736
Epoch: 29, Steps: 128 Train Loss: 3.1328 (Forecasting Loss:0.2132 + XiCon Loss:2.9196 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1206346
	speed: 0.0192s/iter; left time: 172.4966s
Epoch: 30 cost time: 2.4011261463165283
Epoch: 30, Steps: 128 Train Loss: 3.1378 (Forecasting Loss:0.2131 + XiCon Loss:2.9248 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.2412255
	speed: 0.0191s/iter; left time: 169.5004s
Epoch: 31 cost time: 2.296778917312622
Epoch: 31, Steps: 128 Train Loss: 3.1373 (Forecasting Loss:0.2131 + XiCon Loss:2.9242 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.1798494
	speed: 0.0207s/iter; left time: 180.7269s
Epoch: 32 cost time: 2.4787492752075195
Epoch: 32, Steps: 128 Train Loss: 3.1368 (Forecasting Loss:0.2130 + XiCon Loss:2.9238 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1155
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2245026
	speed: 0.0147s/iter; left time: 126.1452s
Epoch: 33 cost time: 2.0166332721710205
Epoch: 33, Steps: 128 Train Loss: 3.1384 (Forecasting Loss:0.2131 + XiCon Loss:2.9253 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1155
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.0805469
	speed: 0.0184s/iter; left time: 155.7272s
Epoch: 34 cost time: 2.137024164199829
Epoch: 34, Steps: 128 Train Loss: 3.1321 (Forecasting Loss:0.2130 + XiCon Loss:2.9191 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1155
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054294053465127945, mae:0.17676307260990143, mape:0.14048393070697784, mspe:0.0373062901198864 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0537+-0.00066, MAE:0.1760+-0.00121, MAPE:0.1402+-0.00083, MSPE:0.0372+-0.00068, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5473
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4370544
	speed: 0.0368s/iter; left time: 430.7445s
Epoch: 1 cost time: 4.014653921127319
Epoch: 1, Steps: 118 Train Loss: 3.4976 (Forecasting Loss:0.3693 + XiCon Loss:3.1283 x Lambda(1.0)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.1777
Validation loss decreased (inf --> 0.271898).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1880038
	speed: 0.0380s/iter; left time: 440.3828s
Epoch: 2 cost time: 4.612728118896484
Epoch: 2, Steps: 118 Train Loss: 3.2661 (Forecasting Loss:0.3105 + XiCon Loss:2.9555 x Lambda(1.0)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.1632
Validation loss decreased (0.271898 --> 0.234151).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2695255
	speed: 0.0385s/iter; left time: 441.5984s
Epoch: 3 cost time: 4.351245403289795
Epoch: 3, Steps: 118 Train Loss: 3.2246 (Forecasting Loss:0.2615 + XiCon Loss:2.9632 x Lambda(1.0)), Vali MSE Loss: 0.2604 Test MSE Loss: 0.1601
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2135525
	speed: 0.0374s/iter; left time: 423.9569s
Epoch: 4 cost time: 4.5185606479644775
Epoch: 4, Steps: 118 Train Loss: 3.1819 (Forecasting Loss:0.2440 + XiCon Loss:2.9379 x Lambda(1.0)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.1503
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2507508
	speed: 0.0370s/iter; left time: 415.0337s
Epoch: 5 cost time: 4.406604766845703
Epoch: 5, Steps: 118 Train Loss: 3.1657 (Forecasting Loss:0.2371 + XiCon Loss:2.9286 x Lambda(1.0)), Vali MSE Loss: 0.3140 Test MSE Loss: 0.1484
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1632414
	speed: 0.0386s/iter; left time: 428.3345s
Epoch: 6 cost time: 4.398289442062378
Epoch: 6, Steps: 118 Train Loss: 3.1512 (Forecasting Loss:0.2353 + XiCon Loss:2.9160 x Lambda(1.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.1480
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1358340
	speed: 0.0385s/iter; left time: 422.7880s
Epoch: 7 cost time: 4.6581268310546875
Epoch: 7, Steps: 118 Train Loss: 3.1495 (Forecasting Loss:0.2339 + XiCon Loss:2.9156 x Lambda(1.0)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.1484
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0976961
	speed: 0.0376s/iter; left time: 408.5502s
Epoch: 8 cost time: 4.283129930496216
Epoch: 8, Steps: 118 Train Loss: 3.1520 (Forecasting Loss:0.2334 + XiCon Loss:2.9185 x Lambda(1.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.1513
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1258743
	speed: 0.0362s/iter; left time: 389.6994s
Epoch: 9 cost time: 4.426375865936279
Epoch: 9, Steps: 118 Train Loss: 3.1477 (Forecasting Loss:0.2329 + XiCon Loss:2.9148 x Lambda(1.0)), Vali MSE Loss: 0.3147 Test MSE Loss: 0.1492
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2516506
	speed: 0.0387s/iter; left time: 411.9107s
Epoch: 10 cost time: 4.704354763031006
Epoch: 10, Steps: 118 Train Loss: 3.1473 (Forecasting Loss:0.2328 + XiCon Loss:2.9145 x Lambda(1.0)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.1496
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0994115
	speed: 0.0378s/iter; left time: 397.4255s
Epoch: 11 cost time: 4.321653604507446
Epoch: 11, Steps: 118 Train Loss: 3.1487 (Forecasting Loss:0.2326 + XiCon Loss:2.9161 x Lambda(1.0)), Vali MSE Loss: 0.3122 Test MSE Loss: 0.1493
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1314168
	speed: 0.0367s/iter; left time: 381.3875s
Epoch: 12 cost time: 4.4189417362213135
Epoch: 12, Steps: 118 Train Loss: 3.1534 (Forecasting Loss:0.2329 + XiCon Loss:2.9206 x Lambda(1.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.1497
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08994577080011368, mae:0.23646733164787292, mape:0.17295971512794495, mspe:0.04858207702636719 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4367
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4843206
	speed: 0.0311s/iter; left time: 364.0688s
Epoch: 1 cost time: 3.8060050010681152
Epoch: 1, Steps: 118 Train Loss: 3.5025 (Forecasting Loss:0.3778 + XiCon Loss:3.1248 x Lambda(1.0)), Vali MSE Loss: 0.2780 Test MSE Loss: 0.1832
Validation loss decreased (inf --> 0.277992).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2594237
	speed: 0.0401s/iter; left time: 464.2476s
Epoch: 2 cost time: 4.676377296447754
Epoch: 2, Steps: 118 Train Loss: 3.2829 (Forecasting Loss:0.3411 + XiCon Loss:2.9418 x Lambda(1.0)), Vali MSE Loss: 0.2395 Test MSE Loss: 0.1525
Validation loss decreased (0.277992 --> 0.239497).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2852154
	speed: 0.0400s/iter; left time: 459.0856s
Epoch: 3 cost time: 4.610001087188721
Epoch: 3, Steps: 118 Train Loss: 3.2682 (Forecasting Loss:0.2877 + XiCon Loss:2.9805 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1555
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3330083
	speed: 0.0395s/iter; left time: 448.6214s
Epoch: 4 cost time: 4.790673732757568
Epoch: 4, Steps: 118 Train Loss: 3.2812 (Forecasting Loss:0.2692 + XiCon Loss:3.0121 x Lambda(1.0)), Vali MSE Loss: 0.2444 Test MSE Loss: 0.1503
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1936915
	speed: 0.0395s/iter; left time: 443.0082s
Epoch: 5 cost time: 4.5146262645721436
Epoch: 5, Steps: 118 Train Loss: 3.2192 (Forecasting Loss:0.2606 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1547
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2227433
	speed: 0.0377s/iter; left time: 418.5634s
Epoch: 6 cost time: 4.56967830657959
Epoch: 6, Steps: 118 Train Loss: 3.1884 (Forecasting Loss:0.2566 + XiCon Loss:2.9318 x Lambda(1.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1478
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3152649
	speed: 0.0401s/iter; left time: 441.2042s
Epoch: 7 cost time: 4.549930095672607
Epoch: 7, Steps: 118 Train Loss: 3.1829 (Forecasting Loss:0.2549 + XiCon Loss:2.9280 x Lambda(1.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1476
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2445359
	speed: 0.0406s/iter; left time: 441.2130s
Epoch: 8 cost time: 4.8443615436553955
Epoch: 8, Steps: 118 Train Loss: 3.1712 (Forecasting Loss:0.2534 + XiCon Loss:2.9177 x Lambda(1.0)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.1487
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2306805
	speed: 0.0423s/iter; left time: 454.8559s
Epoch: 9 cost time: 5.107126235961914
Epoch: 9, Steps: 118 Train Loss: 3.1787 (Forecasting Loss:0.2530 + XiCon Loss:2.9257 x Lambda(1.0)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1493
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2240469
	speed: 0.0393s/iter; left time: 418.2833s
Epoch: 10 cost time: 4.535875558853149
Epoch: 10, Steps: 118 Train Loss: 3.1744 (Forecasting Loss:0.2527 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1494
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1326966
	speed: 0.0413s/iter; left time: 434.3092s
Epoch: 11 cost time: 5.02537989616394
Epoch: 11, Steps: 118 Train Loss: 3.1842 (Forecasting Loss:0.2531 + XiCon Loss:2.9312 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1490
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1896708
	speed: 0.0404s/iter; left time: 420.7829s
Epoch: 12 cost time: 4.893844842910767
Epoch: 12, Steps: 118 Train Loss: 3.1751 (Forecasting Loss:0.2526 + XiCon Loss:2.9225 x Lambda(1.0)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.1491
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07901106774806976, mae:0.2259969413280487, mape:0.1700616031885147, mspe:0.04758986085653305 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4602
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4253256
	speed: 0.0324s/iter; left time: 379.6364s
Epoch: 1 cost time: 3.7500977516174316
Epoch: 1, Steps: 118 Train Loss: 3.4677 (Forecasting Loss:0.3538 + XiCon Loss:3.1139 x Lambda(1.0)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.1670
Validation loss decreased (inf --> 0.255854).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2276020
	speed: 0.0381s/iter; left time: 440.9438s
Epoch: 2 cost time: 4.587042570114136
Epoch: 2, Steps: 118 Train Loss: 3.2718 (Forecasting Loss:0.3368 + XiCon Loss:2.9350 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.1587
Validation loss decreased (0.255854 --> 0.250484).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2113571
	speed: 0.0400s/iter; left time: 458.3667s
Epoch: 3 cost time: 4.885766267776489
Epoch: 3, Steps: 118 Train Loss: 3.1596 (Forecasting Loss:0.2887 + XiCon Loss:2.8709 x Lambda(1.0)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1308765
	speed: 0.0390s/iter; left time: 442.5919s
Epoch: 4 cost time: 4.501564979553223
Epoch: 4, Steps: 118 Train Loss: 3.1834 (Forecasting Loss:0.2662 + XiCon Loss:2.9172 x Lambda(1.0)), Vali MSE Loss: 0.2579 Test MSE Loss: 0.1602
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2370486
	speed: 0.0347s/iter; left time: 390.0090s
Epoch: 5 cost time: 4.281446933746338
Epoch: 5, Steps: 118 Train Loss: 3.1421 (Forecasting Loss:0.2595 + XiCon Loss:2.8826 x Lambda(1.0)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.1549
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1523707
	speed: 0.0388s/iter; left time: 430.9833s
Epoch: 6 cost time: 4.5417304039001465
Epoch: 6, Steps: 118 Train Loss: 3.1212 (Forecasting Loss:0.2561 + XiCon Loss:2.8651 x Lambda(1.0)), Vali MSE Loss: 0.2661 Test MSE Loss: 0.1549
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0814710
	speed: 0.0397s/iter; left time: 436.5436s
Epoch: 7 cost time: 4.6099021434783936
Epoch: 7, Steps: 118 Train Loss: 3.1101 (Forecasting Loss:0.2560 + XiCon Loss:2.8541 x Lambda(1.0)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.1530
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0947270
	speed: 0.0392s/iter; left time: 426.6606s
Epoch: 8 cost time: 4.782986164093018
Epoch: 8, Steps: 118 Train Loss: 3.1075 (Forecasting Loss:0.2539 + XiCon Loss:2.8537 x Lambda(1.0)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.1542
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1194103
	speed: 0.0385s/iter; left time: 414.3368s
Epoch: 9 cost time: 4.5755743980407715
Epoch: 9, Steps: 118 Train Loss: 3.1142 (Forecasting Loss:0.2546 + XiCon Loss:2.8596 x Lambda(1.0)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1523
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0776453
	speed: 0.0402s/iter; left time: 427.6308s
Epoch: 10 cost time: 4.585515260696411
Epoch: 10, Steps: 118 Train Loss: 3.1143 (Forecasting Loss:0.2539 + XiCon Loss:2.8604 x Lambda(1.0)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1529
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1262777
	speed: 0.0400s/iter; left time: 421.2381s
Epoch: 11 cost time: 4.83352518081665
Epoch: 11, Steps: 118 Train Loss: 3.1115 (Forecasting Loss:0.2536 + XiCon Loss:2.8580 x Lambda(1.0)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.1532
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1039212
	speed: 0.0387s/iter; left time: 403.0752s
Epoch: 12 cost time: 4.722821235656738
Epoch: 12, Steps: 118 Train Loss: 3.1065 (Forecasting Loss:0.2537 + XiCon Loss:2.8528 x Lambda(1.0)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.1532
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08597084134817123, mae:0.23152589797973633, mape:0.17142309248447418, mspe:0.04823257401585579 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4446
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4116662
	speed: 0.0334s/iter; left time: 390.3831s
Epoch: 1 cost time: 3.9787869453430176
Epoch: 1, Steps: 118 Train Loss: 3.4564 (Forecasting Loss:0.3543 + XiCon Loss:3.1021 x Lambda(1.0)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.1654
Validation loss decreased (inf --> 0.254144).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1308959
	speed: 0.0380s/iter; left time: 439.8795s
Epoch: 2 cost time: 4.41774845123291
Epoch: 2, Steps: 118 Train Loss: 3.2337 (Forecasting Loss:0.3283 + XiCon Loss:2.9054 x Lambda(1.0)), Vali MSE Loss: 0.2510 Test MSE Loss: 0.1593
Validation loss decreased (0.254144 --> 0.251027).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3621714
	speed: 0.0399s/iter; left time: 457.6697s
Epoch: 3 cost time: 4.785504579544067
Epoch: 3, Steps: 118 Train Loss: 3.2218 (Forecasting Loss:0.2867 + XiCon Loss:2.9351 x Lambda(1.0)), Vali MSE Loss: 0.2402 Test MSE Loss: 0.1511
Validation loss decreased (0.251027 --> 0.240237).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1222548
	speed: 0.0395s/iter; left time: 448.1051s
Epoch: 4 cost time: 4.812090873718262
Epoch: 4, Steps: 118 Train Loss: 3.2348 (Forecasting Loss:0.2779 + XiCon Loss:2.9569 x Lambda(1.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.1453
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3590980
	speed: 0.0400s/iter; left time: 448.9844s
Epoch: 5 cost time: 4.697991847991943
Epoch: 5, Steps: 118 Train Loss: 3.1962 (Forecasting Loss:0.2688 + XiCon Loss:2.9274 x Lambda(1.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1408
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1575725
	speed: 0.0409s/iter; left time: 454.7513s
Epoch: 6 cost time: 4.711338758468628
Epoch: 6, Steps: 118 Train Loss: 3.1829 (Forecasting Loss:0.2637 + XiCon Loss:2.9192 x Lambda(1.0)), Vali MSE Loss: 0.2443 Test MSE Loss: 0.1418
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1516852
	speed: 0.0403s/iter; left time: 442.5375s
Epoch: 7 cost time: 4.872368097305298
Epoch: 7, Steps: 118 Train Loss: 3.1786 (Forecasting Loss:0.2620 + XiCon Loss:2.9167 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.1399
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0858221
	speed: 0.0390s/iter; left time: 423.6073s
Epoch: 8 cost time: 4.763920307159424
Epoch: 8, Steps: 118 Train Loss: 3.1759 (Forecasting Loss:0.2606 + XiCon Loss:2.9153 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1411
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1156936
	speed: 0.0389s/iter; left time: 418.7620s
Epoch: 9 cost time: 4.499892473220825
Epoch: 9, Steps: 118 Train Loss: 3.1890 (Forecasting Loss:0.2596 + XiCon Loss:2.9294 x Lambda(1.0)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1115010
	speed: 0.0390s/iter; left time: 415.0754s
Epoch: 10 cost time: 4.707423686981201
Epoch: 10, Steps: 118 Train Loss: 3.1777 (Forecasting Loss:0.2599 + XiCon Loss:2.9177 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1408
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1114562
	speed: 0.0400s/iter; left time: 420.8513s
Epoch: 11 cost time: 4.836999416351318
Epoch: 11, Steps: 118 Train Loss: 3.1697 (Forecasting Loss:0.2590 + XiCon Loss:2.9107 x Lambda(1.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1396
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1128190
	speed: 0.0394s/iter; left time: 409.6935s
Epoch: 12 cost time: 4.610078573226929
Epoch: 12, Steps: 118 Train Loss: 3.1780 (Forecasting Loss:0.2598 + XiCon Loss:2.9182 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.1400
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2089996
	speed: 0.0395s/iter; left time: 405.8452s
Epoch: 13 cost time: 4.566411972045898
Epoch: 13, Steps: 118 Train Loss: 3.1665 (Forecasting Loss:0.2593 + XiCon Loss:2.9073 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1400
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07997264713048935, mae:0.22226828336715698, mape:0.16275668144226074, mspe:0.04313671588897705 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4654
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.3907518
	speed: 0.0237s/iter; left time: 277.3389s
Epoch: 1 cost time: 2.7789382934570312
Epoch: 1, Steps: 118 Train Loss: 3.4659 (Forecasting Loss:0.3605 + XiCon Loss:3.1054 x Lambda(1.0)), Vali MSE Loss: 0.2557 Test MSE Loss: 0.1652
Validation loss decreased (inf --> 0.255701).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3054886
	speed: 0.0440s/iter; left time: 510.0043s
Epoch: 2 cost time: 5.801971912384033
Epoch: 2, Steps: 118 Train Loss: 3.2730 (Forecasting Loss:0.3246 + XiCon Loss:2.9484 x Lambda(1.0)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1618
Validation loss decreased (0.255701 --> 0.240408).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2497573
	speed: 0.0437s/iter; left time: 501.0542s
Epoch: 3 cost time: 4.907365083694458
Epoch: 3, Steps: 118 Train Loss: 3.2541 (Forecasting Loss:0.2920 + XiCon Loss:2.9621 x Lambda(1.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.1454
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2833271
	speed: 0.0276s/iter; left time: 313.0318s
Epoch: 4 cost time: 3.2449190616607666
Epoch: 4, Steps: 118 Train Loss: 3.1919 (Forecasting Loss:0.2730 + XiCon Loss:2.9189 x Lambda(1.0)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.1509
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1158295
	speed: 0.0485s/iter; left time: 544.3910s
Epoch: 5 cost time: 5.806535005569458
Epoch: 5, Steps: 118 Train Loss: 3.1836 (Forecasting Loss:0.2663 + XiCon Loss:2.9173 x Lambda(1.0)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1540
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2468042
	speed: 0.0522s/iter; left time: 579.9430s
Epoch: 6 cost time: 6.186833381652832
Epoch: 6, Steps: 118 Train Loss: 3.1762 (Forecasting Loss:0.2647 + XiCon Loss:2.9115 x Lambda(1.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.1465
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2050853
	speed: 0.0497s/iter; left time: 546.0608s
Epoch: 7 cost time: 5.762188673019409
Epoch: 7, Steps: 118 Train Loss: 3.1699 (Forecasting Loss:0.2612 + XiCon Loss:2.9087 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1487
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1122017
	speed: 0.0524s/iter; left time: 570.2586s
Epoch: 8 cost time: 6.1766133308410645
Epoch: 8, Steps: 118 Train Loss: 3.1668 (Forecasting Loss:0.2612 + XiCon Loss:2.9056 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.1488
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1117411
	speed: 0.0505s/iter; left time: 543.2348s
Epoch: 9 cost time: 6.037628650665283
Epoch: 9, Steps: 118 Train Loss: 3.1681 (Forecasting Loss:0.2607 + XiCon Loss:2.9074 x Lambda(1.0)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1475
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0906641
	speed: 0.0479s/iter; left time: 509.6904s
Epoch: 10 cost time: 5.785770893096924
Epoch: 10, Steps: 118 Train Loss: 3.1676 (Forecasting Loss:0.2601 + XiCon Loss:2.9075 x Lambda(1.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.1487
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1719012
	speed: 0.0495s/iter; left time: 521.2037s
Epoch: 11 cost time: 5.852285861968994
Epoch: 11, Steps: 118 Train Loss: 3.1631 (Forecasting Loss:0.2605 + XiCon Loss:2.9026 x Lambda(1.0)), Vali MSE Loss: 0.2511 Test MSE Loss: 0.1482
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0977466
	speed: 0.0524s/iter; left time: 545.3723s
Epoch: 12 cost time: 6.1882054805755615
Epoch: 12, Steps: 118 Train Loss: 3.1648 (Forecasting Loss:0.2606 + XiCon Loss:2.9041 x Lambda(1.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.1483
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08867868781089783, mae:0.2348831593990326, mape:0.17055782675743103, mspe:0.046529099345207214 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0847+-0.00620, MAE:0.2302+-0.00744, MAPE:0.1696+-0.00491, MSPE:0.0468+-0.00273, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5666
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6425009
	speed: 0.0745s/iter; left time: 789.7115s
Epoch: 1 cost time: 8.008674144744873
Epoch: 1, Steps: 107 Train Loss: 3.6770 (Forecasting Loss:0.5429 + XiCon Loss:3.1341 x Lambda(1.0)), Vali MSE Loss: 0.3509 Test MSE Loss: 0.2039
Validation loss decreased (inf --> 0.350919).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1555073
	speed: 0.0709s/iter; left time: 743.5435s
Epoch: 2 cost time: 7.5683276653289795
Epoch: 2, Steps: 107 Train Loss: 3.3651 (Forecasting Loss:0.4046 + XiCon Loss:2.9605 x Lambda(1.0)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1584
Validation loss decreased (0.350919 --> 0.228472).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2497792
	speed: 0.0717s/iter; left time: 744.2879s
Epoch: 3 cost time: 7.717254161834717
Epoch: 3, Steps: 107 Train Loss: 3.2477 (Forecasting Loss:0.2954 + XiCon Loss:2.9523 x Lambda(1.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.1478
Validation loss decreased (0.228472 --> 0.227400).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2395310
	speed: 0.0733s/iter; left time: 753.0677s
Epoch: 4 cost time: 7.883915424346924
Epoch: 4, Steps: 107 Train Loss: 3.2445 (Forecasting Loss:0.2797 + XiCon Loss:2.9648 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.1567
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2055206
	speed: 0.0725s/iter; left time: 737.2760s
Epoch: 5 cost time: 7.822972774505615
Epoch: 5, Steps: 107 Train Loss: 3.2294 (Forecasting Loss:0.2702 + XiCon Loss:2.9592 x Lambda(1.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.1518
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1918247
	speed: 0.0754s/iter; left time: 759.4212s
Epoch: 6 cost time: 8.123373985290527
Epoch: 6, Steps: 107 Train Loss: 3.2158 (Forecasting Loss:0.2666 + XiCon Loss:2.9492 x Lambda(1.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1617
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1973801
	speed: 0.0746s/iter; left time: 743.2333s
Epoch: 7 cost time: 7.944226264953613
Epoch: 7, Steps: 107 Train Loss: 3.2124 (Forecasting Loss:0.2656 + XiCon Loss:2.9468 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.1588
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2218735
	speed: 0.0731s/iter; left time: 720.1482s
Epoch: 8 cost time: 7.909635543823242
Epoch: 8, Steps: 107 Train Loss: 3.2093 (Forecasting Loss:0.2648 + XiCon Loss:2.9445 x Lambda(1.0)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1573
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2702646
	speed: 0.0740s/iter; left time: 721.2712s
Epoch: 9 cost time: 7.935581684112549
Epoch: 9, Steps: 107 Train Loss: 3.2064 (Forecasting Loss:0.2640 + XiCon Loss:2.9424 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1569
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2480814
	speed: 0.0714s/iter; left time: 688.1686s
Epoch: 10 cost time: 7.690913915634155
Epoch: 10, Steps: 107 Train Loss: 3.2052 (Forecasting Loss:0.2641 + XiCon Loss:2.9411 x Lambda(1.0)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.1564
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2375419
	speed: 0.0723s/iter; left time: 689.4584s
Epoch: 11 cost time: 7.784918308258057
Epoch: 11, Steps: 107 Train Loss: 3.2036 (Forecasting Loss:0.2632 + XiCon Loss:2.9404 x Lambda(1.0)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.1550
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2256122
	speed: 0.0713s/iter; left time: 671.6424s
Epoch: 12 cost time: 7.787585735321045
Epoch: 12, Steps: 107 Train Loss: 3.2060 (Forecasting Loss:0.2637 + XiCon Loss:2.9423 x Lambda(1.0)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.1562
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2166128
	speed: 0.0722s/iter; left time: 672.9828s
Epoch: 13 cost time: 7.708601236343384
Epoch: 13, Steps: 107 Train Loss: 3.2017 (Forecasting Loss:0.2642 + XiCon Loss:2.9375 x Lambda(1.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.1563
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.07712864875793457, mae:0.21854685246944427, mape:0.15745112299919128, mspe:0.040522076189517975 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4452
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6059375
	speed: 0.0726s/iter; left time: 770.0948s
Epoch: 1 cost time: 7.810256481170654
Epoch: 1, Steps: 107 Train Loss: 3.6820 (Forecasting Loss:0.5402 + XiCon Loss:3.1418 x Lambda(1.0)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2063
Validation loss decreased (inf --> 0.346529).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2862065
	speed: 0.0718s/iter; left time: 753.2490s
Epoch: 2 cost time: 7.772983551025391
Epoch: 2, Steps: 107 Train Loss: 3.4477 (Forecasting Loss:0.4329 + XiCon Loss:3.0148 x Lambda(1.0)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1603
Validation loss decreased (0.346529 --> 0.265432).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3020749
	speed: 0.0704s/iter; left time: 731.3422s
Epoch: 3 cost time: 7.611619710922241
Epoch: 3, Steps: 107 Train Loss: 3.2687 (Forecasting Loss:0.2949 + XiCon Loss:2.9738 x Lambda(1.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1383
Validation loss decreased (0.265432 --> 0.219999).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2650917
	speed: 0.0732s/iter; left time: 752.2023s
Epoch: 4 cost time: 7.842360496520996
Epoch: 4, Steps: 107 Train Loss: 3.2840 (Forecasting Loss:0.2688 + XiCon Loss:3.0152 x Lambda(1.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.1364
Validation loss decreased (0.219999 --> 0.206399).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3575587
	speed: 0.0722s/iter; left time: 734.3706s
Epoch: 5 cost time: 7.759249448776245
Epoch: 5, Steps: 107 Train Loss: 3.2796 (Forecasting Loss:0.2638 + XiCon Loss:3.0157 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1330
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2674479
	speed: 0.0729s/iter; left time: 733.3735s
Epoch: 6 cost time: 7.863561391830444
Epoch: 6, Steps: 107 Train Loss: 3.2808 (Forecasting Loss:0.2620 + XiCon Loss:3.0188 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1323
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2443676
	speed: 0.0732s/iter; left time: 729.4784s
Epoch: 7 cost time: 7.901613712310791
Epoch: 7, Steps: 107 Train Loss: 3.2756 (Forecasting Loss:0.2599 + XiCon Loss:3.0158 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1333
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2382708
	speed: 0.0716s/iter; left time: 705.4315s
Epoch: 8 cost time: 7.719987154006958
Epoch: 8, Steps: 107 Train Loss: 3.2777 (Forecasting Loss:0.2592 + XiCon Loss:3.0185 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1320
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2458265
	speed: 0.0737s/iter; left time: 718.4711s
Epoch: 9 cost time: 7.930568218231201
Epoch: 9, Steps: 107 Train Loss: 3.2734 (Forecasting Loss:0.2590 + XiCon Loss:3.0144 x Lambda(1.0)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1331
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2022061
	speed: 0.0732s/iter; left time: 705.3595s
Epoch: 10 cost time: 7.820174694061279
Epoch: 10, Steps: 107 Train Loss: 3.2718 (Forecasting Loss:0.2587 + XiCon Loss:3.0132 x Lambda(1.0)), Vali MSE Loss: 0.2097 Test MSE Loss: 0.1328
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2739313
	speed: 0.0704s/iter; left time: 670.5391s
Epoch: 11 cost time: 7.663297176361084
Epoch: 11, Steps: 107 Train Loss: 3.2780 (Forecasting Loss:0.2584 + XiCon Loss:3.0196 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1338
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2571237
	speed: 0.0762s/iter; left time: 718.3015s
Epoch: 12 cost time: 8.184636116027832
Epoch: 12, Steps: 107 Train Loss: 3.2747 (Forecasting Loss:0.2581 + XiCon Loss:3.0166 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1328
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2160361
	speed: 0.0714s/iter; left time: 665.6250s
Epoch: 13 cost time: 7.677339553833008
Epoch: 13, Steps: 107 Train Loss: 3.2680 (Forecasting Loss:0.2582 + XiCon Loss:3.0098 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1330
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2572808
	speed: 0.0728s/iter; left time: 670.8440s
Epoch: 14 cost time: 7.874608278274536
Epoch: 14, Steps: 107 Train Loss: 3.2749 (Forecasting Loss:0.2585 + XiCon Loss:3.0165 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1330
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.06682480871677399, mae:0.2059439867734909, mape:0.15511465072631836, mspe:0.04204477742314339 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4569
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6095555
	speed: 0.0708s/iter; left time: 750.5663s
Epoch: 1 cost time: 7.625811338424683
Epoch: 1, Steps: 107 Train Loss: 3.6890 (Forecasting Loss:0.5473 + XiCon Loss:3.1417 x Lambda(1.0)), Vali MSE Loss: 0.3584 Test MSE Loss: 0.1975
Validation loss decreased (inf --> 0.358422).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2718632
	speed: 0.0724s/iter; left time: 759.6514s
Epoch: 2 cost time: 7.740801811218262
Epoch: 2, Steps: 107 Train Loss: 3.3699 (Forecasting Loss:0.3700 + XiCon Loss:2.9999 x Lambda(1.0)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1690
Validation loss decreased (0.358422 --> 0.226639).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2502270
	speed: 0.0721s/iter; left time: 748.4364s
Epoch: 3 cost time: 7.741485357284546
Epoch: 3, Steps: 107 Train Loss: 3.2896 (Forecasting Loss:0.2787 + XiCon Loss:3.0109 x Lambda(1.0)), Vali MSE Loss: 0.2353 Test MSE Loss: 0.1395
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2854962
	speed: 0.0707s/iter; left time: 726.5327s
Epoch: 4 cost time: 7.557545900344849
Epoch: 4, Steps: 107 Train Loss: 3.2744 (Forecasting Loss:0.2722 + XiCon Loss:3.0022 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1381
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2433290
	speed: 0.0690s/iter; left time: 702.2962s
Epoch: 5 cost time: 7.500113010406494
Epoch: 5, Steps: 107 Train Loss: 3.2643 (Forecasting Loss:0.2694 + XiCon Loss:2.9949 x Lambda(1.0)), Vali MSE Loss: 0.2317 Test MSE Loss: 0.1364
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2126455
	speed: 0.0744s/iter; left time: 749.0680s
Epoch: 6 cost time: 7.998723030090332
Epoch: 6, Steps: 107 Train Loss: 3.2539 (Forecasting Loss:0.2676 + XiCon Loss:2.9863 x Lambda(1.0)), Vali MSE Loss: 0.2358 Test MSE Loss: 0.1360
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3112550
	speed: 0.0722s/iter; left time: 718.9569s
Epoch: 7 cost time: 7.7261857986450195
Epoch: 7, Steps: 107 Train Loss: 3.2444 (Forecasting Loss:0.2660 + XiCon Loss:2.9785 x Lambda(1.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1365
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2507646
	speed: 0.0714s/iter; left time: 703.3364s
Epoch: 8 cost time: 7.703565835952759
Epoch: 8, Steps: 107 Train Loss: 3.2505 (Forecasting Loss:0.2657 + XiCon Loss:2.9848 x Lambda(1.0)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1366
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3274314
	speed: 0.0731s/iter; left time: 712.5614s
Epoch: 9 cost time: 7.9133758544921875
Epoch: 9, Steps: 107 Train Loss: 3.2462 (Forecasting Loss:0.2649 + XiCon Loss:2.9813 x Lambda(1.0)), Vali MSE Loss: 0.2413 Test MSE Loss: 0.1363
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2745612
	speed: 0.0724s/iter; left time: 698.1080s
Epoch: 10 cost time: 7.857909679412842
Epoch: 10, Steps: 107 Train Loss: 3.2437 (Forecasting Loss:0.2651 + XiCon Loss:2.9786 x Lambda(1.0)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1366
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2720268
	speed: 0.0763s/iter; left time: 727.6145s
Epoch: 11 cost time: 8.263062953948975
Epoch: 11, Steps: 107 Train Loss: 3.2409 (Forecasting Loss:0.2649 + XiCon Loss:2.9759 x Lambda(1.0)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.1365
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2011819
	speed: 0.0713s/iter; left time: 672.3763s
Epoch: 12 cost time: 7.651153564453125
Epoch: 12, Steps: 107 Train Loss: 3.2439 (Forecasting Loss:0.2651 + XiCon Loss:2.9788 x Lambda(1.0)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1363
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.09513171762228012, mae:0.24280114471912384, mape:0.17006739974021912, mspe:0.04411623254418373 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5094
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6265054
	speed: 0.0725s/iter; left time: 768.8596s
Epoch: 1 cost time: 7.814007759094238
Epoch: 1, Steps: 107 Train Loss: 3.6813 (Forecasting Loss:0.5452 + XiCon Loss:3.1360 x Lambda(1.0)), Vali MSE Loss: 0.3924 Test MSE Loss: 0.2328
Validation loss decreased (inf --> 0.392382).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3226471
	speed: 0.0915s/iter; left time: 960.2352s
Epoch: 2 cost time: 9.871517419815063
Epoch: 2, Steps: 107 Train Loss: 3.3567 (Forecasting Loss:0.3720 + XiCon Loss:2.9847 x Lambda(1.0)), Vali MSE Loss: 0.2950 Test MSE Loss: 0.1956
Validation loss decreased (0.392382 --> 0.295039).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3825307
	speed: 0.0853s/iter; left time: 885.8647s
Epoch: 3 cost time: 9.28556227684021
Epoch: 3, Steps: 107 Train Loss: 3.2994 (Forecasting Loss:0.2947 + XiCon Loss:3.0047 x Lambda(1.0)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.1747
Validation loss decreased (0.295039 --> 0.271572).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2580876
	speed: 0.0944s/iter; left time: 970.5251s
Epoch: 4 cost time: 10.16999363899231
Epoch: 4, Steps: 107 Train Loss: 3.2758 (Forecasting Loss:0.2813 + XiCon Loss:2.9945 x Lambda(1.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.1836
Validation loss decreased (0.271572 --> 0.251968).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2664142
	speed: 0.0895s/iter; left time: 910.2763s
Epoch: 5 cost time: 9.669659614562988
Epoch: 5, Steps: 107 Train Loss: 3.2583 (Forecasting Loss:0.2776 + XiCon Loss:2.9806 x Lambda(1.0)), Vali MSE Loss: 0.2727 Test MSE Loss: 0.1597
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2295802
	speed: 0.0920s/iter; left time: 926.0866s
Epoch: 6 cost time: 9.99966049194336
Epoch: 6, Steps: 107 Train Loss: 3.2433 (Forecasting Loss:0.2706 + XiCon Loss:2.9727 x Lambda(1.0)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.1594
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2468522
	speed: 0.1042s/iter; left time: 1037.4462s
Epoch: 7 cost time: 10.954336166381836
Epoch: 7, Steps: 107 Train Loss: 3.2434 (Forecasting Loss:0.2694 + XiCon Loss:2.9740 x Lambda(1.0)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.1601
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2078624
	speed: 0.0624s/iter; left time: 614.4523s
Epoch: 8 cost time: 6.960475921630859
Epoch: 8, Steps: 107 Train Loss: 3.2333 (Forecasting Loss:0.2675 + XiCon Loss:2.9657 x Lambda(1.0)), Vali MSE Loss: 0.2684 Test MSE Loss: 0.1564
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2831841
	speed: 0.0869s/iter; left time: 846.5827s
Epoch: 9 cost time: 9.397466897964478
Epoch: 9, Steps: 107 Train Loss: 3.2359 (Forecasting Loss:0.2673 + XiCon Loss:2.9686 x Lambda(1.0)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1559
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2865441
	speed: 0.0908s/iter; left time: 875.1826s
Epoch: 10 cost time: 9.829174757003784
Epoch: 10, Steps: 107 Train Loss: 3.2280 (Forecasting Loss:0.2667 + XiCon Loss:2.9613 x Lambda(1.0)), Vali MSE Loss: 0.2701 Test MSE Loss: 0.1552
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3363142
	speed: 0.0927s/iter; left time: 883.2963s
Epoch: 11 cost time: 9.995900392532349
Epoch: 11, Steps: 107 Train Loss: 3.2328 (Forecasting Loss:0.2661 + XiCon Loss:2.9667 x Lambda(1.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.1560
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2638004
	speed: 0.0931s/iter; left time: 877.2418s
Epoch: 12 cost time: 9.999475002288818
Epoch: 12, Steps: 107 Train Loss: 3.2338 (Forecasting Loss:0.2664 + XiCon Loss:2.9674 x Lambda(1.0)), Vali MSE Loss: 0.2712 Test MSE Loss: 0.1545
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2154346
	speed: 0.0937s/iter; left time: 873.3298s
Epoch: 13 cost time: 10.04807996749878
Epoch: 13, Steps: 107 Train Loss: 3.2351 (Forecasting Loss:0.2661 + XiCon Loss:2.9690 x Lambda(1.0)), Vali MSE Loss: 0.2700 Test MSE Loss: 0.1551
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2340219
	speed: 0.0917s/iter; left time: 844.4069s
Epoch: 14 cost time: 9.779562950134277
Epoch: 14, Steps: 107 Train Loss: 3.2323 (Forecasting Loss:0.2653 + XiCon Loss:2.9669 x Lambda(1.0)), Vali MSE Loss: 0.2698 Test MSE Loss: 0.1551
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.10723945498466492, mae:0.2599059045314789, mape:0.18184678256511688, mspe:0.049645502120256424 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4145
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6557851
	speed: 0.0706s/iter; left time: 748.7427s
Epoch: 1 cost time: 7.625338792800903
Epoch: 1, Steps: 107 Train Loss: 3.6617 (Forecasting Loss:0.5312 + XiCon Loss:3.1305 x Lambda(1.0)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.2171
Validation loss decreased (inf --> 0.368546).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3963616
	speed: 0.0848s/iter; left time: 890.0876s
Epoch: 2 cost time: 9.127477884292603
Epoch: 2, Steps: 107 Train Loss: 3.3724 (Forecasting Loss:0.3729 + XiCon Loss:2.9996 x Lambda(1.0)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.1744
Validation loss decreased (0.368546 --> 0.274571).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2480791
	speed: 0.0959s/iter; left time: 996.1669s
Epoch: 3 cost time: 10.35700273513794
Epoch: 3, Steps: 107 Train Loss: 3.3031 (Forecasting Loss:0.2817 + XiCon Loss:3.0214 x Lambda(1.0)), Vali MSE Loss: 0.2862 Test MSE Loss: 0.1773
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1933002
	speed: 0.0985s/iter; left time: 1012.8564s
Epoch: 4 cost time: 10.723363399505615
Epoch: 4, Steps: 107 Train Loss: 3.2484 (Forecasting Loss:0.2729 + XiCon Loss:2.9756 x Lambda(1.0)), Vali MSE Loss: 0.2976 Test MSE Loss: 0.1597
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2135491
	speed: 0.1008s/iter; left time: 1025.1492s
Epoch: 5 cost time: 10.864763498306274
Epoch: 5, Steps: 107 Train Loss: 3.2130 (Forecasting Loss:0.2654 + XiCon Loss:2.9476 x Lambda(1.0)), Vali MSE Loss: 0.2855 Test MSE Loss: 0.1743
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1788821
	speed: 0.0970s/iter; left time: 976.8536s
Epoch: 6 cost time: 10.449131727218628
Epoch: 6, Steps: 107 Train Loss: 3.2063 (Forecasting Loss:0.2629 + XiCon Loss:2.9434 x Lambda(1.0)), Vali MSE Loss: 0.3010 Test MSE Loss: 0.1562
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2497592
	speed: 0.0930s/iter; left time: 925.8209s
Epoch: 7 cost time: 10.034625768661499
Epoch: 7, Steps: 107 Train Loss: 3.1953 (Forecasting Loss:0.2603 + XiCon Loss:2.9350 x Lambda(1.0)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.1539
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1378434
	speed: 0.0971s/iter; left time: 956.6366s
Epoch: 8 cost time: 10.464690923690796
Epoch: 8, Steps: 107 Train Loss: 3.1969 (Forecasting Loss:0.2589 + XiCon Loss:2.9380 x Lambda(1.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.1549
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1492655
	speed: 0.0972s/iter; left time: 947.5975s
Epoch: 9 cost time: 10.488892793655396
Epoch: 9, Steps: 107 Train Loss: 3.1868 (Forecasting Loss:0.2588 + XiCon Loss:2.9281 x Lambda(1.0)), Vali MSE Loss: 0.2881 Test MSE Loss: 0.1527
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1318667
	speed: 0.0963s/iter; left time: 927.9391s
Epoch: 10 cost time: 10.403517007827759
Epoch: 10, Steps: 107 Train Loss: 3.1861 (Forecasting Loss:0.2583 + XiCon Loss:2.9278 x Lambda(1.0)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.1550
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2292395
	speed: 0.0984s/iter; left time: 937.6816s
Epoch: 11 cost time: 10.530587673187256
Epoch: 11, Steps: 107 Train Loss: 3.1824 (Forecasting Loss:0.2582 + XiCon Loss:2.9243 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.1536
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1094620
	speed: 0.0915s/iter; left time: 861.9629s
Epoch: 12 cost time: 9.839578628540039
Epoch: 12, Steps: 107 Train Loss: 3.1862 (Forecasting Loss:0.2575 + XiCon Loss:2.9287 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.1534
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.09978729486465454, mae:0.2490152269601822, mape:0.17657719552516937, mspe:0.04942261427640915 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0892+-0.02077, MAE:0.2352+-0.02771, MAPE:0.1682+-0.01452, MSPE:0.0452+-0.00522, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.5580
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 14.919663906097412
Epoch: 1, Steps: 96 Train Loss: 3.8945 (Forecasting Loss:0.7532 + XiCon Loss:3.1413 x Lambda(1.0)), Vali MSE Loss: 0.4512 Test MSE Loss: 0.3030
Validation loss decreased (inf --> 0.451196).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 14.29751992225647
Epoch: 2, Steps: 96 Train Loss: 3.5176 (Forecasting Loss:0.5204 + XiCon Loss:2.9972 x Lambda(1.0)), Vali MSE Loss: 0.3005 Test MSE Loss: 0.2171
Validation loss decreased (0.451196 --> 0.300491).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 14.625847101211548
Epoch: 3, Steps: 96 Train Loss: 3.4585 (Forecasting Loss:0.3094 + XiCon Loss:3.1491 x Lambda(1.0)), Vali MSE Loss: 0.4148 Test MSE Loss: 0.2274
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 14.8343825340271
Epoch: 4, Steps: 96 Train Loss: 3.5260 (Forecasting Loss:0.3031 + XiCon Loss:3.2229 x Lambda(1.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.1804
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.30211353302002
Epoch: 5, Steps: 96 Train Loss: 3.5308 (Forecasting Loss:0.2917 + XiCon Loss:3.2392 x Lambda(1.0)), Vali MSE Loss: 0.3673 Test MSE Loss: 0.2131
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 14.229483366012573
Epoch: 6, Steps: 96 Train Loss: 3.5278 (Forecasting Loss:0.2917 + XiCon Loss:3.2361 x Lambda(1.0)), Vali MSE Loss: 0.4578 Test MSE Loss: 0.1905
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.019341707229614
Epoch: 7, Steps: 96 Train Loss: 3.5271 (Forecasting Loss:0.2862 + XiCon Loss:3.2408 x Lambda(1.0)), Vali MSE Loss: 0.3774 Test MSE Loss: 0.1854
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.06144094467163
Epoch: 8, Steps: 96 Train Loss: 3.5035 (Forecasting Loss:0.2834 + XiCon Loss:3.2201 x Lambda(1.0)), Vali MSE Loss: 0.3654 Test MSE Loss: 0.1862
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 14.484457731246948
Epoch: 9, Steps: 96 Train Loss: 3.5182 (Forecasting Loss:0.2835 + XiCon Loss:3.2347 x Lambda(1.0)), Vali MSE Loss: 0.3739 Test MSE Loss: 0.1835
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 14.58292007446289
Epoch: 10, Steps: 96 Train Loss: 3.5011 (Forecasting Loss:0.2822 + XiCon Loss:3.2189 x Lambda(1.0)), Vali MSE Loss: 0.3709 Test MSE Loss: 0.1862
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 14.137099981307983
Epoch: 11, Steps: 96 Train Loss: 3.5107 (Forecasting Loss:0.2845 + XiCon Loss:3.2262 x Lambda(1.0)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.1858
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 14.784008026123047
Epoch: 12, Steps: 96 Train Loss: 3.4955 (Forecasting Loss:0.2822 + XiCon Loss:3.2133 x Lambda(1.0)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.1857
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.13578428328037262, mae:0.29848557710647583, mape:0.20608364045619965, mspe:0.059270258992910385 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3692
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.992142677307129
Epoch: 1, Steps: 96 Train Loss: 3.8687 (Forecasting Loss:0.7253 + XiCon Loss:3.1433 x Lambda(1.0)), Vali MSE Loss: 0.4368 Test MSE Loss: 0.2658
Validation loss decreased (inf --> 0.436848).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 14.156046867370605
Epoch: 2, Steps: 96 Train Loss: 3.5421 (Forecasting Loss:0.4789 + XiCon Loss:3.0631 x Lambda(1.0)), Vali MSE Loss: 0.2922 Test MSE Loss: 0.2490
Validation loss decreased (0.436848 --> 0.292226).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 14.756356239318848
Epoch: 3, Steps: 96 Train Loss: 3.4698 (Forecasting Loss:0.3072 + XiCon Loss:3.1626 x Lambda(1.0)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.1793
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 14.063544988632202
Epoch: 4, Steps: 96 Train Loss: 3.5319 (Forecasting Loss:0.3048 + XiCon Loss:3.2271 x Lambda(1.0)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.1437
Validation loss decreased (0.292226 --> 0.262700).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 14.615966796875
Epoch: 5, Steps: 96 Train Loss: 3.5373 (Forecasting Loss:0.2924 + XiCon Loss:3.2449 x Lambda(1.0)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1601
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 14.019911766052246
Epoch: 6, Steps: 96 Train Loss: 3.5491 (Forecasting Loss:0.2891 + XiCon Loss:3.2600 x Lambda(1.0)), Vali MSE Loss: 0.3012 Test MSE Loss: 0.1490
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 14.218936920166016
Epoch: 7, Steps: 96 Train Loss: 3.5382 (Forecasting Loss:0.2866 + XiCon Loss:3.2516 x Lambda(1.0)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.1450
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 14.748064279556274
Epoch: 8, Steps: 96 Train Loss: 3.5287 (Forecasting Loss:0.2861 + XiCon Loss:3.2425 x Lambda(1.0)), Vali MSE Loss: 0.2861 Test MSE Loss: 0.1461
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 14.339402198791504
Epoch: 9, Steps: 96 Train Loss: 3.5379 (Forecasting Loss:0.2857 + XiCon Loss:3.2521 x Lambda(1.0)), Vali MSE Loss: 0.3015 Test MSE Loss: 0.1512
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 14.41194748878479
Epoch: 10, Steps: 96 Train Loss: 3.5368 (Forecasting Loss:0.2845 + XiCon Loss:3.2522 x Lambda(1.0)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.1496
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 14.448891401290894
Epoch: 11, Steps: 96 Train Loss: 3.5364 (Forecasting Loss:0.2841 + XiCon Loss:3.2523 x Lambda(1.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.1504
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 14.220917224884033
Epoch: 12, Steps: 96 Train Loss: 3.5291 (Forecasting Loss:0.2836 + XiCon Loss:3.2455 x Lambda(1.0)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.1498
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 14.384347438812256
Epoch: 13, Steps: 96 Train Loss: 3.5364 (Forecasting Loss:0.2841 + XiCon Loss:3.2523 x Lambda(1.0)), Vali MSE Loss: 0.2921 Test MSE Loss: 0.1493
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 14.29893708229065
Epoch: 14, Steps: 96 Train Loss: 3.5211 (Forecasting Loss:0.2851 + XiCon Loss:3.2360 x Lambda(1.0)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1492
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.07412867248058319, mae:0.21325980126857758, mape:0.15492813289165497, mspe:0.04004637897014618 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3912
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 13.375852346420288
Epoch: 1, Steps: 96 Train Loss: 3.9511 (Forecasting Loss:0.8058 + XiCon Loss:3.1452 x Lambda(1.0)), Vali MSE Loss: 0.6073 Test MSE Loss: 0.3972
Validation loss decreased (inf --> 0.607290).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 17.624861240386963
Epoch: 2, Steps: 96 Train Loss: 3.5134 (Forecasting Loss:0.4919 + XiCon Loss:3.0215 x Lambda(1.0)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.2165
Validation loss decreased (0.607290 --> 0.313948).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 24.69802451133728
Epoch: 3, Steps: 96 Train Loss: 3.3791 (Forecasting Loss:0.2904 + XiCon Loss:3.0888 x Lambda(1.0)), Vali MSE Loss: 0.3413 Test MSE Loss: 0.2099
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 23.33678674697876
Epoch: 4, Steps: 96 Train Loss: 3.3955 (Forecasting Loss:0.2777 + XiCon Loss:3.1178 x Lambda(1.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.2558
Validation loss decreased (0.313948 --> 0.230917).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 22.70917248725891
Epoch: 5, Steps: 96 Train Loss: 3.3721 (Forecasting Loss:0.2685 + XiCon Loss:3.1035 x Lambda(1.0)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.2070
Validation loss decreased (0.230917 --> 0.226485).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 22.470244646072388
Epoch: 6, Steps: 96 Train Loss: 3.3532 (Forecasting Loss:0.2631 + XiCon Loss:3.0900 x Lambda(1.0)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.2238
Validation loss decreased (0.226485 --> 0.225938).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 23.02653694152832
Epoch: 7, Steps: 96 Train Loss: 3.3503 (Forecasting Loss:0.2613 + XiCon Loss:3.0891 x Lambda(1.0)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.2399
Validation loss decreased (0.225938 --> 0.222862).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 22.882025003433228
Epoch: 8, Steps: 96 Train Loss: 3.3520 (Forecasting Loss:0.2604 + XiCon Loss:3.0916 x Lambda(1.0)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.2317
Validation loss decreased (0.222862 --> 0.222674).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 23.071474313735962
Epoch: 9, Steps: 96 Train Loss: 3.3474 (Forecasting Loss:0.2601 + XiCon Loss:3.0873 x Lambda(1.0)), Vali MSE Loss: 0.2233 Test MSE Loss: 0.2265
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 22.819897651672363
Epoch: 10, Steps: 96 Train Loss: 3.3423 (Forecasting Loss:0.2595 + XiCon Loss:3.0828 x Lambda(1.0)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.2292
Validation loss decreased (0.222674 --> 0.222261).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 22.266260862350464
Epoch: 11, Steps: 96 Train Loss: 3.3397 (Forecasting Loss:0.2593 + XiCon Loss:3.0803 x Lambda(1.0)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.2306
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 23.025747060775757
Epoch: 12, Steps: 96 Train Loss: 3.3384 (Forecasting Loss:0.2592 + XiCon Loss:3.0792 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.2291
Validation loss decreased (0.222261 --> 0.222184).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 22.222455978393555
Epoch: 13, Steps: 96 Train Loss: 3.3470 (Forecasting Loss:0.2590 + XiCon Loss:3.0881 x Lambda(1.0)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.2273
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 23.27265954017639
Epoch: 14, Steps: 96 Train Loss: 3.3376 (Forecasting Loss:0.2587 + XiCon Loss:3.0790 x Lambda(1.0)), Vali MSE Loss: 0.2221 Test MSE Loss: 0.2277
Validation loss decreased (0.222184 --> 0.222129).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 23.02047824859619
Epoch: 15, Steps: 96 Train Loss: 3.3319 (Forecasting Loss:0.2600 + XiCon Loss:3.0719 x Lambda(1.0)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.2280
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 22.545233488082886
Epoch: 16, Steps: 96 Train Loss: 3.3337 (Forecasting Loss:0.2588 + XiCon Loss:3.0749 x Lambda(1.0)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.2280
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 23.299809455871582
Epoch: 17, Steps: 96 Train Loss: 3.3384 (Forecasting Loss:0.2596 + XiCon Loss:3.0788 x Lambda(1.0)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.2281
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 22.364476203918457
Epoch: 18, Steps: 96 Train Loss: 3.3492 (Forecasting Loss:0.2587 + XiCon Loss:3.0905 x Lambda(1.0)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.2281
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 22.62682318687439
Epoch: 19, Steps: 96 Train Loss: 3.3363 (Forecasting Loss:0.2602 + XiCon Loss:3.0761 x Lambda(1.0)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.2281
Validation loss decreased (0.222129 --> 0.221905).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 23.12095355987549
Epoch: 20, Steps: 96 Train Loss: 3.3435 (Forecasting Loss:0.2586 + XiCon Loss:3.0849 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.2281
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 22.707040548324585
Epoch: 21, Steps: 96 Train Loss: 3.3371 (Forecasting Loss:0.2601 + XiCon Loss:3.0771 x Lambda(1.0)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.2281
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 22.786845207214355
Epoch: 22, Steps: 96 Train Loss: 3.3360 (Forecasting Loss:0.2587 + XiCon Loss:3.0773 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.2281
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 22.871638774871826
Epoch: 23, Steps: 96 Train Loss: 3.3354 (Forecasting Loss:0.2591 + XiCon Loss:3.0763 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.2281
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 23.178183555603027
Epoch: 24, Steps: 96 Train Loss: 3.3394 (Forecasting Loss:0.2590 + XiCon Loss:3.0804 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.2281
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 23.019991397857666
Epoch: 25, Steps: 96 Train Loss: 3.3465 (Forecasting Loss:0.2595 + XiCon Loss:3.0870 x Lambda(1.0)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.2281
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 23.306119680404663
Epoch: 26, Steps: 96 Train Loss: 3.3345 (Forecasting Loss:0.2590 + XiCon Loss:3.0756 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.2281
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 22.584885120391846
Epoch: 27, Steps: 96 Train Loss: 3.3419 (Forecasting Loss:0.2593 + XiCon Loss:3.0826 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.2281
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 22.770642042160034
Epoch: 28, Steps: 96 Train Loss: 3.3338 (Forecasting Loss:0.2586 + XiCon Loss:3.0752 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.2281
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 22.98657488822937
Epoch: 29, Steps: 96 Train Loss: 3.3348 (Forecasting Loss:0.2593 + XiCon Loss:3.0755 x Lambda(1.0)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.2281
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.14699727296829224, mae:0.3091672956943512, mape:0.2134907990694046, mspe:0.06559032946825027 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4248
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 14.636489152908325
Epoch: 1, Steps: 96 Train Loss: 3.9106 (Forecasting Loss:0.7788 + XiCon Loss:3.1318 x Lambda(1.0)), Vali MSE Loss: 0.5868 Test MSE Loss: 0.3810
Validation loss decreased (inf --> 0.586767).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 24.520876169204712
Epoch: 2, Steps: 96 Train Loss: 3.4136 (Forecasting Loss:0.4197 + XiCon Loss:2.9939 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1811
Validation loss decreased (0.586767 --> 0.249080).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 22.087521076202393
Epoch: 3, Steps: 96 Train Loss: 3.4651 (Forecasting Loss:0.2934 + XiCon Loss:3.1717 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.1842
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 26.580715894699097
Epoch: 4, Steps: 96 Train Loss: 3.4503 (Forecasting Loss:0.2892 + XiCon Loss:3.1611 x Lambda(1.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1698
Validation loss decreased (0.249080 --> 0.242801).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 26.195192575454712
Epoch: 5, Steps: 96 Train Loss: 3.3890 (Forecasting Loss:0.2785 + XiCon Loss:3.1106 x Lambda(1.0)), Vali MSE Loss: 0.2210 Test MSE Loss: 0.1914
Validation loss decreased (0.242801 --> 0.220990).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 26.36866068840027
Epoch: 6, Steps: 96 Train Loss: 3.3791 (Forecasting Loss:0.2759 + XiCon Loss:3.1032 x Lambda(1.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.1887
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 25.761845111846924
Epoch: 7, Steps: 96 Train Loss: 3.3615 (Forecasting Loss:0.2720 + XiCon Loss:3.0895 x Lambda(1.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.1884
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 25.909674167633057
Epoch: 8, Steps: 96 Train Loss: 3.3647 (Forecasting Loss:0.2722 + XiCon Loss:3.0925 x Lambda(1.0)), Vali MSE Loss: 0.2268 Test MSE Loss: 0.1867
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 25.709932565689087
Epoch: 9, Steps: 96 Train Loss: 3.3600 (Forecasting Loss:0.2718 + XiCon Loss:3.0882 x Lambda(1.0)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.1886
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 25.2996826171875
Epoch: 10, Steps: 96 Train Loss: 3.3517 (Forecasting Loss:0.2721 + XiCon Loss:3.0796 x Lambda(1.0)), Vali MSE Loss: 0.2263 Test MSE Loss: 0.1886
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 24.869893550872803
Epoch: 11, Steps: 96 Train Loss: 3.3708 (Forecasting Loss:0.2703 + XiCon Loss:3.1005 x Lambda(1.0)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1873
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 25.23342490196228
Epoch: 12, Steps: 96 Train Loss: 3.3690 (Forecasting Loss:0.2721 + XiCon Loss:3.0968 x Lambda(1.0)), Vali MSE Loss: 0.2245 Test MSE Loss: 0.1875
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 25.40097403526306
Epoch: 13, Steps: 96 Train Loss: 3.3742 (Forecasting Loss:0.2709 + XiCon Loss:3.1033 x Lambda(1.0)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.1877
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 25.337225198745728
Epoch: 14, Steps: 96 Train Loss: 3.3573 (Forecasting Loss:0.2710 + XiCon Loss:3.0863 x Lambda(1.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.1876
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 25.080913543701172
Epoch: 15, Steps: 96 Train Loss: 3.3671 (Forecasting Loss:0.2708 + XiCon Loss:3.0963 x Lambda(1.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1874
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.11454404145479202, mae:0.26835551857948303, mape:0.18842262029647827, mspe:0.053968388587236404 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4936
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 14.826766729354858
Epoch: 1, Steps: 96 Train Loss: 3.8989 (Forecasting Loss:0.7623 + XiCon Loss:3.1366 x Lambda(1.0)), Vali MSE Loss: 0.5635 Test MSE Loss: 0.3671
Validation loss decreased (inf --> 0.563534).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 22.720829010009766
Epoch: 2, Steps: 96 Train Loss: 3.4682 (Forecasting Loss:0.4136 + XiCon Loss:3.0545 x Lambda(1.0)), Vali MSE Loss: 0.3909 Test MSE Loss: 0.2139
Validation loss decreased (0.563534 --> 0.390874).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 25.37668776512146
Epoch: 3, Steps: 96 Train Loss: 3.4413 (Forecasting Loss:0.2871 + XiCon Loss:3.1541 x Lambda(1.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.1898
Validation loss decreased (0.390874 --> 0.319861).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 26.19293212890625
Epoch: 4, Steps: 96 Train Loss: 3.4525 (Forecasting Loss:0.2851 + XiCon Loss:3.1673 x Lambda(1.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.1876
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 25.21790885925293
Epoch: 5, Steps: 96 Train Loss: 3.4260 (Forecasting Loss:0.2825 + XiCon Loss:3.1435 x Lambda(1.0)), Vali MSE Loss: 0.2334 Test MSE Loss: 0.1847
Validation loss decreased (0.319861 --> 0.233421).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 25.004406929016113
Epoch: 6, Steps: 96 Train Loss: 3.4059 (Forecasting Loss:0.2762 + XiCon Loss:3.1298 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.1785
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 25.567367792129517
Epoch: 7, Steps: 96 Train Loss: 3.3842 (Forecasting Loss:0.2739 + XiCon Loss:3.1104 x Lambda(1.0)), Vali MSE Loss: 0.2644 Test MSE Loss: 0.1905
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 24.856834411621094
Epoch: 8, Steps: 96 Train Loss: 3.3837 (Forecasting Loss:0.2740 + XiCon Loss:3.1097 x Lambda(1.0)), Vali MSE Loss: 0.2731 Test MSE Loss: 0.1835
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 24.780492067337036
Epoch: 9, Steps: 96 Train Loss: 3.3921 (Forecasting Loss:0.2730 + XiCon Loss:3.1191 x Lambda(1.0)), Vali MSE Loss: 0.2547 Test MSE Loss: 0.1880
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 25.14370322227478
Epoch: 10, Steps: 96 Train Loss: 3.3890 (Forecasting Loss:0.2726 + XiCon Loss:3.1164 x Lambda(1.0)), Vali MSE Loss: 0.2720 Test MSE Loss: 0.1889
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 24.796201944351196
Epoch: 11, Steps: 96 Train Loss: 3.3916 (Forecasting Loss:0.2723 + XiCon Loss:3.1193 x Lambda(1.0)), Vali MSE Loss: 0.2689 Test MSE Loss: 0.1884
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 25.471729516983032
Epoch: 12, Steps: 96 Train Loss: 3.3890 (Forecasting Loss:0.2721 + XiCon Loss:3.1170 x Lambda(1.0)), Vali MSE Loss: 0.2700 Test MSE Loss: 0.1877
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 25.109820127487183
Epoch: 13, Steps: 96 Train Loss: 3.3820 (Forecasting Loss:0.2706 + XiCon Loss:3.1114 x Lambda(1.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.1880
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 25.03336501121521
Epoch: 14, Steps: 96 Train Loss: 3.3928 (Forecasting Loss:0.2718 + XiCon Loss:3.1211 x Lambda(1.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1880
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 25.02860999107361
Epoch: 15, Steps: 96 Train Loss: 3.3884 (Forecasting Loss:0.2720 + XiCon Loss:3.1164 x Lambda(1.0)), Vali MSE Loss: 0.2704 Test MSE Loss: 0.1881
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.10876525193452835, mae:0.26053619384765625, mape:0.18598414957523346, mspe:0.054670821875333786 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1160+-0.03490, MAE:0.2700+-0.04670, MAPE:0.1898+-0.02817, MSPE:0.0547+-0.01169, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4830
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2799475
	speed: 0.0260s/iter; left time: 329.8197s
Epoch: 1 cost time: 3.2675936222076416
Epoch: 1, Steps: 128 Train Loss: 3.3678 (Forecasting Loss:0.2930 + XiCon Loss:3.0748 x Lambda(1.0)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.2328
Validation loss decreased (inf --> 0.277091).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0972381
	speed: 0.0201s/iter; left time: 252.4367s
Epoch: 2 cost time: 2.5932135581970215
Epoch: 2, Steps: 128 Train Loss: 3.1542 (Forecasting Loss:0.2571 + XiCon Loss:2.8971 x Lambda(1.0)), Vali MSE Loss: 0.2568 Test MSE Loss: 0.2191
Validation loss decreased (0.277091 --> 0.256799).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1934583
	speed: 0.0243s/iter; left time: 301.9404s
Epoch: 3 cost time: 3.0517492294311523
Epoch: 3, Steps: 128 Train Loss: 3.2096 (Forecasting Loss:0.2437 + XiCon Loss:2.9659 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.2208
Validation loss decreased (0.256799 --> 0.252241).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2221406
	speed: 0.0240s/iter; left time: 295.0861s
Epoch: 4 cost time: 2.986292839050293
Epoch: 4, Steps: 128 Train Loss: 3.1659 (Forecasting Loss:0.2373 + XiCon Loss:2.9286 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.2063
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1572752
	speed: 0.0232s/iter; left time: 283.1079s
Epoch: 5 cost time: 2.9483296871185303
Epoch: 5, Steps: 128 Train Loss: 3.1461 (Forecasting Loss:0.2347 + XiCon Loss:2.9114 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2081
Validation loss decreased (0.252241 --> 0.249964).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1796503
	speed: 0.0212s/iter; left time: 255.7647s
Epoch: 6 cost time: 2.762540578842163
Epoch: 6, Steps: 128 Train Loss: 3.1365 (Forecasting Loss:0.2325 + XiCon Loss:2.9041 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2068
Validation loss decreased (0.249964 --> 0.249640).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1426241
	speed: 0.0218s/iter; left time: 260.4323s
Epoch: 7 cost time: 2.7945210933685303
Epoch: 7, Steps: 128 Train Loss: 3.1342 (Forecasting Loss:0.2317 + XiCon Loss:2.9026 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2072
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1276729
	speed: 0.0224s/iter; left time: 264.4421s
Epoch: 8 cost time: 2.8424251079559326
Epoch: 8, Steps: 128 Train Loss: 3.1340 (Forecasting Loss:0.2313 + XiCon Loss:2.9027 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2066
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2178066
	speed: 0.0237s/iter; left time: 277.1732s
Epoch: 9 cost time: 3.019232988357544
Epoch: 9, Steps: 128 Train Loss: 3.1336 (Forecasting Loss:0.2313 + XiCon Loss:2.9023 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2059
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1125646
	speed: 0.0227s/iter; left time: 262.6741s
Epoch: 10 cost time: 2.856447696685791
Epoch: 10, Steps: 128 Train Loss: 3.1336 (Forecasting Loss:0.2312 + XiCon Loss:2.9025 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0328186
	speed: 0.0212s/iter; left time: 242.4622s
Epoch: 11 cost time: 2.7550384998321533
Epoch: 11, Steps: 128 Train Loss: 3.1288 (Forecasting Loss:0.2310 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2061
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0652294
	speed: 0.0237s/iter; left time: 268.1827s
Epoch: 12 cost time: 3.0172319412231445
Epoch: 12, Steps: 128 Train Loss: 3.1249 (Forecasting Loss:0.2311 + XiCon Loss:2.8938 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2060
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0392506
	speed: 0.0234s/iter; left time: 261.3967s
Epoch: 13 cost time: 3.0265400409698486
Epoch: 13, Steps: 128 Train Loss: 3.1410 (Forecasting Loss:0.2310 + XiCon Loss:2.9100 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2060
Validation loss decreased (0.249640 --> 0.249612).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1403413
	speed: 0.0235s/iter; left time: 259.3621s
Epoch: 14 cost time: 2.9902615547180176
Epoch: 14, Steps: 128 Train Loss: 3.1326 (Forecasting Loss:0.2308 + XiCon Loss:2.9019 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1309671
	speed: 0.0211s/iter; left time: 230.4375s
Epoch: 15 cost time: 2.5425009727478027
Epoch: 15, Steps: 128 Train Loss: 3.1329 (Forecasting Loss:0.2308 + XiCon Loss:2.9021 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2060
Validation loss decreased (0.249612 --> 0.249436).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1240716
	speed: 0.0236s/iter; left time: 254.0646s
Epoch: 16 cost time: 2.9709575176239014
Epoch: 16, Steps: 128 Train Loss: 3.1313 (Forecasting Loss:0.2310 + XiCon Loss:2.9002 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2060
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0901780
	speed: 0.0244s/iter; left time: 259.7789s
Epoch: 17 cost time: 3.0135395526885986
Epoch: 17, Steps: 128 Train Loss: 3.1257 (Forecasting Loss:0.2307 + XiCon Loss:2.8950 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2060
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1052525
	speed: 0.0247s/iter; left time: 259.7172s
Epoch: 18 cost time: 3.1062076091766357
Epoch: 18, Steps: 128 Train Loss: 3.1287 (Forecasting Loss:0.2309 + XiCon Loss:2.8978 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2060
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0932562
	speed: 0.0211s/iter; left time: 219.8676s
Epoch: 19 cost time: 2.7702934741973877
Epoch: 19, Steps: 128 Train Loss: 3.1342 (Forecasting Loss:0.2310 + XiCon Loss:2.9032 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2060
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0828562
	speed: 0.0260s/iter; left time: 267.1242s
Epoch: 20 cost time: 3.2799181938171387
Epoch: 20, Steps: 128 Train Loss: 3.1294 (Forecasting Loss:0.2309 + XiCon Loss:2.8985 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2060
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1124949
	speed: 0.0243s/iter; left time: 246.1786s
Epoch: 21 cost time: 3.073828935623169
Epoch: 21, Steps: 128 Train Loss: 3.1279 (Forecasting Loss:0.2306 + XiCon Loss:2.8973 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2060
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1378603
	speed: 0.0241s/iter; left time: 240.8486s
Epoch: 22 cost time: 2.965336799621582
Epoch: 22, Steps: 128 Train Loss: 3.1309 (Forecasting Loss:0.2308 + XiCon Loss:2.9001 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2060
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1611283
	speed: 0.0232s/iter; left time: 228.9014s
Epoch: 23 cost time: 2.9087486267089844
Epoch: 23, Steps: 128 Train Loss: 3.1268 (Forecasting Loss:0.2310 + XiCon Loss:2.8958 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2060
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1016061
	speed: 0.0203s/iter; left time: 198.4202s
Epoch: 24 cost time: 2.3928232192993164
Epoch: 24, Steps: 128 Train Loss: 3.1357 (Forecasting Loss:0.2309 + XiCon Loss:2.9048 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2060
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1237063
	speed: 0.0592s/iter; left time: 570.4661s
Epoch: 25 cost time: 7.203161001205444
Epoch: 25, Steps: 128 Train Loss: 3.1281 (Forecasting Loss:0.2308 + XiCon Loss:2.8973 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2060
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13198015093803406, mae:0.28003761172294617, mape:0.6609959602355957, mspe:19.727861404418945 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.7044
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2977419
	speed: 0.0167s/iter; left time: 211.5008s
Epoch: 1 cost time: 2.08039927482605
Epoch: 1, Steps: 128 Train Loss: 3.3687 (Forecasting Loss:0.2935 + XiCon Loss:3.0752 x Lambda(1.0)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.2275
Validation loss decreased (inf --> 0.274925).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2069852
	speed: 0.0140s/iter; left time: 176.0510s
Epoch: 2 cost time: 1.7627818584442139
Epoch: 2, Steps: 128 Train Loss: 3.1929 (Forecasting Loss:0.2565 + XiCon Loss:2.9364 x Lambda(1.0)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.2171
Validation loss decreased (0.274925 --> 0.261473).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1818485
	speed: 0.0166s/iter; left time: 207.0257s
Epoch: 3 cost time: 2.305788040161133
Epoch: 3, Steps: 128 Train Loss: 3.1767 (Forecasting Loss:0.2397 + XiCon Loss:2.9370 x Lambda(1.0)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.2082
Validation loss decreased (0.261473 --> 0.258942).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0590222
	speed: 0.0229s/iter; left time: 281.9639s
Epoch: 4 cost time: 2.889960289001465
Epoch: 4, Steps: 128 Train Loss: 3.1255 (Forecasting Loss:0.2313 + XiCon Loss:2.8942 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2113
Validation loss decreased (0.258942 --> 0.247711).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1103349
	speed: 0.0236s/iter; left time: 287.3420s
Epoch: 5 cost time: 2.971040725708008
Epoch: 5, Steps: 128 Train Loss: 3.1140 (Forecasting Loss:0.2277 + XiCon Loss:2.8862 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.2126
Validation loss decreased (0.247711 --> 0.245507).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1588819
	speed: 0.0231s/iter; left time: 279.0041s
Epoch: 6 cost time: 2.881380558013916
Epoch: 6, Steps: 128 Train Loss: 3.1044 (Forecasting Loss:0.2256 + XiCon Loss:2.8787 x Lambda(1.0)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.2134
Validation loss decreased (0.245507 --> 0.243450).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0823863
	speed: 0.0194s/iter; left time: 231.7749s
Epoch: 7 cost time: 2.5658700466156006
Epoch: 7, Steps: 128 Train Loss: 3.1084 (Forecasting Loss:0.2239 + XiCon Loss:2.8845 x Lambda(1.0)), Vali MSE Loss: 0.2420 Test MSE Loss: 0.2114
Validation loss decreased (0.243450 --> 0.241988).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0647707
	speed: 0.0231s/iter; left time: 272.8641s
Epoch: 8 cost time: 2.9425060749053955
Epoch: 8, Steps: 128 Train Loss: 3.0985 (Forecasting Loss:0.2229 + XiCon Loss:2.8757 x Lambda(1.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.2114
Validation loss decreased (0.241988 --> 0.241235).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1556478
	speed: 0.0221s/iter; left time: 257.4829s
Epoch: 9 cost time: 2.815976619720459
Epoch: 9, Steps: 128 Train Loss: 3.0975 (Forecasting Loss:0.2229 + XiCon Loss:2.8746 x Lambda(1.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.2114
Validation loss decreased (0.241235 --> 0.241187).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0447664
	speed: 0.0239s/iter; left time: 276.4971s
Epoch: 10 cost time: 2.98785400390625
Epoch: 10, Steps: 128 Train Loss: 3.0924 (Forecasting Loss:0.2226 + XiCon Loss:2.8698 x Lambda(1.0)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.2113
Validation loss decreased (0.241187 --> 0.240968).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2401757
	speed: 0.0219s/iter; left time: 249.9527s
Epoch: 11 cost time: 2.680485486984253
Epoch: 11, Steps: 128 Train Loss: 3.1021 (Forecasting Loss:0.2228 + XiCon Loss:2.8793 x Lambda(1.0)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.2115
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0761070
	speed: 0.0190s/iter; left time: 214.6505s
Epoch: 12 cost time: 2.5314202308654785
Epoch: 12, Steps: 128 Train Loss: 3.0945 (Forecasting Loss:0.2221 + XiCon Loss:2.8724 x Lambda(1.0)), Vali MSE Loss: 0.2415 Test MSE Loss: 0.2115
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1820560
	speed: 0.0240s/iter; left time: 268.1177s
Epoch: 13 cost time: 2.9614689350128174
Epoch: 13, Steps: 128 Train Loss: 3.0971 (Forecasting Loss:0.2218 + XiCon Loss:2.8753 x Lambda(1.0)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.2114
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1443188
	speed: 0.0235s/iter; left time: 259.9192s
Epoch: 14 cost time: 2.9222660064697266
Epoch: 14, Steps: 128 Train Loss: 3.0970 (Forecasting Loss:0.2225 + XiCon Loss:2.8745 x Lambda(1.0)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.2114
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1143570
	speed: 0.0245s/iter; left time: 266.7291s
Epoch: 15 cost time: 2.9986441135406494
Epoch: 15, Steps: 128 Train Loss: 3.1013 (Forecasting Loss:0.2222 + XiCon Loss:2.8791 x Lambda(1.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.2115
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0785279
	speed: 0.0251s/iter; left time: 270.7241s
Epoch: 16 cost time: 3.1304590702056885
Epoch: 16, Steps: 128 Train Loss: 3.1009 (Forecasting Loss:0.2222 + XiCon Loss:2.8788 x Lambda(1.0)), Vali MSE Loss: 0.2414 Test MSE Loss: 0.2115
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0992932
	speed: 0.0233s/iter; left time: 247.8170s
Epoch: 17 cost time: 2.9826760292053223
Epoch: 17, Steps: 128 Train Loss: 3.0920 (Forecasting Loss:0.2219 + XiCon Loss:2.8702 x Lambda(1.0)), Vali MSE Loss: 0.2418 Test MSE Loss: 0.2114
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.0588062
	speed: 0.0246s/iter; left time: 258.4259s
Epoch: 18 cost time: 3.032447099685669
Epoch: 18, Steps: 128 Train Loss: 3.0947 (Forecasting Loss:0.2223 + XiCon Loss:2.8723 x Lambda(1.0)), Vali MSE Loss: 0.2418 Test MSE Loss: 0.2114
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0383823
	speed: 0.0239s/iter; left time: 248.1722s
Epoch: 19 cost time: 3.0116236209869385
Epoch: 19, Steps: 128 Train Loss: 3.0962 (Forecasting Loss:0.2221 + XiCon Loss:2.8740 x Lambda(1.0)), Vali MSE Loss: 0.2417 Test MSE Loss: 0.2114
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0760760
	speed: 0.0236s/iter; left time: 242.6865s
Epoch: 20 cost time: 3.0244128704071045
Epoch: 20, Steps: 128 Train Loss: 3.0918 (Forecasting Loss:0.2225 + XiCon Loss:2.8693 x Lambda(1.0)), Vali MSE Loss: 0.2416 Test MSE Loss: 0.2114
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13607469201087952, mae:0.2865712642669678, mape:0.6812623739242554, mspe:19.27994155883789 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4132
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3156123
	speed: 0.0211s/iter; left time: 268.2939s
Epoch: 1 cost time: 2.6672630310058594
Epoch: 1, Steps: 128 Train Loss: 3.3484 (Forecasting Loss:0.2902 + XiCon Loss:3.0583 x Lambda(1.0)), Vali MSE Loss: 0.2711 Test MSE Loss: 0.2278
Validation loss decreased (inf --> 0.271142).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1751993
	speed: 0.0235s/iter; left time: 295.1169s
Epoch: 2 cost time: 2.9932663440704346
Epoch: 2, Steps: 128 Train Loss: 3.1735 (Forecasting Loss:0.2528 + XiCon Loss:2.9207 x Lambda(1.0)), Vali MSE Loss: 0.2684 Test MSE Loss: 0.2216
Validation loss decreased (0.271142 --> 0.268356).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2127731
	speed: 0.0234s/iter; left time: 291.0129s
Epoch: 3 cost time: 2.9288270473480225
Epoch: 3, Steps: 128 Train Loss: 3.2425 (Forecasting Loss:0.2427 + XiCon Loss:2.9998 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2089
Validation loss decreased (0.268356 --> 0.252891).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1689625
	speed: 0.0234s/iter; left time: 288.1741s
Epoch: 4 cost time: 2.9972944259643555
Epoch: 4, Steps: 128 Train Loss: 3.1905 (Forecasting Loss:0.2334 + XiCon Loss:2.9572 x Lambda(1.0)), Vali MSE Loss: 0.2513 Test MSE Loss: 0.2086
Validation loss decreased (0.252891 --> 0.251346).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1290884
	speed: 0.0216s/iter; left time: 263.1741s
Epoch: 5 cost time: 2.722461700439453
Epoch: 5, Steps: 128 Train Loss: 3.1584 (Forecasting Loss:0.2290 + XiCon Loss:2.9294 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2070
Validation loss decreased (0.251346 --> 0.248128).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1238070
	speed: 0.0238s/iter; left time: 286.6437s
Epoch: 6 cost time: 2.9936509132385254
Epoch: 6, Steps: 128 Train Loss: 3.1469 (Forecasting Loss:0.2270 + XiCon Loss:2.9199 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.2083
Validation loss decreased (0.248128 --> 0.245632).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1431465
	speed: 0.0234s/iter; left time: 278.9574s
Epoch: 7 cost time: 2.929661512374878
Epoch: 7, Steps: 128 Train Loss: 3.1390 (Forecasting Loss:0.2260 + XiCon Loss:2.9130 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.2076
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0818727
	speed: 0.0244s/iter; left time: 288.3034s
Epoch: 8 cost time: 3.0651674270629883
Epoch: 8, Steps: 128 Train Loss: 3.1350 (Forecasting Loss:0.2254 + XiCon Loss:2.9096 x Lambda(1.0)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.2078
Validation loss decreased (0.245632 --> 0.244955).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2085445
	speed: 0.0225s/iter; left time: 262.6665s
Epoch: 9 cost time: 2.733293294906616
Epoch: 9, Steps: 128 Train Loss: 3.1351 (Forecasting Loss:0.2252 + XiCon Loss:2.9099 x Lambda(1.0)), Vali MSE Loss: 0.2451 Test MSE Loss: 0.2086
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0556026
	speed: 0.0245s/iter; left time: 283.3612s
Epoch: 10 cost time: 3.1097676753997803
Epoch: 10, Steps: 128 Train Loss: 3.1279 (Forecasting Loss:0.2243 + XiCon Loss:2.9036 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.2090
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0908575
	speed: 0.0222s/iter; left time: 253.0821s
Epoch: 11 cost time: 2.8320720195770264
Epoch: 11, Steps: 128 Train Loss: 3.1276 (Forecasting Loss:0.2244 + XiCon Loss:2.9033 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.2088
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1791503
	speed: 0.0236s/iter; left time: 266.8791s
Epoch: 12 cost time: 2.954242467880249
Epoch: 12, Steps: 128 Train Loss: 3.1293 (Forecasting Loss:0.2245 + XiCon Loss:2.9049 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.2089
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1250441
	speed: 0.0236s/iter; left time: 263.0082s
Epoch: 13 cost time: 2.918363332748413
Epoch: 13, Steps: 128 Train Loss: 3.1270 (Forecasting Loss:0.2245 + XiCon Loss:2.9026 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.2090
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1897049
	speed: 0.0210s/iter; left time: 232.2461s
Epoch: 14 cost time: 2.7792680263519287
Epoch: 14, Steps: 128 Train Loss: 3.1223 (Forecasting Loss:0.2242 + XiCon Loss:2.8981 x Lambda(1.0)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.2089
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1640732
	speed: 0.0241s/iter; left time: 263.1801s
Epoch: 15 cost time: 3.0803258419036865
Epoch: 15, Steps: 128 Train Loss: 3.1339 (Forecasting Loss:0.2250 + XiCon Loss:2.9089 x Lambda(1.0)), Vali MSE Loss: 0.2451 Test MSE Loss: 0.2089
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1493149
	speed: 0.0256s/iter; left time: 276.4730s
Epoch: 16 cost time: 3.242905378341675
Epoch: 16, Steps: 128 Train Loss: 3.1333 (Forecasting Loss:0.2245 + XiCon Loss:2.9088 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.2089
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1368148
	speed: 0.0249s/iter; left time: 265.5229s
Epoch: 17 cost time: 3.047856569290161
Epoch: 17, Steps: 128 Train Loss: 3.1318 (Forecasting Loss:0.2243 + XiCon Loss:2.9075 x Lambda(1.0)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.2089
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1727705
	speed: 0.0209s/iter; left time: 220.2614s
Epoch: 18 cost time: 2.733566999435425
Epoch: 18, Steps: 128 Train Loss: 3.1342 (Forecasting Loss:0.2244 + XiCon Loss:2.9098 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.2089
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13287858664989471, mae:0.2827363908290863, mape:0.6851298213005066, mspe:22.69725227355957 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4164
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3253527
	speed: 0.0242s/iter; left time: 307.4399s
Epoch: 1 cost time: 3.0631256103515625
Epoch: 1, Steps: 128 Train Loss: 3.3647 (Forecasting Loss:0.2942 + XiCon Loss:3.0705 x Lambda(1.0)), Vali MSE Loss: 0.2765 Test MSE Loss: 0.2304
Validation loss decreased (inf --> 0.276503).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0933797
	speed: 0.0237s/iter; left time: 297.7352s
Epoch: 2 cost time: 2.9914538860321045
Epoch: 2, Steps: 128 Train Loss: 3.1562 (Forecasting Loss:0.2561 + XiCon Loss:2.9001 x Lambda(1.0)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.2159
Validation loss decreased (0.276503 --> 0.258041).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1080160
	speed: 0.0235s/iter; left time: 292.6915s
Epoch: 3 cost time: 2.9521422386169434
Epoch: 3, Steps: 128 Train Loss: 3.1693 (Forecasting Loss:0.2424 + XiCon Loss:2.9268 x Lambda(1.0)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.2136
Validation loss decreased (0.258041 --> 0.255177).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1689737
	speed: 0.0198s/iter; left time: 244.3830s
Epoch: 4 cost time: 2.5599513053894043
Epoch: 4, Steps: 128 Train Loss: 3.1734 (Forecasting Loss:0.2363 + XiCon Loss:2.9371 x Lambda(1.0)), Vali MSE Loss: 0.2449 Test MSE Loss: 0.2136
Validation loss decreased (0.255177 --> 0.244854).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1656811
	speed: 0.0227s/iter; left time: 276.9021s
Epoch: 5 cost time: 2.8792755603790283
Epoch: 5, Steps: 128 Train Loss: 3.1459 (Forecasting Loss:0.2323 + XiCon Loss:2.9136 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2054
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1169736
	speed: 0.0252s/iter; left time: 303.6698s
Epoch: 6 cost time: 3.1301727294921875
Epoch: 6, Steps: 128 Train Loss: 3.1367 (Forecasting Loss:0.2300 + XiCon Loss:2.9067 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2066
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0848126
	speed: 0.0227s/iter; left time: 271.0649s
Epoch: 7 cost time: 2.8111143112182617
Epoch: 7, Steps: 128 Train Loss: 3.1406 (Forecasting Loss:0.2290 + XiCon Loss:2.9116 x Lambda(1.0)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.2069
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2438881
	speed: 0.0227s/iter; left time: 267.8323s
Epoch: 8 cost time: 2.786400556564331
Epoch: 8, Steps: 128 Train Loss: 3.1314 (Forecasting Loss:0.2286 + XiCon Loss:2.9028 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2068541
	speed: 0.0212s/iter; left time: 247.2961s
Epoch: 9 cost time: 2.7867934703826904
Epoch: 9, Steps: 128 Train Loss: 3.1242 (Forecasting Loss:0.2283 + XiCon Loss:2.8960 x Lambda(1.0)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.2062
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1029916
	speed: 0.0233s/iter; left time: 269.1089s
Epoch: 10 cost time: 2.957547426223755
Epoch: 10, Steps: 128 Train Loss: 3.1375 (Forecasting Loss:0.2281 + XiCon Loss:2.9094 x Lambda(1.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.2064
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1428280
	speed: 0.0254s/iter; left time: 290.4237s
Epoch: 11 cost time: 3.342416763305664
Epoch: 11, Steps: 128 Train Loss: 3.1340 (Forecasting Loss:0.2281 + XiCon Loss:2.9059 x Lambda(1.0)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.2063
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1170824
	speed: 0.0229s/iter; left time: 258.6467s
Epoch: 12 cost time: 2.9717767238616943
Epoch: 12, Steps: 128 Train Loss: 3.1362 (Forecasting Loss:0.2281 + XiCon Loss:2.9081 x Lambda(1.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.2064
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0864129
	speed: 0.0199s/iter; left time: 221.8941s
Epoch: 13 cost time: 2.593299627304077
Epoch: 13, Steps: 128 Train Loss: 3.1270 (Forecasting Loss:0.2282 + XiCon Loss:2.8988 x Lambda(1.0)), Vali MSE Loss: 0.2472 Test MSE Loss: 0.2063
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1156704
	speed: 0.0227s/iter; left time: 250.3112s
Epoch: 14 cost time: 2.846372127532959
Epoch: 14, Steps: 128 Train Loss: 3.1192 (Forecasting Loss:0.2278 + XiCon Loss:2.8914 x Lambda(1.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.2063
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13950859010219574, mae:0.28766968846321106, mape:0.685741662979126, mspe:20.966318130493164 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4312
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3092337
	speed: 0.0226s/iter; left time: 287.4984s
Epoch: 1 cost time: 2.883061647415161
Epoch: 1, Steps: 128 Train Loss: 3.3486 (Forecasting Loss:0.2908 + XiCon Loss:3.0577 x Lambda(1.0)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2264
Validation loss decreased (inf --> 0.272502).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0761230
	speed: 0.0235s/iter; left time: 295.3196s
Epoch: 2 cost time: 2.940439462661743
Epoch: 2, Steps: 128 Train Loss: 3.1527 (Forecasting Loss:0.2591 + XiCon Loss:2.8936 x Lambda(1.0)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.2302
Validation loss decreased (0.272502 --> 0.260171).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.0650635
	speed: 0.0214s/iter; left time: 266.8093s
Epoch: 3 cost time: 2.7473137378692627
Epoch: 3, Steps: 128 Train Loss: 3.1416 (Forecasting Loss:0.2419 + XiCon Loss:2.8997 x Lambda(1.0)), Vali MSE Loss: 0.2601 Test MSE Loss: 0.2053
Validation loss decreased (0.260171 --> 0.260115).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1038742
	speed: 0.0241s/iter; left time: 296.5066s
Epoch: 4 cost time: 2.9808809757232666
Epoch: 4, Steps: 128 Train Loss: 3.1364 (Forecasting Loss:0.2366 + XiCon Loss:2.8998 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.2157
Validation loss decreased (0.260115 --> 0.253612).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1672773
	speed: 0.0239s/iter; left time: 290.8687s
Epoch: 5 cost time: 2.9824094772338867
Epoch: 5, Steps: 128 Train Loss: 3.1853 (Forecasting Loss:0.2346 + XiCon Loss:2.9507 x Lambda(1.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2050
Validation loss decreased (0.253612 --> 0.250831).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2412844
	speed: 0.0234s/iter; left time: 281.9229s
Epoch: 6 cost time: 2.938169002532959
Epoch: 6, Steps: 128 Train Loss: 3.2250 (Forecasting Loss:0.2329 + XiCon Loss:2.9921 x Lambda(1.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.2094
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1378233
	speed: 0.0243s/iter; left time: 290.3264s
Epoch: 7 cost time: 2.878916025161743
Epoch: 7, Steps: 128 Train Loss: 3.2502 (Forecasting Loss:0.2320 + XiCon Loss:3.0182 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2055
Validation loss decreased (0.250831 --> 0.249907).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2183454
	speed: 0.0198s/iter; left time: 234.0501s
Epoch: 8 cost time: 2.6315126419067383
Epoch: 8, Steps: 128 Train Loss: 3.2465 (Forecasting Loss:0.2317 + XiCon Loss:3.0148 x Lambda(1.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2058
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1736567
	speed: 0.0235s/iter; left time: 274.3534s
Epoch: 9 cost time: 2.935748815536499
Epoch: 9, Steps: 128 Train Loss: 3.2648 (Forecasting Loss:0.2312 + XiCon Loss:3.0336 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2055
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3335190
	speed: 0.0266s/iter; left time: 307.1333s
Epoch: 10 cost time: 3.336731433868408
Epoch: 10, Steps: 128 Train Loss: 3.2672 (Forecasting Loss:0.2312 + XiCon Loss:3.0360 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2054
Validation loss decreased (0.249907 --> 0.249333).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3891118
	speed: 0.0233s/iter; left time: 266.6264s
Epoch: 11 cost time: 2.957261800765991
Epoch: 11, Steps: 128 Train Loss: 3.2739 (Forecasting Loss:0.2312 + XiCon Loss:3.0428 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2055
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4035299
	speed: 0.0194s/iter; left time: 219.2213s
Epoch: 12 cost time: 2.602987051010132
Epoch: 12, Steps: 128 Train Loss: 3.2638 (Forecasting Loss:0.2310 + XiCon Loss:3.0327 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2054
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2769332
	speed: 0.0234s/iter; left time: 261.6594s
Epoch: 13 cost time: 2.9713447093963623
Epoch: 13, Steps: 128 Train Loss: 3.2624 (Forecasting Loss:0.2310 + XiCon Loss:3.0313 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2055
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4328489
	speed: 0.0238s/iter; left time: 262.8055s
Epoch: 14 cost time: 3.06522536277771
Epoch: 14, Steps: 128 Train Loss: 3.2597 (Forecasting Loss:0.2310 + XiCon Loss:3.0287 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2055
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3799195
	speed: 0.0228s/iter; left time: 248.6446s
Epoch: 15 cost time: 2.8742787837982178
Epoch: 15, Steps: 128 Train Loss: 3.2706 (Forecasting Loss:0.2312 + XiCon Loss:3.0394 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2055
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2386720
	speed: 0.0239s/iter; left time: 257.6253s
Epoch: 16 cost time: 2.8551416397094727
Epoch: 16, Steps: 128 Train Loss: 3.2540 (Forecasting Loss:0.2312 + XiCon Loss:3.0228 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2055
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2781274
	speed: 0.0221s/iter; left time: 235.8770s
Epoch: 17 cost time: 2.807833671569824
Epoch: 17, Steps: 128 Train Loss: 3.2683 (Forecasting Loss:0.2311 + XiCon Loss:3.0372 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2055
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3329580
	speed: 0.0239s/iter; left time: 251.5232s
Epoch: 18 cost time: 2.9700374603271484
Epoch: 18, Steps: 128 Train Loss: 3.2727 (Forecasting Loss:0.2309 + XiCon Loss:3.0417 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2055
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2841356
	speed: 0.0232s/iter; left time: 241.5105s
Epoch: 19 cost time: 2.895658493041992
Epoch: 19, Steps: 128 Train Loss: 3.2602 (Forecasting Loss:0.2311 + XiCon Loss:3.0291 x Lambda(1.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2055
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3519371
	speed: 0.0235s/iter; left time: 241.8133s
Epoch: 20 cost time: 2.9276857376098633
Epoch: 20, Steps: 128 Train Loss: 3.2649 (Forecasting Loss:0.2313 + XiCon Loss:3.0336 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13131721317768097, mae:0.2794959843158722, mape:0.6617631912231445, mspe:19.582801818847656 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1344+-0.00424, MAE:0.2833+-0.00461, MAPE:0.6750+-0.01556, MSPE:20.4508+-1.75150, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4541
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4628053
	speed: 0.0385s/iter; left time: 450.2872s
Epoch: 1 cost time: 4.468477964401245
Epoch: 1, Steps: 118 Train Loss: 3.5028 (Forecasting Loss:0.4160 + XiCon Loss:3.0868 x Lambda(1.0)), Vali MSE Loss: 0.4398 Test MSE Loss: 0.3380
Validation loss decreased (inf --> 0.439757).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3043718
	speed: 0.0436s/iter; left time: 505.4996s
Epoch: 2 cost time: 5.216773271560669
Epoch: 2, Steps: 118 Train Loss: 3.2970 (Forecasting Loss:0.3609 + XiCon Loss:2.9361 x Lambda(1.0)), Vali MSE Loss: 0.3692 Test MSE Loss: 0.2739
Validation loss decreased (0.439757 --> 0.369161).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2456956
	speed: 0.0411s/iter; left time: 471.7120s
Epoch: 3 cost time: 4.712685585021973
Epoch: 3, Steps: 118 Train Loss: 3.3288 (Forecasting Loss:0.3109 + XiCon Loss:3.0179 x Lambda(1.0)), Vali MSE Loss: 0.3531 Test MSE Loss: 0.2740
Validation loss decreased (0.369161 --> 0.353146).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2277205
	speed: 0.0432s/iter; left time: 489.8724s
Epoch: 4 cost time: 5.101819038391113
Epoch: 4, Steps: 118 Train Loss: 3.2363 (Forecasting Loss:0.2990 + XiCon Loss:2.9372 x Lambda(1.0)), Vali MSE Loss: 0.3644 Test MSE Loss: 0.2682
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1777973
	speed: 0.0429s/iter; left time: 481.4051s
Epoch: 5 cost time: 5.028151273727417
Epoch: 5, Steps: 118 Train Loss: 3.1997 (Forecasting Loss:0.2888 + XiCon Loss:2.9109 x Lambda(1.0)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.2619
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1441174
	speed: 0.0417s/iter; left time: 463.7067s
Epoch: 6 cost time: 4.950805187225342
Epoch: 6, Steps: 118 Train Loss: 3.1896 (Forecasting Loss:0.2834 + XiCon Loss:2.9061 x Lambda(1.0)), Vali MSE Loss: 0.3461 Test MSE Loss: 0.2619
Validation loss decreased (0.353146 --> 0.346055).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2309115
	speed: 0.0410s/iter; left time: 450.8796s
Epoch: 7 cost time: 4.885778188705444
Epoch: 7, Steps: 118 Train Loss: 3.1816 (Forecasting Loss:0.2809 + XiCon Loss:2.9007 x Lambda(1.0)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2635
Validation loss decreased (0.346055 --> 0.338623).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1120775
	speed: 0.0429s/iter; left time: 467.0249s
Epoch: 8 cost time: 5.016119718551636
Epoch: 8, Steps: 118 Train Loss: 3.1730 (Forecasting Loss:0.2809 + XiCon Loss:2.8920 x Lambda(1.0)), Vali MSE Loss: 0.3389 Test MSE Loss: 0.2614
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1359675
	speed: 0.0434s/iter; left time: 466.7852s
Epoch: 9 cost time: 5.07233190536499
Epoch: 9, Steps: 118 Train Loss: 3.1764 (Forecasting Loss:0.2788 + XiCon Loss:2.8976 x Lambda(1.0)), Vali MSE Loss: 0.3401 Test MSE Loss: 0.2608
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1744146
	speed: 0.0477s/iter; left time: 507.1928s
Epoch: 10 cost time: 5.630701780319214
Epoch: 10, Steps: 118 Train Loss: 3.1721 (Forecasting Loss:0.2775 + XiCon Loss:2.8946 x Lambda(1.0)), Vali MSE Loss: 0.3397 Test MSE Loss: 0.2601
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1137424
	speed: 0.0474s/iter; left time: 498.8672s
Epoch: 11 cost time: 5.564012289047241
Epoch: 11, Steps: 118 Train Loss: 3.1741 (Forecasting Loss:0.2782 + XiCon Loss:2.8958 x Lambda(1.0)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2605
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1350513
	speed: 0.0425s/iter; left time: 442.0456s
Epoch: 12 cost time: 5.0952229499816895
Epoch: 12, Steps: 118 Train Loss: 3.1743 (Forecasting Loss:0.2782 + XiCon Loss:2.8961 x Lambda(1.0)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2610
Validation loss decreased (0.338623 --> 0.338574).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1604695
	speed: 0.0401s/iter; left time: 412.0560s
Epoch: 13 cost time: 4.747921466827393
Epoch: 13, Steps: 118 Train Loss: 3.1709 (Forecasting Loss:0.2785 + XiCon Loss:2.8924 x Lambda(1.0)), Vali MSE Loss: 0.3394 Test MSE Loss: 0.2609
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1667202
	speed: 0.0426s/iter; left time: 433.2664s
Epoch: 14 cost time: 4.947801351547241
Epoch: 14, Steps: 118 Train Loss: 3.1822 (Forecasting Loss:0.2780 + XiCon Loss:2.9042 x Lambda(1.0)), Vali MSE Loss: 0.3392 Test MSE Loss: 0.2609
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2387049
	speed: 0.0435s/iter; left time: 437.1569s
Epoch: 15 cost time: 5.0462000370025635
Epoch: 15, Steps: 118 Train Loss: 3.1642 (Forecasting Loss:0.2783 + XiCon Loss:2.8859 x Lambda(1.0)), Vali MSE Loss: 0.3392 Test MSE Loss: 0.2609
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1571686
	speed: 0.0439s/iter; left time: 436.4343s
Epoch: 16 cost time: 5.0320916175842285
Epoch: 16, Steps: 118 Train Loss: 3.1768 (Forecasting Loss:0.2776 + XiCon Loss:2.8992 x Lambda(1.0)), Vali MSE Loss: 0.3394 Test MSE Loss: 0.2609
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1201334
	speed: 0.0462s/iter; left time: 453.1963s
Epoch: 17 cost time: 5.404247999191284
Epoch: 17, Steps: 118 Train Loss: 3.1726 (Forecasting Loss:0.2780 + XiCon Loss:2.8946 x Lambda(1.0)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.2609
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1396949
	speed: 0.0436s/iter; left time: 422.8438s
Epoch: 18 cost time: 5.226545333862305
Epoch: 18, Steps: 118 Train Loss: 3.1747 (Forecasting Loss:0.2774 + XiCon Loss:2.8973 x Lambda(1.0)), Vali MSE Loss: 0.3395 Test MSE Loss: 0.2609
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1941521
	speed: 0.0464s/iter; left time: 444.3150s
Epoch: 19 cost time: 5.2483556270599365
Epoch: 19, Steps: 118 Train Loss: 3.1755 (Forecasting Loss:0.2780 + XiCon Loss:2.8976 x Lambda(1.0)), Vali MSE Loss: 0.3398 Test MSE Loss: 0.2609
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1911101
	speed: 0.0413s/iter; left time: 390.5023s
Epoch: 20 cost time: 4.895895004272461
Epoch: 20, Steps: 118 Train Loss: 3.1714 (Forecasting Loss:0.2782 + XiCon Loss:2.8933 x Lambda(1.0)), Vali MSE Loss: 0.3396 Test MSE Loss: 0.2609
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0997906
	speed: 0.0439s/iter; left time: 409.6917s
Epoch: 21 cost time: 5.12634539604187
Epoch: 21, Steps: 118 Train Loss: 3.1727 (Forecasting Loss:0.2780 + XiCon Loss:2.8947 x Lambda(1.0)), Vali MSE Loss: 0.3404 Test MSE Loss: 0.2609
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2315378
	speed: 0.0417s/iter; left time: 384.8922s
Epoch: 22 cost time: 4.927048444747925
Epoch: 22, Steps: 118 Train Loss: 3.1764 (Forecasting Loss:0.2783 + XiCon Loss:2.8981 x Lambda(1.0)), Vali MSE Loss: 0.3410 Test MSE Loss: 0.2609
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17860454320907593, mae:0.3434167802333832, mape:0.6509961485862732, mspe:17.88204002380371 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4178
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.3990862
	speed: 0.0344s/iter; left time: 402.4937s
Epoch: 1 cost time: 4.0254011154174805
Epoch: 1, Steps: 118 Train Loss: 3.4727 (Forecasting Loss:0.4026 + XiCon Loss:3.0701 x Lambda(1.0)), Vali MSE Loss: 0.4186 Test MSE Loss: 0.3005
Validation loss decreased (inf --> 0.418624).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1994021
	speed: 0.0359s/iter; left time: 416.1477s
Epoch: 2 cost time: 4.200425386428833
Epoch: 2, Steps: 118 Train Loss: 3.2604 (Forecasting Loss:0.3410 + XiCon Loss:2.9193 x Lambda(1.0)), Vali MSE Loss: 0.3710 Test MSE Loss: 0.3089
Validation loss decreased (0.418624 --> 0.370974).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2747884
	speed: 0.0379s/iter; left time: 434.0437s
Epoch: 3 cost time: 4.593206882476807
Epoch: 3, Steps: 118 Train Loss: 3.2444 (Forecasting Loss:0.3055 + XiCon Loss:2.9389 x Lambda(1.0)), Vali MSE Loss: 0.3549 Test MSE Loss: 0.2679
Validation loss decreased (0.370974 --> 0.354883).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1856914
	speed: 0.0343s/iter; left time: 388.8682s
Epoch: 4 cost time: 4.049764394760132
Epoch: 4, Steps: 118 Train Loss: 3.2473 (Forecasting Loss:0.2897 + XiCon Loss:2.9576 x Lambda(1.0)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2677
Validation loss decreased (0.354883 --> 0.317869).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2014310
	speed: 0.0362s/iter; left time: 406.0344s
Epoch: 5 cost time: 4.247002601623535
Epoch: 5, Steps: 118 Train Loss: 3.2216 (Forecasting Loss:0.2805 + XiCon Loss:2.9411 x Lambda(1.0)), Vali MSE Loss: 0.2956 Test MSE Loss: 0.2622
Validation loss decreased (0.317869 --> 0.295615).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2292750
	speed: 0.0364s/iter; left time: 403.9863s
Epoch: 6 cost time: 4.289000988006592
Epoch: 6, Steps: 118 Train Loss: 3.2094 (Forecasting Loss:0.2752 + XiCon Loss:2.9342 x Lambda(1.0)), Vali MSE Loss: 0.2878 Test MSE Loss: 0.2647
Validation loss decreased (0.295615 --> 0.287807).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1477275
	speed: 0.0353s/iter; left time: 388.5279s
Epoch: 7 cost time: 4.1975648403167725
Epoch: 7, Steps: 118 Train Loss: 3.2029 (Forecasting Loss:0.2725 + XiCon Loss:2.9304 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2624
Validation loss decreased (0.287807 --> 0.285151).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1245060
	speed: 0.0335s/iter; left time: 364.0766s
Epoch: 8 cost time: 3.950610876083374
Epoch: 8, Steps: 118 Train Loss: 3.1954 (Forecasting Loss:0.2711 + XiCon Loss:2.9243 x Lambda(1.0)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2607
Validation loss decreased (0.285151 --> 0.283656).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2301121
	speed: 0.0371s/iter; left time: 398.9417s
Epoch: 9 cost time: 4.317822456359863
Epoch: 9, Steps: 118 Train Loss: 3.1896 (Forecasting Loss:0.2704 + XiCon Loss:2.9192 x Lambda(1.0)), Vali MSE Loss: 0.2854 Test MSE Loss: 0.2597
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1729264
	speed: 0.0363s/iter; left time: 386.0214s
Epoch: 10 cost time: 4.255386114120483
Epoch: 10, Steps: 118 Train Loss: 3.1952 (Forecasting Loss:0.2694 + XiCon Loss:2.9258 x Lambda(1.0)), Vali MSE Loss: 0.2835 Test MSE Loss: 0.2612
Validation loss decreased (0.283656 --> 0.283504).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1838500
	speed: 0.0370s/iter; left time: 389.0493s
Epoch: 11 cost time: 4.191413640975952
Epoch: 11, Steps: 118 Train Loss: 3.1915 (Forecasting Loss:0.2696 + XiCon Loss:2.9219 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2608
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2001159
	speed: 0.0344s/iter; left time: 358.3450s
Epoch: 12 cost time: 4.0645225048065186
Epoch: 12, Steps: 118 Train Loss: 3.1943 (Forecasting Loss:0.2693 + XiCon Loss:2.9250 x Lambda(1.0)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.2601
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2592351
	speed: 0.0359s/iter; left time: 368.7496s
Epoch: 13 cost time: 4.2370359897613525
Epoch: 13, Steps: 118 Train Loss: 3.1969 (Forecasting Loss:0.2694 + XiCon Loss:2.9275 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2601
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1389384
	speed: 0.0365s/iter; left time: 371.1004s
Epoch: 14 cost time: 4.273903131484985
Epoch: 14, Steps: 118 Train Loss: 3.1903 (Forecasting Loss:0.2695 + XiCon Loss:2.9208 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2601
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2628639
	speed: 0.0365s/iter; left time: 366.5048s
Epoch: 15 cost time: 4.184928894042969
Epoch: 15, Steps: 118 Train Loss: 3.1898 (Forecasting Loss:0.2695 + XiCon Loss:2.9203 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2601
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1676567
	speed: 0.0379s/iter; left time: 376.8582s
Epoch: 16 cost time: 4.477163553237915
Epoch: 16, Steps: 118 Train Loss: 3.1920 (Forecasting Loss:0.2694 + XiCon Loss:2.9226 x Lambda(1.0)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.2601
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1577411
	speed: 0.0368s/iter; left time: 360.7447s
Epoch: 17 cost time: 4.2906975746154785
Epoch: 17, Steps: 118 Train Loss: 3.1957 (Forecasting Loss:0.2693 + XiCon Loss:2.9264 x Lambda(1.0)), Vali MSE Loss: 0.2834 Test MSE Loss: 0.2601
Validation loss decreased (0.283504 --> 0.283368).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2084174
	speed: 0.0345s/iter; left time: 334.8111s
Epoch: 18 cost time: 4.0750627517700195
Epoch: 18, Steps: 118 Train Loss: 3.2025 (Forecasting Loss:0.2698 + XiCon Loss:2.9328 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2601
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2463348
	speed: 0.0331s/iter; left time: 316.6633s
Epoch: 19 cost time: 3.8847174644470215
Epoch: 19, Steps: 118 Train Loss: 3.1879 (Forecasting Loss:0.2697 + XiCon Loss:2.9182 x Lambda(1.0)), Vali MSE Loss: 0.2835 Test MSE Loss: 0.2601
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1563921
	speed: 0.0353s/iter; left time: 333.6495s
Epoch: 20 cost time: 4.130934715270996
Epoch: 20, Steps: 118 Train Loss: 3.1892 (Forecasting Loss:0.2697 + XiCon Loss:2.9194 x Lambda(1.0)), Vali MSE Loss: 0.2831 Test MSE Loss: 0.2601
Validation loss decreased (0.283368 --> 0.283138).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1910388
	speed: 0.0369s/iter; left time: 344.7208s
Epoch: 21 cost time: 4.31184720993042
Epoch: 21, Steps: 118 Train Loss: 3.1889 (Forecasting Loss:0.2695 + XiCon Loss:2.9194 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2601
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2914817
	speed: 0.0359s/iter; left time: 331.4862s
Epoch: 22 cost time: 4.266434192657471
Epoch: 22, Steps: 118 Train Loss: 3.1887 (Forecasting Loss:0.2696 + XiCon Loss:2.9192 x Lambda(1.0)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.2601
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2213869
	speed: 0.0343s/iter; left time: 312.1834s
Epoch: 23 cost time: 4.080941438674927
Epoch: 23, Steps: 118 Train Loss: 3.1899 (Forecasting Loss:0.2694 + XiCon Loss:2.9204 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2601
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1464815
	speed: 0.0349s/iter; left time: 314.0083s
Epoch: 24 cost time: 4.140674352645874
Epoch: 24, Steps: 118 Train Loss: 3.1921 (Forecasting Loss:0.2695 + XiCon Loss:2.9226 x Lambda(1.0)), Vali MSE Loss: 0.2840 Test MSE Loss: 0.2601
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1597314
	speed: 0.0357s/iter; left time: 316.5132s
Epoch: 25 cost time: 4.204256296157837
Epoch: 25, Steps: 118 Train Loss: 3.1926 (Forecasting Loss:0.2696 + XiCon Loss:2.9230 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2601
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1266518
	speed: 0.0349s/iter; left time: 305.2228s
Epoch: 26 cost time: 4.095228672027588
Epoch: 26, Steps: 118 Train Loss: 3.1916 (Forecasting Loss:0.2695 + XiCon Loss:2.9221 x Lambda(1.0)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2601
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.2628241
	speed: 0.0372s/iter; left time: 321.0071s
Epoch: 27 cost time: 4.347212314605713
Epoch: 27, Steps: 118 Train Loss: 3.1915 (Forecasting Loss:0.2693 + XiCon Loss:2.9223 x Lambda(1.0)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.2601
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2041183
	speed: 0.0358s/iter; left time: 305.0260s
Epoch: 28 cost time: 4.17546010017395
Epoch: 28, Steps: 118 Train Loss: 3.1963 (Forecasting Loss:0.2695 + XiCon Loss:2.9269 x Lambda(1.0)), Vali MSE Loss: 0.2830 Test MSE Loss: 0.2601
Validation loss decreased (0.283138 --> 0.282968).  Saving model ...
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1710439
	speed: 0.0358s/iter; left time: 300.3803s
Epoch: 29 cost time: 4.313746213912964
Epoch: 29, Steps: 118 Train Loss: 3.1917 (Forecasting Loss:0.2700 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2601
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.1557989
	speed: 0.0343s/iter; left time: 284.3381s
Epoch: 30 cost time: 4.001432657241821
Epoch: 30, Steps: 118 Train Loss: 3.1878 (Forecasting Loss:0.2690 + XiCon Loss:2.9188 x Lambda(1.0)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.2601
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.2017300
	speed: 0.0360s/iter; left time: 293.8477s
Epoch: 31 cost time: 4.219325304031372
Epoch: 31, Steps: 118 Train Loss: 3.1917 (Forecasting Loss:0.2697 + XiCon Loss:2.9220 x Lambda(1.0)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2601
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.1873057
	speed: 0.0356s/iter; left time: 286.2899s
Epoch: 32 cost time: 4.1777660846710205
Epoch: 32, Steps: 118 Train Loss: 3.1899 (Forecasting Loss:0.2695 + XiCon Loss:2.9204 x Lambda(1.0)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2601
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.1637127
	speed: 0.0374s/iter; left time: 296.7786s
Epoch: 33 cost time: 4.3886754512786865
Epoch: 33, Steps: 118 Train Loss: 3.1964 (Forecasting Loss:0.2698 + XiCon Loss:2.9266 x Lambda(1.0)), Vali MSE Loss: 0.2832 Test MSE Loss: 0.2601
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.2828808
	speed: 0.0336s/iter; left time: 262.1907s
Epoch: 34 cost time: 3.9997522830963135
Epoch: 34, Steps: 118 Train Loss: 3.1943 (Forecasting Loss:0.2694 + XiCon Loss:2.9249 x Lambda(1.0)), Vali MSE Loss: 0.2835 Test MSE Loss: 0.2601
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 3.2109673
	speed: 0.0368s/iter; left time: 282.6306s
Epoch: 35 cost time: 4.288569211959839
Epoch: 35, Steps: 118 Train Loss: 3.1884 (Forecasting Loss:0.2696 + XiCon Loss:2.9188 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2601
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 3.3228517
	speed: 0.0348s/iter; left time: 263.5424s
Epoch: 36 cost time: 4.079569101333618
Epoch: 36, Steps: 118 Train Loss: 3.1955 (Forecasting Loss:0.2696 + XiCon Loss:2.9259 x Lambda(1.0)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.2601
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 3.1534624
	speed: 0.0351s/iter; left time: 261.4982s
Epoch: 37 cost time: 4.138438940048218
Epoch: 37, Steps: 118 Train Loss: 3.1903 (Forecasting Loss:0.2693 + XiCon Loss:2.9209 x Lambda(1.0)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.2601
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 3.1566436
	speed: 0.0351s/iter; left time: 257.2896s
Epoch: 38 cost time: 4.167826175689697
Epoch: 38, Steps: 118 Train Loss: 3.1915 (Forecasting Loss:0.2695 + XiCon Loss:2.9220 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2601
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17793405055999756, mae:0.34230026602745056, mape:0.6725330948829651, mspe:20.848133087158203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3673
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4533601
	speed: 0.0361s/iter; left time: 422.5735s
Epoch: 1 cost time: 4.2017412185668945
Epoch: 1, Steps: 118 Train Loss: 3.4901 (Forecasting Loss:0.4100 + XiCon Loss:3.0801 x Lambda(1.0)), Vali MSE Loss: 0.4260 Test MSE Loss: 0.3186
Validation loss decreased (inf --> 0.426037).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2343845
	speed: 0.0463s/iter; left time: 536.6239s
Epoch: 2 cost time: 5.393106937408447
Epoch: 2, Steps: 118 Train Loss: 3.3047 (Forecasting Loss:0.3875 + XiCon Loss:2.9172 x Lambda(1.0)), Vali MSE Loss: 0.4305 Test MSE Loss: 0.3304
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4160519
	speed: 0.0385s/iter; left time: 441.1118s
Epoch: 3 cost time: 4.360219240188599
Epoch: 3, Steps: 118 Train Loss: 3.3500 (Forecasting Loss:0.3729 + XiCon Loss:2.9771 x Lambda(1.0)), Vali MSE Loss: 0.4132 Test MSE Loss: 0.3115
Validation loss decreased (0.426037 --> 0.413241).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3758259
	speed: 0.0460s/iter; left time: 522.0504s
Epoch: 4 cost time: 6.305441856384277
Epoch: 4, Steps: 118 Train Loss: 3.4112 (Forecasting Loss:0.3664 + XiCon Loss:3.0448 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3069
Validation loss decreased (0.413241 --> 0.409041).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4772305
	speed: 0.0359s/iter; left time: 403.1222s
Epoch: 5 cost time: 4.102370500564575
Epoch: 5, Steps: 118 Train Loss: 3.4283 (Forecasting Loss:0.3617 + XiCon Loss:3.0666 x Lambda(1.0)), Vali MSE Loss: 0.4102 Test MSE Loss: 0.3055
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4398472
	speed: 0.0269s/iter; left time: 298.7626s
Epoch: 6 cost time: 3.1638259887695312
Epoch: 6, Steps: 118 Train Loss: 3.4245 (Forecasting Loss:0.3601 + XiCon Loss:3.0645 x Lambda(1.0)), Vali MSE Loss: 0.4109 Test MSE Loss: 0.3049
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2956409
	speed: 0.0432s/iter; left time: 475.0874s
Epoch: 7 cost time: 5.186184406280518
Epoch: 7, Steps: 118 Train Loss: 3.4255 (Forecasting Loss:0.3587 + XiCon Loss:3.0667 x Lambda(1.0)), Vali MSE Loss: 0.4087 Test MSE Loss: 0.3051
Validation loss decreased (0.409041 --> 0.408665).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3174338
	speed: 0.0519s/iter; left time: 564.3513s
Epoch: 8 cost time: 6.119133472442627
Epoch: 8, Steps: 118 Train Loss: 3.4129 (Forecasting Loss:0.3582 + XiCon Loss:3.0547 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3044
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4138832
	speed: 0.0513s/iter; left time: 552.1506s
Epoch: 9 cost time: 6.009063482284546
Epoch: 9, Steps: 118 Train Loss: 3.4185 (Forecasting Loss:0.3587 + XiCon Loss:3.0598 x Lambda(1.0)), Vali MSE Loss: 0.4086 Test MSE Loss: 0.3043
Validation loss decreased (0.408665 --> 0.408609).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3330724
	speed: 0.0505s/iter; left time: 537.7453s
Epoch: 10 cost time: 5.9735188484191895
Epoch: 10, Steps: 118 Train Loss: 3.4306 (Forecasting Loss:0.3576 + XiCon Loss:3.0730 x Lambda(1.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3043
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3082647
	speed: 0.0448s/iter; left time: 471.4414s
Epoch: 11 cost time: 5.4199934005737305
Epoch: 11, Steps: 118 Train Loss: 3.4326 (Forecasting Loss:0.3578 + XiCon Loss:3.0748 x Lambda(1.0)), Vali MSE Loss: 0.4094 Test MSE Loss: 0.3041
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.5070562
	speed: 0.0497s/iter; left time: 516.6124s
Epoch: 12 cost time: 5.905439853668213
Epoch: 12, Steps: 118 Train Loss: 3.4434 (Forecasting Loss:0.3573 + XiCon Loss:3.0861 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3040
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3783398
	speed: 0.0514s/iter; left time: 528.9204s
Epoch: 13 cost time: 6.0423173904418945
Epoch: 13, Steps: 118 Train Loss: 3.4362 (Forecasting Loss:0.3577 + XiCon Loss:3.0785 x Lambda(1.0)), Vali MSE Loss: 0.4086 Test MSE Loss: 0.3041
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4967742
	speed: 0.0536s/iter; left time: 544.8750s
Epoch: 14 cost time: 6.167375564575195
Epoch: 14, Steps: 118 Train Loss: 3.4266 (Forecasting Loss:0.3575 + XiCon Loss:3.0691 x Lambda(1.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3040
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4201705
	speed: 0.0409s/iter; left time: 411.5006s
Epoch: 15 cost time: 4.556811571121216
Epoch: 15, Steps: 118 Train Loss: 3.4350 (Forecasting Loss:0.3574 + XiCon Loss:3.0776 x Lambda(1.0)), Vali MSE Loss: 0.4088 Test MSE Loss: 0.3040
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4178307
	speed: 0.0456s/iter; left time: 453.3105s
Epoch: 16 cost time: 5.482544183731079
Epoch: 16, Steps: 118 Train Loss: 3.4310 (Forecasting Loss:0.3576 + XiCon Loss:3.0734 x Lambda(1.0)), Vali MSE Loss: 0.4083 Test MSE Loss: 0.3040
Validation loss decreased (0.408609 --> 0.408322).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3556025
	speed: 0.0522s/iter; left time: 512.0344s
Epoch: 17 cost time: 6.1498191356658936
Epoch: 17, Steps: 118 Train Loss: 3.4259 (Forecasting Loss:0.3576 + XiCon Loss:3.0683 x Lambda(1.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3040
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4225934
	speed: 0.0537s/iter; left time: 520.2816s
Epoch: 18 cost time: 6.294102430343628
Epoch: 18, Steps: 118 Train Loss: 3.4261 (Forecasting Loss:0.3578 + XiCon Loss:3.0683 x Lambda(1.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3040
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.6366792
	speed: 0.0491s/iter; left time: 470.2858s
Epoch: 19 cost time: 5.855816125869751
Epoch: 19, Steps: 118 Train Loss: 3.4498 (Forecasting Loss:0.3575 + XiCon Loss:3.0924 x Lambda(1.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3040
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.5101120
	speed: 0.0323s/iter; left time: 305.1874s
Epoch: 20 cost time: 3.7120304107666016
Epoch: 20, Steps: 118 Train Loss: 3.4367 (Forecasting Loss:0.3576 + XiCon Loss:3.0791 x Lambda(1.0)), Vali MSE Loss: 0.4085 Test MSE Loss: 0.3040
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3479028
	speed: 0.0523s/iter; left time: 488.7913s
Epoch: 21 cost time: 6.169706344604492
Epoch: 21, Steps: 118 Train Loss: 3.4257 (Forecasting Loss:0.3575 + XiCon Loss:3.0682 x Lambda(1.0)), Vali MSE Loss: 0.4081 Test MSE Loss: 0.3040
Validation loss decreased (0.408322 --> 0.408062).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3060684
	speed: 0.0529s/iter; left time: 487.5328s
Epoch: 22 cost time: 6.173545837402344
Epoch: 22, Steps: 118 Train Loss: 3.4303 (Forecasting Loss:0.3578 + XiCon Loss:3.0724 x Lambda(1.0)), Vali MSE Loss: 0.4090 Test MSE Loss: 0.3040
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.5033412
	speed: 0.0528s/iter; left time: 480.8626s
Epoch: 23 cost time: 6.242188215255737
Epoch: 23, Steps: 118 Train Loss: 3.4517 (Forecasting Loss:0.3576 + XiCon Loss:3.0941 x Lambda(1.0)), Vali MSE Loss: 0.4096 Test MSE Loss: 0.3040
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3254344
	speed: 0.0498s/iter; left time: 447.3841s
Epoch: 24 cost time: 5.71471381187439
Epoch: 24, Steps: 118 Train Loss: 3.4302 (Forecasting Loss:0.3579 + XiCon Loss:3.0722 x Lambda(1.0)), Vali MSE Loss: 0.4089 Test MSE Loss: 0.3040
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4374247
	speed: 0.0266s/iter; left time: 235.6233s
Epoch: 25 cost time: 3.139521837234497
Epoch: 25, Steps: 118 Train Loss: 3.4470 (Forecasting Loss:0.3576 + XiCon Loss:3.0894 x Lambda(1.0)), Vali MSE Loss: 0.4100 Test MSE Loss: 0.3040
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.4466901
	speed: 0.0535s/iter; left time: 468.2900s
Epoch: 26 cost time: 6.33828067779541
Epoch: 26, Steps: 118 Train Loss: 3.4274 (Forecasting Loss:0.3575 + XiCon Loss:3.0699 x Lambda(1.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3040
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3422329
	speed: 0.0520s/iter; left time: 448.8265s
Epoch: 27 cost time: 6.10538125038147
Epoch: 27, Steps: 118 Train Loss: 3.4346 (Forecasting Loss:0.3578 + XiCon Loss:3.0768 x Lambda(1.0)), Vali MSE Loss: 0.4086 Test MSE Loss: 0.3040
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.4037976
	speed: 0.0526s/iter; left time: 447.5261s
Epoch: 28 cost time: 6.159361839294434
Epoch: 28, Steps: 118 Train Loss: 3.4241 (Forecasting Loss:0.3576 + XiCon Loss:3.0666 x Lambda(1.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3040
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.2388656
	speed: 0.0472s/iter; left time: 396.1819s
Epoch: 29 cost time: 5.559768915176392
Epoch: 29, Steps: 118 Train Loss: 3.4231 (Forecasting Loss:0.3577 + XiCon Loss:3.0654 x Lambda(1.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3040
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.3872118
	speed: 0.0334s/iter; left time: 276.3319s
Epoch: 30 cost time: 4.271658182144165
Epoch: 30, Steps: 118 Train Loss: 3.4357 (Forecasting Loss:0.3577 + XiCon Loss:3.0780 x Lambda(1.0)), Vali MSE Loss: 0.4089 Test MSE Loss: 0.3040
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.5691166
	speed: 0.0528s/iter; left time: 431.1844s
Epoch: 31 cost time: 6.2456254959106445
Epoch: 31, Steps: 118 Train Loss: 3.4285 (Forecasting Loss:0.3578 + XiCon Loss:3.0708 x Lambda(1.0)), Vali MSE Loss: 0.4088 Test MSE Loss: 0.3040
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.22609031200408936, mae:0.3819573223590851, mape:0.641565203666687, mspe:14.574061393737793 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4572
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4643466
	speed: 0.0396s/iter; left time: 463.0528s
Epoch: 1 cost time: 4.69430136680603
Epoch: 1, Steps: 118 Train Loss: 3.5072 (Forecasting Loss:0.4108 + XiCon Loss:3.0964 x Lambda(1.0)), Vali MSE Loss: 0.4365 Test MSE Loss: 0.3291
Validation loss decreased (inf --> 0.436536).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3488479
	speed: 0.0513s/iter; left time: 593.9408s
Epoch: 2 cost time: 5.897140741348267
Epoch: 2, Steps: 118 Train Loss: 3.3321 (Forecasting Loss:0.3522 + XiCon Loss:2.9799 x Lambda(1.0)), Vali MSE Loss: 0.4457 Test MSE Loss: 0.2954
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2143912
	speed: 0.0469s/iter; left time: 538.2110s
Epoch: 3 cost time: 5.546221733093262
Epoch: 3, Steps: 118 Train Loss: 3.2617 (Forecasting Loss:0.3035 + XiCon Loss:2.9582 x Lambda(1.0)), Vali MSE Loss: 0.3559 Test MSE Loss: 0.2631
Validation loss decreased (0.436536 --> 0.355916).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2350209
	speed: 0.0493s/iter; left time: 559.6228s
Epoch: 4 cost time: 5.782870769500732
Epoch: 4, Steps: 118 Train Loss: 3.2311 (Forecasting Loss:0.2901 + XiCon Loss:2.9410 x Lambda(1.0)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.2568
Validation loss decreased (0.355916 --> 0.327036).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1935959
	speed: 0.0496s/iter; left time: 557.4452s
Epoch: 5 cost time: 5.813730478286743
Epoch: 5, Steps: 118 Train Loss: 3.2109 (Forecasting Loss:0.2813 + XiCon Loss:2.9296 x Lambda(1.0)), Vali MSE Loss: 0.3452 Test MSE Loss: 0.2555
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1336527
	speed: 0.0480s/iter; left time: 533.7457s
Epoch: 6 cost time: 5.4930548667907715
Epoch: 6, Steps: 118 Train Loss: 3.1992 (Forecasting Loss:0.2776 + XiCon Loss:2.9216 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2550
Validation loss decreased (0.327036 --> 0.321227).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1538937
	speed: 0.0429s/iter; left time: 471.6130s
Epoch: 7 cost time: 5.106096267700195
Epoch: 7, Steps: 118 Train Loss: 3.1935 (Forecasting Loss:0.2762 + XiCon Loss:2.9174 x Lambda(1.0)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.2539
Validation loss decreased (0.321227 --> 0.311175).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1484363
	speed: 0.0476s/iter; left time: 517.7983s
Epoch: 8 cost time: 5.612108469009399
Epoch: 8, Steps: 118 Train Loss: 3.1906 (Forecasting Loss:0.2741 + XiCon Loss:2.9165 x Lambda(1.0)), Vali MSE Loss: 0.3175 Test MSE Loss: 0.2539
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1290946
	speed: 0.0466s/iter; left time: 500.9383s
Epoch: 9 cost time: 5.448704242706299
Epoch: 9, Steps: 118 Train Loss: 3.1859 (Forecasting Loss:0.2739 + XiCon Loss:2.9121 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2537
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1933167
	speed: 0.0466s/iter; left time: 496.1777s
Epoch: 10 cost time: 5.51071310043335
Epoch: 10, Steps: 118 Train Loss: 3.1858 (Forecasting Loss:0.2740 + XiCon Loss:2.9119 x Lambda(1.0)), Vali MSE Loss: 0.3166 Test MSE Loss: 0.2536
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1576982
	speed: 0.0430s/iter; left time: 452.2587s
Epoch: 11 cost time: 4.951497793197632
Epoch: 11, Steps: 118 Train Loss: 3.1861 (Forecasting Loss:0.2739 + XiCon Loss:2.9122 x Lambda(1.0)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2536
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2415445
	speed: 0.0498s/iter; left time: 518.2708s
Epoch: 12 cost time: 5.910509824752808
Epoch: 12, Steps: 118 Train Loss: 3.1843 (Forecasting Loss:0.2740 + XiCon Loss:2.9103 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2536
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1272421
	speed: 0.0489s/iter; left time: 502.8408s
Epoch: 13 cost time: 5.735714912414551
Epoch: 13, Steps: 118 Train Loss: 3.1856 (Forecasting Loss:0.2731 + XiCon Loss:2.9125 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2536
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1963978
	speed: 0.0475s/iter; left time: 482.9918s
Epoch: 14 cost time: 5.641718626022339
Epoch: 14, Steps: 118 Train Loss: 3.1856 (Forecasting Loss:0.2730 + XiCon Loss:2.9126 x Lambda(1.0)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2536
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2117052
	speed: 0.0417s/iter; left time: 419.5050s
Epoch: 15 cost time: 5.036457538604736
Epoch: 15, Steps: 118 Train Loss: 3.1895 (Forecasting Loss:0.2732 + XiCon Loss:2.9162 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2536
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1786544
	speed: 0.0492s/iter; left time: 488.8956s
Epoch: 16 cost time: 5.771007061004639
Epoch: 16, Steps: 118 Train Loss: 3.1887 (Forecasting Loss:0.2733 + XiCon Loss:2.9154 x Lambda(1.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2536
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2647181
	speed: 0.0492s/iter; left time: 482.8445s
Epoch: 17 cost time: 5.764973878860474
Epoch: 17, Steps: 118 Train Loss: 3.1833 (Forecasting Loss:0.2734 + XiCon Loss:2.9100 x Lambda(1.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2536
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1713773012161255, mae:0.33638253808021545, mape:0.6477227807044983, mspe:19.98056411743164 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3357
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 3.4197631
	speed: 0.0425s/iter; left time: 497.8707s
Epoch: 1 cost time: 5.04157280921936
Epoch: 1, Steps: 118 Train Loss: 3.5036 (Forecasting Loss:0.4077 + XiCon Loss:3.0959 x Lambda(1.0)), Vali MSE Loss: 0.4321 Test MSE Loss: 0.3243
Validation loss decreased (inf --> 0.432087).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4507463
	speed: 0.0473s/iter; left time: 548.4447s
Epoch: 2 cost time: 5.628204584121704
Epoch: 2, Steps: 118 Train Loss: 3.3084 (Forecasting Loss:0.3624 + XiCon Loss:2.9460 x Lambda(1.0)), Vali MSE Loss: 0.3762 Test MSE Loss: 0.2744
Validation loss decreased (0.432087 --> 0.376201).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2024338
	speed: 0.0508s/iter; left time: 582.7965s
Epoch: 3 cost time: 5.987555265426636
Epoch: 3, Steps: 118 Train Loss: 3.2667 (Forecasting Loss:0.3148 + XiCon Loss:2.9519 x Lambda(1.0)), Vali MSE Loss: 0.3703 Test MSE Loss: 0.2660
Validation loss decreased (0.376201 --> 0.370311).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1573691
	speed: 0.0486s/iter; left time: 551.9494s
Epoch: 4 cost time: 5.773440837860107
Epoch: 4, Steps: 118 Train Loss: 3.2370 (Forecasting Loss:0.2978 + XiCon Loss:2.9392 x Lambda(1.0)), Vali MSE Loss: 0.3663 Test MSE Loss: 0.2560
Validation loss decreased (0.370311 --> 0.366264).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2109663
	speed: 0.0516s/iter; left time: 579.3024s
Epoch: 5 cost time: 5.986065626144409
Epoch: 5, Steps: 118 Train Loss: 3.1882 (Forecasting Loss:0.2899 + XiCon Loss:2.8983 x Lambda(1.0)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.2554
Validation loss decreased (0.366264 --> 0.360038).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2229650
	speed: 0.0480s/iter; left time: 533.5726s
Epoch: 6 cost time: 5.567816734313965
Epoch: 6, Steps: 118 Train Loss: 3.1828 (Forecasting Loss:0.2865 + XiCon Loss:2.8964 x Lambda(1.0)), Vali MSE Loss: 0.3609 Test MSE Loss: 0.2620
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2324226
	speed: 0.0502s/iter; left time: 551.7642s
Epoch: 7 cost time: 5.856821775436401
Epoch: 7, Steps: 118 Train Loss: 3.1859 (Forecasting Loss:0.2837 + XiCon Loss:2.9022 x Lambda(1.0)), Vali MSE Loss: 0.3601 Test MSE Loss: 0.2561
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2845688
	speed: 0.0513s/iter; left time: 558.1586s
Epoch: 8 cost time: 6.000396251678467
Epoch: 8, Steps: 118 Train Loss: 3.1813 (Forecasting Loss:0.2834 + XiCon Loss:2.8979 x Lambda(1.0)), Vali MSE Loss: 0.3572 Test MSE Loss: 0.2562
Validation loss decreased (0.360038 --> 0.357166).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2477336
	speed: 0.0493s/iter; left time: 530.4421s
Epoch: 9 cost time: 5.914886474609375
Epoch: 9, Steps: 118 Train Loss: 3.1715 (Forecasting Loss:0.2826 + XiCon Loss:2.8889 x Lambda(1.0)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.2545
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1093440
	speed: 0.0497s/iter; left time: 528.7745s
Epoch: 10 cost time: 6.008734941482544
Epoch: 10, Steps: 118 Train Loss: 3.1730 (Forecasting Loss:0.2826 + XiCon Loss:2.8903 x Lambda(1.0)), Vali MSE Loss: 0.3591 Test MSE Loss: 0.2552
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1897037
	speed: 0.0485s/iter; left time: 509.8182s
Epoch: 11 cost time: 5.764960527420044
Epoch: 11, Steps: 118 Train Loss: 3.1715 (Forecasting Loss:0.2824 + XiCon Loss:2.8890 x Lambda(1.0)), Vali MSE Loss: 0.3579 Test MSE Loss: 0.2550
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1219177
	speed: 0.0523s/iter; left time: 544.1311s
Epoch: 12 cost time: 6.143071889877319
Epoch: 12, Steps: 118 Train Loss: 3.1719 (Forecasting Loss:0.2820 + XiCon Loss:2.8899 x Lambda(1.0)), Vali MSE Loss: 0.3578 Test MSE Loss: 0.2552
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1413486
	speed: 0.0500s/iter; left time: 514.0339s
Epoch: 13 cost time: 5.9826719760894775
Epoch: 13, Steps: 118 Train Loss: 3.1783 (Forecasting Loss:0.2824 + XiCon Loss:2.8959 x Lambda(1.0)), Vali MSE Loss: 0.3585 Test MSE Loss: 0.2552
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1905267
	speed: 0.0502s/iter; left time: 510.8601s
Epoch: 14 cost time: 5.935864210128784
Epoch: 14, Steps: 118 Train Loss: 3.1800 (Forecasting Loss:0.2826 + XiCon Loss:2.8974 x Lambda(1.0)), Vali MSE Loss: 0.3570 Test MSE Loss: 0.2552
Validation loss decreased (0.357166 --> 0.356968).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1815727
	speed: 0.0491s/iter; left time: 493.2770s
Epoch: 15 cost time: 5.802589178085327
Epoch: 15, Steps: 118 Train Loss: 3.1709 (Forecasting Loss:0.2822 + XiCon Loss:2.8887 x Lambda(1.0)), Vali MSE Loss: 0.3569 Test MSE Loss: 0.2552
Validation loss decreased (0.356968 --> 0.356877).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1738577
	speed: 0.0534s/iter; left time: 530.5366s
Epoch: 16 cost time: 6.216136932373047
Epoch: 16, Steps: 118 Train Loss: 3.1737 (Forecasting Loss:0.2820 + XiCon Loss:2.8918 x Lambda(1.0)), Vali MSE Loss: 0.3583 Test MSE Loss: 0.2551
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1901169
	speed: 0.0485s/iter; left time: 475.7953s
Epoch: 17 cost time: 5.765752553939819
Epoch: 17, Steps: 118 Train Loss: 3.1763 (Forecasting Loss:0.2819 + XiCon Loss:2.8945 x Lambda(1.0)), Vali MSE Loss: 0.3590 Test MSE Loss: 0.2551
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2228570
	speed: 0.0494s/iter; left time: 478.7267s
Epoch: 18 cost time: 5.824863910675049
Epoch: 18, Steps: 118 Train Loss: 3.1659 (Forecasting Loss:0.2819 + XiCon Loss:2.8840 x Lambda(1.0)), Vali MSE Loss: 0.3584 Test MSE Loss: 0.2552
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2006793
	speed: 0.0484s/iter; left time: 463.9140s
Epoch: 19 cost time: 5.827013969421387
Epoch: 19, Steps: 118 Train Loss: 3.1730 (Forecasting Loss:0.2823 + XiCon Loss:2.8907 x Lambda(1.0)), Vali MSE Loss: 0.3581 Test MSE Loss: 0.2552
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2649601
	speed: 0.0502s/iter; left time: 475.2625s
Epoch: 20 cost time: 5.813997268676758
Epoch: 20, Steps: 118 Train Loss: 3.1747 (Forecasting Loss:0.2819 + XiCon Loss:2.8927 x Lambda(1.0)), Vali MSE Loss: 0.3572 Test MSE Loss: 0.2552
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2938383
	speed: 0.0535s/iter; left time: 499.9179s
Epoch: 21 cost time: 6.266976833343506
Epoch: 21, Steps: 118 Train Loss: 3.1798 (Forecasting Loss:0.2822 + XiCon Loss:2.8976 x Lambda(1.0)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.2552
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1476054
	speed: 0.0499s/iter; left time: 460.4207s
Epoch: 22 cost time: 5.846357107162476
Epoch: 22, Steps: 118 Train Loss: 3.1771 (Forecasting Loss:0.2814 + XiCon Loss:2.8957 x Lambda(1.0)), Vali MSE Loss: 0.3582 Test MSE Loss: 0.2552
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1381814
	speed: 0.0444s/iter; left time: 404.2976s
Epoch: 23 cost time: 5.325907468795776
Epoch: 23, Steps: 118 Train Loss: 3.1788 (Forecasting Loss:0.2824 + XiCon Loss:2.8964 x Lambda(1.0)), Vali MSE Loss: 0.3576 Test MSE Loss: 0.2552
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1489646
	speed: 0.0501s/iter; left time: 449.8712s
Epoch: 24 cost time: 6.020220518112183
Epoch: 24, Steps: 118 Train Loss: 3.1677 (Forecasting Loss:0.2821 + XiCon Loss:2.8856 x Lambda(1.0)), Vali MSE Loss: 0.3584 Test MSE Loss: 0.2552
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2220504
	speed: 0.0493s/iter; left time: 436.8554s
Epoch: 25 cost time: 5.770957708358765
Epoch: 25, Steps: 118 Train Loss: 3.1700 (Forecasting Loss:0.2827 + XiCon Loss:2.8873 x Lambda(1.0)), Vali MSE Loss: 0.3579 Test MSE Loss: 0.2552
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1733395904302597, mae:0.3370826840400696, mape:0.6334728598594666, mspe:17.728622436523438 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1855+-0.02845, MAE:0.3482+-0.02373, MAPE:0.6493+-0.01816, MSPE:18.2027+-3.01942, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4341
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6724710
	speed: 0.0533s/iter; left time: 564.5232s
Epoch: 1 cost time: 5.611750841140747
Epoch: 1, Steps: 107 Train Loss: 3.7363 (Forecasting Loss:0.6386 + XiCon Loss:3.0977 x Lambda(1.0)), Vali MSE Loss: 0.6216 Test MSE Loss: 0.4990
Validation loss decreased (inf --> 0.621587).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1616135
	speed: 0.0713s/iter; left time: 748.4098s
Epoch: 2 cost time: 7.7271130084991455
Epoch: 2, Steps: 107 Train Loss: 3.3985 (Forecasting Loss:0.4905 + XiCon Loss:2.9080 x Lambda(1.0)), Vali MSE Loss: 0.4262 Test MSE Loss: 0.2882
Validation loss decreased (0.621587 --> 0.426195).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2724690
	speed: 0.0728s/iter; left time: 756.2223s
Epoch: 3 cost time: 7.8165318965911865
Epoch: 3, Steps: 107 Train Loss: 3.2603 (Forecasting Loss:0.3266 + XiCon Loss:2.9337 x Lambda(1.0)), Vali MSE Loss: 0.4285 Test MSE Loss: 0.2607
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2457447
	speed: 0.0714s/iter; left time: 734.2914s
Epoch: 4 cost time: 7.6194634437561035
Epoch: 4, Steps: 107 Train Loss: 3.2858 (Forecasting Loss:0.3046 + XiCon Loss:2.9812 x Lambda(1.0)), Vali MSE Loss: 0.4574 Test MSE Loss: 0.2530
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2944899
	speed: 0.0665s/iter; left time: 676.7976s
Epoch: 5 cost time: 7.167422294616699
Epoch: 5, Steps: 107 Train Loss: 3.2549 (Forecasting Loss:0.2957 + XiCon Loss:2.9592 x Lambda(1.0)), Vali MSE Loss: 0.4349 Test MSE Loss: 0.2596
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2172098
	speed: 0.0693s/iter; left time: 698.0462s
Epoch: 6 cost time: 7.428877830505371
Epoch: 6, Steps: 107 Train Loss: 3.2370 (Forecasting Loss:0.2873 + XiCon Loss:2.9498 x Lambda(1.0)), Vali MSE Loss: 0.4229 Test MSE Loss: 0.2621
Validation loss decreased (0.426195 --> 0.422943).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3018339
	speed: 0.0686s/iter; left time: 683.3552s
Epoch: 7 cost time: 7.455259084701538
Epoch: 7, Steps: 107 Train Loss: 3.2341 (Forecasting Loss:0.2839 + XiCon Loss:2.9502 x Lambda(1.0)), Vali MSE Loss: 0.3957 Test MSE Loss: 0.2606
Validation loss decreased (0.422943 --> 0.395687).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2061229
	speed: 0.0675s/iter; left time: 664.8712s
Epoch: 8 cost time: 7.303266763687134
Epoch: 8, Steps: 107 Train Loss: 3.2244 (Forecasting Loss:0.2816 + XiCon Loss:2.9428 x Lambda(1.0)), Vali MSE Loss: 0.3917 Test MSE Loss: 0.2513
Validation loss decreased (0.395687 --> 0.391695).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2417068
	speed: 0.0671s/iter; left time: 653.8964s
Epoch: 9 cost time: 7.220077991485596
Epoch: 9, Steps: 107 Train Loss: 3.2166 (Forecasting Loss:0.2812 + XiCon Loss:2.9354 x Lambda(1.0)), Vali MSE Loss: 0.3899 Test MSE Loss: 0.2581
Validation loss decreased (0.391695 --> 0.389944).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2751572
	speed: 0.0712s/iter; left time: 686.0906s
Epoch: 10 cost time: 7.700939655303955
Epoch: 10, Steps: 107 Train Loss: 3.2183 (Forecasting Loss:0.2797 + XiCon Loss:2.9387 x Lambda(1.0)), Vali MSE Loss: 0.3899 Test MSE Loss: 0.2553
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2516575
	speed: 0.0718s/iter; left time: 684.8003s
Epoch: 11 cost time: 7.684495687484741
Epoch: 11, Steps: 107 Train Loss: 3.2155 (Forecasting Loss:0.2797 + XiCon Loss:2.9358 x Lambda(1.0)), Vali MSE Loss: 0.3888 Test MSE Loss: 0.2538
Validation loss decreased (0.389944 --> 0.388771).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2664676
	speed: 0.0674s/iter; left time: 635.4297s
Epoch: 12 cost time: 7.311361789703369
Epoch: 12, Steps: 107 Train Loss: 3.2182 (Forecasting Loss:0.2793 + XiCon Loss:2.9388 x Lambda(1.0)), Vali MSE Loss: 0.3902 Test MSE Loss: 0.2539
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1884046
	speed: 0.0662s/iter; left time: 616.5830s
Epoch: 13 cost time: 7.198062419891357
Epoch: 13, Steps: 107 Train Loss: 3.2171 (Forecasting Loss:0.2793 + XiCon Loss:2.9378 x Lambda(1.0)), Vali MSE Loss: 0.3898 Test MSE Loss: 0.2540
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1868465
	speed: 0.0671s/iter; left time: 617.6513s
Epoch: 14 cost time: 7.201033592224121
Epoch: 14, Steps: 107 Train Loss: 3.2107 (Forecasting Loss:0.2791 + XiCon Loss:2.9316 x Lambda(1.0)), Vali MSE Loss: 0.3888 Test MSE Loss: 0.2542
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2164376
	speed: 0.0701s/iter; left time: 637.9524s
Epoch: 15 cost time: 7.514146566390991
Epoch: 15, Steps: 107 Train Loss: 3.2148 (Forecasting Loss:0.2800 + XiCon Loss:2.9348 x Lambda(1.0)), Vali MSE Loss: 0.3890 Test MSE Loss: 0.2539
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2463763
	speed: 0.0685s/iter; left time: 616.0343s
Epoch: 16 cost time: 7.42724084854126
Epoch: 16, Steps: 107 Train Loss: 3.2117 (Forecasting Loss:0.2793 + XiCon Loss:2.9324 x Lambda(1.0)), Vali MSE Loss: 0.3892 Test MSE Loss: 0.2539
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2223616
	speed: 0.0701s/iter; left time: 623.0392s
Epoch: 17 cost time: 7.633679151535034
Epoch: 17, Steps: 107 Train Loss: 3.2142 (Forecasting Loss:0.2799 + XiCon Loss:2.9343 x Lambda(1.0)), Vali MSE Loss: 0.3898 Test MSE Loss: 0.2539
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1920953
	speed: 0.0700s/iter; left time: 614.3759s
Epoch: 18 cost time: 7.484729766845703
Epoch: 18, Steps: 107 Train Loss: 3.2157 (Forecasting Loss:0.2799 + XiCon Loss:2.9359 x Lambda(1.0)), Vali MSE Loss: 0.3891 Test MSE Loss: 0.2539
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2127128
	speed: 0.0722s/iter; left time: 626.1155s
Epoch: 19 cost time: 7.6901702880859375
Epoch: 19, Steps: 107 Train Loss: 3.2190 (Forecasting Loss:0.2794 + XiCon Loss:2.9397 x Lambda(1.0)), Vali MSE Loss: 0.3890 Test MSE Loss: 0.2539
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1629822
	speed: 0.0651s/iter; left time: 557.9787s
Epoch: 20 cost time: 7.101028680801392
Epoch: 20, Steps: 107 Train Loss: 3.2179 (Forecasting Loss:0.2794 + XiCon Loss:2.9385 x Lambda(1.0)), Vali MSE Loss: 0.3899 Test MSE Loss: 0.2539
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2957070
	speed: 0.0703s/iter; left time: 594.4936s
Epoch: 21 cost time: 7.538059234619141
Epoch: 21, Steps: 107 Train Loss: 3.2149 (Forecasting Loss:0.2799 + XiCon Loss:2.9349 x Lambda(1.0)), Vali MSE Loss: 0.3892 Test MSE Loss: 0.2539
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17110899090766907, mae:0.33643004298210144, mape:0.5841162800788879, mspe:13.752954483032227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3644
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6151271
	speed: 0.0592s/iter; left time: 627.3329s
Epoch: 1 cost time: 6.339888334274292
Epoch: 1, Steps: 107 Train Loss: 3.7000 (Forecasting Loss:0.6179 + XiCon Loss:3.0821 x Lambda(1.0)), Vali MSE Loss: 0.5695 Test MSE Loss: 0.4380
Validation loss decreased (inf --> 0.569534).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3257852
	speed: 0.0700s/iter; left time: 734.3271s
Epoch: 2 cost time: 7.4829490184783936
Epoch: 2, Steps: 107 Train Loss: 3.4311 (Forecasting Loss:0.4908 + XiCon Loss:2.9404 x Lambda(1.0)), Vali MSE Loss: 0.4146 Test MSE Loss: 0.2832
Validation loss decreased (0.569534 --> 0.414586).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3128467
	speed: 0.0675s/iter; left time: 701.5250s
Epoch: 3 cost time: 7.2449421882629395
Epoch: 3, Steps: 107 Train Loss: 3.3275 (Forecasting Loss:0.3296 + XiCon Loss:2.9978 x Lambda(1.0)), Vali MSE Loss: 0.3687 Test MSE Loss: 0.3278
Validation loss decreased (0.414586 --> 0.368727).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3044248
	speed: 0.0664s/iter; left time: 682.4087s
Epoch: 4 cost time: 7.139605283737183
Epoch: 4, Steps: 107 Train Loss: 3.3114 (Forecasting Loss:0.3126 + XiCon Loss:2.9988 x Lambda(1.0)), Vali MSE Loss: 0.3713 Test MSE Loss: 0.2955
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2343140
	speed: 0.0709s/iter; left time: 721.4778s
Epoch: 5 cost time: 7.593618154525757
Epoch: 5, Steps: 107 Train Loss: 3.2534 (Forecasting Loss:0.3026 + XiCon Loss:2.9508 x Lambda(1.0)), Vali MSE Loss: 0.3612 Test MSE Loss: 0.3003
Validation loss decreased (0.368727 --> 0.361223).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2946010
	speed: 0.0694s/iter; left time: 698.5868s
Epoch: 6 cost time: 7.474630117416382
Epoch: 6, Steps: 107 Train Loss: 3.2398 (Forecasting Loss:0.2997 + XiCon Loss:2.9401 x Lambda(1.0)), Vali MSE Loss: 0.3613 Test MSE Loss: 0.2989
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2273893
	speed: 0.0660s/iter; left time: 657.2271s
Epoch: 7 cost time: 7.081380128860474
Epoch: 7, Steps: 107 Train Loss: 3.2387 (Forecasting Loss:0.2989 + XiCon Loss:2.9399 x Lambda(1.0)), Vali MSE Loss: 0.3694 Test MSE Loss: 0.2999
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2533579
	speed: 0.0685s/iter; left time: 674.6433s
Epoch: 8 cost time: 7.388489723205566
Epoch: 8, Steps: 107 Train Loss: 3.2325 (Forecasting Loss:0.2967 + XiCon Loss:2.9358 x Lambda(1.0)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3014
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1681814
	speed: 0.0679s/iter; left time: 661.9847s
Epoch: 9 cost time: 7.343518495559692
Epoch: 9, Steps: 107 Train Loss: 3.2295 (Forecasting Loss:0.2963 + XiCon Loss:2.9332 x Lambda(1.0)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.3016
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2495489
	speed: 0.0677s/iter; left time: 652.1815s
Epoch: 10 cost time: 7.215859651565552
Epoch: 10, Steps: 107 Train Loss: 3.2214 (Forecasting Loss:0.2967 + XiCon Loss:2.9247 x Lambda(1.0)), Vali MSE Loss: 0.3693 Test MSE Loss: 0.3011
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1954374
	speed: 0.0656s/iter; left time: 624.8955s
Epoch: 11 cost time: 7.068290948867798
Epoch: 11, Steps: 107 Train Loss: 3.2230 (Forecasting Loss:0.2959 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.3689 Test MSE Loss: 0.3011
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1407037
	speed: 0.0686s/iter; left time: 646.0264s
Epoch: 12 cost time: 7.379824876785278
Epoch: 12, Steps: 107 Train Loss: 3.2311 (Forecasting Loss:0.2965 + XiCon Loss:2.9346 x Lambda(1.0)), Vali MSE Loss: 0.3691 Test MSE Loss: 0.3010
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2207332
	speed: 0.0695s/iter; left time: 647.1932s
Epoch: 13 cost time: 7.6061506271362305
Epoch: 13, Steps: 107 Train Loss: 3.2313 (Forecasting Loss:0.2963 + XiCon Loss:2.9349 x Lambda(1.0)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.3010
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2347219
	speed: 0.0698s/iter; left time: 642.9102s
Epoch: 14 cost time: 7.51431131362915
Epoch: 14, Steps: 107 Train Loss: 3.2330 (Forecasting Loss:0.2954 + XiCon Loss:2.9376 x Lambda(1.0)), Vali MSE Loss: 0.3689 Test MSE Loss: 0.3010
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2345245
	speed: 0.0575s/iter; left time: 523.3357s
Epoch: 15 cost time: 6.34390664100647
Epoch: 15, Steps: 107 Train Loss: 3.2253 (Forecasting Loss:0.2956 + XiCon Loss:2.9297 x Lambda(1.0)), Vali MSE Loss: 0.3693 Test MSE Loss: 0.3010
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.22209995985031128, mae:0.3784646689891815, mape:0.6139069199562073, mspe:11.453843116760254 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.0614
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6008193
	speed: 0.0500s/iter; left time: 530.1161s
Epoch: 1 cost time: 5.258875131607056
Epoch: 1, Steps: 107 Train Loss: 3.7051 (Forecasting Loss:0.6033 + XiCon Loss:3.1018 x Lambda(1.0)), Vali MSE Loss: 0.5389 Test MSE Loss: 0.3685
Validation loss decreased (inf --> 0.538857).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3150892
	speed: 0.0311s/iter; left time: 325.9729s
Epoch: 2 cost time: 3.3590126037597656
Epoch: 2, Steps: 107 Train Loss: 3.3759 (Forecasting Loss:0.4228 + XiCon Loss:2.9531 x Lambda(1.0)), Vali MSE Loss: 0.3742 Test MSE Loss: 0.2826
Validation loss decreased (0.538857 --> 0.374186).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2270353
	speed: 0.0503s/iter; left time: 522.8271s
Epoch: 3 cost time: 5.464379549026489
Epoch: 3, Steps: 107 Train Loss: 3.2848 (Forecasting Loss:0.3221 + XiCon Loss:2.9627 x Lambda(1.0)), Vali MSE Loss: 0.3590 Test MSE Loss: 0.2713
Validation loss decreased (0.374186 --> 0.359040).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2655559
	speed: 0.0575s/iter; left time: 591.3574s
Epoch: 4 cost time: 6.194453954696655
Epoch: 4, Steps: 107 Train Loss: 3.2700 (Forecasting Loss:0.3115 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.3825 Test MSE Loss: 0.2557
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2509363
	speed: 0.0604s/iter; left time: 614.5525s
Epoch: 5 cost time: 6.468992710113525
Epoch: 5, Steps: 107 Train Loss: 3.2424 (Forecasting Loss:0.3027 + XiCon Loss:2.9397 x Lambda(1.0)), Vali MSE Loss: 0.3638 Test MSE Loss: 0.2638
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1754682
	speed: 0.0573s/iter; left time: 577.0467s
Epoch: 6 cost time: 6.042831897735596
Epoch: 6, Steps: 107 Train Loss: 3.2320 (Forecasting Loss:0.2948 + XiCon Loss:2.9371 x Lambda(1.0)), Vali MSE Loss: 0.3571 Test MSE Loss: 0.2544
Validation loss decreased (0.359040 --> 0.357100).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2637973
	speed: 0.0525s/iter; left time: 522.7841s
Epoch: 7 cost time: 5.745958089828491
Epoch: 7, Steps: 107 Train Loss: 3.2265 (Forecasting Loss:0.2929 + XiCon Loss:2.9336 x Lambda(1.0)), Vali MSE Loss: 0.3582 Test MSE Loss: 0.2545
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1652217
	speed: 0.0599s/iter; left time: 590.0857s
Epoch: 8 cost time: 6.43584132194519
Epoch: 8, Steps: 107 Train Loss: 3.2175 (Forecasting Loss:0.2904 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.2564
Validation loss decreased (0.357100 --> 0.351813).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2008886
	speed: 0.0594s/iter; left time: 578.6557s
Epoch: 9 cost time: 6.427380323410034
Epoch: 9, Steps: 107 Train Loss: 3.2175 (Forecasting Loss:0.2893 + XiCon Loss:2.9282 x Lambda(1.0)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.2576
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1536882
	speed: 0.0631s/iter; left time: 607.8406s
Epoch: 10 cost time: 6.775192499160767
Epoch: 10, Steps: 107 Train Loss: 3.2210 (Forecasting Loss:0.2891 + XiCon Loss:2.9319 x Lambda(1.0)), Vali MSE Loss: 0.3547 Test MSE Loss: 0.2567
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2109177
	speed: 0.0521s/iter; left time: 496.2610s
Epoch: 11 cost time: 5.463255882263184
Epoch: 11, Steps: 107 Train Loss: 3.2205 (Forecasting Loss:0.2903 + XiCon Loss:2.9302 x Lambda(1.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 0.2593
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2315791
	speed: 0.0520s/iter; left time: 490.1595s
Epoch: 12 cost time: 5.643202304840088
Epoch: 12, Steps: 107 Train Loss: 3.2199 (Forecasting Loss:0.2890 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.3548 Test MSE Loss: 0.2588
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1960948
	speed: 0.0612s/iter; left time: 569.7632s
Epoch: 13 cost time: 6.605395555496216
Epoch: 13, Steps: 107 Train Loss: 3.2200 (Forecasting Loss:0.2881 + XiCon Loss:2.9319 x Lambda(1.0)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.2572
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2345135
	speed: 0.0655s/iter; left time: 603.6170s
Epoch: 14 cost time: 7.0055012702941895
Epoch: 14, Steps: 107 Train Loss: 3.2185 (Forecasting Loss:0.2886 + XiCon Loss:2.9299 x Lambda(1.0)), Vali MSE Loss: 0.3531 Test MSE Loss: 0.2574
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2777679
	speed: 0.0596s/iter; left time: 542.3683s
Epoch: 15 cost time: 6.44103741645813
Epoch: 15, Steps: 107 Train Loss: 3.2204 (Forecasting Loss:0.2892 + XiCon Loss:2.9313 x Lambda(1.0)), Vali MSE Loss: 0.3541 Test MSE Loss: 0.2573
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1869228
	speed: 0.0392s/iter; left time: 352.7392s
Epoch: 16 cost time: 4.176352262496948
Epoch: 16, Steps: 107 Train Loss: 3.2192 (Forecasting Loss:0.2892 + XiCon Loss:2.9300 x Lambda(1.0)), Vali MSE Loss: 0.3544 Test MSE Loss: 0.2574
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1854236
	speed: 0.0608s/iter; left time: 540.0149s
Epoch: 17 cost time: 6.520708322525024
Epoch: 17, Steps: 107 Train Loss: 3.2201 (Forecasting Loss:0.2891 + XiCon Loss:2.9310 x Lambda(1.0)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.2573
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1730309
	speed: 0.0583s/iter; left time: 512.0474s
Epoch: 18 cost time: 6.272701740264893
Epoch: 18, Steps: 107 Train Loss: 3.2182 (Forecasting Loss:0.2888 + XiCon Loss:2.9293 x Lambda(1.0)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2574
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.17632456123828888, mae:0.3364470303058624, mape:0.6440581679344177, mspe:19.233491897583008 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4468
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.6507397
	speed: 0.0578s/iter; left time: 612.5117s
Epoch: 1 cost time: 6.203146934509277
Epoch: 1, Steps: 107 Train Loss: 3.7079 (Forecasting Loss:0.6119 + XiCon Loss:3.0960 x Lambda(1.0)), Vali MSE Loss: 0.5065 Test MSE Loss: 0.3643
Validation loss decreased (inf --> 0.506536).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4819865
	speed: 0.0494s/iter; left time: 518.7742s
Epoch: 2 cost time: 5.184488534927368
Epoch: 2, Steps: 107 Train Loss: 3.4207 (Forecasting Loss:0.4315 + XiCon Loss:2.9892 x Lambda(1.0)), Vali MSE Loss: 0.3831 Test MSE Loss: 0.3886
Validation loss decreased (0.506536 --> 0.383078).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2932086
	speed: 0.0451s/iter; left time: 468.2830s
Epoch: 3 cost time: 4.897201299667358
Epoch: 3, Steps: 107 Train Loss: 3.3611 (Forecasting Loss:0.3275 + XiCon Loss:3.0336 x Lambda(1.0)), Vali MSE Loss: 0.4055 Test MSE Loss: 0.2992
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3571630
	speed: 0.0592s/iter; left time: 609.0337s
Epoch: 4 cost time: 6.332096815109253
Epoch: 4, Steps: 107 Train Loss: 3.3324 (Forecasting Loss:0.3033 + XiCon Loss:3.0291 x Lambda(1.0)), Vali MSE Loss: 0.5522 Test MSE Loss: 0.2424
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3792465
	speed: 0.0593s/iter; left time: 603.2278s
Epoch: 5 cost time: 6.345709323883057
Epoch: 5, Steps: 107 Train Loss: 3.3133 (Forecasting Loss:0.3059 + XiCon Loss:3.0073 x Lambda(1.0)), Vali MSE Loss: 0.3942 Test MSE Loss: 0.2802
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2840230
	speed: 0.0578s/iter; left time: 582.0458s
Epoch: 6 cost time: 6.200824737548828
Epoch: 6, Steps: 107 Train Loss: 3.2913 (Forecasting Loss:0.2972 + XiCon Loss:2.9941 x Lambda(1.0)), Vali MSE Loss: 0.4072 Test MSE Loss: 0.2637
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2445893
	speed: 0.0529s/iter; left time: 527.1713s
Epoch: 7 cost time: 5.711167335510254
Epoch: 7, Steps: 107 Train Loss: 3.2843 (Forecasting Loss:0.2918 + XiCon Loss:2.9925 x Lambda(1.0)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2662
Validation loss decreased (0.383078 --> 0.376030).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2314439
	speed: 0.0579s/iter; left time: 570.5472s
Epoch: 8 cost time: 6.252651691436768
Epoch: 8, Steps: 107 Train Loss: 3.2766 (Forecasting Loss:0.2904 + XiCon Loss:2.9862 x Lambda(1.0)), Vali MSE Loss: 0.3897 Test MSE Loss: 0.2613
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3096576
	speed: 0.0571s/iter; left time: 556.7411s
Epoch: 9 cost time: 6.138620615005493
Epoch: 9, Steps: 107 Train Loss: 3.2805 (Forecasting Loss:0.2895 + XiCon Loss:2.9910 x Lambda(1.0)), Vali MSE Loss: 0.3826 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3464365
	speed: 0.0597s/iter; left time: 575.6999s
Epoch: 10 cost time: 6.437268495559692
Epoch: 10, Steps: 107 Train Loss: 3.2767 (Forecasting Loss:0.2902 + XiCon Loss:2.9865 x Lambda(1.0)), Vali MSE Loss: 0.3842 Test MSE Loss: 0.2677
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2691560
	speed: 0.0543s/iter; left time: 517.9192s
Epoch: 11 cost time: 5.839704275131226
Epoch: 11, Steps: 107 Train Loss: 3.2773 (Forecasting Loss:0.2894 + XiCon Loss:2.9879 x Lambda(1.0)), Vali MSE Loss: 0.3827 Test MSE Loss: 0.2708
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3006902
	speed: 0.0576s/iter; left time: 542.3643s
Epoch: 12 cost time: 6.15160346031189
Epoch: 12, Steps: 107 Train Loss: 3.2715 (Forecasting Loss:0.2882 + XiCon Loss:2.9834 x Lambda(1.0)), Vali MSE Loss: 0.3827 Test MSE Loss: 0.2742
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3051102
	speed: 0.0581s/iter; left time: 541.2263s
Epoch: 13 cost time: 6.239557504653931
Epoch: 13, Steps: 107 Train Loss: 3.2720 (Forecasting Loss:0.2891 + XiCon Loss:2.9829 x Lambda(1.0)), Vali MSE Loss: 0.3809 Test MSE Loss: 0.2749
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3346486
	speed: 0.0562s/iter; left time: 517.5559s
Epoch: 14 cost time: 6.032871961593628
Epoch: 14, Steps: 107 Train Loss: 3.2746 (Forecasting Loss:0.2883 + XiCon Loss:2.9864 x Lambda(1.0)), Vali MSE Loss: 0.3815 Test MSE Loss: 0.2751
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2933619
	speed: 0.0527s/iter; left time: 480.0573s
Epoch: 15 cost time: 5.638596057891846
Epoch: 15, Steps: 107 Train Loss: 3.2756 (Forecasting Loss:0.2889 + XiCon Loss:2.9867 x Lambda(1.0)), Vali MSE Loss: 0.3819 Test MSE Loss: 0.2750
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2264538
	speed: 0.0561s/iter; left time: 504.7931s
Epoch: 16 cost time: 6.050930976867676
Epoch: 16, Steps: 107 Train Loss: 3.2712 (Forecasting Loss:0.2881 + XiCon Loss:2.9831 x Lambda(1.0)), Vali MSE Loss: 0.3812 Test MSE Loss: 0.2750
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2769816
	speed: 0.0554s/iter; left time: 492.4877s
Epoch: 17 cost time: 5.998916387557983
Epoch: 17, Steps: 107 Train Loss: 3.2721 (Forecasting Loss:0.2877 + XiCon Loss:2.9844 x Lambda(1.0)), Vali MSE Loss: 0.3813 Test MSE Loss: 0.2750
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.1837417185306549, mae:0.34857794642448425, mape:0.6193313002586365, mspe:13.676600456237793 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4040
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 3.7154136
	speed: 0.0582s/iter; left time: 617.2767s
Epoch: 1 cost time: 6.239210844039917
Epoch: 1, Steps: 107 Train Loss: 3.7441 (Forecasting Loss:0.6368 + XiCon Loss:3.1072 x Lambda(1.0)), Vali MSE Loss: 0.6032 Test MSE Loss: 0.4803
Validation loss decreased (inf --> 0.603213).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2770598
	speed: 0.0608s/iter; left time: 638.1648s
Epoch: 2 cost time: 6.620386838912964
Epoch: 2, Steps: 107 Train Loss: 3.4656 (Forecasting Loss:0.5380 + XiCon Loss:2.9275 x Lambda(1.0)), Vali MSE Loss: 0.4126 Test MSE Loss: 0.3057
Validation loss decreased (0.603213 --> 0.412595).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3313618
	speed: 0.0659s/iter; left time: 684.9979s
Epoch: 3 cost time: 7.128913402557373
Epoch: 3, Steps: 107 Train Loss: 3.2697 (Forecasting Loss:0.3414 + XiCon Loss:2.9282 x Lambda(1.0)), Vali MSE Loss: 0.3726 Test MSE Loss: 0.4505
Validation loss decreased (0.412595 --> 0.372578).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2295494
	speed: 0.0705s/iter; left time: 724.8365s
Epoch: 4 cost time: 7.595728874206543
Epoch: 4, Steps: 107 Train Loss: 3.2545 (Forecasting Loss:0.3161 + XiCon Loss:2.9384 x Lambda(1.0)), Vali MSE Loss: 0.3727 Test MSE Loss: 0.3106
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2186594
	speed: 0.0718s/iter; left time: 730.7019s
Epoch: 5 cost time: 7.681471586227417
Epoch: 5, Steps: 107 Train Loss: 3.2129 (Forecasting Loss:0.3054 + XiCon Loss:2.9076 x Lambda(1.0)), Vali MSE Loss: 0.3709 Test MSE Loss: 0.3286
Validation loss decreased (0.372578 --> 0.370888).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2046804
	speed: 0.0663s/iter; left time: 667.2313s
Epoch: 6 cost time: 7.115252733230591
Epoch: 6, Steps: 107 Train Loss: 3.1903 (Forecasting Loss:0.2993 + XiCon Loss:2.8910 x Lambda(1.0)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3055
Validation loss decreased (0.370888 --> 0.368305).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1413801
	speed: 0.0701s/iter; left time: 697.8219s
Epoch: 7 cost time: 7.547729253768921
Epoch: 7, Steps: 107 Train Loss: 3.1738 (Forecasting Loss:0.2965 + XiCon Loss:2.8772 x Lambda(1.0)), Vali MSE Loss: 0.3644 Test MSE Loss: 0.2945
Validation loss decreased (0.368305 --> 0.364437).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1480601
	speed: 0.0700s/iter; left time: 689.5670s
Epoch: 8 cost time: 7.555923223495483
Epoch: 8, Steps: 107 Train Loss: 3.1689 (Forecasting Loss:0.2952 + XiCon Loss:2.8736 x Lambda(1.0)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.3062
Validation loss decreased (0.364437 --> 0.361642).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1536067
	speed: 0.0690s/iter; left time: 672.3558s
Epoch: 9 cost time: 7.451516389846802
Epoch: 9, Steps: 107 Train Loss: 3.1653 (Forecasting Loss:0.2952 + XiCon Loss:2.8701 x Lambda(1.0)), Vali MSE Loss: 0.3641 Test MSE Loss: 0.3023
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1303487
	speed: 0.0674s/iter; left time: 649.8181s
Epoch: 10 cost time: 7.234036445617676
Epoch: 10, Steps: 107 Train Loss: 3.1674 (Forecasting Loss:0.2934 + XiCon Loss:2.8739 x Lambda(1.0)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2961
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1581779
	speed: 0.0712s/iter; left time: 678.7536s
Epoch: 11 cost time: 7.672254323959351
Epoch: 11, Steps: 107 Train Loss: 3.1714 (Forecasting Loss:0.2938 + XiCon Loss:2.8777 x Lambda(1.0)), Vali MSE Loss: 0.3655 Test MSE Loss: 0.2975
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3180850
	speed: 0.0687s/iter; left time: 647.1897s
Epoch: 12 cost time: 7.3728978633880615
Epoch: 12, Steps: 107 Train Loss: 3.1689 (Forecasting Loss:0.2932 + XiCon Loss:2.8756 x Lambda(1.0)), Vali MSE Loss: 0.3651 Test MSE Loss: 0.2970
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1790738
	speed: 0.0693s/iter; left time: 645.9118s
Epoch: 13 cost time: 7.389588117599487
Epoch: 13, Steps: 107 Train Loss: 3.1677 (Forecasting Loss:0.2936 + XiCon Loss:2.8740 x Lambda(1.0)), Vali MSE Loss: 0.3663 Test MSE Loss: 0.2973
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1994712
	speed: 0.0678s/iter; left time: 624.5256s
Epoch: 14 cost time: 7.295386791229248
Epoch: 14, Steps: 107 Train Loss: 3.1683 (Forecasting Loss:0.2930 + XiCon Loss:2.8752 x Lambda(1.0)), Vali MSE Loss: 0.3658 Test MSE Loss: 0.2966
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1691020
	speed: 0.0682s/iter; left time: 621.1440s
Epoch: 15 cost time: 7.308623552322388
Epoch: 15, Steps: 107 Train Loss: 3.1693 (Forecasting Loss:0.2932 + XiCon Loss:2.8762 x Lambda(1.0)), Vali MSE Loss: 0.3648 Test MSE Loss: 0.2964
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1310282
	speed: 0.0712s/iter; left time: 640.5233s
Epoch: 16 cost time: 7.755143404006958
Epoch: 16, Steps: 107 Train Loss: 3.1683 (Forecasting Loss:0.2933 + XiCon Loss:2.8750 x Lambda(1.0)), Vali MSE Loss: 0.3652 Test MSE Loss: 0.2964
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1333351
	speed: 0.0679s/iter; left time: 603.8266s
Epoch: 17 cost time: 7.373339891433716
Epoch: 17, Steps: 107 Train Loss: 3.1680 (Forecasting Loss:0.2934 + XiCon Loss:2.8746 x Lambda(1.0)), Vali MSE Loss: 0.3651 Test MSE Loss: 0.2963
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1890893
	speed: 0.0677s/iter; left time: 594.7137s
Epoch: 18 cost time: 7.26440691947937
Epoch: 18, Steps: 107 Train Loss: 3.1662 (Forecasting Loss:0.2937 + XiCon Loss:2.8725 x Lambda(1.0)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2963
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.22791153192520142, mae:0.38443848490715027, mape:0.5820428133010864, mspe:9.596548080444336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1962+-0.03318, MAE:0.3569+-0.02865, MAPE:0.6087+-0.03229, MSPE:13.5427+-4.49333, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4683
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 5.286763668060303
Epoch: 1, Steps: 96 Train Loss: 4.1414 (Forecasting Loss:0.9771 + XiCon Loss:3.1643 x Lambda(1.0)), Vali MSE Loss: 0.6675 Test MSE Loss: 0.9465
Validation loss decreased (inf --> 0.667478).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.598007678985596
Epoch: 2, Steps: 96 Train Loss: 3.8635 (Forecasting Loss:0.7562 + XiCon Loss:3.1073 x Lambda(1.0)), Vali MSE Loss: 0.6938 Test MSE Loss: 0.3379
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.372909069061279
Epoch: 3, Steps: 96 Train Loss: 3.6154 (Forecasting Loss:0.5655 + XiCon Loss:3.0499 x Lambda(1.0)), Vali MSE Loss: 0.5923 Test MSE Loss: 0.2825
Validation loss decreased (0.667478 --> 0.592334).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.911454916000366
Epoch: 4, Steps: 96 Train Loss: 3.5398 (Forecasting Loss:0.5193 + XiCon Loss:3.0206 x Lambda(1.0)), Vali MSE Loss: 0.5402 Test MSE Loss: 0.3146
Validation loss decreased (0.592334 --> 0.540216).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.9197423458099365
Epoch: 5, Steps: 96 Train Loss: 3.5148 (Forecasting Loss:0.5037 + XiCon Loss:3.0111 x Lambda(1.0)), Vali MSE Loss: 0.5365 Test MSE Loss: 0.2970
Validation loss decreased (0.540216 --> 0.536547).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.7540435791015625
Epoch: 6, Steps: 96 Train Loss: 3.5041 (Forecasting Loss:0.4966 + XiCon Loss:3.0075 x Lambda(1.0)), Vali MSE Loss: 0.5191 Test MSE Loss: 0.3155
Validation loss decreased (0.536547 --> 0.519142).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.709813356399536
Epoch: 7, Steps: 96 Train Loss: 3.5007 (Forecasting Loss:0.4947 + XiCon Loss:3.0060 x Lambda(1.0)), Vali MSE Loss: 0.5278 Test MSE Loss: 0.2997
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.386253118515015
Epoch: 8, Steps: 96 Train Loss: 3.4964 (Forecasting Loss:0.4921 + XiCon Loss:3.0043 x Lambda(1.0)), Vali MSE Loss: 0.5203 Test MSE Loss: 0.3060
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.913474082946777
Epoch: 9, Steps: 96 Train Loss: 3.4954 (Forecasting Loss:0.4918 + XiCon Loss:3.0036 x Lambda(1.0)), Vali MSE Loss: 0.5198 Test MSE Loss: 0.3060
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.7020604610443115
Epoch: 10, Steps: 96 Train Loss: 3.4940 (Forecasting Loss:0.4908 + XiCon Loss:3.0032 x Lambda(1.0)), Vali MSE Loss: 0.5187 Test MSE Loss: 0.3063
Validation loss decreased (0.519142 --> 0.518691).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.982030630111694
Epoch: 11, Steps: 96 Train Loss: 3.4953 (Forecasting Loss:0.4914 + XiCon Loss:3.0039 x Lambda(1.0)), Vali MSE Loss: 0.5181 Test MSE Loss: 0.3066
Validation loss decreased (0.518691 --> 0.518143).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.722571134567261
Epoch: 12, Steps: 96 Train Loss: 3.4939 (Forecasting Loss:0.4910 + XiCon Loss:3.0029 x Lambda(1.0)), Vali MSE Loss: 0.5181 Test MSE Loss: 0.3070
Validation loss decreased (0.518143 --> 0.518057).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.559307813644409
Epoch: 13, Steps: 96 Train Loss: 3.4933 (Forecasting Loss:0.4905 + XiCon Loss:3.0027 x Lambda(1.0)), Vali MSE Loss: 0.5184 Test MSE Loss: 0.3070
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.054053783416748
Epoch: 14, Steps: 96 Train Loss: 3.4949 (Forecasting Loss:0.4913 + XiCon Loss:3.0036 x Lambda(1.0)), Vali MSE Loss: 0.5176 Test MSE Loss: 0.3070
Validation loss decreased (0.518057 --> 0.517624).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.7294762134552
Epoch: 15, Steps: 96 Train Loss: 3.4952 (Forecasting Loss:0.4908 + XiCon Loss:3.0044 x Lambda(1.0)), Vali MSE Loss: 0.5177 Test MSE Loss: 0.3069
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.951879024505615
Epoch: 16, Steps: 96 Train Loss: 3.4945 (Forecasting Loss:0.4902 + XiCon Loss:3.0044 x Lambda(1.0)), Vali MSE Loss: 0.5172 Test MSE Loss: 0.3069
Validation loss decreased (0.517624 --> 0.517196).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 4.900464057922363
Epoch: 17, Steps: 96 Train Loss: 3.4947 (Forecasting Loss:0.4912 + XiCon Loss:3.0035 x Lambda(1.0)), Vali MSE Loss: 0.5179 Test MSE Loss: 0.3069
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 4.523274183273315
Epoch: 18, Steps: 96 Train Loss: 3.4941 (Forecasting Loss:0.4897 + XiCon Loss:3.0044 x Lambda(1.0)), Vali MSE Loss: 0.5174 Test MSE Loss: 0.3069
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 5.114133834838867
Epoch: 19, Steps: 96 Train Loss: 3.4935 (Forecasting Loss:0.4894 + XiCon Loss:3.0041 x Lambda(1.0)), Vali MSE Loss: 0.5179 Test MSE Loss: 0.3069
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 4.948519229888916
Epoch: 20, Steps: 96 Train Loss: 3.4914 (Forecasting Loss:0.4895 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.5177 Test MSE Loss: 0.3069
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.725608825683594
Epoch: 21, Steps: 96 Train Loss: 3.4927 (Forecasting Loss:0.4899 + XiCon Loss:3.0028 x Lambda(1.0)), Vali MSE Loss: 0.5180 Test MSE Loss: 0.3069
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.9775261878967285
Epoch: 22, Steps: 96 Train Loss: 3.4958 (Forecasting Loss:0.4916 + XiCon Loss:3.0042 x Lambda(1.0)), Vali MSE Loss: 0.5181 Test MSE Loss: 0.3069
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.520483732223511
Epoch: 23, Steps: 96 Train Loss: 3.4957 (Forecasting Loss:0.4914 + XiCon Loss:3.0043 x Lambda(1.0)), Vali MSE Loss: 0.5182 Test MSE Loss: 0.3069
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.861575603485107
Epoch: 24, Steps: 96 Train Loss: 3.4950 (Forecasting Loss:0.4916 + XiCon Loss:3.0033 x Lambda(1.0)), Vali MSE Loss: 0.5184 Test MSE Loss: 0.3069
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 5.016331195831299
Epoch: 25, Steps: 96 Train Loss: 3.4944 (Forecasting Loss:0.4898 + XiCon Loss:3.0046 x Lambda(1.0)), Vali MSE Loss: 0.5176 Test MSE Loss: 0.3069
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 4.990567684173584
Epoch: 26, Steps: 96 Train Loss: 3.4929 (Forecasting Loss:0.4898 + XiCon Loss:3.0031 x Lambda(1.0)), Vali MSE Loss: 0.5183 Test MSE Loss: 0.3069
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.23506823182106018, mae:0.3787977695465088, mape:0.7584944367408752, mspe:27.31130599975586 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3983
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.722505807876587
Epoch: 1, Steps: 96 Train Loss: 4.1158 (Forecasting Loss:0.9677 + XiCon Loss:3.1481 x Lambda(1.0)), Vali MSE Loss: 0.6767 Test MSE Loss: 0.9866
Validation loss decreased (inf --> 0.676684).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.440979719161987
Epoch: 2, Steps: 96 Train Loss: 3.8802 (Forecasting Loss:0.8068 + XiCon Loss:3.0734 x Lambda(1.0)), Vali MSE Loss: 0.5435 Test MSE Loss: 0.3050
Validation loss decreased (0.676684 --> 0.543507).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.1287360191345215
Epoch: 3, Steps: 96 Train Loss: 3.6229 (Forecasting Loss:0.6310 + XiCon Loss:2.9919 x Lambda(1.0)), Vali MSE Loss: 0.5030 Test MSE Loss: 0.2568
Validation loss decreased (0.543507 --> 0.503015).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.145716190338135
Epoch: 4, Steps: 96 Train Loss: 3.4528 (Forecasting Loss:0.4722 + XiCon Loss:2.9807 x Lambda(1.0)), Vali MSE Loss: 0.4651 Test MSE Loss: 0.2634
Validation loss decreased (0.503015 --> 0.465074).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 5.4755940437316895
Epoch: 5, Steps: 96 Train Loss: 3.3859 (Forecasting Loss:0.4132 + XiCon Loss:2.9727 x Lambda(1.0)), Vali MSE Loss: 0.4675 Test MSE Loss: 0.2682
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 5.219395399093628
Epoch: 6, Steps: 96 Train Loss: 3.3585 (Forecasting Loss:0.3908 + XiCon Loss:2.9677 x Lambda(1.0)), Vali MSE Loss: 0.4509 Test MSE Loss: 0.2682
Validation loss decreased (0.465074 --> 0.450851).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.726257085800171
Epoch: 7, Steps: 96 Train Loss: 3.3460 (Forecasting Loss:0.3785 + XiCon Loss:2.9675 x Lambda(1.0)), Vali MSE Loss: 0.4773 Test MSE Loss: 0.2696
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 5.218472480773926
Epoch: 8, Steps: 96 Train Loss: 3.3438 (Forecasting Loss:0.3761 + XiCon Loss:2.9677 x Lambda(1.0)), Vali MSE Loss: 0.4687 Test MSE Loss: 0.2700
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 5.3574910163879395
Epoch: 9, Steps: 96 Train Loss: 3.3402 (Forecasting Loss:0.3738 + XiCon Loss:2.9664 x Lambda(1.0)), Vali MSE Loss: 0.4539 Test MSE Loss: 0.2692
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.51482081413269
Epoch: 10, Steps: 96 Train Loss: 3.3393 (Forecasting Loss:0.3723 + XiCon Loss:2.9670 x Lambda(1.0)), Vali MSE Loss: 0.4598 Test MSE Loss: 0.2696
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 5.393179178237915
Epoch: 11, Steps: 96 Train Loss: 3.3346 (Forecasting Loss:0.3693 + XiCon Loss:2.9653 x Lambda(1.0)), Vali MSE Loss: 0.4582 Test MSE Loss: 0.2695
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 5.0025200843811035
Epoch: 12, Steps: 96 Train Loss: 3.3380 (Forecasting Loss:0.3710 + XiCon Loss:2.9669 x Lambda(1.0)), Vali MSE Loss: 0.4580 Test MSE Loss: 0.2695
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.407763719558716
Epoch: 13, Steps: 96 Train Loss: 3.3349 (Forecasting Loss:0.3701 + XiCon Loss:2.9648 x Lambda(1.0)), Vali MSE Loss: 0.4591 Test MSE Loss: 0.2696
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.285073280334473
Epoch: 14, Steps: 96 Train Loss: 3.3373 (Forecasting Loss:0.3717 + XiCon Loss:2.9656 x Lambda(1.0)), Vali MSE Loss: 0.4561 Test MSE Loss: 0.2696
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.27941107749939
Epoch: 15, Steps: 96 Train Loss: 3.3379 (Forecasting Loss:0.3708 + XiCon Loss:2.9671 x Lambda(1.0)), Vali MSE Loss: 0.4584 Test MSE Loss: 0.2696
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 5.45329213142395
Epoch: 16, Steps: 96 Train Loss: 3.3388 (Forecasting Loss:0.3735 + XiCon Loss:2.9653 x Lambda(1.0)), Vali MSE Loss: 0.4575 Test MSE Loss: 0.2696
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.18913818895816803, mae:0.347286581993103, mape:0.6517371535301208, mspe:18.13787841796875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4048
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.690439939498901
Epoch: 1, Steps: 96 Train Loss: 4.0597 (Forecasting Loss:0.9207 + XiCon Loss:3.1391 x Lambda(1.0)), Vali MSE Loss: 0.6287 Test MSE Loss: 0.8273
Validation loss decreased (inf --> 0.628706).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.852614641189575
Epoch: 2, Steps: 96 Train Loss: 3.8710 (Forecasting Loss:0.8242 + XiCon Loss:3.0468 x Lambda(1.0)), Vali MSE Loss: 0.6556 Test MSE Loss: 0.6418
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 5.034256458282471
Epoch: 3, Steps: 96 Train Loss: 3.7490 (Forecasting Loss:0.7932 + XiCon Loss:2.9558 x Lambda(1.0)), Vali MSE Loss: 0.6339 Test MSE Loss: 0.5692
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 4.6532251834869385
Epoch: 4, Steps: 96 Train Loss: 3.7045 (Forecasting Loss:0.7601 + XiCon Loss:2.9444 x Lambda(1.0)), Vali MSE Loss: 0.6590 Test MSE Loss: 0.4694
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.521169185638428
Epoch: 5, Steps: 96 Train Loss: 3.6447 (Forecasting Loss:0.6998 + XiCon Loss:2.9449 x Lambda(1.0)), Vali MSE Loss: 0.6493 Test MSE Loss: 0.3596
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.595930814743042
Epoch: 6, Steps: 96 Train Loss: 3.5898 (Forecasting Loss:0.6393 + XiCon Loss:2.9505 x Lambda(1.0)), Vali MSE Loss: 0.6431 Test MSE Loss: 0.3115
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.880841493606567
Epoch: 7, Steps: 96 Train Loss: 3.5531 (Forecasting Loss:0.6025 + XiCon Loss:2.9506 x Lambda(1.0)), Vali MSE Loss: 0.6345 Test MSE Loss: 0.2956
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.87408185005188
Epoch: 8, Steps: 96 Train Loss: 3.5338 (Forecasting Loss:0.5813 + XiCon Loss:2.9525 x Lambda(1.0)), Vali MSE Loss: 0.6254 Test MSE Loss: 0.2886
Validation loss decreased (0.628706 --> 0.625426).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.896937847137451
Epoch: 9, Steps: 96 Train Loss: 3.5281 (Forecasting Loss:0.5754 + XiCon Loss:2.9527 x Lambda(1.0)), Vali MSE Loss: 0.6227 Test MSE Loss: 0.2863
Validation loss decreased (0.625426 --> 0.622653).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 4.738955497741699
Epoch: 10, Steps: 96 Train Loss: 3.5231 (Forecasting Loss:0.5693 + XiCon Loss:2.9537 x Lambda(1.0)), Vali MSE Loss: 0.6225 Test MSE Loss: 0.2855
Validation loss decreased (0.622653 --> 0.622457).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.821789264678955
Epoch: 11, Steps: 96 Train Loss: 3.5189 (Forecasting Loss:0.5667 + XiCon Loss:2.9522 x Lambda(1.0)), Vali MSE Loss: 0.6208 Test MSE Loss: 0.2849
Validation loss decreased (0.622457 --> 0.620810).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.856104135513306
Epoch: 12, Steps: 96 Train Loss: 3.5185 (Forecasting Loss:0.5647 + XiCon Loss:2.9538 x Lambda(1.0)), Vali MSE Loss: 0.6217 Test MSE Loss: 0.2847
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.779853820800781
Epoch: 13, Steps: 96 Train Loss: 3.5201 (Forecasting Loss:0.5674 + XiCon Loss:2.9527 x Lambda(1.0)), Vali MSE Loss: 0.6213 Test MSE Loss: 0.2846
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.0213942527771
Epoch: 14, Steps: 96 Train Loss: 3.5169 (Forecasting Loss:0.5635 + XiCon Loss:2.9534 x Lambda(1.0)), Vali MSE Loss: 0.6202 Test MSE Loss: 0.2845
Validation loss decreased (0.620810 --> 0.620153).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.6672608852386475
Epoch: 15, Steps: 96 Train Loss: 3.5167 (Forecasting Loss:0.5640 + XiCon Loss:2.9527 x Lambda(1.0)), Vali MSE Loss: 0.6217 Test MSE Loss: 0.2845
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 4.177500486373901
Epoch: 16, Steps: 96 Train Loss: 3.5158 (Forecasting Loss:0.5644 + XiCon Loss:2.9515 x Lambda(1.0)), Vali MSE Loss: 0.6182 Test MSE Loss: 0.2845
Validation loss decreased (0.620153 --> 0.618194).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 6.810483694076538
Epoch: 17, Steps: 96 Train Loss: 3.5201 (Forecasting Loss:0.5665 + XiCon Loss:2.9536 x Lambda(1.0)), Vali MSE Loss: 0.6195 Test MSE Loss: 0.2845
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 4.23613166809082
Epoch: 18, Steps: 96 Train Loss: 3.5182 (Forecasting Loss:0.5648 + XiCon Loss:2.9533 x Lambda(1.0)), Vali MSE Loss: 0.6212 Test MSE Loss: 0.2845
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 2.678601026535034
Epoch: 19, Steps: 96 Train Loss: 3.5146 (Forecasting Loss:0.5628 + XiCon Loss:2.9519 x Lambda(1.0)), Vali MSE Loss: 0.6206 Test MSE Loss: 0.2845
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 2.8972573280334473
Epoch: 20, Steps: 96 Train Loss: 3.5186 (Forecasting Loss:0.5644 + XiCon Loss:2.9542 x Lambda(1.0)), Vali MSE Loss: 0.6214 Test MSE Loss: 0.2845
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 4.933356761932373
Epoch: 21, Steps: 96 Train Loss: 3.5188 (Forecasting Loss:0.5635 + XiCon Loss:2.9553 x Lambda(1.0)), Vali MSE Loss: 0.6198 Test MSE Loss: 0.2845
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 4.6579811573028564
Epoch: 22, Steps: 96 Train Loss: 3.5167 (Forecasting Loss:0.5646 + XiCon Loss:2.9521 x Lambda(1.0)), Vali MSE Loss: 0.6204 Test MSE Loss: 0.2845
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 4.778356552124023
Epoch: 23, Steps: 96 Train Loss: 3.5171 (Forecasting Loss:0.5646 + XiCon Loss:2.9524 x Lambda(1.0)), Vali MSE Loss: 0.6204 Test MSE Loss: 0.2845
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 4.770174264907837
Epoch: 24, Steps: 96 Train Loss: 3.5207 (Forecasting Loss:0.5666 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.6210 Test MSE Loss: 0.2845
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 4.233347654342651
Epoch: 25, Steps: 96 Train Loss: 3.5180 (Forecasting Loss:0.5646 + XiCon Loss:2.9534 x Lambda(1.0)), Vali MSE Loss: 0.6198 Test MSE Loss: 0.2845
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 4.911532402038574
Epoch: 26, Steps: 96 Train Loss: 3.5169 (Forecasting Loss:0.5633 + XiCon Loss:2.9537 x Lambda(1.0)), Vali MSE Loss: 0.6206 Test MSE Loss: 0.2845
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.20529012382030487, mae:0.36370110511779785, mape:0.6471683979034424, mspe:14.495293617248535 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3825
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 4.887224912643433
Epoch: 1, Steps: 96 Train Loss: 4.1110 (Forecasting Loss:0.9698 + XiCon Loss:3.1412 x Lambda(1.0)), Vali MSE Loss: 0.6477 Test MSE Loss: 0.8726
Validation loss decreased (inf --> 0.647749).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.764530658721924
Epoch: 2, Steps: 96 Train Loss: 3.8338 (Forecasting Loss:0.7416 + XiCon Loss:3.0922 x Lambda(1.0)), Vali MSE Loss: 0.5453 Test MSE Loss: 0.2853
Validation loss decreased (0.647749 --> 0.545290).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.693241357803345
Epoch: 3, Steps: 96 Train Loss: 3.5514 (Forecasting Loss:0.5104 + XiCon Loss:3.0410 x Lambda(1.0)), Vali MSE Loss: 0.4670 Test MSE Loss: 0.3134
Validation loss decreased (0.545290 --> 0.467001).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 3.429898262023926
Epoch: 4, Steps: 96 Train Loss: 3.5021 (Forecasting Loss:0.4789 + XiCon Loss:3.0232 x Lambda(1.0)), Vali MSE Loss: 0.4741 Test MSE Loss: 0.3040
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.140015363693237
Epoch: 5, Steps: 96 Train Loss: 3.4829 (Forecasting Loss:0.4633 + XiCon Loss:3.0196 x Lambda(1.0)), Vali MSE Loss: 0.4648 Test MSE Loss: 0.3284
Validation loss decreased (0.467001 --> 0.464788).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 4.763678789138794
Epoch: 6, Steps: 96 Train Loss: 3.4747 (Forecasting Loss:0.4584 + XiCon Loss:3.0163 x Lambda(1.0)), Vali MSE Loss: 0.4753 Test MSE Loss: 0.3046
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 4.865739583969116
Epoch: 7, Steps: 96 Train Loss: 3.4725 (Forecasting Loss:0.4557 + XiCon Loss:3.0169 x Lambda(1.0)), Vali MSE Loss: 0.4744 Test MSE Loss: 0.3064
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.8596351146698
Epoch: 8, Steps: 96 Train Loss: 3.4695 (Forecasting Loss:0.4533 + XiCon Loss:3.0162 x Lambda(1.0)), Vali MSE Loss: 0.4738 Test MSE Loss: 0.3084
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.650314092636108
Epoch: 9, Steps: 96 Train Loss: 3.4684 (Forecasting Loss:0.4530 + XiCon Loss:3.0154 x Lambda(1.0)), Vali MSE Loss: 0.4764 Test MSE Loss: 0.3051
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 2.923825263977051
Epoch: 10, Steps: 96 Train Loss: 3.4670 (Forecasting Loss:0.4517 + XiCon Loss:3.0153 x Lambda(1.0)), Vali MSE Loss: 0.4762 Test MSE Loss: 0.3054
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.79486608505249
Epoch: 11, Steps: 96 Train Loss: 3.4648 (Forecasting Loss:0.4519 + XiCon Loss:3.0130 x Lambda(1.0)), Vali MSE Loss: 0.4741 Test MSE Loss: 0.3063
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.813782453536987
Epoch: 12, Steps: 96 Train Loss: 3.4671 (Forecasting Loss:0.4521 + XiCon Loss:3.0150 x Lambda(1.0)), Vali MSE Loss: 0.4752 Test MSE Loss: 0.3059
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 4.831228971481323
Epoch: 13, Steps: 96 Train Loss: 3.4655 (Forecasting Loss:0.4518 + XiCon Loss:3.0138 x Lambda(1.0)), Vali MSE Loss: 0.4747 Test MSE Loss: 0.3062
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 5.018004894256592
Epoch: 14, Steps: 96 Train Loss: 3.4649 (Forecasting Loss:0.4522 + XiCon Loss:3.0127 x Lambda(1.0)), Vali MSE Loss: 0.4745 Test MSE Loss: 0.3063
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 4.402822971343994
Epoch: 15, Steps: 96 Train Loss: 3.4653 (Forecasting Loss:0.4531 + XiCon Loss:3.0121 x Lambda(1.0)), Vali MSE Loss: 0.4747 Test MSE Loss: 0.3063
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2591220438480377, mae:0.3975984752178192, mape:0.7789251804351807, mspe:28.414051055908203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1775
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 3.2080752849578857
Epoch: 1, Steps: 96 Train Loss: 4.0480 (Forecasting Loss:0.9077 + XiCon Loss:3.1404 x Lambda(1.0)), Vali MSE Loss: 0.6185 Test MSE Loss: 0.7741
Validation loss decreased (inf --> 0.618485).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 4.696329355239868
Epoch: 2, Steps: 96 Train Loss: 3.8303 (Forecasting Loss:0.7821 + XiCon Loss:3.0482 x Lambda(1.0)), Vali MSE Loss: 0.5854 Test MSE Loss: 0.3546
Validation loss decreased (0.618485 --> 0.585403).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 4.799013614654541
Epoch: 3, Steps: 96 Train Loss: 3.5692 (Forecasting Loss:0.5955 + XiCon Loss:2.9737 x Lambda(1.0)), Vali MSE Loss: 0.5002 Test MSE Loss: 0.2665
Validation loss decreased (0.585403 --> 0.500245).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 5.010330677032471
Epoch: 4, Steps: 96 Train Loss: 3.5049 (Forecasting Loss:0.5382 + XiCon Loss:2.9667 x Lambda(1.0)), Vali MSE Loss: 0.5103 Test MSE Loss: 0.2690
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 4.515774726867676
Epoch: 5, Steps: 96 Train Loss: 3.4852 (Forecasting Loss:0.5199 + XiCon Loss:2.9653 x Lambda(1.0)), Vali MSE Loss: 0.4907 Test MSE Loss: 0.2889
Validation loss decreased (0.500245 --> 0.490703).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 3.70418119430542
Epoch: 6, Steps: 96 Train Loss: 3.4729 (Forecasting Loss:0.5108 + XiCon Loss:2.9621 x Lambda(1.0)), Vali MSE Loss: 0.4972 Test MSE Loss: 0.2894
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 3.8251736164093018
Epoch: 7, Steps: 96 Train Loss: 3.4706 (Forecasting Loss:0.5096 + XiCon Loss:2.9610 x Lambda(1.0)), Vali MSE Loss: 0.4959 Test MSE Loss: 0.2869
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 4.886488676071167
Epoch: 8, Steps: 96 Train Loss: 3.4694 (Forecasting Loss:0.5090 + XiCon Loss:2.9603 x Lambda(1.0)), Vali MSE Loss: 0.4930 Test MSE Loss: 0.2920
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 4.8191819190979
Epoch: 9, Steps: 96 Train Loss: 3.4651 (Forecasting Loss:0.5046 + XiCon Loss:2.9604 x Lambda(1.0)), Vali MSE Loss: 0.4933 Test MSE Loss: 0.2916
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 5.055717945098877
Epoch: 10, Steps: 96 Train Loss: 3.4666 (Forecasting Loss:0.5057 + XiCon Loss:2.9609 x Lambda(1.0)), Vali MSE Loss: 0.4927 Test MSE Loss: 0.2926
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 4.740079402923584
Epoch: 11, Steps: 96 Train Loss: 3.4660 (Forecasting Loss:0.5053 + XiCon Loss:2.9607 x Lambda(1.0)), Vali MSE Loss: 0.4912 Test MSE Loss: 0.2928
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 4.497253894805908
Epoch: 12, Steps: 96 Train Loss: 3.4694 (Forecasting Loss:0.5077 + XiCon Loss:2.9617 x Lambda(1.0)), Vali MSE Loss: 0.4927 Test MSE Loss: 0.2926
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 5.002933740615845
Epoch: 13, Steps: 96 Train Loss: 3.4658 (Forecasting Loss:0.5058 + XiCon Loss:2.9601 x Lambda(1.0)), Vali MSE Loss: 0.4919 Test MSE Loss: 0.2927
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 4.724053382873535
Epoch: 14, Steps: 96 Train Loss: 3.4661 (Forecasting Loss:0.5061 + XiCon Loss:2.9601 x Lambda(1.0)), Vali MSE Loss: 0.4925 Test MSE Loss: 0.2926
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 5.063415288925171
Epoch: 15, Steps: 96 Train Loss: 3.4671 (Forecasting Loss:0.5075 + XiCon Loss:2.9596 x Lambda(1.0)), Vali MSE Loss: 0.4927 Test MSE Loss: 0.2926
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.2129557728767395, mae:0.3647862374782562, mape:0.724151074886322, mspe:23.67150115966797 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2203+-0.03387, MAE:0.3704+-0.02340, MAPE:0.7121+-0.07507, MSPE:22.4060+-7.41254, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.9250
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.3806107
	speed: 0.0639s/iter; left time: 1687.6770s
	iters: 200, epoch: 1 | loss: 3.3430464
	speed: 0.0574s/iter; left time: 1509.2437s
Epoch: 1 cost time: 14.714634418487549
Epoch: 1, Steps: 265 Train Loss: 3.4207 (Forecasting Loss:0.2098 + XiCon Loss:3.2110 x Lambda(1.0)), Vali MSE Loss: 0.1493 Test MSE Loss: 0.0994
Validation loss decreased (inf --> 0.149328).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.6375751
	speed: 0.0632s/iter; left time: 1651.8486s
	iters: 200, epoch: 2 | loss: 3.3549793
	speed: 0.0590s/iter; left time: 1535.0121s
Epoch: 2 cost time: 16.187715768814087
Epoch: 2, Steps: 265 Train Loss: 3.3960 (Forecasting Loss:0.1994 + XiCon Loss:3.1966 x Lambda(1.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0957
Validation loss decreased (0.149328 --> 0.144207).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3066623
	speed: 0.0621s/iter; left time: 1607.0297s
	iters: 200, epoch: 3 | loss: 3.2230325
	speed: 0.0581s/iter; left time: 1497.3239s
Epoch: 3 cost time: 15.917553663253784
Epoch: 3, Steps: 265 Train Loss: 3.2521 (Forecasting Loss:0.1936 + XiCon Loss:3.0585 x Lambda(1.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0957
Validation loss decreased (0.144207 --> 0.143319).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2531452
	speed: 0.0635s/iter; left time: 1624.8520s
	iters: 200, epoch: 4 | loss: 3.3456883
	speed: 0.0597s/iter; left time: 1523.2411s
Epoch: 4 cost time: 16.23783278465271
Epoch: 4, Steps: 265 Train Loss: 3.2385 (Forecasting Loss:0.1912 + XiCon Loss:3.0473 x Lambda(1.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0958
Validation loss decreased (0.143319 --> 0.143246).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2406335
	speed: 0.0594s/iter; left time: 1504.8934s
	iters: 200, epoch: 5 | loss: 3.2370389
	speed: 0.0594s/iter; left time: 1500.4678s
Epoch: 5 cost time: 15.718147993087769
Epoch: 5, Steps: 265 Train Loss: 3.2356 (Forecasting Loss:0.1900 + XiCon Loss:3.0456 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0955
Validation loss decreased (0.143246 --> 0.142122).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2034988
	speed: 0.0625s/iter; left time: 1568.2884s
	iters: 200, epoch: 6 | loss: 3.2044268
	speed: 0.0584s/iter; left time: 1459.5773s
Epoch: 6 cost time: 16.053171634674072
Epoch: 6, Steps: 265 Train Loss: 3.2323 (Forecasting Loss:0.1895 + XiCon Loss:3.0428 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0950
Validation loss decreased (0.142122 --> 0.141631).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2711141
	speed: 0.0632s/iter; left time: 1568.2170s
	iters: 200, epoch: 7 | loss: 3.2793751
	speed: 0.0609s/iter; left time: 1504.1191s
Epoch: 7 cost time: 16.369137048721313
Epoch: 7, Steps: 265 Train Loss: 3.2316 (Forecasting Loss:0.1892 + XiCon Loss:3.0424 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3059459
	speed: 0.0599s/iter; left time: 1471.0992s
	iters: 200, epoch: 8 | loss: 3.2384357
	speed: 0.0589s/iter; left time: 1440.7873s
Epoch: 8 cost time: 15.855959415435791
Epoch: 8, Steps: 265 Train Loss: 3.2294 (Forecasting Loss:0.1889 + XiCon Loss:3.0404 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2327249
	speed: 0.0636s/iter; left time: 1543.1455s
	iters: 200, epoch: 9 | loss: 3.1839550
	speed: 0.0589s/iter; left time: 1423.1288s
Epoch: 9 cost time: 15.969372510910034
Epoch: 9, Steps: 265 Train Loss: 3.2265 (Forecasting Loss:0.1889 + XiCon Loss:3.0376 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1827035
	speed: 0.0623s/iter; left time: 1497.0383s
	iters: 200, epoch: 10 | loss: 3.3004954
	speed: 0.0597s/iter; left time: 1426.6068s
Epoch: 10 cost time: 15.998742580413818
Epoch: 10, Steps: 265 Train Loss: 3.2298 (Forecasting Loss:0.1889 + XiCon Loss:3.0410 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2651789
	speed: 0.0628s/iter; left time: 1491.4015s
	iters: 200, epoch: 11 | loss: 3.2658479
	speed: 0.0572s/iter; left time: 1352.4529s
Epoch: 11 cost time: 15.967702627182007
Epoch: 11, Steps: 265 Train Loss: 3.2359 (Forecasting Loss:0.1889 + XiCon Loss:3.0470 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1503849
	speed: 0.0614s/iter; left time: 1442.7217s
	iters: 200, epoch: 12 | loss: 3.1625311
	speed: 0.0595s/iter; left time: 1392.4386s
Epoch: 12 cost time: 15.919029712677002
Epoch: 12, Steps: 265 Train Loss: 3.2314 (Forecasting Loss:0.1888 + XiCon Loss:3.0426 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2593954
	speed: 0.0618s/iter; left time: 1433.9671s
	iters: 200, epoch: 13 | loss: 3.2530038
	speed: 0.0613s/iter; left time: 1416.2301s
Epoch: 13 cost time: 16.282991409301758
Epoch: 13, Steps: 265 Train Loss: 3.2295 (Forecasting Loss:0.1888 + XiCon Loss:3.0407 x Lambda(1.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0949
Validation loss decreased (0.141631 --> 0.141543).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1784816
	speed: 0.0655s/iter; left time: 1502.7196s
	iters: 200, epoch: 14 | loss: 3.2470770
	speed: 0.0587s/iter; left time: 1340.9730s
Epoch: 14 cost time: 16.340117692947388
Epoch: 14, Steps: 265 Train Loss: 3.2250 (Forecasting Loss:0.1888 + XiCon Loss:3.0362 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3192830
	speed: 0.0642s/iter; left time: 1456.7810s
	iters: 200, epoch: 15 | loss: 3.2490389
	speed: 0.0600s/iter; left time: 1356.4481s
Epoch: 15 cost time: 16.357633352279663
Epoch: 15, Steps: 265 Train Loss: 3.2314 (Forecasting Loss:0.1888 + XiCon Loss:3.0426 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2108982
	speed: 0.0604s/iter; left time: 1355.3227s
	iters: 200, epoch: 16 | loss: 3.2183311
	speed: 0.0593s/iter; left time: 1323.6278s
Epoch: 16 cost time: 16.00431537628174
Epoch: 16, Steps: 265 Train Loss: 3.2243 (Forecasting Loss:0.1888 + XiCon Loss:3.0355 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2472327
	speed: 0.0647s/iter; left time: 1434.7481s
	iters: 200, epoch: 17 | loss: 3.2155666
	speed: 0.0601s/iter; left time: 1325.7237s
Epoch: 17 cost time: 16.241918802261353
Epoch: 17, Steps: 265 Train Loss: 3.2315 (Forecasting Loss:0.1887 + XiCon Loss:3.0428 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2034602
	speed: 0.0627s/iter; left time: 1373.5210s
	iters: 200, epoch: 18 | loss: 3.2768178
	speed: 0.0615s/iter; left time: 1341.0173s
Epoch: 18 cost time: 16.45481276512146
Epoch: 18, Steps: 265 Train Loss: 3.2245 (Forecasting Loss:0.1887 + XiCon Loss:3.0358 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0949
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2009549
	speed: 0.0587s/iter; left time: 1269.6429s
	iters: 200, epoch: 19 | loss: 3.2801716
	speed: 0.0598s/iter; left time: 1287.1540s
Epoch: 19 cost time: 15.888406753540039
Epoch: 19, Steps: 265 Train Loss: 3.2300 (Forecasting Loss:0.1888 + XiCon Loss:3.0412 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3088820
	speed: 0.0650s/iter; left time: 1388.1656s
	iters: 200, epoch: 20 | loss: 3.2026827
	speed: 0.0581s/iter; left time: 1235.8035s
Epoch: 20 cost time: 16.042135000228882
Epoch: 20, Steps: 265 Train Loss: 3.2305 (Forecasting Loss:0.1887 + XiCon Loss:3.0418 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2303655
	speed: 0.0615s/iter; left time: 1298.2013s
	iters: 200, epoch: 21 | loss: 3.2260644
	speed: 0.0620s/iter; left time: 1301.3579s
Epoch: 21 cost time: 16.225616693496704
Epoch: 21, Steps: 265 Train Loss: 3.2300 (Forecasting Loss:0.1888 + XiCon Loss:3.0411 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2417598
	speed: 0.0605s/iter; left time: 1261.2797s
	iters: 200, epoch: 22 | loss: 3.1917355
	speed: 0.0590s/iter; left time: 1222.6715s
Epoch: 22 cost time: 15.786914587020874
Epoch: 22, Steps: 265 Train Loss: 3.2281 (Forecasting Loss:0.1887 + XiCon Loss:3.0394 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0949
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1849217
	speed: 0.0624s/iter; left time: 1283.0348s
	iters: 200, epoch: 23 | loss: 3.2137365
	speed: 0.0608s/iter; left time: 1244.6483s
Epoch: 23 cost time: 16.19086265563965
Epoch: 23, Steps: 265 Train Loss: 3.2293 (Forecasting Loss:0.1888 + XiCon Loss:3.0405 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039668772369623184, mae:0.15011250972747803, mape:0.11945285648107529, mspe:0.02678927592933178 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7617
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.4058566
	speed: 0.0606s/iter; left time: 1599.1211s
	iters: 200, epoch: 1 | loss: 3.3351197
	speed: 0.0542s/iter; left time: 1425.2100s
Epoch: 1 cost time: 15.165966033935547
Epoch: 1, Steps: 265 Train Loss: 3.4092 (Forecasting Loss:0.2090 + XiCon Loss:3.2002 x Lambda(1.0)), Vali MSE Loss: 0.1481 Test MSE Loss: 0.0979
Validation loss decreased (inf --> 0.148123).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3453939
	speed: 0.0645s/iter; left time: 1686.2792s
	iters: 200, epoch: 2 | loss: 3.5055063
	speed: 0.0603s/iter; left time: 1569.4515s
Epoch: 2 cost time: 16.362826108932495
Epoch: 2, Steps: 265 Train Loss: 3.4407 (Forecasting Loss:0.1982 + XiCon Loss:3.2426 x Lambda(1.0)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.0983
Validation loss decreased (0.148123 --> 0.146326).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3434837
	speed: 0.0599s/iter; left time: 1549.5202s
	iters: 200, epoch: 3 | loss: 3.4042530
	speed: 0.0631s/iter; left time: 1625.2727s
Epoch: 3 cost time: 16.192694187164307
Epoch: 3, Steps: 265 Train Loss: 3.3524 (Forecasting Loss:0.1935 + XiCon Loss:3.1589 x Lambda(1.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0955
Validation loss decreased (0.146326 --> 0.143384).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2626684
	speed: 0.0627s/iter; left time: 1606.4177s
	iters: 200, epoch: 4 | loss: 3.2437804
	speed: 0.0591s/iter; left time: 1507.9708s
Epoch: 4 cost time: 15.89109182357788
Epoch: 4, Steps: 265 Train Loss: 3.2385 (Forecasting Loss:0.1912 + XiCon Loss:3.0473 x Lambda(1.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0953
Validation loss decreased (0.143384 --> 0.143044).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2332757
	speed: 0.0622s/iter; left time: 1575.9069s
	iters: 200, epoch: 5 | loss: 3.1915267
	speed: 0.0614s/iter; left time: 1549.1081s
Epoch: 5 cost time: 16.51890540122986
Epoch: 5, Steps: 265 Train Loss: 3.2236 (Forecasting Loss:0.1902 + XiCon Loss:3.0335 x Lambda(1.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0946
Validation loss decreased (0.143044 --> 0.142162).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2475011
	speed: 0.0601s/iter; left time: 1506.8216s
	iters: 200, epoch: 6 | loss: 3.1809204
	speed: 0.0613s/iter; left time: 1530.0206s
Epoch: 6 cost time: 15.96391773223877
Epoch: 6, Steps: 265 Train Loss: 3.2195 (Forecasting Loss:0.1898 + XiCon Loss:3.0297 x Lambda(1.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1900978
	speed: 0.0652s/iter; left time: 1616.8170s
	iters: 200, epoch: 7 | loss: 3.2874982
	speed: 0.0595s/iter; left time: 1469.9549s
Epoch: 7 cost time: 16.159770250320435
Epoch: 7, Steps: 265 Train Loss: 3.2171 (Forecasting Loss:0.1894 + XiCon Loss:3.0277 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
Validation loss decreased (0.142162 --> 0.142081).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2129474
	speed: 0.0616s/iter; left time: 1512.0810s
	iters: 200, epoch: 8 | loss: 3.2789037
	speed: 0.0594s/iter; left time: 1451.5885s
Epoch: 8 cost time: 15.9831862449646
Epoch: 8, Steps: 265 Train Loss: 3.2220 (Forecasting Loss:0.1893 + XiCon Loss:3.0327 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2219844
	speed: 0.0615s/iter; left time: 1494.0273s
	iters: 200, epoch: 9 | loss: 3.2449152
	speed: 0.0554s/iter; left time: 1339.7256s
Epoch: 9 cost time: 18.373291492462158
Epoch: 9, Steps: 265 Train Loss: 3.2123 (Forecasting Loss:0.1892 + XiCon Loss:3.0231 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.142081 --> 0.141821).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1872332
	speed: 0.0420s/iter; left time: 1008.2017s
	iters: 200, epoch: 10 | loss: 3.1887851
	speed: 0.0418s/iter; left time: 1000.1954s
Epoch: 10 cost time: 12.302454710006714
Epoch: 10, Steps: 265 Train Loss: 3.2186 (Forecasting Loss:0.1890 + XiCon Loss:3.0296 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2526882
	speed: 0.0617s/iter; left time: 1465.4566s
	iters: 200, epoch: 11 | loss: 3.2360108
	speed: 0.0598s/iter; left time: 1413.2226s
Epoch: 11 cost time: 15.964271068572998
Epoch: 11, Steps: 265 Train Loss: 3.2171 (Forecasting Loss:0.1891 + XiCon Loss:3.0280 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0943
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2021322
	speed: 0.0577s/iter; left time: 1354.6761s
	iters: 200, epoch: 12 | loss: 3.2363153
	speed: 0.0601s/iter; left time: 1405.6151s
Epoch: 12 cost time: 15.610375881195068
Epoch: 12, Steps: 265 Train Loss: 3.2132 (Forecasting Loss:0.1891 + XiCon Loss:3.0241 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1750724
	speed: 0.0612s/iter; left time: 1420.2071s
	iters: 200, epoch: 13 | loss: 3.2084064
	speed: 0.0574s/iter; left time: 1327.9975s
Epoch: 13 cost time: 15.360512018203735
Epoch: 13, Steps: 265 Train Loss: 3.2175 (Forecasting Loss:0.1892 + XiCon Loss:3.0283 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1756749
	speed: 0.0568s/iter; left time: 1303.1798s
	iters: 200, epoch: 14 | loss: 3.2325249
	speed: 0.0610s/iter; left time: 1394.9247s
Epoch: 14 cost time: 15.585069179534912
Epoch: 14, Steps: 265 Train Loss: 3.2121 (Forecasting Loss:0.1891 + XiCon Loss:3.0230 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2185094
	speed: 0.0618s/iter; left time: 1401.8168s
	iters: 200, epoch: 15 | loss: 3.2571139
	speed: 0.0597s/iter; left time: 1348.4184s
Epoch: 15 cost time: 14.616213083267212
Epoch: 15, Steps: 265 Train Loss: 3.2141 (Forecasting Loss:0.1891 + XiCon Loss:3.0250 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1688859
	speed: 0.0653s/iter; left time: 1465.0598s
	iters: 200, epoch: 16 | loss: 3.1848516
	speed: 0.0602s/iter; left time: 1342.9468s
Epoch: 16 cost time: 16.673044204711914
Epoch: 16, Steps: 265 Train Loss: 3.2172 (Forecasting Loss:0.1890 + XiCon Loss:3.0282 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2777767
	speed: 0.0598s/iter; left time: 1324.3360s
	iters: 200, epoch: 17 | loss: 3.1953602
	speed: 0.0450s/iter; left time: 992.7198s
Epoch: 17 cost time: 13.840418815612793
Epoch: 17, Steps: 265 Train Loss: 3.2184 (Forecasting Loss:0.1891 + XiCon Loss:3.0293 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3095376
	speed: 0.0617s/iter; left time: 1350.7482s
	iters: 200, epoch: 18 | loss: 3.2747991
	speed: 0.0615s/iter; left time: 1341.0406s
Epoch: 18 cost time: 16.302096605300903
Epoch: 18, Steps: 265 Train Loss: 3.2175 (Forecasting Loss:0.1891 + XiCon Loss:3.0284 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1686997
	speed: 0.0569s/iter; left time: 1231.8727s
	iters: 200, epoch: 19 | loss: 3.2315240
	speed: 0.0453s/iter; left time: 976.1188s
Epoch: 19 cost time: 14.081298589706421
Epoch: 19, Steps: 265 Train Loss: 3.2121 (Forecasting Loss:0.1891 + XiCon Loss:3.0230 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0943
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03929087892174721, mae:0.14943335950374603, mape:0.11871274560689926, mspe:0.026427006348967552 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7230
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.3998210
	speed: 0.0575s/iter; left time: 1517.8007s
	iters: 200, epoch: 1 | loss: 3.3480906
	speed: 0.0591s/iter; left time: 1553.6294s
Epoch: 1 cost time: 15.426987409591675
Epoch: 1, Steps: 265 Train Loss: 3.4020 (Forecasting Loss:0.2107 + XiCon Loss:3.1913 x Lambda(1.0)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.0981
Validation loss decreased (inf --> 0.146842).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3784127
	speed: 0.0634s/iter; left time: 1658.0902s
	iters: 200, epoch: 2 | loss: 3.5140808
	speed: 0.0580s/iter; left time: 1510.4765s
Epoch: 2 cost time: 16.087988138198853
Epoch: 2, Steps: 265 Train Loss: 3.4791 (Forecasting Loss:0.1984 + XiCon Loss:3.2806 x Lambda(1.0)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.0974
Validation loss decreased (0.146842 --> 0.145940).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3700125
	speed: 0.0633s/iter; left time: 1637.4048s
	iters: 200, epoch: 3 | loss: 3.2336574
	speed: 0.0623s/iter; left time: 1606.2201s
Epoch: 3 cost time: 16.50411629676819
Epoch: 3, Steps: 265 Train Loss: 3.3826 (Forecasting Loss:0.1934 + XiCon Loss:3.1892 x Lambda(1.0)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0970
Validation loss decreased (0.145940 --> 0.143514).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3320901
	speed: 0.0601s/iter; left time: 1537.8264s
	iters: 200, epoch: 4 | loss: 3.3294761
	speed: 0.0594s/iter; left time: 1515.8445s
Epoch: 4 cost time: 15.899492263793945
Epoch: 4, Steps: 265 Train Loss: 3.3572 (Forecasting Loss:0.1910 + XiCon Loss:3.1663 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0957
Validation loss decreased (0.143514 --> 0.142122).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4521689
	speed: 0.0637s/iter; left time: 1614.2019s
	iters: 200, epoch: 5 | loss: 3.3729157
	speed: 0.0598s/iter; left time: 1508.9132s
Epoch: 5 cost time: 16.109585523605347
Epoch: 5, Steps: 265 Train Loss: 3.3435 (Forecasting Loss:0.1901 + XiCon Loss:3.1534 x Lambda(1.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0952
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2730103
	speed: 0.0637s/iter; left time: 1597.5034s
	iters: 200, epoch: 6 | loss: 3.2923961
	speed: 0.0619s/iter; left time: 1546.9104s
Epoch: 6 cost time: 16.40798330307007
Epoch: 6, Steps: 265 Train Loss: 3.2836 (Forecasting Loss:0.1897 + XiCon Loss:3.0938 x Lambda(1.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2782397
	speed: 0.0603s/iter; left time: 1496.3056s
	iters: 200, epoch: 7 | loss: 3.3657720
	speed: 0.0584s/iter; left time: 1443.9038s
Epoch: 7 cost time: 15.83211636543274
Epoch: 7, Steps: 265 Train Loss: 3.2726 (Forecasting Loss:0.1893 + XiCon Loss:3.0833 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
Validation loss decreased (0.142122 --> 0.141819).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4020236
	speed: 0.0629s/iter; left time: 1542.7965s
	iters: 200, epoch: 8 | loss: 3.2612936
	speed: 0.0616s/iter; left time: 1506.6728s
Epoch: 8 cost time: 16.30782651901245
Epoch: 8, Steps: 265 Train Loss: 3.2634 (Forecasting Loss:0.1893 + XiCon Loss:3.0741 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3127298
	speed: 0.0621s/iter; left time: 1507.8538s
	iters: 200, epoch: 9 | loss: 3.2316687
	speed: 0.0616s/iter; left time: 1490.0419s
Epoch: 9 cost time: 16.29886293411255
Epoch: 9, Steps: 265 Train Loss: 3.2639 (Forecasting Loss:0.1892 + XiCon Loss:3.0747 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3147836
	speed: 0.0631s/iter; left time: 1514.2337s
	iters: 200, epoch: 10 | loss: 3.3161366
	speed: 0.0579s/iter; left time: 1385.4570s
Epoch: 10 cost time: 16.197019338607788
Epoch: 10, Steps: 265 Train Loss: 3.2641 (Forecasting Loss:0.1892 + XiCon Loss:3.0749 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2027957
	speed: 0.0639s/iter; left time: 1518.4461s
	iters: 200, epoch: 11 | loss: 3.2256334
	speed: 0.0612s/iter; left time: 1446.4654s
Epoch: 11 cost time: 16.433512449264526
Epoch: 11, Steps: 265 Train Loss: 3.2585 (Forecasting Loss:0.1891 + XiCon Loss:3.0694 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.141819 --> 0.141797).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2072458
	speed: 0.0594s/iter; left time: 1394.8291s
	iters: 200, epoch: 12 | loss: 3.3318753
	speed: 0.0650s/iter; left time: 1520.5648s
Epoch: 12 cost time: 16.564294815063477
Epoch: 12, Steps: 265 Train Loss: 3.2614 (Forecasting Loss:0.1890 + XiCon Loss:3.0724 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3293028
	speed: 0.0639s/iter; left time: 1484.5483s
	iters: 200, epoch: 13 | loss: 3.2942104
	speed: 0.0601s/iter; left time: 1388.4241s
Epoch: 13 cost time: 16.15293574333191
Epoch: 13, Steps: 265 Train Loss: 3.2626 (Forecasting Loss:0.1890 + XiCon Loss:3.0736 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141797 --> 0.141745).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2382851
	speed: 0.0628s/iter; left time: 1441.3211s
	iters: 200, epoch: 14 | loss: 3.2289145
	speed: 0.0600s/iter; left time: 1371.3225s
Epoch: 14 cost time: 16.304665327072144
Epoch: 14, Steps: 265 Train Loss: 3.2617 (Forecasting Loss:0.1891 + XiCon Loss:3.0727 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2107651
	speed: 0.0603s/iter; left time: 1367.5398s
	iters: 200, epoch: 15 | loss: 3.3449419
	speed: 0.0590s/iter; left time: 1332.5503s
Epoch: 15 cost time: 15.967405557632446
Epoch: 15, Steps: 265 Train Loss: 3.2613 (Forecasting Loss:0.1890 + XiCon Loss:3.0723 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
Validation loss decreased (0.141745 --> 0.141718).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2971466
	speed: 0.0620s/iter; left time: 1390.5881s
	iters: 200, epoch: 16 | loss: 3.2060387
	speed: 0.0599s/iter; left time: 1338.2345s
Epoch: 16 cost time: 15.98239254951477
Epoch: 16, Steps: 265 Train Loss: 3.2627 (Forecasting Loss:0.1891 + XiCon Loss:3.0736 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2652085
	speed: 0.0636s/iter; left time: 1408.9125s
	iters: 200, epoch: 17 | loss: 3.2159607
	speed: 0.0620s/iter; left time: 1368.1942s
Epoch: 17 cost time: 16.592486143112183
Epoch: 17, Steps: 265 Train Loss: 3.2652 (Forecasting Loss:0.1889 + XiCon Loss:3.0763 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2462659
	speed: 0.0629s/iter; left time: 1378.2426s
	iters: 200, epoch: 18 | loss: 3.2116580
	speed: 0.0573s/iter; left time: 1249.3353s
Epoch: 18 cost time: 15.837600946426392
Epoch: 18, Steps: 265 Train Loss: 3.2626 (Forecasting Loss:0.1890 + XiCon Loss:3.0736 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3677955
	speed: 0.0627s/iter; left time: 1355.5877s
	iters: 200, epoch: 19 | loss: 3.2929771
	speed: 0.0612s/iter; left time: 1318.4919s
Epoch: 19 cost time: 16.344081163406372
Epoch: 19, Steps: 265 Train Loss: 3.2594 (Forecasting Loss:0.1892 + XiCon Loss:3.0702 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2556741
	speed: 0.0613s/iter; left time: 1309.3978s
	iters: 200, epoch: 20 | loss: 3.2605052
	speed: 0.0620s/iter; left time: 1317.4756s
Epoch: 20 cost time: 16.250439167022705
Epoch: 20, Steps: 265 Train Loss: 3.2565 (Forecasting Loss:0.1889 + XiCon Loss:3.0676 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2076643
	speed: 0.0632s/iter; left time: 1333.8405s
	iters: 200, epoch: 21 | loss: 3.3117363
	speed: 0.0579s/iter; left time: 1216.8002s
Epoch: 21 cost time: 15.809826612472534
Epoch: 21, Steps: 265 Train Loss: 3.2603 (Forecasting Loss:0.1891 + XiCon Loss:3.0712 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2827058
	speed: 0.0630s/iter; left time: 1311.9856s
	iters: 200, epoch: 22 | loss: 3.3084769
	speed: 0.0633s/iter; left time: 1312.6311s
Epoch: 22 cost time: 16.729367971420288
Epoch: 22, Steps: 265 Train Loss: 3.2608 (Forecasting Loss:0.1891 + XiCon Loss:3.0717 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2996612
	speed: 0.0598s/iter; left time: 1230.1497s
	iters: 200, epoch: 23 | loss: 3.2830572
	speed: 0.0641s/iter; left time: 1312.7541s
Epoch: 23 cost time: 16.641759395599365
Epoch: 23, Steps: 265 Train Loss: 3.2636 (Forecasting Loss:0.1890 + XiCon Loss:3.0746 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2923973
	speed: 0.0662s/iter; left time: 1345.1545s
	iters: 200, epoch: 24 | loss: 3.2146437
	speed: 0.0627s/iter; left time: 1267.1286s
Epoch: 24 cost time: 16.785494327545166
Epoch: 24, Steps: 265 Train Loss: 3.2612 (Forecasting Loss:0.1891 + XiCon Loss:3.0721 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0945
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2504904
	speed: 0.0658s/iter; left time: 1318.2298s
	iters: 200, epoch: 25 | loss: 3.3051105
	speed: 0.0631s/iter; left time: 1258.2168s
Epoch: 25 cost time: 17.02270746231079
Epoch: 25, Steps: 265 Train Loss: 3.2608 (Forecasting Loss:0.1891 + XiCon Loss:3.0717 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03945605456829071, mae:0.14963407814502716, mape:0.11877451837062836, mspe:0.0263482928276062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.1079
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.4490385
	speed: 0.0614s/iter; left time: 1620.0202s
	iters: 200, epoch: 1 | loss: 3.3455498
	speed: 0.0598s/iter; left time: 1573.1237s
Epoch: 1 cost time: 16.012983322143555
Epoch: 1, Steps: 265 Train Loss: 3.4388 (Forecasting Loss:0.2102 + XiCon Loss:3.2286 x Lambda(1.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.148261).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5418315
	speed: 0.0645s/iter; left time: 1687.0368s
	iters: 200, epoch: 2 | loss: 3.3137121
	speed: 0.0647s/iter; left time: 1684.9130s
Epoch: 2 cost time: 17.04151940345764
Epoch: 2, Steps: 265 Train Loss: 3.4091 (Forecasting Loss:0.1984 + XiCon Loss:3.2107 x Lambda(1.0)), Vali MSE Loss: 0.1466 Test MSE Loss: 0.0968
Validation loss decreased (0.148261 --> 0.146572).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2981184
	speed: 0.0654s/iter; left time: 1692.7407s
	iters: 200, epoch: 3 | loss: 3.2447269
	speed: 0.0621s/iter; left time: 1601.3143s
Epoch: 3 cost time: 16.731182098388672
Epoch: 3, Steps: 265 Train Loss: 3.2871 (Forecasting Loss:0.1934 + XiCon Loss:3.0937 x Lambda(1.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0962
Validation loss decreased (0.146572 --> 0.144001).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2699614
	speed: 0.0676s/iter; left time: 1730.0752s
	iters: 200, epoch: 4 | loss: 3.2466650
	speed: 0.0652s/iter; left time: 1662.6195s
Epoch: 4 cost time: 17.6376473903656
Epoch: 4, Steps: 265 Train Loss: 3.2808 (Forecasting Loss:0.1914 + XiCon Loss:3.0894 x Lambda(1.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0962
Validation loss decreased (0.144001 --> 0.142596).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4126120
	speed: 0.0636s/iter; left time: 1611.4352s
	iters: 200, epoch: 5 | loss: 3.1890173
	speed: 0.0763s/iter; left time: 1926.1121s
Epoch: 5 cost time: 19.93602204322815
Epoch: 5, Steps: 265 Train Loss: 3.2790 (Forecasting Loss:0.1898 + XiCon Loss:3.0892 x Lambda(1.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0982
Validation loss decreased (0.142596 --> 0.142263).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2146194
	speed: 0.0404s/iter; left time: 1014.1432s
	iters: 200, epoch: 6 | loss: 3.1995530
	speed: 0.0517s/iter; left time: 1291.6031s
Epoch: 6 cost time: 13.229809761047363
Epoch: 6, Steps: 265 Train Loss: 3.2616 (Forecasting Loss:0.1889 + XiCon Loss:3.0727 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0973
Validation loss decreased (0.142263 --> 0.142010).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3420849
	speed: 0.0648s/iter; left time: 1607.5730s
	iters: 200, epoch: 7 | loss: 3.2063673
	speed: 0.0618s/iter; left time: 1527.9857s
Epoch: 7 cost time: 16.819071531295776
Epoch: 7, Steps: 265 Train Loss: 3.2643 (Forecasting Loss:0.1888 + XiCon Loss:3.0755 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0982
Validation loss decreased (0.142010 --> 0.141754).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1925960
	speed: 0.0615s/iter; left time: 1508.6788s
	iters: 200, epoch: 8 | loss: 3.2823772
	speed: 0.0626s/iter; left time: 1530.8041s
Epoch: 8 cost time: 16.57309079170227
Epoch: 8, Steps: 265 Train Loss: 3.2615 (Forecasting Loss:0.1887 + XiCon Loss:3.0728 x Lambda(1.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0980
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2838337
	speed: 0.0669s/iter; left time: 1623.5194s
	iters: 200, epoch: 9 | loss: 3.1687071
	speed: 0.0621s/iter; left time: 1500.7266s
Epoch: 9 cost time: 16.277150869369507
Epoch: 9, Steps: 265 Train Loss: 3.2602 (Forecasting Loss:0.1884 + XiCon Loss:3.0718 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0979
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2478957
	speed: 0.0661s/iter; left time: 1586.8136s
	iters: 200, epoch: 10 | loss: 3.2121058
	speed: 0.0637s/iter; left time: 1523.3240s
Epoch: 10 cost time: 17.170029163360596
Epoch: 10, Steps: 265 Train Loss: 3.2557 (Forecasting Loss:0.1883 + XiCon Loss:3.0674 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0979
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1684866
	speed: 0.0643s/iter; left time: 1527.7345s
	iters: 200, epoch: 11 | loss: 3.2288797
	speed: 0.0549s/iter; left time: 1298.8024s
Epoch: 11 cost time: 14.92931318283081
Epoch: 11, Steps: 265 Train Loss: 3.2588 (Forecasting Loss:0.1884 + XiCon Loss:3.0704 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2322171
	speed: 0.0648s/iter; left time: 1520.9319s
	iters: 200, epoch: 12 | loss: 3.2904813
	speed: 0.0640s/iter; left time: 1496.9524s
Epoch: 12 cost time: 16.917658805847168
Epoch: 12, Steps: 265 Train Loss: 3.2544 (Forecasting Loss:0.1883 + XiCon Loss:3.0661 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0981
Validation loss decreased (0.141754 --> 0.141687).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2599275
	speed: 0.0635s/iter; left time: 1474.4730s
	iters: 200, epoch: 13 | loss: 3.3440564
	speed: 0.0441s/iter; left time: 1019.0842s
Epoch: 13 cost time: 14.862605810165405
Epoch: 13, Steps: 265 Train Loss: 3.2558 (Forecasting Loss:0.1884 + XiCon Loss:3.0675 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2168272
	speed: 0.0642s/iter; left time: 1473.1858s
	iters: 200, epoch: 14 | loss: 3.2066686
	speed: 0.0623s/iter; left time: 1423.6972s
Epoch: 14 cost time: 16.80768370628357
Epoch: 14, Steps: 265 Train Loss: 3.2566 (Forecasting Loss:0.1883 + XiCon Loss:3.0682 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0981
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3999839
	speed: 0.0611s/iter; left time: 1385.9749s
	iters: 200, epoch: 15 | loss: 3.2030919
	speed: 0.0626s/iter; left time: 1413.7664s
Epoch: 15 cost time: 16.366052865982056
Epoch: 15, Steps: 265 Train Loss: 3.2605 (Forecasting Loss:0.1882 + XiCon Loss:3.0723 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0981
Validation loss decreased (0.141687 --> 0.141675).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1938910
	speed: 0.0666s/iter; left time: 1492.9038s
	iters: 200, epoch: 16 | loss: 3.2158625
	speed: 0.0632s/iter; left time: 1411.5632s
Epoch: 16 cost time: 17.184430599212646
Epoch: 16, Steps: 265 Train Loss: 3.2593 (Forecasting Loss:0.1884 + XiCon Loss:3.0709 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0981
Validation loss decreased (0.141675 --> 0.141625).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2984917
	speed: 0.0671s/iter; left time: 1487.5695s
	iters: 200, epoch: 17 | loss: 3.3015637
	speed: 0.0644s/iter; left time: 1421.6527s
Epoch: 17 cost time: 17.396279335021973
Epoch: 17, Steps: 265 Train Loss: 3.2598 (Forecasting Loss:0.1885 + XiCon Loss:3.0713 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2126288
	speed: 0.0657s/iter; left time: 1439.2461s
	iters: 200, epoch: 18 | loss: 3.2811007
	speed: 0.0626s/iter; left time: 1363.6450s
Epoch: 18 cost time: 16.80558180809021
Epoch: 18, Steps: 265 Train Loss: 3.2580 (Forecasting Loss:0.1883 + XiCon Loss:3.0697 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2958617
	speed: 0.0637s/iter; left time: 1378.4279s
	iters: 200, epoch: 19 | loss: 3.2728405
	speed: 0.0619s/iter; left time: 1333.1531s
Epoch: 19 cost time: 16.69744062423706
Epoch: 19, Steps: 265 Train Loss: 3.2574 (Forecasting Loss:0.1884 + XiCon Loss:3.0690 x Lambda(1.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0981
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2735708
	speed: 0.0640s/iter; left time: 1367.0521s
	iters: 200, epoch: 20 | loss: 3.2015114
	speed: 0.0642s/iter; left time: 1365.8787s
Epoch: 20 cost time: 16.995152950286865
Epoch: 20, Steps: 265 Train Loss: 3.2588 (Forecasting Loss:0.1885 + XiCon Loss:3.0703 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2686458
	speed: 0.0688s/iter; left time: 1452.5635s
	iters: 200, epoch: 21 | loss: 3.2160854
	speed: 0.0621s/iter; left time: 1303.4954s
Epoch: 21 cost time: 16.945335865020752
Epoch: 21, Steps: 265 Train Loss: 3.2505 (Forecasting Loss:0.1883 + XiCon Loss:3.0622 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3110976
	speed: 0.0664s/iter; left time: 1382.6032s
	iters: 200, epoch: 22 | loss: 3.2200701
	speed: 0.0641s/iter; left time: 1328.5790s
Epoch: 22 cost time: 17.096572637557983
Epoch: 22, Steps: 265 Train Loss: 3.2538 (Forecasting Loss:0.1882 + XiCon Loss:3.0656 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0981
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2848608
	speed: 0.0638s/iter; left time: 1311.7986s
	iters: 200, epoch: 23 | loss: 3.2783191
	speed: 0.0615s/iter; left time: 1258.8693s
Epoch: 23 cost time: 16.753140926361084
Epoch: 23, Steps: 265 Train Loss: 3.2596 (Forecasting Loss:0.1884 + XiCon Loss:3.0711 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0981
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3265157
	speed: 0.0647s/iter; left time: 1313.8082s
	iters: 200, epoch: 24 | loss: 3.3133302
	speed: 0.0641s/iter; left time: 1294.9573s
Epoch: 24 cost time: 16.937620401382446
Epoch: 24, Steps: 265 Train Loss: 3.2614 (Forecasting Loss:0.1884 + XiCon Loss:3.0729 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.3071101
	speed: 0.0636s/iter; left time: 1274.6743s
	iters: 200, epoch: 25 | loss: 3.2246840
	speed: 0.0619s/iter; left time: 1233.8049s
Epoch: 25 cost time: 16.68309211730957
Epoch: 25, Steps: 265 Train Loss: 3.2618 (Forecasting Loss:0.1885 + XiCon Loss:3.0734 x Lambda(1.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0981
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2467055
	speed: 0.0659s/iter; left time: 1303.5994s
	iters: 200, epoch: 26 | loss: 3.2263217
	speed: 0.0564s/iter; left time: 1108.7882s
Epoch: 26 cost time: 15.051452875137329
Epoch: 26, Steps: 265 Train Loss: 3.2546 (Forecasting Loss:0.1884 + XiCon Loss:3.0662 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0981
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04369501769542694, mae:0.15242591500282288, mape:0.12051962316036224, mspe:0.02803323231637478 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.3149
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.4489288
	speed: 0.0654s/iter; left time: 1726.0408s
	iters: 200, epoch: 1 | loss: 3.3488467
	speed: 0.0599s/iter; left time: 1575.9030s
Epoch: 1 cost time: 16.296998262405396
Epoch: 1, Steps: 265 Train Loss: 3.4279 (Forecasting Loss:0.2104 + XiCon Loss:3.2175 x Lambda(1.0)), Vali MSE Loss: 0.1490 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.149021).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.6375799
	speed: 0.0650s/iter; left time: 1698.0770s
	iters: 200, epoch: 2 | loss: 3.4693780
	speed: 0.0653s/iter; left time: 1701.0703s
Epoch: 2 cost time: 17.051547288894653
Epoch: 2, Steps: 265 Train Loss: 3.5361 (Forecasting Loss:0.1983 + XiCon Loss:3.3378 x Lambda(1.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.0964
Validation loss decreased (0.149021 --> 0.145584).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2784202
	speed: 0.0658s/iter; left time: 1702.5121s
	iters: 200, epoch: 3 | loss: 3.2988467
	speed: 0.0628s/iter; left time: 1618.0924s
Epoch: 3 cost time: 16.772525310516357
Epoch: 3, Steps: 265 Train Loss: 3.4090 (Forecasting Loss:0.1935 + XiCon Loss:3.2156 x Lambda(1.0)), Vali MSE Loss: 0.1436 Test MSE Loss: 0.0957
Validation loss decreased (0.145584 --> 0.143621).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4109728
	speed: 0.0647s/iter; left time: 1655.8106s
	iters: 200, epoch: 4 | loss: 3.5002744
	speed: 0.0625s/iter; left time: 1594.5163s
Epoch: 4 cost time: 16.940327882766724
Epoch: 4, Steps: 265 Train Loss: 3.3941 (Forecasting Loss:0.1913 + XiCon Loss:3.2028 x Lambda(1.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0954
Validation loss decreased (0.143621 --> 0.142300).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2459924
	speed: 0.0665s/iter; left time: 1685.9469s
	iters: 200, epoch: 5 | loss: 3.4813199
	speed: 0.0624s/iter; left time: 1574.8367s
Epoch: 5 cost time: 17.101672887802124
Epoch: 5, Steps: 265 Train Loss: 3.4023 (Forecasting Loss:0.1903 + XiCon Loss:3.2121 x Lambda(1.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0944
Validation loss decreased (0.142300 --> 0.141979).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4293485
	speed: 0.0637s/iter; left time: 1597.6746s
	iters: 200, epoch: 6 | loss: 3.4500711
	speed: 0.0620s/iter; left time: 1547.4281s
Epoch: 6 cost time: 16.61676335334778
Epoch: 6, Steps: 265 Train Loss: 3.4031 (Forecasting Loss:0.1898 + XiCon Loss:3.2133 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
Validation loss decreased (0.141979 --> 0.141739).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3998349
	speed: 0.0654s/iter; left time: 1623.2870s
	iters: 200, epoch: 7 | loss: 3.3473706
	speed: 0.0623s/iter; left time: 1540.3019s
Epoch: 7 cost time: 16.914701223373413
Epoch: 7, Steps: 265 Train Loss: 3.4058 (Forecasting Loss:0.1894 + XiCon Loss:3.2164 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
Validation loss decreased (0.141739 --> 0.141622).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3889053
	speed: 0.0662s/iter; left time: 1626.0822s
	iters: 200, epoch: 8 | loss: 3.3879235
	speed: 0.0639s/iter; left time: 1562.8652s
Epoch: 8 cost time: 17.33233141899109
Epoch: 8, Steps: 265 Train Loss: 3.3969 (Forecasting Loss:0.1891 + XiCon Loss:3.2078 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2991438
	speed: 0.0634s/iter; left time: 1540.0657s
	iters: 200, epoch: 9 | loss: 3.3014746
	speed: 0.0593s/iter; left time: 1432.8291s
Epoch: 9 cost time: 16.33588671684265
Epoch: 9, Steps: 265 Train Loss: 3.3968 (Forecasting Loss:0.1890 + XiCon Loss:3.2078 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0947
Validation loss decreased (0.141622 --> 0.141594).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2855217
	speed: 0.0643s/iter; left time: 1543.4285s
	iters: 200, epoch: 10 | loss: 3.4943831
	speed: 0.0627s/iter; left time: 1500.3783s
Epoch: 10 cost time: 16.741713285446167
Epoch: 10, Steps: 265 Train Loss: 3.3954 (Forecasting Loss:0.1890 + XiCon Loss:3.2064 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2820120
	speed: 0.0636s/iter; left time: 1510.0650s
	iters: 200, epoch: 11 | loss: 3.4630561
	speed: 0.0641s/iter; left time: 1516.5019s
Epoch: 11 cost time: 17.036082983016968
Epoch: 11, Steps: 265 Train Loss: 3.3857 (Forecasting Loss:0.1889 + XiCon Loss:3.1968 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2684877
	speed: 0.0653s/iter; left time: 1533.6748s
	iters: 200, epoch: 12 | loss: 3.6060534
	speed: 0.0609s/iter; left time: 1423.3996s
Epoch: 12 cost time: 16.770039558410645
Epoch: 12, Steps: 265 Train Loss: 3.3950 (Forecasting Loss:0.1888 + XiCon Loss:3.2062 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3844841
	speed: 0.0665s/iter; left time: 1544.8496s
	iters: 200, epoch: 13 | loss: 3.4606981
	speed: 0.0618s/iter; left time: 1428.4286s
Epoch: 13 cost time: 17.01915407180786
Epoch: 13, Steps: 265 Train Loss: 3.3961 (Forecasting Loss:0.1888 + XiCon Loss:3.2073 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3436551
	speed: 0.0631s/iter; left time: 1448.6416s
	iters: 200, epoch: 14 | loss: 3.3355615
	speed: 0.0623s/iter; left time: 1424.3971s
Epoch: 14 cost time: 16.6517276763916
Epoch: 14, Steps: 265 Train Loss: 3.3960 (Forecasting Loss:0.1888 + XiCon Loss:3.2072 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2899580
	speed: 0.0653s/iter; left time: 1481.6454s
	iters: 200, epoch: 15 | loss: 3.3491764
	speed: 0.0616s/iter; left time: 1392.2077s
Epoch: 15 cost time: 16.616847276687622
Epoch: 15, Steps: 265 Train Loss: 3.3944 (Forecasting Loss:0.1888 + XiCon Loss:3.2056 x Lambda(1.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
Validation loss decreased (0.141594 --> 0.141536).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4493763
	speed: 0.0644s/iter; left time: 1443.4277s
	iters: 200, epoch: 16 | loss: 3.2126255
	speed: 0.0638s/iter; left time: 1425.0364s
Epoch: 16 cost time: 17.133089780807495
Epoch: 16, Steps: 265 Train Loss: 3.3889 (Forecasting Loss:0.1889 + XiCon Loss:3.2001 x Lambda(1.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
Validation loss decreased (0.141536 --> 0.141527).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3693924
	speed: 0.0637s/iter; left time: 1412.0654s
	iters: 200, epoch: 17 | loss: 3.6733541
	speed: 0.0623s/iter; left time: 1373.7641s
Epoch: 17 cost time: 16.760162353515625
Epoch: 17, Steps: 265 Train Loss: 3.3972 (Forecasting Loss:0.1888 + XiCon Loss:3.2085 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.6100936
	speed: 0.0646s/iter; left time: 1413.3975s
	iters: 200, epoch: 18 | loss: 3.4453986
	speed: 0.0642s/iter; left time: 1400.0344s
Epoch: 18 cost time: 16.879761457443237
Epoch: 18, Steps: 265 Train Loss: 3.3951 (Forecasting Loss:0.1888 + XiCon Loss:3.2063 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4123228
	speed: 0.0646s/iter; left time: 1397.4217s
	iters: 200, epoch: 19 | loss: 3.3089387
	speed: 0.0617s/iter; left time: 1328.7993s
Epoch: 19 cost time: 16.793128728866577
Epoch: 19, Steps: 265 Train Loss: 3.4010 (Forecasting Loss:0.1889 + XiCon Loss:3.2122 x Lambda(1.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
Validation loss decreased (0.141527 --> 0.141463).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3335338
	speed: 0.0646s/iter; left time: 1380.0824s
	iters: 200, epoch: 20 | loss: 3.3247654
	speed: 0.0622s/iter; left time: 1321.8772s
Epoch: 20 cost time: 16.842082023620605
Epoch: 20, Steps: 265 Train Loss: 3.3933 (Forecasting Loss:0.1888 + XiCon Loss:3.2044 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.5859685
	speed: 0.0658s/iter; left time: 1388.3083s
	iters: 200, epoch: 21 | loss: 3.3302670
	speed: 0.0618s/iter; left time: 1297.2079s
Epoch: 21 cost time: 16.86812424659729
Epoch: 21, Steps: 265 Train Loss: 3.3882 (Forecasting Loss:0.1889 + XiCon Loss:3.1993 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.4800572
	speed: 0.0638s/iter; left time: 1329.5680s
	iters: 200, epoch: 22 | loss: 3.4535913
	speed: 0.0644s/iter; left time: 1336.0307s
Epoch: 22 cost time: 16.841212272644043
Epoch: 22, Steps: 265 Train Loss: 3.3955 (Forecasting Loss:0.1889 + XiCon Loss:3.2066 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3142240
	speed: 0.0670s/iter; left time: 1378.1071s
	iters: 200, epoch: 23 | loss: 3.3377938
	speed: 0.0635s/iter; left time: 1300.8456s
Epoch: 23 cost time: 16.97407579421997
Epoch: 23, Steps: 265 Train Loss: 3.3816 (Forecasting Loss:0.1887 + XiCon Loss:3.1929 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2707846
	speed: 0.0646s/iter; left time: 1311.7961s
	iters: 200, epoch: 24 | loss: 3.2948916
	speed: 0.0633s/iter; left time: 1279.2059s
Epoch: 24 cost time: 16.926183700561523
Epoch: 24, Steps: 265 Train Loss: 3.4022 (Forecasting Loss:0.1889 + XiCon Loss:3.2132 x Lambda(1.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0948
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2030044
	speed: 0.0670s/iter; left time: 1342.7707s
	iters: 200, epoch: 25 | loss: 3.5207756
	speed: 0.0618s/iter; left time: 1232.8154s
Epoch: 25 cost time: 17.088523864746094
Epoch: 25, Steps: 265 Train Loss: 3.3940 (Forecasting Loss:0.1889 + XiCon Loss:3.2051 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3047745
	speed: 0.0638s/iter; left time: 1261.1421s
	iters: 200, epoch: 26 | loss: 3.3653221
	speed: 0.0613s/iter; left time: 1206.3561s
Epoch: 26 cost time: 16.630019426345825
Epoch: 26, Steps: 265 Train Loss: 3.3883 (Forecasting Loss:0.1888 + XiCon Loss:3.1995 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.4970725
	speed: 0.0634s/iter; left time: 1237.1019s
	iters: 200, epoch: 27 | loss: 3.2827191
	speed: 0.0628s/iter; left time: 1218.3529s
Epoch: 27 cost time: 16.704885244369507
Epoch: 27, Steps: 265 Train Loss: 3.4022 (Forecasting Loss:0.1887 + XiCon Loss:3.2135 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.6041822
	speed: 0.0659s/iter; left time: 1268.6929s
	iters: 200, epoch: 28 | loss: 3.5241218
	speed: 0.0640s/iter; left time: 1225.6556s
Epoch: 28 cost time: 16.941086769104004
Epoch: 28, Steps: 265 Train Loss: 3.4025 (Forecasting Loss:0.1888 + XiCon Loss:3.2137 x Lambda(1.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.5451028
	speed: 0.0658s/iter; left time: 1249.6730s
	iters: 200, epoch: 29 | loss: 3.4414775
	speed: 0.0624s/iter; left time: 1178.5218s
Epoch: 29 cost time: 17.220119953155518
Epoch: 29, Steps: 265 Train Loss: 3.4025 (Forecasting Loss:0.1887 + XiCon Loss:3.2137 x Lambda(1.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039604414254426956, mae:0.14994527399539948, mape:0.11896371096372604, mspe:0.02644045650959015 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0403+-0.00233, MAE:0.1503+-0.00150, MAPE:0.1193+-0.00093, MSPE:0.0268+-0.00088, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7375
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.5426643
	speed: 0.1091s/iter; left time: 2782.4491s
	iters: 200, epoch: 1 | loss: 3.3953323
	speed: 0.0963s/iter; left time: 2446.7055s
Epoch: 1 cost time: 26.768348455429077
Epoch: 1, Steps: 256 Train Loss: 3.5133 (Forecasting Loss:0.3040 + XiCon Loss:3.2093 x Lambda(1.0)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.1676
Validation loss decreased (inf --> 0.220922).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.8852580
	speed: 0.1075s/iter; left time: 2712.9420s
	iters: 200, epoch: 2 | loss: 3.5595119
	speed: 0.1398s/iter; left time: 3515.9315s
Epoch: 2 cost time: 32.59731197357178
Epoch: 2, Steps: 256 Train Loss: 3.6646 (Forecasting Loss:0.3053 + XiCon Loss:3.3593 x Lambda(1.0)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1664
Validation loss decreased (0.220922 --> 0.220754).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5616398
	speed: 0.1308s/iter; left time: 3267.5214s
	iters: 200, epoch: 3 | loss: 3.6648080
	speed: 0.1403s/iter; left time: 3492.5797s
Epoch: 3 cost time: 34.73277282714844
Epoch: 3, Steps: 256 Train Loss: 3.6380 (Forecasting Loss:0.2999 + XiCon Loss:3.3382 x Lambda(1.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1656
Validation loss decreased (0.220754 --> 0.220350).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.6330667
	speed: 0.1244s/iter; left time: 3077.4391s
	iters: 200, epoch: 4 | loss: 3.5853634
	speed: 0.1185s/iter; left time: 2918.4911s
Epoch: 4 cost time: 31.89459490776062
Epoch: 4, Steps: 256 Train Loss: 3.5599 (Forecasting Loss:0.2980 + XiCon Loss:3.2619 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4971347
	speed: 0.1349s/iter; left time: 3301.3150s
	iters: 200, epoch: 5 | loss: 3.5604703
	speed: 0.1023s/iter; left time: 2493.7531s
Epoch: 5 cost time: 31.425851106643677
Epoch: 5, Steps: 256 Train Loss: 3.5307 (Forecasting Loss:0.2968 + XiCon Loss:3.2339 x Lambda(1.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.1672
Validation loss decreased (0.220350 --> 0.219568).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4570026
	speed: 0.1412s/iter; left time: 3419.9804s
	iters: 200, epoch: 6 | loss: 3.5262291
	speed: 0.1295s/iter; left time: 3124.1545s
Epoch: 6 cost time: 32.33546853065491
Epoch: 6, Steps: 256 Train Loss: 3.5370 (Forecasting Loss:0.2963 + XiCon Loss:3.2407 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1667
Validation loss decreased (0.219568 --> 0.219404).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.6772962
	speed: 0.1364s/iter; left time: 3267.8019s
	iters: 200, epoch: 7 | loss: 3.6661477
	speed: 0.1367s/iter; left time: 3263.1573s
Epoch: 7 cost time: 33.909454584121704
Epoch: 7, Steps: 256 Train Loss: 3.5396 (Forecasting Loss:0.2959 + XiCon Loss:3.2438 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1667
Validation loss decreased (0.219404 --> 0.219118).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.7791479
	speed: 0.1361s/iter; left time: 3227.7139s
	iters: 200, epoch: 8 | loss: 3.6015329
	speed: 0.1388s/iter; left time: 3277.1905s
Epoch: 8 cost time: 35.03394317626953
Epoch: 8, Steps: 256 Train Loss: 3.5267 (Forecasting Loss:0.2958 + XiCon Loss:3.2310 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.6252978
	speed: 0.1093s/iter; left time: 2562.5394s
	iters: 200, epoch: 9 | loss: 3.5594492
	speed: 0.1338s/iter; left time: 3124.5558s
Epoch: 9 cost time: 31.931875228881836
Epoch: 9, Steps: 256 Train Loss: 3.5289 (Forecasting Loss:0.2957 + XiCon Loss:3.2332 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4214563
	speed: 0.1093s/iter; left time: 2536.1797s
	iters: 200, epoch: 10 | loss: 3.4384456
	speed: 0.1278s/iter; left time: 2951.9713s
Epoch: 10 cost time: 31.214353799819946
Epoch: 10, Steps: 256 Train Loss: 3.5375 (Forecasting Loss:0.2956 + XiCon Loss:3.2419 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1668
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.6054864
	speed: 0.1346s/iter; left time: 3086.7381s
	iters: 200, epoch: 11 | loss: 3.4381177
	speed: 0.1359s/iter; left time: 3104.5360s
Epoch: 11 cost time: 35.09745216369629
Epoch: 11, Steps: 256 Train Loss: 3.5427 (Forecasting Loss:0.2956 + XiCon Loss:3.2471 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1667
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.7335141
	speed: 0.1358s/iter; left time: 3080.8816s
	iters: 200, epoch: 12 | loss: 3.5315807
	speed: 0.1363s/iter; left time: 3077.2373s
Epoch: 12 cost time: 35.21498656272888
Epoch: 12, Steps: 256 Train Loss: 3.5306 (Forecasting Loss:0.2955 + XiCon Loss:3.2350 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1667
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5481484
	speed: 0.1354s/iter; left time: 3037.5947s
	iters: 200, epoch: 13 | loss: 3.5306628
	speed: 0.1365s/iter; left time: 3047.3348s
Epoch: 13 cost time: 34.882763624191284
Epoch: 13, Steps: 256 Train Loss: 3.5319 (Forecasting Loss:0.2955 + XiCon Loss:3.2364 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1667
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.5374994
	speed: 0.1280s/iter; left time: 2838.8814s
	iters: 200, epoch: 14 | loss: 3.4284651
	speed: 0.1114s/iter; left time: 2459.4343s
Epoch: 14 cost time: 31.777861833572388
Epoch: 14, Steps: 256 Train Loss: 3.5337 (Forecasting Loss:0.2955 + XiCon Loss:3.2382 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1667
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.6153765
	speed: 0.1344s/iter; left time: 2946.0454s
	iters: 200, epoch: 15 | loss: 3.7009010
	speed: 0.1033s/iter; left time: 2253.6419s
Epoch: 15 cost time: 31.19731593132019
Epoch: 15, Steps: 256 Train Loss: 3.5331 (Forecasting Loss:0.2955 + XiCon Loss:3.2376 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1667
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4798417
	speed: 0.1399s/iter; left time: 3031.4024s
	iters: 200, epoch: 16 | loss: 3.4667349
	speed: 0.1342s/iter; left time: 2894.3499s
Epoch: 16 cost time: 35.07664918899536
Epoch: 16, Steps: 256 Train Loss: 3.5337 (Forecasting Loss:0.2955 + XiCon Loss:3.2382 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1667
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3408260
	speed: 0.1414s/iter; left time: 3027.5031s
	iters: 200, epoch: 17 | loss: 3.5544226
	speed: 0.1309s/iter; left time: 2788.0719s
Epoch: 17 cost time: 35.13350200653076
Epoch: 17, Steps: 256 Train Loss: 3.5236 (Forecasting Loss:0.2955 + XiCon Loss:3.2281 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1667
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09329437464475632, mae:0.24020254611968994, mape:0.17520524561405182, mspe:0.047359827905893326 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.2285
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.4966044
	speed: 0.0692s/iter; left time: 1765.1515s
	iters: 200, epoch: 1 | loss: 3.3551025
	speed: 0.1209s/iter; left time: 3071.3914s
Epoch: 1 cost time: 25.782233715057373
Epoch: 1, Steps: 256 Train Loss: 3.4892 (Forecasting Loss:0.2935 + XiCon Loss:3.1957 x Lambda(1.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1552
Validation loss decreased (inf --> 0.207785).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.6289873
	speed: 0.1357s/iter; left time: 3426.0011s
	iters: 200, epoch: 2 | loss: 3.5939114
	speed: 0.1341s/iter; left time: 3371.7129s
Epoch: 2 cost time: 34.75507307052612
Epoch: 2, Steps: 256 Train Loss: 3.6195 (Forecasting Loss:0.3069 + XiCon Loss:3.3126 x Lambda(1.0)), Vali MSE Loss: 0.2238 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4426711
	speed: 0.1402s/iter; left time: 3504.3211s
	iters: 200, epoch: 3 | loss: 3.3843231
	speed: 0.1348s/iter; left time: 3355.7429s
Epoch: 3 cost time: 35.244046211242676
Epoch: 3, Steps: 256 Train Loss: 3.4362 (Forecasting Loss:0.3007 + XiCon Loss:3.1355 x Lambda(1.0)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1682
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4386976
	speed: 0.1336s/iter; left time: 3304.0861s
	iters: 200, epoch: 4 | loss: 3.3754239
	speed: 0.1338s/iter; left time: 3296.5950s
Epoch: 4 cost time: 34.60918068885803
Epoch: 4, Steps: 256 Train Loss: 3.4190 (Forecasting Loss:0.2982 + XiCon Loss:3.1207 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1686
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3836200
	speed: 0.1345s/iter; left time: 3291.4008s
	iters: 200, epoch: 5 | loss: 3.5002296
	speed: 0.1323s/iter; left time: 3224.3902s
Epoch: 5 cost time: 34.383997201919556
Epoch: 5, Steps: 256 Train Loss: 3.4106 (Forecasting Loss:0.2969 + XiCon Loss:3.1137 x Lambda(1.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1677
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4016159
	speed: 0.1365s/iter; left time: 3307.2241s
	iters: 200, epoch: 6 | loss: 3.4396529
	speed: 0.1357s/iter; left time: 3272.4601s
Epoch: 6 cost time: 35.308258295059204
Epoch: 6, Steps: 256 Train Loss: 3.4099 (Forecasting Loss:0.2963 + XiCon Loss:3.1136 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1675
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3884468
	speed: 0.1367s/iter; left time: 3276.2789s
	iters: 200, epoch: 7 | loss: 3.4517746
	speed: 0.1341s/iter; left time: 3200.2009s
Epoch: 7 cost time: 34.85502338409424
Epoch: 7, Steps: 256 Train Loss: 3.4092 (Forecasting Loss:0.2959 + XiCon Loss:3.1134 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1672
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4479876
	speed: 0.1359s/iter; left time: 3220.9279s
	iters: 200, epoch: 8 | loss: 3.3880744
	speed: 0.1314s/iter; left time: 3102.8070s
Epoch: 8 cost time: 34.37258744239807
Epoch: 8, Steps: 256 Train Loss: 3.4112 (Forecasting Loss:0.2957 + XiCon Loss:3.1155 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1674
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4942949
	speed: 0.1385s/iter; left time: 3249.3499s
	iters: 200, epoch: 9 | loss: 3.4415662
	speed: 0.1298s/iter; left time: 3030.8761s
Epoch: 9 cost time: 34.62150311470032
Epoch: 9, Steps: 256 Train Loss: 3.4114 (Forecasting Loss:0.2956 + XiCon Loss:3.1159 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1673
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3524628
	speed: 0.1379s/iter; left time: 3198.9103s
	iters: 200, epoch: 10 | loss: 3.3211446
	speed: 0.1290s/iter; left time: 2980.2687s
Epoch: 10 cost time: 34.56685209274292
Epoch: 10, Steps: 256 Train Loss: 3.4121 (Forecasting Loss:0.2955 + XiCon Loss:3.1166 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1673
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4287782
	speed: 0.1381s/iter; left time: 3167.1243s
	iters: 200, epoch: 11 | loss: 3.3572114
	speed: 0.1290s/iter; left time: 2947.5484s
Epoch: 11 cost time: 34.6671507358551
Epoch: 11, Steps: 256 Train Loss: 3.4100 (Forecasting Loss:0.2954 + XiCon Loss:3.1145 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1673
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.0842277780175209, mae:0.2262442409992218, mape:0.16659699380397797, mspe:0.04404926300048828 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.5219
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.4725757
	speed: 0.1159s/iter; left time: 2955.9419s
	iters: 200, epoch: 1 | loss: 3.4085860
	speed: 0.1175s/iter; left time: 2985.7473s
Epoch: 1 cost time: 29.938605546951294
Epoch: 1, Steps: 256 Train Loss: 3.4753 (Forecasting Loss:0.3013 + XiCon Loss:3.1740 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1570
Validation loss decreased (inf --> 0.211397).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.8491745
	speed: 0.1465s/iter; left time: 3699.2774s
	iters: 200, epoch: 2 | loss: 3.6561337
	speed: 0.1387s/iter; left time: 3488.6589s
Epoch: 2 cost time: 36.374295473098755
Epoch: 2, Steps: 256 Train Loss: 3.5904 (Forecasting Loss:0.3053 + XiCon Loss:3.2851 x Lambda(1.0)), Vali MSE Loss: 0.2234 Test MSE Loss: 0.1691
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.6120172
	speed: 0.1372s/iter; left time: 3428.6132s
	iters: 200, epoch: 3 | loss: 3.5087316
	speed: 0.1347s/iter; left time: 3352.0230s
Epoch: 3 cost time: 34.72638654708862
Epoch: 3, Steps: 256 Train Loss: 3.4911 (Forecasting Loss:0.3014 + XiCon Loss:3.1897 x Lambda(1.0)), Vali MSE Loss: 0.2218 Test MSE Loss: 0.1689
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.6437452
	speed: 0.1343s/iter; left time: 3321.9196s
	iters: 200, epoch: 4 | loss: 3.5471139
	speed: 0.1401s/iter; left time: 3451.5100s
Epoch: 4 cost time: 34.97873663902283
Epoch: 4, Steps: 256 Train Loss: 3.4779 (Forecasting Loss:0.2980 + XiCon Loss:3.1800 x Lambda(1.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1675
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5501394
	speed: 0.1335s/iter; left time: 3267.2966s
	iters: 200, epoch: 5 | loss: 3.4241719
	speed: 0.1347s/iter; left time: 3282.4432s
Epoch: 5 cost time: 34.20496940612793
Epoch: 5, Steps: 256 Train Loss: 3.4892 (Forecasting Loss:0.2965 + XiCon Loss:3.1927 x Lambda(1.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1669
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4860394
	speed: 0.1341s/iter; left time: 3247.1370s
	iters: 200, epoch: 6 | loss: 3.4664576
	speed: 0.1396s/iter; left time: 3367.4021s
Epoch: 6 cost time: 35.059353828430176
Epoch: 6, Steps: 256 Train Loss: 3.4799 (Forecasting Loss:0.2959 + XiCon Loss:3.1840 x Lambda(1.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1667
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5139215
	speed: 0.1315s/iter; left time: 3152.1497s
	iters: 200, epoch: 7 | loss: 3.4433455
	speed: 0.1342s/iter; left time: 3201.9901s
Epoch: 7 cost time: 34.181793212890625
Epoch: 7, Steps: 256 Train Loss: 3.4489 (Forecasting Loss:0.2955 + XiCon Loss:3.1533 x Lambda(1.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1668
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4802907
	speed: 0.1279s/iter; left time: 3032.2225s
	iters: 200, epoch: 8 | loss: 3.4471436
	speed: 0.1344s/iter; left time: 3172.7959s
Epoch: 8 cost time: 33.947113037109375
Epoch: 8, Steps: 256 Train Loss: 3.4459 (Forecasting Loss:0.2953 + XiCon Loss:3.1505 x Lambda(1.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.1666
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4893150
	speed: 0.1311s/iter; left time: 3073.8327s
	iters: 200, epoch: 9 | loss: 3.4726429
	speed: 0.1389s/iter; left time: 3243.1374s
Epoch: 9 cost time: 34.724570751190186
Epoch: 9, Steps: 256 Train Loss: 3.4457 (Forecasting Loss:0.2952 + XiCon Loss:3.1505 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1666
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.5673561
	speed: 0.1232s/iter; left time: 2858.6897s
	iters: 200, epoch: 10 | loss: 3.3828185
	speed: 0.1164s/iter; left time: 2688.4241s
Epoch: 10 cost time: 29.20537519454956
Epoch: 10, Steps: 256 Train Loss: 3.4531 (Forecasting Loss:0.2952 + XiCon Loss:3.1579 x Lambda(1.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1666
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3177936
	speed: 0.1310s/iter; left time: 3005.2427s
	iters: 200, epoch: 11 | loss: 3.4784029
	speed: 0.1371s/iter; left time: 3131.7481s
Epoch: 11 cost time: 34.32727313041687
Epoch: 11, Steps: 256 Train Loss: 3.4502 (Forecasting Loss:0.2951 + XiCon Loss:3.1551 x Lambda(1.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.1666
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08629921823740005, mae:0.22769881784915924, mape:0.16637495160102844, mspe:0.04341365024447441 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.1042
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.5153422
	speed: 0.1191s/iter; left time: 3037.9289s
	iters: 200, epoch: 1 | loss: 3.4104686
	speed: 0.0838s/iter; left time: 2129.4709s
Epoch: 1 cost time: 24.594514846801758
Epoch: 1, Steps: 256 Train Loss: 3.5067 (Forecasting Loss:0.3054 + XiCon Loss:3.2013 x Lambda(1.0)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1697
Validation loss decreased (inf --> 0.222594).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5659666
	speed: 0.1436s/iter; left time: 3626.0872s
	iters: 200, epoch: 2 | loss: 3.7165318
	speed: 0.1359s/iter; left time: 3416.0120s
Epoch: 2 cost time: 33.97951602935791
Epoch: 2, Steps: 256 Train Loss: 3.7127 (Forecasting Loss:0.3091 + XiCon Loss:3.4036 x Lambda(1.0)), Vali MSE Loss: 0.2256 Test MSE Loss: 0.1716
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.5982430
	speed: 0.1357s/iter; left time: 3390.0198s
	iters: 200, epoch: 3 | loss: 3.5959637
	speed: 0.1371s/iter; left time: 3411.7687s
Epoch: 3 cost time: 34.834909439086914
Epoch: 3, Steps: 256 Train Loss: 3.6729 (Forecasting Loss:0.3006 + XiCon Loss:3.3723 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1688
Validation loss decreased (0.222594 --> 0.222229).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.5811212
	speed: 0.0861s/iter; left time: 2129.1808s
	iters: 200, epoch: 4 | loss: 3.5201480
	speed: 0.1308s/iter; left time: 3222.6501s
Epoch: 4 cost time: 29.077985048294067
Epoch: 4, Steps: 256 Train Loss: 3.5937 (Forecasting Loss:0.2979 + XiCon Loss:3.2958 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1669
Validation loss decreased (0.222229 --> 0.220633).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4099779
	speed: 0.1299s/iter; left time: 3180.0454s
	iters: 200, epoch: 5 | loss: 3.6950662
	speed: 0.0937s/iter; left time: 2285.1967s
Epoch: 5 cost time: 30.07366371154785
Epoch: 5, Steps: 256 Train Loss: 3.5334 (Forecasting Loss:0.2970 + XiCon Loss:3.2365 x Lambda(1.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1668
Validation loss decreased (0.220633 --> 0.219843).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4574800
	speed: 0.1349s/iter; left time: 3266.2342s
	iters: 200, epoch: 6 | loss: 3.4090018
	speed: 0.1096s/iter; left time: 2642.6460s
Epoch: 6 cost time: 28.743570566177368
Epoch: 6, Steps: 256 Train Loss: 3.5268 (Forecasting Loss:0.2962 + XiCon Loss:3.2306 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
Validation loss decreased (0.219843 --> 0.219104).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3678322
	speed: 0.1370s/iter; left time: 3282.7275s
	iters: 200, epoch: 7 | loss: 3.4526405
	speed: 0.1400s/iter; left time: 3341.3768s
Epoch: 7 cost time: 34.41336727142334
Epoch: 7, Steps: 256 Train Loss: 3.5200 (Forecasting Loss:0.2959 + XiCon Loss:3.2240 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1666
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5044191
	speed: 0.1208s/iter; left time: 2863.0972s
	iters: 200, epoch: 8 | loss: 3.4297822
	speed: 0.1323s/iter; left time: 3123.7604s
Epoch: 8 cost time: 33.37720823287964
Epoch: 8, Steps: 256 Train Loss: 3.5079 (Forecasting Loss:0.2957 + XiCon Loss:3.2122 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1667
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4271746
	speed: 0.0907s/iter; left time: 2127.6313s
	iters: 200, epoch: 9 | loss: 3.4849377
	speed: 0.1265s/iter; left time: 2954.3782s
Epoch: 9 cost time: 29.339751958847046
Epoch: 9, Steps: 256 Train Loss: 3.5055 (Forecasting Loss:0.2957 + XiCon Loss:3.2098 x Lambda(1.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1667
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4833734
	speed: 0.1302s/iter; left time: 3021.2896s
	iters: 200, epoch: 10 | loss: 3.6710427
	speed: 0.1276s/iter; left time: 2946.3189s
Epoch: 10 cost time: 33.63119673728943
Epoch: 10, Steps: 256 Train Loss: 3.5132 (Forecasting Loss:0.2956 + XiCon Loss:3.2176 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1667
Validation loss decreased (0.219104 --> 0.219084).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3742385
	speed: 0.1338s/iter; left time: 3069.3071s
	iters: 200, epoch: 11 | loss: 3.4243910
	speed: 0.1311s/iter; left time: 2994.3487s
Epoch: 11 cost time: 34.045610189437866
Epoch: 11, Steps: 256 Train Loss: 3.5012 (Forecasting Loss:0.2956 + XiCon Loss:3.2056 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1666
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4347935
	speed: 0.1320s/iter; left time: 2994.8254s
	iters: 200, epoch: 12 | loss: 3.5177011
	speed: 0.0844s/iter; left time: 1907.0635s
Epoch: 12 cost time: 28.95862627029419
Epoch: 12, Steps: 256 Train Loss: 3.4986 (Forecasting Loss:0.2955 + XiCon Loss:3.2030 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1666
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4819980
	speed: 0.1324s/iter; left time: 2969.5919s
	iters: 200, epoch: 13 | loss: 3.4885149
	speed: 0.1264s/iter; left time: 2823.4657s
Epoch: 13 cost time: 31.004608392715454
Epoch: 13, Steps: 256 Train Loss: 3.5031 (Forecasting Loss:0.2955 + XiCon Loss:3.2075 x Lambda(1.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.1666
Validation loss decreased (0.219084 --> 0.218851).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3890464
	speed: 0.1341s/iter; left time: 2973.5414s
	iters: 200, epoch: 14 | loss: 3.5377560
	speed: 0.1336s/iter; left time: 2948.0987s
Epoch: 14 cost time: 34.145150661468506
Epoch: 14, Steps: 256 Train Loss: 3.5059 (Forecasting Loss:0.2955 + XiCon Loss:3.2104 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.5890698
	speed: 0.1352s/iter; left time: 2962.5570s
	iters: 200, epoch: 15 | loss: 3.5263243
	speed: 0.1350s/iter; left time: 2945.9488s
Epoch: 15 cost time: 34.48687434196472
Epoch: 15, Steps: 256 Train Loss: 3.4962 (Forecasting Loss:0.2955 + XiCon Loss:3.2007 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.5289145
	speed: 0.0917s/iter; left time: 1986.6344s
	iters: 200, epoch: 16 | loss: 3.4800029
	speed: 0.1343s/iter; left time: 2895.1525s
Epoch: 16 cost time: 30.151121377944946
Epoch: 16, Steps: 256 Train Loss: 3.4999 (Forecasting Loss:0.2955 + XiCon Loss:3.2044 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.6683457
	speed: 0.1279s/iter; left time: 2738.2267s
	iters: 200, epoch: 17 | loss: 3.3798020
	speed: 0.1350s/iter; left time: 2876.7982s
Epoch: 17 cost time: 34.05323767662048
Epoch: 17, Steps: 256 Train Loss: 3.5031 (Forecasting Loss:0.2955 + XiCon Loss:3.2076 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1666
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3925545
	speed: 0.1247s/iter; left time: 2636.5490s
	iters: 200, epoch: 18 | loss: 3.5430567
	speed: 0.1342s/iter; left time: 2825.3371s
Epoch: 18 cost time: 33.550450563430786
Epoch: 18, Steps: 256 Train Loss: 3.4997 (Forecasting Loss:0.2955 + XiCon Loss:3.2042 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4358437
	speed: 0.1306s/iter; left time: 2728.0338s
	iters: 200, epoch: 19 | loss: 3.5231972
	speed: 0.1320s/iter; left time: 2743.8075s
Epoch: 19 cost time: 34.0023295879364
Epoch: 19, Steps: 256 Train Loss: 3.4988 (Forecasting Loss:0.2955 + XiCon Loss:3.2033 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3541684
	speed: 0.1289s/iter; left time: 2660.9118s
	iters: 200, epoch: 20 | loss: 3.4244254
	speed: 0.1357s/iter; left time: 2786.7543s
Epoch: 20 cost time: 34.22934055328369
Epoch: 20, Steps: 256 Train Loss: 3.4974 (Forecasting Loss:0.2955 + XiCon Loss:3.2019 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1666
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.5641773
	speed: 0.1291s/iter; left time: 2632.0840s
	iters: 200, epoch: 21 | loss: 3.3628829
	speed: 0.1362s/iter; left time: 2762.6643s
Epoch: 21 cost time: 34.093778133392334
Epoch: 21, Steps: 256 Train Loss: 3.5011 (Forecasting Loss:0.2955 + XiCon Loss:3.2056 x Lambda(1.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.1666
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5073621
	speed: 0.1303s/iter; left time: 2621.7378s
	iters: 200, epoch: 22 | loss: 3.5474894
	speed: 0.1350s/iter; left time: 2704.0454s
Epoch: 22 cost time: 33.83293795585632
Epoch: 22, Steps: 256 Train Loss: 3.4967 (Forecasting Loss:0.2955 + XiCon Loss:3.2012 x Lambda(1.0)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.1666
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.6336224
	speed: 0.1314s/iter; left time: 2611.3178s
	iters: 200, epoch: 23 | loss: 3.4419742
	speed: 0.1282s/iter; left time: 2534.9178s
Epoch: 23 cost time: 33.53340196609497
Epoch: 23, Steps: 256 Train Loss: 3.5024 (Forecasting Loss:0.2955 + XiCon Loss:3.2069 x Lambda(1.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1666
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.0931326225399971, mae:0.24012316763401031, mape:0.17501547932624817, mspe:0.04714664816856384 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.2341
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.5239344
	speed: 0.1259s/iter; left time: 3209.3524s
	iters: 200, epoch: 1 | loss: 3.4132977
	speed: 0.1201s/iter; left time: 3050.4869s
Epoch: 1 cost time: 30.91864824295044
Epoch: 1, Steps: 256 Train Loss: 3.5065 (Forecasting Loss:0.2956 + XiCon Loss:3.2108 x Lambda(1.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1530
Validation loss decreased (inf --> 0.201159).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.7192941
	speed: 0.1519s/iter; left time: 3834.0105s
	iters: 200, epoch: 2 | loss: 3.5184915
	speed: 0.1338s/iter; left time: 3364.0253s
Epoch: 2 cost time: 35.71184206008911
Epoch: 2, Steps: 256 Train Loss: 3.5764 (Forecasting Loss:0.3072 + XiCon Loss:3.2692 x Lambda(1.0)), Vali MSE Loss: 0.2233 Test MSE Loss: 0.1687
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4380481
	speed: 0.1393s/iter; left time: 3480.6385s
	iters: 200, epoch: 3 | loss: 3.5520318
	speed: 0.1302s/iter; left time: 3240.5004s
Epoch: 3 cost time: 34.11566352844238
Epoch: 3, Steps: 256 Train Loss: 3.4371 (Forecasting Loss:0.3004 + XiCon Loss:3.1367 x Lambda(1.0)), Vali MSE Loss: 0.2215 Test MSE Loss: 0.1679
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3676853
	speed: 0.1372s/iter; left time: 3392.7727s
	iters: 200, epoch: 4 | loss: 3.3435857
	speed: 0.1306s/iter; left time: 3217.0434s
Epoch: 4 cost time: 34.286808490753174
Epoch: 4, Steps: 256 Train Loss: 3.4104 (Forecasting Loss:0.2978 + XiCon Loss:3.1126 x Lambda(1.0)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1663
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3905797
	speed: 0.1361s/iter; left time: 3330.3320s
	iters: 200, epoch: 5 | loss: 3.4052310
	speed: 0.1302s/iter; left time: 3173.7916s
Epoch: 5 cost time: 34.29516887664795
Epoch: 5, Steps: 256 Train Loss: 3.4020 (Forecasting Loss:0.2968 + XiCon Loss:3.1052 x Lambda(1.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1665
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4590373
	speed: 0.1377s/iter; left time: 3336.2204s
	iters: 200, epoch: 6 | loss: 3.3415594
	speed: 0.1295s/iter; left time: 3124.0067s
Epoch: 6 cost time: 33.99463105201721
Epoch: 6, Steps: 256 Train Loss: 3.3922 (Forecasting Loss:0.2960 + XiCon Loss:3.0962 x Lambda(1.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1659
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4660952
	speed: 0.1354s/iter; left time: 3243.9152s
	iters: 200, epoch: 7 | loss: 3.3966441
	speed: 0.1288s/iter; left time: 3074.3716s
Epoch: 7 cost time: 34.18755578994751
Epoch: 7, Steps: 256 Train Loss: 3.3963 (Forecasting Loss:0.2957 + XiCon Loss:3.1006 x Lambda(1.0)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1659
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3953547
	speed: 0.1366s/iter; left time: 3239.3355s
	iters: 200, epoch: 8 | loss: 3.4063282
	speed: 0.1297s/iter; left time: 3062.2393s
Epoch: 8 cost time: 34.18566942214966
Epoch: 8, Steps: 256 Train Loss: 3.3949 (Forecasting Loss:0.2955 + XiCon Loss:3.0994 x Lambda(1.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1657
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3632545
	speed: 0.1352s/iter; left time: 3170.5143s
	iters: 200, epoch: 9 | loss: 3.4196997
	speed: 0.1305s/iter; left time: 3048.3027s
Epoch: 9 cost time: 34.25849723815918
Epoch: 9, Steps: 256 Train Loss: 3.3860 (Forecasting Loss:0.2954 + XiCon Loss:3.0906 x Lambda(1.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1658
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3456819
	speed: 0.1373s/iter; left time: 3185.3961s
	iters: 200, epoch: 10 | loss: 3.3560216
	speed: 0.1256s/iter; left time: 2900.6805s
Epoch: 10 cost time: 33.8501238822937
Epoch: 10, Steps: 256 Train Loss: 3.3940 (Forecasting Loss:0.2954 + XiCon Loss:3.0986 x Lambda(1.0)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1658
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3286133
	speed: 0.1389s/iter; left time: 3185.7238s
	iters: 200, epoch: 11 | loss: 3.3375890
	speed: 0.1320s/iter; left time: 3014.0530s
Epoch: 11 cost time: 34.81061601638794
Epoch: 11, Steps: 256 Train Loss: 3.3921 (Forecasting Loss:0.2953 + XiCon Loss:3.0968 x Lambda(1.0)), Vali MSE Loss: 0.2199 Test MSE Loss: 0.1658
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08238355815410614, mae:0.22368812561035156, mape:0.16660839319229126, mspe:0.045182086527347565 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0879+-0.00630, MAE:0.2316+-0.00988, MAPE:0.1700+-0.00584, MSPE:0.0454+-0.00221, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 20.8101
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6190789
	speed: 0.1309s/iter; left time: 3181.0834s
	iters: 200, epoch: 1 | loss: 3.5183451
	speed: 0.1291s/iter; left time: 3124.3247s
Epoch: 1 cost time: 32.445252418518066
Epoch: 1, Steps: 244 Train Loss: 3.6137 (Forecasting Loss:0.3663 + XiCon Loss:3.2474 x Lambda(1.0)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.1687
Validation loss decreased (inf --> 0.262239).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.5929708
	speed: 0.2064s/iter; left time: 4964.4843s
	iters: 200, epoch: 2 | loss: 3.4952154
	speed: 0.1910s/iter; left time: 4575.5179s
Epoch: 2 cost time: 48.537424087524414
Epoch: 2, Steps: 244 Train Loss: 3.5152 (Forecasting Loss:0.3696 + XiCon Loss:3.1456 x Lambda(1.0)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1710
Validation loss decreased (0.262239 --> 0.261924).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.3842194
	speed: 0.1597s/iter; left time: 3802.7307s
	iters: 200, epoch: 3 | loss: 3.3909326
	speed: 0.1858s/iter; left time: 4406.9720s
Epoch: 3 cost time: 43.34086585044861
Epoch: 3, Steps: 244 Train Loss: 3.4220 (Forecasting Loss:0.3472 + XiCon Loss:3.0748 x Lambda(1.0)), Vali MSE Loss: 0.2535 Test MSE Loss: 0.1599
Validation loss decreased (0.261924 --> 0.253545).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.3514280
	speed: 0.1605s/iter; left time: 3781.7440s
	iters: 200, epoch: 4 | loss: 3.3527787
	speed: 0.1784s/iter; left time: 4186.0072s
Epoch: 4 cost time: 42.01077055931091
Epoch: 4, Steps: 244 Train Loss: 3.3861 (Forecasting Loss:0.3250 + XiCon Loss:3.0610 x Lambda(1.0)), Vali MSE Loss: 0.2691 Test MSE Loss: 0.1671
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.3628213
	speed: 0.1778s/iter; left time: 4146.7598s
	iters: 200, epoch: 5 | loss: 3.4039717
	speed: 0.1782s/iter; left time: 4138.7615s
Epoch: 5 cost time: 43.97430372238159
Epoch: 5, Steps: 244 Train Loss: 3.3642 (Forecasting Loss:0.3068 + XiCon Loss:3.0575 x Lambda(1.0)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1681
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2982852
	speed: 0.1759s/iter; left time: 4059.3629s
	iters: 200, epoch: 6 | loss: 3.3628082
	speed: 0.1657s/iter; left time: 3806.9505s
Epoch: 6 cost time: 42.505587339401245
Epoch: 6, Steps: 244 Train Loss: 3.3560 (Forecasting Loss:0.2978 + XiCon Loss:3.0581 x Lambda(1.0)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1692
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.3201249
	speed: 0.1887s/iter; left time: 4308.9249s
	iters: 200, epoch: 7 | loss: 3.3130240
	speed: 0.1676s/iter; left time: 3810.7576s
Epoch: 7 cost time: 44.16763973236084
Epoch: 7, Steps: 244 Train Loss: 3.3503 (Forecasting Loss:0.2941 + XiCon Loss:3.0562 x Lambda(1.0)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1632
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.3972564
	speed: 0.1805s/iter; left time: 4077.1506s
	iters: 200, epoch: 8 | loss: 3.3122032
	speed: 0.1748s/iter; left time: 3932.0502s
Epoch: 8 cost time: 44.12233591079712
Epoch: 8, Steps: 244 Train Loss: 3.3442 (Forecasting Loss:0.2915 + XiCon Loss:3.0527 x Lambda(1.0)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1652
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.3437378
	speed: 0.1795s/iter; left time: 4011.6547s
	iters: 200, epoch: 9 | loss: 3.3156819
	speed: 0.1715s/iter; left time: 3815.5819s
Epoch: 9 cost time: 43.80888891220093
Epoch: 9, Steps: 244 Train Loss: 3.3402 (Forecasting Loss:0.2898 + XiCon Loss:3.0504 x Lambda(1.0)), Vali MSE Loss: 0.2664 Test MSE Loss: 0.1669
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2968421
	speed: 0.1726s/iter; left time: 3815.4903s
	iters: 200, epoch: 10 | loss: 3.3259485
	speed: 0.1743s/iter; left time: 3834.3776s
Epoch: 10 cost time: 43.3787157535553
Epoch: 10, Steps: 244 Train Loss: 3.3397 (Forecasting Loss:0.2900 + XiCon Loss:3.0497 x Lambda(1.0)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1660
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.3227818
	speed: 0.1904s/iter; left time: 4163.3127s
	iters: 200, epoch: 11 | loss: 3.3255203
	speed: 0.1893s/iter; left time: 4120.0288s
Epoch: 11 cost time: 46.10011887550354
Epoch: 11, Steps: 244 Train Loss: 3.3379 (Forecasting Loss:0.2895 + XiCon Loss:3.0483 x Lambda(1.0)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.1650
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.3038180
	speed: 0.1643s/iter; left time: 3552.3779s
	iters: 200, epoch: 12 | loss: 3.3597751
	speed: 0.1891s/iter; left time: 4068.9574s
Epoch: 12 cost time: 43.847094774246216
Epoch: 12, Steps: 244 Train Loss: 3.3407 (Forecasting Loss:0.2894 + XiCon Loss:3.0513 x Lambda(1.0)), Vali MSE Loss: 0.2652 Test MSE Loss: 0.1655
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.3840518
	speed: 0.1867s/iter; left time: 3990.8099s
	iters: 200, epoch: 13 | loss: 3.3618362
	speed: 0.1889s/iter; left time: 4019.3404s
Epoch: 13 cost time: 46.16793346405029
Epoch: 13, Steps: 244 Train Loss: 3.3412 (Forecasting Loss:0.2890 + XiCon Loss:3.0521 x Lambda(1.0)), Vali MSE Loss: 0.2653 Test MSE Loss: 0.1656
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08737433701753616, mae:0.23236873745918274, mape:0.16613881289958954, mspe:0.042508866637945175 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8295
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.5850341
	speed: 0.1510s/iter; left time: 3670.3809s
	iters: 200, epoch: 1 | loss: 3.5020711
	speed: 0.1447s/iter; left time: 3502.9206s
Epoch: 1 cost time: 36.38186287879944
Epoch: 1, Steps: 244 Train Loss: 3.5913 (Forecasting Loss:0.3640 + XiCon Loss:3.2273 x Lambda(1.0)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1668
Validation loss decreased (inf --> 0.263990).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.5566750
	speed: 0.2043s/iter; left time: 4913.7085s
	iters: 200, epoch: 2 | loss: 3.4934976
	speed: 0.1794s/iter; left time: 4298.6606s
Epoch: 2 cost time: 45.96176075935364
Epoch: 2, Steps: 244 Train Loss: 3.5210 (Forecasting Loss:0.3453 + XiCon Loss:3.1757 x Lambda(1.0)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1608
Validation loss decreased (0.263990 --> 0.239767).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.3252854
	speed: 0.1750s/iter; left time: 4167.5284s
	iters: 200, epoch: 3 | loss: 3.3276236
	speed: 0.1757s/iter; left time: 4167.1617s
Epoch: 3 cost time: 42.81647515296936
Epoch: 3, Steps: 244 Train Loss: 3.3436 (Forecasting Loss:0.3058 + XiCon Loss:3.0378 x Lambda(1.0)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.1544
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.3318114
	speed: 0.1838s/iter; left time: 4330.8943s
	iters: 200, epoch: 4 | loss: 3.2600260
	speed: 0.1756s/iter; left time: 4121.9140s
Epoch: 4 cost time: 43.448354721069336
Epoch: 4, Steps: 244 Train Loss: 3.3033 (Forecasting Loss:0.2841 + XiCon Loss:3.0192 x Lambda(1.0)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.1541
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2707589
	speed: 0.1760s/iter; left time: 4105.2778s
	iters: 200, epoch: 5 | loss: 3.2545838
	speed: 0.1725s/iter; left time: 4007.1557s
Epoch: 5 cost time: 42.984132051467896
Epoch: 5, Steps: 244 Train Loss: 3.2875 (Forecasting Loss:0.2762 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1617
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2672818
	speed: 0.1745s/iter; left time: 4027.8966s
	iters: 200, epoch: 6 | loss: 3.2928045
	speed: 0.1744s/iter; left time: 4008.4954s
Epoch: 6 cost time: 42.43766450881958
Epoch: 6, Steps: 244 Train Loss: 3.2755 (Forecasting Loss:0.2701 + XiCon Loss:3.0054 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1573
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2221048
	speed: 0.1748s/iter; left time: 3991.5544s
	iters: 200, epoch: 7 | loss: 3.2885628
	speed: 0.1708s/iter; left time: 3883.5015s
Epoch: 7 cost time: 42.26297187805176
Epoch: 7, Steps: 244 Train Loss: 3.2743 (Forecasting Loss:0.2677 + XiCon Loss:3.0066 x Lambda(1.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1546
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2806451
	speed: 0.1766s/iter; left time: 3989.5382s
	iters: 200, epoch: 8 | loss: 3.2606723
	speed: 0.1710s/iter; left time: 3846.3524s
Epoch: 8 cost time: 42.44189691543579
Epoch: 8, Steps: 244 Train Loss: 3.2696 (Forecasting Loss:0.2665 + XiCon Loss:3.0031 x Lambda(1.0)), Vali MSE Loss: 0.2419 Test MSE Loss: 0.1572
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.2728770
	speed: 0.1744s/iter; left time: 3897.3444s
	iters: 200, epoch: 9 | loss: 3.3166866
	speed: 0.1689s/iter; left time: 3756.7736s
Epoch: 9 cost time: 42.16672873497009
Epoch: 9, Steps: 244 Train Loss: 3.2701 (Forecasting Loss:0.2651 + XiCon Loss:3.0050 x Lambda(1.0)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.1564
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2485595
	speed: 0.1732s/iter; left time: 3828.7801s
	iters: 200, epoch: 10 | loss: 3.2427671
	speed: 0.1718s/iter; left time: 3781.0388s
Epoch: 10 cost time: 41.96691632270813
Epoch: 10, Steps: 244 Train Loss: 3.2664 (Forecasting Loss:0.2645 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.2430 Test MSE Loss: 0.1551
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2914088
	speed: 0.1712s/iter; left time: 3743.0519s
	iters: 200, epoch: 11 | loss: 3.2552605
	speed: 0.1720s/iter; left time: 3743.0113s
Epoch: 11 cost time: 41.86495804786682
Epoch: 11, Steps: 244 Train Loss: 3.2681 (Forecasting Loss:0.2648 + XiCon Loss:3.0033 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1554
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2877917
	speed: 0.1726s/iter; left time: 3731.4741s
	iters: 200, epoch: 12 | loss: 3.2432427
	speed: 0.1728s/iter; left time: 3717.4807s
Epoch: 12 cost time: 42.286049365997314
Epoch: 12, Steps: 244 Train Loss: 3.2677 (Forecasting Loss:0.2646 + XiCon Loss:3.0031 x Lambda(1.0)), Vali MSE Loss: 0.2436 Test MSE Loss: 0.1556
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08809075504541397, mae:0.23350465297698975, mape:0.16696007549762726, mspe:0.042935047298669815 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6370158
	speed: 0.1497s/iter; left time: 3637.8493s
	iters: 200, epoch: 1 | loss: 3.5444884
	speed: 0.1529s/iter; left time: 3700.7350s
Epoch: 1 cost time: 37.229220390319824
Epoch: 1, Steps: 244 Train Loss: 3.6326 (Forecasting Loss:0.3649 + XiCon Loss:3.2678 x Lambda(1.0)), Vali MSE Loss: 0.2625 Test MSE Loss: 0.1705
Validation loss decreased (inf --> 0.262498).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.4972131
	speed: 0.2004s/iter; left time: 4820.5026s
	iters: 200, epoch: 2 | loss: 3.5126052
	speed: 0.1967s/iter; left time: 4711.7467s
Epoch: 2 cost time: 47.68272590637207
Epoch: 2, Steps: 244 Train Loss: 3.5171 (Forecasting Loss:0.3774 + XiCon Loss:3.1396 x Lambda(1.0)), Vali MSE Loss: 0.2771 Test MSE Loss: 0.1758
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.7150512
	speed: 0.1740s/iter; left time: 4143.3976s
	iters: 200, epoch: 3 | loss: 3.5087090
	speed: 0.1696s/iter; left time: 4021.4287s
Epoch: 3 cost time: 42.16179442405701
Epoch: 3, Steps: 244 Train Loss: 3.5673 (Forecasting Loss:0.3619 + XiCon Loss:3.2054 x Lambda(1.0)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.1695
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.5768089
	speed: 0.1804s/iter; left time: 4252.8266s
	iters: 200, epoch: 4 | loss: 3.4746611
	speed: 0.1715s/iter; left time: 4024.6297s
Epoch: 4 cost time: 43.213300704956055
Epoch: 4, Steps: 244 Train Loss: 3.5308 (Forecasting Loss:0.3561 + XiCon Loss:3.1748 x Lambda(1.0)), Vali MSE Loss: 0.2631 Test MSE Loss: 0.1677
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.4600658
	speed: 0.1721s/iter; left time: 4013.7966s
	iters: 200, epoch: 5 | loss: 3.4079342
	speed: 0.1712s/iter; left time: 3976.4932s
Epoch: 5 cost time: 42.10215401649475
Epoch: 5, Steps: 244 Train Loss: 3.5173 (Forecasting Loss:0.3528 + XiCon Loss:3.1645 x Lambda(1.0)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1663
Validation loss decreased (0.262498 --> 0.261054).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.5268505
	speed: 0.1765s/iter; left time: 4074.2368s
	iters: 200, epoch: 6 | loss: 3.5119035
	speed: 0.1652s/iter; left time: 3797.4521s
Epoch: 6 cost time: 41.733293533325195
Epoch: 6, Steps: 244 Train Loss: 3.5050 (Forecasting Loss:0.3493 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.2591 Test MSE Loss: 0.1742
Validation loss decreased (0.261054 --> 0.259087).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.5745249
	speed: 0.1467s/iter; left time: 3351.0846s
	iters: 200, epoch: 7 | loss: 3.5014617
	speed: 0.1710s/iter; left time: 3888.1047s
Epoch: 7 cost time: 39.378254413604736
Epoch: 7, Steps: 244 Train Loss: 3.5113 (Forecasting Loss:0.3462 + XiCon Loss:3.1651 x Lambda(1.0)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1752
Validation loss decreased (0.259087 --> 0.258949).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.6447678
	speed: 0.1708s/iter; left time: 3858.7659s
	iters: 200, epoch: 8 | loss: 3.4048820
	speed: 0.1687s/iter; left time: 3795.2655s
Epoch: 8 cost time: 41.51205778121948
Epoch: 8, Steps: 244 Train Loss: 3.5034 (Forecasting Loss:0.3454 + XiCon Loss:3.1579 x Lambda(1.0)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.1758
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.5206687
	speed: 0.1528s/iter; left time: 3413.9891s
	iters: 200, epoch: 9 | loss: 3.5208139
	speed: 0.1697s/iter; left time: 3775.9810s
Epoch: 9 cost time: 39.887913942337036
Epoch: 9, Steps: 244 Train Loss: 3.5032 (Forecasting Loss:0.3438 + XiCon Loss:3.1594 x Lambda(1.0)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1756
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.5854678
	speed: 0.1499s/iter; left time: 3314.1079s
	iters: 200, epoch: 10 | loss: 3.5105023
	speed: 0.1699s/iter; left time: 3738.4905s
Epoch: 10 cost time: 39.58711266517639
Epoch: 10, Steps: 244 Train Loss: 3.5008 (Forecasting Loss:0.3433 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1771
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.4523726
	speed: 0.1514s/iter; left time: 3310.7889s
	iters: 200, epoch: 11 | loss: 3.5480776
	speed: 0.1759s/iter; left time: 3826.9814s
Epoch: 11 cost time: 40.36784100532532
Epoch: 11, Steps: 244 Train Loss: 3.5020 (Forecasting Loss:0.3430 + XiCon Loss:3.1589 x Lambda(1.0)), Vali MSE Loss: 0.2623 Test MSE Loss: 0.1783
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.4619913
	speed: 0.1577s/iter; left time: 3409.2365s
	iters: 200, epoch: 12 | loss: 3.5976815
	speed: 0.1671s/iter; left time: 3595.4270s
Epoch: 12 cost time: 40.06195878982544
Epoch: 12, Steps: 244 Train Loss: 3.5013 (Forecasting Loss:0.3429 + XiCon Loss:3.1584 x Lambda(1.0)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1772
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.4942055
	speed: 0.1661s/iter; left time: 3550.4355s
	iters: 200, epoch: 13 | loss: 3.4869680
	speed: 0.1680s/iter; left time: 3573.0211s
Epoch: 13 cost time: 40.91835331916809
Epoch: 13, Steps: 244 Train Loss: 3.5031 (Forecasting Loss:0.3432 + XiCon Loss:3.1599 x Lambda(1.0)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1771
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.4525132
	speed: 0.1739s/iter; left time: 3674.9961s
	iters: 200, epoch: 14 | loss: 3.5038579
	speed: 0.1731s/iter; left time: 3639.8842s
Epoch: 14 cost time: 42.312978744506836
Epoch: 14, Steps: 244 Train Loss: 3.4977 (Forecasting Loss:0.3430 + XiCon Loss:3.1547 x Lambda(1.0)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1770
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.4216261
	speed: 0.1687s/iter; left time: 3522.3884s
	iters: 200, epoch: 15 | loss: 3.6112275
	speed: 0.1601s/iter; left time: 3328.0961s
Epoch: 15 cost time: 40.543675661087036
Epoch: 15, Steps: 244 Train Loss: 3.5005 (Forecasting Loss:0.3428 + XiCon Loss:3.1577 x Lambda(1.0)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1771
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.4149282
	speed: 0.1765s/iter; left time: 3642.2096s
	iters: 200, epoch: 16 | loss: 3.4618609
	speed: 0.1540s/iter; left time: 3162.5226s
Epoch: 16 cost time: 40.861783504486084
Epoch: 16, Steps: 244 Train Loss: 3.5017 (Forecasting Loss:0.3428 + XiCon Loss:3.1589 x Lambda(1.0)), Vali MSE Loss: 0.2620 Test MSE Loss: 0.1772
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.4776402
	speed: 0.1788s/iter; left time: 3647.9636s
	iters: 200, epoch: 17 | loss: 3.5297537
	speed: 0.1519s/iter; left time: 3083.5338s
Epoch: 17 cost time: 40.70189332962036
Epoch: 17, Steps: 244 Train Loss: 3.4987 (Forecasting Loss:0.3431 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1772
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09969867765903473, mae:0.2507842183113098, mape:0.18044397234916687, mspe:0.04980017989873886 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.7471
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6271272
	speed: 0.1529s/iter; left time: 3714.7043s
	iters: 200, epoch: 1 | loss: 3.5483980
	speed: 0.1493s/iter; left time: 3612.2453s
Epoch: 1 cost time: 36.63972210884094
Epoch: 1, Steps: 244 Train Loss: 3.6115 (Forecasting Loss:0.3610 + XiCon Loss:3.2504 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1620
Validation loss decreased (inf --> 0.248604).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.5959382
	speed: 0.2069s/iter; left time: 4976.9158s
	iters: 200, epoch: 2 | loss: 3.4774210
	speed: 0.1728s/iter; left time: 4139.2295s
Epoch: 2 cost time: 46.3062858581543
Epoch: 2, Steps: 244 Train Loss: 3.5267 (Forecasting Loss:0.3810 + XiCon Loss:3.1457 x Lambda(1.0)), Vali MSE Loss: 0.2723 Test MSE Loss: 0.1763
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.4190276
	speed: 0.1719s/iter; left time: 4092.3544s
	iters: 200, epoch: 3 | loss: 3.3739185
	speed: 0.1658s/iter; left time: 3931.7749s
Epoch: 3 cost time: 41.02370595932007
Epoch: 3, Steps: 244 Train Loss: 3.4354 (Forecasting Loss:0.3667 + XiCon Loss:3.0688 x Lambda(1.0)), Vali MSE Loss: 0.2668 Test MSE Loss: 0.1731
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.4411335
	speed: 0.1673s/iter; left time: 3942.8764s
	iters: 200, epoch: 4 | loss: 3.4406784
	speed: 0.1651s/iter; left time: 3875.0211s
Epoch: 4 cost time: 40.53150725364685
Epoch: 4, Steps: 244 Train Loss: 3.4163 (Forecasting Loss:0.3612 + XiCon Loss:3.0552 x Lambda(1.0)), Vali MSE Loss: 0.2630 Test MSE Loss: 0.1703
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.3878961
	speed: 0.1681s/iter; left time: 3921.0556s
	iters: 200, epoch: 5 | loss: 3.4594009
	speed: 0.1686s/iter; left time: 3914.5760s
Epoch: 5 cost time: 41.06571340560913
Epoch: 5, Steps: 244 Train Loss: 3.4104 (Forecasting Loss:0.3589 + XiCon Loss:3.0515 x Lambda(1.0)), Vali MSE Loss: 0.2641 Test MSE Loss: 0.1715
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.4162917
	speed: 0.1688s/iter; left time: 3895.4970s
	iters: 200, epoch: 6 | loss: 3.3980083
	speed: 0.1652s/iter; left time: 3795.7512s
Epoch: 6 cost time: 40.803184270858765
Epoch: 6, Steps: 244 Train Loss: 3.4042 (Forecasting Loss:0.3577 + XiCon Loss:3.0465 x Lambda(1.0)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1706
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.4543893
	speed: 0.1741s/iter; left time: 3976.2148s
	iters: 200, epoch: 7 | loss: 3.3486099
	speed: 0.1473s/iter; left time: 3348.8824s
Epoch: 7 cost time: 39.610349893569946
Epoch: 7, Steps: 244 Train Loss: 3.4009 (Forecasting Loss:0.3568 + XiCon Loss:3.0441 x Lambda(1.0)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1701
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.3877432
	speed: 0.1663s/iter; left time: 3758.2175s
	iters: 200, epoch: 8 | loss: 3.4045935
	speed: 0.1636s/iter; left time: 3679.4431s
Epoch: 8 cost time: 40.47472929954529
Epoch: 8, Steps: 244 Train Loss: 3.4032 (Forecasting Loss:0.3565 + XiCon Loss:3.0467 x Lambda(1.0)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1701
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.3922775
	speed: 0.1741s/iter; left time: 3891.9317s
	iters: 200, epoch: 9 | loss: 3.4177554
	speed: 0.1648s/iter; left time: 3665.8475s
Epoch: 9 cost time: 41.227598428726196
Epoch: 9, Steps: 244 Train Loss: 3.3967 (Forecasting Loss:0.3562 + XiCon Loss:3.0405 x Lambda(1.0)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1699
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.4355197
	speed: 0.1751s/iter; left time: 3870.6588s
	iters: 200, epoch: 10 | loss: 3.4065831
	speed: 0.1618s/iter; left time: 3561.2357s
Epoch: 10 cost time: 41.16743040084839
Epoch: 10, Steps: 244 Train Loss: 3.3995 (Forecasting Loss:0.3561 + XiCon Loss:3.0434 x Lambda(1.0)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1699
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.3877881
	speed: 0.1690s/iter; left time: 3695.5680s
	iters: 200, epoch: 11 | loss: 3.3717098
	speed: 0.1628s/iter; left time: 3542.2917s
Epoch: 11 cost time: 40.47248959541321
Epoch: 11, Steps: 244 Train Loss: 3.3999 (Forecasting Loss:0.3561 + XiCon Loss:3.0438 x Lambda(1.0)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1699
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08776550740003586, mae:0.23627670109272003, mape:0.16955479979515076, mspe:0.0433993935585022 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.9092
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.6452250
	speed: 0.1483s/iter; left time: 3604.2561s
	iters: 200, epoch: 1 | loss: 3.4875290
	speed: 0.1465s/iter; left time: 3544.6628s
Epoch: 1 cost time: 35.46067428588867
Epoch: 1, Steps: 244 Train Loss: 3.5979 (Forecasting Loss:0.3486 + XiCon Loss:3.2493 x Lambda(1.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1568
Validation loss decreased (inf --> 0.222247).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.5622187
	speed: 0.2012s/iter; left time: 4841.2414s
	iters: 200, epoch: 2 | loss: 3.5623591
	speed: 0.1728s/iter; left time: 4139.4626s
Epoch: 2 cost time: 44.93915367126465
Epoch: 2, Steps: 244 Train Loss: 3.5838 (Forecasting Loss:0.3843 + XiCon Loss:3.1995 x Lambda(1.0)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1746
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.4460299
	speed: 0.1798s/iter; left time: 4282.0799s
	iters: 200, epoch: 3 | loss: 3.3950751
	speed: 0.1684s/iter; left time: 3993.8063s
Epoch: 3 cost time: 42.08406066894531
Epoch: 3, Steps: 244 Train Loss: 3.4510 (Forecasting Loss:0.3668 + XiCon Loss:3.0841 x Lambda(1.0)), Vali MSE Loss: 0.2683 Test MSE Loss: 0.1748
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.4423590
	speed: 0.1671s/iter; left time: 3938.4049s
	iters: 200, epoch: 4 | loss: 3.4341166
	speed: 0.1637s/iter; left time: 3842.1150s
Epoch: 4 cost time: 40.66836142539978
Epoch: 4, Steps: 244 Train Loss: 3.4200 (Forecasting Loss:0.3570 + XiCon Loss:3.0630 x Lambda(1.0)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.1700
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.3602891
	speed: 0.1714s/iter; left time: 3997.4660s
	iters: 200, epoch: 5 | loss: 3.4322405
	speed: 0.1635s/iter; left time: 3798.2780s
Epoch: 5 cost time: 40.78861451148987
Epoch: 5, Steps: 244 Train Loss: 3.4050 (Forecasting Loss:0.3500 + XiCon Loss:3.0549 x Lambda(1.0)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.1665
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.3919010
	speed: 0.1766s/iter; left time: 4075.1560s
	iters: 200, epoch: 6 | loss: 3.3925195
	speed: 0.1619s/iter; left time: 3719.6506s
Epoch: 6 cost time: 41.20173144340515
Epoch: 6, Steps: 244 Train Loss: 3.4003 (Forecasting Loss:0.3482 + XiCon Loss:3.0521 x Lambda(1.0)), Vali MSE Loss: 0.2542 Test MSE Loss: 0.1655
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.3466623
	speed: 0.1750s/iter; left time: 3995.7049s
	iters: 200, epoch: 7 | loss: 3.4085789
	speed: 0.1637s/iter; left time: 3722.0804s
Epoch: 7 cost time: 41.23618769645691
Epoch: 7, Steps: 244 Train Loss: 3.3982 (Forecasting Loss:0.3465 + XiCon Loss:3.0517 x Lambda(1.0)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.1656
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.4460263
	speed: 0.1742s/iter; left time: 3935.3486s
	iters: 200, epoch: 8 | loss: 3.3846848
	speed: 0.1647s/iter; left time: 3704.8583s
Epoch: 8 cost time: 41.123942375183105
Epoch: 8, Steps: 244 Train Loss: 3.3919 (Forecasting Loss:0.3455 + XiCon Loss:3.0464 x Lambda(1.0)), Vali MSE Loss: 0.2538 Test MSE Loss: 0.1652
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.3537285
	speed: 0.1735s/iter; left time: 3877.8573s
	iters: 200, epoch: 9 | loss: 3.3575859
	speed: 0.1733s/iter; left time: 3856.4579s
Epoch: 9 cost time: 42.12850570678711
Epoch: 9, Steps: 244 Train Loss: 3.3928 (Forecasting Loss:0.3449 + XiCon Loss:3.0479 x Lambda(1.0)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1649
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.3909028
	speed: 0.1679s/iter; left time: 3711.6299s
	iters: 200, epoch: 10 | loss: 3.3556135
	speed: 0.1673s/iter; left time: 3682.4105s
Epoch: 10 cost time: 40.92702841758728
Epoch: 10, Steps: 244 Train Loss: 3.3920 (Forecasting Loss:0.3445 + XiCon Loss:3.0474 x Lambda(1.0)), Vali MSE Loss: 0.2537 Test MSE Loss: 0.1649
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.3548803
	speed: 0.1721s/iter; left time: 3761.9264s
	iters: 200, epoch: 11 | loss: 3.3678489
	speed: 0.1661s/iter; left time: 3614.4888s
Epoch: 11 cost time: 41.34931945800781
Epoch: 11, Steps: 244 Train Loss: 3.3919 (Forecasting Loss:0.3444 + XiCon Loss:3.0475 x Lambda(1.0)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1652
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08426934480667114, mae:0.22930212318897247, mape:0.16596437990665436, mspe:0.04291737079620361 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0894+-0.00737, MAE:0.2364+-0.01042, MAPE:0.1698+-0.00759, MSPE:0.0443+-0.00383, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8110
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8214555
	speed: 0.1288s/iter; left time: 2987.9447s
	iters: 200, epoch: 1 | loss: 3.7823730
	speed: 0.1369s/iter; left time: 3162.1759s
Epoch: 1 cost time: 31.125192403793335
Epoch: 1, Steps: 233 Train Loss: 3.8320 (Forecasting Loss:0.4353 + XiCon Loss:3.3967 x Lambda(1.0)), Vali MSE Loss: 0.2980 Test MSE Loss: 0.1807
Validation loss decreased (inf --> 0.297963).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5441506
	speed: 0.1354s/iter; left time: 3110.2777s
	iters: 200, epoch: 2 | loss: 3.4479160
	speed: 0.1410s/iter; left time: 3223.4014s
Epoch: 2 cost time: 32.37678050994873
Epoch: 2, Steps: 233 Train Loss: 3.5301 (Forecasting Loss:0.3545 + XiCon Loss:3.1756 x Lambda(1.0)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1965
Validation loss decreased (0.297963 --> 0.240550).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4340935
	speed: 0.1382s/iter; left time: 3140.8422s
	iters: 200, epoch: 3 | loss: 3.3693390
	speed: 0.1355s/iter; left time: 3068.0365s
Epoch: 3 cost time: 32.07775831222534
Epoch: 3, Steps: 233 Train Loss: 3.3966 (Forecasting Loss:0.3069 + XiCon Loss:3.0898 x Lambda(1.0)), Vali MSE Loss: 0.2674 Test MSE Loss: 0.1714
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3826480
	speed: 0.1168s/iter; left time: 2628.4190s
	iters: 200, epoch: 4 | loss: 3.3985991
	speed: 0.1429s/iter; left time: 3200.4572s
Epoch: 4 cost time: 30.76557421684265
Epoch: 4, Steps: 233 Train Loss: 3.3816 (Forecasting Loss:0.2981 + XiCon Loss:3.0835 x Lambda(1.0)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.1835
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3903921
	speed: 0.1338s/iter; left time: 2978.7263s
	iters: 200, epoch: 5 | loss: 3.3782864
	speed: 0.1423s/iter; left time: 3154.9874s
Epoch: 5 cost time: 32.33408236503601
Epoch: 5, Steps: 233 Train Loss: 3.3675 (Forecasting Loss:0.2937 + XiCon Loss:3.0738 x Lambda(1.0)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1695
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3378546
	speed: 0.1316s/iter; left time: 2899.8162s
	iters: 200, epoch: 6 | loss: 3.3524153
	speed: 0.1188s/iter; left time: 2607.0409s
Epoch: 6 cost time: 29.90158700942993
Epoch: 6, Steps: 233 Train Loss: 3.3612 (Forecasting Loss:0.2906 + XiCon Loss:3.0706 x Lambda(1.0)), Vali MSE Loss: 0.2755 Test MSE Loss: 0.1952
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3804798
	speed: 0.1432s/iter; left time: 3121.8074s
	iters: 200, epoch: 7 | loss: 3.3540125
	speed: 0.1116s/iter; left time: 2421.8750s
Epoch: 7 cost time: 30.07447123527527
Epoch: 7, Steps: 233 Train Loss: 3.3557 (Forecasting Loss:0.2892 + XiCon Loss:3.0665 x Lambda(1.0)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.1798
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3385348
	speed: 0.1459s/iter; left time: 3147.9637s
	iters: 200, epoch: 8 | loss: 3.3771365
	speed: 0.1371s/iter; left time: 2943.8990s
Epoch: 8 cost time: 31.49065065383911
Epoch: 8, Steps: 233 Train Loss: 3.3564 (Forecasting Loss:0.2882 + XiCon Loss:3.0682 x Lambda(1.0)), Vali MSE Loss: 0.2953 Test MSE Loss: 0.1795
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3269989
	speed: 0.1407s/iter; left time: 3002.3884s
	iters: 200, epoch: 9 | loss: 3.3767564
	speed: 0.1412s/iter; left time: 2998.5811s
Epoch: 9 cost time: 32.648889780044556
Epoch: 9, Steps: 233 Train Loss: 3.3552 (Forecasting Loss:0.2878 + XiCon Loss:3.0674 x Lambda(1.0)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.1809
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3755004
	speed: 0.1106s/iter; left time: 2334.8606s
	iters: 200, epoch: 10 | loss: 3.3851128
	speed: 0.1415s/iter; left time: 2972.5107s
Epoch: 10 cost time: 29.88696575164795
Epoch: 10, Steps: 233 Train Loss: 3.3548 (Forecasting Loss:0.2868 + XiCon Loss:3.0680 x Lambda(1.0)), Vali MSE Loss: 0.2957 Test MSE Loss: 0.1840
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3684599
	speed: 0.1367s/iter; left time: 2852.0649s
	iters: 200, epoch: 11 | loss: 3.3669510
	speed: 0.1446s/iter; left time: 3004.2048s
Epoch: 11 cost time: 32.859952211380005
Epoch: 11, Steps: 233 Train Loss: 3.3523 (Forecasting Loss:0.2870 + XiCon Loss:3.0654 x Lambda(1.0)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.1849
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3425534
	speed: 0.1376s/iter; left time: 2840.4901s
	iters: 200, epoch: 12 | loss: 3.3568473
	speed: 0.1390s/iter; left time: 2853.8604s
Epoch: 12 cost time: 32.31844115257263
Epoch: 12, Steps: 233 Train Loss: 3.3514 (Forecasting Loss:0.2874 + XiCon Loss:3.0640 x Lambda(1.0)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.1856
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11880084872245789, mae:0.2742721140384674, mape:0.1910942941904068, mspe:0.05391165614128113 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 19.3531
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8304005
	speed: 0.1297s/iter; left time: 3009.5692s
	iters: 200, epoch: 1 | loss: 3.7142408
	speed: 0.1315s/iter; left time: 3038.6618s
Epoch: 1 cost time: 30.140431880950928
Epoch: 1, Steps: 233 Train Loss: 3.8168 (Forecasting Loss:0.4429 + XiCon Loss:3.3739 x Lambda(1.0)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1861
Validation loss decreased (inf --> 0.292926).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5642073
	speed: 0.1408s/iter; left time: 3234.5849s
	iters: 200, epoch: 2 | loss: 3.4485562
	speed: 0.1363s/iter; left time: 3117.0025s
Epoch: 2 cost time: 32.662922382354736
Epoch: 2, Steps: 233 Train Loss: 3.5350 (Forecasting Loss:0.3652 + XiCon Loss:3.1698 x Lambda(1.0)), Vali MSE Loss: 0.2808 Test MSE Loss: 0.1895
Validation loss decreased (0.292926 --> 0.280789).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3680139
	speed: 0.1304s/iter; left time: 2964.2575s
	iters: 200, epoch: 3 | loss: 3.3364172
	speed: 0.1545s/iter; left time: 3497.5467s
Epoch: 3 cost time: 33.703547954559326
Epoch: 3, Steps: 233 Train Loss: 3.3832 (Forecasting Loss:0.3094 + XiCon Loss:3.0738 x Lambda(1.0)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.1711
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3339510
	speed: 0.1530s/iter; left time: 3442.0998s
	iters: 200, epoch: 4 | loss: 3.3475153
	speed: 0.1564s/iter; left time: 3504.7020s
Epoch: 4 cost time: 35.927250623703
Epoch: 4, Steps: 233 Train Loss: 3.3586 (Forecasting Loss:0.3012 + XiCon Loss:3.0574 x Lambda(1.0)), Vali MSE Loss: 0.3635 Test MSE Loss: 0.1676
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3727913
	speed: 0.1584s/iter; left time: 3526.5280s
	iters: 200, epoch: 5 | loss: 3.3356888
	speed: 0.1531s/iter; left time: 3393.7517s
Epoch: 5 cost time: 36.418701171875
Epoch: 5, Steps: 233 Train Loss: 3.3429 (Forecasting Loss:0.2953 + XiCon Loss:3.0477 x Lambda(1.0)), Vali MSE Loss: 0.3466 Test MSE Loss: 0.1734
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3305542
	speed: 0.1541s/iter; left time: 3396.7358s
	iters: 200, epoch: 6 | loss: 3.3149183
	speed: 0.1543s/iter; left time: 3384.8481s
Epoch: 6 cost time: 35.98622536659241
Epoch: 6, Steps: 233 Train Loss: 3.3396 (Forecasting Loss:0.2930 + XiCon Loss:3.0466 x Lambda(1.0)), Vali MSE Loss: 0.3644 Test MSE Loss: 0.1717
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3361857
	speed: 0.1492s/iter; left time: 3253.6883s
	iters: 200, epoch: 7 | loss: 3.3336668
	speed: 0.1538s/iter; left time: 3338.8165s
Epoch: 7 cost time: 35.31984567642212
Epoch: 7, Steps: 233 Train Loss: 3.3370 (Forecasting Loss:0.2917 + XiCon Loss:3.0453 x Lambda(1.0)), Vali MSE Loss: 0.3621 Test MSE Loss: 0.1744
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3330350
	speed: 0.1562s/iter; left time: 3369.3184s
	iters: 200, epoch: 8 | loss: 3.3256569
	speed: 0.1568s/iter; left time: 3365.5278s
Epoch: 8 cost time: 36.43202328681946
Epoch: 8, Steps: 233 Train Loss: 3.3354 (Forecasting Loss:0.2908 + XiCon Loss:3.0446 x Lambda(1.0)), Vali MSE Loss: 0.3728 Test MSE Loss: 0.1724
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3204424
	speed: 0.1530s/iter; left time: 3264.7145s
	iters: 200, epoch: 9 | loss: 3.3484831
	speed: 0.1531s/iter; left time: 3251.2778s
Epoch: 9 cost time: 35.97723078727722
Epoch: 9, Steps: 233 Train Loss: 3.3347 (Forecasting Loss:0.2909 + XiCon Loss:3.0437 x Lambda(1.0)), Vali MSE Loss: 0.3580 Test MSE Loss: 0.1753
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3610032
	speed: 0.1573s/iter; left time: 3320.6276s
	iters: 200, epoch: 10 | loss: 3.3323345
	speed: 0.1527s/iter; left time: 3206.5447s
Epoch: 10 cost time: 36.167691707611084
Epoch: 10, Steps: 233 Train Loss: 3.3340 (Forecasting Loss:0.2909 + XiCon Loss:3.0431 x Lambda(1.0)), Vali MSE Loss: 0.3647 Test MSE Loss: 0.1735
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3599129
	speed: 0.1545s/iter; left time: 3224.0133s
	iters: 200, epoch: 11 | loss: 3.3611391
	speed: 0.1512s/iter; left time: 3140.9863s
Epoch: 11 cost time: 35.718440532684326
Epoch: 11, Steps: 233 Train Loss: 3.3320 (Forecasting Loss:0.2904 + XiCon Loss:3.0416 x Lambda(1.0)), Vali MSE Loss: 0.3629 Test MSE Loss: 0.1736
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3394718
	speed: 0.1533s/iter; left time: 3164.6479s
	iters: 200, epoch: 12 | loss: 3.3623021
	speed: 0.1539s/iter; left time: 3161.0341s
Epoch: 12 cost time: 35.76758527755737
Epoch: 12, Steps: 233 Train Loss: 3.3323 (Forecasting Loss:0.2904 + XiCon Loss:3.0420 x Lambda(1.0)), Vali MSE Loss: 0.3648 Test MSE Loss: 0.1736
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11217930167913437, mae:0.2667686343193054, mape:0.1868087500333786, mspe:0.05172908678650856 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8686
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8698175
	speed: 0.1074s/iter; left time: 2492.8081s
	iters: 200, epoch: 1 | loss: 3.7696486
	speed: 0.1262s/iter; left time: 2914.4538s
Epoch: 1 cost time: 27.66564702987671
Epoch: 1, Steps: 233 Train Loss: 3.8360 (Forecasting Loss:0.4458 + XiCon Loss:3.3902 x Lambda(1.0)), Vali MSE Loss: 0.3019 Test MSE Loss: 0.1951
Validation loss decreased (inf --> 0.301876).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4829707
	speed: 0.1365s/iter; left time: 3134.6700s
	iters: 200, epoch: 2 | loss: 3.4168758
	speed: 0.1514s/iter; left time: 3462.5223s
Epoch: 2 cost time: 33.73830318450928
Epoch: 2, Steps: 233 Train Loss: 3.5295 (Forecasting Loss:0.3785 + XiCon Loss:3.1510 x Lambda(1.0)), Vali MSE Loss: 0.2745 Test MSE Loss: 0.1830
Validation loss decreased (0.301876 --> 0.274537).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3342741
	speed: 0.1514s/iter; left time: 3442.6065s
	iters: 200, epoch: 3 | loss: 3.3679054
	speed: 0.1525s/iter; left time: 3452.3680s
Epoch: 3 cost time: 35.663915157318115
Epoch: 3, Steps: 233 Train Loss: 3.3667 (Forecasting Loss:0.3144 + XiCon Loss:3.0522 x Lambda(1.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.1782
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3503957
	speed: 0.1527s/iter; left time: 3436.8014s
	iters: 200, epoch: 4 | loss: 3.3538256
	speed: 0.1518s/iter; left time: 3400.7985s
Epoch: 4 cost time: 35.75336575508118
Epoch: 4, Steps: 233 Train Loss: 3.3287 (Forecasting Loss:0.2948 + XiCon Loss:3.0339 x Lambda(1.0)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.1979
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3001552
	speed: 0.1529s/iter; left time: 3404.2373s
	iters: 200, epoch: 5 | loss: 3.2887058
	speed: 0.1499s/iter; left time: 3322.8256s
Epoch: 5 cost time: 35.46104073524475
Epoch: 5, Steps: 233 Train Loss: 3.3126 (Forecasting Loss:0.2854 + XiCon Loss:3.0272 x Lambda(1.0)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.1897
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3345456
	speed: 0.1565s/iter; left time: 3448.4213s
	iters: 200, epoch: 6 | loss: 3.2629240
	speed: 0.1485s/iter; left time: 3257.0436s
Epoch: 6 cost time: 35.51428270339966
Epoch: 6, Steps: 233 Train Loss: 3.3050 (Forecasting Loss:0.2814 + XiCon Loss:3.0236 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.1851
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2656581
	speed: 0.1564s/iter; left time: 3410.1408s
	iters: 200, epoch: 7 | loss: 3.2881010
	speed: 0.1482s/iter; left time: 3216.7652s
Epoch: 7 cost time: 35.555925130844116
Epoch: 7, Steps: 233 Train Loss: 3.3048 (Forecasting Loss:0.2791 + XiCon Loss:3.0257 x Lambda(1.0)), Vali MSE Loss: 0.3086 Test MSE Loss: 0.1906
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2966270
	speed: 0.1562s/iter; left time: 3370.0850s
	iters: 200, epoch: 8 | loss: 3.3218780
	speed: 0.1461s/iter; left time: 3136.5932s
Epoch: 8 cost time: 35.55047655105591
Epoch: 8, Steps: 233 Train Loss: 3.3011 (Forecasting Loss:0.2784 + XiCon Loss:3.0227 x Lambda(1.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.1827
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3085427
	speed: 0.1565s/iter; left time: 3339.1048s
	iters: 200, epoch: 9 | loss: 3.2703259
	speed: 0.1556s/iter; left time: 3304.2956s
Epoch: 9 cost time: 36.44673681259155
Epoch: 9, Steps: 233 Train Loss: 3.3002 (Forecasting Loss:0.2779 + XiCon Loss:3.0223 x Lambda(1.0)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.1845
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3067636
	speed: 0.1553s/iter; left time: 3277.5999s
	iters: 200, epoch: 10 | loss: 3.2987413
	speed: 0.1475s/iter; left time: 3098.1945s
Epoch: 10 cost time: 35.60796856880188
Epoch: 10, Steps: 233 Train Loss: 3.2987 (Forecasting Loss:0.2773 + XiCon Loss:3.0213 x Lambda(1.0)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.1852
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3367951
	speed: 0.1550s/iter; left time: 3235.0682s
	iters: 200, epoch: 11 | loss: 3.2821548
	speed: 0.1515s/iter; left time: 3146.0740s
Epoch: 11 cost time: 35.66665077209473
Epoch: 11, Steps: 233 Train Loss: 3.2999 (Forecasting Loss:0.2769 + XiCon Loss:3.0229 x Lambda(1.0)), Vali MSE Loss: 0.3188 Test MSE Loss: 0.1839
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3354702
	speed: 0.1546s/iter; left time: 3191.0291s
	iters: 200, epoch: 12 | loss: 3.3088114
	speed: 0.1504s/iter; left time: 3088.8789s
Epoch: 12 cost time: 35.432642698287964
Epoch: 12, Steps: 233 Train Loss: 3.2993 (Forecasting Loss:0.2775 + XiCon Loss:3.0218 x Lambda(1.0)), Vali MSE Loss: 0.3165 Test MSE Loss: 0.1852
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.10663264989852905, mae:0.25936102867126465, mape:0.18094420433044434, mspe:0.048515331000089645 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4884
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8386154
	speed: 0.1224s/iter; left time: 2839.5976s
	iters: 200, epoch: 1 | loss: 3.6965759
	speed: 0.1280s/iter; left time: 2956.1048s
Epoch: 1 cost time: 29.319661617279053
Epoch: 1, Steps: 233 Train Loss: 3.8086 (Forecasting Loss:0.4483 + XiCon Loss:3.3604 x Lambda(1.0)), Vali MSE Loss: 0.3067 Test MSE Loss: 0.1984
Validation loss decreased (inf --> 0.306745).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5982475
	speed: 0.1520s/iter; left time: 3491.8655s
	iters: 200, epoch: 2 | loss: 3.3052039
	speed: 0.1584s/iter; left time: 3621.6524s
Epoch: 2 cost time: 36.18489050865173
Epoch: 2, Steps: 233 Train Loss: 3.4841 (Forecasting Loss:0.3922 + XiCon Loss:3.0919 x Lambda(1.0)), Vali MSE Loss: 0.3258 Test MSE Loss: 0.1794
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2712195
	speed: 0.1584s/iter; left time: 3601.4070s
	iters: 200, epoch: 3 | loss: 3.3405361
	speed: 0.1572s/iter; left time: 3557.1236s
Epoch: 3 cost time: 36.836212396621704
Epoch: 3, Steps: 233 Train Loss: 3.2859 (Forecasting Loss:0.3146 + XiCon Loss:2.9712 x Lambda(1.0)), Vali MSE Loss: 0.3432 Test MSE Loss: 0.1638
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3062303
	speed: 0.1531s/iter; left time: 3444.3173s
	iters: 200, epoch: 4 | loss: 3.3331726
	speed: 0.1549s/iter; left time: 3469.7922s
Epoch: 4 cost time: 36.04614472389221
Epoch: 4, Steps: 233 Train Loss: 3.3330 (Forecasting Loss:0.2909 + XiCon Loss:3.0420 x Lambda(1.0)), Vali MSE Loss: 0.3301 Test MSE Loss: 0.1714
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2962239
	speed: 0.1559s/iter; left time: 3470.7328s
	iters: 200, epoch: 5 | loss: 3.3126333
	speed: 0.1526s/iter; left time: 3382.9072s
Epoch: 5 cost time: 36.04564094543457
Epoch: 5, Steps: 233 Train Loss: 3.3137 (Forecasting Loss:0.2808 + XiCon Loss:3.0329 x Lambda(1.0)), Vali MSE Loss: 0.3378 Test MSE Loss: 0.1711
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3163111
	speed: 0.1512s/iter; left time: 3330.9232s
	iters: 200, epoch: 6 | loss: 3.3194103
	speed: 0.1507s/iter; left time: 3305.2828s
Epoch: 6 cost time: 35.44520688056946
Epoch: 6, Steps: 233 Train Loss: 3.3086 (Forecasting Loss:0.2788 + XiCon Loss:3.0298 x Lambda(1.0)), Vali MSE Loss: 0.3380 Test MSE Loss: 0.1734
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3201149
	speed: 0.1520s/iter; left time: 3313.3353s
	iters: 200, epoch: 7 | loss: 3.2979004
	speed: 0.1482s/iter; left time: 3216.5955s
Epoch: 7 cost time: 35.04749083518982
Epoch: 7, Steps: 233 Train Loss: 3.3060 (Forecasting Loss:0.2772 + XiCon Loss:3.0289 x Lambda(1.0)), Vali MSE Loss: 0.3693 Test MSE Loss: 0.1649
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3010361
	speed: 0.1587s/iter; left time: 3423.9241s
	iters: 200, epoch: 8 | loss: 3.2942836
	speed: 0.1521s/iter; left time: 3266.4832s
Epoch: 8 cost time: 36.50715231895447
Epoch: 8, Steps: 233 Train Loss: 3.3036 (Forecasting Loss:0.2765 + XiCon Loss:3.0272 x Lambda(1.0)), Vali MSE Loss: 0.3668 Test MSE Loss: 0.1671
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3522613
	speed: 0.1560s/iter; left time: 3328.1366s
	iters: 200, epoch: 9 | loss: 3.3109846
	speed: 0.1345s/iter; left time: 2856.4008s
Epoch: 9 cost time: 32.23945236206055
Epoch: 9, Steps: 233 Train Loss: 3.3005 (Forecasting Loss:0.2758 + XiCon Loss:3.0246 x Lambda(1.0)), Vali MSE Loss: 0.3634 Test MSE Loss: 0.1692
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2730558
	speed: 0.1053s/iter; left time: 2222.1786s
	iters: 200, epoch: 10 | loss: 3.3287287
	speed: 0.1650s/iter; left time: 3466.0969s
Epoch: 10 cost time: 32.516791343688965
Epoch: 10, Steps: 233 Train Loss: 3.3038 (Forecasting Loss:0.2758 + XiCon Loss:3.0280 x Lambda(1.0)), Vali MSE Loss: 0.3607 Test MSE Loss: 0.1686
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3323789
	speed: 0.1755s/iter; left time: 3663.4731s
	iters: 200, epoch: 11 | loss: 3.2928281
	speed: 0.1569s/iter; left time: 3259.5962s
Epoch: 11 cost time: 39.19310736656189
Epoch: 11, Steps: 233 Train Loss: 3.3008 (Forecasting Loss:0.2757 + XiCon Loss:3.0252 x Lambda(1.0)), Vali MSE Loss: 0.3645 Test MSE Loss: 0.1675
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.1202624961733818, mae:0.2765475809574127, mape:0.19433048367500305, mspe:0.05626535415649414 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5594
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8346720
	speed: 0.1166s/iter; left time: 2705.8411s
	iters: 200, epoch: 1 | loss: 3.7068961
	speed: 0.0985s/iter; left time: 2275.4032s
Epoch: 1 cost time: 25.973333835601807
Epoch: 1, Steps: 233 Train Loss: 3.7979 (Forecasting Loss:0.4425 + XiCon Loss:3.3553 x Lambda(1.0)), Vali MSE Loss: 0.2906 Test MSE Loss: 0.1857
Validation loss decreased (inf --> 0.290613).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4902902
	speed: 0.1511s/iter; left time: 3471.5946s
	iters: 200, epoch: 2 | loss: 3.4335091
	speed: 0.1446s/iter; left time: 3306.3256s
Epoch: 2 cost time: 34.31253457069397
Epoch: 2, Steps: 233 Train Loss: 3.4956 (Forecasting Loss:0.3613 + XiCon Loss:3.1343 x Lambda(1.0)), Vali MSE Loss: 0.2426 Test MSE Loss: 0.1835
Validation loss decreased (0.290613 --> 0.242556).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.4870880
	speed: 0.0977s/iter; left time: 2221.9139s
	iters: 200, epoch: 3 | loss: 3.4145632
	speed: 0.1404s/iter; left time: 3177.6653s
Epoch: 3 cost time: 28.48561954498291
Epoch: 3, Steps: 233 Train Loss: 3.4357 (Forecasting Loss:0.3110 + XiCon Loss:3.1247 x Lambda(1.0)), Vali MSE Loss: 0.3291 Test MSE Loss: 0.1532
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3406255
	speed: 0.1416s/iter; left time: 3186.3987s
	iters: 200, epoch: 4 | loss: 3.3875015
	speed: 0.1246s/iter; left time: 2791.0815s
Epoch: 4 cost time: 29.155368328094482
Epoch: 4, Steps: 233 Train Loss: 3.3804 (Forecasting Loss:0.2888 + XiCon Loss:3.0916 x Lambda(1.0)), Vali MSE Loss: 0.3285 Test MSE Loss: 0.1662
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3832736
	speed: 0.1435s/iter; left time: 3194.9491s
	iters: 200, epoch: 5 | loss: 3.3550246
	speed: 0.1410s/iter; left time: 3125.1900s
Epoch: 5 cost time: 33.01791572570801
Epoch: 5, Steps: 233 Train Loss: 3.3652 (Forecasting Loss:0.2831 + XiCon Loss:3.0821 x Lambda(1.0)), Vali MSE Loss: 0.3002 Test MSE Loss: 0.1747
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3622937
	speed: 0.1397s/iter; left time: 3078.3014s
	iters: 200, epoch: 6 | loss: 3.3431811
	speed: 0.0768s/iter; left time: 1684.5860s
Epoch: 6 cost time: 25.963188886642456
Epoch: 6, Steps: 233 Train Loss: 3.3568 (Forecasting Loss:0.2800 + XiCon Loss:3.0768 x Lambda(1.0)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.1620
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3802075
	speed: 0.1456s/iter; left time: 3173.6518s
	iters: 200, epoch: 7 | loss: 3.3539107
	speed: 0.1356s/iter; left time: 2943.1673s
Epoch: 7 cost time: 32.746432065963745
Epoch: 7, Steps: 233 Train Loss: 3.3560 (Forecasting Loss:0.2791 + XiCon Loss:3.0770 x Lambda(1.0)), Vali MSE Loss: 0.3022 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3546939
	speed: 0.0955s/iter; left time: 2060.1088s
	iters: 200, epoch: 8 | loss: 3.3486738
	speed: 0.1168s/iter; left time: 2506.7458s
Epoch: 8 cost time: 25.686283826828003
Epoch: 8, Steps: 233 Train Loss: 3.3519 (Forecasting Loss:0.2781 + XiCon Loss:3.0738 x Lambda(1.0)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.1640
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3661747
	speed: 0.1412s/iter; left time: 3012.6617s
	iters: 200, epoch: 9 | loss: 3.3396976
	speed: 0.1363s/iter; left time: 2895.3810s
Epoch: 9 cost time: 32.641249656677246
Epoch: 9, Steps: 233 Train Loss: 3.3508 (Forecasting Loss:0.2777 + XiCon Loss:3.0731 x Lambda(1.0)), Vali MSE Loss: 0.3059 Test MSE Loss: 0.1632
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3860672
	speed: 0.1018s/iter; left time: 2148.4664s
	iters: 200, epoch: 10 | loss: 3.3241796
	speed: 0.1364s/iter; left time: 2865.6918s
Epoch: 10 cost time: 28.221489906311035
Epoch: 10, Steps: 233 Train Loss: 3.3501 (Forecasting Loss:0.2777 + XiCon Loss:3.0724 x Lambda(1.0)), Vali MSE Loss: 0.3056 Test MSE Loss: 0.1626
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3286264
	speed: 0.1429s/iter; left time: 2981.4481s
	iters: 200, epoch: 11 | loss: 3.3803062
	speed: 0.1342s/iter; left time: 2787.7996s
Epoch: 11 cost time: 32.24903678894043
Epoch: 11, Steps: 233 Train Loss: 3.3516 (Forecasting Loss:0.2775 + XiCon Loss:3.0741 x Lambda(1.0)), Vali MSE Loss: 0.3043 Test MSE Loss: 0.1631
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3891563
	speed: 0.1452s/iter; left time: 2995.9931s
	iters: 200, epoch: 12 | loss: 3.3931882
	speed: 0.1356s/iter; left time: 2785.4526s
Epoch: 12 cost time: 32.54676294326782
Epoch: 12, Steps: 233 Train Loss: 3.3513 (Forecasting Loss:0.2777 + XiCon Loss:3.0736 x Lambda(1.0)), Vali MSE Loss: 0.3042 Test MSE Loss: 0.1625
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.10767487436532974, mae:0.2593925893306732, mape:0.18410241603851318, mspe:0.0521954782307148 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1131+-0.00775, MAE:0.2673+-0.01001, MAPE:0.1875+-0.00665, MSPE:0.0525+-0.00355, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2895
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5019736
	speed: 0.0587s/iter; left time: 1549.0940s
	iters: 200, epoch: 1 | loss: 3.4464109
	speed: 0.0529s/iter; left time: 1391.6232s
Epoch: 1 cost time: 13.947231531143188
Epoch: 1, Steps: 265 Train Loss: 3.4889 (Forecasting Loss:0.2277 + XiCon Loss:3.2612 x Lambda(1.0)), Vali MSE Loss: 0.2091 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.209087).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3190536
	speed: 0.0533s/iter; left time: 1392.3968s
	iters: 200, epoch: 2 | loss: 3.3191555
	speed: 0.0541s/iter; left time: 1409.4939s
Epoch: 2 cost time: 14.307144403457642
Epoch: 2, Steps: 265 Train Loss: 3.3337 (Forecasting Loss:0.2088 + XiCon Loss:3.1248 x Lambda(1.0)), Vali MSE Loss: 0.2066 Test MSE Loss: 0.1669
Validation loss decreased (0.209087 --> 0.206644).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1732678
	speed: 0.0569s/iter; left time: 1471.4453s
	iters: 200, epoch: 3 | loss: 3.1819088
	speed: 0.0534s/iter; left time: 1375.1252s
Epoch: 3 cost time: 14.492487907409668
Epoch: 3, Steps: 265 Train Loss: 3.2156 (Forecasting Loss:0.2012 + XiCon Loss:3.0145 x Lambda(1.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1619
Validation loss decreased (0.206644 --> 0.203703).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1427779
	speed: 0.0515s/iter; left time: 1318.6101s
	iters: 200, epoch: 4 | loss: 3.2300377
	speed: 0.0453s/iter; left time: 1156.3610s
Epoch: 4 cost time: 13.343724727630615
Epoch: 4, Steps: 265 Train Loss: 3.1851 (Forecasting Loss:0.1990 + XiCon Loss:2.9861 x Lambda(1.0)), Vali MSE Loss: 0.2009 Test MSE Loss: 0.1607
Validation loss decreased (0.203703 --> 0.200898).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1906154
	speed: 0.0585s/iter; left time: 1482.3227s
	iters: 200, epoch: 5 | loss: 3.1840069
	speed: 0.0561s/iter; left time: 1415.5123s
Epoch: 5 cost time: 15.2993004322052
Epoch: 5, Steps: 265 Train Loss: 3.1811 (Forecasting Loss:0.1971 + XiCon Loss:2.9840 x Lambda(1.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1595
Validation loss decreased (0.200898 --> 0.199083).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2475228
	speed: 0.0592s/iter; left time: 1485.5929s
	iters: 200, epoch: 6 | loss: 3.2179310
	speed: 0.0561s/iter; left time: 1401.6252s
Epoch: 6 cost time: 14.759340524673462
Epoch: 6, Steps: 265 Train Loss: 3.1798 (Forecasting Loss:0.1964 + XiCon Loss:2.9834 x Lambda(1.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1707969
	speed: 0.0520s/iter; left time: 1290.2948s
	iters: 200, epoch: 7 | loss: 3.2003777
	speed: 0.0545s/iter; left time: 1347.5270s
Epoch: 7 cost time: 14.34230661392212
Epoch: 7, Steps: 265 Train Loss: 3.1807 (Forecasting Loss:0.1962 + XiCon Loss:2.9845 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1997392
	speed: 0.0587s/iter; left time: 1439.8812s
	iters: 200, epoch: 8 | loss: 3.2235894
	speed: 0.0559s/iter; left time: 1365.5240s
Epoch: 8 cost time: 15.065629959106445
Epoch: 8, Steps: 265 Train Loss: 3.1767 (Forecasting Loss:0.1959 + XiCon Loss:2.9808 x Lambda(1.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1997662
	speed: 0.0544s/iter; left time: 1321.9521s
	iters: 200, epoch: 9 | loss: 3.1916540
	speed: 0.0433s/iter; left time: 1047.2263s
Epoch: 9 cost time: 13.147784233093262
Epoch: 9, Steps: 265 Train Loss: 3.1800 (Forecasting Loss:0.1958 + XiCon Loss:2.9842 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
Validation loss decreased (0.199083 --> 0.199002).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2192559
	speed: 0.0578s/iter; left time: 1387.9543s
	iters: 200, epoch: 10 | loss: 3.2342472
	speed: 0.0554s/iter; left time: 1325.5732s
Epoch: 10 cost time: 15.087595701217651
Epoch: 10, Steps: 265 Train Loss: 3.1745 (Forecasting Loss:0.1957 + XiCon Loss:2.9788 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1654935
	speed: 0.0595s/iter; left time: 1413.4230s
	iters: 200, epoch: 11 | loss: 3.1229882
	speed: 0.0545s/iter; left time: 1289.9685s
Epoch: 11 cost time: 14.867242336273193
Epoch: 11, Steps: 265 Train Loss: 3.1776 (Forecasting Loss:0.1958 + XiCon Loss:2.9819 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1588
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1874478
	speed: 0.0407s/iter; left time: 956.5307s
	iters: 200, epoch: 12 | loss: 3.1830173
	speed: 0.0289s/iter; left time: 676.5773s
Epoch: 12 cost time: 8.844182014465332
Epoch: 12, Steps: 265 Train Loss: 3.1820 (Forecasting Loss:0.1957 + XiCon Loss:2.9863 x Lambda(1.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1953216
	speed: 0.0612s/iter; left time: 1421.7111s
	iters: 200, epoch: 13 | loss: 3.1288667
	speed: 0.0548s/iter; left time: 1267.3433s
Epoch: 13 cost time: 15.205318212509155
Epoch: 13, Steps: 265 Train Loss: 3.1767 (Forecasting Loss:0.1956 + XiCon Loss:2.9811 x Lambda(1.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2307386
	speed: 0.0593s/iter; left time: 1361.3247s
	iters: 200, epoch: 14 | loss: 3.2117412
	speed: 0.0562s/iter; left time: 1284.0003s
Epoch: 14 cost time: 14.999184131622314
Epoch: 14, Steps: 265 Train Loss: 3.1778 (Forecasting Loss:0.1956 + XiCon Loss:2.9821 x Lambda(1.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1616971
	speed: 0.0493s/iter; left time: 1119.6355s
	iters: 200, epoch: 15 | loss: 3.1577401
	speed: 0.0458s/iter; left time: 1033.7462s
Epoch: 15 cost time: 13.010077476501465
Epoch: 15, Steps: 265 Train Loss: 3.1778 (Forecasting Loss:0.1956 + XiCon Loss:2.9822 x Lambda(1.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1588
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1859760
	speed: 0.0589s/iter; left time: 1320.0704s
	iters: 200, epoch: 16 | loss: 3.1712942
	speed: 0.0566s/iter; left time: 1263.7030s
Epoch: 16 cost time: 15.0890371799469
Epoch: 16, Steps: 265 Train Loss: 3.1782 (Forecasting Loss:0.1956 + XiCon Loss:2.9826 x Lambda(1.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1588
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1693535
	speed: 0.0575s/iter; left time: 1274.3949s
	iters: 200, epoch: 17 | loss: 3.1830196
	speed: 0.0571s/iter; left time: 1259.6450s
Epoch: 17 cost time: 14.329201459884644
Epoch: 17, Steps: 265 Train Loss: 3.1768 (Forecasting Loss:0.1956 + XiCon Loss:2.9812 x Lambda(1.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1946912
	speed: 0.0522s/iter; left time: 1143.2774s
	iters: 200, epoch: 18 | loss: 3.1950831
	speed: 0.0532s/iter; left time: 1159.5471s
Epoch: 18 cost time: 14.09252405166626
Epoch: 18, Steps: 265 Train Loss: 3.1757 (Forecasting Loss:0.1956 + XiCon Loss:2.9801 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1588
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2002797
	speed: 0.0590s/iter; left time: 1275.2265s
	iters: 200, epoch: 19 | loss: 3.1442318
	speed: 0.0571s/iter; left time: 1228.5539s
Epoch: 19 cost time: 15.276937246322632
Epoch: 19, Steps: 265 Train Loss: 3.1751 (Forecasting Loss:0.1956 + XiCon Loss:2.9795 x Lambda(1.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1588
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09193876385688782, mae:0.2255493551492691, mape:0.5430089831352234, mspe:11.298495292663574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0603
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5113993
	speed: 0.0573s/iter; left time: 1511.9844s
	iters: 200, epoch: 1 | loss: 3.3666122
	speed: 0.0551s/iter; left time: 1450.0680s
Epoch: 1 cost time: 15.01337194442749
Epoch: 1, Steps: 265 Train Loss: 3.4738 (Forecasting Loss:0.2274 + XiCon Loss:3.2464 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1680
Validation loss decreased (inf --> 0.211178).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4218760
	speed: 0.0591s/iter; left time: 1543.6043s
	iters: 200, epoch: 2 | loss: 3.3065212
	speed: 0.0554s/iter; left time: 1443.3872s
Epoch: 2 cost time: 14.456575870513916
Epoch: 2, Steps: 265 Train Loss: 3.3728 (Forecasting Loss:0.2075 + XiCon Loss:3.1653 x Lambda(1.0)), Vali MSE Loss: 0.2071 Test MSE Loss: 0.1688
Validation loss decreased (0.211178 --> 0.207074).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2977571
	speed: 0.0556s/iter; left time: 1438.6120s
	iters: 200, epoch: 3 | loss: 3.2320299
	speed: 0.0566s/iter; left time: 1457.6094s
Epoch: 3 cost time: 14.803415536880493
Epoch: 3, Steps: 265 Train Loss: 3.3170 (Forecasting Loss:0.2009 + XiCon Loss:3.1162 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1630
Validation loss decreased (0.207074 --> 0.204748).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2643988
	speed: 0.0575s/iter; left time: 1471.6932s
	iters: 200, epoch: 4 | loss: 3.2076054
	speed: 0.0577s/iter; left time: 1472.2693s
Epoch: 4 cost time: 15.033338785171509
Epoch: 4, Steps: 265 Train Loss: 3.2454 (Forecasting Loss:0.1987 + XiCon Loss:3.0467 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1606
Validation loss decreased (0.204748 --> 0.200805).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2260830
	speed: 0.0522s/iter; left time: 1321.9304s
	iters: 200, epoch: 5 | loss: 3.1912229
	speed: 0.0454s/iter; left time: 1147.1539s
Epoch: 5 cost time: 13.220316171646118
Epoch: 5, Steps: 265 Train Loss: 3.2143 (Forecasting Loss:0.1971 + XiCon Loss:3.0172 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1603
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2371607
	speed: 0.0594s/iter; left time: 1489.3655s
	iters: 200, epoch: 6 | loss: 3.2319572
	speed: 0.0547s/iter; left time: 1365.7345s
Epoch: 6 cost time: 14.932008028030396
Epoch: 6, Steps: 265 Train Loss: 3.2068 (Forecasting Loss:0.1962 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1597
Validation loss decreased (0.200805 --> 0.198332).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2262061
	speed: 0.0577s/iter; left time: 1432.1089s
	iters: 200, epoch: 7 | loss: 3.2023666
	speed: 0.0571s/iter; left time: 1410.4526s
Epoch: 7 cost time: 14.649232149124146
Epoch: 7, Steps: 265 Train Loss: 3.2032 (Forecasting Loss:0.1959 + XiCon Loss:3.0073 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1600
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2028947
	speed: 0.0495s/iter; left time: 1214.1087s
	iters: 200, epoch: 8 | loss: 3.2390902
	speed: 0.0539s/iter; left time: 1318.8324s
Epoch: 8 cost time: 13.89531421661377
Epoch: 8, Steps: 265 Train Loss: 3.2024 (Forecasting Loss:0.1957 + XiCon Loss:3.0067 x Lambda(1.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1598
Validation loss decreased (0.198332 --> 0.198245).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1590333
	speed: 0.0568s/iter; left time: 1378.7011s
	iters: 200, epoch: 9 | loss: 3.2013850
	speed: 0.0562s/iter; left time: 1359.6882s
Epoch: 9 cost time: 15.03149676322937
Epoch: 9, Steps: 265 Train Loss: 3.2037 (Forecasting Loss:0.1956 + XiCon Loss:3.0081 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1598
Validation loss decreased (0.198245 --> 0.197886).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2499101
	speed: 0.0551s/iter; left time: 1322.3273s
	iters: 200, epoch: 10 | loss: 3.2264016
	speed: 0.0452s/iter; left time: 1082.0432s
Epoch: 10 cost time: 13.033238172531128
Epoch: 10, Steps: 265 Train Loss: 3.2032 (Forecasting Loss:0.1955 + XiCon Loss:3.0077 x Lambda(1.0)), Vali MSE Loss: 0.1983 Test MSE Loss: 0.1598
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2089138
	speed: 0.0597s/iter; left time: 1417.2321s
	iters: 200, epoch: 11 | loss: 3.1783674
	speed: 0.0584s/iter; left time: 1382.3471s
Epoch: 11 cost time: 15.573567390441895
Epoch: 11, Steps: 265 Train Loss: 3.2048 (Forecasting Loss:0.1954 + XiCon Loss:3.0094 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1598
Validation loss decreased (0.197886 --> 0.197823).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2331066
	speed: 0.0603s/iter; left time: 1416.7702s
	iters: 200, epoch: 12 | loss: 3.1956689
	speed: 0.0559s/iter; left time: 1308.1221s
Epoch: 12 cost time: 15.01829743385315
Epoch: 12, Steps: 265 Train Loss: 3.2024 (Forecasting Loss:0.1954 + XiCon Loss:3.0070 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1598
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2694075
	speed: 0.0504s/iter; left time: 1169.4113s
	iters: 200, epoch: 13 | loss: 3.1990566
	speed: 0.0573s/iter; left time: 1324.2147s
Epoch: 13 cost time: 14.290067911148071
Epoch: 13, Steps: 265 Train Loss: 3.2039 (Forecasting Loss:0.1954 + XiCon Loss:3.0085 x Lambda(1.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1597
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1896853
	speed: 0.0567s/iter; left time: 1301.7353s
	iters: 200, epoch: 14 | loss: 3.1958306
	speed: 0.0559s/iter; left time: 1276.7728s
Epoch: 14 cost time: 14.945923089981079
Epoch: 14, Steps: 265 Train Loss: 3.2016 (Forecasting Loss:0.1954 + XiCon Loss:3.0062 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2396572
	speed: 0.0566s/iter; left time: 1284.1028s
	iters: 200, epoch: 15 | loss: 3.1984355
	speed: 0.0454s/iter; left time: 1025.3361s
Epoch: 15 cost time: 13.072938203811646
Epoch: 15, Steps: 265 Train Loss: 3.2000 (Forecasting Loss:0.1954 + XiCon Loss:3.0045 x Lambda(1.0)), Vali MSE Loss: 0.1981 Test MSE Loss: 0.1598
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1594605
	speed: 0.0584s/iter; left time: 1309.3330s
	iters: 200, epoch: 16 | loss: 3.1734900
	speed: 0.0541s/iter; left time: 1207.7611s
Epoch: 16 cost time: 14.686171293258667
Epoch: 16, Steps: 265 Train Loss: 3.2034 (Forecasting Loss:0.1954 + XiCon Loss:3.0081 x Lambda(1.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1597
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1804440
	speed: 0.0568s/iter; left time: 1258.8752s
	iters: 200, epoch: 17 | loss: 3.1968651
	speed: 0.0552s/iter; left time: 1218.4854s
Epoch: 17 cost time: 14.671019077301025
Epoch: 17, Steps: 265 Train Loss: 3.2023 (Forecasting Loss:0.1953 + XiCon Loss:3.0070 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1597
Validation loss decreased (0.197823 --> 0.197747).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1929698
	speed: 0.0480s/iter; left time: 1050.4708s
	iters: 200, epoch: 18 | loss: 3.1731029
	speed: 0.0525s/iter; left time: 1143.9643s
Epoch: 18 cost time: 13.691637992858887
Epoch: 18, Steps: 265 Train Loss: 3.2030 (Forecasting Loss:0.1953 + XiCon Loss:3.0077 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1689639
	speed: 0.0600s/iter; left time: 1298.0871s
	iters: 200, epoch: 19 | loss: 3.1786509
	speed: 0.0557s/iter; left time: 1198.4336s
Epoch: 19 cost time: 15.230270624160767
Epoch: 19, Steps: 265 Train Loss: 3.2002 (Forecasting Loss:0.1954 + XiCon Loss:3.0048 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1597
Validation loss decreased (0.197747 --> 0.197660).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1917195
	speed: 0.0575s/iter; left time: 1228.9638s
	iters: 200, epoch: 20 | loss: 3.2035890
	speed: 0.0482s/iter; left time: 1025.9226s
Epoch: 20 cost time: 13.548685789108276
Epoch: 20, Steps: 265 Train Loss: 3.2000 (Forecasting Loss:0.1954 + XiCon Loss:3.0046 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1597
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2277646
	speed: 0.0562s/iter; left time: 1186.3516s
	iters: 200, epoch: 21 | loss: 3.2288048
	speed: 0.0556s/iter; left time: 1168.4742s
Epoch: 21 cost time: 14.868127822875977
Epoch: 21, Steps: 265 Train Loss: 3.2042 (Forecasting Loss:0.1954 + XiCon Loss:3.0088 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2456381
	speed: 0.0585s/iter; left time: 1217.8787s
	iters: 200, epoch: 22 | loss: 3.2394869
	speed: 0.0550s/iter; left time: 1139.6434s
Epoch: 22 cost time: 15.009560346603394
Epoch: 22, Steps: 265 Train Loss: 3.2041 (Forecasting Loss:0.1953 + XiCon Loss:3.0088 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1591883
	speed: 0.0478s/iter; left time: 983.8240s
	iters: 200, epoch: 23 | loss: 3.1669717
	speed: 0.0488s/iter; left time: 999.9727s
Epoch: 23 cost time: 13.36412787437439
Epoch: 23, Steps: 265 Train Loss: 3.2022 (Forecasting Loss:0.1954 + XiCon Loss:3.0068 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1597
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2329314
	speed: 0.0567s/iter; left time: 1151.2094s
	iters: 200, epoch: 24 | loss: 3.2413645
	speed: 0.0565s/iter; left time: 1141.0228s
Epoch: 24 cost time: 14.796096801757812
Epoch: 24, Steps: 265 Train Loss: 3.2044 (Forecasting Loss:0.1954 + XiCon Loss:3.0090 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2050173
	speed: 0.0585s/iter; left time: 1172.9965s
	iters: 200, epoch: 25 | loss: 3.1722112
	speed: 0.0519s/iter; left time: 1034.3701s
Epoch: 25 cost time: 13.933974981307983
Epoch: 25, Steps: 265 Train Loss: 3.2029 (Forecasting Loss:0.1954 + XiCon Loss:3.0075 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1981964
	speed: 0.0555s/iter; left time: 1097.6170s
	iters: 200, epoch: 26 | loss: 3.1758547
	speed: 0.0547s/iter; left time: 1077.0858s
Epoch: 26 cost time: 14.521594285964966
Epoch: 26, Steps: 265 Train Loss: 3.2032 (Forecasting Loss:0.1954 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1597
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.2074320
	speed: 0.0590s/iter; left time: 1151.7062s
	iters: 200, epoch: 27 | loss: 3.1935413
	speed: 0.0587s/iter; left time: 1140.1832s
Epoch: 27 cost time: 15.435041189193726
Epoch: 27, Steps: 265 Train Loss: 3.2037 (Forecasting Loss:0.1954 + XiCon Loss:3.0084 x Lambda(1.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1597
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1959343
	speed: 0.0500s/iter; left time: 961.5967s
	iters: 200, epoch: 28 | loss: 3.2188313
	speed: 0.0456s/iter; left time: 873.1547s
Epoch: 28 cost time: 13.11785888671875
Epoch: 28, Steps: 265 Train Loss: 3.2016 (Forecasting Loss:0.1954 + XiCon Loss:3.0062 x Lambda(1.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1597
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.2111313
	speed: 0.0564s/iter; left time: 1070.7433s
	iters: 200, epoch: 29 | loss: 3.2076175
	speed: 0.0583s/iter; left time: 1099.9708s
Epoch: 29 cost time: 15.026612997055054
Epoch: 29, Steps: 265 Train Loss: 3.2026 (Forecasting Loss:0.1954 + XiCon Loss:3.0072 x Lambda(1.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1597
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09299277514219284, mae:0.2265053391456604, mape:0.5453492999076843, mspe:11.368200302124023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3972
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5397456
	speed: 0.0569s/iter; left time: 1501.5862s
	iters: 200, epoch: 1 | loss: 3.3942761
	speed: 0.0538s/iter; left time: 1414.4241s
Epoch: 1 cost time: 14.686269283294678
Epoch: 1, Steps: 265 Train Loss: 3.4934 (Forecasting Loss:0.2264 + XiCon Loss:3.2670 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1670
Validation loss decreased (inf --> 0.210868).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3838170
	speed: 0.0588s/iter; left time: 1535.9193s
	iters: 200, epoch: 2 | loss: 3.5148816
	speed: 0.0553s/iter; left time: 1440.5536s
Epoch: 2 cost time: 14.887240171432495
Epoch: 2, Steps: 265 Train Loss: 3.4345 (Forecasting Loss:0.2075 + XiCon Loss:3.2269 x Lambda(1.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1648
Validation loss decreased (0.210868 --> 0.205048).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3733754
	speed: 0.0467s/iter; left time: 1208.8115s
	iters: 200, epoch: 3 | loss: 3.2646911
	speed: 0.0469s/iter; left time: 1209.4828s
Epoch: 3 cost time: 13.065993547439575
Epoch: 3, Steps: 265 Train Loss: 3.3669 (Forecasting Loss:0.2014 + XiCon Loss:3.1655 x Lambda(1.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1626
Validation loss decreased (0.205048 --> 0.203488).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3480978
	speed: 0.0585s/iter; left time: 1497.5625s
	iters: 200, epoch: 4 | loss: 3.2985585
	speed: 0.0567s/iter; left time: 1446.7505s
Epoch: 4 cost time: 15.037776231765747
Epoch: 4, Steps: 265 Train Loss: 3.3404 (Forecasting Loss:0.1983 + XiCon Loss:3.1421 x Lambda(1.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1633
Validation loss decreased (0.203488 --> 0.202773).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2703681
	speed: 0.0564s/iter; left time: 1428.4443s
	iters: 200, epoch: 5 | loss: 3.3281202
	speed: 0.0528s/iter; left time: 1332.3903s
Epoch: 5 cost time: 13.85276198387146
Epoch: 5, Steps: 265 Train Loss: 3.3324 (Forecasting Loss:0.1968 + XiCon Loss:3.1356 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1602
Validation loss decreased (0.202773 --> 0.200199).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4015632
	speed: 0.0531s/iter; left time: 1331.8228s
	iters: 200, epoch: 6 | loss: 3.3400078
	speed: 0.0573s/iter; left time: 1432.1178s
Epoch: 6 cost time: 14.675844669342041
Epoch: 6, Steps: 265 Train Loss: 3.3296 (Forecasting Loss:0.1960 + XiCon Loss:3.1337 x Lambda(1.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1596
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3646426
	speed: 0.0593s/iter; left time: 1472.1281s
	iters: 200, epoch: 7 | loss: 3.3940377
	speed: 0.0555s/iter; left time: 1370.4891s
Epoch: 7 cost time: 15.155194520950317
Epoch: 7, Steps: 265 Train Loss: 3.3241 (Forecasting Loss:0.1954 + XiCon Loss:3.1286 x Lambda(1.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1596
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3050570
	speed: 0.0531s/iter; left time: 1303.9718s
	iters: 200, epoch: 8 | loss: 3.3200617
	speed: 0.0449s/iter; left time: 1097.8447s
Epoch: 8 cost time: 13.646688461303711
Epoch: 8, Steps: 265 Train Loss: 3.3231 (Forecasting Loss:0.1951 + XiCon Loss:3.1280 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1594
Validation loss decreased (0.200199 --> 0.200110).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2658479
	speed: 0.0583s/iter; left time: 1415.4088s
	iters: 200, epoch: 9 | loss: 3.3671954
	speed: 0.0580s/iter; left time: 1403.3307s
Epoch: 9 cost time: 15.249990463256836
Epoch: 9, Steps: 265 Train Loss: 3.3290 (Forecasting Loss:0.1951 + XiCon Loss:3.1339 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1595
Validation loss decreased (0.200110 --> 0.200102).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2703705
	speed: 0.0603s/iter; left time: 1448.3433s
	iters: 200, epoch: 10 | loss: 3.3437266
	speed: 0.0557s/iter; left time: 1332.0733s
Epoch: 10 cost time: 14.417306900024414
Epoch: 10, Steps: 265 Train Loss: 3.3257 (Forecasting Loss:0.1949 + XiCon Loss:3.1308 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
Validation loss decreased (0.200102 --> 0.199885).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3629830
	speed: 0.0535s/iter; left time: 1270.9563s
	iters: 200, epoch: 11 | loss: 3.4128797
	speed: 0.0537s/iter; left time: 1270.5451s
Epoch: 11 cost time: 14.420418500900269
Epoch: 11, Steps: 265 Train Loss: 3.3203 (Forecasting Loss:0.1949 + XiCon Loss:3.1254 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1594
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3398237
	speed: 0.0587s/iter; left time: 1377.7941s
	iters: 200, epoch: 12 | loss: 3.2616587
	speed: 0.0552s/iter; left time: 1290.6295s
Epoch: 12 cost time: 14.97643780708313
Epoch: 12, Steps: 265 Train Loss: 3.3204 (Forecasting Loss:0.1949 + XiCon Loss:3.1254 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3145468
	speed: 0.0543s/iter; left time: 1261.7705s
	iters: 200, epoch: 13 | loss: 3.2486963
	speed: 0.0451s/iter; left time: 1042.9059s
Epoch: 13 cost time: 12.459923028945923
Epoch: 13, Steps: 265 Train Loss: 3.3266 (Forecasting Loss:0.1950 + XiCon Loss:3.1317 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1594
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3191729
	speed: 0.0662s/iter; left time: 1519.8708s
	iters: 200, epoch: 14 | loss: 3.2577393
	speed: 0.0650s/iter; left time: 1486.0025s
Epoch: 14 cost time: 15.33249545097351
Epoch: 14, Steps: 265 Train Loss: 3.3230 (Forecasting Loss:0.1948 + XiCon Loss:3.1282 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1594
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3290017
	speed: 0.0340s/iter; left time: 771.9175s
	iters: 200, epoch: 15 | loss: 3.2789237
	speed: 0.0444s/iter; left time: 1004.0318s
Epoch: 15 cost time: 11.563612461090088
Epoch: 15, Steps: 265 Train Loss: 3.3187 (Forecasting Loss:0.1948 + XiCon Loss:3.1239 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2750750
	speed: 0.0614s/iter; left time: 1376.3157s
	iters: 200, epoch: 16 | loss: 3.3913884
	speed: 0.0560s/iter; left time: 1249.7325s
Epoch: 16 cost time: 15.335039854049683
Epoch: 16, Steps: 265 Train Loss: 3.3200 (Forecasting Loss:0.1948 + XiCon Loss:3.1252 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2997415
	speed: 0.0623s/iter; left time: 1379.9256s
	iters: 200, epoch: 17 | loss: 3.2844315
	speed: 0.0517s/iter; left time: 1140.1956s
Epoch: 17 cost time: 14.429078817367554
Epoch: 17, Steps: 265 Train Loss: 3.3170 (Forecasting Loss:0.1948 + XiCon Loss:3.1222 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3158395
	speed: 0.0507s/iter; left time: 1111.1175s
	iters: 200, epoch: 18 | loss: 3.2973018
	speed: 0.0585s/iter; left time: 1275.7596s
Epoch: 18 cost time: 14.63702392578125
Epoch: 18, Steps: 265 Train Loss: 3.3227 (Forecasting Loss:0.1948 + XiCon Loss:3.1278 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1594
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3424158
	speed: 0.0574s/iter; left time: 1241.3437s
	iters: 200, epoch: 19 | loss: 3.2498252
	speed: 0.0570s/iter; left time: 1227.4460s
Epoch: 19 cost time: 15.312134027481079
Epoch: 19, Steps: 265 Train Loss: 3.3215 (Forecasting Loss:0.1948 + XiCon Loss:3.1267 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1594
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3159394
	speed: 0.0538s/iter; left time: 1148.6210s
	iters: 200, epoch: 20 | loss: 3.3564718
	speed: 0.0433s/iter; left time: 921.4113s
Epoch: 20 cost time: 11.63739800453186
Epoch: 20, Steps: 265 Train Loss: 3.3202 (Forecasting Loss:0.1949 + XiCon Loss:3.1253 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
Validation loss decreased (0.199885 --> 0.199876).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3207383
	speed: 0.0310s/iter; left time: 654.8518s
	iters: 200, epoch: 21 | loss: 3.3163574
	speed: 0.0470s/iter; left time: 987.2669s
Epoch: 21 cost time: 11.438412189483643
Epoch: 21, Steps: 265 Train Loss: 3.3226 (Forecasting Loss:0.1949 + XiCon Loss:3.1277 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1594
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.3213077
	speed: 0.0594s/iter; left time: 1238.3065s
	iters: 200, epoch: 22 | loss: 3.2689636
	speed: 0.0566s/iter; left time: 1173.4349s
Epoch: 22 cost time: 15.194025754928589
Epoch: 22, Steps: 265 Train Loss: 3.3193 (Forecasting Loss:0.1948 + XiCon Loss:3.1245 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1594
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3173401
	speed: 0.0593s/iter; left time: 1219.4017s
	iters: 200, epoch: 23 | loss: 3.2938712
	speed: 0.0535s/iter; left time: 1094.7399s
Epoch: 23 cost time: 14.179219722747803
Epoch: 23, Steps: 265 Train Loss: 3.3199 (Forecasting Loss:0.1948 + XiCon Loss:3.1251 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.2390146
	speed: 0.0318s/iter; left time: 645.3322s
	iters: 200, epoch: 24 | loss: 3.3766491
	speed: 0.0308s/iter; left time: 622.0907s
Epoch: 24 cost time: 8.842290163040161
Epoch: 24, Steps: 265 Train Loss: 3.3187 (Forecasting Loss:0.1948 + XiCon Loss:3.1239 x Lambda(1.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1594
Validation loss decreased (0.199876 --> 0.199673).  Saving model ...
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2644105
	speed: 0.0573s/iter; left time: 1149.1915s
	iters: 200, epoch: 25 | loss: 3.2863283
	speed: 0.0551s/iter; left time: 1098.6919s
Epoch: 25 cost time: 14.930591344833374
Epoch: 25, Steps: 265 Train Loss: 3.3214 (Forecasting Loss:0.1949 + XiCon Loss:3.1265 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2859664
	speed: 0.0592s/iter; left time: 1170.3620s
	iters: 200, epoch: 26 | loss: 3.3154974
	speed: 0.0559s/iter; left time: 1099.6612s
Epoch: 26 cost time: 15.153313398361206
Epoch: 26, Steps: 265 Train Loss: 3.3257 (Forecasting Loss:0.1949 + XiCon Loss:3.1309 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3447709
	speed: 0.0451s/iter; left time: 879.2539s
	iters: 200, epoch: 27 | loss: 3.2796998
	speed: 0.0289s/iter; left time: 560.4072s
Epoch: 27 cost time: 9.236357927322388
Epoch: 27, Steps: 265 Train Loss: 3.3256 (Forecasting Loss:0.1948 + XiCon Loss:3.1308 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1594
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.2739410
	speed: 0.0493s/iter; left time: 948.5664s
	iters: 200, epoch: 28 | loss: 3.2895272
	speed: 0.0580s/iter; left time: 1111.1510s
Epoch: 28 cost time: 14.453250169754028
Epoch: 28, Steps: 265 Train Loss: 3.3195 (Forecasting Loss:0.1947 + XiCon Loss:3.1248 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.2976615
	speed: 0.0584s/iter; left time: 1107.6917s
	iters: 200, epoch: 29 | loss: 3.3703055
	speed: 0.0581s/iter; left time: 1096.2953s
Epoch: 29 cost time: 15.260969161987305
Epoch: 29, Steps: 265 Train Loss: 3.3187 (Forecasting Loss:0.1948 + XiCon Loss:3.1239 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2338204
	speed: 0.0540s/iter; left time: 1011.2693s
	iters: 200, epoch: 30 | loss: 3.3304110
	speed: 0.0414s/iter; left time: 770.6615s
Epoch: 30 cost time: 11.389864921569824
Epoch: 30, Steps: 265 Train Loss: 3.3179 (Forecasting Loss:0.1948 + XiCon Loss:3.1230 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.3822045
	speed: 0.0314s/iter; left time: 578.7696s
	iters: 200, epoch: 31 | loss: 3.2495332
	speed: 0.0478s/iter; left time: 876.6257s
Epoch: 31 cost time: 11.64804196357727
Epoch: 31, Steps: 265 Train Loss: 3.3218 (Forecasting Loss:0.1948 + XiCon Loss:3.1270 x Lambda(1.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1594
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.2832978
	speed: 0.0574s/iter; left time: 1044.2410s
	iters: 200, epoch: 32 | loss: 3.3078094
	speed: 0.0546s/iter; left time: 986.6583s
Epoch: 32 cost time: 14.78153109550476
Epoch: 32, Steps: 265 Train Loss: 3.3182 (Forecasting Loss:0.1948 + XiCon Loss:3.1234 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1594
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.2366877
	speed: 0.0604s/iter; left time: 1082.0563s
	iters: 200, epoch: 33 | loss: 3.4169698
	speed: 0.0506s/iter; left time: 902.3788s
Epoch: 33 cost time: 14.09751033782959
Epoch: 33, Steps: 265 Train Loss: 3.3202 (Forecasting Loss:0.1948 + XiCon Loss:3.1254 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1594
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.2550607
	speed: 0.0317s/iter; left time: 560.0755s
	iters: 200, epoch: 34 | loss: 3.3609428
	speed: 0.0303s/iter; left time: 531.2169s
Epoch: 34 cost time: 8.958511352539062
Epoch: 34, Steps: 265 Train Loss: 3.3213 (Forecasting Loss:0.1949 + XiCon Loss:3.1264 x Lambda(1.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1594
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09234797954559326, mae:0.22636741399765015, mape:0.5448164343833923, mspe:11.181074142456055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9999
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.4870872
	speed: 0.0581s/iter; left time: 1533.7814s
	iters: 200, epoch: 1 | loss: 3.3994036
	speed: 0.0564s/iter; left time: 1483.0535s
Epoch: 1 cost time: 14.491037130355835
Epoch: 1, Steps: 265 Train Loss: 3.4780 (Forecasting Loss:0.2266 + XiCon Loss:3.2514 x Lambda(1.0)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1664
Validation loss decreased (inf --> 0.208172).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4887519
	speed: 0.0358s/iter; left time: 936.9180s
	iters: 200, epoch: 2 | loss: 3.3274138
	speed: 0.0294s/iter; left time: 766.2728s
Epoch: 2 cost time: 8.445784568786621
Epoch: 2, Steps: 265 Train Loss: 3.3889 (Forecasting Loss:0.2079 + XiCon Loss:3.1810 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2637599
	speed: 0.0575s/iter; left time: 1487.1781s
	iters: 200, epoch: 3 | loss: 3.3540726
	speed: 0.0568s/iter; left time: 1462.8014s
Epoch: 3 cost time: 15.178693771362305
Epoch: 3, Steps: 265 Train Loss: 3.3167 (Forecasting Loss:0.2010 + XiCon Loss:3.1157 x Lambda(1.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1645
Validation loss decreased (0.208172 --> 0.202979).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2600989
	speed: 0.0581s/iter; left time: 1487.0696s
	iters: 200, epoch: 4 | loss: 3.2067242
	speed: 0.0551s/iter; left time: 1406.1212s
Epoch: 4 cost time: 14.915763139724731
Epoch: 4, Steps: 265 Train Loss: 3.2427 (Forecasting Loss:0.1987 + XiCon Loss:3.0440 x Lambda(1.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1609
Validation loss decreased (0.202979 --> 0.199510).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2486153
	speed: 0.0466s/iter; left time: 1179.6369s
	iters: 200, epoch: 5 | loss: 3.2660544
	speed: 0.0484s/iter; left time: 1221.1084s
Epoch: 5 cost time: 13.253735780715942
Epoch: 5, Steps: 265 Train Loss: 3.2214 (Forecasting Loss:0.1974 + XiCon Loss:3.0241 x Lambda(1.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1600
Validation loss decreased (0.199510 --> 0.198476).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1820195
	speed: 0.0570s/iter; left time: 1429.4244s
	iters: 200, epoch: 6 | loss: 3.2288833
	speed: 0.0576s/iter; left time: 1439.2556s
Epoch: 6 cost time: 15.149061441421509
Epoch: 6, Steps: 265 Train Loss: 3.2169 (Forecasting Loss:0.1965 + XiCon Loss:3.0203 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1600
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2415011
	speed: 0.0596s/iter; left time: 1477.6640s
	iters: 200, epoch: 7 | loss: 3.2582564
	speed: 0.0564s/iter; left time: 1394.3236s
Epoch: 7 cost time: 14.468648433685303
Epoch: 7, Steps: 265 Train Loss: 3.2188 (Forecasting Loss:0.1960 + XiCon Loss:3.0228 x Lambda(1.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1594
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1840072
	speed: 0.0550s/iter; left time: 1349.9306s
	iters: 200, epoch: 8 | loss: 3.1892765
	speed: 0.0569s/iter; left time: 1390.1153s
Epoch: 8 cost time: 14.82673978805542
Epoch: 8, Steps: 265 Train Loss: 3.2137 (Forecasting Loss:0.1960 + XiCon Loss:3.0177 x Lambda(1.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1592
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1879742
	speed: 0.0607s/iter; left time: 1474.8769s
	iters: 200, epoch: 9 | loss: 3.1986701
	speed: 0.0557s/iter; left time: 1346.0668s
Epoch: 9 cost time: 15.215754747390747
Epoch: 9, Steps: 265 Train Loss: 3.2126 (Forecasting Loss:0.1957 + XiCon Loss:3.0168 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2462535
	speed: 0.0510s/iter; left time: 1225.0522s
	iters: 200, epoch: 10 | loss: 3.1806297
	speed: 0.0418s/iter; left time: 1000.8333s
Epoch: 10 cost time: 11.083452701568604
Epoch: 10, Steps: 265 Train Loss: 3.2114 (Forecasting Loss:0.1957 + XiCon Loss:3.0157 x Lambda(1.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1590
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1762786
	speed: 0.0320s/iter; left time: 759.6831s
	iters: 200, epoch: 11 | loss: 3.1968937
	speed: 0.0509s/iter; left time: 1203.3298s
Epoch: 11 cost time: 11.959113597869873
Epoch: 11, Steps: 265 Train Loss: 3.2132 (Forecasting Loss:0.1956 + XiCon Loss:3.0176 x Lambda(1.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1590
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2233975
	speed: 0.0588s/iter; left time: 1380.7444s
	iters: 200, epoch: 12 | loss: 3.2138016
	speed: 0.0551s/iter; left time: 1288.0540s
Epoch: 12 cost time: 15.091895818710327
Epoch: 12, Steps: 265 Train Loss: 3.2132 (Forecasting Loss:0.1957 + XiCon Loss:3.0175 x Lambda(1.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1590
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2560964
	speed: 0.0583s/iter; left time: 1353.1028s
	iters: 200, epoch: 13 | loss: 3.2163785
	speed: 0.0485s/iter; left time: 1120.8901s
Epoch: 13 cost time: 13.60338044166565
Epoch: 13, Steps: 265 Train Loss: 3.2129 (Forecasting Loss:0.1956 + XiCon Loss:3.0173 x Lambda(1.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1590
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1904657
	speed: 0.0312s/iter; left time: 715.5542s
	iters: 200, epoch: 14 | loss: 3.2038600
	speed: 0.0291s/iter; left time: 663.9992s
Epoch: 14 cost time: 8.950995206832886
Epoch: 14, Steps: 265 Train Loss: 3.2110 (Forecasting Loss:0.1956 + XiCon Loss:3.0154 x Lambda(1.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1590
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2098820
	speed: 0.0579s/iter; left time: 1313.3499s
	iters: 200, epoch: 15 | loss: 3.1784983
	speed: 0.0567s/iter; left time: 1280.4412s
Epoch: 15 cost time: 15.071118831634521
Epoch: 15, Steps: 265 Train Loss: 3.2119 (Forecasting Loss:0.1956 + XiCon Loss:3.0162 x Lambda(1.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1590
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09322421997785568, mae:0.22685112059116364, mape:0.5434156656265259, mspe:11.024513244628906 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1463
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5674386
	speed: 0.0548s/iter; left time: 1446.6134s
	iters: 200, epoch: 1 | loss: 3.4004269
	speed: 0.0561s/iter; left time: 1475.5591s
Epoch: 1 cost time: 14.646250009536743
Epoch: 1, Steps: 265 Train Loss: 3.5021 (Forecasting Loss:0.2284 + XiCon Loss:3.2738 x Lambda(1.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1673
Validation loss decreased (inf --> 0.211288).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3815963
	speed: 0.0570s/iter; left time: 1489.7168s
	iters: 200, epoch: 2 | loss: 3.7324054
	speed: 0.0546s/iter; left time: 1422.2168s
Epoch: 2 cost time: 14.8465416431427
Epoch: 2, Steps: 265 Train Loss: 3.5032 (Forecasting Loss:0.2066 + XiCon Loss:3.2966 x Lambda(1.0)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1666
Validation loss decreased (0.211288 --> 0.205283).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.6341276
	speed: 0.0520s/iter; left time: 1344.7232s
	iters: 200, epoch: 3 | loss: 3.5309663
	speed: 0.0446s/iter; left time: 1149.4638s
Epoch: 3 cost time: 13.301008224487305
Epoch: 3, Steps: 265 Train Loss: 3.5795 (Forecasting Loss:0.2007 + XiCon Loss:3.3787 x Lambda(1.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1646
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.4685152
	speed: 0.0585s/iter; left time: 1497.5950s
	iters: 200, epoch: 4 | loss: 3.3975840
	speed: 0.0562s/iter; left time: 1433.5873s
Epoch: 4 cost time: 14.936650514602661
Epoch: 4, Steps: 265 Train Loss: 3.5239 (Forecasting Loss:0.1988 + XiCon Loss:3.3251 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1611
Validation loss decreased (0.205283 --> 0.199177).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4915376
	speed: 0.0597s/iter; left time: 1513.8980s
	iters: 200, epoch: 5 | loss: 3.5688114
	speed: 0.0574s/iter; left time: 1448.9458s
Epoch: 5 cost time: 14.862162590026855
Epoch: 5, Steps: 265 Train Loss: 3.5188 (Forecasting Loss:0.1972 + XiCon Loss:3.3216 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1607
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4625852
	speed: 0.0514s/iter; left time: 1289.1258s
	iters: 200, epoch: 6 | loss: 3.5073540
	speed: 0.0586s/iter; left time: 1464.6554s
Epoch: 6 cost time: 14.723624467849731
Epoch: 6, Steps: 265 Train Loss: 3.5196 (Forecasting Loss:0.1965 + XiCon Loss:3.3232 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1601
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.4988399
	speed: 0.0580s/iter; left time: 1439.8401s
	iters: 200, epoch: 7 | loss: 3.4987276
	speed: 0.0577s/iter; left time: 1426.3882s
Epoch: 7 cost time: 15.178239583969116
Epoch: 7, Steps: 265 Train Loss: 3.5133 (Forecasting Loss:0.1960 + XiCon Loss:3.3173 x Lambda(1.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1601
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5315883
	speed: 0.0575s/iter; left time: 1412.0756s
	iters: 200, epoch: 8 | loss: 3.5080338
	speed: 0.0445s/iter; left time: 1088.6155s
Epoch: 8 cost time: 13.384005069732666
Epoch: 8, Steps: 265 Train Loss: 3.5050 (Forecasting Loss:0.1958 + XiCon Loss:3.3092 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1598
Validation loss decreased (0.199177 --> 0.198956).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4994829
	speed: 0.0578s/iter; left time: 1403.8665s
	iters: 200, epoch: 9 | loss: 3.5246897
	speed: 0.0578s/iter; left time: 1396.5875s
Epoch: 9 cost time: 15.169832468032837
Epoch: 9, Steps: 265 Train Loss: 3.5058 (Forecasting Loss:0.1957 + XiCon Loss:3.3100 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1597
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4831023
	speed: 0.0579s/iter; left time: 1391.4022s
	iters: 200, epoch: 10 | loss: 3.5969450
	speed: 0.0566s/iter; left time: 1354.1257s
Epoch: 10 cost time: 14.9385085105896
Epoch: 10, Steps: 265 Train Loss: 3.4983 (Forecasting Loss:0.1957 + XiCon Loss:3.3026 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1597
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4227011
	speed: 0.0471s/iter; left time: 1118.1521s
	iters: 200, epoch: 11 | loss: 3.6049786
	speed: 0.0560s/iter; left time: 1323.9871s
Epoch: 11 cost time: 14.031413555145264
Epoch: 11, Steps: 265 Train Loss: 3.5030 (Forecasting Loss:0.1956 + XiCon Loss:3.3074 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1597
Validation loss decreased (0.198956 --> 0.198893).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4049809
	speed: 0.0569s/iter; left time: 1337.2923s
	iters: 200, epoch: 12 | loss: 3.3941886
	speed: 0.0562s/iter; left time: 1313.5420s
Epoch: 12 cost time: 14.660820484161377
Epoch: 12, Steps: 265 Train Loss: 3.5000 (Forecasting Loss:0.1956 + XiCon Loss:3.3044 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1597
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.5280833
	speed: 0.0624s/iter; left time: 1448.3066s
	iters: 200, epoch: 13 | loss: 3.5433488
	speed: 0.0429s/iter; left time: 991.9753s
Epoch: 13 cost time: 13.521604537963867
Epoch: 13, Steps: 265 Train Loss: 3.4966 (Forecasting Loss:0.1956 + XiCon Loss:3.3010 x Lambda(1.0)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1597
Validation loss decreased (0.198893 --> 0.198497).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4662044
	speed: 0.0568s/iter; left time: 1304.1106s
	iters: 200, epoch: 14 | loss: 3.4865317
	speed: 0.0558s/iter; left time: 1275.2611s
Epoch: 14 cost time: 15.045563220977783
Epoch: 14, Steps: 265 Train Loss: 3.4985 (Forecasting Loss:0.1955 + XiCon Loss:3.3030 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1597
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.5122039
	speed: 0.0601s/iter; left time: 1363.3283s
	iters: 200, epoch: 15 | loss: 3.4521787
	speed: 0.0556s/iter; left time: 1257.1042s
Epoch: 15 cost time: 15.194593906402588
Epoch: 15, Steps: 265 Train Loss: 3.4968 (Forecasting Loss:0.1956 + XiCon Loss:3.3012 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1597
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4497247
	speed: 0.0456s/iter; left time: 1021.8933s
	iters: 200, epoch: 16 | loss: 3.4466166
	speed: 0.0541s/iter; left time: 1208.7953s
Epoch: 16 cost time: 13.538474321365356
Epoch: 16, Steps: 265 Train Loss: 3.5060 (Forecasting Loss:0.1956 + XiCon Loss:3.3104 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1597
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3956921
	speed: 0.0582s/iter; left time: 1289.0492s
	iters: 200, epoch: 17 | loss: 3.3547862
	speed: 0.0568s/iter; left time: 1253.4903s
Epoch: 17 cost time: 15.134628534317017
Epoch: 17, Steps: 265 Train Loss: 3.5039 (Forecasting Loss:0.1956 + XiCon Loss:3.3083 x Lambda(1.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1597
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4225550
	speed: 0.0595s/iter; left time: 1303.1557s
	iters: 200, epoch: 18 | loss: 3.4405663
	speed: 0.0459s/iter; left time: 1001.5177s
Epoch: 18 cost time: 13.39589810371399
Epoch: 18, Steps: 265 Train Loss: 3.4980 (Forecasting Loss:0.1955 + XiCon Loss:3.3026 x Lambda(1.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1597
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4706681
	speed: 0.0565s/iter; left time: 1223.1615s
	iters: 200, epoch: 19 | loss: 3.4657726
	speed: 0.0588s/iter; left time: 1266.6226s
Epoch: 19 cost time: 15.119550228118896
Epoch: 19, Steps: 265 Train Loss: 3.5017 (Forecasting Loss:0.1956 + XiCon Loss:3.3061 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1597
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.5177896
	speed: 0.0578s/iter; left time: 1234.6332s
	iters: 200, epoch: 20 | loss: 3.5399740
	speed: 0.0577s/iter; left time: 1226.8163s
Epoch: 20 cost time: 14.973750829696655
Epoch: 20, Steps: 265 Train Loss: 3.5050 (Forecasting Loss:0.1955 + XiCon Loss:3.3095 x Lambda(1.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1597
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.5549390
	speed: 0.0475s/iter; left time: 1003.1021s
	iters: 200, epoch: 21 | loss: 3.5439210
	speed: 0.0510s/iter; left time: 1070.2676s
Epoch: 21 cost time: 13.468945264816284
Epoch: 21, Steps: 265 Train Loss: 3.5054 (Forecasting Loss:0.1955 + XiCon Loss:3.3099 x Lambda(1.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1597
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.5262785
	speed: 0.0576s/iter; left time: 1200.2156s
	iters: 200, epoch: 22 | loss: 3.4482942
	speed: 0.0594s/iter; left time: 1231.4817s
Epoch: 22 cost time: 15.373685359954834
Epoch: 22, Steps: 265 Train Loss: 3.4930 (Forecasting Loss:0.1956 + XiCon Loss:3.2974 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1597
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.4812233
	speed: 0.0581s/iter; left time: 1195.0550s
	iters: 200, epoch: 23 | loss: 3.4770021
	speed: 0.0507s/iter; left time: 1037.3843s
Epoch: 23 cost time: 13.839776039123535
Epoch: 23, Steps: 265 Train Loss: 3.5017 (Forecasting Loss:0.1955 + XiCon Loss:3.3062 x Lambda(1.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1597
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09272066503763199, mae:0.22675538063049316, mape:0.5441009998321533, mspe:11.23592472076416 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0926+-0.00064, MAE:0.2264+-0.00064, MAPE:0.5441+-0.00120, MSPE:11.2216+-0.16201, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.1897
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.7874832
	speed: 0.0823s/iter; left time: 2098.4512s
	iters: 200, epoch: 1 | loss: 3.8413663
	speed: 0.0751s/iter; left time: 1906.8942s
Epoch: 1 cost time: 20.04327082633972
Epoch: 1, Steps: 256 Train Loss: 3.8096 (Forecasting Loss:0.4343 + XiCon Loss:3.3753 x Lambda(1.0)), Vali MSE Loss: 0.4134 Test MSE Loss: 0.3834
Validation loss decreased (inf --> 0.413446).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.6367075
	speed: 0.0784s/iter; left time: 1978.4920s
	iters: 200, epoch: 2 | loss: 3.6198940
	speed: 0.0752s/iter; left time: 1889.7736s
Epoch: 2 cost time: 19.72505235671997
Epoch: 2, Steps: 256 Train Loss: 3.6626 (Forecasting Loss:0.3463 + XiCon Loss:3.3163 x Lambda(1.0)), Vali MSE Loss: 0.3246 Test MSE Loss: 0.3033
Validation loss decreased (0.413446 --> 0.324622).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5821514
	speed: 0.0804s/iter; left time: 2009.7651s
	iters: 200, epoch: 3 | loss: 3.5194228
	speed: 0.0781s/iter; left time: 1943.2418s
Epoch: 3 cost time: 19.998867511749268
Epoch: 3, Steps: 256 Train Loss: 3.5401 (Forecasting Loss:0.3236 + XiCon Loss:3.2165 x Lambda(1.0)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.3014
Validation loss decreased (0.324622 --> 0.315336).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5157108
	speed: 0.0802s/iter; left time: 1982.3899s
	iters: 200, epoch: 4 | loss: 3.5218718
	speed: 0.0764s/iter; left time: 1882.1575s
Epoch: 4 cost time: 19.882095336914062
Epoch: 4, Steps: 256 Train Loss: 3.5045 (Forecasting Loss:0.3212 + XiCon Loss:3.1833 x Lambda(1.0)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.3005
Validation loss decreased (0.315336 --> 0.315140).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.4843066
	speed: 0.0778s/iter; left time: 1905.2106s
	iters: 200, epoch: 5 | loss: 3.5471511
	speed: 0.0768s/iter; left time: 1873.0950s
Epoch: 5 cost time: 19.79534101486206
Epoch: 5, Steps: 256 Train Loss: 3.4898 (Forecasting Loss:0.3207 + XiCon Loss:3.1691 x Lambda(1.0)), Vali MSE Loss: 0.3144 Test MSE Loss: 0.2999
Validation loss decreased (0.315140 --> 0.314415).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.4639490
	speed: 0.0809s/iter; left time: 1958.3092s
	iters: 200, epoch: 6 | loss: 3.4776020
	speed: 0.0797s/iter; left time: 1921.5409s
Epoch: 6 cost time: 20.394163370132446
Epoch: 6, Steps: 256 Train Loss: 3.4834 (Forecasting Loss:0.3211 + XiCon Loss:3.1623 x Lambda(1.0)), Vali MSE Loss: 0.3116 Test MSE Loss: 0.3005
Validation loss decreased (0.314415 --> 0.311615).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5060403
	speed: 0.0767s/iter; left time: 1837.5885s
	iters: 200, epoch: 7 | loss: 3.4797459
	speed: 0.0783s/iter; left time: 1869.1172s
Epoch: 7 cost time: 19.92009425163269
Epoch: 7, Steps: 256 Train Loss: 3.4805 (Forecasting Loss:0.3213 + XiCon Loss:3.1592 x Lambda(1.0)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.3002
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.4723372
	speed: 0.0812s/iter; left time: 1924.0502s
	iters: 200, epoch: 8 | loss: 3.4666884
	speed: 0.0775s/iter; left time: 1830.5010s
Epoch: 8 cost time: 20.154614686965942
Epoch: 8, Steps: 256 Train Loss: 3.4795 (Forecasting Loss:0.3215 + XiCon Loss:3.1580 x Lambda(1.0)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.3000
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.5264285
	speed: 0.0808s/iter; left time: 1894.2467s
	iters: 200, epoch: 9 | loss: 3.5025842
	speed: 0.0753s/iter; left time: 1758.7691s
Epoch: 9 cost time: 19.829084396362305
Epoch: 9, Steps: 256 Train Loss: 3.4797 (Forecasting Loss:0.3216 + XiCon Loss:3.1581 x Lambda(1.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.2999
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4921944
	speed: 0.0796s/iter; left time: 1846.9940s
	iters: 200, epoch: 10 | loss: 3.4930031
	speed: 0.0777s/iter; left time: 1795.7447s
Epoch: 10 cost time: 20.107439517974854
Epoch: 10, Steps: 256 Train Loss: 3.4774 (Forecasting Loss:0.3216 + XiCon Loss:3.1558 x Lambda(1.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.2999
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.5061228
	speed: 0.0789s/iter; left time: 1809.7754s
	iters: 200, epoch: 11 | loss: 3.4908316
	speed: 0.0792s/iter; left time: 1807.9734s
Epoch: 11 cost time: 20.316171407699585
Epoch: 11, Steps: 256 Train Loss: 3.4791 (Forecasting Loss:0.3216 + XiCon Loss:3.1575 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2999
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.4895387
	speed: 0.0804s/iter; left time: 1823.4646s
	iters: 200, epoch: 12 | loss: 3.4672999
	speed: 0.0762s/iter; left time: 1721.3576s
Epoch: 12 cost time: 19.953895807266235
Epoch: 12, Steps: 256 Train Loss: 3.4785 (Forecasting Loss:0.3215 + XiCon Loss:3.1569 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2999
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.4788327
	speed: 0.0779s/iter; left time: 1747.8428s
	iters: 200, epoch: 13 | loss: 3.4913435
	speed: 0.0772s/iter; left time: 1724.5544s
Epoch: 13 cost time: 19.914632320404053
Epoch: 13, Steps: 256 Train Loss: 3.4788 (Forecasting Loss:0.3215 + XiCon Loss:3.1573 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2999
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.4898329
	speed: 0.0811s/iter; left time: 1798.6112s
	iters: 200, epoch: 14 | loss: 3.4812539
	speed: 0.0766s/iter; left time: 1691.7990s
Epoch: 14 cost time: 19.920788049697876
Epoch: 14, Steps: 256 Train Loss: 3.4778 (Forecasting Loss:0.3216 + XiCon Loss:3.1562 x Lambda(1.0)), Vali MSE Loss: 0.3125 Test MSE Loss: 0.2999
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4851432
	speed: 0.0796s/iter; left time: 1743.6249s
	iters: 200, epoch: 15 | loss: 3.4491878
	speed: 0.0781s/iter; left time: 1704.4429s
Epoch: 15 cost time: 20.163496255874634
Epoch: 15, Steps: 256 Train Loss: 3.4771 (Forecasting Loss:0.3215 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2999
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.5321264
	speed: 0.0797s/iter; left time: 1725.4627s
	iters: 200, epoch: 16 | loss: 3.4541793
	speed: 0.0767s/iter; left time: 1654.6653s
Epoch: 16 cost time: 20.096186876296997
Epoch: 16, Steps: 256 Train Loss: 3.4778 (Forecasting Loss:0.3217 + XiCon Loss:3.1562 x Lambda(1.0)), Vali MSE Loss: 0.3125 Test MSE Loss: 0.2999
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22666871547698975, mae:0.37436985969543457, mape:0.7856875658035278, mspe:20.980085372924805 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9216
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.7936747
	speed: 0.0767s/iter; left time: 1955.2394s
	iters: 200, epoch: 1 | loss: 3.7786524
	speed: 0.0721s/iter; left time: 1831.6755s
Epoch: 1 cost time: 18.851370573043823
Epoch: 1, Steps: 256 Train Loss: 3.7984 (Forecasting Loss:0.4375 + XiCon Loss:3.3610 x Lambda(1.0)), Vali MSE Loss: 0.4230 Test MSE Loss: 0.3914
Validation loss decreased (inf --> 0.422966).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.6964171
	speed: 0.0632s/iter; left time: 1596.7310s
	iters: 200, epoch: 2 | loss: 3.6243396
	speed: 0.0631s/iter; left time: 1586.7385s
Epoch: 2 cost time: 18.245736360549927
Epoch: 2, Steps: 256 Train Loss: 3.6451 (Forecasting Loss:0.3525 + XiCon Loss:3.2926 x Lambda(1.0)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.3045
Validation loss decreased (0.422966 --> 0.338626).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5491211
	speed: 0.0391s/iter; left time: 976.4673s
	iters: 200, epoch: 3 | loss: 3.4900372
	speed: 0.0520s/iter; left time: 1293.6481s
Epoch: 3 cost time: 13.284924983978271
Epoch: 3, Steps: 256 Train Loss: 3.5193 (Forecasting Loss:0.3344 + XiCon Loss:3.1849 x Lambda(1.0)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.3032
Validation loss decreased (0.338626 --> 0.335618).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.4749136
	speed: 0.0749s/iter; left time: 1852.8897s
	iters: 200, epoch: 4 | loss: 3.5111425
	speed: 0.0726s/iter; left time: 1787.9156s
Epoch: 4 cost time: 18.776607275009155
Epoch: 4, Steps: 256 Train Loss: 3.4978 (Forecasting Loss:0.3323 + XiCon Loss:3.1655 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3015
Validation loss decreased (0.335618 --> 0.333571).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5018108
	speed: 0.0745s/iter; left time: 1823.5307s
	iters: 200, epoch: 5 | loss: 3.4889824
	speed: 0.0585s/iter; left time: 1426.3210s
Epoch: 5 cost time: 17.351841688156128
Epoch: 5, Steps: 256 Train Loss: 3.4937 (Forecasting Loss:0.3315 + XiCon Loss:3.1623 x Lambda(1.0)), Vali MSE Loss: 0.3347 Test MSE Loss: 0.3026
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.4803376
	speed: 0.0743s/iter; left time: 1798.6700s
	iters: 200, epoch: 6 | loss: 3.5227518
	speed: 0.0744s/iter; left time: 1794.8589s
Epoch: 6 cost time: 19.0377357006073
Epoch: 6, Steps: 256 Train Loss: 3.4936 (Forecasting Loss:0.3310 + XiCon Loss:3.1626 x Lambda(1.0)), Vali MSE Loss: 0.3339 Test MSE Loss: 0.3019
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.5239458
	speed: 0.0751s/iter; left time: 1800.1004s
	iters: 200, epoch: 7 | loss: 3.4828882
	speed: 0.0621s/iter; left time: 1481.3516s
Epoch: 7 cost time: 15.73378324508667
Epoch: 7, Steps: 256 Train Loss: 3.4950 (Forecasting Loss:0.3308 + XiCon Loss:3.1641 x Lambda(1.0)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.3014
Validation loss decreased (0.333571 --> 0.333279).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5122080
	speed: 0.0409s/iter; left time: 968.7780s
	iters: 200, epoch: 8 | loss: 3.4952085
	speed: 0.0755s/iter; left time: 1781.7680s
Epoch: 8 cost time: 15.862749338150024
Epoch: 8, Steps: 256 Train Loss: 3.4937 (Forecasting Loss:0.3308 + XiCon Loss:3.1629 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3017
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.4666781
	speed: 0.0779s/iter; left time: 1827.1548s
	iters: 200, epoch: 9 | loss: 3.4741931
	speed: 0.0739s/iter; left time: 1724.8877s
Epoch: 9 cost time: 19.184817790985107
Epoch: 9, Steps: 256 Train Loss: 3.4947 (Forecasting Loss:0.3308 + XiCon Loss:3.1639 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3017
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4611986
	speed: 0.0658s/iter; left time: 1526.1267s
	iters: 200, epoch: 10 | loss: 3.5296113
	speed: 0.0342s/iter; left time: 789.4078s
Epoch: 10 cost time: 11.88225531578064
Epoch: 10, Steps: 256 Train Loss: 3.4943 (Forecasting Loss:0.3308 + XiCon Loss:3.1635 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.4958243
	speed: 0.0743s/iter; left time: 1703.6020s
	iters: 200, epoch: 11 | loss: 3.4566538
	speed: 0.0752s/iter; left time: 1717.0358s
Epoch: 11 cost time: 19.146129608154297
Epoch: 11, Steps: 256 Train Loss: 3.4957 (Forecasting Loss:0.3307 + XiCon Loss:3.1650 x Lambda(1.0)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.3017
Validation loss decreased (0.333279 --> 0.333270).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.4836516
	speed: 0.0788s/iter; left time: 1787.1727s
	iters: 200, epoch: 12 | loss: 3.5059118
	speed: 0.0715s/iter; left time: 1614.4760s
Epoch: 12 cost time: 19.451740980148315
Epoch: 12, Steps: 256 Train Loss: 3.4958 (Forecasting Loss:0.3308 + XiCon Loss:3.1650 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3017
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.5210602
	speed: 0.0377s/iter; left time: 845.7764s
	iters: 200, epoch: 13 | loss: 3.5288591
	speed: 0.0348s/iter; left time: 777.2120s
Epoch: 13 cost time: 10.56895399093628
Epoch: 13, Steps: 256 Train Loss: 3.4956 (Forecasting Loss:0.3307 + XiCon Loss:3.1649 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3017
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.5143006
	speed: 0.0764s/iter; left time: 1695.0505s
	iters: 200, epoch: 14 | loss: 3.5570898
	speed: 0.0766s/iter; left time: 1690.5404s
Epoch: 14 cost time: 19.321120500564575
Epoch: 14, Steps: 256 Train Loss: 3.4961 (Forecasting Loss:0.3309 + XiCon Loss:3.1652 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3017
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4852514
	speed: 0.0772s/iter; left time: 1691.6106s
	iters: 200, epoch: 15 | loss: 3.5073001
	speed: 0.0728s/iter; left time: 1587.8551s
Epoch: 15 cost time: 17.121523141860962
Epoch: 15, Steps: 256 Train Loss: 3.4944 (Forecasting Loss:0.3306 + XiCon Loss:3.1637 x Lambda(1.0)), Vali MSE Loss: 0.3334 Test MSE Loss: 0.3017
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.4868188
	speed: 0.0372s/iter; left time: 805.1009s
	iters: 200, epoch: 16 | loss: 3.5198767
	speed: 0.0615s/iter; left time: 1326.0399s
Epoch: 16 cost time: 14.022113561630249
Epoch: 16, Steps: 256 Train Loss: 3.4958 (Forecasting Loss:0.3307 + XiCon Loss:3.1651 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3017
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.5132232
	speed: 0.0774s/iter; left time: 1656.7947s
	iters: 200, epoch: 17 | loss: 3.4751043
	speed: 0.0736s/iter; left time: 1567.1849s
Epoch: 17 cost time: 19.231031894683838
Epoch: 17, Steps: 256 Train Loss: 3.4949 (Forecasting Loss:0.3308 + XiCon Loss:3.1641 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.5161402
	speed: 0.0740s/iter; left time: 1565.4415s
	iters: 200, epoch: 18 | loss: 3.5114126
	speed: 0.0429s/iter; left time: 902.2475s
Epoch: 18 cost time: 13.603280544281006
Epoch: 18, Steps: 256 Train Loss: 3.4932 (Forecasting Loss:0.3307 + XiCon Loss:3.1625 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3017
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.4851584
	speed: 0.0581s/iter; left time: 1214.6948s
	iters: 200, epoch: 19 | loss: 3.5219631
	speed: 0.0738s/iter; left time: 1535.2725s
Epoch: 19 cost time: 17.39869475364685
Epoch: 19, Steps: 256 Train Loss: 3.4933 (Forecasting Loss:0.3309 + XiCon Loss:3.1625 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3017
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.4767938
	speed: 0.0771s/iter; left time: 1590.5382s
	iters: 200, epoch: 20 | loss: 3.4965830
	speed: 0.0742s/iter; left time: 1524.0905s
Epoch: 20 cost time: 19.05234146118164
Epoch: 20, Steps: 256 Train Loss: 3.4937 (Forecasting Loss:0.3308 + XiCon Loss:3.1628 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3017
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.5330803
	speed: 0.0506s/iter; left time: 1031.8054s
	iters: 200, epoch: 21 | loss: 3.4651256
	speed: 0.0340s/iter; left time: 689.9475s
Epoch: 21 cost time: 10.379285097122192
Epoch: 21, Steps: 256 Train Loss: 3.4945 (Forecasting Loss:0.3307 + XiCon Loss:3.1638 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3017
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22418542206287384, mae:0.37917545437812805, mape:0.7178046703338623, mspe:18.24500274658203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4217
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.8683605
	speed: 0.0805s/iter; left time: 2053.2244s
	iters: 200, epoch: 1 | loss: 3.8311820
	speed: 0.0725s/iter; left time: 1841.9993s
Epoch: 1 cost time: 19.375811338424683
Epoch: 1, Steps: 256 Train Loss: 3.8258 (Forecasting Loss:0.4351 + XiCon Loss:3.3907 x Lambda(1.0)), Vali MSE Loss: 0.4088 Test MSE Loss: 0.3795
Validation loss decreased (inf --> 0.408789).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.6347876
	speed: 0.0817s/iter; left time: 2062.8857s
	iters: 200, epoch: 2 | loss: 3.5584781
	speed: 0.0785s/iter; left time: 1972.6780s
Epoch: 2 cost time: 20.52749013900757
Epoch: 2, Steps: 256 Train Loss: 3.6505 (Forecasting Loss:0.3538 + XiCon Loss:3.2966 x Lambda(1.0)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.3076
Validation loss decreased (0.408789 --> 0.338808).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5601666
	speed: 0.0829s/iter; left time: 2070.7025s
	iters: 200, epoch: 3 | loss: 3.5385013
	speed: 0.0765s/iter; left time: 1905.0584s
Epoch: 3 cost time: 20.400879621505737
Epoch: 3, Steps: 256 Train Loss: 3.5310 (Forecasting Loss:0.3348 + XiCon Loss:3.1962 x Lambda(1.0)), Vali MSE Loss: 0.3317 Test MSE Loss: 0.3021
Validation loss decreased (0.338808 --> 0.331705).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5086048
	speed: 0.0810s/iter; left time: 2002.2171s
	iters: 200, epoch: 4 | loss: 3.4988558
	speed: 0.0782s/iter; left time: 1925.3612s
Epoch: 4 cost time: 20.46563744544983
Epoch: 4, Steps: 256 Train Loss: 3.4965 (Forecasting Loss:0.3294 + XiCon Loss:3.1672 x Lambda(1.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2972
Validation loss decreased (0.331705 --> 0.323148).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.4879346
	speed: 0.0788s/iter; left time: 1929.2410s
	iters: 200, epoch: 5 | loss: 3.5043426
	speed: 0.0554s/iter; left time: 1351.6315s
Epoch: 5 cost time: 15.640951156616211
Epoch: 5, Steps: 256 Train Loss: 3.4861 (Forecasting Loss:0.3262 + XiCon Loss:3.1600 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2971
Validation loss decreased (0.323148 --> 0.322152).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.4659696
	speed: 0.0610s/iter; left time: 1477.0685s
	iters: 200, epoch: 6 | loss: 3.5014663
	speed: 0.0786s/iter; left time: 1896.9788s
Epoch: 6 cost time: 18.54696249961853
Epoch: 6, Steps: 256 Train Loss: 3.4818 (Forecasting Loss:0.3249 + XiCon Loss:3.1569 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2962
Validation loss decreased (0.322152 --> 0.320052).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.4552748
	speed: 0.0813s/iter; left time: 1949.1793s
	iters: 200, epoch: 7 | loss: 3.4595623
	speed: 0.0802s/iter; left time: 1914.5018s
Epoch: 7 cost time: 20.250593900680542
Epoch: 7, Steps: 256 Train Loss: 3.4799 (Forecasting Loss:0.3244 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2960
Validation loss decreased (0.320052 --> 0.319332).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.4759455
	speed: 0.0415s/iter; left time: 983.7042s
	iters: 200, epoch: 8 | loss: 3.4848356
	speed: 0.0403s/iter; left time: 951.3014s
Epoch: 8 cost time: 12.314263343811035
Epoch: 8, Steps: 256 Train Loss: 3.4777 (Forecasting Loss:0.3242 + XiCon Loss:3.1535 x Lambda(1.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2963
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.4605803
	speed: 0.0799s/iter; left time: 1874.6855s
	iters: 200, epoch: 9 | loss: 3.4600167
	speed: 0.0777s/iter; left time: 1814.7617s
Epoch: 9 cost time: 20.251195669174194
Epoch: 9, Steps: 256 Train Loss: 3.4786 (Forecasting Loss:0.3240 + XiCon Loss:3.1545 x Lambda(1.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2961
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4671907
	speed: 0.0807s/iter; left time: 1871.5078s
	iters: 200, epoch: 10 | loss: 3.4612279
	speed: 0.0619s/iter; left time: 1429.9154s
Epoch: 10 cost time: 16.520429372787476
Epoch: 10, Steps: 256 Train Loss: 3.4778 (Forecasting Loss:0.3239 + XiCon Loss:3.1540 x Lambda(1.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2961
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.4837952
	speed: 0.0567s/iter; left time: 1301.5061s
	iters: 200, epoch: 11 | loss: 3.5166144
	speed: 0.0768s/iter; left time: 1754.4161s
Epoch: 11 cost time: 17.96455216407776
Epoch: 11, Steps: 256 Train Loss: 3.4797 (Forecasting Loss:0.3239 + XiCon Loss:3.1558 x Lambda(1.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2960
Validation loss decreased (0.319332 --> 0.319319).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5099607
	speed: 0.0798s/iter; left time: 1810.0045s
	iters: 200, epoch: 12 | loss: 3.4511278
	speed: 0.0783s/iter; left time: 1769.5189s
Epoch: 12 cost time: 19.97717046737671
Epoch: 12, Steps: 256 Train Loss: 3.4789 (Forecasting Loss:0.3239 + XiCon Loss:3.1550 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
Validation loss decreased (0.319319 --> 0.319212).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.4405382
	speed: 0.0477s/iter; left time: 1069.0502s
	iters: 200, epoch: 13 | loss: 3.4761391
	speed: 0.0398s/iter; left time: 888.3924s
Epoch: 13 cost time: 11.924989938735962
Epoch: 13, Steps: 256 Train Loss: 3.4778 (Forecasting Loss:0.3240 + XiCon Loss:3.1538 x Lambda(1.0)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.2960
Validation loss decreased (0.319212 --> 0.319123).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.4473631
	speed: 0.0813s/iter; left time: 1802.3081s
	iters: 200, epoch: 14 | loss: 3.4350333
	speed: 0.0821s/iter; left time: 1811.4044s
Epoch: 14 cost time: 20.982261180877686
Epoch: 14, Steps: 256 Train Loss: 3.4773 (Forecasting Loss:0.3239 + XiCon Loss:3.1534 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4621165
	speed: 0.0816s/iter; left time: 1787.9997s
	iters: 200, epoch: 15 | loss: 3.4329393
	speed: 0.0738s/iter; left time: 1610.1051s
Epoch: 15 cost time: 19.870476722717285
Epoch: 15, Steps: 256 Train Loss: 3.4788 (Forecasting Loss:0.3239 + XiCon Loss:3.1549 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.4662240
	speed: 0.0819s/iter; left time: 1773.6267s
	iters: 200, epoch: 16 | loss: 3.5029607
	speed: 0.0800s/iter; left time: 1724.2425s
Epoch: 16 cost time: 20.594531059265137
Epoch: 16, Steps: 256 Train Loss: 3.4773 (Forecasting Loss:0.3240 + XiCon Loss:3.1533 x Lambda(1.0)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.2960
Validation loss decreased (0.319123 --> 0.319119).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.4938054
	speed: 0.0791s/iter; left time: 1692.9074s
	iters: 200, epoch: 17 | loss: 3.4677789
	speed: 0.0770s/iter; left time: 1639.9690s
Epoch: 17 cost time: 20.085247039794922
Epoch: 17, Steps: 256 Train Loss: 3.4785 (Forecasting Loss:0.3239 + XiCon Loss:3.1545 x Lambda(1.0)), Vali MSE Loss: 0.3191 Test MSE Loss: 0.2960
Validation loss decreased (0.319119 --> 0.319090).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.4929378
	speed: 0.0832s/iter; left time: 1760.5016s
	iters: 200, epoch: 18 | loss: 3.5142293
	speed: 0.0793s/iter; left time: 1668.6645s
Epoch: 18 cost time: 20.652225732803345
Epoch: 18, Steps: 256 Train Loss: 3.4775 (Forecasting Loss:0.3239 + XiCon Loss:3.1536 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.4843276
	speed: 0.0788s/iter; left time: 1647.0071s
	iters: 200, epoch: 19 | loss: 3.4590473
	speed: 0.0782s/iter; left time: 1625.6537s
Epoch: 19 cost time: 20.269176721572876
Epoch: 19, Steps: 256 Train Loss: 3.4781 (Forecasting Loss:0.3238 + XiCon Loss:3.1543 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.4724195
	speed: 0.0816s/iter; left time: 1684.9679s
	iters: 200, epoch: 20 | loss: 3.4498401
	speed: 0.0790s/iter; left time: 1622.4665s
Epoch: 20 cost time: 20.1802179813385
Epoch: 20, Steps: 256 Train Loss: 3.4772 (Forecasting Loss:0.3240 + XiCon Loss:3.1533 x Lambda(1.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2960
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.4825308
	speed: 0.0768s/iter; left time: 1564.3954s
	iters: 200, epoch: 21 | loss: 3.4542663
	speed: 0.0793s/iter; left time: 1608.6136s
Epoch: 21 cost time: 20.24487066268921
Epoch: 21, Steps: 256 Train Loss: 3.4775 (Forecasting Loss:0.3238 + XiCon Loss:3.1537 x Lambda(1.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2960
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.5005136
	speed: 0.0795s/iter; left time: 1600.8780s
	iters: 200, epoch: 22 | loss: 3.4485934
	speed: 0.0780s/iter; left time: 1562.7254s
Epoch: 22 cost time: 20.334481954574585
Epoch: 22, Steps: 256 Train Loss: 3.4775 (Forecasting Loss:0.3239 + XiCon Loss:3.1537 x Lambda(1.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2960
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.4602787
	speed: 0.0806s/iter; left time: 1601.1699s
	iters: 200, epoch: 23 | loss: 3.4776173
	speed: 0.0777s/iter; left time: 1536.4351s
Epoch: 23 cost time: 20.19336748123169
Epoch: 23, Steps: 256 Train Loss: 3.4788 (Forecasting Loss:0.3239 + XiCon Loss:3.1549 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.4450445
	speed: 0.0799s/iter; left time: 1567.6787s
	iters: 200, epoch: 24 | loss: 3.5165524
	speed: 0.0807s/iter; left time: 1575.6375s
Epoch: 24 cost time: 20.374157190322876
Epoch: 24, Steps: 256 Train Loss: 3.4780 (Forecasting Loss:0.3240 + XiCon Loss:3.1539 x Lambda(1.0)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2960
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.4415560
	speed: 0.0796s/iter; left time: 1540.7735s
	iters: 200, epoch: 25 | loss: 3.4707806
	speed: 0.0813s/iter; left time: 1564.7715s
Epoch: 25 cost time: 20.5325026512146
Epoch: 25, Steps: 256 Train Loss: 3.4781 (Forecasting Loss:0.3239 + XiCon Loss:3.1542 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.5189142
	speed: 0.0787s/iter; left time: 1503.9787s
	iters: 200, epoch: 26 | loss: 3.4824548
	speed: 0.0765s/iter; left time: 1452.8000s
Epoch: 26 cost time: 19.991015434265137
Epoch: 26, Steps: 256 Train Loss: 3.4783 (Forecasting Loss:0.3239 + XiCon Loss:3.1545 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.5044823
	speed: 0.0792s/iter; left time: 1492.2291s
	iters: 200, epoch: 27 | loss: 3.4916201
	speed: 0.0805s/iter; left time: 1509.4906s
Epoch: 27 cost time: 20.570765018463135
Epoch: 27, Steps: 256 Train Loss: 3.4789 (Forecasting Loss:0.3239 + XiCon Loss:3.1550 x Lambda(1.0)), Vali MSE Loss: 0.3192 Test MSE Loss: 0.2960
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.21991071105003357, mae:0.37214216589927673, mape:0.7267788648605347, mspe:18.283912658691406 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.3239
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.8370142
	speed: 0.0798s/iter; left time: 2034.9014s
	iters: 200, epoch: 1 | loss: 3.8458531
	speed: 0.0772s/iter; left time: 1960.2634s
Epoch: 1 cost time: 20.203829288482666
Epoch: 1, Steps: 256 Train Loss: 3.8265 (Forecasting Loss:0.4340 + XiCon Loss:3.3925 x Lambda(1.0)), Vali MSE Loss: 0.4200 Test MSE Loss: 0.3888
Validation loss decreased (inf --> 0.420028).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.6836720
	speed: 0.0771s/iter; left time: 1946.7267s
	iters: 200, epoch: 2 | loss: 3.5580285
	speed: 0.0754s/iter; left time: 1895.6629s
Epoch: 2 cost time: 19.745829343795776
Epoch: 2, Steps: 256 Train Loss: 3.6514 (Forecasting Loss:0.3529 + XiCon Loss:3.2985 x Lambda(1.0)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.3083
Validation loss decreased (0.420028 --> 0.338669).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5644803
	speed: 0.0833s/iter; left time: 2081.5110s
	iters: 200, epoch: 3 | loss: 3.5260291
	speed: 0.0780s/iter; left time: 1940.8034s
Epoch: 3 cost time: 20.51640486717224
Epoch: 3, Steps: 256 Train Loss: 3.5302 (Forecasting Loss:0.3353 + XiCon Loss:3.1949 x Lambda(1.0)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.3051
Validation loss decreased (0.338669 --> 0.335167).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.5151753
	speed: 0.0781s/iter; left time: 1932.5795s
	iters: 200, epoch: 4 | loss: 3.4749916
	speed: 0.0789s/iter; left time: 1943.9086s
Epoch: 4 cost time: 20.205778121948242
Epoch: 4, Steps: 256 Train Loss: 3.5056 (Forecasting Loss:0.3327 + XiCon Loss:3.1729 x Lambda(1.0)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.3031
Validation loss decreased (0.335167 --> 0.332859).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.5084851
	speed: 0.0837s/iter; left time: 2048.3908s
	iters: 200, epoch: 5 | loss: 3.5255077
	speed: 0.0788s/iter; left time: 1920.8649s
Epoch: 5 cost time: 20.417644500732422
Epoch: 5, Steps: 256 Train Loss: 3.4958 (Forecasting Loss:0.3312 + XiCon Loss:3.1647 x Lambda(1.0)), Vali MSE Loss: 0.3328 Test MSE Loss: 0.3030
Validation loss decreased (0.332859 --> 0.332793).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.5212564
	speed: 0.0796s/iter; left time: 1927.9272s
	iters: 200, epoch: 6 | loss: 3.5031004
	speed: 0.0797s/iter; left time: 1923.3349s
Epoch: 6 cost time: 20.306370496749878
Epoch: 6, Steps: 256 Train Loss: 3.4937 (Forecasting Loss:0.3303 + XiCon Loss:3.1634 x Lambda(1.0)), Vali MSE Loss: 0.3312 Test MSE Loss: 0.3017
Validation loss decreased (0.332793 --> 0.331238).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.4794056
	speed: 0.0829s/iter; left time: 1987.4357s
	iters: 200, epoch: 7 | loss: 3.4942515
	speed: 0.0779s/iter; left time: 1858.5709s
Epoch: 7 cost time: 20.56684637069702
Epoch: 7, Steps: 256 Train Loss: 3.4919 (Forecasting Loss:0.3299 + XiCon Loss:3.1620 x Lambda(1.0)), Vali MSE Loss: 0.3312 Test MSE Loss: 0.3017
Validation loss decreased (0.331238 --> 0.331214).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5040939
	speed: 0.0780s/iter; left time: 1848.7072s
	iters: 200, epoch: 8 | loss: 3.4998653
	speed: 0.0777s/iter; left time: 1833.4387s
Epoch: 8 cost time: 20.0576012134552
Epoch: 8, Steps: 256 Train Loss: 3.4919 (Forecasting Loss:0.3297 + XiCon Loss:3.1622 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3015
Validation loss decreased (0.331214 --> 0.330662).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.4686465
	speed: 0.0820s/iter; left time: 1922.6338s
	iters: 200, epoch: 9 | loss: 3.4880962
	speed: 0.0782s/iter; left time: 1826.5228s
Epoch: 9 cost time: 20.325961351394653
Epoch: 9, Steps: 256 Train Loss: 3.4902 (Forecasting Loss:0.3296 + XiCon Loss:3.1606 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3014
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4511757
	speed: 0.0804s/iter; left time: 1864.8447s
	iters: 200, epoch: 10 | loss: 3.4553857
	speed: 0.0778s/iter; left time: 1797.0810s
Epoch: 10 cost time: 20.31558895111084
Epoch: 10, Steps: 256 Train Loss: 3.4903 (Forecasting Loss:0.3295 + XiCon Loss:3.1608 x Lambda(1.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.3014
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.5023918
	speed: 0.0814s/iter; left time: 1866.7271s
	iters: 200, epoch: 11 | loss: 3.4594669
	speed: 0.0756s/iter; left time: 1726.7497s
Epoch: 11 cost time: 20.20449709892273
Epoch: 11, Steps: 256 Train Loss: 3.4922 (Forecasting Loss:0.3294 + XiCon Loss:3.1628 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3014
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.4679272
	speed: 0.0834s/iter; left time: 1891.1102s
	iters: 200, epoch: 12 | loss: 3.4766953
	speed: 0.0819s/iter; left time: 1850.5675s
Epoch: 12 cost time: 20.945659637451172
Epoch: 12, Steps: 256 Train Loss: 3.4899 (Forecasting Loss:0.3295 + XiCon Loss:3.1605 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.3014
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.4758441
	speed: 0.0815s/iter; left time: 1827.5852s
	iters: 200, epoch: 13 | loss: 3.4700952
	speed: 0.0803s/iter; left time: 1792.1921s
Epoch: 13 cost time: 20.467963218688965
Epoch: 13, Steps: 256 Train Loss: 3.4910 (Forecasting Loss:0.3294 + XiCon Loss:3.1615 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3014
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.4916415
	speed: 0.0798s/iter; left time: 1769.0819s
	iters: 200, epoch: 14 | loss: 3.4885693
	speed: 0.0781s/iter; left time: 1724.1344s
Epoch: 14 cost time: 20.370799779891968
Epoch: 14, Steps: 256 Train Loss: 3.4903 (Forecasting Loss:0.3295 + XiCon Loss:3.1608 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.3014
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4805830
	speed: 0.0766s/iter; left time: 1678.1644s
	iters: 200, epoch: 15 | loss: 3.4724460
	speed: 0.0768s/iter; left time: 1674.6087s
Epoch: 15 cost time: 19.742884635925293
Epoch: 15, Steps: 256 Train Loss: 3.4899 (Forecasting Loss:0.3294 + XiCon Loss:3.1604 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3014
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.5057757
	speed: 0.0807s/iter; left time: 1748.6948s
	iters: 200, epoch: 16 | loss: 3.5208929
	speed: 0.0785s/iter; left time: 1692.1014s
Epoch: 16 cost time: 20.471983909606934
Epoch: 16, Steps: 256 Train Loss: 3.4909 (Forecasting Loss:0.3294 + XiCon Loss:3.1615 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.3014
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.5106597
	speed: 0.0792s/iter; left time: 1694.5983s
	iters: 200, epoch: 17 | loss: 3.4956343
	speed: 0.0790s/iter; left time: 1683.7724s
Epoch: 17 cost time: 20.292881727218628
Epoch: 17, Steps: 256 Train Loss: 3.4920 (Forecasting Loss:0.3294 + XiCon Loss:3.1626 x Lambda(1.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3014
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.5176034
	speed: 0.0834s/iter; left time: 1764.6294s
	iters: 200, epoch: 18 | loss: 3.4545355
	speed: 0.0770s/iter; left time: 1620.9607s
Epoch: 18 cost time: 20.327574968338013
Epoch: 18, Steps: 256 Train Loss: 3.4902 (Forecasting Loss:0.3295 + XiCon Loss:3.1607 x Lambda(1.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.3014
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22484716773033142, mae:0.37823888659477234, mape:0.7140159010887146, mspe:18.102832794189453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5989
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 3.7892969
	speed: 0.0811s/iter; left time: 2067.7910s
	iters: 200, epoch: 1 | loss: 3.8340943
	speed: 0.0750s/iter; left time: 1906.2009s
Epoch: 1 cost time: 20.123170375823975
Epoch: 1, Steps: 256 Train Loss: 3.8271 (Forecasting Loss:0.4381 + XiCon Loss:3.3890 x Lambda(1.0)), Vali MSE Loss: 0.3982 Test MSE Loss: 0.3709
Validation loss decreased (inf --> 0.398236).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.7045014
	speed: 0.0828s/iter; left time: 2091.1955s
	iters: 200, epoch: 2 | loss: 3.6361282
	speed: 0.0801s/iter; left time: 2014.7099s
Epoch: 2 cost time: 20.687171459197998
Epoch: 2, Steps: 256 Train Loss: 3.6608 (Forecasting Loss:0.3555 + XiCon Loss:3.3052 x Lambda(1.0)), Vali MSE Loss: 0.3373 Test MSE Loss: 0.3062
Validation loss decreased (0.398236 --> 0.337263).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.5484841
	speed: 0.0820s/iter; left time: 2048.0358s
	iters: 200, epoch: 3 | loss: 3.5538330
	speed: 0.0787s/iter; left time: 1958.0719s
Epoch: 3 cost time: 19.919991970062256
Epoch: 3, Steps: 256 Train Loss: 3.5486 (Forecasting Loss:0.3368 + XiCon Loss:3.2118 x Lambda(1.0)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.3045
Validation loss decreased (0.337263 --> 0.336043).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.4975343
	speed: 0.0931s/iter; left time: 2302.6188s
	iters: 200, epoch: 4 | loss: 3.5053663
	speed: 0.0578s/iter; left time: 1424.4794s
Epoch: 4 cost time: 17.381510019302368
Epoch: 4, Steps: 256 Train Loss: 3.5202 (Forecasting Loss:0.3341 + XiCon Loss:3.1861 x Lambda(1.0)), Vali MSE Loss: 0.3344 Test MSE Loss: 0.3033
Validation loss decreased (0.336043 --> 0.334422).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.4933972
	speed: 0.0665s/iter; left time: 1628.3805s
	iters: 200, epoch: 5 | loss: 3.5043826
	speed: 0.0771s/iter; left time: 1878.8637s
Epoch: 5 cost time: 18.66142177581787
Epoch: 5, Steps: 256 Train Loss: 3.5109 (Forecasting Loss:0.3328 + XiCon Loss:3.1781 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3027
Validation loss decreased (0.334422 --> 0.333831).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.4820161
	speed: 0.0791s/iter; left time: 1916.7741s
	iters: 200, epoch: 6 | loss: 3.5104294
	speed: 0.0742s/iter; left time: 1789.0505s
Epoch: 6 cost time: 19.696987628936768
Epoch: 6, Steps: 256 Train Loss: 3.5078 (Forecasting Loss:0.3322 + XiCon Loss:3.1755 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3025
Validation loss decreased (0.333831 --> 0.333684).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.4935641
	speed: 0.0730s/iter; left time: 1750.5935s
	iters: 200, epoch: 7 | loss: 3.5379970
	speed: 0.0763s/iter; left time: 1821.4490s
Epoch: 7 cost time: 19.438899993896484
Epoch: 7, Steps: 256 Train Loss: 3.5043 (Forecasting Loss:0.3319 + XiCon Loss:3.1724 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.5058079
	speed: 0.0804s/iter; left time: 1905.5565s
	iters: 200, epoch: 8 | loss: 3.5095351
	speed: 0.0748s/iter; left time: 1765.2947s
Epoch: 8 cost time: 19.99934720993042
Epoch: 8, Steps: 256 Train Loss: 3.5052 (Forecasting Loss:0.3319 + XiCon Loss:3.1733 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.4622631
	speed: 0.0415s/iter; left time: 974.1723s
	iters: 200, epoch: 9 | loss: 3.5200679
	speed: 0.0461s/iter; left time: 1075.6443s
Epoch: 9 cost time: 12.97433853149414
Epoch: 9, Steps: 256 Train Loss: 3.5027 (Forecasting Loss:0.3318 + XiCon Loss:3.1709 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.4539616
	speed: 0.0810s/iter; left time: 1880.0267s
	iters: 200, epoch: 10 | loss: 3.4880047
	speed: 0.0794s/iter; left time: 1833.3450s
Epoch: 10 cost time: 20.43186926841736
Epoch: 10, Steps: 256 Train Loss: 3.5027 (Forecasting Loss:0.3317 + XiCon Loss:3.1709 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3024
Validation loss decreased (0.333684 --> 0.333501).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.4852159
	speed: 0.0800s/iter; left time: 1835.5219s
	iters: 200, epoch: 11 | loss: 3.4815719
	speed: 0.0568s/iter; left time: 1297.5129s
Epoch: 11 cost time: 15.92929744720459
Epoch: 11, Steps: 256 Train Loss: 3.5035 (Forecasting Loss:0.3318 + XiCon Loss:3.1717 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.5453062
	speed: 0.0555s/iter; left time: 1259.2991s
	iters: 200, epoch: 12 | loss: 3.5153718
	speed: 0.0777s/iter; left time: 1755.5713s
Epoch: 12 cost time: 17.78643012046814
Epoch: 12, Steps: 256 Train Loss: 3.5029 (Forecasting Loss:0.3318 + XiCon Loss:3.1711 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.4402323
	speed: 0.0820s/iter; left time: 1839.9265s
	iters: 200, epoch: 13 | loss: 3.5134342
	speed: 0.0788s/iter; left time: 1760.4546s
Epoch: 13 cost time: 20.482240438461304
Epoch: 13, Steps: 256 Train Loss: 3.5026 (Forecasting Loss:0.3317 + XiCon Loss:3.1709 x Lambda(1.0)), Vali MSE Loss: 0.3334 Test MSE Loss: 0.3024
Validation loss decreased (0.333501 --> 0.333437).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.5314229
	speed: 0.0467s/iter; left time: 1035.7927s
	iters: 200, epoch: 14 | loss: 3.5177541
	speed: 0.0397s/iter; left time: 876.6231s
Epoch: 14 cost time: 11.43916130065918
Epoch: 14, Steps: 256 Train Loss: 3.5041 (Forecasting Loss:0.3318 + XiCon Loss:3.1724 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.4721014
	speed: 0.0772s/iter; left time: 1692.6982s
	iters: 200, epoch: 15 | loss: 3.5120826
	speed: 0.0757s/iter; left time: 1652.2847s
Epoch: 15 cost time: 19.69151282310486
Epoch: 15, Steps: 256 Train Loss: 3.5028 (Forecasting Loss:0.3317 + XiCon Loss:3.1710 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.5347598
	speed: 0.0792s/iter; left time: 1715.1534s
	iters: 200, epoch: 16 | loss: 3.5071905
	speed: 0.0786s/iter; left time: 1695.4605s
Epoch: 16 cost time: 18.143853425979614
Epoch: 16, Steps: 256 Train Loss: 3.5035 (Forecasting Loss:0.3317 + XiCon Loss:3.1718 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3024
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.5225635
	speed: 0.0413s/iter; left time: 884.3846s
	iters: 200, epoch: 17 | loss: 3.4551511
	speed: 0.0713s/iter; left time: 1518.4448s
Epoch: 17 cost time: 15.628695487976074
Epoch: 17, Steps: 256 Train Loss: 3.5035 (Forecasting Loss:0.3317 + XiCon Loss:3.1718 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.4607427
	speed: 0.0812s/iter; left time: 1717.0102s
	iters: 200, epoch: 18 | loss: 3.4946084
	speed: 0.0797s/iter; left time: 1676.8290s
Epoch: 18 cost time: 20.58260750770569
Epoch: 18, Steps: 256 Train Loss: 3.5025 (Forecasting Loss:0.3318 + XiCon Loss:3.1708 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.5036209
	speed: 0.0679s/iter; left time: 1419.3503s
	iters: 200, epoch: 19 | loss: 3.5208158
	speed: 0.0397s/iter; left time: 825.8637s
Epoch: 19 cost time: 13.002312183380127
Epoch: 19, Steps: 256 Train Loss: 3.5034 (Forecasting Loss:0.3317 + XiCon Loss:3.1717 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3024
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.5024829
	speed: 0.0789s/iter; left time: 1628.9079s
	iters: 200, epoch: 20 | loss: 3.4915898
	speed: 0.0785s/iter; left time: 1611.3375s
Epoch: 20 cost time: 20.21000623703003
Epoch: 20, Steps: 256 Train Loss: 3.5042 (Forecasting Loss:0.3318 + XiCon Loss:3.1724 x Lambda(1.0)), Vali MSE Loss: 0.3334 Test MSE Loss: 0.3024
Validation loss decreased (0.333437 --> 0.333360).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.4698391
	speed: 0.0794s/iter; left time: 1617.6925s
	iters: 200, epoch: 21 | loss: 3.5120234
	speed: 0.0783s/iter; left time: 1587.3392s
Epoch: 21 cost time: 18.57102084159851
Epoch: 21, Steps: 256 Train Loss: 3.5023 (Forecasting Loss:0.3317 + XiCon Loss:3.1706 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.5047183
	speed: 0.0462s/iter; left time: 929.7293s
	iters: 200, epoch: 22 | loss: 3.4906385
	speed: 0.0769s/iter; left time: 1539.0510s
Epoch: 22 cost time: 16.66250729560852
Epoch: 22, Steps: 256 Train Loss: 3.5040 (Forecasting Loss:0.3317 + XiCon Loss:3.1722 x Lambda(1.0)), Vali MSE Loss: 0.3335 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.5255105
	speed: 0.0789s/iter; left time: 1567.7490s
	iters: 200, epoch: 23 | loss: 3.5516810
	speed: 0.0798s/iter; left time: 1576.8808s
Epoch: 23 cost time: 20.30074667930603
Epoch: 23, Steps: 256 Train Loss: 3.5025 (Forecasting Loss:0.3318 + XiCon Loss:3.1708 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.5161750
	speed: 0.0598s/iter; left time: 1173.0699s
	iters: 200, epoch: 24 | loss: 3.4964781
	speed: 0.0399s/iter; left time: 778.1433s
Epoch: 24 cost time: 12.77155327796936
Epoch: 24, Steps: 256 Train Loss: 3.5025 (Forecasting Loss:0.3317 + XiCon Loss:3.1708 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.4970338
	speed: 0.0780s/iter; left time: 1509.4405s
	iters: 200, epoch: 25 | loss: 3.4805140
	speed: 0.0780s/iter; left time: 1501.4212s
Epoch: 25 cost time: 19.895375967025757
Epoch: 25, Steps: 256 Train Loss: 3.5041 (Forecasting Loss:0.3318 + XiCon Loss:3.1723 x Lambda(1.0)), Vali MSE Loss: 0.3339 Test MSE Loss: 0.3024
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.5005229
	speed: 0.0807s/iter; left time: 1542.3846s
	iters: 200, epoch: 26 | loss: 3.5294020
	speed: 0.0765s/iter; left time: 1452.7078s
Epoch: 26 cost time: 17.949542760849
Epoch: 26, Steps: 256 Train Loss: 3.5021 (Forecasting Loss:0.3317 + XiCon Loss:3.1704 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.4987106
	speed: 0.0498s/iter; left time: 939.0095s
	iters: 200, epoch: 27 | loss: 3.5278714
	speed: 0.0790s/iter; left time: 1480.2438s
Epoch: 27 cost time: 17.234668254852295
Epoch: 27, Steps: 256 Train Loss: 3.5027 (Forecasting Loss:0.3317 + XiCon Loss:3.1710 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3024
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.5368774
	speed: 0.0814s/iter; left time: 1512.7643s
	iters: 200, epoch: 28 | loss: 3.4955022
	speed: 0.0783s/iter; left time: 1448.2002s
Epoch: 28 cost time: 20.23880958557129
Epoch: 28, Steps: 256 Train Loss: 3.5031 (Forecasting Loss:0.3317 + XiCon Loss:3.1714 x Lambda(1.0)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.3024
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.5006762
	speed: 0.0782s/iter; left time: 1433.9932s
	iters: 200, epoch: 29 | loss: 3.5171547
	speed: 0.0768s/iter; left time: 1399.6592s
Epoch: 29 cost time: 19.98456883430481
Epoch: 29, Steps: 256 Train Loss: 3.5037 (Forecasting Loss:0.3317 + XiCon Loss:3.1720 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.3024
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.5365157
	speed: 0.0796s/iter; left time: 1439.6696s
	iters: 200, epoch: 30 | loss: 3.5493236
	speed: 0.0757s/iter; left time: 1360.3710s
Epoch: 30 cost time: 19.722535133361816
Epoch: 30, Steps: 256 Train Loss: 3.5025 (Forecasting Loss:0.3317 + XiCon Loss:3.1709 x Lambda(1.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3024
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22527457773685455, mae:0.37950414419174194, mape:0.7208189964294434, mspe:18.696033477783203 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2242+-0.00317, MAE:0.3767+-0.00405, MAPE:0.7330+-0.03701, MSPE:18.8616+-1.49581, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5193
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.7956102
	speed: 0.1197s/iter; left time: 2908.2133s
	iters: 200, epoch: 1 | loss: 3.7775326
	speed: 0.1130s/iter; left time: 2734.6881s
Epoch: 1 cost time: 28.44015645980835
Epoch: 1, Steps: 244 Train Loss: 3.8291 (Forecasting Loss:0.4576 + XiCon Loss:3.3715 x Lambda(1.0)), Vali MSE Loss: 0.4553 Test MSE Loss: 0.3567
Validation loss decreased (inf --> 0.455320).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5758038
	speed: 0.1216s/iter; left time: 2925.3710s
	iters: 200, epoch: 2 | loss: 3.5707381
	speed: 0.1172s/iter; left time: 2807.5995s
Epoch: 2 cost time: 29.113319396972656
Epoch: 2, Steps: 244 Train Loss: 3.5976 (Forecasting Loss:0.3666 + XiCon Loss:3.2310 x Lambda(1.0)), Vali MSE Loss: 0.3678 Test MSE Loss: 0.3001
Validation loss decreased (0.455320 --> 0.367834).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5686047
	speed: 0.1193s/iter; left time: 2841.2992s
	iters: 200, epoch: 3 | loss: 3.6046939
	speed: 0.0675s/iter; left time: 1600.7288s
Epoch: 3 cost time: 22.375515699386597
Epoch: 3, Steps: 244 Train Loss: 3.5970 (Forecasting Loss:0.3467 + XiCon Loss:3.2503 x Lambda(1.0)), Vali MSE Loss: 0.3793 Test MSE Loss: 0.2929
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5769939
	speed: 0.1202s/iter; left time: 2833.4186s
	iters: 200, epoch: 4 | loss: 3.5560207
	speed: 0.1172s/iter; left time: 2750.5609s
Epoch: 4 cost time: 28.84698486328125
Epoch: 4, Steps: 244 Train Loss: 3.5755 (Forecasting Loss:0.3429 + XiCon Loss:3.2326 x Lambda(1.0)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.2907
Validation loss decreased (0.367834 --> 0.352012).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5916116
	speed: 0.1065s/iter; left time: 2484.8595s
	iters: 200, epoch: 5 | loss: 3.6233504
	speed: 0.0660s/iter; left time: 1532.5179s
Epoch: 5 cost time: 22.67132830619812
Epoch: 5, Steps: 244 Train Loss: 3.5644 (Forecasting Loss:0.3412 + XiCon Loss:3.2232 x Lambda(1.0)), Vali MSE Loss: 0.3489 Test MSE Loss: 0.2926
Validation loss decreased (0.352012 --> 0.348866).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5606179
	speed: 0.1204s/iter; left time: 2779.8123s
	iters: 200, epoch: 6 | loss: 3.5560431
	speed: 0.1205s/iter; left time: 2768.8011s
Epoch: 6 cost time: 29.246976375579834
Epoch: 6, Steps: 244 Train Loss: 3.5568 (Forecasting Loss:0.3396 + XiCon Loss:3.2172 x Lambda(1.0)), Vali MSE Loss: 0.3624 Test MSE Loss: 0.2929
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5358660
	speed: 0.1157s/iter; left time: 2641.6948s
	iters: 200, epoch: 7 | loss: 3.5450401
	speed: 0.1183s/iter; left time: 2690.2568s
Epoch: 7 cost time: 28.65008783340454
Epoch: 7, Steps: 244 Train Loss: 3.5537 (Forecasting Loss:0.3393 + XiCon Loss:3.2143 x Lambda(1.0)), Vali MSE Loss: 0.3530 Test MSE Loss: 0.2915
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5188830
	speed: 0.1223s/iter; left time: 2763.9981s
	iters: 200, epoch: 8 | loss: 3.5916600
	speed: 0.1131s/iter; left time: 2543.6464s
Epoch: 8 cost time: 28.905370712280273
Epoch: 8, Steps: 244 Train Loss: 3.5534 (Forecasting Loss:0.3395 + XiCon Loss:3.2139 x Lambda(1.0)), Vali MSE Loss: 0.3564 Test MSE Loss: 0.2919
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5038867
	speed: 0.1234s/iter; left time: 2758.1735s
	iters: 200, epoch: 9 | loss: 3.5308285
	speed: 0.1195s/iter; left time: 2658.4307s
Epoch: 9 cost time: 29.675750255584717
Epoch: 9, Steps: 244 Train Loss: 3.5514 (Forecasting Loss:0.3392 + XiCon Loss:3.2122 x Lambda(1.0)), Vali MSE Loss: 0.3531 Test MSE Loss: 0.2917
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5216405
	speed: 0.1153s/iter; left time: 2548.6901s
	iters: 200, epoch: 10 | loss: 3.5182409
	speed: 0.1174s/iter; left time: 2582.9111s
Epoch: 10 cost time: 28.522144079208374
Epoch: 10, Steps: 244 Train Loss: 3.5507 (Forecasting Loss:0.3390 + XiCon Loss:3.2117 x Lambda(1.0)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.2917
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6104290
	speed: 0.1183s/iter; left time: 2586.4721s
	iters: 200, epoch: 11 | loss: 3.5288022
	speed: 0.1143s/iter; left time: 2486.4046s
Epoch: 11 cost time: 28.45089030265808
Epoch: 11, Steps: 244 Train Loss: 3.5507 (Forecasting Loss:0.3394 + XiCon Loss:3.2114 x Lambda(1.0)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.2917
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5681047
	speed: 0.1197s/iter; left time: 2588.5814s
	iters: 200, epoch: 12 | loss: 3.5179851
	speed: 0.1190s/iter; left time: 2559.8442s
Epoch: 12 cost time: 29.14214324951172
Epoch: 12, Steps: 244 Train Loss: 3.5506 (Forecasting Loss:0.3392 + XiCon Loss:3.2114 x Lambda(1.0)), Vali MSE Loss: 0.3532 Test MSE Loss: 0.2917
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5880044
	speed: 0.1181s/iter; left time: 2523.9840s
	iters: 200, epoch: 13 | loss: 3.5373936
	speed: 0.1208s/iter; left time: 2570.6324s
Epoch: 13 cost time: 29.179904460906982
Epoch: 13, Steps: 244 Train Loss: 3.5513 (Forecasting Loss:0.3386 + XiCon Loss:3.2127 x Lambda(1.0)), Vali MSE Loss: 0.3532 Test MSE Loss: 0.2918
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5095825
	speed: 0.1223s/iter; left time: 2584.5368s
	iters: 200, epoch: 14 | loss: 3.6151016
	speed: 0.1160s/iter; left time: 2439.3382s
Epoch: 14 cost time: 29.0526921749115
Epoch: 14, Steps: 244 Train Loss: 3.5471 (Forecasting Loss:0.3387 + XiCon Loss:3.2083 x Lambda(1.0)), Vali MSE Loss: 0.3532 Test MSE Loss: 0.2918
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5825078
	speed: 0.1206s/iter; left time: 2518.9212s
	iters: 200, epoch: 15 | loss: 3.5563729
	speed: 0.1189s/iter; left time: 2470.9621s
Epoch: 15 cost time: 29.200847625732422
Epoch: 15, Steps: 244 Train Loss: 3.5491 (Forecasting Loss:0.3391 + XiCon Loss:3.2100 x Lambda(1.0)), Vali MSE Loss: 0.3534 Test MSE Loss: 0.2918
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2136681079864502, mae:0.371478408575058, mape:0.7101700305938721, mspe:20.04193687438965 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5570
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.7964442
	speed: 0.1127s/iter; left time: 2737.7603s
	iters: 200, epoch: 1 | loss: 3.8139851
	speed: 0.1059s/iter; left time: 2563.8114s
Epoch: 1 cost time: 26.46480679512024
Epoch: 1, Steps: 244 Train Loss: 3.8294 (Forecasting Loss:0.4646 + XiCon Loss:3.3648 x Lambda(1.0)), Vali MSE Loss: 0.4797 Test MSE Loss: 0.3856
Validation loss decreased (inf --> 0.479739).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5606050
	speed: 0.1170s/iter; left time: 2815.8184s
	iters: 200, epoch: 2 | loss: 3.5516682
	speed: 0.1135s/iter; left time: 2718.0438s
Epoch: 2 cost time: 27.919384002685547
Epoch: 2, Steps: 244 Train Loss: 3.5987 (Forecasting Loss:0.3867 + XiCon Loss:3.2119 x Lambda(1.0)), Vali MSE Loss: 0.3785 Test MSE Loss: 0.2967
Validation loss decreased (0.479739 --> 0.378475).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5872273
	speed: 0.1070s/iter; left time: 2547.2987s
	iters: 200, epoch: 3 | loss: 3.6150584
	speed: 0.1116s/iter; left time: 2645.3372s
Epoch: 3 cost time: 26.830799341201782
Epoch: 3, Steps: 244 Train Loss: 3.6192 (Forecasting Loss:0.3633 + XiCon Loss:3.2559 x Lambda(1.0)), Vali MSE Loss: 0.3714 Test MSE Loss: 0.2983
Validation loss decreased (0.378475 --> 0.371357).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.7227647
	speed: 0.1142s/iter; left time: 2691.5814s
	iters: 200, epoch: 4 | loss: 3.6461411
	speed: 0.1083s/iter; left time: 2540.9529s
Epoch: 4 cost time: 27.128466844558716
Epoch: 4, Steps: 244 Train Loss: 3.6249 (Forecasting Loss:0.3576 + XiCon Loss:3.2673 x Lambda(1.0)), Vali MSE Loss: 0.3738 Test MSE Loss: 0.3011
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6453819
	speed: 0.1154s/iter; left time: 2691.7729s
	iters: 200, epoch: 5 | loss: 3.6083126
	speed: 0.1124s/iter; left time: 2611.4853s
Epoch: 5 cost time: 27.704503297805786
Epoch: 5, Steps: 244 Train Loss: 3.6113 (Forecasting Loss:0.3547 + XiCon Loss:3.2565 x Lambda(1.0)), Vali MSE Loss: 0.3703 Test MSE Loss: 0.3008
Validation loss decreased (0.371357 --> 0.370330).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5339842
	speed: 0.1103s/iter; left time: 2545.1949s
	iters: 200, epoch: 6 | loss: 3.6023581
	speed: 0.1101s/iter; left time: 2529.4660s
Epoch: 6 cost time: 26.901935338974
Epoch: 6, Steps: 244 Train Loss: 3.6082 (Forecasting Loss:0.3540 + XiCon Loss:3.2542 x Lambda(1.0)), Vali MSE Loss: 0.3683 Test MSE Loss: 0.3009
Validation loss decreased (0.370330 --> 0.368285).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6003399
	speed: 0.1163s/iter; left time: 2655.2298s
	iters: 200, epoch: 7 | loss: 3.6050508
	speed: 0.1150s/iter; left time: 2615.4276s
Epoch: 7 cost time: 27.9422767162323
Epoch: 7, Steps: 244 Train Loss: 3.6077 (Forecasting Loss:0.3534 + XiCon Loss:3.2544 x Lambda(1.0)), Vali MSE Loss: 0.3678 Test MSE Loss: 0.3010
Validation loss decreased (0.368285 --> 0.367837).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5784333
	speed: 0.1155s/iter; left time: 2608.6788s
	iters: 200, epoch: 8 | loss: 3.5835328
	speed: 0.1110s/iter; left time: 2495.6613s
Epoch: 8 cost time: 27.66576600074768
Epoch: 8, Steps: 244 Train Loss: 3.6042 (Forecasting Loss:0.3529 + XiCon Loss:3.2513 x Lambda(1.0)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3012
Validation loss decreased (0.367837 --> 0.367565).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6125815
	speed: 0.1152s/iter; left time: 2574.2863s
	iters: 200, epoch: 9 | loss: 3.5955853
	speed: 0.1116s/iter; left time: 2482.9407s
Epoch: 9 cost time: 27.645681619644165
Epoch: 9, Steps: 244 Train Loss: 3.6040 (Forecasting Loss:0.3528 + XiCon Loss:3.2512 x Lambda(1.0)), Vali MSE Loss: 0.3673 Test MSE Loss: 0.3011
Validation loss decreased (0.367565 --> 0.367334).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6025095
	speed: 0.1152s/iter; left time: 2546.7682s
	iters: 200, epoch: 10 | loss: 3.6603885
	speed: 0.1141s/iter; left time: 2510.9720s
Epoch: 10 cost time: 27.836370706558228
Epoch: 10, Steps: 244 Train Loss: 3.6015 (Forecasting Loss:0.3527 + XiCon Loss:3.2487 x Lambda(1.0)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3012
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6274197
	speed: 0.1116s/iter; left time: 2438.6500s
	iters: 200, epoch: 11 | loss: 3.5978835
	speed: 0.1108s/iter; left time: 2411.2848s
Epoch: 11 cost time: 27.220065116882324
Epoch: 11, Steps: 244 Train Loss: 3.6035 (Forecasting Loss:0.3526 + XiCon Loss:3.2508 x Lambda(1.0)), Vali MSE Loss: 0.3677 Test MSE Loss: 0.3013
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6277304
	speed: 0.1164s/iter; left time: 2517.2464s
	iters: 200, epoch: 12 | loss: 3.5273209
	speed: 0.1041s/iter; left time: 2239.4376s
Epoch: 12 cost time: 27.30993676185608
Epoch: 12, Steps: 244 Train Loss: 3.6011 (Forecasting Loss:0.3528 + XiCon Loss:3.2483 x Lambda(1.0)), Vali MSE Loss: 0.3677 Test MSE Loss: 0.3012
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5598679
	speed: 0.1179s/iter; left time: 2519.4388s
	iters: 200, epoch: 13 | loss: 3.5886233
	speed: 0.1122s/iter; left time: 2385.9874s
Epoch: 13 cost time: 27.949074029922485
Epoch: 13, Steps: 244 Train Loss: 3.6021 (Forecasting Loss:0.3528 + XiCon Loss:3.2493 x Lambda(1.0)), Vali MSE Loss: 0.3672 Test MSE Loss: 0.3012
Validation loss decreased (0.367334 --> 0.367188).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5490959
	speed: 0.1117s/iter; left time: 2360.5548s
	iters: 200, epoch: 14 | loss: 3.5687819
	speed: 0.1129s/iter; left time: 2373.6602s
Epoch: 14 cost time: 27.2953679561615
Epoch: 14, Steps: 244 Train Loss: 3.6031 (Forecasting Loss:0.3526 + XiCon Loss:3.2504 x Lambda(1.0)), Vali MSE Loss: 0.3677 Test MSE Loss: 0.3012
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5746834
	speed: 0.1135s/iter; left time: 2369.6357s
	iters: 200, epoch: 15 | loss: 3.5821483
	speed: 0.1082s/iter; left time: 2249.5683s
Epoch: 15 cost time: 26.883394718170166
Epoch: 15, Steps: 244 Train Loss: 3.6029 (Forecasting Loss:0.3527 + XiCon Loss:3.2502 x Lambda(1.0)), Vali MSE Loss: 0.3672 Test MSE Loss: 0.3012
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6032560
	speed: 0.1130s/iter; left time: 2331.7113s
	iters: 200, epoch: 16 | loss: 3.5609932
	speed: 0.1121s/iter; left time: 2302.6969s
Epoch: 16 cost time: 27.450273513793945
Epoch: 16, Steps: 244 Train Loss: 3.6013 (Forecasting Loss:0.3528 + XiCon Loss:3.2485 x Lambda(1.0)), Vali MSE Loss: 0.3677 Test MSE Loss: 0.3012
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5817173
	speed: 0.1100s/iter; left time: 2244.4351s
	iters: 200, epoch: 17 | loss: 3.5891135
	speed: 0.1139s/iter; left time: 2312.4497s
Epoch: 17 cost time: 27.251323699951172
Epoch: 17, Steps: 244 Train Loss: 3.6023 (Forecasting Loss:0.3527 + XiCon Loss:3.2497 x Lambda(1.0)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3012
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6021719
	speed: 0.1146s/iter; left time: 2309.3375s
	iters: 200, epoch: 18 | loss: 3.6542737
	speed: 0.1123s/iter; left time: 2251.1028s
Epoch: 18 cost time: 27.149144649505615
Epoch: 18, Steps: 244 Train Loss: 3.6001 (Forecasting Loss:0.3527 + XiCon Loss:3.2474 x Lambda(1.0)), Vali MSE Loss: 0.3672 Test MSE Loss: 0.3012
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6146472
	speed: 0.1143s/iter; left time: 2275.2356s
	iters: 200, epoch: 19 | loss: 3.6490629
	speed: 0.1106s/iter; left time: 2190.1762s
Epoch: 19 cost time: 27.524937868118286
Epoch: 19, Steps: 244 Train Loss: 3.6018 (Forecasting Loss:0.3525 + XiCon Loss:3.2493 x Lambda(1.0)), Vali MSE Loss: 0.3673 Test MSE Loss: 0.3012
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.6358776
	speed: 0.1127s/iter; left time: 2216.5500s
	iters: 200, epoch: 20 | loss: 3.6313946
	speed: 0.0778s/iter; left time: 1523.0856s
Epoch: 20 cost time: 24.731961011886597
Epoch: 20, Steps: 244 Train Loss: 3.6019 (Forecasting Loss:0.3525 + XiCon Loss:3.2494 x Lambda(1.0)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3012
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.5885403
	speed: 0.0568s/iter; left time: 1103.0389s
	iters: 200, epoch: 21 | loss: 3.5898869
	speed: 0.1005s/iter; left time: 1941.8091s
Epoch: 21 cost time: 20.691846132278442
Epoch: 21, Steps: 244 Train Loss: 3.6039 (Forecasting Loss:0.3528 + XiCon Loss:3.2511 x Lambda(1.0)), Vali MSE Loss: 0.3676 Test MSE Loss: 0.3012
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.6259229
	speed: 0.1166s/iter; left time: 2236.6105s
	iters: 200, epoch: 22 | loss: 3.6529446
	speed: 0.1104s/iter; left time: 2105.9675s
Epoch: 22 cost time: 27.474451065063477
Epoch: 22, Steps: 244 Train Loss: 3.5998 (Forecasting Loss:0.3529 + XiCon Loss:3.2469 x Lambda(1.0)), Vali MSE Loss: 0.3677 Test MSE Loss: 0.3012
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.6870551
	speed: 0.1162s/iter; left time: 2200.1115s
	iters: 200, epoch: 23 | loss: 3.6112342
	speed: 0.1105s/iter; left time: 2081.3529s
Epoch: 23 cost time: 27.632450819015503
Epoch: 23, Steps: 244 Train Loss: 3.6031 (Forecasting Loss:0.3529 + XiCon Loss:3.2503 x Lambda(1.0)), Vali MSE Loss: 0.3675 Test MSE Loss: 0.3012
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22386081516742706, mae:0.3786093592643738, mape:0.6757709383964539, mspe:17.89385986328125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0208
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.8657527
	speed: 0.0905s/iter; left time: 2200.0272s
	iters: 200, epoch: 1 | loss: 3.7869852
	speed: 0.1087s/iter; left time: 2630.9072s
Epoch: 1 cost time: 24.889631032943726
Epoch: 1, Steps: 244 Train Loss: 3.8391 (Forecasting Loss:0.4606 + XiCon Loss:3.3786 x Lambda(1.0)), Vali MSE Loss: 0.4473 Test MSE Loss: 0.3484
Validation loss decreased (inf --> 0.447333).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5922470
	speed: 0.1139s/iter; left time: 2739.5268s
	iters: 200, epoch: 2 | loss: 3.5281904
	speed: 0.1092s/iter; left time: 2615.9428s
Epoch: 2 cost time: 25.796592712402344
Epoch: 2, Steps: 244 Train Loss: 3.6032 (Forecasting Loss:0.4002 + XiCon Loss:3.2030 x Lambda(1.0)), Vali MSE Loss: 0.4180 Test MSE Loss: 0.3198
Validation loss decreased (0.447333 --> 0.417995).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5675611
	speed: 0.1530s/iter; left time: 3644.5458s
	iters: 200, epoch: 3 | loss: 3.6359422
	speed: 0.1547s/iter; left time: 3668.5456s
Epoch: 3 cost time: 37.50715661048889
Epoch: 3, Steps: 244 Train Loss: 3.5927 (Forecasting Loss:0.3926 + XiCon Loss:3.2001 x Lambda(1.0)), Vali MSE Loss: 0.4198 Test MSE Loss: 0.3223
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6618204
	speed: 0.1418s/iter; left time: 3341.2827s
	iters: 200, epoch: 4 | loss: 3.6735196
	speed: 0.0969s/iter; left time: 2273.7455s
Epoch: 4 cost time: 30.511048555374146
Epoch: 4, Steps: 244 Train Loss: 3.6271 (Forecasting Loss:0.3893 + XiCon Loss:3.2378 x Lambda(1.0)), Vali MSE Loss: 0.4196 Test MSE Loss: 0.3218
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6250312
	speed: 0.1620s/iter; left time: 3779.1393s
	iters: 200, epoch: 5 | loss: 3.6237230
	speed: 0.1571s/iter; left time: 3648.4661s
Epoch: 5 cost time: 38.43493294715881
Epoch: 5, Steps: 244 Train Loss: 3.6481 (Forecasting Loss:0.3868 + XiCon Loss:3.2613 x Lambda(1.0)), Vali MSE Loss: 0.4195 Test MSE Loss: 0.3215
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6241617
	speed: 0.1094s/iter; left time: 2524.4490s
	iters: 200, epoch: 6 | loss: 3.7818739
	speed: 0.1558s/iter; left time: 3579.5492s
Epoch: 6 cost time: 33.47761416435242
Epoch: 6, Steps: 244 Train Loss: 3.6654 (Forecasting Loss:0.3858 + XiCon Loss:3.2797 x Lambda(1.0)), Vali MSE Loss: 0.4192 Test MSE Loss: 0.3221
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6796000
	speed: 0.1608s/iter; left time: 3671.2064s
	iters: 200, epoch: 7 | loss: 3.5877399
	speed: 0.1001s/iter; left time: 2275.6436s
Epoch: 7 cost time: 30.750382661819458
Epoch: 7, Steps: 244 Train Loss: 3.6661 (Forecasting Loss:0.3853 + XiCon Loss:3.2808 x Lambda(1.0)), Vali MSE Loss: 0.4191 Test MSE Loss: 0.3222
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6482973
	speed: 0.1598s/iter; left time: 3611.1627s
	iters: 200, epoch: 8 | loss: 3.6440785
	speed: 0.1574s/iter; left time: 3539.3937s
Epoch: 8 cost time: 38.407143115997314
Epoch: 8, Steps: 244 Train Loss: 3.6714 (Forecasting Loss:0.3851 + XiCon Loss:3.2864 x Lambda(1.0)), Vali MSE Loss: 0.4192 Test MSE Loss: 0.3222
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.7055931
	speed: 0.0970s/iter; left time: 2167.8228s
	iters: 200, epoch: 9 | loss: 3.7502921
	speed: 0.1411s/iter; left time: 3139.4308s
Epoch: 9 cost time: 30.814185619354248
Epoch: 9, Steps: 244 Train Loss: 3.6725 (Forecasting Loss:0.3851 + XiCon Loss:3.2874 x Lambda(1.0)), Vali MSE Loss: 0.4194 Test MSE Loss: 0.3224
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.7172298
	speed: 0.1594s/iter; left time: 3523.1823s
	iters: 200, epoch: 10 | loss: 3.5942919
	speed: 0.1439s/iter; left time: 3165.7810s
Epoch: 10 cost time: 33.97969079017639
Epoch: 10, Steps: 244 Train Loss: 3.6704 (Forecasting Loss:0.3851 + XiCon Loss:3.2853 x Lambda(1.0)), Vali MSE Loss: 0.4191 Test MSE Loss: 0.3224
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6667833
	speed: 0.1521s/iter; left time: 3324.2553s
	iters: 200, epoch: 11 | loss: 3.5682607
	speed: 0.1574s/iter; left time: 3425.7791s
Epoch: 11 cost time: 37.79196047782898
Epoch: 11, Steps: 244 Train Loss: 3.6769 (Forecasting Loss:0.3850 + XiCon Loss:3.2918 x Lambda(1.0)), Vali MSE Loss: 0.4194 Test MSE Loss: 0.3224
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.7440319
	speed: 0.1469s/iter; left time: 3174.6584s
	iters: 200, epoch: 12 | loss: 3.7007835
	speed: 0.1587s/iter; left time: 3414.7356s
Epoch: 12 cost time: 37.351067304611206
Epoch: 12, Steps: 244 Train Loss: 3.6782 (Forecasting Loss:0.3851 + XiCon Loss:3.2931 x Lambda(1.0)), Vali MSE Loss: 0.4192 Test MSE Loss: 0.3224
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.24313350021839142, mae:0.39653632044792175, mape:0.6632733345031738, mspe:15.0150785446167 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5410
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.8228569
	speed: 0.1148s/iter; left time: 2789.7406s
	iters: 200, epoch: 1 | loss: 3.8482201
	speed: 0.1143s/iter; left time: 2767.2193s
Epoch: 1 cost time: 28.10814642906189
Epoch: 1, Steps: 244 Train Loss: 3.8437 (Forecasting Loss:0.4592 + XiCon Loss:3.3846 x Lambda(1.0)), Vali MSE Loss: 0.4526 Test MSE Loss: 0.3542
Validation loss decreased (inf --> 0.452564).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6147406
	speed: 0.1136s/iter; left time: 2732.5739s
	iters: 200, epoch: 2 | loss: 3.5356486
	speed: 0.1118s/iter; left time: 2678.5684s
Epoch: 2 cost time: 27.44869637489319
Epoch: 2, Steps: 244 Train Loss: 3.6224 (Forecasting Loss:0.3781 + XiCon Loss:3.2443 x Lambda(1.0)), Vali MSE Loss: 0.3519 Test MSE Loss: 0.3021
Validation loss decreased (0.452564 --> 0.351883).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5427032
	speed: 0.1156s/iter; left time: 2752.1655s
	iters: 200, epoch: 3 | loss: 3.5388787
	speed: 0.1108s/iter; left time: 2627.9778s
Epoch: 3 cost time: 27.713825702667236
Epoch: 3, Steps: 244 Train Loss: 3.5935 (Forecasting Loss:0.3553 + XiCon Loss:3.2382 x Lambda(1.0)), Vali MSE Loss: 0.3533 Test MSE Loss: 0.2984
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5846319
	speed: 0.1176s/iter; left time: 2772.8505s
	iters: 200, epoch: 4 | loss: 3.5577669
	speed: 0.1144s/iter; left time: 2685.8935s
Epoch: 4 cost time: 28.285552501678467
Epoch: 4, Steps: 244 Train Loss: 3.5914 (Forecasting Loss:0.3504 + XiCon Loss:3.2410 x Lambda(1.0)), Vali MSE Loss: 0.3640 Test MSE Loss: 0.3069
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5301876
	speed: 0.1110s/iter; left time: 2590.1551s
	iters: 200, epoch: 5 | loss: 3.5373366
	speed: 0.1102s/iter; left time: 2559.7368s
Epoch: 5 cost time: 27.057117700576782
Epoch: 5, Steps: 244 Train Loss: 3.5773 (Forecasting Loss:0.3474 + XiCon Loss:3.2299 x Lambda(1.0)), Vali MSE Loss: 0.3523 Test MSE Loss: 0.3029
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5987635
	speed: 0.1150s/iter; left time: 2654.0433s
	iters: 200, epoch: 6 | loss: 3.5252554
	speed: 0.1129s/iter; left time: 2593.4258s
Epoch: 6 cost time: 27.555586576461792
Epoch: 6, Steps: 244 Train Loss: 3.5731 (Forecasting Loss:0.3460 + XiCon Loss:3.2271 x Lambda(1.0)), Vali MSE Loss: 0.3533 Test MSE Loss: 0.3046
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5515962
	speed: 0.1171s/iter; left time: 2673.9328s
	iters: 200, epoch: 7 | loss: 3.5638463
	speed: 0.1126s/iter; left time: 2560.2411s
Epoch: 7 cost time: 27.915013074874878
Epoch: 7, Steps: 244 Train Loss: 3.5711 (Forecasting Loss:0.3456 + XiCon Loss:3.2256 x Lambda(1.0)), Vali MSE Loss: 0.3535 Test MSE Loss: 0.3027
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5882559
	speed: 0.1136s/iter; left time: 2567.5025s
	iters: 200, epoch: 8 | loss: 3.5233226
	speed: 0.1137s/iter; left time: 2556.8555s
Epoch: 8 cost time: 27.67426347732544
Epoch: 8, Steps: 244 Train Loss: 3.5697 (Forecasting Loss:0.3451 + XiCon Loss:3.2247 x Lambda(1.0)), Vali MSE Loss: 0.3537 Test MSE Loss: 0.3027
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4795403
	speed: 0.1159s/iter; left time: 2591.2565s
	iters: 200, epoch: 9 | loss: 3.5435245
	speed: 0.1143s/iter; left time: 2544.1542s
Epoch: 9 cost time: 27.967577695846558
Epoch: 9, Steps: 244 Train Loss: 3.5734 (Forecasting Loss:0.3450 + XiCon Loss:3.2285 x Lambda(1.0)), Vali MSE Loss: 0.3533 Test MSE Loss: 0.3026
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5757356
	speed: 0.1144s/iter; left time: 2529.0341s
	iters: 200, epoch: 10 | loss: 3.5134826
	speed: 0.1129s/iter; left time: 2484.4807s
Epoch: 10 cost time: 27.756123304367065
Epoch: 10, Steps: 244 Train Loss: 3.5728 (Forecasting Loss:0.3451 + XiCon Loss:3.2277 x Lambda(1.0)), Vali MSE Loss: 0.3507 Test MSE Loss: 0.3029
Validation loss decreased (0.351883 --> 0.350671).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6892993
	speed: 0.1148s/iter; left time: 2509.3980s
	iters: 200, epoch: 11 | loss: 3.5502343
	speed: 0.1098s/iter; left time: 2388.7725s
Epoch: 11 cost time: 27.46167254447937
Epoch: 11, Steps: 244 Train Loss: 3.5678 (Forecasting Loss:0.3449 + XiCon Loss:3.2229 x Lambda(1.0)), Vali MSE Loss: 0.3522 Test MSE Loss: 0.3030
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4956539
	speed: 0.1159s/iter; left time: 2504.8971s
	iters: 200, epoch: 12 | loss: 3.5893862
	speed: 0.1123s/iter; left time: 2416.7157s
Epoch: 12 cost time: 27.88693404197693
Epoch: 12, Steps: 244 Train Loss: 3.5714 (Forecasting Loss:0.3450 + XiCon Loss:3.2265 x Lambda(1.0)), Vali MSE Loss: 0.3515 Test MSE Loss: 0.3030
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5638306
	speed: 0.1144s/iter; left time: 2444.9586s
	iters: 200, epoch: 13 | loss: 3.5264125
	speed: 0.1132s/iter; left time: 2408.8101s
Epoch: 13 cost time: 27.894270658493042
Epoch: 13, Steps: 244 Train Loss: 3.5722 (Forecasting Loss:0.3450 + XiCon Loss:3.2271 x Lambda(1.0)), Vali MSE Loss: 0.3519 Test MSE Loss: 0.3031
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6546340
	speed: 0.1156s/iter; left time: 2441.8156s
	iters: 200, epoch: 14 | loss: 3.6173439
	speed: 0.1113s/iter; left time: 2340.2437s
Epoch: 14 cost time: 27.708219051361084
Epoch: 14, Steps: 244 Train Loss: 3.5734 (Forecasting Loss:0.3450 + XiCon Loss:3.2284 x Lambda(1.0)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.3031
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5471048
	speed: 0.1152s/iter; left time: 2405.3034s
	iters: 200, epoch: 15 | loss: 3.5155849
	speed: 0.1128s/iter; left time: 2344.5645s
Epoch: 15 cost time: 27.652299404144287
Epoch: 15, Steps: 244 Train Loss: 3.5734 (Forecasting Loss:0.3445 + XiCon Loss:3.2289 x Lambda(1.0)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.3031
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6354289
	speed: 0.1162s/iter; left time: 2397.9773s
	iters: 200, epoch: 16 | loss: 3.5430813
	speed: 0.1145s/iter; left time: 2351.0920s
Epoch: 16 cost time: 28.04277539253235
Epoch: 16, Steps: 244 Train Loss: 3.5679 (Forecasting Loss:0.3449 + XiCon Loss:3.2230 x Lambda(1.0)), Vali MSE Loss: 0.3518 Test MSE Loss: 0.3031
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5686746
	speed: 0.1151s/iter; left time: 2348.2380s
	iters: 200, epoch: 17 | loss: 3.5759432
	speed: 0.1101s/iter; left time: 2234.8045s
Epoch: 17 cost time: 27.664546728134155
Epoch: 17, Steps: 244 Train Loss: 3.5722 (Forecasting Loss:0.3450 + XiCon Loss:3.2272 x Lambda(1.0)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.3031
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.5043995
	speed: 0.1150s/iter; left time: 2317.5826s
	iters: 200, epoch: 18 | loss: 3.5766251
	speed: 0.1142s/iter; left time: 2290.1883s
Epoch: 18 cost time: 27.858330249786377
Epoch: 18, Steps: 244 Train Loss: 3.5733 (Forecasting Loss:0.3447 + XiCon Loss:3.2285 x Lambda(1.0)), Vali MSE Loss: 0.3517 Test MSE Loss: 0.3031
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4572206
	speed: 0.1166s/iter; left time: 2321.5491s
	iters: 200, epoch: 19 | loss: 3.5399008
	speed: 0.1136s/iter; left time: 2250.8081s
Epoch: 19 cost time: 28.0287823677063
Epoch: 19, Steps: 244 Train Loss: 3.5660 (Forecasting Loss:0.3449 + XiCon Loss:3.2211 x Lambda(1.0)), Vali MSE Loss: 0.3517 Test MSE Loss: 0.3031
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.5735328
	speed: 0.1194s/iter; left time: 2347.9409s
	iters: 200, epoch: 20 | loss: 3.4948037
	speed: 0.1076s/iter; left time: 2104.6220s
Epoch: 20 cost time: 27.653728723526
Epoch: 20, Steps: 244 Train Loss: 3.5690 (Forecasting Loss:0.3448 + XiCon Loss:3.2243 x Lambda(1.0)), Vali MSE Loss: 0.3519 Test MSE Loss: 0.3031
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22578084468841553, mae:0.3801026940345764, mape:0.695688784122467, mspe:18.991086959838867 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5643
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 3.8346345
	speed: 0.1059s/iter; left time: 2572.2993s
	iters: 200, epoch: 1 | loss: 3.8166170
	speed: 0.1108s/iter; left time: 2681.9531s
Epoch: 1 cost time: 26.574416399002075
Epoch: 1, Steps: 244 Train Loss: 3.8343 (Forecasting Loss:0.4605 + XiCon Loss:3.3738 x Lambda(1.0)), Vali MSE Loss: 0.4523 Test MSE Loss: 0.3539
Validation loss decreased (inf --> 0.452256).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5498340
	speed: 0.1145s/iter; left time: 2754.9017s
	iters: 200, epoch: 2 | loss: 3.5136418
	speed: 0.1095s/iter; left time: 2622.5943s
Epoch: 2 cost time: 27.108641624450684
Epoch: 2, Steps: 244 Train Loss: 3.5738 (Forecasting Loss:0.3643 + XiCon Loss:3.2095 x Lambda(1.0)), Vali MSE Loss: 0.3644 Test MSE Loss: 0.3336
Validation loss decreased (0.452256 --> 0.364412).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4740186
	speed: 0.1135s/iter; left time: 2703.9260s
	iters: 200, epoch: 3 | loss: 3.4805031
	speed: 0.1124s/iter; left time: 2664.1815s
Epoch: 3 cost time: 27.479753494262695
Epoch: 3, Steps: 244 Train Loss: 3.4854 (Forecasting Loss:0.3441 + XiCon Loss:3.1414 x Lambda(1.0)), Vali MSE Loss: 0.3598 Test MSE Loss: 0.3409
Validation loss decreased (0.364412 --> 0.359849).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4632859
	speed: 0.1136s/iter; left time: 2677.0064s
	iters: 200, epoch: 4 | loss: 3.5114241
	speed: 0.1085s/iter; left time: 2546.4837s
Epoch: 4 cost time: 27.164552211761475
Epoch: 4, Steps: 244 Train Loss: 3.4744 (Forecasting Loss:0.3413 + XiCon Loss:3.1330 x Lambda(1.0)), Vali MSE Loss: 0.3526 Test MSE Loss: 0.3364
Validation loss decreased (0.359849 --> 0.352565).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4295180
	speed: 0.1167s/iter; left time: 2721.8858s
	iters: 200, epoch: 5 | loss: 3.4950929
	speed: 0.1093s/iter; left time: 2537.8301s
Epoch: 5 cost time: 27.18690299987793
Epoch: 5, Steps: 244 Train Loss: 3.4695 (Forecasting Loss:0.3394 + XiCon Loss:3.1301 x Lambda(1.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.3312
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4718916
	speed: 0.1144s/iter; left time: 2641.3453s
	iters: 200, epoch: 6 | loss: 3.4801254
	speed: 0.1114s/iter; left time: 2561.0601s
Epoch: 6 cost time: 27.658442497253418
Epoch: 6, Steps: 244 Train Loss: 3.4671 (Forecasting Loss:0.3389 + XiCon Loss:3.1282 x Lambda(1.0)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.3330
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4691584
	speed: 0.1124s/iter; left time: 2566.7925s
	iters: 200, epoch: 7 | loss: 3.4466288
	speed: 0.0914s/iter; left time: 2077.2960s
Epoch: 7 cost time: 22.88413429260254
Epoch: 7, Steps: 244 Train Loss: 3.4657 (Forecasting Loss:0.3384 + XiCon Loss:3.1273 x Lambda(1.0)), Vali MSE Loss: 0.3615 Test MSE Loss: 0.3322
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4609735
	speed: 0.0670s/iter; left time: 1513.1306s
	iters: 200, epoch: 8 | loss: 3.4742520
	speed: 0.0575s/iter; left time: 1293.2597s
Epoch: 8 cost time: 15.822826862335205
Epoch: 8, Steps: 244 Train Loss: 3.4670 (Forecasting Loss:0.3377 + XiCon Loss:3.1292 x Lambda(1.0)), Vali MSE Loss: 0.3542 Test MSE Loss: 0.3329
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4515615
	speed: 0.0769s/iter; left time: 1718.3024s
	iters: 200, epoch: 9 | loss: 3.4680970
	speed: 0.0777s/iter; left time: 1728.7011s
Epoch: 9 cost time: 18.802587509155273
Epoch: 9, Steps: 244 Train Loss: 3.4653 (Forecasting Loss:0.3375 + XiCon Loss:3.1277 x Lambda(1.0)), Vali MSE Loss: 0.3584 Test MSE Loss: 0.3319
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4524646
	speed: 0.0773s/iter; left time: 1709.0699s
	iters: 200, epoch: 10 | loss: 3.4858286
	speed: 0.0804s/iter; left time: 1769.4905s
Epoch: 10 cost time: 19.122116327285767
Epoch: 10, Steps: 244 Train Loss: 3.4661 (Forecasting Loss:0.3375 + XiCon Loss:3.1286 x Lambda(1.0)), Vali MSE Loss: 0.3591 Test MSE Loss: 0.3320
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4414985
	speed: 0.0791s/iter; left time: 1728.4163s
	iters: 200, epoch: 11 | loss: 3.4547243
	speed: 0.0829s/iter; left time: 1804.7308s
Epoch: 11 cost time: 19.546857357025146
Epoch: 11, Steps: 244 Train Loss: 3.4641 (Forecasting Loss:0.3375 + XiCon Loss:3.1266 x Lambda(1.0)), Vali MSE Loss: 0.3578 Test MSE Loss: 0.3321
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4432783
	speed: 0.0776s/iter; left time: 1677.7991s
	iters: 200, epoch: 12 | loss: 3.4337716
	speed: 0.0801s/iter; left time: 1722.7570s
Epoch: 12 cost time: 19.297730684280396
Epoch: 12, Steps: 244 Train Loss: 3.4651 (Forecasting Loss:0.3377 + XiCon Loss:3.1275 x Lambda(1.0)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.3321
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4873102
	speed: 0.0796s/iter; left time: 1700.6240s
	iters: 200, epoch: 13 | loss: 3.4295294
	speed: 0.0832s/iter; left time: 1769.1398s
Epoch: 13 cost time: 19.55595302581787
Epoch: 13, Steps: 244 Train Loss: 3.4662 (Forecasting Loss:0.3375 + XiCon Loss:3.1287 x Lambda(1.0)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.3321
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4747202
	speed: 0.0799s/iter; left time: 1688.7733s
	iters: 200, epoch: 14 | loss: 3.4758272
	speed: 0.0776s/iter; left time: 1632.4361s
Epoch: 14 cost time: 19.106445789337158
Epoch: 14, Steps: 244 Train Loss: 3.4647 (Forecasting Loss:0.3377 + XiCon Loss:3.1270 x Lambda(1.0)), Vali MSE Loss: 0.3578 Test MSE Loss: 0.3321
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2651907205581665, mae:0.4076595902442932, mape:0.7615154981613159, mspe:22.00796890258789 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2343+-0.02514, MAE:0.3869+-0.01838, MAPE:0.7013+-0.04742, MSPE:18.7900+-3.22691, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5979
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8929262
	speed: 0.1874s/iter; left time: 4346.7646s
	iters: 200, epoch: 1 | loss: 3.9304991
	speed: 0.1897s/iter; left time: 4381.7085s
Epoch: 1 cost time: 44.37163591384888
Epoch: 1, Steps: 233 Train Loss: 3.9295 (Forecasting Loss:0.5483 + XiCon Loss:3.3812 x Lambda(1.0)), Vali MSE Loss: 0.5230 Test MSE Loss: 0.4249
Validation loss decreased (inf --> 0.523036).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.5956891
	speed: 0.1919s/iter; left time: 4408.0275s
	iters: 200, epoch: 2 | loss: 3.6388462
	speed: 0.1930s/iter; left time: 4413.1424s
Epoch: 2 cost time: 45.21458292007446
Epoch: 2, Steps: 233 Train Loss: 3.6457 (Forecasting Loss:0.4043 + XiCon Loss:3.2415 x Lambda(1.0)), Vali MSE Loss: 0.3540 Test MSE Loss: 0.3159
Validation loss decreased (0.523036 --> 0.354024).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6299970
	speed: 0.1881s/iter; left time: 4276.5019s
	iters: 200, epoch: 3 | loss: 3.6396270
	speed: 0.1955s/iter; left time: 4424.9171s
Epoch: 3 cost time: 44.83269000053406
Epoch: 3, Steps: 233 Train Loss: 3.6408 (Forecasting Loss:0.3663 + XiCon Loss:3.2746 x Lambda(1.0)), Vali MSE Loss: 0.3374 Test MSE Loss: 0.3034
Validation loss decreased (0.354024 --> 0.337362).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5815010
	speed: 0.1975s/iter; left time: 4444.8477s
	iters: 200, epoch: 4 | loss: 3.6130953
	speed: 0.1938s/iter; left time: 4341.4479s
Epoch: 4 cost time: 45.761735677719116
Epoch: 4, Steps: 233 Train Loss: 3.6261 (Forecasting Loss:0.3599 + XiCon Loss:3.2661 x Lambda(1.0)), Vali MSE Loss: 0.3163 Test MSE Loss: 0.3066
Validation loss decreased (0.337362 --> 0.316263).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6998744
	speed: 0.1941s/iter; left time: 4323.0591s
	iters: 200, epoch: 5 | loss: 3.6444554
	speed: 0.1886s/iter; left time: 4180.9454s
Epoch: 5 cost time: 44.6829948425293
Epoch: 5, Steps: 233 Train Loss: 3.6114 (Forecasting Loss:0.3577 + XiCon Loss:3.2536 x Lambda(1.0)), Vali MSE Loss: 0.3085 Test MSE Loss: 0.3034
Validation loss decreased (0.316263 --> 0.308456).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6236467
	speed: 0.1932s/iter; left time: 4256.5698s
	iters: 200, epoch: 6 | loss: 3.6064308
	speed: 0.1911s/iter; left time: 4191.9738s
Epoch: 6 cost time: 44.91829776763916
Epoch: 6, Steps: 233 Train Loss: 3.6047 (Forecasting Loss:0.3560 + XiCon Loss:3.2487 x Lambda(1.0)), Vali MSE Loss: 0.3084 Test MSE Loss: 0.3026
Validation loss decreased (0.308456 --> 0.308352).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6236782
	speed: 0.1936s/iter; left time: 4220.0370s
	iters: 200, epoch: 7 | loss: 3.5639648
	speed: 0.1935s/iter; left time: 4200.0157s
Epoch: 7 cost time: 44.93192386627197
Epoch: 7, Steps: 233 Train Loss: 3.6058 (Forecasting Loss:0.3549 + XiCon Loss:3.2510 x Lambda(1.0)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.3022
Validation loss decreased (0.308352 --> 0.306756).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6141863
	speed: 0.1905s/iter; left time: 4109.7230s
	iters: 200, epoch: 8 | loss: 3.5684907
	speed: 0.1647s/iter; left time: 3536.1464s
Epoch: 8 cost time: 41.05052065849304
Epoch: 8, Steps: 233 Train Loss: 3.6051 (Forecasting Loss:0.3548 + XiCon Loss:3.2503 x Lambda(1.0)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.3011
Validation loss decreased (0.306756 --> 0.306281).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6382635
	speed: 0.1979s/iter; left time: 4222.7858s
	iters: 200, epoch: 9 | loss: 3.6067743
	speed: 0.1940s/iter; left time: 4120.7282s
Epoch: 9 cost time: 45.37000823020935
Epoch: 9, Steps: 233 Train Loss: 3.6004 (Forecasting Loss:0.3541 + XiCon Loss:3.2464 x Lambda(1.0)), Vali MSE Loss: 0.3052 Test MSE Loss: 0.3014
Validation loss decreased (0.306281 --> 0.305174).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6478939
	speed: 0.1986s/iter; left time: 4191.3084s
	iters: 200, epoch: 10 | loss: 3.6209159
	speed: 0.1958s/iter; left time: 4112.1303s
Epoch: 10 cost time: 45.800620794296265
Epoch: 10, Steps: 233 Train Loss: 3.6010 (Forecasting Loss:0.3542 + XiCon Loss:3.2468 x Lambda(1.0)), Vali MSE Loss: 0.3045 Test MSE Loss: 0.3012
Validation loss decreased (0.305174 --> 0.304533).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6120665
	speed: 0.1934s/iter; left time: 4036.9895s
	iters: 200, epoch: 11 | loss: 3.6207697
	speed: 0.1882s/iter; left time: 3909.4723s
Epoch: 11 cost time: 44.354135274887085
Epoch: 11, Steps: 233 Train Loss: 3.6001 (Forecasting Loss:0.3538 + XiCon Loss:3.2463 x Lambda(1.0)), Vali MSE Loss: 0.3048 Test MSE Loss: 0.3012
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6510210
	speed: 0.1934s/iter; left time: 3990.3574s
	iters: 200, epoch: 12 | loss: 3.5827007
	speed: 0.1938s/iter; left time: 3980.5314s
Epoch: 12 cost time: 44.826951026916504
Epoch: 12, Steps: 233 Train Loss: 3.5997 (Forecasting Loss:0.3541 + XiCon Loss:3.2456 x Lambda(1.0)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.3012
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5605395
	speed: 0.1944s/iter; left time: 3966.5181s
	iters: 200, epoch: 13 | loss: 3.6332788
	speed: 0.1952s/iter; left time: 3964.0539s
Epoch: 13 cost time: 45.006176471710205
Epoch: 13, Steps: 233 Train Loss: 3.5983 (Forecasting Loss:0.3538 + XiCon Loss:3.2445 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6311922
	speed: 0.1919s/iter; left time: 3870.7820s
	iters: 200, epoch: 14 | loss: 3.6152658
	speed: 0.1942s/iter; left time: 3897.0114s
Epoch: 14 cost time: 44.77126479148865
Epoch: 14, Steps: 233 Train Loss: 3.5997 (Forecasting Loss:0.3536 + XiCon Loss:3.2460 x Lambda(1.0)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.3011
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5824947
	speed: 0.1971s/iter; left time: 3929.3594s
	iters: 200, epoch: 15 | loss: 3.5809269
	speed: 0.1921s/iter; left time: 3810.7817s
Epoch: 15 cost time: 45.05520176887512
Epoch: 15, Steps: 233 Train Loss: 3.5981 (Forecasting Loss:0.3539 + XiCon Loss:3.2443 x Lambda(1.0)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.3011
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6060400
	speed: 0.1959s/iter; left time: 3859.9238s
	iters: 200, epoch: 16 | loss: 3.5926106
	speed: 0.1951s/iter; left time: 3825.8829s
Epoch: 16 cost time: 45.57140040397644
Epoch: 16, Steps: 233 Train Loss: 3.6011 (Forecasting Loss:0.3537 + XiCon Loss:3.2474 x Lambda(1.0)), Vali MSE Loss: 0.3045 Test MSE Loss: 0.3011
Validation loss decreased (0.304533 --> 0.304523).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6222212
	speed: 0.1936s/iter; left time: 3770.3273s
	iters: 200, epoch: 17 | loss: 3.6028731
	speed: 0.1931s/iter; left time: 3741.4014s
Epoch: 17 cost time: 45.066763401031494
Epoch: 17, Steps: 233 Train Loss: 3.6002 (Forecasting Loss:0.3541 + XiCon Loss:3.2461 x Lambda(1.0)), Vali MSE Loss: 0.3048 Test MSE Loss: 0.3011
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.5868404
	speed: 0.1943s/iter; left time: 3738.7793s
	iters: 200, epoch: 18 | loss: 3.5730052
	speed: 0.1874s/iter; left time: 3586.1772s
Epoch: 18 cost time: 44.59617853164673
Epoch: 18, Steps: 233 Train Loss: 3.5994 (Forecasting Loss:0.3540 + XiCon Loss:3.2454 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.6236577
	speed: 0.1910s/iter; left time: 3630.9114s
	iters: 200, epoch: 19 | loss: 3.6024313
	speed: 0.1984s/iter; left time: 3750.7821s
Epoch: 19 cost time: 45.29406976699829
Epoch: 19, Steps: 233 Train Loss: 3.6002 (Forecasting Loss:0.3541 + XiCon Loss:3.2461 x Lambda(1.0)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.3011
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.5907564
	speed: 0.1888s/iter; left time: 3543.6939s
	iters: 200, epoch: 20 | loss: 3.6102803
	speed: 0.1600s/iter; left time: 2987.2004s
Epoch: 20 cost time: 41.037683963775635
Epoch: 20, Steps: 233 Train Loss: 3.5988 (Forecasting Loss:0.3540 + XiCon Loss:3.2448 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.5893109
	speed: 0.1932s/iter; left time: 3581.3159s
	iters: 200, epoch: 21 | loss: 3.6193511
	speed: 0.1938s/iter; left time: 3574.2235s
Epoch: 21 cost time: 44.995718479156494
Epoch: 21, Steps: 233 Train Loss: 3.5968 (Forecasting Loss:0.3537 + XiCon Loss:3.2431 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.5460167
	speed: 0.1951s/iter; left time: 3572.6805s
	iters: 200, epoch: 22 | loss: 3.6373351
	speed: 0.1898s/iter; left time: 3455.8559s
Epoch: 22 cost time: 45.004101514816284
Epoch: 22, Steps: 233 Train Loss: 3.5989 (Forecasting Loss:0.3541 + XiCon Loss:3.2448 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.6074631
	speed: 0.1950s/iter; left time: 3525.4003s
	iters: 200, epoch: 23 | loss: 3.5975037
	speed: 0.1929s/iter; left time: 3467.6744s
Epoch: 23 cost time: 45.36385679244995
Epoch: 23, Steps: 233 Train Loss: 3.5991 (Forecasting Loss:0.3540 + XiCon Loss:3.2451 x Lambda(1.0)), Vali MSE Loss: 0.3048 Test MSE Loss: 0.3011
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.6558495
	speed: 0.1928s/iter; left time: 3439.1454s
	iters: 200, epoch: 24 | loss: 3.6400776
	speed: 0.1880s/iter; left time: 3335.5382s
Epoch: 24 cost time: 44.19204020500183
Epoch: 24, Steps: 233 Train Loss: 3.5984 (Forecasting Loss:0.3538 + XiCon Loss:3.2446 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.6077814
	speed: 0.1951s/iter; left time: 3435.6788s
	iters: 200, epoch: 25 | loss: 3.5649331
	speed: 0.1956s/iter; left time: 3425.1891s
Epoch: 25 cost time: 45.3204185962677
Epoch: 25, Steps: 233 Train Loss: 3.5976 (Forecasting Loss:0.3537 + XiCon Loss:3.2440 x Lambda(1.0)), Vali MSE Loss: 0.3046 Test MSE Loss: 0.3011
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.6272352
	speed: 0.1958s/iter; left time: 3402.9211s
	iters: 200, epoch: 26 | loss: 3.5453303
	speed: 0.1904s/iter; left time: 3289.6621s
Epoch: 26 cost time: 45.13064098358154
Epoch: 26, Steps: 233 Train Loss: 3.5987 (Forecasting Loss:0.3541 + XiCon Loss:3.2446 x Lambda(1.0)), Vali MSE Loss: 0.3047 Test MSE Loss: 0.3011
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.22363346815109253, mae:0.37864887714385986, mape:0.6858275532722473, mspe:18.848421096801758 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4179
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8686638
	speed: 0.1719s/iter; left time: 3987.8856s
	iters: 200, epoch: 1 | loss: 3.8872070
	speed: 0.1856s/iter; left time: 4287.2945s
Epoch: 1 cost time: 41.879027128219604
Epoch: 1, Steps: 233 Train Loss: 3.9116 (Forecasting Loss:0.5487 + XiCon Loss:3.3629 x Lambda(1.0)), Vali MSE Loss: 0.5183 Test MSE Loss: 0.4255
Validation loss decreased (inf --> 0.518313).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6814132
	speed: 0.1821s/iter; left time: 4182.7409s
	iters: 200, epoch: 2 | loss: 3.6984067
	speed: 0.1853s/iter; left time: 4238.0119s
Epoch: 2 cost time: 43.149513244628906
Epoch: 2, Steps: 233 Train Loss: 3.6748 (Forecasting Loss:0.4393 + XiCon Loss:3.2355 x Lambda(1.0)), Vali MSE Loss: 0.3833 Test MSE Loss: 0.3128
Validation loss decreased (0.518313 --> 0.383281).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6351635
	speed: 0.1806s/iter; left time: 4105.3626s
	iters: 200, epoch: 3 | loss: 3.6574986
	speed: 0.1822s/iter; left time: 4122.9663s
Epoch: 3 cost time: 42.31291127204895
Epoch: 3, Steps: 233 Train Loss: 3.6133 (Forecasting Loss:0.3640 + XiCon Loss:3.2493 x Lambda(1.0)), Vali MSE Loss: 0.3906 Test MSE Loss: 0.3391
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.6740272
	speed: 0.1862s/iter; left time: 4188.8842s
	iters: 200, epoch: 4 | loss: 3.5252190
	speed: 0.1754s/iter; left time: 3929.0114s
Epoch: 4 cost time: 42.08308219909668
Epoch: 4, Steps: 233 Train Loss: 3.6034 (Forecasting Loss:0.3590 + XiCon Loss:3.2444 x Lambda(1.0)), Vali MSE Loss: 0.3839 Test MSE Loss: 0.3349
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6108294
	speed: 0.1893s/iter; left time: 4216.5034s
	iters: 200, epoch: 5 | loss: 3.5413084
	speed: 0.1793s/iter; left time: 3975.9691s
Epoch: 5 cost time: 42.70312571525574
Epoch: 5, Steps: 233 Train Loss: 3.5992 (Forecasting Loss:0.3567 + XiCon Loss:3.2425 x Lambda(1.0)), Vali MSE Loss: 0.3838 Test MSE Loss: 0.3281
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5992584
	speed: 0.1815s/iter; left time: 3998.6999s
	iters: 200, epoch: 6 | loss: 3.5564685
	speed: 0.1705s/iter; left time: 3740.5123s
Epoch: 6 cost time: 39.271602630615234
Epoch: 6, Steps: 233 Train Loss: 3.5951 (Forecasting Loss:0.3550 + XiCon Loss:3.2400 x Lambda(1.0)), Vali MSE Loss: 0.3811 Test MSE Loss: 0.3282
Validation loss decreased (0.383281 --> 0.381055).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5696249
	speed: 0.1815s/iter; left time: 3957.8940s
	iters: 200, epoch: 7 | loss: 3.6069393
	speed: 0.1800s/iter; left time: 3907.0488s
Epoch: 7 cost time: 42.080350399017334
Epoch: 7, Steps: 233 Train Loss: 3.5917 (Forecasting Loss:0.3547 + XiCon Loss:3.2369 x Lambda(1.0)), Vali MSE Loss: 0.3799 Test MSE Loss: 0.3261
Validation loss decreased (0.381055 --> 0.379937).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.5694637
	speed: 0.1795s/iter; left time: 3872.4826s
	iters: 200, epoch: 8 | loss: 3.6293454
	speed: 0.1832s/iter; left time: 3934.2143s
Epoch: 8 cost time: 42.092013120651245
Epoch: 8, Steps: 233 Train Loss: 3.5928 (Forecasting Loss:0.3543 + XiCon Loss:3.2385 x Lambda(1.0)), Vali MSE Loss: 0.3851 Test MSE Loss: 0.3287
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6218853
	speed: 0.1827s/iter; left time: 3898.1017s
	iters: 200, epoch: 9 | loss: 3.5938237
	speed: 0.1787s/iter; left time: 3794.5671s
Epoch: 9 cost time: 41.85450482368469
Epoch: 9, Steps: 233 Train Loss: 3.5930 (Forecasting Loss:0.3539 + XiCon Loss:3.2391 x Lambda(1.0)), Vali MSE Loss: 0.3850 Test MSE Loss: 0.3307
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5767558
	speed: 0.1795s/iter; left time: 3787.3542s
	iters: 200, epoch: 10 | loss: 3.5782762
	speed: 0.1914s/iter; left time: 4020.4679s
Epoch: 10 cost time: 42.89676761627197
Epoch: 10, Steps: 233 Train Loss: 3.5937 (Forecasting Loss:0.3538 + XiCon Loss:3.2399 x Lambda(1.0)), Vali MSE Loss: 0.3839 Test MSE Loss: 0.3294
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6514497
	speed: 0.1871s/iter; left time: 3905.3758s
	iters: 200, epoch: 11 | loss: 3.6051488
	speed: 0.1792s/iter; left time: 3722.0931s
Epoch: 11 cost time: 42.637847900390625
Epoch: 11, Steps: 233 Train Loss: 3.5917 (Forecasting Loss:0.3532 + XiCon Loss:3.2385 x Lambda(1.0)), Vali MSE Loss: 0.3848 Test MSE Loss: 0.3298
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6031969
	speed: 0.1839s/iter; left time: 3794.4597s
	iters: 200, epoch: 12 | loss: 3.5691080
	speed: 0.1753s/iter; left time: 3600.0939s
Epoch: 12 cost time: 42.45083785057068
Epoch: 12, Steps: 233 Train Loss: 3.5917 (Forecasting Loss:0.3536 + XiCon Loss:3.2381 x Lambda(1.0)), Vali MSE Loss: 0.3850 Test MSE Loss: 0.3294
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.5936756
	speed: 0.1800s/iter; left time: 3672.0088s
	iters: 200, epoch: 13 | loss: 3.5725620
	speed: 0.1740s/iter; left time: 3532.7669s
Epoch: 13 cost time: 41.460999727249146
Epoch: 13, Steps: 233 Train Loss: 3.5893 (Forecasting Loss:0.3538 + XiCon Loss:3.2355 x Lambda(1.0)), Vali MSE Loss: 0.3844 Test MSE Loss: 0.3295
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5843570
	speed: 0.1845s/iter; left time: 3721.6429s
	iters: 200, epoch: 14 | loss: 3.5754941
	speed: 0.1807s/iter; left time: 3627.2959s
Epoch: 14 cost time: 42.45350456237793
Epoch: 14, Steps: 233 Train Loss: 3.5922 (Forecasting Loss:0.3535 + XiCon Loss:3.2387 x Lambda(1.0)), Vali MSE Loss: 0.3846 Test MSE Loss: 0.3295
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5912266
	speed: 0.1813s/iter; left time: 3615.6543s
	iters: 200, epoch: 15 | loss: 3.6466994
	speed: 0.1772s/iter; left time: 3514.7750s
Epoch: 15 cost time: 41.815067768096924
Epoch: 15, Steps: 233 Train Loss: 3.5924 (Forecasting Loss:0.3533 + XiCon Loss:3.2390 x Lambda(1.0)), Vali MSE Loss: 0.3844 Test MSE Loss: 0.3294
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6131928
	speed: 0.1758s/iter; left time: 3464.1342s
	iters: 200, epoch: 16 | loss: 3.5976546
	speed: 0.1829s/iter; left time: 3584.9688s
Epoch: 16 cost time: 41.75404095649719
Epoch: 16, Steps: 233 Train Loss: 3.5932 (Forecasting Loss:0.3535 + XiCon Loss:3.2397 x Lambda(1.0)), Vali MSE Loss: 0.3844 Test MSE Loss: 0.3295
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.6344457
	speed: 0.1853s/iter; left time: 3607.5326s
	iters: 200, epoch: 17 | loss: 3.6026852
	speed: 0.1767s/iter; left time: 3424.1093s
Epoch: 17 cost time: 42.125909090042114
Epoch: 17, Steps: 233 Train Loss: 3.5948 (Forecasting Loss:0.3537 + XiCon Loss:3.2410 x Lambda(1.0)), Vali MSE Loss: 0.3843 Test MSE Loss: 0.3295
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.25026023387908936, mae:0.4018438160419464, mape:0.6233142614364624, mspe:13.24817943572998 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5646
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 4.0088377
	speed: 0.1828s/iter; left time: 4241.4517s
	iters: 200, epoch: 1 | loss: 3.9339700
	speed: 0.1820s/iter; left time: 4205.4028s
Epoch: 1 cost time: 41.014708518981934
Epoch: 1, Steps: 233 Train Loss: 3.9391 (Forecasting Loss:0.5540 + XiCon Loss:3.3851 x Lambda(1.0)), Vali MSE Loss: 0.5461 Test MSE Loss: 0.4601
Validation loss decreased (inf --> 0.546068).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6980600
	speed: 0.1939s/iter; left time: 4452.6696s
	iters: 200, epoch: 2 | loss: 3.6372924
	speed: 0.1901s/iter; left time: 4348.1887s
Epoch: 2 cost time: 44.84882593154907
Epoch: 2, Steps: 233 Train Loss: 3.6915 (Forecasting Loss:0.4886 + XiCon Loss:3.2030 x Lambda(1.0)), Vali MSE Loss: 0.4629 Test MSE Loss: 0.3702
Validation loss decreased (0.546068 --> 0.462933).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5236211
	speed: 0.1901s/iter; left time: 4322.6361s
	iters: 200, epoch: 3 | loss: 3.5191252
	speed: 0.1955s/iter; left time: 4425.0793s
Epoch: 3 cost time: 45.22820806503296
Epoch: 3, Steps: 233 Train Loss: 3.5368 (Forecasting Loss:0.4002 + XiCon Loss:3.1366 x Lambda(1.0)), Vali MSE Loss: 0.3740 Test MSE Loss: 0.3264
Validation loss decreased (0.462933 --> 0.373952).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5510962
	speed: 0.1952s/iter; left time: 4393.1705s
	iters: 200, epoch: 4 | loss: 3.6327577
	speed: 0.1928s/iter; left time: 4318.8836s
Epoch: 4 cost time: 45.67286491394043
Epoch: 4, Steps: 233 Train Loss: 3.5823 (Forecasting Loss:0.3572 + XiCon Loss:3.2251 x Lambda(1.0)), Vali MSE Loss: 0.3507 Test MSE Loss: 0.3196
Validation loss decreased (0.373952 --> 0.350674).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.6061237
	speed: 0.1922s/iter; left time: 4280.5852s
	iters: 200, epoch: 5 | loss: 3.6981030
	speed: 0.1952s/iter; left time: 4327.4040s
Epoch: 5 cost time: 45.50214862823486
Epoch: 5, Steps: 233 Train Loss: 3.6356 (Forecasting Loss:0.3496 + XiCon Loss:3.2859 x Lambda(1.0)), Vali MSE Loss: 0.3373 Test MSE Loss: 0.3557
Validation loss decreased (0.350674 --> 0.337295).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6523476
	speed: 0.1980s/iter; left time: 4363.6119s
	iters: 200, epoch: 6 | loss: 3.6386528
	speed: 0.1944s/iter; left time: 4263.7544s
Epoch: 6 cost time: 45.94223999977112
Epoch: 6, Steps: 233 Train Loss: 3.6520 (Forecasting Loss:0.3489 + XiCon Loss:3.3031 x Lambda(1.0)), Vali MSE Loss: 0.3396 Test MSE Loss: 0.3624
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6294315
	speed: 0.1910s/iter; left time: 4164.6518s
	iters: 200, epoch: 7 | loss: 3.7553763
	speed: 0.1925s/iter; left time: 4177.9169s
Epoch: 7 cost time: 44.965826749801636
Epoch: 7, Steps: 233 Train Loss: 3.6549 (Forecasting Loss:0.3490 + XiCon Loss:3.3059 x Lambda(1.0)), Vali MSE Loss: 0.3511 Test MSE Loss: 0.3632
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6535127
	speed: 0.2034s/iter; left time: 4386.4551s
	iters: 200, epoch: 8 | loss: 3.6642337
	speed: 0.1938s/iter; left time: 4160.5456s
Epoch: 8 cost time: 46.27322697639465
Epoch: 8, Steps: 233 Train Loss: 3.6541 (Forecasting Loss:0.3491 + XiCon Loss:3.3050 x Lambda(1.0)), Vali MSE Loss: 0.3522 Test MSE Loss: 0.3653
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.6312847
	speed: 0.1948s/iter; left time: 4156.9693s
	iters: 200, epoch: 9 | loss: 3.6539736
	speed: 0.1984s/iter; left time: 4213.5719s
Epoch: 9 cost time: 45.377875089645386
Epoch: 9, Steps: 233 Train Loss: 3.6551 (Forecasting Loss:0.3495 + XiCon Loss:3.3055 x Lambda(1.0)), Vali MSE Loss: 0.3528 Test MSE Loss: 0.3666
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6165709
	speed: 0.1966s/iter; left time: 4149.6348s
	iters: 200, epoch: 10 | loss: 3.6580691
	speed: 0.1978s/iter; left time: 4155.3546s
Epoch: 10 cost time: 45.941718339920044
Epoch: 10, Steps: 233 Train Loss: 3.6587 (Forecasting Loss:0.3494 + XiCon Loss:3.3093 x Lambda(1.0)), Vali MSE Loss: 0.3504 Test MSE Loss: 0.3694
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6496377
	speed: 0.1972s/iter; left time: 4115.2267s
	iters: 200, epoch: 11 | loss: 3.6118963
	speed: 0.1950s/iter; left time: 4050.8448s
Epoch: 11 cost time: 45.734801292419434
Epoch: 11, Steps: 233 Train Loss: 3.6590 (Forecasting Loss:0.3495 + XiCon Loss:3.3095 x Lambda(1.0)), Vali MSE Loss: 0.3509 Test MSE Loss: 0.3692
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6924322
	speed: 0.1978s/iter; left time: 4081.9845s
	iters: 200, epoch: 12 | loss: 3.6754897
	speed: 0.1894s/iter; left time: 3889.3379s
Epoch: 12 cost time: 45.42784237861633
Epoch: 12, Steps: 233 Train Loss: 3.6541 (Forecasting Loss:0.3495 + XiCon Loss:3.3046 x Lambda(1.0)), Vali MSE Loss: 0.3519 Test MSE Loss: 0.3687
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6576400
	speed: 0.1925s/iter; left time: 3927.2002s
	iters: 200, epoch: 13 | loss: 3.6978137
	speed: 0.1814s/iter; left time: 3682.7148s
Epoch: 13 cost time: 42.216678619384766
Epoch: 13, Steps: 233 Train Loss: 3.6583 (Forecasting Loss:0.3498 + XiCon Loss:3.3085 x Lambda(1.0)), Vali MSE Loss: 0.3519 Test MSE Loss: 0.3686
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6642504
	speed: 0.2040s/iter; left time: 4114.5782s
	iters: 200, epoch: 14 | loss: 3.5981989
	speed: 0.1994s/iter; left time: 4002.6687s
Epoch: 14 cost time: 47.3927366733551
Epoch: 14, Steps: 233 Train Loss: 3.6556 (Forecasting Loss:0.3492 + XiCon Loss:3.3065 x Lambda(1.0)), Vali MSE Loss: 0.3526 Test MSE Loss: 0.3684
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6512611
	speed: 0.2044s/iter; left time: 4075.1370s
	iters: 200, epoch: 15 | loss: 3.7052894
	speed: 0.2064s/iter; left time: 4093.8578s
Epoch: 15 cost time: 47.85526132583618
Epoch: 15, Steps: 233 Train Loss: 3.6552 (Forecasting Loss:0.3495 + XiCon Loss:3.3057 x Lambda(1.0)), Vali MSE Loss: 0.3524 Test MSE Loss: 0.3684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2822706401348114, mae:0.4292265772819519, mape:0.6231564879417419, mspe:11.339622497558594 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.4029
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.9469545
	speed: 0.1851s/iter; left time: 4295.2602s
	iters: 200, epoch: 1 | loss: 3.8915169
	speed: 0.1872s/iter; left time: 4325.2618s
Epoch: 1 cost time: 43.46051502227783
Epoch: 1, Steps: 233 Train Loss: 3.9280 (Forecasting Loss:0.5509 + XiCon Loss:3.3771 x Lambda(1.0)), Vali MSE Loss: 0.5173 Test MSE Loss: 0.4239
Validation loss decreased (inf --> 0.517313).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.6993213
	speed: 0.1906s/iter; left time: 4378.5640s
	iters: 200, epoch: 2 | loss: 3.5961325
	speed: 0.1979s/iter; left time: 4526.4497s
Epoch: 2 cost time: 45.14718055725098
Epoch: 2, Steps: 233 Train Loss: 3.6534 (Forecasting Loss:0.4394 + XiCon Loss:3.2140 x Lambda(1.0)), Vali MSE Loss: 0.3905 Test MSE Loss: 0.3304
Validation loss decreased (0.517313 --> 0.390540).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.5571733
	speed: 0.1898s/iter; left time: 4314.7532s
	iters: 200, epoch: 3 | loss: 3.5566144
	speed: 0.1992s/iter; left time: 4509.8086s
Epoch: 3 cost time: 45.053927183151245
Epoch: 3, Steps: 233 Train Loss: 3.5418 (Forecasting Loss:0.3873 + XiCon Loss:3.1546 x Lambda(1.0)), Vali MSE Loss: 0.3748 Test MSE Loss: 0.3353
Validation loss decreased (0.390540 --> 0.374838).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4784436
	speed: 0.1962s/iter; left time: 4414.3415s
	iters: 200, epoch: 4 | loss: 3.5277138
	speed: 0.1857s/iter; left time: 4159.8878s
Epoch: 4 cost time: 44.444149017333984
Epoch: 4, Steps: 233 Train Loss: 3.5247 (Forecasting Loss:0.3835 + XiCon Loss:3.1412 x Lambda(1.0)), Vali MSE Loss: 0.3764 Test MSE Loss: 0.3092
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4987197
	speed: 0.1955s/iter; left time: 4353.2383s
	iters: 200, epoch: 5 | loss: 3.5323534
	speed: 0.1920s/iter; left time: 4257.5149s
Epoch: 5 cost time: 45.15110111236572
Epoch: 5, Steps: 233 Train Loss: 3.5199 (Forecasting Loss:0.3834 + XiCon Loss:3.1365 x Lambda(1.0)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3063
Validation loss decreased (0.374838 --> 0.374696).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.5320253
	speed: 0.1916s/iter; left time: 4222.7527s
	iters: 200, epoch: 6 | loss: 3.5540390
	speed: 0.1920s/iter; left time: 4212.2666s
Epoch: 6 cost time: 44.56022596359253
Epoch: 6, Steps: 233 Train Loss: 3.5653 (Forecasting Loss:0.3814 + XiCon Loss:3.1839 x Lambda(1.0)), Vali MSE Loss: 0.3783 Test MSE Loss: 0.3065
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.5980177
	speed: 0.1970s/iter; left time: 4294.9421s
	iters: 200, epoch: 7 | loss: 3.5970039
	speed: 0.1910s/iter; left time: 4145.0679s
Epoch: 7 cost time: 45.546173334121704
Epoch: 7, Steps: 233 Train Loss: 3.5840 (Forecasting Loss:0.3790 + XiCon Loss:3.2050 x Lambda(1.0)), Vali MSE Loss: 0.3815 Test MSE Loss: 0.3067
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6090598
	speed: 0.1924s/iter; left time: 4149.1155s
	iters: 200, epoch: 8 | loss: 3.6079383
	speed: 0.1918s/iter; left time: 4116.9528s
Epoch: 8 cost time: 44.5696976184845
Epoch: 8, Steps: 233 Train Loss: 3.5953 (Forecasting Loss:0.3779 + XiCon Loss:3.2174 x Lambda(1.0)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.3050
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5512397
	speed: 0.1928s/iter; left time: 4114.3833s
	iters: 200, epoch: 9 | loss: 3.5624819
	speed: 0.1916s/iter; left time: 4068.5511s
Epoch: 9 cost time: 44.93343377113342
Epoch: 9, Steps: 233 Train Loss: 3.5926 (Forecasting Loss:0.3770 + XiCon Loss:3.2156 x Lambda(1.0)), Vali MSE Loss: 0.3801 Test MSE Loss: 0.3050
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.5996401
	speed: 0.1941s/iter; left time: 4095.6814s
	iters: 200, epoch: 10 | loss: 3.5931580
	speed: 0.1876s/iter; left time: 3940.3184s
Epoch: 10 cost time: 44.56167674064636
Epoch: 10, Steps: 233 Train Loss: 3.5984 (Forecasting Loss:0.3767 + XiCon Loss:3.2216 x Lambda(1.0)), Vali MSE Loss: 0.3789 Test MSE Loss: 0.3042
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6057248
	speed: 0.1915s/iter; left time: 3997.8361s
	iters: 200, epoch: 11 | loss: 3.6245174
	speed: 0.1938s/iter; left time: 4026.2073s
Epoch: 11 cost time: 44.69146490097046
Epoch: 11, Steps: 233 Train Loss: 3.6004 (Forecasting Loss:0.3769 + XiCon Loss:3.2236 x Lambda(1.0)), Vali MSE Loss: 0.3801 Test MSE Loss: 0.3048
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6806998
	speed: 0.1904s/iter; left time: 3930.1820s
	iters: 200, epoch: 12 | loss: 3.5557880
	speed: 0.1865s/iter; left time: 3829.5964s
Epoch: 12 cost time: 43.92281413078308
Epoch: 12, Steps: 233 Train Loss: 3.6008 (Forecasting Loss:0.3766 + XiCon Loss:3.2242 x Lambda(1.0)), Vali MSE Loss: 0.3806 Test MSE Loss: 0.3048
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6060960
	speed: 0.1955s/iter; left time: 3989.0092s
	iters: 200, epoch: 13 | loss: 3.5572319
	speed: 0.1829s/iter; left time: 3714.4955s
Epoch: 13 cost time: 42.725839138031006
Epoch: 13, Steps: 233 Train Loss: 3.6002 (Forecasting Loss:0.3767 + XiCon Loss:3.2235 x Lambda(1.0)), Vali MSE Loss: 0.3806 Test MSE Loss: 0.3047
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6174052
	speed: 0.1908s/iter; left time: 3848.2513s
	iters: 200, epoch: 14 | loss: 3.5613260
	speed: 0.1919s/iter; left time: 3851.4781s
Epoch: 14 cost time: 44.1870322227478
Epoch: 14, Steps: 233 Train Loss: 3.5992 (Forecasting Loss:0.3764 + XiCon Loss:3.2228 x Lambda(1.0)), Vali MSE Loss: 0.3803 Test MSE Loss: 0.3047
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.6242771
	speed: 0.1916s/iter; left time: 3820.7246s
	iters: 200, epoch: 15 | loss: 3.6738129
	speed: 0.1792s/iter; left time: 3555.1038s
Epoch: 15 cost time: 43.76073122024536
Epoch: 15, Steps: 233 Train Loss: 3.6004 (Forecasting Loss:0.3768 + XiCon Loss:3.2236 x Lambda(1.0)), Vali MSE Loss: 0.3805 Test MSE Loss: 0.3047
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.2318107634782791, mae:0.38075825572013855, mape:0.6525166630744934, mspe:17.848421096801758 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.5353
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 3.8989899
	speed: 0.1838s/iter; left time: 4263.8814s
	iters: 200, epoch: 1 | loss: 3.8870964
	speed: 0.1880s/iter; left time: 4343.7002s
Epoch: 1 cost time: 43.432677030563354
Epoch: 1, Steps: 233 Train Loss: 3.9250 (Forecasting Loss:0.5492 + XiCon Loss:3.3758 x Lambda(1.0)), Vali MSE Loss: 0.5088 Test MSE Loss: 0.4142
Validation loss decreased (inf --> 0.508804).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.7031264
	speed: 0.1938s/iter; left time: 4452.1715s
	iters: 200, epoch: 2 | loss: 3.7195525
	speed: 0.1920s/iter; left time: 4390.9167s
Epoch: 2 cost time: 45.499144554138184
Epoch: 2, Steps: 233 Train Loss: 3.7262 (Forecasting Loss:0.4421 + XiCon Loss:3.2840 x Lambda(1.0)), Vali MSE Loss: 0.4374 Test MSE Loss: 0.3499
Validation loss decreased (0.508804 --> 0.437391).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.6538265
	speed: 0.1931s/iter; left time: 4389.2755s
	iters: 200, epoch: 3 | loss: 3.6931245
	speed: 0.1860s/iter; left time: 4209.5949s
Epoch: 3 cost time: 44.16930913925171
Epoch: 3, Steps: 233 Train Loss: 3.6653 (Forecasting Loss:0.3693 + XiCon Loss:3.2960 x Lambda(1.0)), Vali MSE Loss: 0.3983 Test MSE Loss: 0.3615
Validation loss decreased (0.437391 --> 0.398321).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5983341
	speed: 0.1916s/iter; left time: 4311.1721s
	iters: 200, epoch: 4 | loss: 3.5952652
	speed: 0.1846s/iter; left time: 4135.0616s
Epoch: 4 cost time: 43.81237483024597
Epoch: 4, Steps: 233 Train Loss: 3.6514 (Forecasting Loss:0.3599 + XiCon Loss:3.2915 x Lambda(1.0)), Vali MSE Loss: 0.3786 Test MSE Loss: 0.3748
Validation loss decreased (0.398321 --> 0.378649).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.7455325
	speed: 0.1929s/iter; left time: 4295.8761s
	iters: 200, epoch: 5 | loss: 3.6568422
	speed: 0.1937s/iter; left time: 4293.8919s
Epoch: 5 cost time: 45.12160849571228
Epoch: 5, Steps: 233 Train Loss: 3.6448 (Forecasting Loss:0.3568 + XiCon Loss:3.2880 x Lambda(1.0)), Vali MSE Loss: 0.3747 Test MSE Loss: 0.3660
Validation loss decreased (0.378649 --> 0.374653).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.6382303
	speed: 0.1945s/iter; left time: 4286.8343s
	iters: 200, epoch: 6 | loss: 3.6394238
	speed: 0.1834s/iter; left time: 4022.9858s
Epoch: 6 cost time: 44.26870036125183
Epoch: 6, Steps: 233 Train Loss: 3.6366 (Forecasting Loss:0.3547 + XiCon Loss:3.2818 x Lambda(1.0)), Vali MSE Loss: 0.3700 Test MSE Loss: 0.3682
Validation loss decreased (0.374653 --> 0.370028).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.6154838
	speed: 0.1960s/iter; left time: 4272.3426s
	iters: 200, epoch: 7 | loss: 3.6246240
	speed: 0.1909s/iter; left time: 4143.5806s
Epoch: 7 cost time: 45.029629945755005
Epoch: 7, Steps: 233 Train Loss: 3.6317 (Forecasting Loss:0.3539 + XiCon Loss:3.2778 x Lambda(1.0)), Vali MSE Loss: 0.3718 Test MSE Loss: 0.3685
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.6950731
	speed: 0.1895s/iter; left time: 4087.6829s
	iters: 200, epoch: 8 | loss: 3.6589699
	speed: 0.1854s/iter; left time: 3979.8994s
Epoch: 8 cost time: 43.895888566970825
Epoch: 8, Steps: 233 Train Loss: 3.6292 (Forecasting Loss:0.3536 + XiCon Loss:3.2756 x Lambda(1.0)), Vali MSE Loss: 0.3704 Test MSE Loss: 0.3685
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5852311
	speed: 0.1954s/iter; left time: 4169.4867s
	iters: 200, epoch: 9 | loss: 3.5891731
	speed: 0.1804s/iter; left time: 3831.8547s
Epoch: 9 cost time: 44.133004903793335
Epoch: 9, Steps: 233 Train Loss: 3.6341 (Forecasting Loss:0.3533 + XiCon Loss:3.2808 x Lambda(1.0)), Vali MSE Loss: 0.3727 Test MSE Loss: 0.3688
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.6355922
	speed: 0.1881s/iter; left time: 3969.2610s
	iters: 200, epoch: 10 | loss: 3.6353621
	speed: 0.1871s/iter; left time: 3929.5568s
Epoch: 10 cost time: 43.956998109817505
Epoch: 10, Steps: 233 Train Loss: 3.6324 (Forecasting Loss:0.3535 + XiCon Loss:3.2790 x Lambda(1.0)), Vali MSE Loss: 0.3722 Test MSE Loss: 0.3692
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.6600661
	speed: 0.1916s/iter; left time: 3999.2474s
	iters: 200, epoch: 11 | loss: 3.6119661
	speed: 0.1846s/iter; left time: 3834.4016s
Epoch: 11 cost time: 44.12075757980347
Epoch: 11, Steps: 233 Train Loss: 3.6336 (Forecasting Loss:0.3538 + XiCon Loss:3.2798 x Lambda(1.0)), Vali MSE Loss: 0.3716 Test MSE Loss: 0.3693
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.6325622
	speed: 0.1919s/iter; left time: 3960.4301s
	iters: 200, epoch: 12 | loss: 3.6050310
	speed: 0.1886s/iter; left time: 3872.7663s
Epoch: 12 cost time: 44.62568497657776
Epoch: 12, Steps: 233 Train Loss: 3.6334 (Forecasting Loss:0.3534 + XiCon Loss:3.2801 x Lambda(1.0)), Vali MSE Loss: 0.3712 Test MSE Loss: 0.3693
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.6825135
	speed: 0.1955s/iter; left time: 3988.8591s
	iters: 200, epoch: 13 | loss: 3.5961268
	speed: 0.1901s/iter; left time: 3860.6879s
Epoch: 13 cost time: 44.84863090515137
Epoch: 13, Steps: 233 Train Loss: 3.6270 (Forecasting Loss:0.3538 + XiCon Loss:3.2732 x Lambda(1.0)), Vali MSE Loss: 0.3712 Test MSE Loss: 0.3693
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.6056616
	speed: 0.1930s/iter; left time: 3894.0995s
	iters: 200, epoch: 14 | loss: 3.6453404
	speed: 0.1945s/iter; left time: 3903.6427s
Epoch: 14 cost time: 45.08298087120056
Epoch: 14, Steps: 233 Train Loss: 3.6223 (Forecasting Loss:0.3538 + XiCon Loss:3.2685 x Lambda(1.0)), Vali MSE Loss: 0.3715 Test MSE Loss: 0.3693
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.5947878
	speed: 0.1943s/iter; left time: 3873.5258s
	iters: 200, epoch: 15 | loss: 3.6184611
	speed: 0.1910s/iter; left time: 3789.9768s
Epoch: 15 cost time: 44.843663930892944
Epoch: 15, Steps: 233 Train Loss: 3.6301 (Forecasting Loss:0.3528 + XiCon Loss:3.2773 x Lambda(1.0)), Vali MSE Loss: 0.3714 Test MSE Loss: 0.3693
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.6384943
	speed: 0.1926s/iter; left time: 3794.7975s
	iters: 200, epoch: 16 | loss: 3.6006138
	speed: 0.1884s/iter; left time: 3693.3516s
Epoch: 16 cost time: 44.34630489349365
Epoch: 16, Steps: 233 Train Loss: 3.6245 (Forecasting Loss:0.3535 + XiCon Loss:3.2710 x Lambda(1.0)), Vali MSE Loss: 0.3712 Test MSE Loss: 0.3693
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.30127647519111633, mae:0.435149222612381, mape:0.7126915454864502, mspe:20.408714294433594 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2579+-0.04113, MAE:0.4051+-0.03278, MAPE:0.6595+-0.04889, MSPE:16.3387+-4.79631, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
