Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.8672
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.0054474
	speed: 0.0324s/iter; left time: 412.0100s
Epoch: 1 cost time: 3.7757396697998047
Epoch: 1, Steps: 128 Train Loss: 31.2044 (Forecasting Loss:0.2444 + XiCon Loss:3.0960 x Lambda(10.0)), Vali MSE Loss: 0.1737 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173660).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.4454441
	speed: 0.0268s/iter; left time: 336.9120s
Epoch: 2 cost time: 3.215240955352783
Epoch: 2, Steps: 128 Train Loss: 29.4209 (Forecasting Loss:0.2470 + XiCon Loss:2.9174 x Lambda(10.0)), Vali MSE Loss: 0.1760 Test MSE Loss: 0.1332
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 29.2347584
	speed: 0.0248s/iter; left time: 308.4472s
Epoch: 3 cost time: 2.922553062438965
Epoch: 3, Steps: 128 Train Loss: 29.3885 (Forecasting Loss:0.2317 + XiCon Loss:2.9157 x Lambda(10.0)), Vali MSE Loss: 0.1685 Test MSE Loss: 0.1234
Validation loss decreased (0.173660 --> 0.168490).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 28.4012241
	speed: 0.0274s/iter; left time: 337.0556s
Epoch: 4 cost time: 3.36558198928833
Epoch: 4, Steps: 128 Train Loss: 28.8422 (Forecasting Loss:0.2224 + XiCon Loss:2.8620 x Lambda(10.0)), Vali MSE Loss: 0.1679 Test MSE Loss: 0.1151
Validation loss decreased (0.168490 --> 0.167900).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.5819244
	speed: 0.0246s/iter; left time: 299.5152s
Epoch: 5 cost time: 3.0447723865509033
Epoch: 5, Steps: 128 Train Loss: 28.6561 (Forecasting Loss:0.2169 + XiCon Loss:2.8439 x Lambda(10.0)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1166
Validation loss decreased (0.167900 --> 0.165349).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.0121269
	speed: 0.0336s/iter; left time: 405.5523s
Epoch: 6 cost time: 4.043960809707642
Epoch: 6, Steps: 128 Train Loss: 28.5869 (Forecasting Loss:0.2148 + XiCon Loss:2.8372 x Lambda(10.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1148
Validation loss decreased (0.165349 --> 0.164379).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.3662205
	speed: 0.0261s/iter; left time: 311.7588s
Epoch: 7 cost time: 3.3441519737243652
Epoch: 7, Steps: 128 Train Loss: 28.4975 (Forecasting Loss:0.2137 + XiCon Loss:2.8284 x Lambda(10.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1161
Validation loss decreased (0.164379 --> 0.163044).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 28.4522781
	speed: 0.0275s/iter; left time: 324.1358s
Epoch: 8 cost time: 3.3634448051452637
Epoch: 8, Steps: 128 Train Loss: 28.5380 (Forecasting Loss:0.2133 + XiCon Loss:2.8325 x Lambda(10.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1152
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 29.0382042
	speed: 0.0273s/iter; left time: 318.8300s
Epoch: 9 cost time: 3.4043054580688477
Epoch: 9, Steps: 128 Train Loss: 28.4993 (Forecasting Loss:0.2127 + XiCon Loss:2.8287 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1150
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 28.4184799
	speed: 0.0281s/iter; left time: 324.1676s
Epoch: 10 cost time: 3.4507086277008057
Epoch: 10, Steps: 128 Train Loss: 28.4525 (Forecasting Loss:0.2126 + XiCon Loss:2.8240 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 28.2581577
	speed: 0.0277s/iter; left time: 315.8553s
Epoch: 11 cost time: 3.621708869934082
Epoch: 11, Steps: 128 Train Loss: 28.4389 (Forecasting Loss:0.2124 + XiCon Loss:2.8227 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1148
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 27.9273911
	speed: 0.0275s/iter; left time: 310.6101s
Epoch: 12 cost time: 3.3835701942443848
Epoch: 12, Steps: 128 Train Loss: 28.4217 (Forecasting Loss:0.2123 + XiCon Loss:2.8209 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1148
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 29.0167923
	speed: 0.0272s/iter; left time: 303.3683s
Epoch: 13 cost time: 3.4645345211029053
Epoch: 13, Steps: 128 Train Loss: 28.4559 (Forecasting Loss:0.2123 + XiCon Loss:2.8244 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1148
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.4047050
	speed: 0.0276s/iter; left time: 304.4132s
Epoch: 14 cost time: 3.3290152549743652
Epoch: 14, Steps: 128 Train Loss: 28.4644 (Forecasting Loss:0.2124 + XiCon Loss:2.8252 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1148
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.2166729
	speed: 0.0274s/iter; left time: 298.4660s
Epoch: 15 cost time: 3.427842855453491
Epoch: 15, Steps: 128 Train Loss: 28.5259 (Forecasting Loss:0.2124 + XiCon Loss:2.8313 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1148
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 27.8941593
	speed: 0.0323s/iter; left time: 348.7141s
Epoch: 16 cost time: 3.892408847808838
Epoch: 16, Steps: 128 Train Loss: 28.4809 (Forecasting Loss:0.2124 + XiCon Loss:2.8268 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1148
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 27.9224739
	speed: 0.0380s/iter; left time: 404.9567s
Epoch: 17 cost time: 4.862505674362183
Epoch: 17, Steps: 128 Train Loss: 28.4176 (Forecasting Loss:0.2126 + XiCon Loss:2.8205 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1148
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05444912612438202, mae:0.1777152419090271, mape:0.1407652050256729, mspe:0.03667754307389259 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7696
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6566734
	speed: 0.0290s/iter; left time: 367.9301s
Epoch: 1 cost time: 3.510770320892334
Epoch: 1, Steps: 128 Train Loss: 30.9834 (Forecasting Loss:0.2418 + XiCon Loss:3.0742 x Lambda(10.0)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1222
Validation loss decreased (inf --> 0.173806).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.2254677
	speed: 0.0260s/iter; left time: 327.0309s
Epoch: 2 cost time: 3.422119617462158
Epoch: 2, Steps: 128 Train Loss: 29.1772 (Forecasting Loss:0.2447 + XiCon Loss:2.8933 x Lambda(10.0)), Vali MSE Loss: 0.1794 Test MSE Loss: 0.1216
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 30.9323692
	speed: 0.0280s/iter; left time: 348.3837s
Epoch: 3 cost time: 3.453003168106079
Epoch: 3, Steps: 128 Train Loss: 29.6317 (Forecasting Loss:0.2313 + XiCon Loss:2.9400 x Lambda(10.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1210
Validation loss decreased (0.173806 --> 0.168813).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.4482956
	speed: 0.0279s/iter; left time: 344.1347s
Epoch: 4 cost time: 3.3516933917999268
Epoch: 4, Steps: 128 Train Loss: 29.5124 (Forecasting Loss:0.2226 + XiCon Loss:2.9290 x Lambda(10.0)), Vali MSE Loss: 0.1679 Test MSE Loss: 0.1190
Validation loss decreased (0.168813 --> 0.167940).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 28.9619484
	speed: 0.0310s/iter; left time: 378.1574s
Epoch: 5 cost time: 3.8229012489318848
Epoch: 5, Steps: 128 Train Loss: 29.1391 (Forecasting Loss:0.2174 + XiCon Loss:2.8922 x Lambda(10.0)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1169
Validation loss decreased (0.167940 --> 0.165638).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 29.1471729
	speed: 0.0276s/iter; left time: 332.9972s
Epoch: 6 cost time: 3.2838923931121826
Epoch: 6, Steps: 128 Train Loss: 29.1227 (Forecasting Loss:0.2149 + XiCon Loss:2.8908 x Lambda(10.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1167
Validation loss decreased (0.165638 --> 0.164627).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.1542702
	speed: 0.0271s/iter; left time: 323.3596s
Epoch: 7 cost time: 3.3933358192443848
Epoch: 7, Steps: 128 Train Loss: 29.0052 (Forecasting Loss:0.2134 + XiCon Loss:2.8792 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1141
Validation loss decreased (0.164627 --> 0.164102).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 29.6876526
	speed: 0.0279s/iter; left time: 329.8035s
Epoch: 8 cost time: 3.3861987590789795
Epoch: 8, Steps: 128 Train Loss: 29.0047 (Forecasting Loss:0.2127 + XiCon Loss:2.8792 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
Validation loss decreased (0.164102 --> 0.164059).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 29.0851002
	speed: 0.0253s/iter; left time: 295.0295s
Epoch: 9 cost time: 3.2387807369232178
Epoch: 9, Steps: 128 Train Loss: 29.0806 (Forecasting Loss:0.2122 + XiCon Loss:2.8868 x Lambda(10.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1143
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.4098225
	speed: 0.0326s/iter; left time: 376.8771s
Epoch: 10 cost time: 3.9402999877929688
Epoch: 10, Steps: 128 Train Loss: 29.0216 (Forecasting Loss:0.2119 + XiCon Loss:2.8810 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
Validation loss decreased (0.164059 --> 0.163852).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.4145508
	speed: 0.0318s/iter; left time: 363.1674s
Epoch: 11 cost time: 4.146771430969238
Epoch: 11, Steps: 128 Train Loss: 28.9841 (Forecasting Loss:0.2122 + XiCon Loss:2.8772 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 28.4267807
	speed: 0.0285s/iter; left time: 321.4125s
Epoch: 12 cost time: 3.523231029510498
Epoch: 12, Steps: 128 Train Loss: 29.0148 (Forecasting Loss:0.2119 + XiCon Loss:2.8803 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
Validation loss decreased (0.163852 --> 0.163736).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.9540710
	speed: 0.0275s/iter; left time: 306.7409s
Epoch: 13 cost time: 3.4127683639526367
Epoch: 13, Steps: 128 Train Loss: 28.9835 (Forecasting Loss:0.2119 + XiCon Loss:2.8772 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.2827988
	speed: 0.0298s/iter; left time: 328.7210s
Epoch: 14 cost time: 3.6936635971069336
Epoch: 14, Steps: 128 Train Loss: 28.9602 (Forecasting Loss:0.2119 + XiCon Loss:2.8748 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 28.9096375
	speed: 0.0283s/iter; left time: 308.8512s
Epoch: 15 cost time: 3.4266111850738525
Epoch: 15, Steps: 128 Train Loss: 29.0074 (Forecasting Loss:0.2117 + XiCon Loss:2.8796 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1145
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 29.4525452
	speed: 0.0269s/iter; left time: 289.5687s
Epoch: 16 cost time: 3.2619707584381104
Epoch: 16, Steps: 128 Train Loss: 29.0019 (Forecasting Loss:0.2121 + XiCon Loss:2.8790 x Lambda(10.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 29.0774136
	speed: 0.0349s/iter; left time: 371.6545s
Epoch: 17 cost time: 4.127063274383545
Epoch: 17, Steps: 128 Train Loss: 29.0740 (Forecasting Loss:0.2119 + XiCon Loss:2.8862 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
Validation loss decreased (0.163736 --> 0.163662).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 28.4899006
	speed: 0.0270s/iter; left time: 284.4134s
Epoch: 18 cost time: 3.4028964042663574
Epoch: 18, Steps: 128 Train Loss: 28.9455 (Forecasting Loss:0.2117 + XiCon Loss:2.8734 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 28.6467304
	speed: 0.0286s/iter; left time: 297.8411s
Epoch: 19 cost time: 3.4897587299346924
Epoch: 19, Steps: 128 Train Loss: 28.9822 (Forecasting Loss:0.2120 + XiCon Loss:2.8770 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 29.3562660
	speed: 0.0239s/iter; left time: 245.3059s
Epoch: 20 cost time: 3.1084015369415283
Epoch: 20, Steps: 128 Train Loss: 28.9054 (Forecasting Loss:0.2116 + XiCon Loss:2.8694 x Lambda(10.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1145
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 28.6269608
	speed: 0.0263s/iter; left time: 266.5627s
Epoch: 21 cost time: 3.142040729522705
Epoch: 21, Steps: 128 Train Loss: 29.0229 (Forecasting Loss:0.2118 + XiCon Loss:2.8811 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 29.4819469
	speed: 0.0268s/iter; left time: 268.8375s
Epoch: 22 cost time: 3.3286566734313965
Epoch: 22, Steps: 128 Train Loss: 29.0368 (Forecasting Loss:0.2119 + XiCon Loss:2.8825 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1145
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 28.4158154
	speed: 0.0336s/iter; left time: 332.0315s
Epoch: 23 cost time: 4.156440496444702
Epoch: 23, Steps: 128 Train Loss: 29.0040 (Forecasting Loss:0.2119 + XiCon Loss:2.8792 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 28.6923676
	speed: 0.0278s/iter; left time: 271.0069s
Epoch: 24 cost time: 3.6917381286621094
Epoch: 24, Steps: 128 Train Loss: 28.9248 (Forecasting Loss:0.2120 + XiCon Loss:2.8713 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1145
Validation loss decreased (0.163662 --> 0.163656).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 28.8351688
	speed: 0.0276s/iter; left time: 265.5227s
Epoch: 25 cost time: 3.3899660110473633
Epoch: 25, Steps: 128 Train Loss: 29.0045 (Forecasting Loss:0.2119 + XiCon Loss:2.8793 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 28.7637463
	speed: 0.0265s/iter; left time: 251.3919s
Epoch: 26 cost time: 3.3230462074279785
Epoch: 26, Steps: 128 Train Loss: 29.0129 (Forecasting Loss:0.2118 + XiCon Loss:2.8801 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.9431210
	speed: 0.0294s/iter; left time: 275.1888s
Epoch: 27 cost time: 3.626215696334839
Epoch: 27, Steps: 128 Train Loss: 28.9795 (Forecasting Loss:0.2119 + XiCon Loss:2.8768 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 29.4159222
	speed: 0.0283s/iter; left time: 261.8642s
Epoch: 28 cost time: 3.6232237815856934
Epoch: 28, Steps: 128 Train Loss: 28.9664 (Forecasting Loss:0.2118 + XiCon Loss:2.8755 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1145
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 28.5276508
	speed: 0.0291s/iter; left time: 265.3161s
Epoch: 29 cost time: 3.679461717605591
Epoch: 29, Steps: 128 Train Loss: 28.9834 (Forecasting Loss:0.2119 + XiCon Loss:2.8772 x Lambda(10.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1145
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 28.3450832
	speed: 0.0250s/iter; left time: 225.0177s
Epoch: 30 cost time: 3.1168243885040283
Epoch: 30, Steps: 128 Train Loss: 28.9207 (Forecasting Loss:0.2119 + XiCon Loss:2.8709 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 29.1241837
	speed: 0.0260s/iter; left time: 230.7973s
Epoch: 31 cost time: 3.305955410003662
Epoch: 31, Steps: 128 Train Loss: 28.9855 (Forecasting Loss:0.2119 + XiCon Loss:2.8774 x Lambda(10.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1145
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 28.4790096
	speed: 0.0248s/iter; left time: 216.8349s
Epoch: 32 cost time: 3.1791088581085205
Epoch: 32, Steps: 128 Train Loss: 29.0353 (Forecasting Loss:0.2118 + XiCon Loss:2.8824 x Lambda(10.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1145
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 29.2200298
	speed: 0.0248s/iter; left time: 213.7258s
Epoch: 33 cost time: 3.1958436965942383
Epoch: 33, Steps: 128 Train Loss: 29.0291 (Forecasting Loss:0.2118 + XiCon Loss:2.8817 x Lambda(10.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1145
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 28.2908974
	speed: 0.0304s/iter; left time: 257.4179s
Epoch: 34 cost time: 3.9265947341918945
Epoch: 34, Steps: 128 Train Loss: 28.9998 (Forecasting Loss:0.2119 + XiCon Loss:2.8788 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1145
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.053266823291778564, mae:0.17567402124404907, mape:0.14121076464653015, mspe:0.038675881922245026 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7416
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.4255161
	speed: 0.0253s/iter; left time: 321.6315s
Epoch: 1 cost time: 3.1033291816711426
Epoch: 1, Steps: 128 Train Loss: 30.7750 (Forecasting Loss:0.2449 + XiCon Loss:3.0530 x Lambda(10.0)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1219
Validation loss decreased (inf --> 0.173441).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 28.6697865
	speed: 0.0265s/iter; left time: 332.6660s
Epoch: 2 cost time: 3.4717819690704346
Epoch: 2, Steps: 128 Train Loss: 29.2596 (Forecasting Loss:0.2470 + XiCon Loss:2.9013 x Lambda(10.0)), Vali MSE Loss: 0.1772 Test MSE Loss: 0.1269
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 29.8541946
	speed: 0.0279s/iter; left time: 346.8840s
Epoch: 3 cost time: 3.5183167457580566
Epoch: 3, Steps: 128 Train Loss: 30.1629 (Forecasting Loss:0.2279 + XiCon Loss:2.9935 x Lambda(10.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1198
Validation loss decreased (0.173441 --> 0.168770).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.2627964
	speed: 0.0261s/iter; left time: 321.8002s
Epoch: 4 cost time: 3.2651748657226562
Epoch: 4, Steps: 128 Train Loss: 29.7282 (Forecasting Loss:0.2213 + XiCon Loss:2.9507 x Lambda(10.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1157
Validation loss decreased (0.168770 --> 0.166579).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 29.6653099
	speed: 0.0269s/iter; left time: 327.7289s
Epoch: 5 cost time: 3.293545961380005
Epoch: 5, Steps: 128 Train Loss: 29.3542 (Forecasting Loss:0.2171 + XiCon Loss:2.9137 x Lambda(10.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1152
Validation loss decreased (0.166579 --> 0.165229).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 28.6663761
	speed: 0.0355s/iter; left time: 428.2461s
Epoch: 6 cost time: 4.243438482284546
Epoch: 6, Steps: 128 Train Loss: 29.2558 (Forecasting Loss:0.2157 + XiCon Loss:2.9040 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1160
Validation loss decreased (0.165229 --> 0.163528).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 28.9534664
	speed: 0.0276s/iter; left time: 328.8768s
Epoch: 7 cost time: 3.3947768211364746
Epoch: 7, Steps: 128 Train Loss: 29.1775 (Forecasting Loss:0.2147 + XiCon Loss:2.8963 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1156
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 28.8793221
	speed: 0.0281s/iter; left time: 331.2910s
Epoch: 8 cost time: 3.4538092613220215
Epoch: 8, Steps: 128 Train Loss: 29.1499 (Forecasting Loss:0.2139 + XiCon Loss:2.8936 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 29.1985531
	speed: 0.0271s/iter; left time: 316.8464s
Epoch: 9 cost time: 3.311154842376709
Epoch: 9, Steps: 128 Train Loss: 29.2112 (Forecasting Loss:0.2137 + XiCon Loss:2.8998 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 29.7211475
	speed: 0.0303s/iter; left time: 349.5384s
Epoch: 10 cost time: 3.7489254474639893
Epoch: 10, Steps: 128 Train Loss: 29.1381 (Forecasting Loss:0.2135 + XiCon Loss:2.8925 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1160
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 30.4240208
	speed: 0.0293s/iter; left time: 334.3569s
Epoch: 11 cost time: 4.329258918762207
Epoch: 11, Steps: 128 Train Loss: 29.1704 (Forecasting Loss:0.2133 + XiCon Loss:2.8957 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1159
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 28.8455734
	speed: 0.0294s/iter; left time: 332.2735s
Epoch: 12 cost time: 3.63248610496521
Epoch: 12, Steps: 128 Train Loss: 29.1850 (Forecasting Loss:0.2131 + XiCon Loss:2.8972 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 28.6813049
	speed: 0.0304s/iter; left time: 339.4848s
Epoch: 13 cost time: 3.950824737548828
Epoch: 13, Steps: 128 Train Loss: 29.0935 (Forecasting Loss:0.2134 + XiCon Loss:2.8880 x Lambda(10.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1158
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 28.6143093
	speed: 0.0303s/iter; left time: 334.8867s
Epoch: 14 cost time: 3.817274808883667
Epoch: 14, Steps: 128 Train Loss: 29.0981 (Forecasting Loss:0.2134 + XiCon Loss:2.8885 x Lambda(10.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 29.0314007
	speed: 0.0279s/iter; left time: 304.7561s
Epoch: 15 cost time: 3.436127185821533
Epoch: 15, Steps: 128 Train Loss: 29.2009 (Forecasting Loss:0.2135 + XiCon Loss:2.8987 x Lambda(10.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1158
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 29.4818325
	speed: 0.0252s/iter; left time: 271.6205s
Epoch: 16 cost time: 3.221102714538574
Epoch: 16, Steps: 128 Train Loss: 29.1526 (Forecasting Loss:0.2134 + XiCon Loss:2.8939 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1158
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05431221053004265, mae:0.1776113659143448, mape:0.14151234924793243, mspe:0.03791066259145737 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.7533
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.7364750
	speed: 0.0310s/iter; left time: 394.2496s
Epoch: 1 cost time: 3.745258331298828
Epoch: 1, Steps: 128 Train Loss: 30.9845 (Forecasting Loss:0.2454 + XiCon Loss:3.0739 x Lambda(10.0)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1223
Validation loss decreased (inf --> 0.171976).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.3298531
	speed: 0.0283s/iter; left time: 356.1956s
Epoch: 2 cost time: 3.504750967025757
Epoch: 2, Steps: 128 Train Loss: 29.4273 (Forecasting Loss:0.2439 + XiCon Loss:2.9183 x Lambda(10.0)), Vali MSE Loss: 0.1739 Test MSE Loss: 0.1255
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.4790821
	speed: 0.0272s/iter; left time: 338.6188s
Epoch: 3 cost time: 3.323983669281006
Epoch: 3, Steps: 128 Train Loss: 28.7272 (Forecasting Loss:0.2309 + XiCon Loss:2.8496 x Lambda(10.0)), Vali MSE Loss: 0.1685 Test MSE Loss: 0.1187
Validation loss decreased (0.171976 --> 0.168458).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.6006031
	speed: 0.0231s/iter; left time: 284.3124s
Epoch: 4 cost time: 2.8688387870788574
Epoch: 4, Steps: 128 Train Loss: 29.1215 (Forecasting Loss:0.2220 + XiCon Loss:2.8900 x Lambda(10.0)), Vali MSE Loss: 0.1665 Test MSE Loss: 0.1186
Validation loss decreased (0.168458 --> 0.166455).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 30.5196552
	speed: 0.0259s/iter; left time: 315.9983s
Epoch: 5 cost time: 3.303915500640869
Epoch: 5, Steps: 128 Train Loss: 29.9367 (Forecasting Loss:0.2175 + XiCon Loss:2.9719 x Lambda(10.0)), Vali MSE Loss: 0.1653 Test MSE Loss: 0.1224
Validation loss decreased (0.166455 --> 0.165330).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 30.5060310
	speed: 0.0280s/iter; left time: 337.4181s
Epoch: 6 cost time: 3.418910503387451
Epoch: 6, Steps: 128 Train Loss: 30.6438 (Forecasting Loss:0.2152 + XiCon Loss:3.0429 x Lambda(10.0)), Vali MSE Loss: 0.1659 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.7698936
	speed: 0.0288s/iter; left time: 344.1438s
Epoch: 7 cost time: 3.5008466243743896
Epoch: 7, Steps: 128 Train Loss: 30.7409 (Forecasting Loss:0.2139 + XiCon Loss:3.0527 x Lambda(10.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1155
Validation loss decreased (0.165330 --> 0.163056).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 30.9133224
	speed: 0.0281s/iter; left time: 332.2668s
Epoch: 8 cost time: 3.749600648880005
Epoch: 8, Steps: 128 Train Loss: 30.7141 (Forecasting Loss:0.2131 + XiCon Loss:3.0501 x Lambda(10.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1156
Validation loss decreased (0.163056 --> 0.162832).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 30.3864212
	speed: 0.0266s/iter; left time: 311.1093s
Epoch: 9 cost time: 3.525057077407837
Epoch: 9, Steps: 128 Train Loss: 30.6138 (Forecasting Loss:0.2125 + XiCon Loss:3.0401 x Lambda(10.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1153
Validation loss decreased (0.162832 --> 0.162291).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 32.1729622
	speed: 0.0270s/iter; left time: 312.2016s
Epoch: 10 cost time: 3.332043170928955
Epoch: 10, Steps: 128 Train Loss: 30.6834 (Forecasting Loss:0.2122 + XiCon Loss:3.0471 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1156
Validation loss decreased (0.162291 --> 0.162113).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 30.2126389
	speed: 0.0270s/iter; left time: 308.0609s
Epoch: 11 cost time: 3.322896718978882
Epoch: 11, Steps: 128 Train Loss: 30.6577 (Forecasting Loss:0.2120 + XiCon Loss:3.0446 x Lambda(10.0)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1157
Validation loss decreased (0.162113 --> 0.161799).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 30.6712723
	speed: 0.0314s/iter; left time: 354.2519s
Epoch: 12 cost time: 4.243222236633301
Epoch: 12, Steps: 128 Train Loss: 30.7135 (Forecasting Loss:0.2121 + XiCon Loss:3.0501 x Lambda(10.0)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1157
Validation loss decreased (0.161799 --> 0.161763).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 31.0748158
	speed: 0.0337s/iter; left time: 376.4160s
Epoch: 13 cost time: 3.94195818901062
Epoch: 13, Steps: 128 Train Loss: 30.6684 (Forecasting Loss:0.2121 + XiCon Loss:3.0456 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 30.1980724
	speed: 0.0275s/iter; left time: 303.2394s
Epoch: 14 cost time: 3.5287742614746094
Epoch: 14, Steps: 128 Train Loss: 30.6461 (Forecasting Loss:0.2117 + XiCon Loss:3.0434 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 30.2569294
	speed: 0.0312s/iter; left time: 340.4578s
Epoch: 15 cost time: 3.9310405254364014
Epoch: 15, Steps: 128 Train Loss: 30.6623 (Forecasting Loss:0.2118 + XiCon Loss:3.0451 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 30.0294476
	speed: 0.0298s/iter; left time: 321.3948s
Epoch: 16 cost time: 3.664804220199585
Epoch: 16, Steps: 128 Train Loss: 30.6574 (Forecasting Loss:0.2120 + XiCon Loss:3.0445 x Lambda(10.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 30.1055946
	speed: 0.0272s/iter; left time: 289.2474s
Epoch: 17 cost time: 3.335343599319458
Epoch: 17, Steps: 128 Train Loss: 30.6614 (Forecasting Loss:0.2121 + XiCon Loss:3.0449 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 31.3526325
	speed: 0.0318s/iter; left time: 334.4344s
Epoch: 18 cost time: 4.065006256103516
Epoch: 18, Steps: 128 Train Loss: 30.6779 (Forecasting Loss:0.2120 + XiCon Loss:3.0466 x Lambda(10.0)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 29.7623882
	speed: 0.0315s/iter; left time: 327.0890s
Epoch: 19 cost time: 3.9090733528137207
Epoch: 19, Steps: 128 Train Loss: 30.6274 (Forecasting Loss:0.2118 + XiCon Loss:3.0416 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 31.2106285
	speed: 0.0249s/iter; left time: 255.3407s
Epoch: 20 cost time: 3.204991579055786
Epoch: 20, Steps: 128 Train Loss: 30.6226 (Forecasting Loss:0.2119 + XiCon Loss:3.0411 x Lambda(10.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1157
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 30.5998688
	speed: 0.0305s/iter; left time: 309.7805s
Epoch: 21 cost time: 3.7423624992370605
Epoch: 21, Steps: 128 Train Loss: 30.6063 (Forecasting Loss:0.2119 + XiCon Loss:3.0394 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 31.1333580
	speed: 0.0308s/iter; left time: 308.3828s
Epoch: 22 cost time: 3.9250309467315674
Epoch: 22, Steps: 128 Train Loss: 30.6047 (Forecasting Loss:0.2121 + XiCon Loss:3.0393 x Lambda(10.0)), Vali MSE Loss: 0.1617 Test MSE Loss: 0.1157
Validation loss decreased (0.161763 --> 0.161747).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 30.3885250
	speed: 0.0304s/iter; left time: 300.1646s
Epoch: 23 cost time: 4.031681299209595
Epoch: 23, Steps: 128 Train Loss: 30.5694 (Forecasting Loss:0.2120 + XiCon Loss:3.0357 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 30.3765812
	speed: 0.0258s/iter; left time: 252.1018s
Epoch: 24 cost time: 3.2687742710113525
Epoch: 24, Steps: 128 Train Loss: 30.6779 (Forecasting Loss:0.2119 + XiCon Loss:3.0466 x Lambda(10.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 30.7659264
	speed: 0.0246s/iter; left time: 237.0183s
Epoch: 25 cost time: 3.214027166366577
Epoch: 25, Steps: 128 Train Loss: 30.6482 (Forecasting Loss:0.2120 + XiCon Loss:3.0436 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 30.7393360
	speed: 0.0278s/iter; left time: 263.7928s
Epoch: 26 cost time: 3.4674105644226074
Epoch: 26, Steps: 128 Train Loss: 30.6244 (Forecasting Loss:0.2119 + XiCon Loss:3.0412 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 31.4500084
	speed: 0.0250s/iter; left time: 233.9947s
Epoch: 27 cost time: 3.291170835494995
Epoch: 27, Steps: 128 Train Loss: 30.6369 (Forecasting Loss:0.2121 + XiCon Loss:3.0425 x Lambda(10.0)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 30.5756302
	speed: 0.0259s/iter; left time: 239.3458s
Epoch: 28 cost time: 3.2873916625976562
Epoch: 28, Steps: 128 Train Loss: 30.6546 (Forecasting Loss:0.2121 + XiCon Loss:3.0442 x Lambda(10.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 30.1157913
	speed: 0.0314s/iter; left time: 286.0189s
Epoch: 29 cost time: 3.8675897121429443
Epoch: 29, Steps: 128 Train Loss: 30.6345 (Forecasting Loss:0.2119 + XiCon Loss:3.0423 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 30.6455650
	speed: 0.0284s/iter; left time: 255.2505s
Epoch: 30 cost time: 3.4307363033294678
Epoch: 30, Steps: 128 Train Loss: 30.6102 (Forecasting Loss:0.2118 + XiCon Loss:3.0398 x Lambda(10.0)), Vali MSE Loss: 0.1616 Test MSE Loss: 0.1157
Validation loss decreased (0.161747 --> 0.161576).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 30.3103142
	speed: 0.0278s/iter; left time: 246.4201s
Epoch: 31 cost time: 3.4781696796417236
Epoch: 31, Steps: 128 Train Loss: 30.5716 (Forecasting Loss:0.2118 + XiCon Loss:3.0360 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 30.6569023
	speed: 0.0299s/iter; left time: 261.5324s
Epoch: 32 cost time: 3.624131679534912
Epoch: 32, Steps: 128 Train Loss: 30.6003 (Forecasting Loss:0.2120 + XiCon Loss:3.0388 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 30.0563583
	speed: 0.0266s/iter; left time: 228.7874s
Epoch: 33 cost time: 3.2118637561798096
Epoch: 33, Steps: 128 Train Loss: 30.6090 (Forecasting Loss:0.2119 + XiCon Loss:3.0397 x Lambda(10.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 30.9065266
	speed: 0.0258s/iter; left time: 219.0382s
Epoch: 34 cost time: 3.3863911628723145
Epoch: 34, Steps: 128 Train Loss: 30.6550 (Forecasting Loss:0.2120 + XiCon Loss:3.0443 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 30.9188709
	speed: 0.0320s/iter; left time: 267.3932s
Epoch: 35 cost time: 3.8896737098693848
Epoch: 35, Steps: 128 Train Loss: 30.6090 (Forecasting Loss:0.2116 + XiCon Loss:3.0397 x Lambda(10.0)), Vali MSE Loss: 0.1619 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 30.5676632
	speed: 0.0255s/iter; left time: 209.2871s
Epoch: 36 cost time: 3.2304232120513916
Epoch: 36, Steps: 128 Train Loss: 30.6319 (Forecasting Loss:0.2120 + XiCon Loss:3.0420 x Lambda(10.0)), Vali MSE Loss: 0.1623 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 30.3239536
	speed: 0.0290s/iter; left time: 235.0845s
Epoch: 37 cost time: 3.7353971004486084
Epoch: 37, Steps: 128 Train Loss: 30.6521 (Forecasting Loss:0.2120 + XiCon Loss:3.0440 x Lambda(10.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 30.9603424
	speed: 0.0302s/iter; left time: 240.3546s
Epoch: 38 cost time: 3.663522958755493
Epoch: 38, Steps: 128 Train Loss: 30.6651 (Forecasting Loss:0.2120 + XiCon Loss:3.0453 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 39 | loss: 31.3445797
	speed: 0.0273s/iter; left time: 213.6123s
Epoch: 39 cost time: 3.4943063259124756
Epoch: 39, Steps: 128 Train Loss: 30.7311 (Forecasting Loss:0.2118 + XiCon Loss:3.0519 x Lambda(10.0)), Vali MSE Loss: 0.1621 Test MSE Loss: 0.1157
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 40 | loss: 31.5789680
	speed: 0.0308s/iter; left time: 237.2290s
Epoch: 40 cost time: 3.9943974018096924
Epoch: 40, Steps: 128 Train Loss: 30.7124 (Forecasting Loss:0.2118 + XiCon Loss:3.0501 x Lambda(10.0)), Vali MSE Loss: 0.1620 Test MSE Loss: 0.1157
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05398928374052048, mae:0.17734508216381073, mape:0.14198537170886993, mspe:0.038574375212192535 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.6474
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.9196815
	speed: 0.0282s/iter; left time: 357.6203s
Epoch: 1 cost time: 3.422334671020508
Epoch: 1, Steps: 128 Train Loss: 31.1137 (Forecasting Loss:0.2453 + XiCon Loss:3.0868 x Lambda(10.0)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1239
Validation loss decreased (inf --> 0.175386).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 29.3797016
	speed: 0.0303s/iter; left time: 380.9369s
Epoch: 2 cost time: 3.7757701873779297
Epoch: 2, Steps: 128 Train Loss: 29.5128 (Forecasting Loss:0.2508 + XiCon Loss:2.9262 x Lambda(10.0)), Vali MSE Loss: 0.1756 Test MSE Loss: 0.1240
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 28.8766537
	speed: 0.0270s/iter; left time: 335.6465s
Epoch: 3 cost time: 3.3605892658233643
Epoch: 3, Steps: 128 Train Loss: 29.1206 (Forecasting Loss:0.2294 + XiCon Loss:2.8891 x Lambda(10.0)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1206
Validation loss decreased (0.175386 --> 0.168043).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 29.7310753
	speed: 0.0283s/iter; left time: 348.6651s
Epoch: 4 cost time: 3.4280340671539307
Epoch: 4, Steps: 128 Train Loss: 30.5520 (Forecasting Loss:0.2207 + XiCon Loss:3.0331 x Lambda(10.0)), Vali MSE Loss: 0.1675 Test MSE Loss: 0.1170
Validation loss decreased (0.168043 --> 0.167526).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 29.6207771
	speed: 0.0343s/iter; left time: 418.1260s
Epoch: 5 cost time: 4.2396769523620605
Epoch: 5, Steps: 128 Train Loss: 30.0654 (Forecasting Loss:0.2168 + XiCon Loss:2.9849 x Lambda(10.0)), Vali MSE Loss: 0.1654 Test MSE Loss: 0.1187
Validation loss decreased (0.167526 --> 0.165361).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 31.0167007
	speed: 0.0265s/iter; left time: 319.3762s
Epoch: 6 cost time: 3.202291965484619
Epoch: 6, Steps: 128 Train Loss: 29.8902 (Forecasting Loss:0.2134 + XiCon Loss:2.9677 x Lambda(10.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1153
Validation loss decreased (0.165361 --> 0.163069).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 29.8576851
	speed: 0.0352s/iter; left time: 419.7544s
Epoch: 7 cost time: 4.156246185302734
Epoch: 7, Steps: 128 Train Loss: 29.6981 (Forecasting Loss:0.2119 + XiCon Loss:2.9486 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 30.0535526
	speed: 0.0263s/iter; left time: 310.1863s
Epoch: 8 cost time: 3.1545917987823486
Epoch: 8, Steps: 128 Train Loss: 29.6487 (Forecasting Loss:0.2114 + XiCon Loss:2.9437 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1158
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 29.5327816
	speed: 0.0283s/iter; left time: 330.2041s
Epoch: 9 cost time: 3.6158268451690674
Epoch: 9, Steps: 128 Train Loss: 29.5946 (Forecasting Loss:0.2112 + XiCon Loss:2.9383 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 28.8250904
	speed: 0.0263s/iter; left time: 303.3072s
Epoch: 10 cost time: 3.560169219970703
Epoch: 10, Steps: 128 Train Loss: 29.5933 (Forecasting Loss:0.2109 + XiCon Loss:2.9382 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 29.0305443
	speed: 0.0279s/iter; left time: 318.7243s
Epoch: 11 cost time: 3.4837489128112793
Epoch: 11, Steps: 128 Train Loss: 29.5888 (Forecasting Loss:0.2102 + XiCon Loss:2.9379 x Lambda(10.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 30.4959126
	speed: 0.0299s/iter; left time: 337.8069s
Epoch: 12 cost time: 3.5095889568328857
Epoch: 12, Steps: 128 Train Loss: 29.5873 (Forecasting Loss:0.2102 + XiCon Loss:2.9377 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1156
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 30.8349857
	speed: 0.0274s/iter; left time: 305.6327s
Epoch: 13 cost time: 3.3918678760528564
Epoch: 13, Steps: 128 Train Loss: 29.6385 (Forecasting Loss:0.2104 + XiCon Loss:2.9428 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 30.1182480
	speed: 0.0280s/iter; left time: 309.1530s
Epoch: 14 cost time: 3.612779140472412
Epoch: 14, Steps: 128 Train Loss: 29.6142 (Forecasting Loss:0.2103 + XiCon Loss:2.9404 x Lambda(10.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1156
Validation loss decreased (0.163069 --> 0.163016).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 29.3411617
	speed: 0.0302s/iter; left time: 329.5964s
Epoch: 15 cost time: 3.7438201904296875
Epoch: 15, Steps: 128 Train Loss: 29.5635 (Forecasting Loss:0.2105 + XiCon Loss:2.9353 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 29.8032227
	speed: 0.0317s/iter; left time: 341.4864s
Epoch: 16 cost time: 3.827877998352051
Epoch: 16, Steps: 128 Train Loss: 29.5320 (Forecasting Loss:0.2102 + XiCon Loss:2.9322 x Lambda(10.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1156
Validation loss decreased (0.163016 --> 0.162945).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 29.1758118
	speed: 0.0257s/iter; left time: 273.5245s
Epoch: 17 cost time: 3.3359994888305664
Epoch: 17, Steps: 128 Train Loss: 29.5400 (Forecasting Loss:0.2105 + XiCon Loss:2.9330 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1156
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 29.5854511
	speed: 0.0276s/iter; left time: 290.6185s
Epoch: 18 cost time: 3.4041147232055664
Epoch: 18, Steps: 128 Train Loss: 29.5613 (Forecasting Loss:0.2102 + XiCon Loss:2.9351 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1156
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 29.1633110
	speed: 0.0255s/iter; left time: 265.1092s
Epoch: 19 cost time: 3.1740314960479736
Epoch: 19, Steps: 128 Train Loss: 29.5748 (Forecasting Loss:0.2104 + XiCon Loss:2.9364 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1156
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 28.8070755
	speed: 0.0281s/iter; left time: 288.8932s
Epoch: 20 cost time: 3.469135284423828
Epoch: 20, Steps: 128 Train Loss: 29.6390 (Forecasting Loss:0.2104 + XiCon Loss:2.9429 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1156
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 29.6711349
	speed: 0.0255s/iter; left time: 258.9908s
Epoch: 21 cost time: 3.1302382946014404
Epoch: 21, Steps: 128 Train Loss: 29.6101 (Forecasting Loss:0.2104 + XiCon Loss:2.9400 x Lambda(10.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1156
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 29.8434830
	speed: 0.0356s/iter; left time: 356.4506s
Epoch: 22 cost time: 4.579242467880249
Epoch: 22, Steps: 128 Train Loss: 29.5868 (Forecasting Loss:0.2104 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1156
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 29.6808605
	speed: 0.0258s/iter; left time: 254.6152s
Epoch: 23 cost time: 3.14715838432312
Epoch: 23, Steps: 128 Train Loss: 29.5914 (Forecasting Loss:0.2104 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1156
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 30.0895767
	speed: 0.0270s/iter; left time: 263.4816s
Epoch: 24 cost time: 3.4302170276641846
Epoch: 24, Steps: 128 Train Loss: 29.6177 (Forecasting Loss:0.2101 + XiCon Loss:2.9408 x Lambda(10.0)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1156
Validation loss decreased (0.162945 --> 0.162812).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 28.7871437
	speed: 0.0330s/iter; left time: 318.2092s
Epoch: 25 cost time: 4.032848834991455
Epoch: 25, Steps: 128 Train Loss: 29.5309 (Forecasting Loss:0.2105 + XiCon Loss:2.9320 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1156
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 29.8272057
	speed: 0.0309s/iter; left time: 293.6468s
Epoch: 26 cost time: 3.927180767059326
Epoch: 26, Steps: 128 Train Loss: 29.6106 (Forecasting Loss:0.2105 + XiCon Loss:2.9400 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 28.8780441
	speed: 0.0286s/iter; left time: 268.5315s
Epoch: 27 cost time: 3.6174676418304443
Epoch: 27, Steps: 128 Train Loss: 29.5757 (Forecasting Loss:0.2100 + XiCon Loss:2.9366 x Lambda(10.0)), Vali MSE Loss: 0.1629 Test MSE Loss: 0.1156
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 29.1773205
	speed: 0.0253s/iter; left time: 234.2285s
Epoch: 28 cost time: 3.223020315170288
Epoch: 28, Steps: 128 Train Loss: 29.5588 (Forecasting Loss:0.2103 + XiCon Loss:2.9349 x Lambda(10.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1156
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 28.8850803
	speed: 0.0251s/iter; left time: 228.4133s
Epoch: 29 cost time: 3.207392692565918
Epoch: 29, Steps: 128 Train Loss: 29.5803 (Forecasting Loss:0.2102 + XiCon Loss:2.9370 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 29.9094849
	speed: 0.0263s/iter; left time: 236.2060s
Epoch: 30 cost time: 3.154696464538574
Epoch: 30, Steps: 128 Train Loss: 29.5907 (Forecasting Loss:0.2104 + XiCon Loss:2.9380 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 30.6225872
	speed: 0.0279s/iter; left time: 247.0835s
Epoch: 31 cost time: 3.5902833938598633
Epoch: 31, Steps: 128 Train Loss: 29.6554 (Forecasting Loss:0.2108 + XiCon Loss:2.9445 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 28.9643517
	speed: 0.0294s/iter; left time: 256.4970s
Epoch: 32 cost time: 3.665957450866699
Epoch: 32, Steps: 128 Train Loss: 29.5738 (Forecasting Loss:0.2104 + XiCon Loss:2.9363 x Lambda(10.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1156
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 30.5441666
	speed: 0.0315s/iter; left time: 271.3239s
Epoch: 33 cost time: 3.8986263275146484
Epoch: 33, Steps: 128 Train Loss: 29.5855 (Forecasting Loss:0.2099 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1156
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 28.8243752
	speed: 0.0276s/iter; left time: 234.0991s
Epoch: 34 cost time: 4.500910043716431
Epoch: 34, Steps: 128 Train Loss: 29.6166 (Forecasting Loss:0.2102 + XiCon Loss:2.9406 x Lambda(10.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1156
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.054238900542259216, mae:0.17697274684906006, mape:0.14107748866081238, mspe:0.03799393028020859 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0541+-0.00058, MAE:0.1771+-0.00103, MAPE:0.1413+-0.00057, MSPE:0.0380+-0.00099, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.2108
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3346024
	speed: 0.0405s/iter; left time: 474.1090s
Epoch: 1 cost time: 4.574130535125732
Epoch: 1, Steps: 118 Train Loss: 31.6516 (Forecasting Loss:0.3698 + XiCon Loss:3.1282 x Lambda(10.0)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.1790
Validation loss decreased (inf --> 0.273515).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6416206
	speed: 0.0322s/iter; left time: 372.4312s
Epoch: 2 cost time: 3.986116409301758
Epoch: 2, Steps: 118 Train Loss: 29.6816 (Forecasting Loss:0.3287 + XiCon Loss:2.9353 x Lambda(10.0)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1724
Validation loss decreased (0.273515 --> 0.240926).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4710732
	speed: 0.0530s/iter; left time: 607.9336s
Epoch: 3 cost time: 6.182382583618164
Epoch: 3, Steps: 118 Train Loss: 30.0615 (Forecasting Loss:0.2959 + XiCon Loss:2.9766 x Lambda(10.0)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1618
Validation loss decreased (0.240926 --> 0.239444).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.5971451
	speed: 0.0481s/iter; left time: 546.2176s
Epoch: 4 cost time: 5.641913414001465
Epoch: 4, Steps: 118 Train Loss: 29.5575 (Forecasting Loss:0.2843 + XiCon Loss:2.9273 x Lambda(10.0)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1476
Validation loss decreased (0.239444 --> 0.234643).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9689922
	speed: 0.0519s/iter; left time: 582.3097s
Epoch: 5 cost time: 5.964034795761108
Epoch: 5, Steps: 118 Train Loss: 29.2834 (Forecasting Loss:0.2720 + XiCon Loss:2.9011 x Lambda(10.0)), Vali MSE Loss: 0.2368 Test MSE Loss: 0.1459
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2230377
	speed: 0.0484s/iter; left time: 537.3866s
Epoch: 6 cost time: 5.635457754135132
Epoch: 6, Steps: 118 Train Loss: 29.1827 (Forecasting Loss:0.2675 + XiCon Loss:2.8915 x Lambda(10.0)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1442
Validation loss decreased (0.234643 --> 0.230683).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.7478790
	speed: 0.0458s/iter; left time: 502.9325s
Epoch: 7 cost time: 5.413583278656006
Epoch: 7, Steps: 118 Train Loss: 29.1277 (Forecasting Loss:0.2643 + XiCon Loss:2.8863 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.1420
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.9510784
	speed: 0.0480s/iter; left time: 521.8033s
Epoch: 8 cost time: 5.772700786590576
Epoch: 8, Steps: 118 Train Loss: 29.1261 (Forecasting Loss:0.2623 + XiCon Loss:2.8864 x Lambda(10.0)), Vali MSE Loss: 0.2346 Test MSE Loss: 0.1420
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.0110970
	speed: 0.0542s/iter; left time: 583.5579s
Epoch: 9 cost time: 6.392502069473267
Epoch: 9, Steps: 118 Train Loss: 29.1372 (Forecasting Loss:0.2625 + XiCon Loss:2.8875 x Lambda(10.0)), Vali MSE Loss: 0.2329 Test MSE Loss: 0.1435
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3595600
	speed: 0.0464s/iter; left time: 493.5559s
Epoch: 10 cost time: 5.436142444610596
Epoch: 10, Steps: 118 Train Loss: 29.1481 (Forecasting Loss:0.2624 + XiCon Loss:2.8886 x Lambda(10.0)), Vali MSE Loss: 0.2333 Test MSE Loss: 0.1431
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.6244793
	speed: 0.0486s/iter; left time: 511.1118s
Epoch: 11 cost time: 6.0687878131866455
Epoch: 11, Steps: 118 Train Loss: 29.1672 (Forecasting Loss:0.2625 + XiCon Loss:2.8905 x Lambda(10.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1428
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.4865532
	speed: 0.0792s/iter; left time: 823.4229s
Epoch: 12 cost time: 9.084059715270996
Epoch: 12, Steps: 118 Train Loss: 29.1905 (Forecasting Loss:0.2625 + XiCon Loss:2.8928 x Lambda(10.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1427
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.9532948
	speed: 0.0761s/iter; left time: 782.8929s
Epoch: 13 cost time: 8.999442100524902
Epoch: 13, Steps: 118 Train Loss: 29.1780 (Forecasting Loss:0.2622 + XiCon Loss:2.8916 x Lambda(10.0)), Vali MSE Loss: 0.2336 Test MSE Loss: 0.1428
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4197693
	speed: 0.0756s/iter; left time: 769.0442s
Epoch: 14 cost time: 9.108179330825806
Epoch: 14, Steps: 118 Train Loss: 29.1941 (Forecasting Loss:0.2621 + XiCon Loss:2.8932 x Lambda(10.0)), Vali MSE Loss: 0.2343 Test MSE Loss: 0.1428
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9135399
	speed: 0.0827s/iter; left time: 831.3358s
Epoch: 15 cost time: 9.767507314682007
Epoch: 15, Steps: 118 Train Loss: 29.1665 (Forecasting Loss:0.2625 + XiCon Loss:2.8904 x Lambda(10.0)), Vali MSE Loss: 0.2336 Test MSE Loss: 0.1427
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.5375977
	speed: 0.0812s/iter; left time: 805.9134s
Epoch: 16 cost time: 9.55563497543335
Epoch: 16, Steps: 118 Train Loss: 29.1355 (Forecasting Loss:0.2626 + XiCon Loss:2.8873 x Lambda(10.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.1427
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07390936464071274, mae:0.2144668698310852, mape:0.15784256160259247, mspe:0.0411163866519928 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.1769
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3715019
	speed: 0.0737s/iter; left time: 862.5750s
Epoch: 1 cost time: 8.713123798370361
Epoch: 1, Steps: 118 Train Loss: 31.6749 (Forecasting Loss:0.3526 + XiCon Loss:3.1322 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1626
Validation loss decreased (inf --> 0.252852).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8261948
	speed: 0.0730s/iter; left time: 845.8167s
Epoch: 2 cost time: 8.815949201583862
Epoch: 2, Steps: 118 Train Loss: 29.4812 (Forecasting Loss:0.3288 + XiCon Loss:2.9152 x Lambda(10.0)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.1626
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7411594
	speed: 0.0785s/iter; left time: 899.5898s
Epoch: 3 cost time: 9.11799931526184
Epoch: 3, Steps: 118 Train Loss: 30.0772 (Forecasting Loss:0.2981 + XiCon Loss:2.9779 x Lambda(10.0)), Vali MSE Loss: 0.2442 Test MSE Loss: 0.1592
Validation loss decreased (0.252852 --> 0.244206).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.6370964
	speed: 0.0789s/iter; left time: 895.6772s
Epoch: 4 cost time: 9.30357313156128
Epoch: 4, Steps: 118 Train Loss: 29.9163 (Forecasting Loss:0.2859 + XiCon Loss:2.9630 x Lambda(10.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1498
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2223988
	speed: 0.0742s/iter; left time: 833.3365s
Epoch: 5 cost time: 8.903493881225586
Epoch: 5, Steps: 118 Train Loss: 29.5821 (Forecasting Loss:0.2715 + XiCon Loss:2.9311 x Lambda(10.0)), Vali MSE Loss: 0.2398 Test MSE Loss: 0.1467
Validation loss decreased (0.244206 --> 0.239804).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.1974239
	speed: 0.0829s/iter; left time: 921.3683s
Epoch: 6 cost time: 9.83392858505249
Epoch: 6, Steps: 118 Train Loss: 29.4325 (Forecasting Loss:0.2693 + XiCon Loss:2.9163 x Lambda(10.0)), Vali MSE Loss: 0.2431 Test MSE Loss: 0.1447
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.9391003
	speed: 0.0799s/iter; left time: 878.4691s
Epoch: 7 cost time: 9.670147895812988
Epoch: 7, Steps: 118 Train Loss: 29.4193 (Forecasting Loss:0.2687 + XiCon Loss:2.9151 x Lambda(10.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1439
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3279438
	speed: 0.0827s/iter; left time: 899.2995s
Epoch: 8 cost time: 9.743849277496338
Epoch: 8, Steps: 118 Train Loss: 29.4080 (Forecasting Loss:0.2667 + XiCon Loss:2.9141 x Lambda(10.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1450
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.0581207
	speed: 0.0802s/iter; left time: 862.9053s
Epoch: 9 cost time: 9.538800954818726
Epoch: 9, Steps: 118 Train Loss: 29.3000 (Forecasting Loss:0.2671 + XiCon Loss:2.9033 x Lambda(10.0)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1444
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.8009033
	speed: 0.0764s/iter; left time: 812.9536s
Epoch: 10 cost time: 9.082998514175415
Epoch: 10, Steps: 118 Train Loss: 29.2476 (Forecasting Loss:0.2672 + XiCon Loss:2.8980 x Lambda(10.0)), Vali MSE Loss: 0.2428 Test MSE Loss: 0.1446
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.0567551
	speed: 0.0806s/iter; left time: 848.2130s
Epoch: 11 cost time: 9.430805921554565
Epoch: 11, Steps: 118 Train Loss: 29.3206 (Forecasting Loss:0.2658 + XiCon Loss:2.9055 x Lambda(10.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1443
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.5476360
	speed: 0.0813s/iter; left time: 845.2548s
Epoch: 12 cost time: 9.590085983276367
Epoch: 12, Steps: 118 Train Loss: 29.3662 (Forecasting Loss:0.2668 + XiCon Loss:2.9099 x Lambda(10.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1443
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6250839
	speed: 0.0830s/iter; left time: 853.8749s
Epoch: 13 cost time: 9.789645910263062
Epoch: 13, Steps: 118 Train Loss: 29.3802 (Forecasting Loss:0.2666 + XiCon Loss:2.9114 x Lambda(10.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1444
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.5764256
	speed: 0.0786s/iter; left time: 798.6849s
Epoch: 14 cost time: 9.333269119262695
Epoch: 14, Steps: 118 Train Loss: 29.3112 (Forecasting Loss:0.2671 + XiCon Loss:2.9044 x Lambda(10.0)), Vali MSE Loss: 0.2444 Test MSE Loss: 0.1443
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.3300171
	speed: 0.0769s/iter; left time: 773.0937s
Epoch: 15 cost time: 9.135958909988403
Epoch: 15, Steps: 118 Train Loss: 29.2782 (Forecasting Loss:0.2664 + XiCon Loss:2.9012 x Lambda(10.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1444
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07605793327093124, mae:0.21734857559204102, mape:0.15841339528560638, mspe:0.040569670498371124 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.4026
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.2745171
	speed: 0.0808s/iter; left time: 945.7798s
Epoch: 1 cost time: 9.382616996765137
Epoch: 1, Steps: 118 Train Loss: 31.6245 (Forecasting Loss:0.3542 + XiCon Loss:3.1270 x Lambda(10.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.1657
Validation loss decreased (inf --> 0.253107).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8696861
	speed: 0.0810s/iter; left time: 938.3144s
Epoch: 2 cost time: 9.686459302902222
Epoch: 2, Steps: 118 Train Loss: 29.6148 (Forecasting Loss:0.3439 + XiCon Loss:2.9271 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.1563
Validation loss decreased (0.253107 --> 0.250646).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4664669
	speed: 0.0753s/iter; left time: 863.0577s
Epoch: 3 cost time: 8.959433317184448
Epoch: 3, Steps: 118 Train Loss: 30.5053 (Forecasting Loss:0.3245 + XiCon Loss:3.0181 x Lambda(10.0)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.1531
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9455528
	speed: 0.0826s/iter; left time: 937.3083s
Epoch: 4 cost time: 9.889901638031006
Epoch: 4, Steps: 118 Train Loss: 30.2524 (Forecasting Loss:0.2958 + XiCon Loss:2.9957 x Lambda(10.0)), Vali MSE Loss: 0.2638 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.5098400
	speed: 0.0770s/iter; left time: 864.4874s
Epoch: 5 cost time: 8.856192111968994
Epoch: 5, Steps: 118 Train Loss: 29.9468 (Forecasting Loss:0.2784 + XiCon Loss:2.9668 x Lambda(10.0)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.1590
Validation loss decreased (0.250646 --> 0.247785).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.0220127
	speed: 0.0812s/iter; left time: 902.2012s
Epoch: 6 cost time: 9.34499979019165
Epoch: 6, Steps: 118 Train Loss: 29.7324 (Forecasting Loss:0.2765 + XiCon Loss:2.9456 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.1585
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.7357235
	speed: 0.0728s/iter; left time: 800.2813s
Epoch: 7 cost time: 8.768264293670654
Epoch: 7, Steps: 118 Train Loss: 29.6405 (Forecasting Loss:0.2746 + XiCon Loss:2.9366 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.1570
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3524418
	speed: 0.0823s/iter; left time: 894.5856s
Epoch: 8 cost time: 9.645155191421509
Epoch: 8, Steps: 118 Train Loss: 29.5760 (Forecasting Loss:0.2741 + XiCon Loss:2.9302 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1575
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.2627716
	speed: 0.0757s/iter; left time: 814.0335s
Epoch: 9 cost time: 9.067552089691162
Epoch: 9, Steps: 118 Train Loss: 29.5659 (Forecasting Loss:0.2739 + XiCon Loss:2.9292 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1573
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9252529
	speed: 0.0777s/iter; left time: 826.7819s
Epoch: 10 cost time: 9.096936702728271
Epoch: 10, Steps: 118 Train Loss: 29.6028 (Forecasting Loss:0.2738 + XiCon Loss:2.9329 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.1573
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5511189
	speed: 0.0802s/iter; left time: 843.3214s
Epoch: 11 cost time: 9.44894552230835
Epoch: 11, Steps: 118 Train Loss: 29.6262 (Forecasting Loss:0.2740 + XiCon Loss:2.9352 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1573
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.6062450
	speed: 0.0739s/iter; left time: 768.9504s
Epoch: 12 cost time: 8.881951570510864
Epoch: 12, Steps: 118 Train Loss: 29.4986 (Forecasting Loss:0.2744 + XiCon Loss:2.9224 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1573
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.7797832
	speed: 0.0831s/iter; left time: 854.8824s
Epoch: 13 cost time: 9.908296585083008
Epoch: 13, Steps: 118 Train Loss: 29.5474 (Forecasting Loss:0.2746 + XiCon Loss:2.9273 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.1573
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2075901
	speed: 0.0824s/iter; left time: 837.8840s
Epoch: 14 cost time: 9.800775051116943
Epoch: 14, Steps: 118 Train Loss: 29.5538 (Forecasting Loss:0.2742 + XiCon Loss:2.9280 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.1573
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.1321239
	speed: 0.0848s/iter; left time: 851.6804s
Epoch: 15 cost time: 9.930903196334839
Epoch: 15, Steps: 118 Train Loss: 29.5492 (Forecasting Loss:0.2742 + XiCon Loss:2.9275 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.1573
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.08576001226902008, mae:0.23223009705543518, mape:0.1688654124736786, mspe:0.045221686363220215 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.2715
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3682213
	speed: 0.0696s/iter; left time: 814.1806s
Epoch: 1 cost time: 8.281671285629272
Epoch: 1, Steps: 118 Train Loss: 31.5145 (Forecasting Loss:0.3591 + XiCon Loss:3.1155 x Lambda(10.0)), Vali MSE Loss: 0.2659 Test MSE Loss: 0.1732
Validation loss decreased (inf --> 0.265868).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6040802
	speed: 0.0775s/iter; left time: 897.4818s
Epoch: 2 cost time: 9.28371000289917
Epoch: 2, Steps: 118 Train Loss: 30.4233 (Forecasting Loss:0.3276 + XiCon Loss:3.0096 x Lambda(10.0)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.1636
Validation loss decreased (0.265868 --> 0.246442).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7212906
	speed: 0.0828s/iter; left time: 949.3803s
Epoch: 3 cost time: 9.623573541641235
Epoch: 3, Steps: 118 Train Loss: 30.0053 (Forecasting Loss:0.2963 + XiCon Loss:2.9709 x Lambda(10.0)), Vali MSE Loss: 0.2352 Test MSE Loss: 0.1488
Validation loss decreased (0.246442 --> 0.235199).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.0408268
	speed: 0.0822s/iter; left time: 932.8309s
Epoch: 4 cost time: 9.477123022079468
Epoch: 4, Steps: 118 Train Loss: 29.6046 (Forecasting Loss:0.2862 + XiCon Loss:2.9318 x Lambda(10.0)), Vali MSE Loss: 0.2301 Test MSE Loss: 0.1441
Validation loss decreased (0.235199 --> 0.230117).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.8410664
	speed: 0.0741s/iter; left time: 831.8895s
Epoch: 5 cost time: 8.821300268173218
Epoch: 5, Steps: 118 Train Loss: 29.3910 (Forecasting Loss:0.2803 + XiCon Loss:2.9111 x Lambda(10.0)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.1438
Validation loss decreased (0.230117 --> 0.225800).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.8352852
	speed: 0.0852s/iter; left time: 947.0291s
Epoch: 6 cost time: 9.838520526885986
Epoch: 6, Steps: 118 Train Loss: 29.3240 (Forecasting Loss:0.2780 + XiCon Loss:2.9046 x Lambda(10.0)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1437
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.6409721
	speed: 0.0811s/iter; left time: 892.0248s
Epoch: 7 cost time: 9.57809567451477
Epoch: 7, Steps: 118 Train Loss: 29.3194 (Forecasting Loss:0.2771 + XiCon Loss:2.9042 x Lambda(10.0)), Vali MSE Loss: 0.2268 Test MSE Loss: 0.1439
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.0995598
	speed: 0.0812s/iter; left time: 883.2296s
Epoch: 8 cost time: 9.388739347457886
Epoch: 8, Steps: 118 Train Loss: 29.2629 (Forecasting Loss:0.2758 + XiCon Loss:2.8987 x Lambda(10.0)), Vali MSE Loss: 0.2267 Test MSE Loss: 0.1437
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1387119
	speed: 0.0817s/iter; left time: 879.2078s
Epoch: 9 cost time: 9.688558578491211
Epoch: 9, Steps: 118 Train Loss: 29.2339 (Forecasting Loss:0.2740 + XiCon Loss:2.8960 x Lambda(10.0)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.1441
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.6591587
	speed: 0.0814s/iter; left time: 866.2599s
Epoch: 10 cost time: 9.662509679794312
Epoch: 10, Steps: 118 Train Loss: 29.2803 (Forecasting Loss:0.2748 + XiCon Loss:2.9005 x Lambda(10.0)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1442
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.8850842
	speed: 0.0798s/iter; left time: 839.6995s
Epoch: 11 cost time: 9.30801796913147
Epoch: 11, Steps: 118 Train Loss: 29.3433 (Forecasting Loss:0.2741 + XiCon Loss:2.9069 x Lambda(10.0)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1442
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.6904125
	speed: 0.0817s/iter; left time: 850.0741s
Epoch: 12 cost time: 9.49565577507019
Epoch: 12, Steps: 118 Train Loss: 29.2345 (Forecasting Loss:0.2739 + XiCon Loss:2.8961 x Lambda(10.0)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.1443
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6392555
	speed: 0.0793s/iter; left time: 815.8475s
Epoch: 13 cost time: 9.145509481430054
Epoch: 13, Steps: 118 Train Loss: 29.3201 (Forecasting Loss:0.2742 + XiCon Loss:2.9046 x Lambda(10.0)), Vali MSE Loss: 0.2265 Test MSE Loss: 0.1443
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.6306667
	speed: 0.0776s/iter; left time: 788.4892s
Epoch: 14 cost time: 9.111351490020752
Epoch: 14, Steps: 118 Train Loss: 29.2071 (Forecasting Loss:0.2744 + XiCon Loss:2.8933 x Lambda(10.0)), Vali MSE Loss: 0.2264 Test MSE Loss: 0.1443
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4043293
	speed: 0.0781s/iter; left time: 784.9785s
Epoch: 15 cost time: 9.18048357963562
Epoch: 15, Steps: 118 Train Loss: 29.2660 (Forecasting Loss:0.2740 + XiCon Loss:2.8992 x Lambda(10.0)), Vali MSE Loss: 0.2262 Test MSE Loss: 0.1443
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07299160212278366, mae:0.2145138531923294, mape:0.15825769305229187, mspe:0.04094979539513588 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:490657
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.1653
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.3849125
	speed: 0.0784s/iter; left time: 917.4453s
Epoch: 1 cost time: 9.013725519180298
Epoch: 1, Steps: 118 Train Loss: 31.4798 (Forecasting Loss:0.3740 + XiCon Loss:3.1106 x Lambda(10.0)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1752
Validation loss decreased (inf --> 0.269552).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6249657
	speed: 0.0822s/iter; left time: 952.5142s
Epoch: 2 cost time: 9.734091758728027
Epoch: 2, Steps: 118 Train Loss: 29.7477 (Forecasting Loss:0.3467 + XiCon Loss:2.9401 x Lambda(10.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1700
Validation loss decreased (0.269552 --> 0.258591).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.9359989
	speed: 0.0778s/iter; left time: 892.2324s
Epoch: 3 cost time: 9.12502384185791
Epoch: 3, Steps: 118 Train Loss: 29.2697 (Forecasting Loss:0.3257 + XiCon Loss:2.8944 x Lambda(10.0)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.1494
Validation loss decreased (0.258591 --> 0.230685).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7214432
	speed: 0.0918s/iter; left time: 1041.4689s
Epoch: 4 cost time: 10.601540565490723
Epoch: 4, Steps: 118 Train Loss: 29.9981 (Forecasting Loss:0.3033 + XiCon Loss:2.9695 x Lambda(10.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.1498
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.8875637
	speed: 0.0801s/iter; left time: 898.9091s
Epoch: 5 cost time: 9.646201372146606
Epoch: 5, Steps: 118 Train Loss: 29.2174 (Forecasting Loss:0.2853 + XiCon Loss:2.8932 x Lambda(10.0)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.1451
Validation loss decreased (0.230685 --> 0.228331).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.6488724
	speed: 0.0819s/iter; left time: 910.0937s
Epoch: 6 cost time: 9.653473854064941
Epoch: 6, Steps: 118 Train Loss: 28.9473 (Forecasting Loss:0.2810 + XiCon Loss:2.8666 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1428
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.3871880
	speed: 0.0815s/iter; left time: 895.7717s
Epoch: 7 cost time: 9.682365655899048
Epoch: 7, Steps: 118 Train Loss: 28.8893 (Forecasting Loss:0.2775 + XiCon Loss:2.8612 x Lambda(10.0)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1420
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.6187038
	speed: 0.0827s/iter; left time: 899.2087s
Epoch: 8 cost time: 9.887181043624878
Epoch: 8, Steps: 118 Train Loss: 28.8314 (Forecasting Loss:0.2744 + XiCon Loss:2.8557 x Lambda(10.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1416
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.4719353
	speed: 0.0798s/iter; left time: 857.8770s
Epoch: 9 cost time: 9.551350831985474
Epoch: 9, Steps: 118 Train Loss: 28.8160 (Forecasting Loss:0.2741 + XiCon Loss:2.8542 x Lambda(10.0)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.1417
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.2993889
	speed: 0.0784s/iter; left time: 833.8994s
Epoch: 10 cost time: 9.169032335281372
Epoch: 10, Steps: 118 Train Loss: 28.8135 (Forecasting Loss:0.2740 + XiCon Loss:2.8539 x Lambda(10.0)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.1417
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.1916885
	speed: 0.0792s/iter; left time: 833.3168s
Epoch: 11 cost time: 9.213097333908081
Epoch: 11, Steps: 118 Train Loss: 28.8451 (Forecasting Loss:0.2732 + XiCon Loss:2.8572 x Lambda(10.0)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1417
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.1940269
	speed: 0.0894s/iter; left time: 929.7214s
Epoch: 12 cost time: 10.62300419807434
Epoch: 12, Steps: 118 Train Loss: 28.8138 (Forecasting Loss:0.2733 + XiCon Loss:2.8540 x Lambda(10.0)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1416
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.0405655
	speed: 0.0790s/iter; left time: 812.7012s
Epoch: 13 cost time: 9.344040393829346
Epoch: 13, Steps: 118 Train Loss: 28.7610 (Forecasting Loss:0.2734 + XiCon Loss:2.8488 x Lambda(10.0)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1416
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.6365471
	speed: 0.0821s/iter; left time: 835.1857s
Epoch: 14 cost time: 9.541228294372559
Epoch: 14, Steps: 118 Train Loss: 28.8009 (Forecasting Loss:0.2734 + XiCon Loss:2.8527 x Lambda(10.0)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1416
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.9579029
	speed: 0.0796s/iter; left time: 799.9966s
Epoch: 15 cost time: 9.525291681289673
Epoch: 15, Steps: 118 Train Loss: 28.7894 (Forecasting Loss:0.2731 + XiCon Loss:2.8516 x Lambda(10.0)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.1416
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07361012697219849, mae:0.21651849150657654, mape:0.16031041741371155, mspe:0.04163075610995293 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0765+-0.00661, MAE:0.2190+-0.00930, MAPE:0.1607+-0.00576, MSPE:0.0419+-0.00236, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.3113
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.8966331
	speed: 0.1066s/iter; left time: 1129.6236s
Epoch: 1 cost time: 11.429101705551147
Epoch: 1, Steps: 107 Train Loss: 31.8829 (Forecasting Loss:0.5476 + XiCon Loss:3.1335 x Lambda(10.0)), Vali MSE Loss: 0.3864 Test MSE Loss: 0.2285
Validation loss decreased (inf --> 0.386447).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9735126
	speed: 0.1061s/iter; left time: 1113.3982s
Epoch: 2 cost time: 11.545160293579102
Epoch: 2, Steps: 107 Train Loss: 30.2398 (Forecasting Loss:0.4645 + XiCon Loss:2.9775 x Lambda(10.0)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.1552
Validation loss decreased (0.386447 --> 0.282842).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.3711319
	speed: 0.1213s/iter; left time: 1259.6738s
Epoch: 3 cost time: 12.957976818084717
Epoch: 3, Steps: 107 Train Loss: 29.9615 (Forecasting Loss:0.3581 + XiCon Loss:2.9603 x Lambda(10.0)), Vali MSE Loss: 0.2693 Test MSE Loss: 0.1549
Validation loss decreased (0.282842 --> 0.269279).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.4846973
	speed: 0.1132s/iter; left time: 1163.3700s
Epoch: 4 cost time: 12.178364038467407
Epoch: 4, Steps: 107 Train Loss: 29.6009 (Forecasting Loss:0.3260 + XiCon Loss:2.9275 x Lambda(10.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.1463
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4379921
	speed: 0.1138s/iter; left time: 1157.4423s
Epoch: 5 cost time: 12.194340467453003
Epoch: 5, Steps: 107 Train Loss: 29.4834 (Forecasting Loss:0.3133 + XiCon Loss:2.9170 x Lambda(10.0)), Vali MSE Loss: 0.2758 Test MSE Loss: 0.1503
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2612648
	speed: 0.1145s/iter; left time: 1152.8473s
Epoch: 6 cost time: 12.331088304519653
Epoch: 6, Steps: 107 Train Loss: 29.4175 (Forecasting Loss:0.3070 + XiCon Loss:2.9110 x Lambda(10.0)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.1526
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.4337215
	speed: 0.1154s/iter; left time: 1148.9363s
Epoch: 7 cost time: 12.534928798675537
Epoch: 7, Steps: 107 Train Loss: 29.4060 (Forecasting Loss:0.3043 + XiCon Loss:2.9102 x Lambda(10.0)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.1483
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3620853
	speed: 0.1164s/iter; left time: 1146.5410s
Epoch: 8 cost time: 12.297018051147461
Epoch: 8, Steps: 107 Train Loss: 29.3877 (Forecasting Loss:0.3021 + XiCon Loss:2.9086 x Lambda(10.0)), Vali MSE Loss: 0.2798 Test MSE Loss: 0.1468
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9759197
	speed: 0.1130s/iter; left time: 1101.3204s
Epoch: 9 cost time: 12.16751766204834
Epoch: 9, Steps: 107 Train Loss: 29.3689 (Forecasting Loss:0.3009 + XiCon Loss:2.9068 x Lambda(10.0)), Vali MSE Loss: 0.2740 Test MSE Loss: 0.1504
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8475475
	speed: 0.1122s/iter; left time: 1081.2165s
Epoch: 10 cost time: 12.088878870010376
Epoch: 10, Steps: 107 Train Loss: 29.3768 (Forecasting Loss:0.3004 + XiCon Loss:2.9076 x Lambda(10.0)), Vali MSE Loss: 0.2761 Test MSE Loss: 0.1488
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7771912
	speed: 0.1129s/iter; left time: 1076.0312s
Epoch: 11 cost time: 12.227128982543945
Epoch: 11, Steps: 107 Train Loss: 29.3799 (Forecasting Loss:0.3005 + XiCon Loss:2.9079 x Lambda(10.0)), Vali MSE Loss: 0.2768 Test MSE Loss: 0.1483
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3967953
	speed: 0.1121s/iter; left time: 1056.3352s
Epoch: 12 cost time: 12.079558849334717
Epoch: 12, Steps: 107 Train Loss: 29.3844 (Forecasting Loss:0.3013 + XiCon Loss:2.9083 x Lambda(10.0)), Vali MSE Loss: 0.2768 Test MSE Loss: 0.1488
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3896675
	speed: 0.1103s/iter; left time: 1027.3616s
Epoch: 13 cost time: 11.87446904182434
Epoch: 13, Steps: 107 Train Loss: 29.3401 (Forecasting Loss:0.3006 + XiCon Loss:2.9040 x Lambda(10.0)), Vali MSE Loss: 0.2758 Test MSE Loss: 0.1489
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08277931064367294, mae:0.2270667999982834, mape:0.1621754914522171, mspe:0.04171937331557274 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.4250
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.7313938
	speed: 0.1010s/iter; left time: 1070.9447s
Epoch: 1 cost time: 10.881160020828247
Epoch: 1, Steps: 107 Train Loss: 31.9453 (Forecasting Loss:0.5479 + XiCon Loss:3.1397 x Lambda(10.0)), Vali MSE Loss: 0.3915 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.391523).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4641628
	speed: 0.1103s/iter; left time: 1157.7555s
Epoch: 2 cost time: 12.003352165222168
Epoch: 2, Steps: 107 Train Loss: 30.4888 (Forecasting Loss:0.5091 + XiCon Loss:2.9980 x Lambda(10.0)), Vali MSE Loss: 0.3326 Test MSE Loss: 0.1973
Validation loss decreased (0.391523 --> 0.332620).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.4228668
	speed: 0.1102s/iter; left time: 1145.1520s
Epoch: 3 cost time: 11.982440948486328
Epoch: 3, Steps: 107 Train Loss: 30.6626 (Forecasting Loss:0.4564 + XiCon Loss:3.0206 x Lambda(10.0)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1731
Validation loss decreased (0.332620 --> 0.255411).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1857738
	speed: 0.1174s/iter; left time: 1207.1333s
Epoch: 4 cost time: 12.625315427780151
Epoch: 4, Steps: 107 Train Loss: 30.5635 (Forecasting Loss:0.4001 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.2433 Test MSE Loss: 0.1712
Validation loss decreased (0.255411 --> 0.243339).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0793896
	speed: 0.1149s/iter; left time: 1169.2868s
Epoch: 5 cost time: 12.37677264213562
Epoch: 5, Steps: 107 Train Loss: 30.3002 (Forecasting Loss:0.3729 + XiCon Loss:2.9927 x Lambda(10.0)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1660
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.1475906
	speed: 0.1157s/iter; left time: 1164.8624s
Epoch: 6 cost time: 12.361462354660034
Epoch: 6, Steps: 107 Train Loss: 30.2826 (Forecasting Loss:0.3577 + XiCon Loss:2.9925 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1647
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8868942
	speed: 0.1162s/iter; left time: 1157.2001s
Epoch: 7 cost time: 12.611682653427124
Epoch: 7, Steps: 107 Train Loss: 30.1858 (Forecasting Loss:0.3539 + XiCon Loss:2.9832 x Lambda(10.0)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1647
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.9207535
	speed: 0.1130s/iter; left time: 1112.8448s
Epoch: 8 cost time: 12.183664798736572
Epoch: 8, Steps: 107 Train Loss: 30.2211 (Forecasting Loss:0.3494 + XiCon Loss:2.9872 x Lambda(10.0)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.1637
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8075867
	speed: 0.1121s/iter; left time: 1092.2816s
Epoch: 9 cost time: 11.895832061767578
Epoch: 9, Steps: 107 Train Loss: 30.1474 (Forecasting Loss:0.3477 + XiCon Loss:2.9800 x Lambda(10.0)), Vali MSE Loss: 0.2562 Test MSE Loss: 0.1648
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.6592903
	speed: 0.1336s/iter; left time: 1287.2575s
Epoch: 10 cost time: 14.265208721160889
Epoch: 10, Steps: 107 Train Loss: 30.1480 (Forecasting Loss:0.3483 + XiCon Loss:2.9800 x Lambda(10.0)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.1648
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3465023
	speed: 0.1037s/iter; left time: 988.4093s
Epoch: 11 cost time: 11.279654026031494
Epoch: 11, Steps: 107 Train Loss: 30.2081 (Forecasting Loss:0.3478 + XiCon Loss:2.9860 x Lambda(10.0)), Vali MSE Loss: 0.2571 Test MSE Loss: 0.1650
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.0073261
	speed: 0.1171s/iter; left time: 1103.2980s
Epoch: 12 cost time: 12.62665057182312
Epoch: 12, Steps: 107 Train Loss: 30.1408 (Forecasting Loss:0.3484 + XiCon Loss:2.9792 x Lambda(10.0)), Vali MSE Loss: 0.2574 Test MSE Loss: 0.1652
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6387405
	speed: 0.1118s/iter; left time: 1041.5735s
Epoch: 13 cost time: 12.034924507141113
Epoch: 13, Steps: 107 Train Loss: 30.0973 (Forecasting Loss:0.3467 + XiCon Loss:2.9751 x Lambda(10.0)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.1652
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1575642
	speed: 0.1150s/iter; left time: 1059.0107s
Epoch: 14 cost time: 12.298467874526978
Epoch: 14, Steps: 107 Train Loss: 30.1827 (Forecasting Loss:0.3477 + XiCon Loss:2.9835 x Lambda(10.0)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.1651
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.09515564143657684, mae:0.2471875250339508, mape:0.17811234295368195, mspe:0.04875409975647926 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.3262
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.7553272
	speed: 0.0959s/iter; left time: 1016.5715s
Epoch: 1 cost time: 10.376587390899658
Epoch: 1, Steps: 107 Train Loss: 31.9528 (Forecasting Loss:0.5705 + XiCon Loss:3.1382 x Lambda(10.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.2366
Validation loss decreased (inf --> 0.409777).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.3716087
	speed: 0.1092s/iter; left time: 1146.2402s
Epoch: 2 cost time: 11.84383511543274
Epoch: 2, Steps: 107 Train Loss: 30.6199 (Forecasting Loss:0.4771 + XiCon Loss:3.0143 x Lambda(10.0)), Vali MSE Loss: 0.2830 Test MSE Loss: 0.1669
Validation loss decreased (0.409777 --> 0.282959).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7735271
	speed: 0.1191s/iter; left time: 1237.3299s
Epoch: 3 cost time: 12.852068901062012
Epoch: 3, Steps: 107 Train Loss: 30.3133 (Forecasting Loss:0.3610 + XiCon Loss:2.9952 x Lambda(10.0)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.1667
Validation loss decreased (0.282959 --> 0.266950).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.5915775
	speed: 0.1175s/iter; left time: 1208.2109s
Epoch: 4 cost time: 12.627879858016968
Epoch: 4, Steps: 107 Train Loss: 29.9239 (Forecasting Loss:0.3378 + XiCon Loss:2.9586 x Lambda(10.0)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.1585
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4856491
	speed: 0.1250s/iter; left time: 1271.9249s
Epoch: 5 cost time: 13.390373945236206
Epoch: 5, Steps: 107 Train Loss: 29.7860 (Forecasting Loss:0.3239 + XiCon Loss:2.9462 x Lambda(10.0)), Vali MSE Loss: 0.2699 Test MSE Loss: 0.1604
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3030663
	speed: 0.1135s/iter; left time: 1142.3459s
Epoch: 6 cost time: 12.253502368927002
Epoch: 6, Steps: 107 Train Loss: 29.6240 (Forecasting Loss:0.3170 + XiCon Loss:2.9307 x Lambda(10.0)), Vali MSE Loss: 0.2604 Test MSE Loss: 0.1636
Validation loss decreased (0.266950 --> 0.260400).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.3772163
	speed: 0.1165s/iter; left time: 1160.2946s
Epoch: 7 cost time: 12.494079828262329
Epoch: 7, Steps: 107 Train Loss: 29.5358 (Forecasting Loss:0.3169 + XiCon Loss:2.9219 x Lambda(10.0)), Vali MSE Loss: 0.2687 Test MSE Loss: 0.1637
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.6572762
	speed: 0.1174s/iter; left time: 1156.5580s
Epoch: 8 cost time: 12.647153377532959
Epoch: 8, Steps: 107 Train Loss: 29.5638 (Forecasting Loss:0.3135 + XiCon Loss:2.9250 x Lambda(10.0)), Vali MSE Loss: 0.2640 Test MSE Loss: 0.1662
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3810120
	speed: 0.1160s/iter; left time: 1130.8642s
Epoch: 9 cost time: 12.534107208251953
Epoch: 9, Steps: 107 Train Loss: 29.5369 (Forecasting Loss:0.3115 + XiCon Loss:2.9225 x Lambda(10.0)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.1662
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7458649
	speed: 0.1179s/iter; left time: 1136.6652s
Epoch: 10 cost time: 12.671072483062744
Epoch: 10, Steps: 107 Train Loss: 29.4806 (Forecasting Loss:0.3127 + XiCon Loss:2.9168 x Lambda(10.0)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1660
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.8102379
	speed: 0.1145s/iter; left time: 1090.8873s
Epoch: 11 cost time: 12.324599504470825
Epoch: 11, Steps: 107 Train Loss: 29.4586 (Forecasting Loss:0.3115 + XiCon Loss:2.9147 x Lambda(10.0)), Vali MSE Loss: 0.2649 Test MSE Loss: 0.1666
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.1448288
	speed: 0.1163s/iter; left time: 1096.1882s
Epoch: 12 cost time: 12.496408939361572
Epoch: 12, Steps: 107 Train Loss: 29.4980 (Forecasting Loss:0.3109 + XiCon Loss:2.9187 x Lambda(10.0)), Vali MSE Loss: 0.2654 Test MSE Loss: 0.1665
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3787270
	speed: 0.1184s/iter; left time: 1103.2488s
Epoch: 13 cost time: 12.712312936782837
Epoch: 13, Steps: 107 Train Loss: 29.4787 (Forecasting Loss:0.3124 + XiCon Loss:2.9166 x Lambda(10.0)), Vali MSE Loss: 0.2658 Test MSE Loss: 0.1663
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2784595
	speed: 0.1150s/iter; left time: 1059.3499s
Epoch: 14 cost time: 12.345727920532227
Epoch: 14, Steps: 107 Train Loss: 29.4939 (Forecasting Loss:0.3119 + XiCon Loss:2.9182 x Lambda(10.0)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1663
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.0553703
	speed: 0.1121s/iter; left time: 1020.1364s
Epoch: 15 cost time: 12.118958950042725
Epoch: 15, Steps: 107 Train Loss: 29.4517 (Forecasting Loss:0.3137 + XiCon Loss:2.9138 x Lambda(10.0)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1663
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.4253254
	speed: 0.1220s/iter; left time: 1097.7009s
Epoch: 16 cost time: 13.085162878036499
Epoch: 16, Steps: 107 Train Loss: 29.4431 (Forecasting Loss:0.3117 + XiCon Loss:2.9131 x Lambda(10.0)), Vali MSE Loss: 0.2655 Test MSE Loss: 0.1663
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.08917482942342758, mae:0.2380332201719284, mape:0.17092616856098175, mspe:0.045371219515800476 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.3221
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.7778492
	speed: 0.0968s/iter; left time: 1025.9985s
Epoch: 1 cost time: 10.40518569946289
Epoch: 1, Steps: 107 Train Loss: 31.9881 (Forecasting Loss:0.5446 + XiCon Loss:3.1444 x Lambda(10.0)), Vali MSE Loss: 0.3527 Test MSE Loss: 0.2103
Validation loss decreased (inf --> 0.352728).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.3098888
	speed: 0.1003s/iter; left time: 1052.7849s
Epoch: 2 cost time: 10.82258677482605
Epoch: 2, Steps: 107 Train Loss: 30.8179 (Forecasting Loss:0.4593 + XiCon Loss:3.0359 x Lambda(10.0)), Vali MSE Loss: 0.2729 Test MSE Loss: 0.1998
Validation loss decreased (0.352728 --> 0.272886).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6135788
	speed: 0.1048s/iter; left time: 1088.3714s
Epoch: 3 cost time: 11.146670818328857
Epoch: 3, Steps: 107 Train Loss: 30.9744 (Forecasting Loss:0.3484 + XiCon Loss:3.0626 x Lambda(10.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.2104
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2658634
	speed: 0.1055s/iter; left time: 1084.3582s
Epoch: 4 cost time: 11.390637397766113
Epoch: 4, Steps: 107 Train Loss: 30.9103 (Forecasting Loss:0.3381 + XiCon Loss:3.0572 x Lambda(10.0)), Vali MSE Loss: 0.3016 Test MSE Loss: 0.1806
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6169415
	speed: 0.1021s/iter; left time: 1038.9731s
Epoch: 5 cost time: 11.034981966018677
Epoch: 5, Steps: 107 Train Loss: 30.6702 (Forecasting Loss:0.3272 + XiCon Loss:3.0343 x Lambda(10.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.1879
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5005493
	speed: 0.1023s/iter; left time: 1030.1923s
Epoch: 6 cost time: 10.957180500030518
Epoch: 6, Steps: 107 Train Loss: 30.5861 (Forecasting Loss:0.3261 + XiCon Loss:3.0260 x Lambda(10.0)), Vali MSE Loss: 0.2728 Test MSE Loss: 0.1838
Validation loss decreased (0.272886 --> 0.272826).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4903297
	speed: 0.1000s/iter; left time: 995.7187s
Epoch: 7 cost time: 10.839876890182495
Epoch: 7, Steps: 107 Train Loss: 30.4142 (Forecasting Loss:0.3258 + XiCon Loss:3.0088 x Lambda(10.0)), Vali MSE Loss: 0.2811 Test MSE Loss: 0.1863
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.2797050
	speed: 0.1036s/iter; left time: 1020.8349s
Epoch: 8 cost time: 11.188287019729614
Epoch: 8, Steps: 107 Train Loss: 30.4342 (Forecasting Loss:0.3207 + XiCon Loss:3.0114 x Lambda(10.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.1823
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5262833
	speed: 0.1027s/iter; left time: 1000.9799s
Epoch: 9 cost time: 10.903379201889038
Epoch: 9, Steps: 107 Train Loss: 30.4698 (Forecasting Loss:0.3216 + XiCon Loss:3.0148 x Lambda(10.0)), Vali MSE Loss: 0.2764 Test MSE Loss: 0.1855
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.1497097
	speed: 0.0999s/iter; left time: 963.1767s
Epoch: 10 cost time: 10.803455114364624
Epoch: 10, Steps: 107 Train Loss: 30.4195 (Forecasting Loss:0.3220 + XiCon Loss:3.0098 x Lambda(10.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.1837
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5865364
	speed: 0.0993s/iter; left time: 946.0948s
Epoch: 11 cost time: 10.74076795578003
Epoch: 11, Steps: 107 Train Loss: 30.3765 (Forecasting Loss:0.3213 + XiCon Loss:3.0055 x Lambda(10.0)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.1834
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3078747
	speed: 0.1041s/iter; left time: 981.1490s
Epoch: 12 cost time: 11.124686241149902
Epoch: 12, Steps: 107 Train Loss: 30.3937 (Forecasting Loss:0.3210 + XiCon Loss:3.0073 x Lambda(10.0)), Vali MSE Loss: 0.2785 Test MSE Loss: 0.1838
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.0569286
	speed: 0.1029s/iter; left time: 958.6039s
Epoch: 13 cost time: 11.128587007522583
Epoch: 13, Steps: 107 Train Loss: 30.4246 (Forecasting Loss:0.3204 + XiCon Loss:3.0104 x Lambda(10.0)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.1837
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1645584
	speed: 0.1000s/iter; left time: 920.7905s
Epoch: 14 cost time: 10.830403566360474
Epoch: 14, Steps: 107 Train Loss: 30.3948 (Forecasting Loss:0.3213 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.2786 Test MSE Loss: 0.1838
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4480934
	speed: 0.1077s/iter; left time: 980.2098s
Epoch: 15 cost time: 11.457786560058594
Epoch: 15, Steps: 107 Train Loss: 30.4372 (Forecasting Loss:0.3202 + XiCon Loss:3.0117 x Lambda(10.0)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.1837
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8013058
	speed: 0.1042s/iter; left time: 937.2690s
Epoch: 16 cost time: 11.287555456161499
Epoch: 16, Steps: 107 Train Loss: 30.4006 (Forecasting Loss:0.3204 + XiCon Loss:3.0080 x Lambda(10.0)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.1837
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.10794708132743835, mae:0.2596776783466339, mape:0.18240924179553986, mspe:0.050865538418293 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:974369
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.9979
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.4952507
	speed: 0.1002s/iter; left time: 1062.0445s
Epoch: 1 cost time: 10.805146217346191
Epoch: 1, Steps: 107 Train Loss: 31.8663 (Forecasting Loss:0.5516 + XiCon Loss:3.1315 x Lambda(10.0)), Vali MSE Loss: 0.3799 Test MSE Loss: 0.2326
Validation loss decreased (inf --> 0.379943).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.3321800
	speed: 0.1125s/iter; left time: 1180.1158s
Epoch: 2 cost time: 12.012727737426758
Epoch: 2, Steps: 107 Train Loss: 30.0504 (Forecasting Loss:0.4619 + XiCon Loss:2.9589 x Lambda(10.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1739
Validation loss decreased (0.379943 --> 0.247361).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.9856930
	speed: 0.1021s/iter; left time: 1060.0403s
Epoch: 3 cost time: 11.074589252471924
Epoch: 3, Steps: 107 Train Loss: 30.8390 (Forecasting Loss:0.3406 + XiCon Loss:3.0498 x Lambda(10.0)), Vali MSE Loss: 0.2700 Test MSE Loss: 0.1685
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7778606
	speed: 0.1056s/iter; left time: 1085.7864s
Epoch: 4 cost time: 11.260176181793213
Epoch: 4, Steps: 107 Train Loss: 30.4155 (Forecasting Loss:0.3051 + XiCon Loss:3.0110 x Lambda(10.0)), Vali MSE Loss: 0.2558 Test MSE Loss: 0.2013
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8793106
	speed: 0.1094s/iter; left time: 1112.8935s
Epoch: 5 cost time: 11.762889385223389
Epoch: 5, Steps: 107 Train Loss: 30.0130 (Forecasting Loss:0.2920 + XiCon Loss:2.9721 x Lambda(10.0)), Vali MSE Loss: 0.2696 Test MSE Loss: 0.1787
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.3360481
	speed: 0.1096s/iter; left time: 1102.7651s
Epoch: 6 cost time: 11.564806461334229
Epoch: 6, Steps: 107 Train Loss: 29.8978 (Forecasting Loss:0.2869 + XiCon Loss:2.9611 x Lambda(10.0)), Vali MSE Loss: 0.2561 Test MSE Loss: 0.1849
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0123940
	speed: 0.1024s/iter; left time: 1020.0086s
Epoch: 7 cost time: 11.124111652374268
Epoch: 7, Steps: 107 Train Loss: 29.9130 (Forecasting Loss:0.2855 + XiCon Loss:2.9628 x Lambda(10.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1810
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.6575127
	speed: 0.1117s/iter; left time: 1100.7575s
Epoch: 8 cost time: 12.060365915298462
Epoch: 8, Steps: 107 Train Loss: 29.8232 (Forecasting Loss:0.2846 + XiCon Loss:2.9539 x Lambda(10.0)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.1792
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.7409172
	speed: 0.1065s/iter; left time: 1037.5226s
Epoch: 9 cost time: 11.389161348342896
Epoch: 9, Steps: 107 Train Loss: 29.7914 (Forecasting Loss:0.2846 + XiCon Loss:2.9507 x Lambda(10.0)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.1797
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.7531910
	speed: 0.1082s/iter; left time: 1042.5154s
Epoch: 10 cost time: 11.762600183486938
Epoch: 10, Steps: 107 Train Loss: 29.7242 (Forecasting Loss:0.2843 + XiCon Loss:2.9440 x Lambda(10.0)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.1794
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4259205
	speed: 0.1079s/iter; left time: 1028.0137s
Epoch: 11 cost time: 11.563528537750244
Epoch: 11, Steps: 107 Train Loss: 29.8281 (Forecasting Loss:0.2828 + XiCon Loss:2.9545 x Lambda(10.0)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.1799
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1287804
	speed: 0.1043s/iter; left time: 982.8781s
Epoch: 12 cost time: 11.256178855895996
Epoch: 12, Steps: 107 Train Loss: 29.7992 (Forecasting Loss:0.2824 + XiCon Loss:2.9517 x Lambda(10.0)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.1789
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl1440_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.09806077182292938, mae:0.24964994192123413, mape:0.1786653697490692, mspe:0.04942120984196663 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0946+-0.01177, MAE:0.2443+-0.01533, MAPE:0.1745+-0.00996, MSPE:0.0472+-0.00457, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.4044
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 16.463255405426025
Epoch: 1, Steps: 96 Train Loss: 32.1466 (Forecasting Loss:0.7639 + XiCon Loss:3.1383 x Lambda(10.0)), Vali MSE Loss: 0.4684 Test MSE Loss: 0.3050
Validation loss decreased (inf --> 0.468428).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 17.02570104598999
Epoch: 2, Steps: 96 Train Loss: 30.9897 (Forecasting Loss:0.6098 + XiCon Loss:3.0380 x Lambda(10.0)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.3506
Validation loss decreased (0.468428 --> 0.302562).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.55233883857727
Epoch: 3, Steps: 96 Train Loss: 32.2483 (Forecasting Loss:0.3970 + XiCon Loss:3.1851 x Lambda(10.0)), Vali MSE Loss: 0.4295 Test MSE Loss: 0.2477
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 16.160714149475098
Epoch: 4, Steps: 96 Train Loss: 32.0328 (Forecasting Loss:0.3786 + XiCon Loss:3.1654 x Lambda(10.0)), Vali MSE Loss: 0.3813 Test MSE Loss: 0.3063
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 15.98783802986145
Epoch: 5, Steps: 96 Train Loss: 31.8502 (Forecasting Loss:0.3599 + XiCon Loss:3.1490 x Lambda(10.0)), Vali MSE Loss: 0.3144 Test MSE Loss: 0.2244
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.97106122970581
Epoch: 6, Steps: 96 Train Loss: 31.6056 (Forecasting Loss:0.3561 + XiCon Loss:3.1249 x Lambda(10.0)), Vali MSE Loss: 0.3506 Test MSE Loss: 0.2114
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 16.01524257659912
Epoch: 7, Steps: 96 Train Loss: 31.6447 (Forecasting Loss:0.3492 + XiCon Loss:3.1296 x Lambda(10.0)), Vali MSE Loss: 0.3281 Test MSE Loss: 0.2200
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 16.222554683685303
Epoch: 8, Steps: 96 Train Loss: 31.5316 (Forecasting Loss:0.3460 + XiCon Loss:3.1186 x Lambda(10.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2211
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.409783124923706
Epoch: 9, Steps: 96 Train Loss: 31.5725 (Forecasting Loss:0.3461 + XiCon Loss:3.1226 x Lambda(10.0)), Vali MSE Loss: 0.3296 Test MSE Loss: 0.2203
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.861670970916748
Epoch: 10, Steps: 96 Train Loss: 31.3696 (Forecasting Loss:0.3454 + XiCon Loss:3.1024 x Lambda(10.0)), Vali MSE Loss: 0.3271 Test MSE Loss: 0.2210
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.179633617401123
Epoch: 11, Steps: 96 Train Loss: 31.4751 (Forecasting Loss:0.3450 + XiCon Loss:3.1130 x Lambda(10.0)), Vali MSE Loss: 0.3248 Test MSE Loss: 0.2203
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 15.945108413696289
Epoch: 12, Steps: 96 Train Loss: 31.4177 (Forecasting Loss:0.3450 + XiCon Loss:3.1073 x Lambda(10.0)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.2202
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.270208477973938, mae:0.4310911297798157, mape:0.29444658756256104, mspe:0.11409585177898407 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.3220
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 16.014190912246704
Epoch: 1, Steps: 96 Train Loss: 32.1335 (Forecasting Loss:0.7329 + XiCon Loss:3.1401 x Lambda(10.0)), Vali MSE Loss: 0.4574 Test MSE Loss: 0.2909
Validation loss decreased (inf --> 0.457394).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.166395664215088
Epoch: 2, Steps: 96 Train Loss: 30.5899 (Forecasting Loss:0.5305 + XiCon Loss:3.0059 x Lambda(10.0)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2204
Validation loss decreased (0.457394 --> 0.322669).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 17.223937511444092
Epoch: 3, Steps: 96 Train Loss: 31.1156 (Forecasting Loss:0.3319 + XiCon Loss:3.0784 x Lambda(10.0)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.1657
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 16.335834741592407
Epoch: 4, Steps: 96 Train Loss: 31.1370 (Forecasting Loss:0.3198 + XiCon Loss:3.0817 x Lambda(10.0)), Vali MSE Loss: 0.3636 Test MSE Loss: 0.1512
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 16.57990837097168
Epoch: 5, Steps: 96 Train Loss: 31.1697 (Forecasting Loss:0.3159 + XiCon Loss:3.0854 x Lambda(10.0)), Vali MSE Loss: 0.3451 Test MSE Loss: 0.1713
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.18514084815979
Epoch: 6, Steps: 96 Train Loss: 31.0483 (Forecasting Loss:0.3137 + XiCon Loss:3.0735 x Lambda(10.0)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.1784
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 16.482048749923706
Epoch: 7, Steps: 96 Train Loss: 30.9869 (Forecasting Loss:0.3116 + XiCon Loss:3.0675 x Lambda(10.0)), Vali MSE Loss: 0.3517 Test MSE Loss: 0.1674
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 16.467000007629395
Epoch: 8, Steps: 96 Train Loss: 30.9822 (Forecasting Loss:0.3109 + XiCon Loss:3.0671 x Lambda(10.0)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.1753
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.196620225906372
Epoch: 9, Steps: 96 Train Loss: 31.0570 (Forecasting Loss:0.3107 + XiCon Loss:3.0746 x Lambda(10.0)), Vali MSE Loss: 0.3488 Test MSE Loss: 0.1718
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 16.272046327590942
Epoch: 10, Steps: 96 Train Loss: 31.1402 (Forecasting Loss:0.3099 + XiCon Loss:3.0830 x Lambda(10.0)), Vali MSE Loss: 0.3436 Test MSE Loss: 0.1759
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.275288581848145
Epoch: 11, Steps: 96 Train Loss: 31.0154 (Forecasting Loss:0.3095 + XiCon Loss:3.0706 x Lambda(10.0)), Vali MSE Loss: 0.3425 Test MSE Loss: 0.1765
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 16.321488857269287
Epoch: 12, Steps: 96 Train Loss: 31.0215 (Forecasting Loss:0.3116 + XiCon Loss:3.0710 x Lambda(10.0)), Vali MSE Loss: 0.3440 Test MSE Loss: 0.1758
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.14042404294013977, mae:0.30028241872787476, mape:0.20830538868904114, mspe:0.06197207048535347 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.4297
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 15.780472755432129
Epoch: 1, Steps: 96 Train Loss: 32.1820 (Forecasting Loss:0.7290 + XiCon Loss:3.1453 x Lambda(10.0)), Vali MSE Loss: 0.4315 Test MSE Loss: 0.2787
Validation loss decreased (inf --> 0.431543).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.38352656364441
Epoch: 2, Steps: 96 Train Loss: 30.2656 (Forecasting Loss:0.5970 + XiCon Loss:2.9669 x Lambda(10.0)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.1628
Validation loss decreased (0.431543 --> 0.314964).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.09030270576477
Epoch: 3, Steps: 96 Train Loss: 31.9014 (Forecasting Loss:0.3729 + XiCon Loss:3.1529 x Lambda(10.0)), Vali MSE Loss: 0.2794 Test MSE Loss: 0.2490
Validation loss decreased (0.314964 --> 0.279372).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 15.525651693344116
Epoch: 4, Steps: 96 Train Loss: 33.1376 (Forecasting Loss:0.3536 + XiCon Loss:3.2784 x Lambda(10.0)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.2039
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 16.146119117736816
Epoch: 5, Steps: 96 Train Loss: 33.4653 (Forecasting Loss:0.3470 + XiCon Loss:3.3118 x Lambda(10.0)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.2435
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 15.939737319946289
Epoch: 6, Steps: 96 Train Loss: 33.5155 (Forecasting Loss:0.3351 + XiCon Loss:3.3180 x Lambda(10.0)), Vali MSE Loss: 0.3186 Test MSE Loss: 0.2390
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 17.510419607162476
Epoch: 7, Steps: 96 Train Loss: 33.6424 (Forecasting Loss:0.3321 + XiCon Loss:3.3310 x Lambda(10.0)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2307
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 15.60380744934082
Epoch: 8, Steps: 96 Train Loss: 33.4471 (Forecasting Loss:0.3266 + XiCon Loss:3.3120 x Lambda(10.0)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.2320
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.47242569923401
Epoch: 9, Steps: 96 Train Loss: 33.4113 (Forecasting Loss:0.3266 + XiCon Loss:3.3085 x Lambda(10.0)), Vali MSE Loss: 0.3130 Test MSE Loss: 0.2452
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.924505472183228
Epoch: 10, Steps: 96 Train Loss: 33.6660 (Forecasting Loss:0.3262 + XiCon Loss:3.3340 x Lambda(10.0)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.2380
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 15.970142126083374
Epoch: 11, Steps: 96 Train Loss: 33.4322 (Forecasting Loss:0.3265 + XiCon Loss:3.3106 x Lambda(10.0)), Vali MSE Loss: 0.3146 Test MSE Loss: 0.2357
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 16.187784671783447
Epoch: 12, Steps: 96 Train Loss: 33.5057 (Forecasting Loss:0.3280 + XiCon Loss:3.3178 x Lambda(10.0)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.2357
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 16.348180770874023
Epoch: 13, Steps: 96 Train Loss: 33.5042 (Forecasting Loss:0.3265 + XiCon Loss:3.3178 x Lambda(10.0)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.2362
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.16502884030342102, mae:0.33287808299064636, mape:0.22856442630290985, mspe:0.07086316496133804 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.3450
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 16.498072147369385
Epoch: 1, Steps: 96 Train Loss: 32.1146 (Forecasting Loss:0.7466 + XiCon Loss:3.1368 x Lambda(10.0)), Vali MSE Loss: 0.4667 Test MSE Loss: 0.3054
Validation loss decreased (inf --> 0.466671).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.006873846054077
Epoch: 2, Steps: 96 Train Loss: 30.5930 (Forecasting Loss:0.6183 + XiCon Loss:2.9975 x Lambda(10.0)), Vali MSE Loss: 0.2909 Test MSE Loss: 0.1754
Validation loss decreased (0.466671 --> 0.290938).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.545517444610596
Epoch: 3, Steps: 96 Train Loss: 30.8972 (Forecasting Loss:0.3587 + XiCon Loss:3.0539 x Lambda(10.0)), Vali MSE Loss: 0.3362 Test MSE Loss: 0.2920
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 16.36512327194214
Epoch: 4, Steps: 96 Train Loss: 31.0347 (Forecasting Loss:0.3369 + XiCon Loss:3.0698 x Lambda(10.0)), Vali MSE Loss: 0.3933 Test MSE Loss: 0.2292
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 16.24501323699951
Epoch: 5, Steps: 96 Train Loss: 30.9135 (Forecasting Loss:0.3314 + XiCon Loss:3.0582 x Lambda(10.0)), Vali MSE Loss: 0.3932 Test MSE Loss: 0.2055
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.534995317459106
Epoch: 6, Steps: 96 Train Loss: 30.8080 (Forecasting Loss:0.3267 + XiCon Loss:3.0481 x Lambda(10.0)), Vali MSE Loss: 0.3744 Test MSE Loss: 0.2525
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 17.21543264389038
Epoch: 7, Steps: 96 Train Loss: 30.7558 (Forecasting Loss:0.3235 + XiCon Loss:3.0432 x Lambda(10.0)), Vali MSE Loss: 0.3890 Test MSE Loss: 0.2173
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 16.694645881652832
Epoch: 8, Steps: 96 Train Loss: 30.7932 (Forecasting Loss:0.3222 + XiCon Loss:3.0471 x Lambda(10.0)), Vali MSE Loss: 0.3856 Test MSE Loss: 0.2217
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.886125326156616
Epoch: 9, Steps: 96 Train Loss: 30.7476 (Forecasting Loss:0.3211 + XiCon Loss:3.0427 x Lambda(10.0)), Vali MSE Loss: 0.3824 Test MSE Loss: 0.2270
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 16.765926361083984
Epoch: 10, Steps: 96 Train Loss: 30.6462 (Forecasting Loss:0.3207 + XiCon Loss:3.0325 x Lambda(10.0)), Vali MSE Loss: 0.3852 Test MSE Loss: 0.2228
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.410327434539795
Epoch: 11, Steps: 96 Train Loss: 30.7109 (Forecasting Loss:0.3204 + XiCon Loss:3.0390 x Lambda(10.0)), Vali MSE Loss: 0.3846 Test MSE Loss: 0.2228
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 16.360901832580566
Epoch: 12, Steps: 96 Train Loss: 30.7660 (Forecasting Loss:0.3199 + XiCon Loss:3.0446 x Lambda(10.0)), Vali MSE Loss: 0.3848 Test MSE Loss: 0.2236
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.10095743834972382, mae:0.24978391826152802, mape:0.17859242856502533, mspe:0.04998994991183281 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1463825
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 2.2319
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 16.240408420562744
Epoch: 1, Steps: 96 Train Loss: 32.1516 (Forecasting Loss:0.7159 + XiCon Loss:3.1436 x Lambda(10.0)), Vali MSE Loss: 0.4236 Test MSE Loss: 0.2644
Validation loss decreased (inf --> 0.423592).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 16.791422843933105
Epoch: 2, Steps: 96 Train Loss: 30.9303 (Forecasting Loss:0.5428 + XiCon Loss:3.0388 x Lambda(10.0)), Vali MSE Loss: 0.3556 Test MSE Loss: 0.2406
Validation loss decreased (0.423592 --> 0.355552).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 16.457736015319824
Epoch: 3, Steps: 96 Train Loss: 32.4513 (Forecasting Loss:0.3931 + XiCon Loss:3.2058 x Lambda(10.0)), Vali MSE Loss: 0.3310 Test MSE Loss: 0.2512
Validation loss decreased (0.355552 --> 0.331049).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 16.19775080680847
Epoch: 4, Steps: 96 Train Loss: 32.7488 (Forecasting Loss:0.3582 + XiCon Loss:3.2391 x Lambda(10.0)), Vali MSE Loss: 0.3493 Test MSE Loss: 0.2455
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 16.51947832107544
Epoch: 5, Steps: 96 Train Loss: 32.7236 (Forecasting Loss:0.3471 + XiCon Loss:3.2376 x Lambda(10.0)), Vali MSE Loss: 0.3440 Test MSE Loss: 0.2241
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 16.295329332351685
Epoch: 6, Steps: 96 Train Loss: 32.6423 (Forecasting Loss:0.3421 + XiCon Loss:3.2300 x Lambda(10.0)), Vali MSE Loss: 0.3520 Test MSE Loss: 0.2083
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 16.171199321746826
Epoch: 7, Steps: 96 Train Loss: 32.5840 (Forecasting Loss:0.3377 + XiCon Loss:3.2246 x Lambda(10.0)), Vali MSE Loss: 0.3515 Test MSE Loss: 0.2009
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 16.468116521835327
Epoch: 8, Steps: 96 Train Loss: 32.4110 (Forecasting Loss:0.3354 + XiCon Loss:3.2076 x Lambda(10.0)), Vali MSE Loss: 0.3559 Test MSE Loss: 0.2031
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 16.157492876052856
Epoch: 9, Steps: 96 Train Loss: 32.5000 (Forecasting Loss:0.3378 + XiCon Loss:3.2162 x Lambda(10.0)), Vali MSE Loss: 0.3590 Test MSE Loss: 0.2017
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 15.885151147842407
Epoch: 10, Steps: 96 Train Loss: 32.4588 (Forecasting Loss:0.3345 + XiCon Loss:3.2124 x Lambda(10.0)), Vali MSE Loss: 0.3560 Test MSE Loss: 0.2023
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 16.52960181236267
Epoch: 11, Steps: 96 Train Loss: 32.4606 (Forecasting Loss:0.3364 + XiCon Loss:3.2124 x Lambda(10.0)), Vali MSE Loss: 0.3554 Test MSE Loss: 0.2025
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 16.248237133026123
Epoch: 12, Steps: 96 Train Loss: 32.4411 (Forecasting Loss:0.3348 + XiCon Loss:3.2106 x Lambda(10.0)), Vali MSE Loss: 0.3546 Test MSE Loss: 0.2024
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 16.30779767036438
Epoch: 13, Steps: 96 Train Loss: 32.3766 (Forecasting Loss:0.3350 + XiCon Loss:3.2042 x Lambda(10.0)), Vali MSE Loss: 0.3547 Test MSE Loss: 0.2023
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl2160_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.16977830231189728, mae:0.3325546979904175, mape:0.22903871536254883, mspe:0.07359115779399872 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1693+-0.07780, MAE:0.3293+-0.08224, MAPE:0.2278+-0.05284, MSPE:0.0741+-0.03002, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.7049
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.6963043
	speed: 0.0660s/iter; left time: 838.5651s
Epoch: 1 cost time: 8.146841287612915
Epoch: 1, Steps: 128 Train Loss: 31.0406 (Forecasting Loss:0.2931 + XiCon Loss:3.0747 x Lambda(10.0)), Vali MSE Loss: 0.2773 Test MSE Loss: 0.2331
Validation loss decreased (inf --> 0.277323).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8812428
	speed: 0.0550s/iter; left time: 691.4292s
Epoch: 2 cost time: 7.01538872718811
Epoch: 2, Steps: 128 Train Loss: 29.2228 (Forecasting Loss:0.2570 + XiCon Loss:2.8966 x Lambda(10.0)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.2194
Validation loss decreased (0.277323 --> 0.256419).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1936092
	speed: 0.0566s/iter; left time: 704.3229s
Epoch: 3 cost time: 7.07426643371582
Epoch: 3, Steps: 128 Train Loss: 28.8857 (Forecasting Loss:0.2435 + XiCon Loss:2.8642 x Lambda(10.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.2218
Validation loss decreased (0.256419 --> 0.253162).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5888901
	speed: 0.0554s/iter; left time: 682.6934s
Epoch: 4 cost time: 6.971410512924194
Epoch: 4, Steps: 128 Train Loss: 30.4302 (Forecasting Loss:0.2378 + XiCon Loss:3.0192 x Lambda(10.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.2062
Validation loss decreased (0.253162 --> 0.253084).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9601402
	speed: 0.0579s/iter; left time: 705.8220s
Epoch: 5 cost time: 7.245928049087524
Epoch: 5, Steps: 128 Train Loss: 30.7296 (Forecasting Loss:0.2349 + XiCon Loss:3.0495 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2079
Validation loss decreased (0.253084 --> 0.250689).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.2708931
	speed: 0.0576s/iter; left time: 695.0485s
Epoch: 6 cost time: 7.17459774017334
Epoch: 6, Steps: 128 Train Loss: 30.7686 (Forecasting Loss:0.2332 + XiCon Loss:3.0535 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2061
Validation loss decreased (0.250689 --> 0.249947).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.7164993
	speed: 0.0558s/iter; left time: 666.1251s
Epoch: 7 cost time: 7.2577245235443115
Epoch: 7, Steps: 128 Train Loss: 30.8473 (Forecasting Loss:0.2320 + XiCon Loss:3.0615 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2070
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2357216
	speed: 0.0587s/iter; left time: 692.9208s
Epoch: 8 cost time: 7.408650875091553
Epoch: 8, Steps: 128 Train Loss: 30.8167 (Forecasting Loss:0.2317 + XiCon Loss:3.0585 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2062
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0543480
	speed: 0.0559s/iter; left time: 652.2495s
Epoch: 9 cost time: 7.311846971511841
Epoch: 9, Steps: 128 Train Loss: 30.7639 (Forecasting Loss:0.2316 + XiCon Loss:3.0532 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2054
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.3681545
	speed: 0.0503s/iter; left time: 581.1541s
Epoch: 10 cost time: 6.7271728515625
Epoch: 10, Steps: 128 Train Loss: 30.6868 (Forecasting Loss:0.2316 + XiCon Loss:3.0455 x Lambda(10.0)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.2056
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4126892
	speed: 0.0603s/iter; left time: 688.8625s
Epoch: 11 cost time: 7.4003846645355225
Epoch: 11, Steps: 128 Train Loss: 30.7472 (Forecasting Loss:0.2314 + XiCon Loss:3.0516 x Lambda(10.0)), Vali MSE Loss: 0.2506 Test MSE Loss: 0.2056
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.0682049
	speed: 0.0555s/iter; left time: 627.0089s
Epoch: 12 cost time: 7.374130964279175
Epoch: 12, Steps: 128 Train Loss: 30.8212 (Forecasting Loss:0.2314 + XiCon Loss:3.0590 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2055
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.5959930
	speed: 0.0638s/iter; left time: 712.4506s
Epoch: 13 cost time: 8.009067296981812
Epoch: 13, Steps: 128 Train Loss: 30.8406 (Forecasting Loss:0.2313 + XiCon Loss:3.0609 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2055
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.9213104
	speed: 0.0583s/iter; left time: 643.5960s
Epoch: 14 cost time: 7.4180121421813965
Epoch: 14, Steps: 128 Train Loss: 30.8855 (Forecasting Loss:0.2311 + XiCon Loss:3.0654 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2055
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.4990978
	speed: 0.0581s/iter; left time: 633.5579s
Epoch: 15 cost time: 7.4135661125183105
Epoch: 15, Steps: 128 Train Loss: 30.7830 (Forecasting Loss:0.2311 + XiCon Loss:3.0552 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2055
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.3513451
	speed: 0.0542s/iter; left time: 584.4256s
Epoch: 16 cost time: 6.973093748092651
Epoch: 16, Steps: 128 Train Loss: 30.8288 (Forecasting Loss:0.2313 + XiCon Loss:3.0597 x Lambda(10.0)), Vali MSE Loss: 0.2508 Test MSE Loss: 0.2055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.1318366378545761, mae:0.28040096163749695, mape:0.6630772352218628, mspe:19.67357635498047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2010
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.7009850
	speed: 0.0542s/iter; left time: 688.0143s
Epoch: 1 cost time: 7.066612482070923
Epoch: 1, Steps: 128 Train Loss: 30.8866 (Forecasting Loss:0.2941 + XiCon Loss:3.0593 x Lambda(10.0)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.2311
Validation loss decreased (inf --> 0.274185).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9396801
	speed: 0.0564s/iter; left time: 709.6617s
Epoch: 2 cost time: 7.089221954345703
Epoch: 2, Steps: 128 Train Loss: 29.5986 (Forecasting Loss:0.2580 + XiCon Loss:2.9341 x Lambda(10.0)), Vali MSE Loss: 0.2642 Test MSE Loss: 0.2178
Validation loss decreased (0.274185 --> 0.264196).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7637539
	speed: 0.0535s/iter; left time: 665.8870s
Epoch: 3 cost time: 6.817709445953369
Epoch: 3, Steps: 128 Train Loss: 30.5362 (Forecasting Loss:0.2428 + XiCon Loss:3.0293 x Lambda(10.0)), Vali MSE Loss: 0.2566 Test MSE Loss: 0.2094
Validation loss decreased (0.264196 --> 0.256578).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9160671
	speed: 0.0542s/iter; left time: 667.3376s
Epoch: 4 cost time: 6.80064058303833
Epoch: 4, Steps: 128 Train Loss: 31.3461 (Forecasting Loss:0.2377 + XiCon Loss:3.1108 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2070
Validation loss decreased (0.256578 --> 0.248956).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.8634911
	speed: 0.0588s/iter; left time: 716.5190s
Epoch: 5 cost time: 7.179966449737549
Epoch: 5, Steps: 128 Train Loss: 31.7238 (Forecasting Loss:0.2344 + XiCon Loss:3.1489 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2097
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.2752533
	speed: 0.0585s/iter; left time: 705.1936s
Epoch: 6 cost time: 7.4435930252075195
Epoch: 6, Steps: 128 Train Loss: 32.0558 (Forecasting Loss:0.2327 + XiCon Loss:3.1823 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2063
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.6750984
	speed: 0.0609s/iter; left time: 726.4554s
Epoch: 7 cost time: 7.538466453552246
Epoch: 7, Steps: 128 Train Loss: 31.8631 (Forecasting Loss:0.2319 + XiCon Loss:3.1631 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.2056
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.5712128
	speed: 0.0589s/iter; left time: 694.9920s
Epoch: 8 cost time: 7.740888833999634
Epoch: 8, Steps: 128 Train Loss: 31.8929 (Forecasting Loss:0.2315 + XiCon Loss:3.1661 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2058
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.9328690
	speed: 0.0604s/iter; left time: 705.1930s
Epoch: 9 cost time: 7.313646078109741
Epoch: 9, Steps: 128 Train Loss: 31.9991 (Forecasting Loss:0.2311 + XiCon Loss:3.1768 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2057
Validation loss decreased (0.248956 --> 0.248431).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1275597
	speed: 0.0564s/iter; left time: 651.1490s
Epoch: 10 cost time: 6.83781886100769
Epoch: 10, Steps: 128 Train Loss: 31.8417 (Forecasting Loss:0.2311 + XiCon Loss:3.1611 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.8279057
	speed: 0.0610s/iter; left time: 696.6361s
Epoch: 11 cost time: 7.804534912109375
Epoch: 11, Steps: 128 Train Loss: 31.8947 (Forecasting Loss:0.2311 + XiCon Loss:3.1664 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2056
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 32.6844559
	speed: 0.0569s/iter; left time: 642.2071s
Epoch: 12 cost time: 7.187106609344482
Epoch: 12, Steps: 128 Train Loss: 31.8917 (Forecasting Loss:0.2310 + XiCon Loss:3.1661 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2055
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7351780
	speed: 0.0588s/iter; left time: 656.3169s
Epoch: 13 cost time: 7.469461917877197
Epoch: 13, Steps: 128 Train Loss: 31.8341 (Forecasting Loss:0.2309 + XiCon Loss:3.1603 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2055
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.4872322
	speed: 0.0553s/iter; left time: 609.9962s
Epoch: 14 cost time: 6.746797561645508
Epoch: 14, Steps: 128 Train Loss: 31.9985 (Forecasting Loss:0.2309 + XiCon Loss:3.1768 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2055
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.1451797
	speed: 0.0575s/iter; left time: 627.1094s
Epoch: 15 cost time: 7.219231367111206
Epoch: 15, Steps: 128 Train Loss: 31.9062 (Forecasting Loss:0.2309 + XiCon Loss:3.1675 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2055
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.2197037
	speed: 0.0588s/iter; left time: 633.5390s
Epoch: 16 cost time: 7.775980472564697
Epoch: 16, Steps: 128 Train Loss: 32.0206 (Forecasting Loss:0.2309 + XiCon Loss:3.1790 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2055
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.3023376
	speed: 0.0483s/iter; left time: 514.9322s
Epoch: 17 cost time: 6.320411920547485
Epoch: 17, Steps: 128 Train Loss: 31.9900 (Forecasting Loss:0.2309 + XiCon Loss:3.1759 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2055
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.6959343
	speed: 0.0550s/iter; left time: 578.4762s
Epoch: 18 cost time: 6.858205556869507
Epoch: 18, Steps: 128 Train Loss: 31.9149 (Forecasting Loss:0.2309 + XiCon Loss:3.1684 x Lambda(10.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2055
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.2139015
	speed: 0.0543s/iter; left time: 564.5100s
Epoch: 19 cost time: 6.9726831912994385
Epoch: 19, Steps: 128 Train Loss: 31.9525 (Forecasting Loss:0.2311 + XiCon Loss:3.1721 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13113947212696075, mae:0.2802107036113739, mape:0.6577790975570679, mspe:19.323928833007812 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.5159
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 31.0378208
	speed: 0.0575s/iter; left time: 729.8201s
Epoch: 1 cost time: 6.980591773986816
Epoch: 1, Steps: 128 Train Loss: 31.1738 (Forecasting Loss:0.2882 + XiCon Loss:3.0886 x Lambda(10.0)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.2267
Validation loss decreased (inf --> 0.272523).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.1673164
	speed: 0.0595s/iter; left time: 748.0336s
Epoch: 2 cost time: 7.538577556610107
Epoch: 2, Steps: 128 Train Loss: 29.5314 (Forecasting Loss:0.2574 + XiCon Loss:2.9274 x Lambda(10.0)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.2159
Validation loss decreased (0.272523 --> 0.259454).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.0390949
	speed: 0.0620s/iter; left time: 771.5194s
Epoch: 3 cost time: 7.843573808670044
Epoch: 3, Steps: 128 Train Loss: 28.9216 (Forecasting Loss:0.2429 + XiCon Loss:2.8679 x Lambda(10.0)), Vali MSE Loss: 0.2541 Test MSE Loss: 0.2124
Validation loss decreased (0.259454 --> 0.254084).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.8740654
	speed: 0.0524s/iter; left time: 645.4286s
Epoch: 4 cost time: 6.6364405155181885
Epoch: 4, Steps: 128 Train Loss: 28.5520 (Forecasting Loss:0.2376 + XiCon Loss:2.8314 x Lambda(10.0)), Vali MSE Loss: 0.2543 Test MSE Loss: 0.2079
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.4580536
	speed: 0.0598s/iter; left time: 728.9443s
Epoch: 5 cost time: 7.343374013900757
Epoch: 5, Steps: 128 Train Loss: 28.4867 (Forecasting Loss:0.2342 + XiCon Loss:2.8253 x Lambda(10.0)), Vali MSE Loss: 0.2514 Test MSE Loss: 0.2031
Validation loss decreased (0.254084 --> 0.251374).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.1922264
	speed: 0.0544s/iter; left time: 656.2561s
Epoch: 6 cost time: 7.01923394203186
Epoch: 6, Steps: 128 Train Loss: 28.5452 (Forecasting Loss:0.2322 + XiCon Loss:2.8313 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.2048
Validation loss decreased (0.251374 --> 0.250464).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.0991478
	speed: 0.0594s/iter; left time: 709.3765s
Epoch: 7 cost time: 7.491519451141357
Epoch: 7, Steps: 128 Train Loss: 28.5059 (Forecasting Loss:0.2318 + XiCon Loss:2.8274 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2068
Validation loss decreased (0.250464 --> 0.248895).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.4694061
	speed: 0.0522s/iter; left time: 616.6990s
Epoch: 8 cost time: 6.543083906173706
Epoch: 8, Steps: 128 Train Loss: 28.5236 (Forecasting Loss:0.2313 + XiCon Loss:2.8292 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.3513374
	speed: 0.0544s/iter; left time: 635.6810s
Epoch: 9 cost time: 7.089207887649536
Epoch: 9, Steps: 128 Train Loss: 28.4892 (Forecasting Loss:0.2309 + XiCon Loss:2.8258 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2049
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 27.9009304
	speed: 0.0567s/iter; left time: 655.3470s
Epoch: 10 cost time: 7.207473993301392
Epoch: 10, Steps: 128 Train Loss: 28.5133 (Forecasting Loss:0.2308 + XiCon Loss:2.8283 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2050
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.2137337
	speed: 0.0594s/iter; left time: 677.9375s
Epoch: 11 cost time: 7.512069940567017
Epoch: 11, Steps: 128 Train Loss: 28.5195 (Forecasting Loss:0.2307 + XiCon Loss:2.8289 x Lambda(10.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2050
Validation loss decreased (0.248895 --> 0.248531).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.6586266
	speed: 0.0652s/iter; left time: 736.4469s
Epoch: 12 cost time: 8.101746797561646
Epoch: 12, Steps: 128 Train Loss: 28.5007 (Forecasting Loss:0.2306 + XiCon Loss:2.8270 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2051
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.0779190
	speed: 0.0569s/iter; left time: 634.8027s
Epoch: 13 cost time: 7.166484594345093
Epoch: 13, Steps: 128 Train Loss: 28.4698 (Forecasting Loss:0.2306 + XiCon Loss:2.8239 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2050
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.3463364
	speed: 0.0560s/iter; left time: 617.8641s
Epoch: 14 cost time: 7.149526119232178
Epoch: 14, Steps: 128 Train Loss: 28.4786 (Forecasting Loss:0.2308 + XiCon Loss:2.8248 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2050
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.5633583
	speed: 0.0539s/iter; left time: 587.4717s
Epoch: 15 cost time: 6.718786954879761
Epoch: 15, Steps: 128 Train Loss: 28.4662 (Forecasting Loss:0.2305 + XiCon Loss:2.8236 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2050
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.6701965
	speed: 0.0556s/iter; left time: 599.0278s
Epoch: 16 cost time: 7.139539003372192
Epoch: 16, Steps: 128 Train Loss: 28.4878 (Forecasting Loss:0.2307 + XiCon Loss:2.8257 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2050
Validation loss decreased (0.248531 --> 0.248419).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.6384239
	speed: 0.0572s/iter; left time: 609.2569s
Epoch: 17 cost time: 7.30173134803772
Epoch: 17, Steps: 128 Train Loss: 28.4402 (Forecasting Loss:0.2307 + XiCon Loss:2.8209 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2050
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.0309029
	speed: 0.0561s/iter; left time: 590.1665s
Epoch: 18 cost time: 7.25588321685791
Epoch: 18, Steps: 128 Train Loss: 28.5149 (Forecasting Loss:0.2307 + XiCon Loss:2.8284 x Lambda(10.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.2050
Validation loss decreased (0.248419 --> 0.247911).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.2859993
	speed: 0.0569s/iter; left time: 591.3834s
Epoch: 19 cost time: 6.856831312179565
Epoch: 19, Steps: 128 Train Loss: 28.4444 (Forecasting Loss:0.2305 + XiCon Loss:2.8214 x Lambda(10.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2050
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.1593781
	speed: 0.0592s/iter; left time: 608.2292s
Epoch: 20 cost time: 7.200438737869263
Epoch: 20, Steps: 128 Train Loss: 28.4900 (Forecasting Loss:0.2305 + XiCon Loss:2.8259 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2050
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 28.7721863
	speed: 0.0587s/iter; left time: 595.0980s
Epoch: 21 cost time: 7.542505502700806
Epoch: 21, Steps: 128 Train Loss: 28.4526 (Forecasting Loss:0.2307 + XiCon Loss:2.8222 x Lambda(10.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2050
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.4065685
	speed: 0.0627s/iter; left time: 627.4528s
Epoch: 22 cost time: 7.989716291427612
Epoch: 22, Steps: 128 Train Loss: 28.4822 (Forecasting Loss:0.2306 + XiCon Loss:2.8252 x Lambda(10.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2050
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.1665363
	speed: 0.0541s/iter; left time: 534.2958s
Epoch: 23 cost time: 6.870683431625366
Epoch: 23, Steps: 128 Train Loss: 28.4427 (Forecasting Loss:0.2307 + XiCon Loss:2.8212 x Lambda(10.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2050
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 28.4556770
	speed: 0.0552s/iter; left time: 538.4278s
Epoch: 24 cost time: 7.174505949020386
Epoch: 24, Steps: 128 Train Loss: 28.4438 (Forecasting Loss:0.2306 + XiCon Loss:2.8213 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2050
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.2435646
	speed: 0.0645s/iter; left time: 621.3138s
Epoch: 25 cost time: 7.898080825805664
Epoch: 25, Steps: 128 Train Loss: 28.4989 (Forecasting Loss:0.2306 + XiCon Loss:2.8268 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2050
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 28.4454117
	speed: 0.0566s/iter; left time: 537.4282s
Epoch: 26 cost time: 7.3024067878723145
Epoch: 26, Steps: 128 Train Loss: 28.4946 (Forecasting Loss:0.2305 + XiCon Loss:2.8264 x Lambda(10.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2050
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 28.9241352
	speed: 0.0550s/iter; left time: 515.5654s
Epoch: 27 cost time: 6.987011432647705
Epoch: 27, Steps: 128 Train Loss: 28.5032 (Forecasting Loss:0.2307 + XiCon Loss:2.8272 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2050
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 28.9778118
	speed: 0.0872s/iter; left time: 806.2012s
Epoch: 28 cost time: 10.992637872695923
Epoch: 28, Steps: 128 Train Loss: 28.5146 (Forecasting Loss:0.2306 + XiCon Loss:2.8284 x Lambda(10.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2050
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13075841963291168, mae:0.27929070591926575, mape:0.6612691283226013, mspe:19.42155647277832 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.6288
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.8177013
	speed: 0.0549s/iter; left time: 697.2240s
Epoch: 1 cost time: 6.678393363952637
Epoch: 1, Steps: 128 Train Loss: 30.9926 (Forecasting Loss:0.2947 + XiCon Loss:3.0698 x Lambda(10.0)), Vali MSE Loss: 0.2753 Test MSE Loss: 0.2287
Validation loss decreased (inf --> 0.275331).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.1658916
	speed: 0.0488s/iter; left time: 613.6867s
Epoch: 2 cost time: 6.471691846847534
Epoch: 2, Steps: 128 Train Loss: 29.3605 (Forecasting Loss:0.2569 + XiCon Loss:2.9104 x Lambda(10.0)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.2173
Validation loss decreased (0.275331 --> 0.259546).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.9365730
	speed: 0.0582s/iter; left time: 724.4801s
Epoch: 3 cost time: 7.230618000030518
Epoch: 3, Steps: 128 Train Loss: 29.1279 (Forecasting Loss:0.2430 + XiCon Loss:2.8885 x Lambda(10.0)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.2112
Validation loss decreased (0.259546 --> 0.257254).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.9625034
	speed: 0.0629s/iter; left time: 774.4332s
Epoch: 4 cost time: 7.910447835922241
Epoch: 4, Steps: 128 Train Loss: 30.0567 (Forecasting Loss:0.2374 + XiCon Loss:2.9819 x Lambda(10.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.2119
Validation loss decreased (0.257254 --> 0.246791).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4770298
	speed: 0.0544s/iter; left time: 663.6505s
Epoch: 5 cost time: 6.896521091461182
Epoch: 5, Steps: 128 Train Loss: 29.5981 (Forecasting Loss:0.2344 + XiCon Loss:2.9364 x Lambda(10.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2048
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.8152351
	speed: 0.0567s/iter; left time: 683.4822s
Epoch: 6 cost time: 7.079207420349121
Epoch: 6, Steps: 128 Train Loss: 29.3948 (Forecasting Loss:0.2326 + XiCon Loss:2.9162 x Lambda(10.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2042
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.4394436
	speed: 0.0606s/iter; left time: 723.0678s
Epoch: 7 cost time: 7.4580817222595215
Epoch: 7, Steps: 128 Train Loss: 29.3443 (Forecasting Loss:0.2318 + XiCon Loss:2.9113 x Lambda(10.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2047
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.6750183
	speed: 0.0616s/iter; left time: 727.5413s
Epoch: 8 cost time: 7.860532999038696
Epoch: 8, Steps: 128 Train Loss: 29.2318 (Forecasting Loss:0.2314 + XiCon Loss:2.9000 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2040
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.6393452
	speed: 0.0579s/iter; left time: 675.6323s
Epoch: 9 cost time: 7.353317975997925
Epoch: 9, Steps: 128 Train Loss: 29.1362 (Forecasting Loss:0.2311 + XiCon Loss:2.8905 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2040
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.7000847
	speed: 0.0585s/iter; left time: 675.7428s
Epoch: 10 cost time: 7.42708683013916
Epoch: 10, Steps: 128 Train Loss: 29.2371 (Forecasting Loss:0.2308 + XiCon Loss:2.9006 x Lambda(10.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2042
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.3957119
	speed: 0.0516s/iter; left time: 589.2510s
Epoch: 11 cost time: 6.679682970046997
Epoch: 11, Steps: 128 Train Loss: 29.2337 (Forecasting Loss:0.2309 + XiCon Loss:2.9003 x Lambda(10.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2040
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.6383247
	speed: 0.0597s/iter; left time: 674.0661s
Epoch: 12 cost time: 7.7294957637786865
Epoch: 12, Steps: 128 Train Loss: 29.2273 (Forecasting Loss:0.2310 + XiCon Loss:2.8996 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2041
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.0199127
	speed: 0.0555s/iter; left time: 620.1862s
Epoch: 13 cost time: 7.170483827590942
Epoch: 13, Steps: 128 Train Loss: 29.1213 (Forecasting Loss:0.2309 + XiCon Loss:2.8890 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2040
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2958965
	speed: 0.0564s/iter; left time: 622.9493s
Epoch: 14 cost time: 7.169281482696533
Epoch: 14, Steps: 128 Train Loss: 29.0667 (Forecasting Loss:0.2307 + XiCon Loss:2.8836 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2040
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13788746297359467, mae:0.28586095571517944, mape:0.6857526302337646, mspe:21.362516403198242 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.3119
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 30.7615337
	speed: 0.0533s/iter; left time: 676.6977s
Epoch: 1 cost time: 6.775511980056763
Epoch: 1, Steps: 128 Train Loss: 30.8656 (Forecasting Loss:0.2910 + XiCon Loss:3.0575 x Lambda(10.0)), Vali MSE Loss: 0.2726 Test MSE Loss: 0.2264
Validation loss decreased (inf --> 0.272646).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8480415
	speed: 0.0523s/iter; left time: 658.1939s
Epoch: 2 cost time: 6.692922115325928
Epoch: 2, Steps: 128 Train Loss: 29.2524 (Forecasting Loss:0.2571 + XiCon Loss:2.8995 x Lambda(10.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 0.2289
Validation loss decreased (0.272646 --> 0.258269).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.8482456
	speed: 0.0607s/iter; left time: 755.4492s
Epoch: 3 cost time: 7.879979610443115
Epoch: 3, Steps: 128 Train Loss: 29.6421 (Forecasting Loss:0.2415 + XiCon Loss:2.9401 x Lambda(10.0)), Vali MSE Loss: 0.2587 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.0213737
	speed: 0.0626s/iter; left time: 771.0786s
Epoch: 4 cost time: 7.8379693031311035
Epoch: 4, Steps: 128 Train Loss: 29.7924 (Forecasting Loss:0.2368 + XiCon Loss:2.9556 x Lambda(10.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.2149
Validation loss decreased (0.258269 --> 0.253430).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.3461285
	speed: 0.0610s/iter; left time: 743.7100s
Epoch: 5 cost time: 7.5962724685668945
Epoch: 5, Steps: 128 Train Loss: 30.1676 (Forecasting Loss:0.2348 + XiCon Loss:2.9933 x Lambda(10.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.2043
Validation loss decreased (0.253430 --> 0.250438).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9764252
	speed: 0.0519s/iter; left time: 626.2951s
Epoch: 6 cost time: 6.6689393520355225
Epoch: 6, Steps: 128 Train Loss: 30.2843 (Forecasting Loss:0.2330 + XiCon Loss:3.0051 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.2090
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.8534698
	speed: 0.0550s/iter; left time: 656.8151s
Epoch: 7 cost time: 7.195293188095093
Epoch: 7, Steps: 128 Train Loss: 30.4257 (Forecasting Loss:0.2320 + XiCon Loss:3.0194 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2053
Validation loss decreased (0.250438 --> 0.249588).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.5873966
	speed: 0.0607s/iter; left time: 716.5539s
Epoch: 8 cost time: 7.7414774894714355
Epoch: 8, Steps: 128 Train Loss: 30.3818 (Forecasting Loss:0.2317 + XiCon Loss:3.0150 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2056
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3538837
	speed: 0.0606s/iter; left time: 708.0266s
Epoch: 9 cost time: 7.631981611251831
Epoch: 9, Steps: 128 Train Loss: 30.4090 (Forecasting Loss:0.2312 + XiCon Loss:3.0178 x Lambda(10.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2053
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2787380
	speed: 0.0601s/iter; left time: 693.7010s
Epoch: 10 cost time: 7.58439040184021
Epoch: 10, Steps: 128 Train Loss: 30.4847 (Forecasting Loss:0.2313 + XiCon Loss:3.0253 x Lambda(10.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2052
Validation loss decreased (0.249588 --> 0.249033).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.9376087
	speed: 0.0549s/iter; left time: 626.6015s
Epoch: 11 cost time: 7.115121603012085
Epoch: 11, Steps: 128 Train Loss: 30.4635 (Forecasting Loss:0.2313 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2053
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.1345882
	speed: 0.0595s/iter; left time: 671.4959s
Epoch: 12 cost time: 7.588611125946045
Epoch: 12, Steps: 128 Train Loss: 30.3945 (Forecasting Loss:0.2312 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2052
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.1155949
	speed: 0.0557s/iter; left time: 622.2425s
Epoch: 13 cost time: 7.09058141708374
Epoch: 13, Steps: 128 Train Loss: 30.3609 (Forecasting Loss:0.2312 + XiCon Loss:3.0130 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2053
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.7407894
	speed: 0.0572s/iter; left time: 631.2299s
Epoch: 14 cost time: 7.450571537017822
Epoch: 14, Steps: 128 Train Loss: 30.4818 (Forecasting Loss:0.2311 + XiCon Loss:3.0251 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2053
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3313179
	speed: 0.0550s/iter; left time: 599.4837s
Epoch: 15 cost time: 6.851842880249023
Epoch: 15, Steps: 128 Train Loss: 30.4700 (Forecasting Loss:0.2313 + XiCon Loss:3.0239 x Lambda(10.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2053
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.8829651
	speed: 0.0561s/iter; left time: 605.0228s
Epoch: 16 cost time: 6.973685026168823
Epoch: 16, Steps: 128 Train Loss: 30.3395 (Forecasting Loss:0.2313 + XiCon Loss:3.0108 x Lambda(10.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2053
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.2100029
	speed: 0.0603s/iter; left time: 642.3131s
Epoch: 17 cost time: 7.733850002288818
Epoch: 17, Steps: 128 Train Loss: 30.4136 (Forecasting Loss:0.2312 + XiCon Loss:3.0182 x Lambda(10.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2053
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.5627117
	speed: 0.0583s/iter; left time: 613.5988s
Epoch: 18 cost time: 7.450539827346802
Epoch: 18, Steps: 128 Train Loss: 30.3936 (Forecasting Loss:0.2311 + XiCon Loss:3.0162 x Lambda(10.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2053
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.2465057
	speed: 0.0666s/iter; left time: 692.1839s
Epoch: 19 cost time: 8.308506488800049
Epoch: 19, Steps: 128 Train Loss: 30.4808 (Forecasting Loss:0.2311 + XiCon Loss:3.0250 x Lambda(10.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2053
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.1360416
	speed: 0.0549s/iter; left time: 563.3127s
Epoch: 20 cost time: 6.901160717010498
Epoch: 20, Steps: 128 Train Loss: 30.3779 (Forecasting Loss:0.2313 + XiCon Loss:3.0147 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2053
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13104678690433502, mae:0.2793688476085663, mape:0.6601710319519043, mspe:19.540964126586914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1325+-0.00375, MAE:0.2810+-0.00341, MAPE:0.6656+-0.01418, MSPE:19.8645+-1.05241, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2184
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.9003239
	speed: 0.0814s/iter; left time: 952.6238s
Epoch: 1 cost time: 9.596725463867188
Epoch: 1, Steps: 118 Train Loss: 31.2844 (Forecasting Loss:0.4165 + XiCon Loss:3.0868 x Lambda(10.0)), Vali MSE Loss: 0.4419 Test MSE Loss: 0.3410
Validation loss decreased (inf --> 0.441916).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.6192379
	speed: 0.0773s/iter; left time: 895.3848s
Epoch: 2 cost time: 9.20743203163147
Epoch: 2, Steps: 118 Train Loss: 29.4000 (Forecasting Loss:0.3816 + XiCon Loss:2.9018 x Lambda(10.0)), Vali MSE Loss: 0.4330 Test MSE Loss: 0.3209
Validation loss decreased (0.441916 --> 0.432985).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.8088779
	speed: 0.0812s/iter; left time: 930.8623s
Epoch: 3 cost time: 9.5445396900177
Epoch: 3, Steps: 118 Train Loss: 29.1168 (Forecasting Loss:0.3714 + XiCon Loss:2.8745 x Lambda(10.0)), Vali MSE Loss: 0.4114 Test MSE Loss: 0.3069
Validation loss decreased (0.432985 --> 0.411352).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.5727425
	speed: 0.0853s/iter; left time: 967.5252s
Epoch: 4 cost time: 9.889769792556763
Epoch: 4, Steps: 118 Train Loss: 31.1611 (Forecasting Loss:0.3652 + XiCon Loss:3.0796 x Lambda(10.0)), Vali MSE Loss: 0.4127 Test MSE Loss: 0.3101
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.1567650
	speed: 0.0850s/iter; left time: 953.9211s
Epoch: 5 cost time: 10.023361921310425
Epoch: 5, Steps: 118 Train Loss: 31.7308 (Forecasting Loss:0.3610 + XiCon Loss:3.1370 x Lambda(10.0)), Vali MSE Loss: 0.4115 Test MSE Loss: 0.3097
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.9661369
	speed: 0.0882s/iter; left time: 979.5849s
Epoch: 6 cost time: 10.689412593841553
Epoch: 6, Steps: 118 Train Loss: 32.0018 (Forecasting Loss:0.3592 + XiCon Loss:3.1643 x Lambda(10.0)), Vali MSE Loss: 0.4096 Test MSE Loss: 0.3087
Validation loss decreased (0.411352 --> 0.409621).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.3369217
	speed: 0.0836s/iter; left time: 919.4451s
Epoch: 7 cost time: 9.746602773666382
Epoch: 7, Steps: 118 Train Loss: 32.0103 (Forecasting Loss:0.3580 + XiCon Loss:3.1652 x Lambda(10.0)), Vali MSE Loss: 0.4093 Test MSE Loss: 0.3073
Validation loss decreased (0.409621 --> 0.409302).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.8912163
	speed: 0.0770s/iter; left time: 837.0628s
Epoch: 8 cost time: 9.22697114944458
Epoch: 8, Steps: 118 Train Loss: 32.0870 (Forecasting Loss:0.3573 + XiCon Loss:3.1730 x Lambda(10.0)), Vali MSE Loss: 0.4102 Test MSE Loss: 0.3080
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.2851372
	speed: 0.0840s/iter; left time: 903.1132s
Epoch: 9 cost time: 9.816513061523438
Epoch: 9, Steps: 118 Train Loss: 32.0396 (Forecasting Loss:0.3567 + XiCon Loss:3.1683 x Lambda(10.0)), Vali MSE Loss: 0.4103 Test MSE Loss: 0.3081
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.8442249
	speed: 0.0854s/iter; left time: 908.8667s
Epoch: 10 cost time: 10.06327486038208
Epoch: 10, Steps: 118 Train Loss: 32.1082 (Forecasting Loss:0.3565 + XiCon Loss:3.1752 x Lambda(10.0)), Vali MSE Loss: 0.4108 Test MSE Loss: 0.3082
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.4250336
	speed: 0.0830s/iter; left time: 873.7577s
Epoch: 11 cost time: 9.671221733093262
Epoch: 11, Steps: 118 Train Loss: 32.0899 (Forecasting Loss:0.3565 + XiCon Loss:3.1733 x Lambda(10.0)), Vali MSE Loss: 0.4095 Test MSE Loss: 0.3080
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.5599442
	speed: 0.0794s/iter; left time: 825.6120s
Epoch: 12 cost time: 9.463317632675171
Epoch: 12, Steps: 118 Train Loss: 32.0075 (Forecasting Loss:0.3566 + XiCon Loss:3.1651 x Lambda(10.0)), Vali MSE Loss: 0.4096 Test MSE Loss: 0.3080
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.2802734
	speed: 0.0810s/iter; left time: 833.3842s
Epoch: 13 cost time: 9.750786542892456
Epoch: 13, Steps: 118 Train Loss: 32.0121 (Forecasting Loss:0.3564 + XiCon Loss:3.1656 x Lambda(10.0)), Vali MSE Loss: 0.4099 Test MSE Loss: 0.3080
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.8198051
	speed: 0.0847s/iter; left time: 861.3387s
Epoch: 14 cost time: 10.115339279174805
Epoch: 14, Steps: 118 Train Loss: 32.0158 (Forecasting Loss:0.3562 + XiCon Loss:3.1660 x Lambda(10.0)), Vali MSE Loss: 0.4097 Test MSE Loss: 0.3079
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.9066277
	speed: 0.0785s/iter; left time: 789.2619s
Epoch: 15 cost time: 9.112769603729248
Epoch: 15, Steps: 118 Train Loss: 32.1005 (Forecasting Loss:0.3566 + XiCon Loss:3.1744 x Lambda(10.0)), Vali MSE Loss: 0.4100 Test MSE Loss: 0.3079
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.3795300
	speed: 0.0865s/iter; left time: 858.9900s
Epoch: 16 cost time: 10.051759004592896
Epoch: 16, Steps: 118 Train Loss: 32.0072 (Forecasting Loss:0.3562 + XiCon Loss:3.1651 x Lambda(10.0)), Vali MSE Loss: 0.4096 Test MSE Loss: 0.3079
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 33.3688049
	speed: 0.0847s/iter; left time: 830.7401s
Epoch: 17 cost time: 10.065378427505493
Epoch: 17, Steps: 118 Train Loss: 32.0429 (Forecasting Loss:0.3560 + XiCon Loss:3.1687 x Lambda(10.0)), Vali MSE Loss: 0.4098 Test MSE Loss: 0.3079
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2300088107585907, mae:0.3846057057380676, mape:0.6432394981384277, mspe:14.533539772033691 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2855
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.0830383
	speed: 0.0733s/iter; left time: 857.7254s
Epoch: 1 cost time: 8.564494848251343
Epoch: 1, Steps: 118 Train Loss: 31.3389 (Forecasting Loss:0.4092 + XiCon Loss:3.0930 x Lambda(10.0)), Vali MSE Loss: 0.4295 Test MSE Loss: 0.3213
Validation loss decreased (inf --> 0.429452).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.5642433
	speed: 0.0858s/iter; left time: 994.2687s
Epoch: 2 cost time: 9.968505620956421
Epoch: 2, Steps: 118 Train Loss: 29.4877 (Forecasting Loss:0.3857 + XiCon Loss:2.9102 x Lambda(10.0)), Vali MSE Loss: 0.4275 Test MSE Loss: 0.3172
Validation loss decreased (0.429452 --> 0.427470).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.6467228
	speed: 0.0816s/iter; left time: 935.8810s
Epoch: 3 cost time: 9.850788116455078
Epoch: 3, Steps: 118 Train Loss: 29.0110 (Forecasting Loss:0.3675 + XiCon Loss:2.8644 x Lambda(10.0)), Vali MSE Loss: 0.4195 Test MSE Loss: 0.3082
Validation loss decreased (0.427470 --> 0.419528).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7614212
	speed: 0.0879s/iter; left time: 997.6552s
Epoch: 4 cost time: 10.328870296478271
Epoch: 4, Steps: 118 Train Loss: 29.6303 (Forecasting Loss:0.3563 + XiCon Loss:2.9274 x Lambda(10.0)), Vali MSE Loss: 0.4036 Test MSE Loss: 0.2938
Validation loss decreased (0.419528 --> 0.403573).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7255020
	speed: 0.0907s/iter; left time: 1018.9080s
Epoch: 5 cost time: 10.70991849899292
Epoch: 5, Steps: 118 Train Loss: 29.9830 (Forecasting Loss:0.3496 + XiCon Loss:2.9633 x Lambda(10.0)), Vali MSE Loss: 0.4094 Test MSE Loss: 0.2964
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.2824554
	speed: 0.0818s/iter; left time: 908.7528s
Epoch: 6 cost time: 9.7164785861969
Epoch: 6, Steps: 118 Train Loss: 30.2532 (Forecasting Loss:0.3458 + XiCon Loss:2.9907 x Lambda(10.0)), Vali MSE Loss: 0.4059 Test MSE Loss: 0.2946
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.6314373
	speed: 0.0856s/iter; left time: 940.9315s
Epoch: 7 cost time: 10.1404709815979
Epoch: 7, Steps: 118 Train Loss: 30.2660 (Forecasting Loss:0.3431 + XiCon Loss:2.9923 x Lambda(10.0)), Vali MSE Loss: 0.4015 Test MSE Loss: 0.2929
Validation loss decreased (0.403573 --> 0.401487).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.7460899
	speed: 0.0856s/iter; left time: 930.8943s
Epoch: 8 cost time: 9.987292766571045
Epoch: 8, Steps: 118 Train Loss: 30.4177 (Forecasting Loss:0.3416 + XiCon Loss:3.0076 x Lambda(10.0)), Vali MSE Loss: 0.4037 Test MSE Loss: 0.2928
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4652100
	speed: 0.0868s/iter; left time: 933.8040s
Epoch: 9 cost time: 10.102100610733032
Epoch: 9, Steps: 118 Train Loss: 30.3454 (Forecasting Loss:0.3409 + XiCon Loss:3.0004 x Lambda(10.0)), Vali MSE Loss: 0.4033 Test MSE Loss: 0.2922
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5444527
	speed: 0.0793s/iter; left time: 843.9103s
Epoch: 10 cost time: 9.452539205551147
Epoch: 10, Steps: 118 Train Loss: 30.3514 (Forecasting Loss:0.3402 + XiCon Loss:3.0011 x Lambda(10.0)), Vali MSE Loss: 0.4033 Test MSE Loss: 0.2922
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.7809563
	speed: 0.0860s/iter; left time: 904.8581s
Epoch: 11 cost time: 10.07182765007019
Epoch: 11, Steps: 118 Train Loss: 30.4444 (Forecasting Loss:0.3406 + XiCon Loss:3.0104 x Lambda(10.0)), Vali MSE Loss: 0.4024 Test MSE Loss: 0.2920
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.6844959
	speed: 0.0810s/iter; left time: 843.1470s
Epoch: 12 cost time: 9.704325914382935
Epoch: 12, Steps: 118 Train Loss: 30.4317 (Forecasting Loss:0.3400 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.4021 Test MSE Loss: 0.2919
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.1968651
	speed: 0.0851s/iter; left time: 875.6799s
Epoch: 13 cost time: 9.948142528533936
Epoch: 13, Steps: 118 Train Loss: 30.3101 (Forecasting Loss:0.3400 + XiCon Loss:2.9970 x Lambda(10.0)), Vali MSE Loss: 0.4024 Test MSE Loss: 0.2918
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.8194866
	speed: 0.0861s/iter; left time: 875.5607s
Epoch: 14 cost time: 10.224949836730957
Epoch: 14, Steps: 118 Train Loss: 30.2786 (Forecasting Loss:0.3405 + XiCon Loss:2.9938 x Lambda(10.0)), Vali MSE Loss: 0.4027 Test MSE Loss: 0.2918
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2052574
	speed: 0.0842s/iter; left time: 845.7546s
Epoch: 15 cost time: 9.963101625442505
Epoch: 15, Steps: 118 Train Loss: 30.4464 (Forecasting Loss:0.3405 + XiCon Loss:3.0106 x Lambda(10.0)), Vali MSE Loss: 0.4029 Test MSE Loss: 0.2918
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9485207
	speed: 0.0786s/iter; left time: 780.2139s
Epoch: 16 cost time: 9.30182433128357
Epoch: 16, Steps: 118 Train Loss: 30.5718 (Forecasting Loss:0.3401 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.4027 Test MSE Loss: 0.2918
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6053829
	speed: 0.0862s/iter; left time: 845.7806s
Epoch: 17 cost time: 10.17112946510315
Epoch: 17, Steps: 118 Train Loss: 30.3463 (Forecasting Loss:0.3402 + XiCon Loss:3.0006 x Lambda(10.0)), Vali MSE Loss: 0.4025 Test MSE Loss: 0.2918
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.21394750475883484, mae:0.3717648983001709, mape:0.6353328227996826, mspe:15.161314964294434 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.4110
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 31.0530033
	speed: 0.0803s/iter; left time: 939.8564s
Epoch: 1 cost time: 9.45177936553955
Epoch: 1, Steps: 118 Train Loss: 31.1007 (Forecasting Loss:0.4116 + XiCon Loss:3.0689 x Lambda(10.0)), Vali MSE Loss: 0.4408 Test MSE Loss: 0.3352
Validation loss decreased (inf --> 0.440757).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.1794567
	speed: 0.0809s/iter; left time: 937.5686s
Epoch: 2 cost time: 9.4865083694458
Epoch: 2, Steps: 118 Train Loss: 29.6161 (Forecasting Loss:0.3839 + XiCon Loss:2.9232 x Lambda(10.0)), Vali MSE Loss: 0.4324 Test MSE Loss: 0.3262
Validation loss decreased (0.440757 --> 0.432395).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.8244934
	speed: 0.0753s/iter; left time: 863.8147s
Epoch: 3 cost time: 8.993786573410034
Epoch: 3, Steps: 118 Train Loss: 29.9625 (Forecasting Loss:0.3704 + XiCon Loss:2.9592 x Lambda(10.0)), Vali MSE Loss: 0.4177 Test MSE Loss: 0.3114
Validation loss decreased (0.432395 --> 0.417727).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.9876480
	speed: 0.0929s/iter; left time: 1053.7096s
Epoch: 4 cost time: 10.861262321472168
Epoch: 4, Steps: 118 Train Loss: 30.4200 (Forecasting Loss:0.3650 + XiCon Loss:3.0055 x Lambda(10.0)), Vali MSE Loss: 0.4108 Test MSE Loss: 0.3073
Validation loss decreased (0.417727 --> 0.410800).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.1091938
	speed: 0.0822s/iter; left time: 923.5187s
Epoch: 5 cost time: 9.787440776824951
Epoch: 5, Steps: 118 Train Loss: 30.7845 (Forecasting Loss:0.3615 + XiCon Loss:3.0423 x Lambda(10.0)), Vali MSE Loss: 0.4091 Test MSE Loss: 0.3044
Validation loss decreased (0.410800 --> 0.409141).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9688663
	speed: 0.0817s/iter; left time: 907.9892s
Epoch: 6 cost time: 9.715224266052246
Epoch: 6, Steps: 118 Train Loss: 31.2031 (Forecasting Loss:0.3597 + XiCon Loss:3.0843 x Lambda(10.0)), Vali MSE Loss: 0.4085 Test MSE Loss: 0.3043
Validation loss decreased (0.409141 --> 0.408462).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1598949
	speed: 0.0798s/iter; left time: 877.7612s
Epoch: 7 cost time: 9.432795763015747
Epoch: 7, Steps: 118 Train Loss: 31.2216 (Forecasting Loss:0.3588 + XiCon Loss:3.0863 x Lambda(10.0)), Vali MSE Loss: 0.4076 Test MSE Loss: 0.3025
Validation loss decreased (0.408462 --> 0.407630).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.1409645
	speed: 0.0906s/iter; left time: 985.5045s
Epoch: 8 cost time: 10.571072816848755
Epoch: 8, Steps: 118 Train Loss: 31.2580 (Forecasting Loss:0.3578 + XiCon Loss:3.0900 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.3025
Validation loss decreased (0.407630 --> 0.406885).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.6686249
	speed: 0.0834s/iter; left time: 897.3326s
Epoch: 9 cost time: 9.887116432189941
Epoch: 9, Steps: 118 Train Loss: 31.2941 (Forecasting Loss:0.3575 + XiCon Loss:3.0937 x Lambda(10.0)), Vali MSE Loss: 0.4063 Test MSE Loss: 0.3024
Validation loss decreased (0.406885 --> 0.406296).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.1612854
	speed: 0.0816s/iter; left time: 868.1774s
Epoch: 10 cost time: 9.693968296051025
Epoch: 10, Steps: 118 Train Loss: 31.1678 (Forecasting Loss:0.3572 + XiCon Loss:3.0811 x Lambda(10.0)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3025
Validation loss decreased (0.406296 --> 0.405984).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.9256268
	speed: 0.0864s/iter; left time: 908.6021s
Epoch: 11 cost time: 10.153743982315063
Epoch: 11, Steps: 118 Train Loss: 31.2075 (Forecasting Loss:0.3573 + XiCon Loss:3.0850 x Lambda(10.0)), Vali MSE Loss: 0.4072 Test MSE Loss: 0.3025
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9850025
	speed: 0.0875s/iter; left time: 910.4488s
Epoch: 12 cost time: 10.123739004135132
Epoch: 12, Steps: 118 Train Loss: 31.1521 (Forecasting Loss:0.3571 + XiCon Loss:3.0795 x Lambda(10.0)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.5784206
	speed: 0.0791s/iter; left time: 813.0345s
Epoch: 13 cost time: 9.220108985900879
Epoch: 13, Steps: 118 Train Loss: 31.0700 (Forecasting Loss:0.3572 + XiCon Loss:3.0713 x Lambda(10.0)), Vali MSE Loss: 0.4063 Test MSE Loss: 0.3024
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.2101307
	speed: 0.0748s/iter; left time: 760.5638s
Epoch: 14 cost time: 8.988457918167114
Epoch: 14, Steps: 118 Train Loss: 31.2510 (Forecasting Loss:0.3571 + XiCon Loss:3.0894 x Lambda(10.0)), Vali MSE Loss: 0.4070 Test MSE Loss: 0.3024
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.0384827
	speed: 0.0851s/iter; left time: 855.4157s
Epoch: 15 cost time: 10.251897811889648
Epoch: 15, Steps: 118 Train Loss: 31.2108 (Forecasting Loss:0.3573 + XiCon Loss:3.0854 x Lambda(10.0)), Vali MSE Loss: 0.4065 Test MSE Loss: 0.3024
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4729271
	speed: 0.0818s/iter; left time: 812.0679s
Epoch: 16 cost time: 9.891796588897705
Epoch: 16, Steps: 118 Train Loss: 31.1996 (Forecasting Loss:0.3572 + XiCon Loss:3.0842 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.3024
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.0708485
	speed: 0.0772s/iter; left time: 757.7604s
Epoch: 17 cost time: 9.243249654769897
Epoch: 17, Steps: 118 Train Loss: 31.2733 (Forecasting Loss:0.3571 + XiCon Loss:3.0916 x Lambda(10.0)), Vali MSE Loss: 0.4059 Test MSE Loss: 0.3024
Validation loss decreased (0.405984 --> 0.405872).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.2313976
	speed: 0.0877s/iter; left time: 850.7203s
Epoch: 18 cost time: 10.278117179870605
Epoch: 18, Steps: 118 Train Loss: 31.1608 (Forecasting Loss:0.3570 + XiCon Loss:3.0804 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.3024
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.3955116
	speed: 0.0883s/iter; left time: 846.0368s
Epoch: 19 cost time: 10.107439517974854
Epoch: 19, Steps: 118 Train Loss: 31.2083 (Forecasting Loss:0.3570 + XiCon Loss:3.0851 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.5167942
	speed: 0.0768s/iter; left time: 726.5817s
Epoch: 20 cost time: 9.265599727630615
Epoch: 20, Steps: 118 Train Loss: 31.3192 (Forecasting Loss:0.3572 + XiCon Loss:3.0962 x Lambda(10.0)), Vali MSE Loss: 0.4069 Test MSE Loss: 0.3024
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.0212879
	speed: 0.0760s/iter; left time: 710.2286s
Epoch: 21 cost time: 9.149235248565674
Epoch: 21, Steps: 118 Train Loss: 31.1770 (Forecasting Loss:0.3572 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 0.4065 Test MSE Loss: 0.3024
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.5802155
	speed: 0.0811s/iter; left time: 747.7536s
Epoch: 22 cost time: 9.64238452911377
Epoch: 22, Steps: 118 Train Loss: 31.3192 (Forecasting Loss:0.3574 + XiCon Loss:3.0962 x Lambda(10.0)), Vali MSE Loss: 0.4060 Test MSE Loss: 0.3024
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.6174431
	speed: 0.0794s/iter; left time: 722.9922s
Epoch: 23 cost time: 9.43892502784729
Epoch: 23, Steps: 118 Train Loss: 31.2915 (Forecasting Loss:0.3575 + XiCon Loss:3.0934 x Lambda(10.0)), Vali MSE Loss: 0.4068 Test MSE Loss: 0.3024
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.0008888
	speed: 0.0794s/iter; left time: 713.5877s
Epoch: 24 cost time: 9.288242816925049
Epoch: 24, Steps: 118 Train Loss: 31.3627 (Forecasting Loss:0.3574 + XiCon Loss:3.1005 x Lambda(10.0)), Vali MSE Loss: 0.4062 Test MSE Loss: 0.3024
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.7157898
	speed: 0.0808s/iter; left time: 716.2325s
Epoch: 25 cost time: 9.520663976669312
Epoch: 25, Steps: 118 Train Loss: 31.2373 (Forecasting Loss:0.3576 + XiCon Loss:3.0880 x Lambda(10.0)), Vali MSE Loss: 0.4064 Test MSE Loss: 0.3024
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.8734608
	speed: 0.0783s/iter; left time: 685.2289s
Epoch: 26 cost time: 9.203314542770386
Epoch: 26, Steps: 118 Train Loss: 31.1759 (Forecasting Loss:0.3571 + XiCon Loss:3.0819 x Lambda(10.0)), Vali MSE Loss: 0.4065 Test MSE Loss: 0.3024
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.7346706
	speed: 0.0766s/iter; left time: 660.8831s
Epoch: 27 cost time: 8.904939889907837
Epoch: 27, Steps: 118 Train Loss: 31.3152 (Forecasting Loss:0.3570 + XiCon Loss:3.0958 x Lambda(10.0)), Vali MSE Loss: 0.4061 Test MSE Loss: 0.3024
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.22415751218795776, mae:0.38073593378067017, mape:0.6358310580253601, mspe:14.425551414489746 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.4480
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.9652271
	speed: 0.0781s/iter; left time: 913.6538s
Epoch: 1 cost time: 9.261135816574097
Epoch: 1, Steps: 118 Train Loss: 31.3430 (Forecasting Loss:0.4096 + XiCon Loss:3.0933 x Lambda(10.0)), Vali MSE Loss: 0.4224 Test MSE Loss: 0.3113
Validation loss decreased (inf --> 0.422373).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.8748760
	speed: 0.0845s/iter; left time: 978.8268s
Epoch: 2 cost time: 9.875530481338501
Epoch: 2, Steps: 118 Train Loss: 30.0611 (Forecasting Loss:0.3828 + XiCon Loss:2.9678 x Lambda(10.0)), Vali MSE Loss: 0.4211 Test MSE Loss: 0.3186
Validation loss decreased (0.422373 --> 0.421147).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.7908096
	speed: 0.0791s/iter; left time: 907.3035s
Epoch: 3 cost time: 9.28217887878418
Epoch: 3, Steps: 118 Train Loss: 31.4843 (Forecasting Loss:0.3692 + XiCon Loss:3.1115 x Lambda(10.0)), Vali MSE Loss: 0.4022 Test MSE Loss: 0.3103
Validation loss decreased (0.421147 --> 0.402217).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2005196
	speed: 0.0894s/iter; left time: 1014.7678s
Epoch: 4 cost time: 10.327038764953613
Epoch: 4, Steps: 118 Train Loss: 31.8618 (Forecasting Loss:0.3617 + XiCon Loss:3.1500 x Lambda(10.0)), Vali MSE Loss: 0.4043 Test MSE Loss: 0.3083
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.2788658
	speed: 0.0808s/iter; left time: 906.9010s
Epoch: 5 cost time: 9.631726741790771
Epoch: 5, Steps: 118 Train Loss: 31.8391 (Forecasting Loss:0.3564 + XiCon Loss:3.1483 x Lambda(10.0)), Vali MSE Loss: 0.4034 Test MSE Loss: 0.3048
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5830421
	speed: 0.0828s/iter; left time: 919.9591s
Epoch: 6 cost time: 9.861404180526733
Epoch: 6, Steps: 118 Train Loss: 31.7007 (Forecasting Loss:0.3537 + XiCon Loss:3.1347 x Lambda(10.0)), Vali MSE Loss: 0.4044 Test MSE Loss: 0.3079
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.6589031
	speed: 0.0812s/iter; left time: 892.2159s
Epoch: 7 cost time: 9.608474016189575
Epoch: 7, Steps: 118 Train Loss: 31.6946 (Forecasting Loss:0.3524 + XiCon Loss:3.1342 x Lambda(10.0)), Vali MSE Loss: 0.4034 Test MSE Loss: 0.3073
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.2032471
	speed: 0.0801s/iter; left time: 871.0577s
Epoch: 8 cost time: 9.426372051239014
Epoch: 8, Steps: 118 Train Loss: 31.7453 (Forecasting Loss:0.3520 + XiCon Loss:3.1393 x Lambda(10.0)), Vali MSE Loss: 0.4039 Test MSE Loss: 0.3075
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.3589325
	speed: 0.0825s/iter; left time: 887.7415s
Epoch: 9 cost time: 9.615912437438965
Epoch: 9, Steps: 118 Train Loss: 31.6663 (Forecasting Loss:0.3515 + XiCon Loss:3.1315 x Lambda(10.0)), Vali MSE Loss: 0.4036 Test MSE Loss: 0.3067
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3099556
	speed: 0.0828s/iter; left time: 881.2651s
Epoch: 10 cost time: 9.877130031585693
Epoch: 10, Steps: 118 Train Loss: 31.7703 (Forecasting Loss:0.3509 + XiCon Loss:3.1419 x Lambda(10.0)), Vali MSE Loss: 0.4029 Test MSE Loss: 0.3065
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5569725
	speed: 0.0849s/iter; left time: 893.1790s
Epoch: 11 cost time: 10.142802000045776
Epoch: 11, Steps: 118 Train Loss: 31.7185 (Forecasting Loss:0.3511 + XiCon Loss:3.1367 x Lambda(10.0)), Vali MSE Loss: 0.4033 Test MSE Loss: 0.3064
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6203156
	speed: 0.0791s/iter; left time: 822.3815s
Epoch: 12 cost time: 9.486039161682129
Epoch: 12, Steps: 118 Train Loss: 31.6979 (Forecasting Loss:0.3506 + XiCon Loss:3.1347 x Lambda(10.0)), Vali MSE Loss: 0.4038 Test MSE Loss: 0.3063
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 32.1524162
	speed: 0.0915s/iter; left time: 941.4812s
Epoch: 13 cost time: 10.603403806686401
Epoch: 13, Steps: 118 Train Loss: 31.7334 (Forecasting Loss:0.3512 + XiCon Loss:3.1382 x Lambda(10.0)), Vali MSE Loss: 0.4030 Test MSE Loss: 0.3063
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.2324925661087036, mae:0.38803809881210327, mape:0.6513926982879639, mspe:15.706430435180664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:492225
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.4588
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 30.9070187
	speed: 0.0745s/iter; left time: 871.3608s
Epoch: 1 cost time: 8.927417755126953
Epoch: 1, Steps: 118 Train Loss: 31.2288 (Forecasting Loss:0.4093 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 0.4238 Test MSE Loss: 0.3173
Validation loss decreased (inf --> 0.423806).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8698006
	speed: 0.0779s/iter; left time: 902.7054s
Epoch: 2 cost time: 9.22214674949646
Epoch: 2, Steps: 118 Train Loss: 30.2109 (Forecasting Loss:0.3778 + XiCon Loss:2.9833 x Lambda(10.0)), Vali MSE Loss: 0.4121 Test MSE Loss: 0.3120
Validation loss decreased (0.423806 --> 0.412141).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.2394619
	speed: 0.0885s/iter; left time: 1014.5242s
Epoch: 3 cost time: 10.452118635177612
Epoch: 3, Steps: 118 Train Loss: 30.6282 (Forecasting Loss:0.3369 + XiCon Loss:3.0291 x Lambda(10.0)), Vali MSE Loss: 0.3888 Test MSE Loss: 0.2814
Validation loss decreased (0.412141 --> 0.388789).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2361755
	speed: 0.0935s/iter; left time: 1060.7977s
Epoch: 4 cost time: 10.847768545150757
Epoch: 4, Steps: 118 Train Loss: 30.0918 (Forecasting Loss:0.3231 + XiCon Loss:2.9769 x Lambda(10.0)), Vali MSE Loss: 0.3876 Test MSE Loss: 0.2775
Validation loss decreased (0.388789 --> 0.387576).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9510727
	speed: 0.0840s/iter; left time: 942.8159s
Epoch: 5 cost time: 9.863916635513306
Epoch: 5, Steps: 118 Train Loss: 29.6465 (Forecasting Loss:0.3159 + XiCon Loss:2.9331 x Lambda(10.0)), Vali MSE Loss: 0.3878 Test MSE Loss: 0.2767
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.0923977
	speed: 0.0920s/iter; left time: 1022.1696s
Epoch: 6 cost time: 10.748962640762329
Epoch: 6, Steps: 118 Train Loss: 29.5653 (Forecasting Loss:0.3107 + XiCon Loss:2.9255 x Lambda(10.0)), Vali MSE Loss: 0.3873 Test MSE Loss: 0.2742
Validation loss decreased (0.387576 --> 0.387261).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.1059551
	speed: 0.0889s/iter; left time: 977.5314s
Epoch: 7 cost time: 10.341570138931274
Epoch: 7, Steps: 118 Train Loss: 29.5788 (Forecasting Loss:0.3098 + XiCon Loss:2.9269 x Lambda(10.0)), Vali MSE Loss: 0.3857 Test MSE Loss: 0.2708
Validation loss decreased (0.387261 --> 0.385721).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.4298096
	speed: 0.0913s/iter; left time: 992.7036s
Epoch: 8 cost time: 10.601663589477539
Epoch: 8, Steps: 118 Train Loss: 29.5824 (Forecasting Loss:0.3082 + XiCon Loss:2.9274 x Lambda(10.0)), Vali MSE Loss: 0.3860 Test MSE Loss: 0.2714
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1119976
	speed: 0.0887s/iter; left time: 954.3770s
Epoch: 9 cost time: 10.372429132461548
Epoch: 9, Steps: 118 Train Loss: 29.5251 (Forecasting Loss:0.3085 + XiCon Loss:2.9217 x Lambda(10.0)), Vali MSE Loss: 0.3858 Test MSE Loss: 0.2709
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.2261181
	speed: 0.0834s/iter; left time: 887.7772s
Epoch: 10 cost time: 9.814380407333374
Epoch: 10, Steps: 118 Train Loss: 29.4681 (Forecasting Loss:0.3080 + XiCon Loss:2.9160 x Lambda(10.0)), Vali MSE Loss: 0.3866 Test MSE Loss: 0.2711
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.6173134
	speed: 0.0840s/iter; left time: 884.0234s
Epoch: 11 cost time: 10.038173198699951
Epoch: 11, Steps: 118 Train Loss: 29.5187 (Forecasting Loss:0.3062 + XiCon Loss:2.9213 x Lambda(10.0)), Vali MSE Loss: 0.3853 Test MSE Loss: 0.2711
Validation loss decreased (0.385721 --> 0.385292).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1524544
	speed: 0.0851s/iter; left time: 885.5976s
Epoch: 12 cost time: 9.940101623535156
Epoch: 12, Steps: 118 Train Loss: 29.6141 (Forecasting Loss:0.3076 + XiCon Loss:2.9307 x Lambda(10.0)), Vali MSE Loss: 0.3857 Test MSE Loss: 0.2712
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.7632179
	speed: 0.0835s/iter; left time: 858.3111s
Epoch: 13 cost time: 9.987218141555786
Epoch: 13, Steps: 118 Train Loss: 29.5817 (Forecasting Loss:0.3068 + XiCon Loss:2.9275 x Lambda(10.0)), Vali MSE Loss: 0.3858 Test MSE Loss: 0.2711
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.0568237
	speed: 0.0837s/iter; left time: 850.9761s
Epoch: 14 cost time: 9.933664560317993
Epoch: 14, Steps: 118 Train Loss: 29.5320 (Forecasting Loss:0.3079 + XiCon Loss:2.9224 x Lambda(10.0)), Vali MSE Loss: 0.3863 Test MSE Loss: 0.2711
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.9894943
	speed: 0.0914s/iter; left time: 918.5981s
Epoch: 15 cost time: 10.845825910568237
Epoch: 15, Steps: 118 Train Loss: 29.5749 (Forecasting Loss:0.3073 + XiCon Loss:2.9268 x Lambda(10.0)), Vali MSE Loss: 0.3870 Test MSE Loss: 0.2711
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.9558983
	speed: 0.0851s/iter; left time: 845.4315s
Epoch: 16 cost time: 9.978359699249268
Epoch: 16, Steps: 118 Train Loss: 29.5329 (Forecasting Loss:0.3069 + XiCon Loss:2.9226 x Lambda(10.0)), Vali MSE Loss: 0.3860 Test MSE Loss: 0.2711
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.8749771
	speed: 0.0868s/iter; left time: 852.0819s
Epoch: 17 cost time: 10.226720809936523
Epoch: 17, Steps: 118 Train Loss: 29.5208 (Forecasting Loss:0.3080 + XiCon Loss:2.9213 x Lambda(10.0)), Vali MSE Loss: 0.3866 Test MSE Loss: 0.2711
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.1023712
	speed: 0.0938s/iter; left time: 908.9329s
Epoch: 18 cost time: 11.135662317276001
Epoch: 18, Steps: 118 Train Loss: 29.5797 (Forecasting Loss:0.3067 + XiCon Loss:2.9273 x Lambda(10.0)), Vali MSE Loss: 0.3861 Test MSE Loss: 0.2711
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.1119270
	speed: 0.0915s/iter; left time: 876.1830s
Epoch: 19 cost time: 10.452826976776123
Epoch: 19, Steps: 118 Train Loss: 29.5020 (Forecasting Loss:0.3076 + XiCon Loss:2.9194 x Lambda(10.0)), Vali MSE Loss: 0.3863 Test MSE Loss: 0.2711
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.8760262
	speed: 0.1013s/iter; left time: 958.4055s
Epoch: 20 cost time: 11.771690607070923
Epoch: 20, Steps: 118 Train Loss: 29.6004 (Forecasting Loss:0.3077 + XiCon Loss:2.9293 x Lambda(10.0)), Vali MSE Loss: 0.3859 Test MSE Loss: 0.2711
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.3980198
	speed: 0.0668s/iter; left time: 623.5456s
Epoch: 21 cost time: 7.95756196975708
Epoch: 21, Steps: 118 Train Loss: 29.5777 (Forecasting Loss:0.3075 + XiCon Loss:2.9270 x Lambda(10.0)), Vali MSE Loss: 0.3863 Test MSE Loss: 0.2711
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18968376517295837, mae:0.35257214307785034, mape:0.6206664443016052, mspe:16.570514678955078 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2181+-0.02160, MAE:0.3755+-0.01764, MAPE:0.6373+-0.01411, MSPE:15.2795+-1.10163, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.3656
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.3571815
	speed: 0.0880s/iter; left time: 932.6328s
Epoch: 1 cost time: 9.341407775878906
Epoch: 1, Steps: 107 Train Loss: 31.6135 (Forecasting Loss:0.6400 + XiCon Loss:3.0973 x Lambda(10.0)), Vali MSE Loss: 0.6287 Test MSE Loss: 0.5074
Validation loss decreased (inf --> 0.628731).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.9969139
	speed: 0.0962s/iter; left time: 1009.1443s
Epoch: 2 cost time: 10.178505897521973
Epoch: 2, Steps: 107 Train Loss: 29.6643 (Forecasting Loss:0.5914 + XiCon Loss:2.9073 x Lambda(10.0)), Vali MSE Loss: 0.5646 Test MSE Loss: 0.4118
Validation loss decreased (0.628731 --> 0.564638).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.5546989
	speed: 0.0962s/iter; left time: 999.3502s
Epoch: 3 cost time: 10.369261980056763
Epoch: 3, Steps: 107 Train Loss: 29.5549 (Forecasting Loss:0.5716 + XiCon Loss:2.8983 x Lambda(10.0)), Vali MSE Loss: 0.5435 Test MSE Loss: 0.3973
Validation loss decreased (0.564638 --> 0.543510).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.1866512
	speed: 0.0985s/iter; left time: 1012.6021s
Epoch: 4 cost time: 10.656288862228394
Epoch: 4, Steps: 107 Train Loss: 31.1999 (Forecasting Loss:0.5514 + XiCon Loss:3.0649 x Lambda(10.0)), Vali MSE Loss: 0.5222 Test MSE Loss: 0.3905
Validation loss decreased (0.543510 --> 0.522247).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.4361954
	speed: 0.0961s/iter; left time: 977.1935s
Epoch: 5 cost time: 10.350165367126465
Epoch: 5, Steps: 107 Train Loss: 31.8320 (Forecasting Loss:0.5391 + XiCon Loss:3.1293 x Lambda(10.0)), Vali MSE Loss: 0.5225 Test MSE Loss: 0.3814
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.2807045
	speed: 0.0999s/iter; left time: 1006.0427s
Epoch: 6 cost time: 10.73934030532837
Epoch: 6, Steps: 107 Train Loss: 31.8866 (Forecasting Loss:0.5338 + XiCon Loss:3.1353 x Lambda(10.0)), Vali MSE Loss: 0.5196 Test MSE Loss: 0.3768
Validation loss decreased (0.522247 --> 0.519564).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2239590
	speed: 0.0973s/iter; left time: 968.7307s
Epoch: 7 cost time: 10.563157796859741
Epoch: 7, Steps: 107 Train Loss: 32.0047 (Forecasting Loss:0.5317 + XiCon Loss:3.1473 x Lambda(10.0)), Vali MSE Loss: 0.5190 Test MSE Loss: 0.3768
Validation loss decreased (0.519564 --> 0.518966).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.7752113
	speed: 0.0973s/iter; left time: 958.4365s
Epoch: 8 cost time: 10.52932620048523
Epoch: 8, Steps: 107 Train Loss: 32.1689 (Forecasting Loss:0.5293 + XiCon Loss:3.1640 x Lambda(10.0)), Vali MSE Loss: 0.5209 Test MSE Loss: 0.3767
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.9820461
	speed: 0.0977s/iter; left time: 952.5068s
Epoch: 9 cost time: 10.623568773269653
Epoch: 9, Steps: 107 Train Loss: 32.0948 (Forecasting Loss:0.5294 + XiCon Loss:3.1565 x Lambda(10.0)), Vali MSE Loss: 0.5209 Test MSE Loss: 0.3768
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.8649330
	speed: 0.0864s/iter; left time: 832.8510s
Epoch: 10 cost time: 9.271113634109497
Epoch: 10, Steps: 107 Train Loss: 32.0727 (Forecasting Loss:0.5285 + XiCon Loss:3.1544 x Lambda(10.0)), Vali MSE Loss: 0.5189 Test MSE Loss: 0.3761
Validation loss decreased (0.518966 --> 0.518920).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.4368896
	speed: 0.0982s/iter; left time: 936.0938s
Epoch: 11 cost time: 10.573952913284302
Epoch: 11, Steps: 107 Train Loss: 32.1981 (Forecasting Loss:0.5291 + XiCon Loss:3.1669 x Lambda(10.0)), Vali MSE Loss: 0.5189 Test MSE Loss: 0.3764
Validation loss decreased (0.518920 --> 0.518859).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.4746399
	speed: 0.0980s/iter; left time: 923.7523s
Epoch: 12 cost time: 10.590633869171143
Epoch: 12, Steps: 107 Train Loss: 32.1946 (Forecasting Loss:0.5289 + XiCon Loss:3.1666 x Lambda(10.0)), Vali MSE Loss: 0.5204 Test MSE Loss: 0.3765
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.8847771
	speed: 0.1045s/iter; left time: 973.6114s
Epoch: 13 cost time: 11.248567581176758
Epoch: 13, Steps: 107 Train Loss: 32.0411 (Forecasting Loss:0.5282 + XiCon Loss:3.1513 x Lambda(10.0)), Vali MSE Loss: 0.5191 Test MSE Loss: 0.3766
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.4510384
	speed: 0.0965s/iter; left time: 888.9316s
Epoch: 14 cost time: 10.411850690841675
Epoch: 14, Steps: 107 Train Loss: 31.8646 (Forecasting Loss:0.5282 + XiCon Loss:3.1336 x Lambda(10.0)), Vali MSE Loss: 0.5208 Test MSE Loss: 0.3766
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.1083603
	speed: 0.0987s/iter; left time: 898.7815s
Epoch: 15 cost time: 10.642128467559814
Epoch: 15, Steps: 107 Train Loss: 32.1081 (Forecasting Loss:0.5281 + XiCon Loss:3.1580 x Lambda(10.0)), Vali MSE Loss: 0.5193 Test MSE Loss: 0.3766
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 33.1560478
	speed: 0.1023s/iter; left time: 920.4893s
Epoch: 16 cost time: 11.124911308288574
Epoch: 16, Steps: 107 Train Loss: 32.0690 (Forecasting Loss:0.5282 + XiCon Loss:3.1541 x Lambda(10.0)), Vali MSE Loss: 0.5201 Test MSE Loss: 0.3766
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.5163403
	speed: 0.1007s/iter; left time: 895.3751s
Epoch: 17 cost time: 10.900076627731323
Epoch: 17, Steps: 107 Train Loss: 31.9720 (Forecasting Loss:0.5285 + XiCon Loss:3.1443 x Lambda(10.0)), Vali MSE Loss: 0.5205 Test MSE Loss: 0.3766
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.3017807
	speed: 0.0974s/iter; left time: 855.2091s
Epoch: 18 cost time: 10.50883150100708
Epoch: 18, Steps: 107 Train Loss: 32.1003 (Forecasting Loss:0.5284 + XiCon Loss:3.1572 x Lambda(10.0)), Vali MSE Loss: 0.5201 Test MSE Loss: 0.3766
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.0334244
	speed: 0.1018s/iter; left time: 883.1870s
Epoch: 19 cost time: 11.045950412750244
Epoch: 19, Steps: 107 Train Loss: 31.9806 (Forecasting Loss:0.5282 + XiCon Loss:3.1452 x Lambda(10.0)), Vali MSE Loss: 0.5200 Test MSE Loss: 0.3766
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.0035667
	speed: 0.1024s/iter; left time: 877.1704s
Epoch: 20 cost time: 10.991124153137207
Epoch: 20, Steps: 107 Train Loss: 32.0350 (Forecasting Loss:0.5287 + XiCon Loss:3.1506 x Lambda(10.0)), Vali MSE Loss: 0.5204 Test MSE Loss: 0.3766
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.0813904
	speed: 0.0989s/iter; left time: 837.0998s
Epoch: 21 cost time: 10.64315390586853
Epoch: 21, Steps: 107 Train Loss: 31.9053 (Forecasting Loss:0.5289 + XiCon Loss:3.1376 x Lambda(10.0)), Vali MSE Loss: 0.5191 Test MSE Loss: 0.3766
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.30808213353157043, mae:0.44466307759284973, mape:0.640977680683136, mspe:12.453367233276367 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2685
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 30.9230366
	speed: 0.0824s/iter; left time: 873.1176s
Epoch: 1 cost time: 8.835811376571655
Epoch: 1, Steps: 107 Train Loss: 31.4357 (Forecasting Loss:0.6183 + XiCon Loss:3.0817 x Lambda(10.0)), Vali MSE Loss: 0.5687 Test MSE Loss: 0.4374
Validation loss decreased (inf --> 0.568682).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.5404587
	speed: 0.0977s/iter; left time: 1025.5707s
Epoch: 2 cost time: 10.511565685272217
Epoch: 2, Steps: 107 Train Loss: 29.7699 (Forecasting Loss:0.5920 + XiCon Loss:2.9178 x Lambda(10.0)), Vali MSE Loss: 0.5739 Test MSE Loss: 0.4486
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.2941933
	speed: 0.1016s/iter; left time: 1055.3968s
Epoch: 3 cost time: 10.960544109344482
Epoch: 3, Steps: 107 Train Loss: 30.1009 (Forecasting Loss:0.5447 + XiCon Loss:2.9556 x Lambda(10.0)), Vali MSE Loss: 0.4579 Test MSE Loss: 0.3996
Validation loss decreased (0.568682 --> 0.457885).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7731895
	speed: 0.0962s/iter; left time: 989.0264s
Epoch: 4 cost time: 10.407311916351318
Epoch: 4, Steps: 107 Train Loss: 30.9422 (Forecasting Loss:0.5014 + XiCon Loss:3.0441 x Lambda(10.0)), Vali MSE Loss: 0.5028 Test MSE Loss: 0.3756
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9289513
	speed: 0.1020s/iter; left time: 1037.4209s
Epoch: 5 cost time: 10.867805242538452
Epoch: 5, Steps: 107 Train Loss: 30.4118 (Forecasting Loss:0.4812 + XiCon Loss:2.9931 x Lambda(10.0)), Vali MSE Loss: 0.5431 Test MSE Loss: 0.3401
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7385864
	speed: 0.1049s/iter; left time: 1056.3494s
Epoch: 6 cost time: 11.356675148010254
Epoch: 6, Steps: 107 Train Loss: 30.3064 (Forecasting Loss:0.4741 + XiCon Loss:2.9832 x Lambda(10.0)), Vali MSE Loss: 0.4984 Test MSE Loss: 0.3790
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0540943
	speed: 0.1018s/iter; left time: 1014.0527s
Epoch: 7 cost time: 11.01253628730774
Epoch: 7, Steps: 107 Train Loss: 30.4050 (Forecasting Loss:0.4635 + XiCon Loss:2.9942 x Lambda(10.0)), Vali MSE Loss: 0.4882 Test MSE Loss: 0.3712
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5710812
	speed: 0.1028s/iter; left time: 1012.9732s
Epoch: 8 cost time: 11.008942127227783
Epoch: 8, Steps: 107 Train Loss: 30.2759 (Forecasting Loss:0.4639 + XiCon Loss:2.9812 x Lambda(10.0)), Vali MSE Loss: 0.4860 Test MSE Loss: 0.3935
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0630226
	speed: 0.1023s/iter; left time: 997.3382s
Epoch: 9 cost time: 11.002958297729492
Epoch: 9, Steps: 107 Train Loss: 30.3176 (Forecasting Loss:0.4588 + XiCon Loss:2.9859 x Lambda(10.0)), Vali MSE Loss: 0.4826 Test MSE Loss: 0.3768
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.6943436
	speed: 0.1032s/iter; left time: 994.5235s
Epoch: 10 cost time: 11.074666261672974
Epoch: 10, Steps: 107 Train Loss: 30.2116 (Forecasting Loss:0.4593 + XiCon Loss:2.9752 x Lambda(10.0)), Vali MSE Loss: 0.4865 Test MSE Loss: 0.3836
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5920563
	speed: 0.1006s/iter; left time: 958.4736s
Epoch: 11 cost time: 10.808300495147705
Epoch: 11, Steps: 107 Train Loss: 30.1604 (Forecasting Loss:0.4568 + XiCon Loss:2.9704 x Lambda(10.0)), Vali MSE Loss: 0.4831 Test MSE Loss: 0.3803
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.6207371
	speed: 0.1007s/iter; left time: 949.0020s
Epoch: 12 cost time: 10.85740351676941
Epoch: 12, Steps: 107 Train Loss: 30.2498 (Forecasting Loss:0.4569 + XiCon Loss:2.9793 x Lambda(10.0)), Vali MSE Loss: 0.4829 Test MSE Loss: 0.3775
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5782356
	speed: 0.0993s/iter; left time: 925.0996s
Epoch: 13 cost time: 10.822738409042358
Epoch: 13, Steps: 107 Train Loss: 30.2217 (Forecasting Loss:0.4572 + XiCon Loss:2.9765 x Lambda(10.0)), Vali MSE Loss: 0.4849 Test MSE Loss: 0.3775
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.3345775604248047, mae:0.4646516740322113, mape:0.6613980531692505, mspe:12.409405708312988 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2503
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.0868664
	speed: 0.0909s/iter; left time: 963.2153s
Epoch: 1 cost time: 9.801918983459473
Epoch: 1, Steps: 107 Train Loss: 31.4735 (Forecasting Loss:0.6164 + XiCon Loss:3.0857 x Lambda(10.0)), Vali MSE Loss: 0.5767 Test MSE Loss: 0.4396
Validation loss decreased (inf --> 0.576720).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.3461761
	speed: 0.0953s/iter; left time: 999.7738s
Epoch: 2 cost time: 10.281975507736206
Epoch: 2, Steps: 107 Train Loss: 29.7334 (Forecasting Loss:0.6064 + XiCon Loss:2.9127 x Lambda(10.0)), Vali MSE Loss: 0.5469 Test MSE Loss: 0.4067
Validation loss decreased (0.576720 --> 0.546885).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.2016830
	speed: 0.1005s/iter; left time: 1043.4886s
Epoch: 3 cost time: 10.755540132522583
Epoch: 3, Steps: 107 Train Loss: 29.5332 (Forecasting Loss:0.5730 + XiCon Loss:2.8960 x Lambda(10.0)), Vali MSE Loss: 0.5750 Test MSE Loss: 0.4171
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.9754429
	speed: 0.0963s/iter; left time: 990.0843s
Epoch: 4 cost time: 10.382506132125854
Epoch: 4, Steps: 107 Train Loss: 29.9999 (Forecasting Loss:0.5684 + XiCon Loss:2.9432 x Lambda(10.0)), Vali MSE Loss: 0.5443 Test MSE Loss: 0.4074
Validation loss decreased (0.546885 --> 0.544285).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.5081711
	speed: 0.0966s/iter; left time: 982.3508s
Epoch: 5 cost time: 10.363643884658813
Epoch: 5, Steps: 107 Train Loss: 30.7732 (Forecasting Loss:0.5645 + XiCon Loss:3.0209 x Lambda(10.0)), Vali MSE Loss: 0.5520 Test MSE Loss: 0.4035
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.9036255
	speed: 0.0991s/iter; left time: 997.7395s
Epoch: 6 cost time: 10.62014889717102
Epoch: 6, Steps: 107 Train Loss: 31.0598 (Forecasting Loss:0.5623 + XiCon Loss:3.0498 x Lambda(10.0)), Vali MSE Loss: 0.5490 Test MSE Loss: 0.4053
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.5536652
	speed: 0.1012s/iter; left time: 1007.4294s
Epoch: 7 cost time: 10.849942207336426
Epoch: 7, Steps: 107 Train Loss: 31.2744 (Forecasting Loss:0.5608 + XiCon Loss:3.0714 x Lambda(10.0)), Vali MSE Loss: 0.5482 Test MSE Loss: 0.4052
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5576992
	speed: 0.0980s/iter; left time: 965.5181s
Epoch: 8 cost time: 10.550685405731201
Epoch: 8, Steps: 107 Train Loss: 31.3853 (Forecasting Loss:0.5604 + XiCon Loss:3.0825 x Lambda(10.0)), Vali MSE Loss: 0.5485 Test MSE Loss: 0.4038
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.0292816
	speed: 0.0950s/iter; left time: 925.7028s
Epoch: 9 cost time: 10.162900924682617
Epoch: 9, Steps: 107 Train Loss: 31.3484 (Forecasting Loss:0.5596 + XiCon Loss:3.0789 x Lambda(10.0)), Vali MSE Loss: 0.5478 Test MSE Loss: 0.4035
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.2074165
	speed: 0.0997s/iter; left time: 961.2460s
Epoch: 10 cost time: 10.761936664581299
Epoch: 10, Steps: 107 Train Loss: 31.3060 (Forecasting Loss:0.5598 + XiCon Loss:3.0746 x Lambda(10.0)), Vali MSE Loss: 0.5477 Test MSE Loss: 0.4040
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.9189034
	speed: 0.1025s/iter; left time: 977.2857s
Epoch: 11 cost time: 11.026595830917358
Epoch: 11, Steps: 107 Train Loss: 31.3592 (Forecasting Loss:0.5592 + XiCon Loss:3.0800 x Lambda(10.0)), Vali MSE Loss: 0.5474 Test MSE Loss: 0.4038
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5813141
	speed: 0.0980s/iter; left time: 923.1647s
Epoch: 12 cost time: 10.436272382736206
Epoch: 12, Steps: 107 Train Loss: 31.2722 (Forecasting Loss:0.5595 + XiCon Loss:3.0713 x Lambda(10.0)), Vali MSE Loss: 0.5473 Test MSE Loss: 0.4039
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5435562
	speed: 0.0965s/iter; left time: 899.2358s
Epoch: 13 cost time: 10.442078113555908
Epoch: 13, Steps: 107 Train Loss: 31.3501 (Forecasting Loss:0.5595 + XiCon Loss:3.0791 x Lambda(10.0)), Vali MSE Loss: 0.5473 Test MSE Loss: 0.4039
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6994781
	speed: 0.1034s/iter; left time: 951.8896s
Epoch: 14 cost time: 11.087258100509644
Epoch: 14, Steps: 107 Train Loss: 31.2584 (Forecasting Loss:0.5594 + XiCon Loss:3.0699 x Lambda(10.0)), Vali MSE Loss: 0.5461 Test MSE Loss: 0.4039
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.34368419647216797, mae:0.47113871574401855, mape:0.6652969717979431, mspe:11.630392074584961 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2455
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.2121487
	speed: 0.0906s/iter; left time: 960.8857s
Epoch: 1 cost time: 9.728403568267822
Epoch: 1, Steps: 107 Train Loss: 31.5479 (Forecasting Loss:0.6190 + XiCon Loss:3.0929 x Lambda(10.0)), Vali MSE Loss: 0.5615 Test MSE Loss: 0.4292
Validation loss decreased (inf --> 0.561549).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1505260
	speed: 0.1002s/iter; left time: 1051.1629s
Epoch: 2 cost time: 10.798956871032715
Epoch: 2, Steps: 107 Train Loss: 30.4690 (Forecasting Loss:0.5805 + XiCon Loss:2.9889 x Lambda(10.0)), Vali MSE Loss: 0.6572 Test MSE Loss: 0.3865
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6534996
	speed: 0.1012s/iter; left time: 1050.6738s
Epoch: 3 cost time: 10.816580533981323
Epoch: 3, Steps: 107 Train Loss: 31.1356 (Forecasting Loss:0.5236 + XiCon Loss:3.0612 x Lambda(10.0)), Vali MSE Loss: 0.5497 Test MSE Loss: 0.3352
Validation loss decreased (0.561549 --> 0.549680).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.4523888
	speed: 0.0945s/iter; left time: 971.4640s
Epoch: 4 cost time: 10.124269247055054
Epoch: 4, Steps: 107 Train Loss: 30.5793 (Forecasting Loss:0.4282 + XiCon Loss:3.0151 x Lambda(10.0)), Vali MSE Loss: 0.5766 Test MSE Loss: 0.2875
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.4908276
	speed: 0.0946s/iter; left time: 962.8362s
Epoch: 5 cost time: 10.161048650741577
Epoch: 5, Steps: 107 Train Loss: 30.1943 (Forecasting Loss:0.3866 + XiCon Loss:2.9808 x Lambda(10.0)), Vali MSE Loss: 0.5235 Test MSE Loss: 0.2801
Validation loss decreased (0.549680 --> 0.523533).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6708508
	speed: 0.0889s/iter; left time: 894.6289s
Epoch: 6 cost time: 9.541865110397339
Epoch: 6, Steps: 107 Train Loss: 29.8741 (Forecasting Loss:0.3726 + XiCon Loss:2.9502 x Lambda(10.0)), Vali MSE Loss: 0.5088 Test MSE Loss: 0.2776
Validation loss decreased (0.523533 --> 0.508838).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.4593716
	speed: 0.0929s/iter; left time: 925.2119s
Epoch: 7 cost time: 9.99630856513977
Epoch: 7, Steps: 107 Train Loss: 29.8522 (Forecasting Loss:0.3668 + XiCon Loss:2.9485 x Lambda(10.0)), Vali MSE Loss: 0.4883 Test MSE Loss: 0.2742
Validation loss decreased (0.508838 --> 0.488261).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0761147
	speed: 0.0889s/iter; left time: 875.5757s
Epoch: 8 cost time: 9.612835168838501
Epoch: 8, Steps: 107 Train Loss: 29.9060 (Forecasting Loss:0.3638 + XiCon Loss:2.9542 x Lambda(10.0)), Vali MSE Loss: 0.5007 Test MSE Loss: 0.2739
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4369240
	speed: 0.0915s/iter; left time: 892.1021s
Epoch: 9 cost time: 9.828419923782349
Epoch: 9, Steps: 107 Train Loss: 29.8302 (Forecasting Loss:0.3630 + XiCon Loss:2.9467 x Lambda(10.0)), Vali MSE Loss: 0.4926 Test MSE Loss: 0.2736
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.0210018
	speed: 0.0886s/iter; left time: 854.2119s
Epoch: 10 cost time: 9.507408618927002
Epoch: 10, Steps: 107 Train Loss: 29.8721 (Forecasting Loss:0.3630 + XiCon Loss:2.9509 x Lambda(10.0)), Vali MSE Loss: 0.4959 Test MSE Loss: 0.2737
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2516727
	speed: 0.0889s/iter; left time: 847.1960s
Epoch: 11 cost time: 9.61409306526184
Epoch: 11, Steps: 107 Train Loss: 29.8604 (Forecasting Loss:0.3637 + XiCon Loss:2.9497 x Lambda(10.0)), Vali MSE Loss: 0.4972 Test MSE Loss: 0.2735
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.4166603
	speed: 0.0955s/iter; left time: 900.1533s
Epoch: 12 cost time: 10.091758489608765
Epoch: 12, Steps: 107 Train Loss: 29.8269 (Forecasting Loss:0.3623 + XiCon Loss:2.9465 x Lambda(10.0)), Vali MSE Loss: 0.4958 Test MSE Loss: 0.2734
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2501869
	speed: 0.0879s/iter; left time: 818.8369s
Epoch: 13 cost time: 9.462305784225464
Epoch: 13, Steps: 107 Train Loss: 29.8416 (Forecasting Loss:0.3635 + XiCon Loss:2.9478 x Lambda(10.0)), Vali MSE Loss: 0.4967 Test MSE Loss: 0.2734
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.3720703
	speed: 0.0879s/iter; left time: 809.7781s
Epoch: 14 cost time: 9.583708047866821
Epoch: 14, Steps: 107 Train Loss: 29.7955 (Forecasting Loss:0.3633 + XiCon Loss:2.9432 x Lambda(10.0)), Vali MSE Loss: 0.4942 Test MSE Loss: 0.2734
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4750175
	speed: 0.0894s/iter; left time: 813.7404s
Epoch: 15 cost time: 9.650720596313477
Epoch: 15, Steps: 107 Train Loss: 29.8210 (Forecasting Loss:0.3628 + XiCon Loss:2.9458 x Lambda(10.0)), Vali MSE Loss: 0.4954 Test MSE Loss: 0.2734
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.2663460
	speed: 0.0945s/iter; left time: 850.5053s
Epoch: 16 cost time: 10.188234806060791
Epoch: 16, Steps: 107 Train Loss: 29.8400 (Forecasting Loss:0.3630 + XiCon Loss:2.9477 x Lambda(10.0)), Vali MSE Loss: 0.4971 Test MSE Loss: 0.2734
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6599693
	speed: 0.0924s/iter; left time: 821.3860s
Epoch: 17 cost time: 9.814955949783325
Epoch: 17, Steps: 107 Train Loss: 29.8810 (Forecasting Loss:0.3629 + XiCon Loss:2.9518 x Lambda(10.0)), Vali MSE Loss: 0.4945 Test MSE Loss: 0.2734
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.19144584238529205, mae:0.35704702138900757, mape:0.6130213737487793, mspe:16.073278427124023 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:977505
train 6865
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2386
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6865
val 1441
test 1441
	iters: 100, epoch: 1 | loss: 31.1706715
	speed: 0.0861s/iter; left time: 912.6202s
Epoch: 1 cost time: 9.244538068771362
Epoch: 1, Steps: 107 Train Loss: 31.6189 (Forecasting Loss:0.6213 + XiCon Loss:3.0998 x Lambda(10.0)), Vali MSE Loss: 0.5868 Test MSE Loss: 0.4540
Validation loss decreased (inf --> 0.586776).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9018555
	speed: 0.1115s/iter; left time: 1169.9314s
Epoch: 2 cost time: 12.016770124435425
Epoch: 2, Steps: 107 Train Loss: 29.8232 (Forecasting Loss:0.5844 + XiCon Loss:2.9239 x Lambda(10.0)), Vali MSE Loss: 0.5540 Test MSE Loss: 0.4052
Validation loss decreased (0.586776 --> 0.554006).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0173759
	speed: 0.1077s/iter; left time: 1119.0354s
Epoch: 3 cost time: 11.569094181060791
Epoch: 3, Steps: 107 Train Loss: 30.8476 (Forecasting Loss:0.5601 + XiCon Loss:3.0287 x Lambda(10.0)), Vali MSE Loss: 0.5894 Test MSE Loss: 0.3877
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2513733
	speed: 0.1013s/iter; left time: 1040.9216s
Epoch: 4 cost time: 10.892529249191284
Epoch: 4, Steps: 107 Train Loss: 30.3208 (Forecasting Loss:0.5548 + XiCon Loss:2.9766 x Lambda(10.0)), Vali MSE Loss: 0.5774 Test MSE Loss: 0.3594
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.3947411
	speed: 0.1032s/iter; left time: 1049.5940s
Epoch: 5 cost time: 10.980018615722656
Epoch: 5, Steps: 107 Train Loss: 30.0305 (Forecasting Loss:0.5345 + XiCon Loss:2.9496 x Lambda(10.0)), Vali MSE Loss: 0.5443 Test MSE Loss: 0.3295
Validation loss decreased (0.554006 --> 0.544310).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.2727051
	speed: 0.0948s/iter; left time: 954.0148s
Epoch: 6 cost time: 10.234857559204102
Epoch: 6, Steps: 107 Train Loss: 29.9967 (Forecasting Loss:0.5030 + XiCon Loss:2.9494 x Lambda(10.0)), Vali MSE Loss: 0.5255 Test MSE Loss: 0.3240
Validation loss decreased (0.544310 --> 0.525505).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6584606
	speed: 0.1001s/iter; left time: 996.5959s
Epoch: 7 cost time: 10.81208610534668
Epoch: 7, Steps: 107 Train Loss: 29.8641 (Forecasting Loss:0.4872 + XiCon Loss:2.9377 x Lambda(10.0)), Vali MSE Loss: 0.5309 Test MSE Loss: 0.3186
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.7437782
	speed: 0.0968s/iter; left time: 953.8321s
Epoch: 8 cost time: 10.333655834197998
Epoch: 8, Steps: 107 Train Loss: 29.8179 (Forecasting Loss:0.4790 + XiCon Loss:2.9339 x Lambda(10.0)), Vali MSE Loss: 0.5108 Test MSE Loss: 0.3176
Validation loss decreased (0.525505 --> 0.510850).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5443211
	speed: 0.0924s/iter; left time: 900.4192s
Epoch: 9 cost time: 9.995168447494507
Epoch: 9, Steps: 107 Train Loss: 29.8065 (Forecasting Loss:0.4764 + XiCon Loss:2.9330 x Lambda(10.0)), Vali MSE Loss: 0.5097 Test MSE Loss: 0.3176
Validation loss decreased (0.510850 --> 0.509690).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2017975
	speed: 0.0998s/iter; left time: 962.0285s
Epoch: 10 cost time: 10.723021984100342
Epoch: 10, Steps: 107 Train Loss: 29.8737 (Forecasting Loss:0.4737 + XiCon Loss:2.9400 x Lambda(10.0)), Vali MSE Loss: 0.5109 Test MSE Loss: 0.3173
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2345505
	speed: 0.0950s/iter; left time: 905.7216s
Epoch: 11 cost time: 10.272711277008057
Epoch: 11, Steps: 107 Train Loss: 29.8891 (Forecasting Loss:0.4723 + XiCon Loss:2.9417 x Lambda(10.0)), Vali MSE Loss: 0.5110 Test MSE Loss: 0.3173
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9035950
	speed: 0.0937s/iter; left time: 882.8889s
Epoch: 12 cost time: 10.121616840362549
Epoch: 12, Steps: 107 Train Loss: 29.8900 (Forecasting Loss:0.4718 + XiCon Loss:2.9418 x Lambda(10.0)), Vali MSE Loss: 0.5115 Test MSE Loss: 0.3172
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6244659
	speed: 0.0955s/iter; left time: 890.2266s
Epoch: 13 cost time: 10.454102516174316
Epoch: 13, Steps: 107 Train Loss: 29.8903 (Forecasting Loss:0.4726 + XiCon Loss:2.9418 x Lambda(10.0)), Vali MSE Loss: 0.5110 Test MSE Loss: 0.3172
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.9947491
	speed: 0.0917s/iter; left time: 844.5659s
Epoch: 14 cost time: 9.937638759613037
Epoch: 14, Steps: 107 Train Loss: 29.8893 (Forecasting Loss:0.4739 + XiCon Loss:2.9415 x Lambda(10.0)), Vali MSE Loss: 0.5112 Test MSE Loss: 0.3172
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5673008
	speed: 0.0948s/iter; left time: 863.3281s
Epoch: 15 cost time: 10.2920560836792
Epoch: 15, Steps: 107 Train Loss: 29.7926 (Forecasting Loss:0.4725 + XiCon Loss:2.9320 x Lambda(10.0)), Vali MSE Loss: 0.5104 Test MSE Loss: 0.3171
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0206203
	speed: 0.0942s/iter; left time: 847.5521s
Epoch: 16 cost time: 10.0545072555542
Epoch: 16, Steps: 107 Train Loss: 29.8070 (Forecasting Loss:0.4703 + XiCon Loss:2.9337 x Lambda(10.0)), Vali MSE Loss: 0.5116 Test MSE Loss: 0.3171
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.6998711
	speed: 0.0977s/iter; left time: 868.5342s
Epoch: 17 cost time: 10.447965383529663
Epoch: 17, Steps: 107 Train Loss: 29.8414 (Forecasting Loss:0.4728 + XiCon Loss:2.9369 x Lambda(10.0)), Vali MSE Loss: 0.5118 Test MSE Loss: 0.3171
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6667843
	speed: 0.1006s/iter; left time: 883.3673s
Epoch: 18 cost time: 10.87368392944336
Epoch: 18, Steps: 107 Train Loss: 29.7705 (Forecasting Loss:0.4729 + XiCon Loss:2.9298 x Lambda(10.0)), Vali MSE Loss: 0.5109 Test MSE Loss: 0.3171
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8217602
	speed: 0.0984s/iter; left time: 853.7002s
Epoch: 19 cost time: 10.555333375930786
Epoch: 19, Steps: 107 Train Loss: 29.9088 (Forecasting Loss:0.4729 + XiCon Loss:2.9436 x Lambda(10.0)), Vali MSE Loss: 0.5117 Test MSE Loss: 0.3171
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl1440_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1441
test shape: (22, 64, 1440, 1) (22, 64, 1440, 1)
test shape: (1408, 1440, 1) (1408, 1440, 1)
mse:0.24024875462055206, mae:0.39498329162597656, mape:0.6316311955451965, mspe:15.769801139831543 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2836+-0.08137, MAE:0.4265+-0.06081, MAPE:0.6425+-0.02682, MSPE:13.6672+-2.59075, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.6443
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 8.545690774917603
Epoch: 1, Steps: 96 Train Loss: 32.6216 (Forecasting Loss:0.9781 + XiCon Loss:3.1644 x Lambda(10.0)), Vali MSE Loss: 0.6710 Test MSE Loss: 0.9603
Validation loss decreased (inf --> 0.671000).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 8.200709342956543
Epoch: 2, Steps: 96 Train Loss: 31.6692 (Forecasting Loss:0.8078 + XiCon Loss:3.0861 x Lambda(10.0)), Vali MSE Loss: 0.6328 Test MSE Loss: 0.4933
Validation loss decreased (0.671000 --> 0.632831).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.484938859939575
Epoch: 3, Steps: 96 Train Loss: 30.7458 (Forecasting Loss:0.7851 + XiCon Loss:2.9961 x Lambda(10.0)), Vali MSE Loss: 0.6280 Test MSE Loss: 0.4735
Validation loss decreased (0.632831 --> 0.628041).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 8.163636684417725
Epoch: 4, Steps: 96 Train Loss: 30.5022 (Forecasting Loss:0.7778 + XiCon Loss:2.9724 x Lambda(10.0)), Vali MSE Loss: 0.6547 Test MSE Loss: 0.5191
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.894144773483276
Epoch: 5, Steps: 96 Train Loss: 30.4212 (Forecasting Loss:0.7715 + XiCon Loss:2.9650 x Lambda(10.0)), Vali MSE Loss: 0.6495 Test MSE Loss: 0.5038
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.654759883880615
Epoch: 6, Steps: 96 Train Loss: 30.3742 (Forecasting Loss:0.7681 + XiCon Loss:2.9606 x Lambda(10.0)), Vali MSE Loss: 0.6389 Test MSE Loss: 0.4646
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 8.247663021087646
Epoch: 7, Steps: 96 Train Loss: 30.3563 (Forecasting Loss:0.7644 + XiCon Loss:2.9592 x Lambda(10.0)), Vali MSE Loss: 0.6360 Test MSE Loss: 0.4615
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.985893726348877
Epoch: 8, Steps: 96 Train Loss: 30.3295 (Forecasting Loss:0.7633 + XiCon Loss:2.9566 x Lambda(10.0)), Vali MSE Loss: 0.6324 Test MSE Loss: 0.4562
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.9490156173706055
Epoch: 9, Steps: 96 Train Loss: 30.3327 (Forecasting Loss:0.7624 + XiCon Loss:2.9570 x Lambda(10.0)), Vali MSE Loss: 0.6340 Test MSE Loss: 0.4576
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.7228922843933105
Epoch: 10, Steps: 96 Train Loss: 30.3223 (Forecasting Loss:0.7615 + XiCon Loss:2.9561 x Lambda(10.0)), Vali MSE Loss: 0.6347 Test MSE Loss: 0.4558
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.72479510307312
Epoch: 11, Steps: 96 Train Loss: 30.3339 (Forecasting Loss:0.7614 + XiCon Loss:2.9572 x Lambda(10.0)), Vali MSE Loss: 0.6353 Test MSE Loss: 0.4558
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 8.4648916721344
Epoch: 12, Steps: 96 Train Loss: 30.3291 (Forecasting Loss:0.7622 + XiCon Loss:2.9567 x Lambda(10.0)), Vali MSE Loss: 0.6336 Test MSE Loss: 0.4552
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 8.262207746505737
Epoch: 13, Steps: 96 Train Loss: 30.3250 (Forecasting Loss:0.7611 + XiCon Loss:2.9564 x Lambda(10.0)), Vali MSE Loss: 0.6363 Test MSE Loss: 0.4555
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.4200531542301178, mae:0.5270364880561829, mape:0.6272169351577759, mspe:5.699617385864258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.3163
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 7.671255588531494
Epoch: 1, Steps: 96 Train Loss: 32.6289 (Forecasting Loss:0.9578 + XiCon Loss:3.1671 x Lambda(10.0)), Vali MSE Loss: 0.6732 Test MSE Loss: 0.9628
Validation loss decreased (inf --> 0.673240).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 8.102825403213501
Epoch: 2, Steps: 96 Train Loss: 31.7478 (Forecasting Loss:0.8483 + XiCon Loss:3.0900 x Lambda(10.0)), Vali MSE Loss: 0.7211 Test MSE Loss: 0.7558
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.613586664199829
Epoch: 3, Steps: 96 Train Loss: 30.8624 (Forecasting Loss:0.8085 + XiCon Loss:3.0054 x Lambda(10.0)), Vali MSE Loss: 0.7234 Test MSE Loss: 0.7211
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.685803413391113
Epoch: 4, Steps: 96 Train Loss: 30.5816 (Forecasting Loss:0.7968 + XiCon Loss:2.9785 x Lambda(10.0)), Vali MSE Loss: 0.7125 Test MSE Loss: 0.7146
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 8.13739013671875
Epoch: 5, Steps: 96 Train Loss: 30.4681 (Forecasting Loss:0.7894 + XiCon Loss:2.9679 x Lambda(10.0)), Vali MSE Loss: 0.7164 Test MSE Loss: 0.7121
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.184131860733032
Epoch: 6, Steps: 96 Train Loss: 30.4190 (Forecasting Loss:0.7854 + XiCon Loss:2.9634 x Lambda(10.0)), Vali MSE Loss: 0.7132 Test MSE Loss: 0.7125
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.542098760604858
Epoch: 7, Steps: 96 Train Loss: 30.4022 (Forecasting Loss:0.7834 + XiCon Loss:2.9619 x Lambda(10.0)), Vali MSE Loss: 0.7148 Test MSE Loss: 0.7126
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.616957426071167
Epoch: 8, Steps: 96 Train Loss: 30.3879 (Forecasting Loss:0.7823 + XiCon Loss:2.9606 x Lambda(10.0)), Vali MSE Loss: 0.7141 Test MSE Loss: 0.7129
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 8.276265144348145
Epoch: 9, Steps: 96 Train Loss: 30.3896 (Forecasting Loss:0.7819 + XiCon Loss:2.9608 x Lambda(10.0)), Vali MSE Loss: 0.7137 Test MSE Loss: 0.7129
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.451587677001953
Epoch: 10, Steps: 96 Train Loss: 30.3824 (Forecasting Loss:0.7816 + XiCon Loss:2.9601 x Lambda(10.0)), Vali MSE Loss: 0.7157 Test MSE Loss: 0.7129
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 7.658825159072876
Epoch: 11, Steps: 96 Train Loss: 30.3863 (Forecasting Loss:0.7817 + XiCon Loss:2.9605 x Lambda(10.0)), Vali MSE Loss: 0.7146 Test MSE Loss: 0.7127
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:1.0408953428268433, mae:0.88463294506073, mape:0.8970850110054016, mspe:5.3258056640625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2768
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 8.024141550064087
Epoch: 1, Steps: 96 Train Loss: 32.5221 (Forecasting Loss:0.9492 + XiCon Loss:3.1573 x Lambda(10.0)), Vali MSE Loss: 0.6741 Test MSE Loss: 0.9461
Validation loss decreased (inf --> 0.674139).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.675272703170776
Epoch: 2, Steps: 96 Train Loss: 31.5094 (Forecasting Loss:0.8317 + XiCon Loss:3.0678 x Lambda(10.0)), Vali MSE Loss: 0.6224 Test MSE Loss: 0.6062
Validation loss decreased (0.674139 --> 0.622387).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.963562250137329
Epoch: 3, Steps: 96 Train Loss: 30.5341 (Forecasting Loss:0.7774 + XiCon Loss:2.9757 x Lambda(10.0)), Vali MSE Loss: 0.6025 Test MSE Loss: 0.6210
Validation loss decreased (0.622387 --> 0.602495).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 10.133539915084839
Epoch: 4, Steps: 96 Train Loss: 30.3184 (Forecasting Loss:0.7357 + XiCon Loss:2.9583 x Lambda(10.0)), Vali MSE Loss: 0.6170 Test MSE Loss: 0.5783
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 9.593685388565063
Epoch: 5, Steps: 96 Train Loss: 30.2411 (Forecasting Loss:0.6982 + XiCon Loss:2.9543 x Lambda(10.0)), Vali MSE Loss: 0.5926 Test MSE Loss: 0.5023
Validation loss decreased (0.602495 --> 0.592550).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 6.685873746871948
Epoch: 6, Steps: 96 Train Loss: 30.1720 (Forecasting Loss:0.6728 + XiCon Loss:2.9499 x Lambda(10.0)), Vali MSE Loss: 0.5798 Test MSE Loss: 0.4447
Validation loss decreased (0.592550 --> 0.579834).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.736944913864136
Epoch: 7, Steps: 96 Train Loss: 30.1507 (Forecasting Loss:0.6663 + XiCon Loss:2.9484 x Lambda(10.0)), Vali MSE Loss: 0.5970 Test MSE Loss: 0.4681
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 8.000985145568848
Epoch: 8, Steps: 96 Train Loss: 30.1428 (Forecasting Loss:0.6592 + XiCon Loss:2.9484 x Lambda(10.0)), Vali MSE Loss: 0.5962 Test MSE Loss: 0.4668
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 7.790414571762085
Epoch: 9, Steps: 96 Train Loss: 30.1520 (Forecasting Loss:0.6605 + XiCon Loss:2.9491 x Lambda(10.0)), Vali MSE Loss: 0.5890 Test MSE Loss: 0.4565
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 7.705050230026245
Epoch: 10, Steps: 96 Train Loss: 30.1198 (Forecasting Loss:0.6584 + XiCon Loss:2.9461 x Lambda(10.0)), Vali MSE Loss: 0.5921 Test MSE Loss: 0.4591
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 8.672841548919678
Epoch: 11, Steps: 96 Train Loss: 30.1345 (Forecasting Loss:0.6594 + XiCon Loss:2.9475 x Lambda(10.0)), Vali MSE Loss: 0.5941 Test MSE Loss: 0.4598
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 7.97650671005249
Epoch: 12, Steps: 96 Train Loss: 30.1343 (Forecasting Loss:0.6586 + XiCon Loss:2.9476 x Lambda(10.0)), Vali MSE Loss: 0.5946 Test MSE Loss: 0.4585
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 8.156892538070679
Epoch: 13, Steps: 96 Train Loss: 30.1478 (Forecasting Loss:0.6558 + XiCon Loss:2.9492 x Lambda(10.0)), Vali MSE Loss: 0.5931 Test MSE Loss: 0.4579
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 7.961355924606323
Epoch: 14, Steps: 96 Train Loss: 30.1267 (Forecasting Loss:0.6570 + XiCon Loss:2.9470 x Lambda(10.0)), Vali MSE Loss: 0.5922 Test MSE Loss: 0.4578
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 8.007419109344482
Epoch: 15, Steps: 96 Train Loss: 30.1266 (Forecasting Loss:0.6602 + XiCon Loss:2.9466 x Lambda(10.0)), Vali MSE Loss: 0.5929 Test MSE Loss: 0.4579
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 8.432912349700928
Epoch: 16, Steps: 96 Train Loss: 30.1432 (Forecasting Loss:0.6559 + XiCon Loss:2.9487 x Lambda(10.0)), Vali MSE Loss: 0.5920 Test MSE Loss: 0.4578
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.38747233152389526, mae:0.5019087791442871, mape:0.6355223655700684, mspe:7.472303867340088 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.2497
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 7.711828231811523
Epoch: 1, Steps: 96 Train Loss: 32.5243 (Forecasting Loss:0.9343 + XiCon Loss:3.1590 x Lambda(10.0)), Vali MSE Loss: 0.6384 Test MSE Loss: 0.8128
Validation loss decreased (inf --> 0.638383).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 7.2764294147491455
Epoch: 2, Steps: 96 Train Loss: 31.5725 (Forecasting Loss:0.8299 + XiCon Loss:3.0743 x Lambda(10.0)), Vali MSE Loss: 0.6463 Test MSE Loss: 0.5861
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 7.922815799713135
Epoch: 3, Steps: 96 Train Loss: 30.5686 (Forecasting Loss:0.7927 + XiCon Loss:2.9776 x Lambda(10.0)), Vali MSE Loss: 0.6279 Test MSE Loss: 0.5417
Validation loss decreased (0.638383 --> 0.627928).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.932384967803955
Epoch: 4, Steps: 96 Train Loss: 30.3171 (Forecasting Loss:0.7709 + XiCon Loss:2.9546 x Lambda(10.0)), Vali MSE Loss: 0.6281 Test MSE Loss: 0.5773
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.879027366638184
Epoch: 5, Steps: 96 Train Loss: 30.2193 (Forecasting Loss:0.7520 + XiCon Loss:2.9467 x Lambda(10.0)), Vali MSE Loss: 0.6147 Test MSE Loss: 0.5085
Validation loss decreased (0.627928 --> 0.614697).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 7.697304725646973
Epoch: 6, Steps: 96 Train Loss: 30.1675 (Forecasting Loss:0.7375 + XiCon Loss:2.9430 x Lambda(10.0)), Vali MSE Loss: 0.6061 Test MSE Loss: 0.4801
Validation loss decreased (0.614697 --> 0.606121).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 7.064846515655518
Epoch: 7, Steps: 96 Train Loss: 30.1497 (Forecasting Loss:0.7274 + XiCon Loss:2.9422 x Lambda(10.0)), Vali MSE Loss: 0.6064 Test MSE Loss: 0.4790
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.842891693115234
Epoch: 8, Steps: 96 Train Loss: 30.1318 (Forecasting Loss:0.7238 + XiCon Loss:2.9408 x Lambda(10.0)), Vali MSE Loss: 0.6084 Test MSE Loss: 0.4737
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 8.192195177078247
Epoch: 9, Steps: 96 Train Loss: 30.1452 (Forecasting Loss:0.7203 + XiCon Loss:2.9425 x Lambda(10.0)), Vali MSE Loss: 0.6069 Test MSE Loss: 0.4719
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 8.57260012626648
Epoch: 10, Steps: 96 Train Loss: 30.1167 (Forecasting Loss:0.7191 + XiCon Loss:2.9398 x Lambda(10.0)), Vali MSE Loss: 0.6063 Test MSE Loss: 0.4709
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 8.159070253372192
Epoch: 11, Steps: 96 Train Loss: 30.1023 (Forecasting Loss:0.7160 + XiCon Loss:2.9386 x Lambda(10.0)), Vali MSE Loss: 0.6056 Test MSE Loss: 0.4692
Validation loss decreased (0.606121 --> 0.605569).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 7.509273290634155
Epoch: 12, Steps: 96 Train Loss: 30.1122 (Forecasting Loss:0.7197 + XiCon Loss:2.9393 x Lambda(10.0)), Vali MSE Loss: 0.6068 Test MSE Loss: 0.4693
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 7.6285316944122314
Epoch: 13, Steps: 96 Train Loss: 30.1275 (Forecasting Loss:0.7201 + XiCon Loss:2.9407 x Lambda(10.0)), Vali MSE Loss: 0.6062 Test MSE Loss: 0.4698
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 8.47577691078186
Epoch: 14, Steps: 96 Train Loss: 30.1160 (Forecasting Loss:0.7195 + XiCon Loss:2.9397 x Lambda(10.0)), Vali MSE Loss: 0.6066 Test MSE Loss: 0.4702
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 8.646831750869751
Epoch: 15, Steps: 96 Train Loss: 30.1282 (Forecasting Loss:0.7159 + XiCon Loss:2.9412 x Lambda(10.0)), Vali MSE Loss: 0.6072 Test MSE Loss: 0.4703
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 8.418569803237915
Epoch: 16, Steps: 96 Train Loss: 30.1411 (Forecasting Loss:0.7172 + XiCon Loss:2.9424 x Lambda(10.0)), Vali MSE Loss: 0.6050 Test MSE Loss: 0.4703
Validation loss decreased (0.605569 --> 0.604998).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 7.890984058380127
Epoch: 17, Steps: 96 Train Loss: 30.1209 (Forecasting Loss:0.7171 + XiCon Loss:2.9404 x Lambda(10.0)), Vali MSE Loss: 0.6074 Test MSE Loss: 0.4703
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 8.454418420791626
Epoch: 18, Steps: 96 Train Loss: 30.1171 (Forecasting Loss:0.7160 + XiCon Loss:2.9401 x Lambda(10.0)), Vali MSE Loss: 0.6059 Test MSE Loss: 0.4703
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 7.936593532562256
Epoch: 19, Steps: 96 Train Loss: 30.1120 (Forecasting Loss:0.7165 + XiCon Loss:2.9396 x Lambda(10.0)), Vali MSE Loss: 0.6052 Test MSE Loss: 0.4703
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 8.122399091720581
Epoch: 20, Steps: 96 Train Loss: 30.1386 (Forecasting Loss:0.7185 + XiCon Loss:2.9420 x Lambda(10.0)), Vali MSE Loss: 0.6059 Test MSE Loss: 0.4703
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 8.21721863746643
Epoch: 21, Steps: 96 Train Loss: 30.1275 (Forecasting Loss:0.7185 + XiCon Loss:2.9409 x Lambda(10.0)), Vali MSE Loss: 0.6053 Test MSE Loss: 0.4703
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 8.330775022506714
Epoch: 22, Steps: 96 Train Loss: 30.1317 (Forecasting Loss:0.7194 + XiCon Loss:2.9412 x Lambda(10.0)), Vali MSE Loss: 0.6039 Test MSE Loss: 0.4703
Validation loss decreased (0.604998 --> 0.603880).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 8.25362515449524
Epoch: 23, Steps: 96 Train Loss: 30.1167 (Forecasting Loss:0.7189 + XiCon Loss:2.9398 x Lambda(10.0)), Vali MSE Loss: 0.6057 Test MSE Loss: 0.4703
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 8.345182657241821
Epoch: 24, Steps: 96 Train Loss: 30.1320 (Forecasting Loss:0.7175 + XiCon Loss:2.9414 x Lambda(10.0)), Vali MSE Loss: 0.6070 Test MSE Loss: 0.4703
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 8.22094178199768
Epoch: 25, Steps: 96 Train Loss: 30.1319 (Forecasting Loss:0.7177 + XiCon Loss:2.9414 x Lambda(10.0)), Vali MSE Loss: 0.6067 Test MSE Loss: 0.4703
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 8.343631029129028
Epoch: 26, Steps: 96 Train Loss: 30.1198 (Forecasting Loss:0.7154 + XiCon Loss:2.9404 x Lambda(10.0)), Vali MSE Loss: 0.6035 Test MSE Loss: 0.4703
Validation loss decreased (0.603880 --> 0.603482).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 7.845984697341919
Epoch: 27, Steps: 96 Train Loss: 30.1273 (Forecasting Loss:0.7182 + XiCon Loss:2.9409 x Lambda(10.0)), Vali MSE Loss: 0.6078 Test MSE Loss: 0.4703
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 8.350728273391724
Epoch: 28, Steps: 96 Train Loss: 30.1206 (Forecasting Loss:0.7180 + XiCon Loss:2.9403 x Lambda(10.0)), Vali MSE Loss: 0.6057 Test MSE Loss: 0.4703
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 8.419602870941162
Epoch: 29, Steps: 96 Train Loss: 30.1202 (Forecasting Loss:0.7177 + XiCon Loss:2.9403 x Lambda(10.0)), Vali MSE Loss: 0.6070 Test MSE Loss: 0.4703
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 8.28190279006958
Epoch: 30, Steps: 96 Train Loss: 30.1334 (Forecasting Loss:0.7173 + XiCon Loss:2.9416 x Lambda(10.0)), Vali MSE Loss: 0.6060 Test MSE Loss: 0.4703
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 7.9080491065979
Epoch: 31, Steps: 96 Train Loss: 30.1344 (Forecasting Loss:0.7174 + XiCon Loss:2.9417 x Lambda(10.0)), Vali MSE Loss: 0.6070 Test MSE Loss: 0.4703
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 7.589346170425415
Epoch: 32, Steps: 96 Train Loss: 30.1167 (Forecasting Loss:0.7176 + XiCon Loss:2.9399 x Lambda(10.0)), Vali MSE Loss: 0.6059 Test MSE Loss: 0.4703
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 8.336486577987671
Epoch: 33, Steps: 96 Train Loss: 30.1161 (Forecasting Loss:0.7178 + XiCon Loss:2.9398 x Lambda(10.0)), Vali MSE Loss: 0.6069 Test MSE Loss: 0.4703
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 8.220969438552856
Epoch: 34, Steps: 96 Train Loss: 30.1217 (Forecasting Loss:0.7176 + XiCon Loss:2.9404 x Lambda(10.0)), Vali MSE Loss: 0.6077 Test MSE Loss: 0.4703
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 8.409126043319702
Epoch: 35, Steps: 96 Train Loss: 30.1338 (Forecasting Loss:0.7172 + XiCon Loss:2.9417 x Lambda(10.0)), Vali MSE Loss: 0.6051 Test MSE Loss: 0.4703
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 8.589632511138916
Epoch: 36, Steps: 96 Train Loss: 30.1323 (Forecasting Loss:0.7177 + XiCon Loss:2.9415 x Lambda(10.0)), Vali MSE Loss: 0.6070 Test MSE Loss: 0.4703
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.41687890887260437, mae:0.5236467123031616, mape:0.6308169960975647, mspe:6.007292747497559 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457649
train 6145
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 2.5668
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 6145
val 721
test 721
Epoch: 1 cost time: 8.625484466552734
Epoch: 1, Steps: 96 Train Loss: 32.6747 (Forecasting Loss:0.9728 + XiCon Loss:3.1702 x Lambda(10.0)), Vali MSE Loss: 0.6864 Test MSE Loss: 1.0068
Validation loss decreased (inf --> 0.686380).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 8.041996002197266
Epoch: 2, Steps: 96 Train Loss: 31.6689 (Forecasting Loss:0.8485 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 0.7417 Test MSE Loss: 0.8417
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0005
Epoch: 3 cost time: 8.174773216247559
Epoch: 3, Steps: 96 Train Loss: 30.7073 (Forecasting Loss:0.8086 + XiCon Loss:2.9899 x Lambda(10.0)), Vali MSE Loss: 0.7332 Test MSE Loss: 0.7675
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00025
Epoch: 4 cost time: 7.47611141204834
Epoch: 4, Steps: 96 Train Loss: 30.4580 (Forecasting Loss:0.7819 + XiCon Loss:2.9676 x Lambda(10.0)), Vali MSE Loss: 0.6844 Test MSE Loss: 0.6982
Validation loss decreased (0.686380 --> 0.684388).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 7.869596004486084
Epoch: 5, Steps: 96 Train Loss: 30.3879 (Forecasting Loss:0.7669 + XiCon Loss:2.9621 x Lambda(10.0)), Vali MSE Loss: 0.6680 Test MSE Loss: 0.6710
Validation loss decreased (0.684388 --> 0.668002).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 8.298288345336914
Epoch: 6, Steps: 96 Train Loss: 30.3442 (Forecasting Loss:0.7631 + XiCon Loss:2.9581 x Lambda(10.0)), Vali MSE Loss: 0.6594 Test MSE Loss: 0.6668
Validation loss decreased (0.668002 --> 0.659449).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 8.267998456954956
Epoch: 7, Steps: 96 Train Loss: 30.3184 (Forecasting Loss:0.7602 + XiCon Loss:2.9558 x Lambda(10.0)), Vali MSE Loss: 0.6541 Test MSE Loss: 0.6638
Validation loss decreased (0.659449 --> 0.654068).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 7.727435350418091
Epoch: 8, Steps: 96 Train Loss: 30.3050 (Forecasting Loss:0.7554 + XiCon Loss:2.9550 x Lambda(10.0)), Vali MSE Loss: 0.6513 Test MSE Loss: 0.6621
Validation loss decreased (0.654068 --> 0.651298).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 8.096047639846802
Epoch: 9, Steps: 96 Train Loss: 30.3073 (Forecasting Loss:0.7568 + XiCon Loss:2.9551 x Lambda(10.0)), Vali MSE Loss: 0.6510 Test MSE Loss: 0.6601
Validation loss decreased (0.651298 --> 0.651005).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 8.444817781448364
Epoch: 10, Steps: 96 Train Loss: 30.2822 (Forecasting Loss:0.7551 + XiCon Loss:2.9527 x Lambda(10.0)), Vali MSE Loss: 0.6528 Test MSE Loss: 0.6601
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 8.141083478927612
Epoch: 11, Steps: 96 Train Loss: 30.2951 (Forecasting Loss:0.7584 + XiCon Loss:2.9537 x Lambda(10.0)), Vali MSE Loss: 0.6476 Test MSE Loss: 0.6600
Validation loss decreased (0.651005 --> 0.647611).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 8.243278980255127
Epoch: 12, Steps: 96 Train Loss: 30.3125 (Forecasting Loss:0.7567 + XiCon Loss:2.9556 x Lambda(10.0)), Vali MSE Loss: 0.6471 Test MSE Loss: 0.6601
Validation loss decreased (0.647611 --> 0.647088).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 8.466545343399048
Epoch: 13, Steps: 96 Train Loss: 30.2906 (Forecasting Loss:0.7559 + XiCon Loss:2.9535 x Lambda(10.0)), Vali MSE Loss: 0.6524 Test MSE Loss: 0.6601
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 8.276461362838745
Epoch: 14, Steps: 96 Train Loss: 30.2940 (Forecasting Loss:0.7546 + XiCon Loss:2.9539 x Lambda(10.0)), Vali MSE Loss: 0.6480 Test MSE Loss: 0.6600
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 8.30396032333374
Epoch: 15, Steps: 96 Train Loss: 30.3083 (Forecasting Loss:0.7563 + XiCon Loss:2.9552 x Lambda(10.0)), Vali MSE Loss: 0.6504 Test MSE Loss: 0.6600
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 8.41294813156128
Epoch: 16, Steps: 96 Train Loss: 30.2915 (Forecasting Loss:0.7568 + XiCon Loss:2.9535 x Lambda(10.0)), Vali MSE Loss: 0.6509 Test MSE Loss: 0.6600
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 8.646039724349976
Epoch: 17, Steps: 96 Train Loss: 30.3051 (Forecasting Loss:0.7578 + XiCon Loss:2.9547 x Lambda(10.0)), Vali MSE Loss: 0.6508 Test MSE Loss: 0.6600
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 7.569915533065796
Epoch: 18, Steps: 96 Train Loss: 30.2979 (Forecasting Loss:0.7572 + XiCon Loss:2.9541 x Lambda(10.0)), Vali MSE Loss: 0.6477 Test MSE Loss: 0.6600
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 7.987598657608032
Epoch: 19, Steps: 96 Train Loss: 30.2994 (Forecasting Loss:0.7551 + XiCon Loss:2.9544 x Lambda(10.0)), Vali MSE Loss: 0.6509 Test MSE Loss: 0.6600
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 8.105669260025024
Epoch: 20, Steps: 96 Train Loss: 30.3045 (Forecasting Loss:0.7546 + XiCon Loss:2.9550 x Lambda(10.0)), Vali MSE Loss: 0.6472 Test MSE Loss: 0.6600
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 7.835635662078857
Epoch: 21, Steps: 96 Train Loss: 30.2870 (Forecasting Loss:0.7560 + XiCon Loss:2.9531 x Lambda(10.0)), Vali MSE Loss: 0.6510 Test MSE Loss: 0.6600
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 7.886859655380249
Epoch: 22, Steps: 96 Train Loss: 30.2980 (Forecasting Loss:0.7565 + XiCon Loss:2.9542 x Lambda(10.0)), Vali MSE Loss: 0.6526 Test MSE Loss: 0.6600
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl2160_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 721
test shape: (11, 64, 2160, 1) (11, 64, 2160, 1)
test shape: (704, 2160, 1) (704, 2160, 1)
mse:0.6596402525901794, mae:0.660555362701416, mape:0.7627681493759155, mspe:6.830598831176758 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5850+-0.34449, MAE:0.6196+-0.19977, MAPE:0.7107+-0.14751, MSPE:6.2671+-1.08346, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.3686
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.1177559
	speed: 0.1057s/iter; left time: 2791.6474s
	iters: 200, epoch: 1 | loss: 31.4924870
	speed: 0.0920s/iter; left time: 2418.5716s
Epoch: 1 cost time: 26.231041193008423
Epoch: 1, Steps: 265 Train Loss: 32.2947 (Forecasting Loss:0.2125 + XiCon Loss:3.2082 x Lambda(10.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.0980
Validation loss decreased (inf --> 0.146071).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.5368004
	speed: 0.1013s/iter; left time: 2647.5089s
	iters: 200, epoch: 2 | loss: 32.4888115
	speed: 0.1000s/iter; left time: 2603.6962s
Epoch: 2 cost time: 26.793978929519653
Epoch: 2, Steps: 265 Train Loss: 32.1086 (Forecasting Loss:0.1981 + XiCon Loss:3.1911 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0957
Validation loss decreased (0.146071 --> 0.144237).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.6580811
	speed: 0.1047s/iter; left time: 2708.9091s
	iters: 200, epoch: 3 | loss: 30.5335941
	speed: 0.0976s/iter; left time: 2514.5847s
Epoch: 3 cost time: 26.48110270500183
Epoch: 3, Steps: 265 Train Loss: 31.0135 (Forecasting Loss:0.1936 + XiCon Loss:3.0820 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0955
Validation loss decreased (0.144237 --> 0.143340).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7589073
	speed: 0.1003s/iter; left time: 2568.1224s
	iters: 200, epoch: 4 | loss: 32.2850685
	speed: 0.0983s/iter; left time: 2506.6217s
Epoch: 4 cost time: 26.489975452423096
Epoch: 4, Steps: 265 Train Loss: 30.9287 (Forecasting Loss:0.1914 + XiCon Loss:3.0737 x Lambda(10.0)), Vali MSE Loss: 0.1433 Test MSE Loss: 0.0955
Validation loss decreased (0.143340 --> 0.143317).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.8549118
	speed: 0.1072s/iter; left time: 2715.4784s
	iters: 200, epoch: 5 | loss: 30.3307343
	speed: 0.0997s/iter; left time: 2515.7549s
Epoch: 5 cost time: 27.348368883132935
Epoch: 5, Steps: 265 Train Loss: 30.8662 (Forecasting Loss:0.1903 + XiCon Loss:3.0676 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0950
Validation loss decreased (0.143317 --> 0.142118).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.0045490
	speed: 0.1068s/iter; left time: 2677.9701s
	iters: 200, epoch: 6 | loss: 30.3356667
	speed: 0.1035s/iter; left time: 2585.2089s
Epoch: 6 cost time: 27.545034885406494
Epoch: 6, Steps: 265 Train Loss: 30.7952 (Forecasting Loss:0.1899 + XiCon Loss:3.0605 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.142118 --> 0.141623).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2544765
	speed: 0.1057s/iter; left time: 2622.2269s
	iters: 200, epoch: 7 | loss: 30.7192955
	speed: 0.0943s/iter; left time: 2329.5457s
Epoch: 7 cost time: 26.62466073036194
Epoch: 7, Steps: 265 Train Loss: 30.8316 (Forecasting Loss:0.1896 + XiCon Loss:3.0642 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1739502
	speed: 0.1042s/iter; left time: 2557.0131s
	iters: 200, epoch: 8 | loss: 30.8291550
	speed: 0.0950s/iter; left time: 2321.1574s
Epoch: 8 cost time: 26.11272382736206
Epoch: 8, Steps: 265 Train Loss: 30.7921 (Forecasting Loss:0.1894 + XiCon Loss:3.0603 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0945
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.0158863
	speed: 0.1027s/iter; left time: 2492.6788s
	iters: 200, epoch: 9 | loss: 30.2007923
	speed: 0.1016s/iter; left time: 2456.6529s
Epoch: 9 cost time: 26.96706199645996
Epoch: 9, Steps: 265 Train Loss: 30.7690 (Forecasting Loss:0.1894 + XiCon Loss:3.0580 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5458546
	speed: 0.0985s/iter; left time: 2365.8135s
	iters: 200, epoch: 10 | loss: 30.4200096
	speed: 0.1015s/iter; left time: 2426.6502s
Epoch: 10 cost time: 26.795318603515625
Epoch: 10, Steps: 265 Train Loss: 30.7758 (Forecasting Loss:0.1893 + XiCon Loss:3.0587 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1858692
	speed: 0.1058s/iter; left time: 2512.8124s
	iters: 200, epoch: 11 | loss: 31.7159309
	speed: 0.0993s/iter; left time: 2348.2789s
Epoch: 11 cost time: 26.993951082229614
Epoch: 11, Steps: 265 Train Loss: 30.7922 (Forecasting Loss:0.1894 + XiCon Loss:3.0603 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1003456
	speed: 0.1038s/iter; left time: 2438.1539s
	iters: 200, epoch: 12 | loss: 30.2840061
	speed: 0.0992s/iter; left time: 2319.1945s
Epoch: 12 cost time: 26.95454478263855
Epoch: 12, Steps: 265 Train Loss: 30.7898 (Forecasting Loss:0.1893 + XiCon Loss:3.0601 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7365837
	speed: 0.1022s/iter; left time: 2372.4190s
	iters: 200, epoch: 13 | loss: 32.1048622
	speed: 0.1003s/iter; left time: 2319.0456s
Epoch: 13 cost time: 26.72050952911377
Epoch: 13, Steps: 265 Train Loss: 30.7677 (Forecasting Loss:0.1892 + XiCon Loss:3.0579 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
Validation loss decreased (0.141623 --> 0.141522).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3400269
	speed: 0.1134s/iter; left time: 2603.3992s
	iters: 200, epoch: 14 | loss: 30.9075584
	speed: 0.1058s/iter; left time: 2418.6167s
Epoch: 14 cost time: 28.834158658981323
Epoch: 14, Steps: 265 Train Loss: 30.7334 (Forecasting Loss:0.1893 + XiCon Loss:3.0544 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.4948559
	speed: 0.1040s/iter; left time: 2359.1225s
	iters: 200, epoch: 15 | loss: 30.6970406
	speed: 0.1131s/iter; left time: 2554.4742s
Epoch: 15 cost time: 28.567228078842163
Epoch: 15, Steps: 265 Train Loss: 30.8095 (Forecasting Loss:0.1892 + XiCon Loss:3.0620 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.3198414
	speed: 0.1046s/iter; left time: 2346.6822s
	iters: 200, epoch: 16 | loss: 31.3758125
	speed: 0.1044s/iter; left time: 2331.7098s
Epoch: 16 cost time: 27.660318613052368
Epoch: 16, Steps: 265 Train Loss: 30.7349 (Forecasting Loss:0.1892 + XiCon Loss:3.0546 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.0066967
	speed: 0.1111s/iter; left time: 2462.8010s
	iters: 200, epoch: 17 | loss: 31.5921001
	speed: 0.1010s/iter; left time: 2228.0593s
Epoch: 17 cost time: 28.16829013824463
Epoch: 17, Steps: 265 Train Loss: 30.7633 (Forecasting Loss:0.1891 + XiCon Loss:3.0574 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.3300533
	speed: 0.1114s/iter; left time: 2439.8316s
	iters: 200, epoch: 18 | loss: 31.2099915
	speed: 0.1110s/iter; left time: 2418.7561s
Epoch: 18 cost time: 29.18846106529236
Epoch: 18, Steps: 265 Train Loss: 30.7393 (Forecasting Loss:0.1891 + XiCon Loss:3.0550 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2811680
	speed: 0.1068s/iter; left time: 2309.5069s
	iters: 200, epoch: 19 | loss: 31.1803627
	speed: 0.1038s/iter; left time: 2234.1679s
Epoch: 19 cost time: 27.858750104904175
Epoch: 19, Steps: 265 Train Loss: 30.7515 (Forecasting Loss:0.1892 + XiCon Loss:3.0562 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.3488922
	speed: 0.1061s/iter; left time: 2266.8305s
	iters: 200, epoch: 20 | loss: 30.3754959
	speed: 0.1001s/iter; left time: 2128.4948s
Epoch: 20 cost time: 27.24042057991028
Epoch: 20, Steps: 265 Train Loss: 30.7818 (Forecasting Loss:0.1891 + XiCon Loss:3.0593 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.6279278
	speed: 0.1088s/iter; left time: 2295.5357s
	iters: 200, epoch: 21 | loss: 30.4593048
	speed: 0.1056s/iter; left time: 2217.2014s
Epoch: 21 cost time: 28.505659103393555
Epoch: 21, Steps: 265 Train Loss: 30.7863 (Forecasting Loss:0.1893 + XiCon Loss:3.0597 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.2984085
	speed: 0.1068s/iter; left time: 2224.3096s
	iters: 200, epoch: 22 | loss: 30.6481285
	speed: 0.1062s/iter; left time: 2202.4971s
Epoch: 22 cost time: 28.082298278808594
Epoch: 22, Steps: 265 Train Loss: 30.7777 (Forecasting Loss:0.1892 + XiCon Loss:3.0588 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.3763771
	speed: 0.1116s/iter; left time: 2295.5859s
	iters: 200, epoch: 23 | loss: 30.2538738
	speed: 0.1061s/iter; left time: 2171.2971s
Epoch: 23 cost time: 27.775939226150513
Epoch: 23, Steps: 265 Train Loss: 30.7904 (Forecasting Loss:0.1893 + XiCon Loss:3.0601 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039363469928503036, mae:0.14950135350227356, mape:0.11864477396011353, mspe:0.02631451189517975 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 31.4799
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.2732964
	speed: 0.1049s/iter; left time: 2768.9672s
	iters: 200, epoch: 1 | loss: 31.4625664
	speed: 0.0991s/iter; left time: 2605.5719s
Epoch: 1 cost time: 26.69470191001892
Epoch: 1, Steps: 265 Train Loss: 32.1881 (Forecasting Loss:0.2101 + XiCon Loss:3.1978 x Lambda(10.0)), Vali MSE Loss: 0.1480 Test MSE Loss: 0.0986
Validation loss decreased (inf --> 0.147980).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.9089546
	speed: 0.1015s/iter; left time: 2653.7717s
	iters: 200, epoch: 2 | loss: 33.6205978
	speed: 0.0942s/iter; left time: 2451.8367s
Epoch: 2 cost time: 26.22614049911499
Epoch: 2, Steps: 265 Train Loss: 32.2320 (Forecasting Loss:0.1984 + XiCon Loss:3.2034 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0980
Validation loss decreased (0.147980 --> 0.146525).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.0925064
	speed: 0.1017s/iter; left time: 2631.4260s
	iters: 200, epoch: 3 | loss: 32.3301735
	speed: 0.0989s/iter; left time: 2548.9927s
Epoch: 3 cost time: 26.450859546661377
Epoch: 3, Steps: 265 Train Loss: 32.4990 (Forecasting Loss:0.1937 + XiCon Loss:3.2305 x Lambda(10.0)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0955
Validation loss decreased (0.146525 --> 0.143491).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0281563
	speed: 0.1067s/iter; left time: 2731.7611s
	iters: 200, epoch: 4 | loss: 32.0244942
	speed: 0.1033s/iter; left time: 2634.5647s
Epoch: 4 cost time: 27.74275827407837
Epoch: 4, Steps: 265 Train Loss: 31.7552 (Forecasting Loss:0.1912 + XiCon Loss:3.1564 x Lambda(10.0)), Vali MSE Loss: 0.1430 Test MSE Loss: 0.0953
Validation loss decreased (0.143491 --> 0.142984).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.3456306
	speed: 0.0995s/iter; left time: 2522.0182s
	iters: 200, epoch: 5 | loss: 30.8563271
	speed: 0.1028s/iter; left time: 2594.0098s
Epoch: 5 cost time: 26.588282585144043
Epoch: 5, Steps: 265 Train Loss: 31.3174 (Forecasting Loss:0.1902 + XiCon Loss:3.1127 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0945
Validation loss decreased (0.142984 --> 0.141956).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.2156601
	speed: 0.1043s/iter; left time: 2614.4482s
	iters: 200, epoch: 6 | loss: 30.6959038
	speed: 0.0965s/iter; left time: 2410.7071s
Epoch: 6 cost time: 26.351215839385986
Epoch: 6, Steps: 265 Train Loss: 31.2264 (Forecasting Loss:0.1899 + XiCon Loss:3.1037 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9621677
	speed: 0.1014s/iter; left time: 2514.9525s
	iters: 200, epoch: 7 | loss: 31.4059563
	speed: 0.1121s/iter; left time: 2770.0645s
Epoch: 7 cost time: 28.32149910926819
Epoch: 7, Steps: 265 Train Loss: 31.2071 (Forecasting Loss:0.1895 + XiCon Loss:3.1018 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0945
Validation loss decreased (0.141956 --> 0.141845).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0611839
	speed: 0.1076s/iter; left time: 2641.8758s
	iters: 200, epoch: 8 | loss: 31.7765617
	speed: 0.1072s/iter; left time: 2620.8869s
Epoch: 8 cost time: 28.285059928894043
Epoch: 8, Steps: 265 Train Loss: 31.2603 (Forecasting Loss:0.1894 + XiCon Loss:3.1071 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
Validation loss decreased (0.141845 --> 0.141844).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.5161629
	speed: 0.1034s/iter; left time: 2510.5052s
	iters: 200, epoch: 9 | loss: 31.0360909
	speed: 0.0950s/iter; left time: 2298.1263s
Epoch: 9 cost time: 26.36387300491333
Epoch: 9, Steps: 265 Train Loss: 31.1663 (Forecasting Loss:0.1893 + XiCon Loss:3.0977 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141844 --> 0.141577).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7888012
	speed: 0.1065s/iter; left time: 2558.7373s
	iters: 200, epoch: 10 | loss: 30.8408623
	speed: 0.1017s/iter; left time: 2432.0021s
Epoch: 10 cost time: 27.87340807914734
Epoch: 10, Steps: 265 Train Loss: 31.2181 (Forecasting Loss:0.1892 + XiCon Loss:3.1029 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.7112579
	speed: 0.1037s/iter; left time: 2462.9423s
	iters: 200, epoch: 11 | loss: 31.2826405
	speed: 0.1052s/iter; left time: 2487.2005s
Epoch: 11 cost time: 26.95062828063965
Epoch: 11, Steps: 265 Train Loss: 31.1992 (Forecasting Loss:0.1892 + XiCon Loss:3.1010 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.0182018
	speed: 0.1019s/iter; left time: 2392.7495s
	iters: 200, epoch: 12 | loss: 31.3000412
	speed: 0.0984s/iter; left time: 2302.3475s
Epoch: 12 cost time: 27.263277053833008
Epoch: 12, Steps: 265 Train Loss: 31.1620 (Forecasting Loss:0.1892 + XiCon Loss:3.0973 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6335716
	speed: 0.1074s/iter; left time: 2494.5891s
	iters: 200, epoch: 13 | loss: 30.9736443
	speed: 0.1012s/iter; left time: 2340.7491s
Epoch: 13 cost time: 27.591906547546387
Epoch: 13, Steps: 265 Train Loss: 31.2123 (Forecasting Loss:0.1893 + XiCon Loss:3.1023 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0943
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.9034500
	speed: 0.1045s/iter; left time: 2399.6030s
	iters: 200, epoch: 14 | loss: 31.4356613
	speed: 0.1059s/iter; left time: 2420.5488s
Epoch: 14 cost time: 27.787566900253296
Epoch: 14, Steps: 265 Train Loss: 31.1458 (Forecasting Loss:0.1892 + XiCon Loss:3.0957 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.1787949
	speed: 0.1069s/iter; left time: 2426.4168s
	iters: 200, epoch: 15 | loss: 31.7242565
	speed: 0.0989s/iter; left time: 2234.8403s
Epoch: 15 cost time: 26.98966336250305
Epoch: 15, Steps: 265 Train Loss: 31.1694 (Forecasting Loss:0.1892 + XiCon Loss:3.0980 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6997986
	speed: 0.1054s/iter; left time: 2364.6116s
	iters: 200, epoch: 16 | loss: 30.6779423
	speed: 0.0984s/iter; left time: 2195.7683s
Epoch: 16 cost time: 26.716734409332275
Epoch: 16, Steps: 265 Train Loss: 31.1985 (Forecasting Loss:0.1892 + XiCon Loss:3.1009 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.9152431
	speed: 0.1065s/iter; left time: 2359.0591s
	iters: 200, epoch: 17 | loss: 31.0095310
	speed: 0.0933s/iter; left time: 2058.8824s
Epoch: 17 cost time: 26.736422538757324
Epoch: 17, Steps: 265 Train Loss: 31.2091 (Forecasting Loss:0.1892 + XiCon Loss:3.1020 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.0263214
	speed: 0.1071s/iter; left time: 2345.8404s
	iters: 200, epoch: 18 | loss: 31.6663342
	speed: 0.1010s/iter; left time: 2200.5520s
Epoch: 18 cost time: 27.60954475402832
Epoch: 18, Steps: 265 Train Loss: 31.2009 (Forecasting Loss:0.1893 + XiCon Loss:3.1012 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.6018200
	speed: 0.0996s/iter; left time: 2154.7482s
	iters: 200, epoch: 19 | loss: 31.3599815
	speed: 0.0996s/iter; left time: 2144.6925s
Epoch: 19 cost time: 26.307945489883423
Epoch: 19, Steps: 265 Train Loss: 31.1613 (Forecasting Loss:0.1892 + XiCon Loss:3.0972 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0943
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039301156997680664, mae:0.14940571784973145, mape:0.1185808777809143, mspe:0.026284703984856606 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 29.6047
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.1669540
	speed: 0.1055s/iter; left time: 2785.2904s
	iters: 200, epoch: 1 | loss: 31.4941349
	speed: 0.1018s/iter; left time: 2676.1370s
Epoch: 1 cost time: 27.370275259017944
Epoch: 1, Steps: 265 Train Loss: 32.1176 (Forecasting Loss:0.2113 + XiCon Loss:3.1906 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.146495).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.7697754
	speed: 0.1017s/iter; left time: 2657.0068s
	iters: 200, epoch: 2 | loss: 33.4055405
	speed: 0.1014s/iter; left time: 2639.2258s
Epoch: 2 cost time: 26.999828577041626
Epoch: 2, Steps: 265 Train Loss: 33.0023 (Forecasting Loss:0.1979 + XiCon Loss:3.2804 x Lambda(10.0)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.0984
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.9721031
	speed: 0.1006s/iter; left time: 2602.4998s
	iters: 200, epoch: 3 | loss: 32.8516960
	speed: 0.0967s/iter; left time: 2492.5016s
Epoch: 3 cost time: 26.147777795791626
Epoch: 3, Steps: 265 Train Loss: 33.0783 (Forecasting Loss:0.1931 + XiCon Loss:3.2885 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.0971
Validation loss decreased (0.146495 --> 0.144311).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.3176422
	speed: 0.0979s/iter; left time: 2506.8887s
	iters: 200, epoch: 4 | loss: 32.2141190
	speed: 0.0941s/iter; left time: 2400.9797s
Epoch: 4 cost time: 25.35185718536377
Epoch: 4, Steps: 265 Train Loss: 33.0090 (Forecasting Loss:0.1906 + XiCon Loss:3.2818 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0956
Validation loss decreased (0.144311 --> 0.143164).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.5243034
	speed: 0.1075s/iter; left time: 2725.1297s
	iters: 200, epoch: 5 | loss: 32.6452255
	speed: 0.1028s/iter; left time: 2593.9908s
Epoch: 5 cost time: 27.87153196334839
Epoch: 5, Steps: 265 Train Loss: 32.7153 (Forecasting Loss:0.1893 + XiCon Loss:3.2526 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.0960
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.9553986
	speed: 0.1080s/iter; left time: 2708.9218s
	iters: 200, epoch: 6 | loss: 33.5893822
	speed: 0.1035s/iter; left time: 2584.6057s
Epoch: 6 cost time: 27.784071683883667
Epoch: 6, Steps: 265 Train Loss: 32.7309 (Forecasting Loss:0.1888 + XiCon Loss:3.2542 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.0957
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.9799652
	speed: 0.1004s/iter; left time: 2489.9986s
	iters: 200, epoch: 7 | loss: 34.4391403
	speed: 0.0908s/iter; left time: 2243.7652s
Epoch: 7 cost time: 25.440876960754395
Epoch: 7, Steps: 265 Train Loss: 32.5211 (Forecasting Loss:0.1885 + XiCon Loss:3.2333 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0960
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.9962425
	speed: 0.1055s/iter; left time: 2589.7210s
	iters: 200, epoch: 8 | loss: 32.2721519
	speed: 0.1004s/iter; left time: 2454.3321s
Epoch: 8 cost time: 27.263850450515747
Epoch: 8, Steps: 265 Train Loss: 32.5272 (Forecasting Loss:0.1883 + XiCon Loss:3.2339 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0961
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.0354424
	speed: 0.0986s/iter; left time: 2394.1092s
	iters: 200, epoch: 9 | loss: 33.6376762
	speed: 0.0974s/iter; left time: 2354.4758s
Epoch: 9 cost time: 26.08398675918579
Epoch: 9, Steps: 265 Train Loss: 32.5201 (Forecasting Loss:0.1883 + XiCon Loss:3.2332 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0961
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.1967430
	speed: 0.1031s/iter; left time: 2477.2415s
	iters: 200, epoch: 10 | loss: 32.1846657
	speed: 0.1031s/iter; left time: 2466.0671s
Epoch: 10 cost time: 26.934348344802856
Epoch: 10, Steps: 265 Train Loss: 32.3931 (Forecasting Loss:0.1882 + XiCon Loss:3.2205 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0960
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.9318924
	speed: 0.1053s/iter; left time: 2501.4494s
	iters: 200, epoch: 11 | loss: 32.2878799
	speed: 0.0968s/iter; left time: 2288.6851s
Epoch: 11 cost time: 26.975760221481323
Epoch: 11, Steps: 265 Train Loss: 32.5384 (Forecasting Loss:0.1881 + XiCon Loss:3.2350 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.0961
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6176376
	speed: 0.1104s/iter; left time: 2591.8205s
	iters: 200, epoch: 12 | loss: 32.2646370
	speed: 0.0981s/iter; left time: 2295.1785s
Epoch: 12 cost time: 27.600263118743896
Epoch: 12, Steps: 265 Train Loss: 32.4519 (Forecasting Loss:0.1881 + XiCon Loss:3.2264 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0960
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.3191299
	speed: 0.1073s/iter; left time: 2491.3737s
	iters: 200, epoch: 13 | loss: 32.3532372
	speed: 0.0980s/iter; left time: 2264.8351s
Epoch: 13 cost time: 27.518771648406982
Epoch: 13, Steps: 265 Train Loss: 32.4389 (Forecasting Loss:0.1880 + XiCon Loss:3.2251 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.0960
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.8128510
	speed: 0.1071s/iter; left time: 2459.0204s
	iters: 200, epoch: 14 | loss: 32.4219704
	speed: 0.0989s/iter; left time: 2259.3880s
Epoch: 14 cost time: 26.82327151298523
Epoch: 14, Steps: 265 Train Loss: 32.5594 (Forecasting Loss:0.1881 + XiCon Loss:3.2371 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0960
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04021631181240082, mae:0.15097767114639282, mape:0.12073110044002533, mspe:0.02796388976275921 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 31.3090
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.7559128
	speed: 0.0982s/iter; left time: 2592.8708s
	iters: 200, epoch: 1 | loss: 31.6315670
	speed: 0.0954s/iter; left time: 2509.8223s
Epoch: 1 cost time: 26.09696316719055
Epoch: 1, Steps: 265 Train Loss: 32.4034 (Forecasting Loss:0.2104 + XiCon Loss:3.2193 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.0993
Validation loss decreased (inf --> 0.148258).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 35.5184593
	speed: 0.1057s/iter; left time: 2762.5067s
	iters: 200, epoch: 2 | loss: 35.0559464
	speed: 0.0986s/iter; left time: 2567.6870s
Epoch: 2 cost time: 26.578409671783447
Epoch: 2, Steps: 265 Train Loss: 34.1421 (Forecasting Loss:0.1975 + XiCon Loss:3.3945 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0973
Validation loss decreased (0.148258 --> 0.143817).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.6499062
	speed: 0.1042s/iter; left time: 2696.8460s
	iters: 200, epoch: 3 | loss: 34.8437805
	speed: 0.0994s/iter; left time: 2561.9583s
Epoch: 3 cost time: 26.835569143295288
Epoch: 3, Steps: 265 Train Loss: 34.0621 (Forecasting Loss:0.1930 + XiCon Loss:3.3869 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0958
Validation loss decreased (0.143817 --> 0.141652).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.9796371
	speed: 0.1066s/iter; left time: 2728.5040s
	iters: 200, epoch: 4 | loss: 31.6793365
	speed: 0.1035s/iter; left time: 2639.2509s
Epoch: 4 cost time: 27.081119298934937
Epoch: 4, Steps: 265 Train Loss: 33.7182 (Forecasting Loss:0.1906 + XiCon Loss:3.3528 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.0961
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.3199081
	speed: 0.0977s/iter; left time: 2475.9959s
	iters: 200, epoch: 5 | loss: 31.6481457
	speed: 0.0970s/iter; left time: 2449.3529s
Epoch: 5 cost time: 25.568251132965088
Epoch: 5, Steps: 265 Train Loss: 33.1824 (Forecasting Loss:0.1902 + XiCon Loss:3.2992 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0951
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 35.5300446
	speed: 0.1052s/iter; left time: 2636.8366s
	iters: 200, epoch: 6 | loss: 34.8034630
	speed: 0.0981s/iter; left time: 2449.3303s
Epoch: 6 cost time: 26.82442617416382
Epoch: 6, Steps: 265 Train Loss: 33.0947 (Forecasting Loss:0.1896 + XiCon Loss:3.2905 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.2639198
	speed: 0.1026s/iter; left time: 2544.7959s
	iters: 200, epoch: 7 | loss: 32.8064766
	speed: 0.0966s/iter; left time: 2386.8122s
Epoch: 7 cost time: 26.64351511001587
Epoch: 7, Steps: 265 Train Loss: 33.1294 (Forecasting Loss:0.1893 + XiCon Loss:3.2940 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0947
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.4404144
	speed: 0.0997s/iter; left time: 2448.3053s
	iters: 200, epoch: 8 | loss: 35.8890800
	speed: 0.0999s/iter; left time: 2441.2289s
Epoch: 8 cost time: 26.440366744995117
Epoch: 8, Steps: 265 Train Loss: 32.9780 (Forecasting Loss:0.1892 + XiCon Loss:3.2789 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 33.5333138
	speed: 0.1038s/iter; left time: 2521.3062s
	iters: 200, epoch: 9 | loss: 33.4366837
	speed: 0.0983s/iter; left time: 2376.2919s
Epoch: 9 cost time: 26.39568853378296
Epoch: 9, Steps: 265 Train Loss: 33.0111 (Forecasting Loss:0.1890 + XiCon Loss:3.2822 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 35.5869675
	speed: 0.1059s/iter; left time: 2543.7441s
	iters: 200, epoch: 10 | loss: 32.6112328
	speed: 0.1050s/iter; left time: 2511.5773s
Epoch: 10 cost time: 28.008715391159058
Epoch: 10, Steps: 265 Train Loss: 32.9987 (Forecasting Loss:0.1890 + XiCon Loss:3.2810 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.141652 --> 0.141565).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.6737175
	speed: 0.1141s/iter; left time: 2710.3190s
	iters: 200, epoch: 11 | loss: 32.2214661
	speed: 0.1084s/iter; left time: 2563.6961s
Epoch: 11 cost time: 29.20083713531494
Epoch: 11, Steps: 265 Train Loss: 33.0257 (Forecasting Loss:0.1891 + XiCon Loss:3.2837 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 33.8440132
	speed: 0.1108s/iter; left time: 2601.5683s
	iters: 200, epoch: 12 | loss: 32.0946655
	speed: 0.1037s/iter; left time: 2424.3801s
Epoch: 12 cost time: 28.047117710113525
Epoch: 12, Steps: 265 Train Loss: 32.9855 (Forecasting Loss:0.1890 + XiCon Loss:3.2796 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.6676979
	speed: 0.1055s/iter; left time: 2449.4044s
	iters: 200, epoch: 13 | loss: 32.5804977
	speed: 0.0999s/iter; left time: 2308.7772s
Epoch: 13 cost time: 27.74144744873047
Epoch: 13, Steps: 265 Train Loss: 33.0276 (Forecasting Loss:0.1889 + XiCon Loss:3.2839 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.8687592
	speed: 0.1075s/iter; left time: 2468.8205s
	iters: 200, epoch: 14 | loss: 32.3927498
	speed: 0.1110s/iter; left time: 2536.2949s
Epoch: 14 cost time: 28.92015290260315
Epoch: 14, Steps: 265 Train Loss: 32.9644 (Forecasting Loss:0.1889 + XiCon Loss:3.2776 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.9726486
	speed: 0.1104s/iter; left time: 2505.6310s
	iters: 200, epoch: 15 | loss: 32.0376778
	speed: 0.1068s/iter; left time: 2412.8538s
Epoch: 15 cost time: 28.63127326965332
Epoch: 15, Steps: 265 Train Loss: 32.9421 (Forecasting Loss:0.1890 + XiCon Loss:3.2753 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.4111977
	speed: 0.1061s/iter; left time: 2379.0717s
	iters: 200, epoch: 16 | loss: 32.1510048
	speed: 0.0953s/iter; left time: 2127.4373s
Epoch: 16 cost time: 26.226001739501953
Epoch: 16, Steps: 265 Train Loss: 32.9699 (Forecasting Loss:0.1890 + XiCon Loss:3.2781 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.8854332
	speed: 0.1091s/iter; left time: 2418.4193s
	iters: 200, epoch: 17 | loss: 33.2370949
	speed: 0.1122s/iter; left time: 2476.1223s
Epoch: 17 cost time: 29.174245834350586
Epoch: 17, Steps: 265 Train Loss: 33.0582 (Forecasting Loss:0.1888 + XiCon Loss:3.2869 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.6430664
	speed: 0.1098s/iter; left time: 2404.7069s
	iters: 200, epoch: 18 | loss: 31.2907066
	speed: 0.1078s/iter; left time: 2350.6064s
Epoch: 18 cost time: 28.607770681381226
Epoch: 18, Steps: 265 Train Loss: 32.9952 (Forecasting Loss:0.1890 + XiCon Loss:3.2806 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 33.9183655
	speed: 0.1045s/iter; left time: 2261.0497s
	iters: 200, epoch: 19 | loss: 32.4004250
	speed: 0.1020s/iter; left time: 2195.4691s
Epoch: 19 cost time: 27.43103551864624
Epoch: 19, Steps: 265 Train Loss: 33.0143 (Forecasting Loss:0.1890 + XiCon Loss:3.2825 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.9733429
	speed: 0.1036s/iter; left time: 2213.5319s
	iters: 200, epoch: 20 | loss: 33.2458687
	speed: 0.0975s/iter; left time: 2072.4198s
Epoch: 20 cost time: 26.14769721031189
Epoch: 20, Steps: 265 Train Loss: 33.1369 (Forecasting Loss:0.1889 + XiCon Loss:3.2948 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039411839097738266, mae:0.14976544678211212, mape:0.11927645653486252, mspe:0.0268902275711298 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:156609
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.6542
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.3765182
	speed: 0.1044s/iter; left time: 2757.1181s
	iters: 200, epoch: 1 | loss: 31.4630966
	speed: 0.1001s/iter; left time: 2632.1516s
Epoch: 1 cost time: 27.44420862197876
Epoch: 1, Steps: 265 Train Loss: 32.3115 (Forecasting Loss:0.2102 + XiCon Loss:3.2101 x Lambda(10.0)), Vali MSE Loss: 0.1472 Test MSE Loss: 0.0979
Validation loss decreased (inf --> 0.147199).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.9669838
	speed: 0.1095s/iter; left time: 2862.9802s
	iters: 200, epoch: 2 | loss: 34.2712135
	speed: 0.1013s/iter; left time: 2636.8505s
Epoch: 2 cost time: 27.949087619781494
Epoch: 2, Steps: 265 Train Loss: 32.9138 (Forecasting Loss:0.1978 + XiCon Loss:3.2716 x Lambda(10.0)), Vali MSE Loss: 0.1476 Test MSE Loss: 0.0997
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.5711555
	speed: 0.1048s/iter; left time: 2712.0560s
	iters: 200, epoch: 3 | loss: 32.7671242
	speed: 0.0986s/iter; left time: 2541.9746s
Epoch: 3 cost time: 26.809876203536987
Epoch: 3, Steps: 265 Train Loss: 32.5362 (Forecasting Loss:0.1932 + XiCon Loss:3.2343 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0960
Validation loss decreased (0.147199 --> 0.144131).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.7816811
	speed: 0.1043s/iter; left time: 2669.5097s
	iters: 200, epoch: 4 | loss: 31.6506462
	speed: 0.1024s/iter; left time: 2610.9239s
Epoch: 4 cost time: 27.16360354423523
Epoch: 4, Steps: 265 Train Loss: 32.4396 (Forecasting Loss:0.1912 + XiCon Loss:3.2248 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0948
Validation loss decreased (0.144131 --> 0.142636).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0921001
	speed: 0.1075s/iter; left time: 2724.4306s
	iters: 200, epoch: 5 | loss: 32.7836838
	speed: 0.1043s/iter; left time: 2633.3409s
Epoch: 5 cost time: 27.718590021133423
Epoch: 5, Steps: 265 Train Loss: 32.0040 (Forecasting Loss:0.1902 + XiCon Loss:3.1814 x Lambda(10.0)), Vali MSE Loss: 0.1427 Test MSE Loss: 0.0950
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9103680
	speed: 0.1041s/iter; left time: 2611.4054s
	iters: 200, epoch: 6 | loss: 32.6305084
	speed: 0.0976s/iter; left time: 2436.9325s
Epoch: 6 cost time: 26.429001808166504
Epoch: 6, Steps: 265 Train Loss: 31.6483 (Forecasting Loss:0.1895 + XiCon Loss:3.1459 x Lambda(10.0)), Vali MSE Loss: 0.1427 Test MSE Loss: 0.0951
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1937675
	speed: 0.1016s/iter; left time: 2521.5621s
	iters: 200, epoch: 7 | loss: 31.2244053
	speed: 0.1032s/iter; left time: 2551.3987s
Epoch: 7 cost time: 27.364617586135864
Epoch: 7, Steps: 265 Train Loss: 31.4434 (Forecasting Loss:0.1892 + XiCon Loss:3.1254 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0947
Validation loss decreased (0.142636 --> 0.142054).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.3007793
	speed: 0.1052s/iter; left time: 2583.4147s
	iters: 200, epoch: 8 | loss: 30.3435917
	speed: 0.0950s/iter; left time: 2321.5119s
Epoch: 8 cost time: 26.489988088607788
Epoch: 8, Steps: 265 Train Loss: 31.2389 (Forecasting Loss:0.1890 + XiCon Loss:3.1050 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0947
Validation loss decreased (0.142054 --> 0.141864).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.0888500
	speed: 0.1026s/iter; left time: 2490.4389s
	iters: 200, epoch: 9 | loss: 31.3177834
	speed: 0.1017s/iter; left time: 2458.6460s
Epoch: 9 cost time: 27.144762992858887
Epoch: 9, Steps: 265 Train Loss: 31.2338 (Forecasting Loss:0.1890 + XiCon Loss:3.1045 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
Validation loss decreased (0.141864 --> 0.141683).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.4475117
	speed: 0.1016s/iter; left time: 2440.4234s
	iters: 200, epoch: 10 | loss: 31.6013126
	speed: 0.1000s/iter; left time: 2391.0324s
Epoch: 10 cost time: 26.338382482528687
Epoch: 10, Steps: 265 Train Loss: 31.2217 (Forecasting Loss:0.1889 + XiCon Loss:3.1033 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5304775
	speed: 0.1085s/iter; left time: 2577.1367s
	iters: 200, epoch: 11 | loss: 32.2615242
	speed: 0.1001s/iter; left time: 2367.3712s
Epoch: 11 cost time: 27.356573343276978
Epoch: 11, Steps: 265 Train Loss: 31.2179 (Forecasting Loss:0.1888 + XiCon Loss:3.1029 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9561081
	speed: 0.1036s/iter; left time: 2433.5476s
	iters: 200, epoch: 12 | loss: 31.2202492
	speed: 0.1003s/iter; left time: 2345.9517s
Epoch: 12 cost time: 27.13897967338562
Epoch: 12, Steps: 265 Train Loss: 31.2245 (Forecasting Loss:0.1888 + XiCon Loss:3.1036 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.6165810
	speed: 0.1111s/iter; left time: 2579.3954s
	iters: 200, epoch: 13 | loss: 30.3252602
	speed: 0.1031s/iter; left time: 2384.1297s
Epoch: 13 cost time: 28.09886407852173
Epoch: 13, Steps: 265 Train Loss: 31.2061 (Forecasting Loss:0.1888 + XiCon Loss:3.1017 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.7423878
	speed: 0.1111s/iter; left time: 2551.0419s
	iters: 200, epoch: 14 | loss: 29.9714947
	speed: 0.0986s/iter; left time: 2253.1977s
Epoch: 14 cost time: 28.058168649673462
Epoch: 14, Steps: 265 Train Loss: 31.1581 (Forecasting Loss:0.1889 + XiCon Loss:3.0969 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.8119755
	speed: 0.1022s/iter; left time: 2318.3756s
	iters: 200, epoch: 15 | loss: 30.4354668
	speed: 0.0985s/iter; left time: 2225.2331s
Epoch: 15 cost time: 26.210113763809204
Epoch: 15, Steps: 265 Train Loss: 31.2095 (Forecasting Loss:0.1889 + XiCon Loss:3.1021 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.1773682
	speed: 0.1034s/iter; left time: 2319.4392s
	iters: 200, epoch: 16 | loss: 30.9513969
	speed: 0.0985s/iter; left time: 2200.0891s
Epoch: 16 cost time: 27.076438188552856
Epoch: 16, Steps: 265 Train Loss: 31.2058 (Forecasting Loss:0.1888 + XiCon Loss:3.1017 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.4333134
	speed: 0.1015s/iter; left time: 2248.7585s
	iters: 200, epoch: 17 | loss: 31.5815372
	speed: 0.1001s/iter; left time: 2208.7295s
Epoch: 17 cost time: 26.902461767196655
Epoch: 17, Steps: 265 Train Loss: 31.2269 (Forecasting Loss:0.1888 + XiCon Loss:3.1038 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.3499794
	speed: 0.1053s/iter; left time: 2306.2760s
	iters: 200, epoch: 18 | loss: 32.3863144
	speed: 0.1008s/iter; left time: 2196.2035s
Epoch: 18 cost time: 26.917494297027588
Epoch: 18, Steps: 265 Train Loss: 31.2134 (Forecasting Loss:0.1888 + XiCon Loss:3.1025 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0946
Validation loss decreased (0.141683 --> 0.141607).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.2896881
	speed: 0.1075s/iter; left time: 2325.6779s
	iters: 200, epoch: 19 | loss: 30.4706345
	speed: 0.1000s/iter; left time: 2153.0079s
Epoch: 19 cost time: 27.303765296936035
Epoch: 19, Steps: 265 Train Loss: 31.1715 (Forecasting Loss:0.1888 + XiCon Loss:3.0983 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.4710045
	speed: 0.1038s/iter; left time: 2217.3721s
	iters: 200, epoch: 20 | loss: 31.3039169
	speed: 0.1001s/iter; left time: 2128.7983s
Epoch: 20 cost time: 27.42152166366577
Epoch: 20, Steps: 265 Train Loss: 31.1156 (Forecasting Loss:0.1889 + XiCon Loss:3.0927 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.2315369
	speed: 0.1017s/iter; left time: 2146.7507s
	iters: 200, epoch: 21 | loss: 31.3219872
	speed: 0.0962s/iter; left time: 2021.1657s
Epoch: 21 cost time: 26.900732278823853
Epoch: 21, Steps: 265 Train Loss: 31.1421 (Forecasting Loss:0.1888 + XiCon Loss:3.0953 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.0387707
	speed: 0.1058s/iter; left time: 2205.3137s
	iters: 200, epoch: 22 | loss: 31.1537647
	speed: 0.1042s/iter; left time: 2159.9531s
Epoch: 22 cost time: 27.463133335113525
Epoch: 22, Steps: 265 Train Loss: 31.1734 (Forecasting Loss:0.1888 + XiCon Loss:3.0985 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.7765427
	speed: 0.1023s/iter; left time: 2104.8706s
	iters: 200, epoch: 23 | loss: 30.8523254
	speed: 0.1004s/iter; left time: 2054.9397s
Epoch: 23 cost time: 26.795954704284668
Epoch: 23, Steps: 265 Train Loss: 31.2121 (Forecasting Loss:0.1889 + XiCon Loss:3.1023 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 31.6422253
	speed: 0.1012s/iter; left time: 2055.2283s
	iters: 200, epoch: 24 | loss: 30.4349804
	speed: 0.1006s/iter; left time: 2032.1165s
Epoch: 24 cost time: 26.80216407775879
Epoch: 24, Steps: 265 Train Loss: 31.1558 (Forecasting Loss:0.1889 + XiCon Loss:3.0967 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.4515877
	speed: 0.0981s/iter; left time: 1965.4151s
	iters: 200, epoch: 25 | loss: 31.2871113
	speed: 0.0977s/iter; left time: 1947.7705s
Epoch: 25 cost time: 25.714916467666626
Epoch: 25, Steps: 265 Train Loss: 31.1968 (Forecasting Loss:0.1888 + XiCon Loss:3.1008 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.5535278
	speed: 0.1068s/iter; left time: 2112.7139s
	iters: 200, epoch: 26 | loss: 30.3046589
	speed: 0.0987s/iter; left time: 1941.4155s
Epoch: 26 cost time: 26.748660564422607
Epoch: 26, Steps: 265 Train Loss: 31.1866 (Forecasting Loss:0.1888 + XiCon Loss:3.0998 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 31.4243469
	speed: 0.1022s/iter; left time: 1994.8714s
	iters: 200, epoch: 27 | loss: 31.5733700
	speed: 0.0995s/iter; left time: 1932.3095s
Epoch: 27 cost time: 26.93281626701355
Epoch: 27, Steps: 265 Train Loss: 31.1525 (Forecasting Loss:0.1889 + XiCon Loss:3.0964 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.2711086
	speed: 0.1033s/iter; left time: 1988.9917s
	iters: 200, epoch: 28 | loss: 30.5844116
	speed: 0.0997s/iter; left time: 1908.2376s
Epoch: 28 cost time: 26.71611261367798
Epoch: 28, Steps: 265 Train Loss: 31.1442 (Forecasting Loss:0.1888 + XiCon Loss:3.0955 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03947161138057709, mae:0.14974907040596008, mape:0.11900518834590912, mspe:0.02646559849381447 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0396+-0.00047, MAE:0.1499+-0.00079, MAPE:0.1192+-0.00109, MSPE:0.0268+-0.00087, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 31.2788
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 32.5918732
	speed: 0.1511s/iter; left time: 3853.8581s
	iters: 200, epoch: 1 | loss: 31.3754826
	speed: 0.1422s/iter; left time: 3611.3680s
Epoch: 1 cost time: 37.907665729522705
Epoch: 1, Steps: 256 Train Loss: 32.4022 (Forecasting Loss:0.3046 + XiCon Loss:3.2098 x Lambda(10.0)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1684
Validation loss decreased (inf --> 0.221997).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.7176514
	speed: 0.1732s/iter; left time: 4372.0912s
	iters: 200, epoch: 2 | loss: 34.3199997
	speed: 0.1597s/iter; left time: 4016.3483s
Epoch: 2 cost time: 42.17199945449829
Epoch: 2, Steps: 256 Train Loss: 33.6475 (Forecasting Loss:0.3058 + XiCon Loss:3.3342 x Lambda(10.0)), Vali MSE Loss: 0.2244 Test MSE Loss: 0.1684
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.3530998
	speed: 0.1643s/iter; left time: 4105.3158s
	iters: 200, epoch: 3 | loss: 32.8841248
	speed: 0.1607s/iter; left time: 3998.4633s
Epoch: 3 cost time: 40.959216833114624
Epoch: 3, Steps: 256 Train Loss: 33.4079 (Forecasting Loss:0.3002 + XiCon Loss:3.3108 x Lambda(10.0)), Vali MSE Loss: 0.2226 Test MSE Loss: 0.1677
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 34.5596466
	speed: 0.1600s/iter; left time: 3956.2994s
	iters: 200, epoch: 4 | loss: 34.1483765
	speed: 0.1550s/iter; left time: 3818.7147s
Epoch: 4 cost time: 40.85365581512451
Epoch: 4, Steps: 256 Train Loss: 33.0012 (Forecasting Loss:0.2977 + XiCon Loss:3.2703 x Lambda(10.0)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1685
Validation loss decreased (0.221997 --> 0.221987).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 33.0580902
	speed: 0.1610s/iter; left time: 3939.7368s
	iters: 200, epoch: 5 | loss: 33.2899437
	speed: 0.1569s/iter; left time: 3823.9070s
Epoch: 5 cost time: 41.08467388153076
Epoch: 5, Steps: 256 Train Loss: 32.6584 (Forecasting Loss:0.2966 + XiCon Loss:3.2362 x Lambda(10.0)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1677
Validation loss decreased (0.221987 --> 0.220784).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.4330063
	speed: 0.1551s/iter; left time: 3757.4090s
	iters: 200, epoch: 6 | loss: 31.5458717
	speed: 0.1582s/iter; left time: 3815.2122s
Epoch: 6 cost time: 40.803706407547
Epoch: 6, Steps: 256 Train Loss: 32.7007 (Forecasting Loss:0.2959 + XiCon Loss:3.2405 x Lambda(10.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1671
Validation loss decreased (0.220784 --> 0.220636).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.6472969
	speed: 0.1609s/iter; left time: 3855.7022s
	iters: 200, epoch: 7 | loss: 33.1095428
	speed: 0.1518s/iter; left time: 3623.3008s
Epoch: 7 cost time: 40.49491500854492
Epoch: 7, Steps: 256 Train Loss: 32.6562 (Forecasting Loss:0.2954 + XiCon Loss:3.2361 x Lambda(10.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1671
Validation loss decreased (0.220636 --> 0.220332).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.7964516
	speed: 0.1639s/iter; left time: 3884.8074s
	iters: 200, epoch: 8 | loss: 32.8927841
	speed: 0.1446s/iter; left time: 3414.7284s
Epoch: 8 cost time: 39.74437093734741
Epoch: 8, Steps: 256 Train Loss: 32.7442 (Forecasting Loss:0.2954 + XiCon Loss:3.2449 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1672
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.2038078
	speed: 0.1630s/iter; left time: 3822.8965s
	iters: 200, epoch: 9 | loss: 32.0381470
	speed: 0.1604s/iter; left time: 3746.6010s
Epoch: 9 cost time: 41.3110466003418
Epoch: 9, Steps: 256 Train Loss: 32.7796 (Forecasting Loss:0.2953 + XiCon Loss:3.2484 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1671
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 34.1973495
	speed: 0.1609s/iter; left time: 3732.5436s
	iters: 200, epoch: 10 | loss: 33.9998131
	speed: 0.1516s/iter; left time: 3501.5535s
Epoch: 10 cost time: 40.41309094429016
Epoch: 10, Steps: 256 Train Loss: 32.6997 (Forecasting Loss:0.2952 + XiCon Loss:3.2405 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1670
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 35.9868927
	speed: 0.1584s/iter; left time: 3634.6314s
	iters: 200, epoch: 11 | loss: 32.4869270
	speed: 0.1514s/iter; left time: 3458.9462s
Epoch: 11 cost time: 39.98112487792969
Epoch: 11, Steps: 256 Train Loss: 32.7538 (Forecasting Loss:0.2952 + XiCon Loss:3.2459 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1670
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.8205910
	speed: 0.1693s/iter; left time: 3840.3265s
	iters: 200, epoch: 12 | loss: 31.0571327
	speed: 0.1564s/iter; left time: 3531.9360s
Epoch: 12 cost time: 41.44188380241394
Epoch: 12, Steps: 256 Train Loss: 32.7447 (Forecasting Loss:0.2951 + XiCon Loss:3.2450 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1670
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.7510223
	speed: 0.1624s/iter; left time: 3642.9921s
	iters: 200, epoch: 13 | loss: 31.3369713
	speed: 0.1586s/iter; left time: 3541.1652s
Epoch: 13 cost time: 41.005895376205444
Epoch: 13, Steps: 256 Train Loss: 32.6801 (Forecasting Loss:0.2951 + XiCon Loss:3.2385 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1670
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.5765953
	speed: 0.1645s/iter; left time: 3646.8411s
	iters: 200, epoch: 14 | loss: 33.7503624
	speed: 0.1550s/iter; left time: 3420.3152s
Epoch: 14 cost time: 40.713897466659546
Epoch: 14, Steps: 256 Train Loss: 32.7473 (Forecasting Loss:0.2951 + XiCon Loss:3.2452 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1670
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.8628235
	speed: 0.1670s/iter; left time: 3660.4395s
	iters: 200, epoch: 15 | loss: 34.4791412
	speed: 0.1538s/iter; left time: 3355.0599s
Epoch: 15 cost time: 41.0888454914093
Epoch: 15, Steps: 256 Train Loss: 32.6754 (Forecasting Loss:0.2951 + XiCon Loss:3.2380 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1670
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.1246071
	speed: 0.1625s/iter; left time: 3519.2444s
	iters: 200, epoch: 16 | loss: 31.1194324
	speed: 0.1524s/iter; left time: 3286.9015s
Epoch: 16 cost time: 40.52493762969971
Epoch: 16, Steps: 256 Train Loss: 32.6667 (Forecasting Loss:0.2951 + XiCon Loss:3.2372 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1670
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.6365738
	speed: 0.1636s/iter; left time: 3502.4123s
	iters: 200, epoch: 17 | loss: 33.3920212
	speed: 0.1560s/iter; left time: 3322.6619s
Epoch: 17 cost time: 40.67265582084656
Epoch: 17, Steps: 256 Train Loss: 32.6696 (Forecasting Loss:0.2951 + XiCon Loss:3.2374 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1670
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09356589615345001, mae:0.2406984567642212, mape:0.17554542422294617, mspe:0.047530245035886765 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.6725
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 32.1559029
	speed: 0.1364s/iter; left time: 3479.0363s
	iters: 200, epoch: 1 | loss: 31.1053524
	speed: 0.1322s/iter; left time: 3357.2699s
Epoch: 1 cost time: 34.29665207862854
Epoch: 1, Steps: 256 Train Loss: 32.2964 (Forecasting Loss:0.3018 + XiCon Loss:3.1995 x Lambda(10.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1647
Validation loss decreased (inf --> 0.222233).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 36.8375053
	speed: 0.1542s/iter; left time: 3893.0613s
	iters: 200, epoch: 2 | loss: 39.4462051
	speed: 0.1473s/iter; left time: 3703.6041s
Epoch: 2 cost time: 38.461233139038086
Epoch: 2, Steps: 256 Train Loss: 35.3140 (Forecasting Loss:0.3075 + XiCon Loss:3.5007 x Lambda(10.0)), Vali MSE Loss: 0.2234 Test MSE Loss: 0.1693
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.5108795
	speed: 0.1469s/iter; left time: 3669.6557s
	iters: 200, epoch: 3 | loss: 33.1281624
	speed: 0.1449s/iter; left time: 3606.0374s
Epoch: 3 cost time: 37.610071659088135
Epoch: 3, Steps: 256 Train Loss: 32.5890 (Forecasting Loss:0.3019 + XiCon Loss:3.2287 x Lambda(10.0)), Vali MSE Loss: 0.2224 Test MSE Loss: 0.1682
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.4485626
	speed: 0.1440s/iter; left time: 3560.7217s
	iters: 200, epoch: 4 | loss: 33.1451988
	speed: 0.1462s/iter; left time: 3600.9625s
Epoch: 4 cost time: 37.29297089576721
Epoch: 4, Steps: 256 Train Loss: 32.4273 (Forecasting Loss:0.2982 + XiCon Loss:3.2129 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1684
Validation loss decreased (0.222233 --> 0.220548).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.9917068
	speed: 0.1473s/iter; left time: 3606.2984s
	iters: 200, epoch: 5 | loss: 31.8403149
	speed: 0.1465s/iter; left time: 3571.2756s
Epoch: 5 cost time: 37.75815534591675
Epoch: 5, Steps: 256 Train Loss: 31.9121 (Forecasting Loss:0.2969 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1675
Validation loss decreased (0.220548 --> 0.219665).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.5494003
	speed: 0.1475s/iter; left time: 3573.7436s
	iters: 200, epoch: 6 | loss: 32.0111961
	speed: 0.1417s/iter; left time: 3417.7043s
Epoch: 6 cost time: 37.28264904022217
Epoch: 6, Steps: 256 Train Loss: 31.6442 (Forecasting Loss:0.2964 + XiCon Loss:3.1348 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1672
Validation loss decreased (0.219665 --> 0.219473).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.8215809
	speed: 0.1379s/iter; left time: 3304.0702s
	iters: 200, epoch: 7 | loss: 32.8938637
	speed: 0.1457s/iter; left time: 3476.6050s
Epoch: 7 cost time: 36.48975992202759
Epoch: 7, Steps: 256 Train Loss: 31.5574 (Forecasting Loss:0.2959 + XiCon Loss:3.1261 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1669
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0973473
	speed: 0.1508s/iter; left time: 3576.2551s
	iters: 200, epoch: 8 | loss: 31.1618462
	speed: 0.1483s/iter; left time: 3502.3676s
Epoch: 8 cost time: 38.19731426239014
Epoch: 8, Steps: 256 Train Loss: 31.5145 (Forecasting Loss:0.2957 + XiCon Loss:3.1219 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1671
Validation loss decreased (0.219473 --> 0.219403).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.2844658
	speed: 0.1506s/iter; left time: 3531.5869s
	iters: 200, epoch: 9 | loss: 32.2908211
	speed: 0.1450s/iter; left time: 3385.7451s
Epoch: 9 cost time: 38.12717580795288
Epoch: 9, Steps: 256 Train Loss: 31.5507 (Forecasting Loss:0.2956 + XiCon Loss:3.1255 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.2980366
	speed: 0.1532s/iter; left time: 3553.7782s
	iters: 200, epoch: 10 | loss: 32.4104805
	speed: 0.1466s/iter; left time: 3385.2521s
Epoch: 10 cost time: 38.59955596923828
Epoch: 10, Steps: 256 Train Loss: 31.5215 (Forecasting Loss:0.2955 + XiCon Loss:3.1226 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1670
Validation loss decreased (0.219403 --> 0.219354).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.7613029
	speed: 0.1507s/iter; left time: 3457.9013s
	iters: 200, epoch: 11 | loss: 32.1621819
	speed: 0.1410s/iter; left time: 3219.4790s
Epoch: 11 cost time: 37.25815176963806
Epoch: 11, Steps: 256 Train Loss: 31.4820 (Forecasting Loss:0.2955 + XiCon Loss:3.1187 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.0191174
	speed: 0.1462s/iter; left time: 3316.0710s
	iters: 200, epoch: 12 | loss: 32.1328278
	speed: 0.1431s/iter; left time: 3231.9257s
Epoch: 12 cost time: 37.14065599441528
Epoch: 12, Steps: 256 Train Loss: 31.5002 (Forecasting Loss:0.2955 + XiCon Loss:3.1205 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.1912861
	speed: 0.1467s/iter; left time: 3290.9696s
	iters: 200, epoch: 13 | loss: 31.4266796
	speed: 0.1429s/iter; left time: 3189.7223s
Epoch: 13 cost time: 37.049007415771484
Epoch: 13, Steps: 256 Train Loss: 31.5434 (Forecasting Loss:0.2955 + XiCon Loss:3.1248 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1670
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6711807
	speed: 0.1447s/iter; left time: 3207.3951s
	iters: 200, epoch: 14 | loss: 30.8414345
	speed: 0.1440s/iter; left time: 3177.7182s
Epoch: 14 cost time: 37.00538945198059
Epoch: 14, Steps: 256 Train Loss: 31.4986 (Forecasting Loss:0.2955 + XiCon Loss:3.1203 x Lambda(10.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1670
Validation loss decreased (0.219354 --> 0.219199).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.7470226
	speed: 0.1483s/iter; left time: 3249.2561s
	iters: 200, epoch: 15 | loss: 31.3313198
	speed: 0.1443s/iter; left time: 3147.2126s
Epoch: 15 cost time: 37.48561882972717
Epoch: 15, Steps: 256 Train Loss: 31.4593 (Forecasting Loss:0.2955 + XiCon Loss:3.1164 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.3117981
	speed: 0.1496s/iter; left time: 3240.2883s
	iters: 200, epoch: 16 | loss: 30.5887756
	speed: 0.1463s/iter; left time: 3154.1568s
Epoch: 16 cost time: 37.58735394477844
Epoch: 16, Steps: 256 Train Loss: 31.5152 (Forecasting Loss:0.2955 + XiCon Loss:3.1220 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.4379101
	speed: 0.1422s/iter; left time: 3043.3916s
	iters: 200, epoch: 17 | loss: 31.3501701
	speed: 0.1519s/iter; left time: 3235.9396s
Epoch: 17 cost time: 37.149492502212524
Epoch: 17, Steps: 256 Train Loss: 31.4975 (Forecasting Loss:0.2955 + XiCon Loss:3.1202 x Lambda(10.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1670
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.1705360
	speed: 0.1459s/iter; left time: 3084.9332s
	iters: 200, epoch: 18 | loss: 31.1702499
	speed: 0.1438s/iter; left time: 3027.0813s
Epoch: 18 cost time: 37.046608686447144
Epoch: 18, Steps: 256 Train Loss: 31.5126 (Forecasting Loss:0.2955 + XiCon Loss:3.1217 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1670
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.5508499
	speed: 0.1442s/iter; left time: 3012.9236s
	iters: 200, epoch: 19 | loss: 31.1423397
	speed: 0.1391s/iter; left time: 2892.4296s
Epoch: 19 cost time: 36.7530517578125
Epoch: 19, Steps: 256 Train Loss: 31.5000 (Forecasting Loss:0.2955 + XiCon Loss:3.1204 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1670
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.8536015
	speed: 0.1456s/iter; left time: 3004.7501s
	iters: 200, epoch: 20 | loss: 31.6520805
	speed: 0.1506s/iter; left time: 3093.2261s
Epoch: 20 cost time: 37.8869411945343
Epoch: 20, Steps: 256 Train Loss: 31.4757 (Forecasting Loss:0.2955 + XiCon Loss:3.1180 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.1670
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.9097366
	speed: 0.1471s/iter; left time: 2997.0403s
	iters: 200, epoch: 21 | loss: 30.8946056
	speed: 0.1480s/iter; left time: 3002.2492s
Epoch: 21 cost time: 37.743526458740234
Epoch: 21, Steps: 256 Train Loss: 31.5437 (Forecasting Loss:0.2955 + XiCon Loss:3.1248 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1670
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.6121159
	speed: 0.1477s/iter; left time: 2971.8416s
	iters: 200, epoch: 22 | loss: 30.8126526
	speed: 0.1433s/iter; left time: 2869.5435s
Epoch: 22 cost time: 37.714733600616455
Epoch: 22, Steps: 256 Train Loss: 31.5199 (Forecasting Loss:0.2955 + XiCon Loss:3.1224 x Lambda(10.0)), Vali MSE Loss: 0.2194 Test MSE Loss: 0.1670
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.7874088
	speed: 0.1494s/iter; left time: 2969.0897s
	iters: 200, epoch: 23 | loss: 31.3103905
	speed: 0.1399s/iter; left time: 2764.8355s
Epoch: 23 cost time: 37.09500575065613
Epoch: 23, Steps: 256 Train Loss: 31.4739 (Forecasting Loss:0.2955 + XiCon Loss:3.1178 x Lambda(10.0)), Vali MSE Loss: 0.2193 Test MSE Loss: 0.1670
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.1633301
	speed: 0.1505s/iter; left time: 2951.3999s
	iters: 200, epoch: 24 | loss: 30.9990158
	speed: 0.1445s/iter; left time: 2819.5037s
Epoch: 24 cost time: 37.16303777694702
Epoch: 24, Steps: 256 Train Loss: 31.4818 (Forecasting Loss:0.2955 + XiCon Loss:3.1186 x Lambda(10.0)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1670
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09348572045564651, mae:0.24042776226997375, mape:0.1752697378396988, mspe:0.04737401381134987 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 29.8645
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 31.9764462
	speed: 0.1325s/iter; left time: 3378.0048s
	iters: 200, epoch: 1 | loss: 31.5309238
	speed: 0.1388s/iter; left time: 3524.9582s
Epoch: 1 cost time: 34.81986904144287
Epoch: 1, Steps: 256 Train Loss: 32.2565 (Forecasting Loss:0.3049 + XiCon Loss:3.1952 x Lambda(10.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1669
Validation loss decreased (inf --> 0.218290).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 34.9034348
	speed: 0.1584s/iter; left time: 3999.0684s
	iters: 200, epoch: 2 | loss: 34.2195206
	speed: 0.1403s/iter; left time: 3528.7252s
Epoch: 2 cost time: 38.17488646507263
Epoch: 2, Steps: 256 Train Loss: 34.6111 (Forecasting Loss:0.3050 + XiCon Loss:3.4306 x Lambda(10.0)), Vali MSE Loss: 0.2254 Test MSE Loss: 0.1682
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 33.2905998
	speed: 0.1471s/iter; left time: 3676.7908s
	iters: 200, epoch: 3 | loss: 32.7953835
	speed: 0.1469s/iter; left time: 3656.9406s
Epoch: 3 cost time: 37.17979383468628
Epoch: 3, Steps: 256 Train Loss: 33.6649 (Forecasting Loss:0.2995 + XiCon Loss:3.3365 x Lambda(10.0)), Vali MSE Loss: 0.2227 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 33.1214104
	speed: 0.1528s/iter; left time: 3779.9581s
	iters: 200, epoch: 4 | loss: 34.6901207
	speed: 0.1431s/iter; left time: 3525.4271s
Epoch: 4 cost time: 37.655653953552246
Epoch: 4, Steps: 256 Train Loss: 32.8404 (Forecasting Loss:0.2976 + XiCon Loss:3.2543 x Lambda(10.0)), Vali MSE Loss: 0.2213 Test MSE Loss: 0.1678
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.6514149
	speed: 0.1522s/iter; left time: 3724.2106s
	iters: 200, epoch: 5 | loss: 32.3963318
	speed: 0.1402s/iter; left time: 3418.3101s
Epoch: 5 cost time: 37.44159531593323
Epoch: 5, Steps: 256 Train Loss: 32.4986 (Forecasting Loss:0.2966 + XiCon Loss:3.2202 x Lambda(10.0)), Vali MSE Loss: 0.2214 Test MSE Loss: 0.1657
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.6122208
	speed: 0.1526s/iter; left time: 3695.4993s
	iters: 200, epoch: 6 | loss: 31.7767429
	speed: 0.1471s/iter; left time: 3549.1556s
Epoch: 6 cost time: 37.99042367935181
Epoch: 6, Steps: 256 Train Loss: 32.4106 (Forecasting Loss:0.2958 + XiCon Loss:3.2115 x Lambda(10.0)), Vali MSE Loss: 0.2210 Test MSE Loss: 0.1658
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.7986889
	speed: 0.1540s/iter; left time: 3690.8498s
	iters: 200, epoch: 7 | loss: 31.4328270
	speed: 0.1419s/iter; left time: 3385.4404s
Epoch: 7 cost time: 37.97036576271057
Epoch: 7, Steps: 256 Train Loss: 32.1938 (Forecasting Loss:0.2955 + XiCon Loss:3.1898 x Lambda(10.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1657
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 33.6212845
	speed: 0.1508s/iter; left time: 3575.5962s
	iters: 200, epoch: 8 | loss: 33.5472107
	speed: 0.1475s/iter; left time: 3482.9606s
Epoch: 8 cost time: 37.909252405166626
Epoch: 8, Steps: 256 Train Loss: 32.1755 (Forecasting Loss:0.2952 + XiCon Loss:3.1880 x Lambda(10.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1656
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.9056034
	speed: 0.1442s/iter; left time: 3382.8311s
	iters: 200, epoch: 9 | loss: 31.3937855
	speed: 0.1445s/iter; left time: 3374.8904s
Epoch: 9 cost time: 37.219836711883545
Epoch: 9, Steps: 256 Train Loss: 32.1166 (Forecasting Loss:0.2951 + XiCon Loss:3.1822 x Lambda(10.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1656
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 32.0065842
	speed: 0.1450s/iter; left time: 3364.7153s
	iters: 200, epoch: 10 | loss: 32.1702766
	speed: 0.1437s/iter; left time: 3319.5726s
Epoch: 10 cost time: 37.15398335456848
Epoch: 10, Steps: 256 Train Loss: 32.1323 (Forecasting Loss:0.2950 + XiCon Loss:3.1837 x Lambda(10.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1656
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.7207718
	speed: 0.1464s/iter; left time: 3358.4974s
	iters: 200, epoch: 11 | loss: 32.4053154
	speed: 0.1382s/iter; left time: 3156.8299s
Epoch: 11 cost time: 36.5842924118042
Epoch: 11, Steps: 256 Train Loss: 32.2108 (Forecasting Loss:0.2950 + XiCon Loss:3.1916 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1656
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.09322701394557953, mae:0.24052409827709198, mape:0.1759844273328781, mspe:0.04793963581323624 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.1470
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 32.1053925
	speed: 0.1422s/iter; left time: 3625.0263s
	iters: 200, epoch: 1 | loss: 31.6683464
	speed: 0.1389s/iter; left time: 3527.7821s
Epoch: 1 cost time: 35.91709351539612
Epoch: 1, Steps: 256 Train Loss: 32.3119 (Forecasting Loss:0.3055 + XiCon Loss:3.2006 x Lambda(10.0)), Vali MSE Loss: 0.2200 Test MSE Loss: 0.1672
Validation loss decreased (inf --> 0.219973).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.8503189
	speed: 0.1578s/iter; left time: 3984.2196s
	iters: 200, epoch: 2 | loss: 32.2739983
	speed: 0.1480s/iter; left time: 3722.4547s
Epoch: 2 cost time: 39.01836562156677
Epoch: 2, Steps: 256 Train Loss: 33.5324 (Forecasting Loss:0.3056 + XiCon Loss:3.3227 x Lambda(10.0)), Vali MSE Loss: 0.2236 Test MSE Loss: 0.1676
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.4726658
	speed: 0.1498s/iter; left time: 3744.0948s
	iters: 200, epoch: 3 | loss: 31.0292969
	speed: 0.1457s/iter; left time: 3625.6317s
Epoch: 3 cost time: 37.9030876159668
Epoch: 3, Steps: 256 Train Loss: 31.6384 (Forecasting Loss:0.3003 + XiCon Loss:3.1338 x Lambda(10.0)), Vali MSE Loss: 0.2235 Test MSE Loss: 0.1676
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0478363
	speed: 0.1523s/iter; left time: 3767.8591s
	iters: 200, epoch: 4 | loss: 31.0103855
	speed: 0.1468s/iter; left time: 3616.7824s
Epoch: 4 cost time: 37.99305081367493
Epoch: 4, Steps: 256 Train Loss: 31.5261 (Forecasting Loss:0.2977 + XiCon Loss:3.1228 x Lambda(10.0)), Vali MSE Loss: 0.2216 Test MSE Loss: 0.1662
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.9380875
	speed: 0.1494s/iter; left time: 3657.9844s
	iters: 200, epoch: 5 | loss: 30.8548107
	speed: 0.1505s/iter; left time: 3669.3879s
Epoch: 5 cost time: 38.237460136413574
Epoch: 5, Steps: 256 Train Loss: 31.4312 (Forecasting Loss:0.2965 + XiCon Loss:3.1135 x Lambda(10.0)), Vali MSE Loss: 0.2207 Test MSE Loss: 0.1650
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6726093
	speed: 0.1519s/iter; left time: 3679.4107s
	iters: 200, epoch: 6 | loss: 30.8908997
	speed: 0.1536s/iter; left time: 3704.4359s
Epoch: 6 cost time: 39.107439041137695
Epoch: 6, Steps: 256 Train Loss: 31.3552 (Forecasting Loss:0.2959 + XiCon Loss:3.1059 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1654
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9927826
	speed: 0.1532s/iter; left time: 3671.1428s
	iters: 200, epoch: 7 | loss: 30.8940105
	speed: 0.1431s/iter; left time: 3415.3436s
Epoch: 7 cost time: 38.19083070755005
Epoch: 7, Steps: 256 Train Loss: 31.3503 (Forecasting Loss:0.2956 + XiCon Loss:3.1055 x Lambda(10.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1652
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0133533
	speed: 0.1557s/iter; left time: 3692.4782s
	iters: 200, epoch: 8 | loss: 31.9657478
	speed: 0.1452s/iter; left time: 3428.8626s
Epoch: 8 cost time: 38.378249645233154
Epoch: 8, Steps: 256 Train Loss: 31.3852 (Forecasting Loss:0.2954 + XiCon Loss:3.1090 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1652
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.9017334
	speed: 0.1559s/iter; left time: 3655.4324s
	iters: 200, epoch: 9 | loss: 30.9191132
	speed: 0.1544s/iter; left time: 3606.7352s
Epoch: 9 cost time: 39.82841086387634
Epoch: 9, Steps: 256 Train Loss: 31.3946 (Forecasting Loss:0.2953 + XiCon Loss:3.1099 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1650
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.8052483
	speed: 0.1600s/iter; left time: 3711.0904s
	iters: 200, epoch: 10 | loss: 31.5855122
	speed: 0.1555s/iter; left time: 3592.0994s
Epoch: 10 cost time: 39.944884061813354
Epoch: 10, Steps: 256 Train Loss: 31.4069 (Forecasting Loss:0.2952 + XiCon Loss:3.1112 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1651
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1742401
	speed: 0.1549s/iter; left time: 3554.1038s
	iters: 200, epoch: 11 | loss: 31.0959435
	speed: 0.1547s/iter; left time: 3532.8088s
Epoch: 11 cost time: 39.573755502700806
Epoch: 11, Steps: 256 Train Loss: 31.3349 (Forecasting Loss:0.2952 + XiCon Loss:3.1040 x Lambda(10.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.1650
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.0935516357421875, mae:0.2408028244972229, mape:0.1760767102241516, mspe:0.04798917844891548 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1010177
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 32.0378
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 32.0665474
	speed: 0.1411s/iter; left time: 3596.9941s
	iters: 200, epoch: 1 | loss: 31.4108295
	speed: 0.1373s/iter; left time: 3487.8202s
Epoch: 1 cost time: 35.815574407577515
Epoch: 1, Steps: 256 Train Loss: 32.0779 (Forecasting Loss:0.3049 + XiCon Loss:3.1773 x Lambda(10.0)), Vali MSE Loss: 0.2148 Test MSE Loss: 0.1614
Validation loss decreased (inf --> 0.214832).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.1356773
	speed: 0.1559s/iter; left time: 3936.9307s
	iters: 200, epoch: 2 | loss: 32.7959099
	speed: 0.1425s/iter; left time: 3583.4467s
Epoch: 2 cost time: 38.48382925987244
Epoch: 2, Steps: 256 Train Loss: 32.7926 (Forecasting Loss:0.3060 + XiCon Loss:3.2487 x Lambda(10.0)), Vali MSE Loss: 0.2263 Test MSE Loss: 0.1700
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0420303
	speed: 0.1477s/iter; left time: 3690.1645s
	iters: 200, epoch: 3 | loss: 30.5886917
	speed: 0.1450s/iter; left time: 3610.0510s
Epoch: 3 cost time: 37.798407554626465
Epoch: 3, Steps: 256 Train Loss: 31.3204 (Forecasting Loss:0.3001 + XiCon Loss:3.1020 x Lambda(10.0)), Vali MSE Loss: 0.2210 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0342484
	speed: 0.1463s/iter; left time: 3618.2304s
	iters: 200, epoch: 4 | loss: 30.8761902
	speed: 0.1469s/iter; left time: 3617.5819s
Epoch: 4 cost time: 37.86378359794617
Epoch: 4, Steps: 256 Train Loss: 31.2662 (Forecasting Loss:0.2981 + XiCon Loss:3.0968 x Lambda(10.0)), Vali MSE Loss: 0.2212 Test MSE Loss: 0.1663
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.8080559
	speed: 0.1532s/iter; left time: 3749.5205s
	iters: 200, epoch: 5 | loss: 30.6910114
	speed: 0.1422s/iter; left time: 3466.5877s
Epoch: 5 cost time: 37.48449730873108
Epoch: 5, Steps: 256 Train Loss: 31.1624 (Forecasting Loss:0.2963 + XiCon Loss:3.0866 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1691
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.9177628
	speed: 0.1453s/iter; left time: 3518.6844s
	iters: 200, epoch: 6 | loss: 31.1164417
	speed: 0.1399s/iter; left time: 3373.3817s
Epoch: 6 cost time: 36.16054892539978
Epoch: 6, Steps: 256 Train Loss: 31.1964 (Forecasting Loss:0.2953 + XiCon Loss:3.0901 x Lambda(10.0)), Vali MSE Loss: 0.2205 Test MSE Loss: 0.1680
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.2408676
	speed: 0.1488s/iter; left time: 3566.4242s
	iters: 200, epoch: 7 | loss: 31.5009098
	speed: 0.1457s/iter; left time: 3477.7803s
Epoch: 7 cost time: 37.349191427230835
Epoch: 7, Steps: 256 Train Loss: 31.1705 (Forecasting Loss:0.2948 + XiCon Loss:3.0876 x Lambda(10.0)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1681
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.9087925
	speed: 0.1467s/iter; left time: 3478.5979s
	iters: 200, epoch: 8 | loss: 31.5413456
	speed: 0.1422s/iter; left time: 3356.1280s
Epoch: 8 cost time: 36.57128381729126
Epoch: 8, Steps: 256 Train Loss: 31.0900 (Forecasting Loss:0.2946 + XiCon Loss:3.0795 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1680
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.6730556
	speed: 0.1497s/iter; left time: 3511.0937s
	iters: 200, epoch: 9 | loss: 30.6716385
	speed: 0.1410s/iter; left time: 3293.2851s
Epoch: 9 cost time: 37.0846791267395
Epoch: 9, Steps: 256 Train Loss: 31.1625 (Forecasting Loss:0.2945 + XiCon Loss:3.0868 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1682
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5208569
	speed: 0.1513s/iter; left time: 3508.7059s
	iters: 200, epoch: 10 | loss: 30.6902657
	speed: 0.1442s/iter; left time: 3330.8834s
Epoch: 10 cost time: 37.15346574783325
Epoch: 10, Steps: 256 Train Loss: 31.1397 (Forecasting Loss:0.2944 + XiCon Loss:3.0845 x Lambda(10.0)), Vali MSE Loss: 0.2203 Test MSE Loss: 0.1684
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.7785816
	speed: 0.1510s/iter; left time: 3464.2466s
	iters: 200, epoch: 11 | loss: 30.9211960
	speed: 0.1399s/iter; left time: 3196.5171s
Epoch: 11 cost time: 37.39200520515442
Epoch: 11, Steps: 256 Train Loss: 31.1463 (Forecasting Loss:0.2944 + XiCon Loss:3.0852 x Lambda(10.0)), Vali MSE Loss: 0.2204 Test MSE Loss: 0.1684
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl1440_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.08915270864963531, mae:0.23362477123737335, mape:0.17079487442970276, mspe:0.04539888724684715 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0926+-0.00240, MAE:0.2392+-0.00388, MAPE:0.1747+-0.00276, MSPE:0.0472+-0.00132, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 31.1168
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 33.0601425
	speed: 0.1785s/iter; left time: 4337.2457s
	iters: 200, epoch: 1 | loss: 31.9540558
	speed: 0.1703s/iter; left time: 4120.3800s
Epoch: 1 cost time: 42.70123839378357
Epoch: 1, Steps: 244 Train Loss: 32.8310 (Forecasting Loss:0.3674 + XiCon Loss:3.2464 x Lambda(10.0)), Vali MSE Loss: 0.2639 Test MSE Loss: 0.1705
Validation loss decreased (inf --> 0.263898).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 32.0854225
	speed: 0.2107s/iter; left time: 5068.6624s
	iters: 200, epoch: 2 | loss: 33.4053574
	speed: 0.1980s/iter; left time: 4743.0990s
Epoch: 2 cost time: 49.720829248428345
Epoch: 2, Steps: 244 Train Loss: 32.0499 (Forecasting Loss:0.3760 + XiCon Loss:3.1674 x Lambda(10.0)), Vali MSE Loss: 0.2698 Test MSE Loss: 0.1754
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 30.8928280
	speed: 0.1973s/iter; left time: 4699.3349s
	iters: 200, epoch: 3 | loss: 31.0726204
	speed: 0.1954s/iter; left time: 4632.6223s
Epoch: 3 cost time: 47.818220138549805
Epoch: 3, Steps: 244 Train Loss: 31.1501 (Forecasting Loss:0.3649 + XiCon Loss:3.0785 x Lambda(10.0)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.1728
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 30.4806271
	speed: 0.1956s/iter; left time: 4609.9321s
	iters: 200, epoch: 4 | loss: 30.7731361
	speed: 0.1958s/iter; left time: 4594.7704s
Epoch: 4 cost time: 47.820146560668945
Epoch: 4, Steps: 244 Train Loss: 30.8082 (Forecasting Loss:0.3605 + XiCon Loss:3.0448 x Lambda(10.0)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1699
Validation loss decreased (0.263898 --> 0.261004).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 30.8505001
	speed: 0.1962s/iter; left time: 4575.7624s
	iters: 200, epoch: 5 | loss: 31.3447857
	speed: 0.1955s/iter; left time: 4540.4287s
Epoch: 5 cost time: 47.76428508758545
Epoch: 5, Steps: 244 Train Loss: 30.7487 (Forecasting Loss:0.3577 + XiCon Loss:3.0391 x Lambda(10.0)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.1696
Validation loss decreased (0.261004 --> 0.259782).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 30.3379269
	speed: 0.1969s/iter; left time: 4545.4343s
	iters: 200, epoch: 6 | loss: 30.6865826
	speed: 0.1940s/iter; left time: 4458.7857s
Epoch: 6 cost time: 47.8159863948822
Epoch: 6, Steps: 244 Train Loss: 30.7328 (Forecasting Loss:0.3476 + XiCon Loss:3.0385 x Lambda(10.0)), Vali MSE Loss: 0.2558 Test MSE Loss: 0.1662
Validation loss decreased (0.259782 --> 0.255796).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 30.5256538
	speed: 0.1993s/iter; left time: 4550.9014s
	iters: 200, epoch: 7 | loss: 30.3955650
	speed: 0.1959s/iter; left time: 4454.8986s
Epoch: 7 cost time: 48.18574047088623
Epoch: 7, Steps: 244 Train Loss: 30.7215 (Forecasting Loss:0.3447 + XiCon Loss:3.0377 x Lambda(10.0)), Vali MSE Loss: 0.2543 Test MSE Loss: 0.1645
Validation loss decreased (0.255796 --> 0.254305).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 31.0413513
	speed: 0.2021s/iter; left time: 4564.9763s
	iters: 200, epoch: 8 | loss: 30.3827763
	speed: 0.1974s/iter; left time: 4439.4424s
Epoch: 8 cost time: 48.82084774971008
Epoch: 8, Steps: 244 Train Loss: 30.6849 (Forecasting Loss:0.3429 + XiCon Loss:3.0342 x Lambda(10.0)), Vali MSE Loss: 0.2534 Test MSE Loss: 0.1641
Validation loss decreased (0.254305 --> 0.253418).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 30.8191719
	speed: 0.1980s/iter; left time: 4424.7410s
	iters: 200, epoch: 9 | loss: 30.3705997
	speed: 0.2006s/iter; left time: 4464.1039s
Epoch: 9 cost time: 48.69163680076599
Epoch: 9, Steps: 244 Train Loss: 30.6608 (Forecasting Loss:0.3422 + XiCon Loss:3.0319 x Lambda(10.0)), Vali MSE Loss: 0.2532 Test MSE Loss: 0.1639
Validation loss decreased (0.253418 --> 0.253192).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 30.1311302
	speed: 0.2046s/iter; left time: 4523.7015s
	iters: 200, epoch: 10 | loss: 30.4280281
	speed: 0.1936s/iter; left time: 4260.7323s
Epoch: 10 cost time: 48.19623422622681
Epoch: 10, Steps: 244 Train Loss: 30.6610 (Forecasting Loss:0.3420 + XiCon Loss:3.0319 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1638
Validation loss decreased (0.253192 --> 0.252832).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 30.6932087
	speed: 0.1969s/iter; left time: 4303.5890s
	iters: 200, epoch: 11 | loss: 30.5311699
	speed: 0.1993s/iter; left time: 4337.8726s
Epoch: 11 cost time: 48.36379671096802
Epoch: 11, Steps: 244 Train Loss: 30.6461 (Forecasting Loss:0.3416 + XiCon Loss:3.0304 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1639
Validation loss decreased (0.252832 --> 0.252672).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 30.2918034
	speed: 0.2059s/iter; left time: 4449.9520s
	iters: 200, epoch: 12 | loss: 30.7737484
	speed: 0.2196s/iter; left time: 4724.6896s
Epoch: 12 cost time: 50.478886127471924
Epoch: 12, Steps: 244 Train Loss: 30.6787 (Forecasting Loss:0.3417 + XiCon Loss:3.0337 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1638
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 30.7772598
	speed: 0.1993s/iter; left time: 4259.9188s
	iters: 200, epoch: 13 | loss: 30.8838120
	speed: 0.1960s/iter; left time: 4169.0371s
Epoch: 13 cost time: 48.090834617614746
Epoch: 13, Steps: 244 Train Loss: 30.6849 (Forecasting Loss:0.3414 + XiCon Loss:3.0343 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1638
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 30.6386814
	speed: 0.2002s/iter; left time: 4230.3504s
	iters: 200, epoch: 14 | loss: 30.4984341
	speed: 0.1897s/iter; left time: 3988.5228s
Epoch: 14 cost time: 47.264941930770874
Epoch: 14, Steps: 244 Train Loss: 30.6624 (Forecasting Loss:0.3416 + XiCon Loss:3.0321 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1638
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 30.9477158
	speed: 0.1991s/iter; left time: 4159.2248s
	iters: 200, epoch: 15 | loss: 30.3954391
	speed: 0.1944s/iter; left time: 4040.2900s
Epoch: 15 cost time: 48.31180691719055
Epoch: 15, Steps: 244 Train Loss: 30.6912 (Forecasting Loss:0.3413 + XiCon Loss:3.0350 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1638
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 30.7883492
	speed: 0.1979s/iter; left time: 4084.2572s
	iters: 200, epoch: 16 | loss: 30.8372650
	speed: 0.1981s/iter; left time: 4069.3982s
Epoch: 16 cost time: 48.176918506622314
Epoch: 16, Steps: 244 Train Loss: 30.6572 (Forecasting Loss:0.3414 + XiCon Loss:3.0316 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1638
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 30.4356537
	speed: 0.1929s/iter; left time: 3935.4632s
	iters: 200, epoch: 17 | loss: 30.4843102
	speed: 0.1932s/iter; left time: 3921.7761s
Epoch: 17 cost time: 47.44971823692322
Epoch: 17, Steps: 244 Train Loss: 30.6625 (Forecasting Loss:0.3414 + XiCon Loss:3.0321 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1638
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 30.4447613
	speed: 0.2010s/iter; left time: 4050.7259s
	iters: 200, epoch: 18 | loss: 30.4720879
	speed: 0.1930s/iter; left time: 3870.5546s
Epoch: 18 cost time: 48.363794803619385
Epoch: 18, Steps: 244 Train Loss: 30.6806 (Forecasting Loss:0.3413 + XiCon Loss:3.0339 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1638
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 30.7549076
	speed: 0.2037s/iter; left time: 4055.6575s
	iters: 200, epoch: 19 | loss: 30.4040947
	speed: 0.2015s/iter; left time: 3991.6780s
Epoch: 19 cost time: 49.451276779174805
Epoch: 19, Steps: 244 Train Loss: 30.6649 (Forecasting Loss:0.3414 + XiCon Loss:3.0324 x Lambda(10.0)), Vali MSE Loss: 0.2529 Test MSE Loss: 0.1638
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 30.1831036
	speed: 0.1996s/iter; left time: 3925.7813s
	iters: 200, epoch: 20 | loss: 31.0714722
	speed: 0.1953s/iter; left time: 3821.0462s
Epoch: 20 cost time: 48.40932655334473
Epoch: 20, Steps: 244 Train Loss: 30.6708 (Forecasting Loss:0.3412 + XiCon Loss:3.0330 x Lambda(10.0)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1638
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 31.2134495
	speed: 0.2039s/iter; left time: 3960.0366s
	iters: 200, epoch: 21 | loss: 30.5825996
	speed: 0.1995s/iter; left time: 3855.2508s
Epoch: 21 cost time: 49.01164507865906
Epoch: 21, Steps: 244 Train Loss: 30.6662 (Forecasting Loss:0.3414 + XiCon Loss:3.0325 x Lambda(10.0)), Vali MSE Loss: 0.2528 Test MSE Loss: 0.1638
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09038519114255905, mae:0.2373954802751541, mape:0.16973945498466492, mspe:0.043924007564783096 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 29.3922
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 33.0630264
	speed: 0.1671s/iter; left time: 4060.0901s
	iters: 200, epoch: 1 | loss: 32.0483360
	speed: 0.1595s/iter; left time: 3860.0601s
Epoch: 1 cost time: 39.984357595443726
Epoch: 1, Steps: 244 Train Loss: 32.9559 (Forecasting Loss:0.3660 + XiCon Loss:3.2590 x Lambda(10.0)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.1707
Validation loss decreased (inf --> 0.266285).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 31.8227367
	speed: 0.1969s/iter; left time: 4737.2796s
	iters: 200, epoch: 2 | loss: 31.3529243
	speed: 0.1866s/iter; left time: 4470.7164s
Epoch: 2 cost time: 47.097625494003296
Epoch: 2, Steps: 244 Train Loss: 32.0949 (Forecasting Loss:0.3728 + XiCon Loss:3.1722 x Lambda(10.0)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.1692
Validation loss decreased (0.266285 --> 0.260860).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 31.4777584
	speed: 0.1922s/iter; left time: 4577.9841s
	iters: 200, epoch: 3 | loss: 30.9685535
	speed: 0.1813s/iter; left time: 4298.7057s
Epoch: 3 cost time: 45.52568435668945
Epoch: 3, Steps: 244 Train Loss: 31.1581 (Forecasting Loss:0.3597 + XiCon Loss:3.0798 x Lambda(10.0)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.1653
Validation loss decreased (0.260860 --> 0.257731).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 31.1931229
	speed: 0.1874s/iter; left time: 4416.7130s
	iters: 200, epoch: 4 | loss: 30.6966362
	speed: 0.1846s/iter; left time: 4331.5178s
Epoch: 4 cost time: 45.361053466796875
Epoch: 4, Steps: 244 Train Loss: 31.0696 (Forecasting Loss:0.3527 + XiCon Loss:3.0717 x Lambda(10.0)), Vali MSE Loss: 0.2547 Test MSE Loss: 0.1634
Validation loss decreased (0.257731 --> 0.254747).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 31.6761665
	speed: 0.1841s/iter; left time: 4294.6553s
	iters: 200, epoch: 5 | loss: 31.5680714
	speed: 0.1867s/iter; left time: 4336.4477s
Epoch: 5 cost time: 45.234713554382324
Epoch: 5, Steps: 244 Train Loss: 31.0006 (Forecasting Loss:0.3493 + XiCon Loss:3.0651 x Lambda(10.0)), Vali MSE Loss: 0.2533 Test MSE Loss: 0.1629
Validation loss decreased (0.254747 --> 0.253258).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 31.1063538
	speed: 0.1897s/iter; left time: 4377.8492s
	iters: 200, epoch: 6 | loss: 31.3249512
	speed: 0.1833s/iter; left time: 4211.6548s
Epoch: 6 cost time: 45.523123025894165
Epoch: 6, Steps: 244 Train Loss: 30.9739 (Forecasting Loss:0.3485 + XiCon Loss:3.0625 x Lambda(10.0)), Vali MSE Loss: 0.2563 Test MSE Loss: 0.1640
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 30.8637886
	speed: 0.1824s/iter; left time: 4166.4792s
	iters: 200, epoch: 7 | loss: 30.4828587
	speed: 0.1779s/iter; left time: 4044.8067s
Epoch: 7 cost time: 43.99655365943909
Epoch: 7, Steps: 244 Train Loss: 30.9578 (Forecasting Loss:0.3477 + XiCon Loss:3.0610 x Lambda(10.0)), Vali MSE Loss: 0.2567 Test MSE Loss: 0.1643
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 30.8815289
	speed: 0.1816s/iter; left time: 4103.8781s
	iters: 200, epoch: 8 | loss: 30.8097057
	speed: 0.1794s/iter; left time: 4034.2094s
Epoch: 8 cost time: 44.1751983165741
Epoch: 8, Steps: 244 Train Loss: 30.9330 (Forecasting Loss:0.3473 + XiCon Loss:3.0586 x Lambda(10.0)), Vali MSE Loss: 0.2545 Test MSE Loss: 0.1632
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 31.2811928
	speed: 0.1710s/iter; left time: 3822.7679s
	iters: 200, epoch: 9 | loss: 30.7402973
	speed: 0.1778s/iter; left time: 3955.9704s
Epoch: 9 cost time: 42.570948123931885
Epoch: 9, Steps: 244 Train Loss: 30.9352 (Forecasting Loss:0.3471 + XiCon Loss:3.0588 x Lambda(10.0)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.1636
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 31.2778778
	speed: 0.1833s/iter; left time: 4052.6697s
	iters: 200, epoch: 10 | loss: 30.7870579
	speed: 0.1746s/iter; left time: 3841.7327s
Epoch: 10 cost time: 43.65714764595032
Epoch: 10, Steps: 244 Train Loss: 30.9170 (Forecasting Loss:0.3471 + XiCon Loss:3.0570 x Lambda(10.0)), Vali MSE Loss: 0.2546 Test MSE Loss: 0.1631
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 30.5830116
	speed: 0.1820s/iter; left time: 3977.8879s
	iters: 200, epoch: 11 | loss: 31.3243179
	speed: 0.1815s/iter; left time: 3949.1616s
Epoch: 11 cost time: 44.206090450286865
Epoch: 11, Steps: 244 Train Loss: 30.9473 (Forecasting Loss:0.3471 + XiCon Loss:3.0600 x Lambda(10.0)), Vali MSE Loss: 0.2551 Test MSE Loss: 0.1634
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 30.6538754
	speed: 0.1783s/iter; left time: 3854.5317s
	iters: 200, epoch: 12 | loss: 31.0922966
	speed: 0.1803s/iter; left time: 3880.4793s
Epoch: 12 cost time: 43.84321188926697
Epoch: 12, Steps: 244 Train Loss: 30.9218 (Forecasting Loss:0.3471 + XiCon Loss:3.0575 x Lambda(10.0)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.1633
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 30.9726791
	speed: 0.1821s/iter; left time: 3892.9246s
	iters: 200, epoch: 13 | loss: 31.1958389
	speed: 0.1777s/iter; left time: 3780.1489s
Epoch: 13 cost time: 43.832213401794434
Epoch: 13, Steps: 244 Train Loss: 30.9016 (Forecasting Loss:0.3468 + XiCon Loss:3.0555 x Lambda(10.0)), Vali MSE Loss: 0.2550 Test MSE Loss: 0.1632
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 30.5726566
	speed: 0.1861s/iter; left time: 3932.2695s
	iters: 200, epoch: 14 | loss: 31.1817017
	speed: 0.1761s/iter; left time: 3704.2136s
Epoch: 14 cost time: 44.0857572555542
Epoch: 14, Steps: 244 Train Loss: 30.9145 (Forecasting Loss:0.3466 + XiCon Loss:3.0568 x Lambda(10.0)), Vali MSE Loss: 0.2548 Test MSE Loss: 0.1632
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 30.5459309
	speed: 0.2049s/iter; left time: 4280.1234s
	iters: 200, epoch: 15 | loss: 30.8422508
	speed: 0.1731s/iter; left time: 3598.3289s
Epoch: 15 cost time: 45.96106457710266
Epoch: 15, Steps: 244 Train Loss: 30.9345 (Forecasting Loss:0.3470 + XiCon Loss:3.0587 x Lambda(10.0)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.1632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08911523222923279, mae:0.236695796251297, mape:0.16974200308322906, mspe:0.04383738338947296 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 32.0327
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 32.5808487
	speed: 0.1722s/iter; left time: 4185.0819s
	iters: 200, epoch: 1 | loss: 31.2963371
	speed: 0.1680s/iter; left time: 4064.9377s
Epoch: 1 cost time: 41.40102553367615
Epoch: 1, Steps: 244 Train Loss: 32.5394 (Forecasting Loss:0.3631 + XiCon Loss:3.2176 x Lambda(10.0)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1725
Validation loss decreased (inf --> 0.261449).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 31.9935074
	speed: 0.2036s/iter; left time: 4897.7628s
	iters: 200, epoch: 2 | loss: 31.9844341
	speed: 0.1914s/iter; left time: 4586.0270s
Epoch: 2 cost time: 47.95976448059082
Epoch: 2, Steps: 244 Train Loss: 31.9130 (Forecasting Loss:0.3788 + XiCon Loss:3.1534 x Lambda(10.0)), Vali MSE Loss: 0.2775 Test MSE Loss: 0.1795
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 31.1661339
	speed: 0.1998s/iter; left time: 4757.1021s
	iters: 200, epoch: 3 | loss: 30.8550453
	speed: 0.1885s/iter; left time: 4471.0689s
Epoch: 3 cost time: 47.163127183914185
Epoch: 3, Steps: 244 Train Loss: 31.1450 (Forecasting Loss:0.3690 + XiCon Loss:3.0776 x Lambda(10.0)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.1725
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 30.7067089
	speed: 0.1960s/iter; left time: 4618.7308s
	iters: 200, epoch: 4 | loss: 30.7194500
	speed: 0.1866s/iter; left time: 4380.3989s
Epoch: 4 cost time: 46.61881613731384
Epoch: 4, Steps: 244 Train Loss: 31.0031 (Forecasting Loss:0.3623 + XiCon Loss:3.0641 x Lambda(10.0)), Vali MSE Loss: 0.2690 Test MSE Loss: 0.1707
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 30.7474136
	speed: 0.1946s/iter; left time: 4539.5690s
	iters: 200, epoch: 5 | loss: 30.6797333
	speed: 0.1913s/iter; left time: 4443.7485s
Epoch: 5 cost time: 47.04766082763672
Epoch: 5, Steps: 244 Train Loss: 30.9222 (Forecasting Loss:0.3601 + XiCon Loss:3.0562 x Lambda(10.0)), Vali MSE Loss: 0.2688 Test MSE Loss: 0.1695
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 30.8399754
	speed: 0.1936s/iter; left time: 4468.9939s
	iters: 200, epoch: 6 | loss: 30.4831886
	speed: 0.1891s/iter; left time: 4345.6242s
Epoch: 6 cost time: 46.6294219493866
Epoch: 6, Steps: 244 Train Loss: 30.9003 (Forecasting Loss:0.3591 + XiCon Loss:3.0541 x Lambda(10.0)), Vali MSE Loss: 0.2677 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 30.6408730
	speed: 0.1926s/iter; left time: 4397.9564s
	iters: 200, epoch: 7 | loss: 30.6830997
	speed: 0.1805s/iter; left time: 4103.0108s
Epoch: 7 cost time: 45.472830295562744
Epoch: 7, Steps: 244 Train Loss: 30.9064 (Forecasting Loss:0.3583 + XiCon Loss:3.0548 x Lambda(10.0)), Vali MSE Loss: 0.2678 Test MSE Loss: 0.1686
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 30.9587135
	speed: 0.1906s/iter; left time: 4307.2843s
	iters: 200, epoch: 8 | loss: 30.8592987
	speed: 0.1882s/iter; left time: 4232.4711s
Epoch: 8 cost time: 46.378746509552
Epoch: 8, Steps: 244 Train Loss: 30.8674 (Forecasting Loss:0.3580 + XiCon Loss:3.0509 x Lambda(10.0)), Vali MSE Loss: 0.2675 Test MSE Loss: 0.1689
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 30.9214077
	speed: 0.1927s/iter; left time: 4307.1698s
	iters: 200, epoch: 9 | loss: 30.8186607
	speed: 0.1878s/iter; left time: 4179.1693s
Epoch: 9 cost time: 46.19768786430359
Epoch: 9, Steps: 244 Train Loss: 30.8578 (Forecasting Loss:0.3579 + XiCon Loss:3.0500 x Lambda(10.0)), Vali MSE Loss: 0.2677 Test MSE Loss: 0.1690
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 31.0422249
	speed: 0.1877s/iter; left time: 4149.3134s
	iters: 200, epoch: 10 | loss: 30.5201550
	speed: 0.1855s/iter; left time: 4082.6558s
Epoch: 10 cost time: 45.73789024353027
Epoch: 10, Steps: 244 Train Loss: 30.8969 (Forecasting Loss:0.3577 + XiCon Loss:3.0539 x Lambda(10.0)), Vali MSE Loss: 0.2675 Test MSE Loss: 0.1690
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 30.9519081
	speed: 0.1889s/iter; left time: 4130.2540s
	iters: 200, epoch: 11 | loss: 30.5352840
	speed: 0.1868s/iter; left time: 4065.6205s
Epoch: 11 cost time: 45.945252656936646
Epoch: 11, Steps: 244 Train Loss: 30.8729 (Forecasting Loss:0.3577 + XiCon Loss:3.0515 x Lambda(10.0)), Vali MSE Loss: 0.2676 Test MSE Loss: 0.1689
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09771720319986343, mae:0.24734032154083252, mape:0.17566780745983124, mspe:0.04655517265200615 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 28.5113
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 33.1898766
	speed: 0.1612s/iter; left time: 3917.2276s
	iters: 200, epoch: 1 | loss: 32.5474091
	speed: 0.1505s/iter; left time: 3641.7919s
Epoch: 1 cost time: 37.96896481513977
Epoch: 1, Steps: 244 Train Loss: 32.9479 (Forecasting Loss:0.3676 + XiCon Loss:3.2580 x Lambda(10.0)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.1788
Validation loss decreased (inf --> 0.271885).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 31.9692745
	speed: 0.1875s/iter; left time: 4509.6470s
	iters: 200, epoch: 2 | loss: 32.1506805
	speed: 0.1796s/iter; left time: 4301.6191s
Epoch: 2 cost time: 44.31544780731201
Epoch: 2, Steps: 244 Train Loss: 32.6173 (Forecasting Loss:0.3765 + XiCon Loss:3.2241 x Lambda(10.0)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.1751
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 31.1823406
	speed: 0.1821s/iter; left time: 4335.9018s
	iters: 200, epoch: 3 | loss: 31.8088570
	speed: 0.1793s/iter; left time: 4252.6949s
Epoch: 3 cost time: 44.29726815223694
Epoch: 3, Steps: 244 Train Loss: 31.8365 (Forecasting Loss:0.3659 + XiCon Loss:3.1471 x Lambda(10.0)), Vali MSE Loss: 0.2713 Test MSE Loss: 0.1695
Validation loss decreased (0.271885 --> 0.271350).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 31.0569115
	speed: 0.1850s/iter; left time: 4361.3857s
	iters: 200, epoch: 4 | loss: 31.5480518
	speed: 0.1817s/iter; left time: 4264.0498s
Epoch: 4 cost time: 44.64263367652893
Epoch: 4, Steps: 244 Train Loss: 31.6275 (Forecasting Loss:0.3598 + XiCon Loss:3.1268 x Lambda(10.0)), Vali MSE Loss: 0.2773 Test MSE Loss: 0.1720
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 31.4899235
	speed: 0.1840s/iter; left time: 4291.5498s
	iters: 200, epoch: 5 | loss: 31.1187897
	speed: 0.1803s/iter; left time: 4186.9326s
Epoch: 5 cost time: 44.24905300140381
Epoch: 5, Steps: 244 Train Loss: 31.5450 (Forecasting Loss:0.3566 + XiCon Loss:3.1188 x Lambda(10.0)), Vali MSE Loss: 0.2695 Test MSE Loss: 0.1681
Validation loss decreased (0.271350 --> 0.269500).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 31.7890434
	speed: 0.1864s/iter; left time: 4302.4278s
	iters: 200, epoch: 6 | loss: 31.0230103
	speed: 0.1782s/iter; left time: 4094.5647s
Epoch: 6 cost time: 44.57371950149536
Epoch: 6, Steps: 244 Train Loss: 31.4949 (Forecasting Loss:0.3540 + XiCon Loss:3.1141 x Lambda(10.0)), Vali MSE Loss: 0.2697 Test MSE Loss: 0.1671
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 31.6956635
	speed: 0.1889s/iter; left time: 4314.9387s
	iters: 200, epoch: 7 | loss: 31.8290443
	speed: 0.1786s/iter; left time: 4060.3275s
Epoch: 7 cost time: 44.856019496917725
Epoch: 7, Steps: 244 Train Loss: 31.4648 (Forecasting Loss:0.3528 + XiCon Loss:3.1112 x Lambda(10.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1665
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 30.9615402
	speed: 0.1835s/iter; left time: 4146.3381s
	iters: 200, epoch: 8 | loss: 32.2652817
	speed: 0.1773s/iter; left time: 3988.4079s
Epoch: 8 cost time: 44.19125461578369
Epoch: 8, Steps: 244 Train Loss: 31.4316 (Forecasting Loss:0.3520 + XiCon Loss:3.1080 x Lambda(10.0)), Vali MSE Loss: 0.2708 Test MSE Loss: 0.1667
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 31.2219334
	speed: 0.1883s/iter; left time: 4208.6951s
	iters: 200, epoch: 9 | loss: 30.6713791
	speed: 0.1834s/iter; left time: 4081.3589s
Epoch: 9 cost time: 44.89567518234253
Epoch: 9, Steps: 244 Train Loss: 31.4083 (Forecasting Loss:0.3516 + XiCon Loss:3.1057 x Lambda(10.0)), Vali MSE Loss: 0.2707 Test MSE Loss: 0.1671
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 31.4811821
	speed: 0.1853s/iter; left time: 4095.9110s
	iters: 200, epoch: 10 | loss: 30.7145557
	speed: 0.1763s/iter; left time: 3880.3394s
Epoch: 10 cost time: 44.129448652267456
Epoch: 10, Steps: 244 Train Loss: 31.4085 (Forecasting Loss:0.3513 + XiCon Loss:3.1057 x Lambda(10.0)), Vali MSE Loss: 0.2705 Test MSE Loss: 0.1671
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 31.4609833
	speed: 0.1858s/iter; left time: 4061.7827s
	iters: 200, epoch: 11 | loss: 31.0699673
	speed: 0.1790s/iter; left time: 3895.4092s
Epoch: 11 cost time: 44.36163115501404
Epoch: 11, Steps: 244 Train Loss: 31.3639 (Forecasting Loss:0.3512 + XiCon Loss:3.1013 x Lambda(10.0)), Vali MSE Loss: 0.2707 Test MSE Loss: 0.1671
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 31.5098400
	speed: 0.1880s/iter; left time: 4063.7004s
	iters: 200, epoch: 12 | loss: 31.0140114
	speed: 0.1757s/iter; left time: 3781.1830s
Epoch: 12 cost time: 44.340561628341675
Epoch: 12, Steps: 244 Train Loss: 31.4115 (Forecasting Loss:0.3512 + XiCon Loss:3.1060 x Lambda(10.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1664
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 31.3920345
	speed: 0.1811s/iter; left time: 3871.6426s
	iters: 200, epoch: 13 | loss: 31.0542908
	speed: 0.1833s/iter; left time: 3899.2105s
Epoch: 13 cost time: 45.329429626464844
Epoch: 13, Steps: 244 Train Loss: 31.3900 (Forecasting Loss:0.3512 + XiCon Loss:3.1039 x Lambda(10.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1665
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 31.6709499
	speed: 0.1829s/iter; left time: 3865.3769s
	iters: 200, epoch: 14 | loss: 31.3036098
	speed: 0.1785s/iter; left time: 3753.5791s
Epoch: 14 cost time: 44.42918395996094
Epoch: 14, Steps: 244 Train Loss: 31.3760 (Forecasting Loss:0.3511 + XiCon Loss:3.1025 x Lambda(10.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1666
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 31.9124508
	speed: 0.1865s/iter; left time: 3894.7960s
	iters: 200, epoch: 15 | loss: 30.8483868
	speed: 0.1776s/iter; left time: 3690.6555s
Epoch: 15 cost time: 44.389071464538574
Epoch: 15, Steps: 244 Train Loss: 31.3600 (Forecasting Loss:0.3512 + XiCon Loss:3.1009 x Lambda(10.0)), Vali MSE Loss: 0.2702 Test MSE Loss: 0.1666
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.09406070411205292, mae:0.24219615757465363, mape:0.17347444593906403, mspe:0.046147726476192474 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1948065
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 29.3290
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 32.6582832
	speed: 0.1661s/iter; left time: 4035.3144s
	iters: 200, epoch: 1 | loss: 31.8405323
	speed: 0.1516s/iter; left time: 3668.6915s
Epoch: 1 cost time: 38.62624382972717
Epoch: 1, Steps: 244 Train Loss: 32.6563 (Forecasting Loss:0.3646 + XiCon Loss:3.2292 x Lambda(10.0)), Vali MSE Loss: 0.2728 Test MSE Loss: 0.1729
Validation loss decreased (inf --> 0.272763).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 31.4504108
	speed: 0.1910s/iter; left time: 4595.8625s
	iters: 200, epoch: 2 | loss: 32.8867035
	speed: 0.1816s/iter; left time: 4349.8453s
Epoch: 2 cost time: 45.352755069732666
Epoch: 2, Steps: 244 Train Loss: 32.0949 (Forecasting Loss:0.3704 + XiCon Loss:3.1724 x Lambda(10.0)), Vali MSE Loss: 0.2673 Test MSE Loss: 0.1805
Validation loss decreased (0.272763 --> 0.267287).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 31.3113327
	speed: 0.1885s/iter; left time: 4489.1011s
	iters: 200, epoch: 3 | loss: 31.4151211
	speed: 0.1835s/iter; left time: 4352.2259s
Epoch: 3 cost time: 45.63417673110962
Epoch: 3, Steps: 244 Train Loss: 31.5980 (Forecasting Loss:0.3598 + XiCon Loss:3.1238 x Lambda(10.0)), Vali MSE Loss: 0.2566 Test MSE Loss: 0.1704
Validation loss decreased (0.267287 --> 0.256628).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 31.4038963
	speed: 0.1882s/iter; left time: 4435.5023s
	iters: 200, epoch: 4 | loss: 30.9669647
	speed: 0.1837s/iter; left time: 4310.9960s
Epoch: 4 cost time: 45.55285859107971
Epoch: 4, Steps: 244 Train Loss: 31.3774 (Forecasting Loss:0.3525 + XiCon Loss:3.1025 x Lambda(10.0)), Vali MSE Loss: 0.2531 Test MSE Loss: 0.1689
Validation loss decreased (0.256628 --> 0.253099).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 30.4130154
	speed: 0.1883s/iter; left time: 4393.0135s
	iters: 200, epoch: 5 | loss: 31.0256329
	speed: 0.1870s/iter; left time: 4343.2109s
Epoch: 5 cost time: 46.196083784103394
Epoch: 5, Steps: 244 Train Loss: 31.2227 (Forecasting Loss:0.3465 + XiCon Loss:3.0876 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1652
Validation loss decreased (0.253099 --> 0.250222).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 31.1433392
	speed: 0.1892s/iter; left time: 4367.9323s
	iters: 200, epoch: 6 | loss: 31.5864506
	speed: 0.1864s/iter; left time: 4283.5442s
Epoch: 6 cost time: 45.75873279571533
Epoch: 6, Steps: 244 Train Loss: 31.0944 (Forecasting Loss:0.3401 + XiCon Loss:3.0754 x Lambda(10.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1625
Validation loss decreased (0.250222 --> 0.248381).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 30.9603405
	speed: 0.1875s/iter; left time: 4282.9519s
	iters: 200, epoch: 7 | loss: 30.9907818
	speed: 0.1819s/iter; left time: 4136.6176s
Epoch: 7 cost time: 45.301734924316406
Epoch: 7, Steps: 244 Train Loss: 31.0725 (Forecasting Loss:0.3364 + XiCon Loss:3.0736 x Lambda(10.0)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1618
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 30.9695587
	speed: 0.1934s/iter; left time: 4369.2665s
	iters: 200, epoch: 8 | loss: 30.4486752
	speed: 0.1830s/iter; left time: 4116.0627s
Epoch: 8 cost time: 45.98954629898071
Epoch: 8, Steps: 244 Train Loss: 31.0278 (Forecasting Loss:0.3353 + XiCon Loss:3.0693 x Lambda(10.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1610
Validation loss decreased (0.248381 --> 0.248084).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 30.2757511
	speed: 0.1840s/iter; left time: 4111.8907s
	iters: 200, epoch: 9 | loss: 31.4569397
	speed: 0.1834s/iter; left time: 4081.3761s
Epoch: 9 cost time: 45.245032787323
Epoch: 9, Steps: 244 Train Loss: 31.0232 (Forecasting Loss:0.3334 + XiCon Loss:3.0690 x Lambda(10.0)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.1608
Validation loss decreased (0.248084 --> 0.244694).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 31.2735729
	speed: 0.1928s/iter; left time: 4261.8746s
	iters: 200, epoch: 10 | loss: 30.5605488
	speed: 0.1781s/iter; left time: 3919.9096s
Epoch: 10 cost time: 45.37039494514465
Epoch: 10, Steps: 244 Train Loss: 31.0798 (Forecasting Loss:0.3331 + XiCon Loss:3.0747 x Lambda(10.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.1608
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 31.2122326
	speed: 0.1900s/iter; left time: 4152.7269s
	iters: 200, epoch: 11 | loss: 30.9395485
	speed: 0.1849s/iter; left time: 4023.5480s
Epoch: 11 cost time: 45.650930643081665
Epoch: 11, Steps: 244 Train Loss: 31.0256 (Forecasting Loss:0.3330 + XiCon Loss:3.0693 x Lambda(10.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.1607
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 30.8257732
	speed: 0.1918s/iter; left time: 4145.0656s
	iters: 200, epoch: 12 | loss: 30.7793503
	speed: 0.1845s/iter; left time: 3970.5007s
Epoch: 12 cost time: 45.964982986450195
Epoch: 12, Steps: 244 Train Loss: 31.0647 (Forecasting Loss:0.3326 + XiCon Loss:3.0732 x Lambda(10.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1607
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 31.5949879
	speed: 0.1842s/iter; left time: 3935.9652s
	iters: 200, epoch: 13 | loss: 30.7128372
	speed: 0.1875s/iter; left time: 3988.3536s
Epoch: 13 cost time: 45.46943998336792
Epoch: 13, Steps: 244 Train Loss: 31.0714 (Forecasting Loss:0.3327 + XiCon Loss:3.0739 x Lambda(10.0)), Vali MSE Loss: 0.2505 Test MSE Loss: 0.1607
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 31.7188530
	speed: 0.1927s/iter; left time: 4070.5223s
	iters: 200, epoch: 14 | loss: 29.9770546
	speed: 0.1860s/iter; left time: 3911.2684s
Epoch: 14 cost time: 46.137906551361084
Epoch: 14, Steps: 244 Train Loss: 31.0067 (Forecasting Loss:0.3328 + XiCon Loss:3.0674 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1607
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 31.0542393
	speed: 0.1835s/iter; left time: 3831.7685s
	iters: 200, epoch: 15 | loss: 30.9311199
	speed: 0.1810s/iter; left time: 3762.3397s
Epoch: 15 cost time: 44.706706285476685
Epoch: 15, Steps: 244 Train Loss: 31.0340 (Forecasting Loss:0.3327 + XiCon Loss:3.0701 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1607
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 30.3916912
	speed: 0.1910s/iter; left time: 3942.4443s
	iters: 200, epoch: 16 | loss: 31.2989044
	speed: 0.2374s/iter; left time: 4875.5022s
Epoch: 16 cost time: 54.103222131729126
Epoch: 16, Steps: 244 Train Loss: 31.0695 (Forecasting Loss:0.3327 + XiCon Loss:3.0737 x Lambda(10.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.1607
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 31.6508636
	speed: 0.2017s/iter; left time: 4113.6247s
	iters: 200, epoch: 17 | loss: 29.9620228
	speed: 0.1813s/iter; left time: 3680.1310s
Epoch: 17 cost time: 46.8212628364563
Epoch: 17, Steps: 244 Train Loss: 31.0256 (Forecasting Loss:0.3325 + XiCon Loss:3.0693 x Lambda(10.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.1607
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 30.8739719
	speed: 0.1865s/iter; left time: 3759.3864s
	iters: 200, epoch: 18 | loss: 30.6690331
	speed: 0.1867s/iter; left time: 3743.4135s
Epoch: 18 cost time: 46.2283079624176
Epoch: 18, Steps: 244 Train Loss: 31.0560 (Forecasting Loss:0.3327 + XiCon Loss:3.0723 x Lambda(10.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.1607
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 30.2946262
	speed: 0.2297s/iter; left time: 4572.6452s
	iters: 200, epoch: 19 | loss: 30.7564354
	speed: 0.2459s/iter; left time: 4870.3165s
Epoch: 19 cost time: 58.86233425140381
Epoch: 19, Steps: 244 Train Loss: 31.0355 (Forecasting Loss:0.3326 + XiCon Loss:3.0703 x Lambda(10.0)), Vali MSE Loss: 0.2502 Test MSE Loss: 0.1607
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl2880_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.08724673092365265, mae:0.2344096302986145, mape:0.16795390844345093, mspe:0.04284199699759483 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0917+-0.00520, MAE:0.2396+-0.00642, MAPE:0.1713+-0.00392, MSPE:0.0447+-0.00200, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 28.9207
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.3195419
	speed: 0.1603s/iter; left time: 3719.9203s
	iters: 200, epoch: 1 | loss: 33.9878616
	speed: 0.1544s/iter; left time: 3567.0183s
Epoch: 1 cost time: 36.82549524307251
Epoch: 1, Steps: 233 Train Loss: 34.3897 (Forecasting Loss:0.4392 + XiCon Loss:3.3951 x Lambda(10.0)), Vali MSE Loss: 0.2970 Test MSE Loss: 0.1875
Validation loss decreased (inf --> 0.296993).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7255230
	speed: 0.1890s/iter; left time: 4340.4528s
	iters: 200, epoch: 2 | loss: 31.3949299
	speed: 0.2587s/iter; left time: 5915.5580s
Epoch: 2 cost time: 53.51463556289673
Epoch: 2, Steps: 233 Train Loss: 31.7912 (Forecasting Loss:0.4121 + XiCon Loss:3.1379 x Lambda(10.0)), Vali MSE Loss: 0.2979 Test MSE Loss: 0.2029
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.2602139
	speed: 0.1868s/iter; left time: 4247.4605s
	iters: 200, epoch: 3 | loss: 30.8773232
	speed: 0.1787s/iter; left time: 4045.9740s
Epoch: 3 cost time: 42.309476375579834
Epoch: 3, Steps: 233 Train Loss: 31.1522 (Forecasting Loss:0.3623 + XiCon Loss:3.0790 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.1897
Validation loss decreased (0.296993 --> 0.289624).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.9443092
	speed: 0.1856s/iter; left time: 4177.0437s
	iters: 200, epoch: 4 | loss: 31.0797520
	speed: 0.1801s/iter; left time: 4035.3489s
Epoch: 4 cost time: 42.55587434768677
Epoch: 4, Steps: 233 Train Loss: 30.8845 (Forecasting Loss:0.3367 + XiCon Loss:3.0548 x Lambda(10.0)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.1871
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7462311
	speed: 0.1900s/iter; left time: 4231.9285s
	iters: 200, epoch: 5 | loss: 30.7325096
	speed: 0.1834s/iter; left time: 4064.7842s
Epoch: 5 cost time: 43.321765422821045
Epoch: 5, Steps: 233 Train Loss: 30.7715 (Forecasting Loss:0.3243 + XiCon Loss:3.0447 x Lambda(10.0)), Vali MSE Loss: 0.3388 Test MSE Loss: 0.1843
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4512501
	speed: 0.1857s/iter; left time: 4092.6221s
	iters: 200, epoch: 6 | loss: 30.8656578
	speed: 0.2138s/iter; left time: 4689.9882s
Epoch: 6 cost time: 48.71777391433716
Epoch: 6, Steps: 233 Train Loss: 30.7313 (Forecasting Loss:0.3173 + XiCon Loss:3.0414 x Lambda(10.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.1842
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0809689
	speed: 0.2314s/iter; left time: 5045.7778s
	iters: 200, epoch: 7 | loss: 30.5367165
	speed: 0.1837s/iter; left time: 3987.4646s
Epoch: 7 cost time: 47.33957505226135
Epoch: 7, Steps: 233 Train Loss: 30.6922 (Forecasting Loss:0.3141 + XiCon Loss:3.0378 x Lambda(10.0)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.1836
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.6091537
	speed: 0.1901s/iter; left time: 4099.6204s
	iters: 200, epoch: 8 | loss: 30.5635891
	speed: 0.1830s/iter; left time: 3929.5818s
Epoch: 8 cost time: 43.42539048194885
Epoch: 8, Steps: 233 Train Loss: 30.6656 (Forecasting Loss:0.3136 + XiCon Loss:3.0352 x Lambda(10.0)), Vali MSE Loss: 0.3136 Test MSE Loss: 0.1831
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.5281830
	speed: 0.2371s/iter; left time: 5058.3148s
	iters: 200, epoch: 9 | loss: 30.7048302
	speed: 0.2556s/iter; left time: 5428.9652s
Epoch: 9 cost time: 57.65812587738037
Epoch: 9, Steps: 233 Train Loss: 30.6483 (Forecasting Loss:0.3129 + XiCon Loss:3.0335 x Lambda(10.0)), Vali MSE Loss: 0.3136 Test MSE Loss: 0.1829
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.0427170
	speed: 0.1801s/iter; left time: 3801.0347s
	iters: 200, epoch: 10 | loss: 30.7280445
	speed: 0.1765s/iter; left time: 3707.3117s
Epoch: 10 cost time: 42.8987021446228
Epoch: 10, Steps: 233 Train Loss: 30.6833 (Forecasting Loss:0.3125 + XiCon Loss:3.0371 x Lambda(10.0)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.1827
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1040230
	speed: 0.2271s/iter; left time: 4739.5338s
	iters: 200, epoch: 11 | loss: 30.6343555
	speed: 0.2272s/iter; left time: 4720.1890s
Epoch: 11 cost time: 53.623804330825806
Epoch: 11, Steps: 233 Train Loss: 30.6516 (Forecasting Loss:0.3122 + XiCon Loss:3.0339 x Lambda(10.0)), Vali MSE Loss: 0.3122 Test MSE Loss: 0.1828
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3827858
	speed: 0.1989s/iter; left time: 4105.6240s
	iters: 200, epoch: 12 | loss: 30.6724701
	speed: 0.1805s/iter; left time: 3707.5446s
Epoch: 12 cost time: 44.85760498046875
Epoch: 12, Steps: 233 Train Loss: 30.6311 (Forecasting Loss:0.3123 + XiCon Loss:3.0319 x Lambda(10.0)), Vali MSE Loss: 0.3133 Test MSE Loss: 0.1828
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2970600
	speed: 0.2525s/iter; left time: 5152.1854s
	iters: 200, epoch: 13 | loss: 30.6614704
	speed: 0.1761s/iter; left time: 3576.2316s
Epoch: 13 cost time: 48.72526001930237
Epoch: 13, Steps: 233 Train Loss: 30.6391 (Forecasting Loss:0.3126 + XiCon Loss:3.0327 x Lambda(10.0)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.1828
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.11248043924570084, mae:0.26690348982810974, mape:0.18738040328025818, mspe:0.052272979170084 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.7069
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.1045723
	speed: 0.1396s/iter; left time: 3239.2423s
	iters: 200, epoch: 1 | loss: 33.0473099
	speed: 0.1441s/iter; left time: 3329.6301s
Epoch: 1 cost time: 32.99939513206482
Epoch: 1, Steps: 233 Train Loss: 33.8875 (Forecasting Loss:0.4519 + XiCon Loss:3.3436 x Lambda(10.0)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2023
Validation loss decreased (inf --> 0.311720).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.8863411
	speed: 0.1636s/iter; left time: 3758.3167s
	iters: 200, epoch: 2 | loss: 31.0499725
	speed: 0.1625s/iter; left time: 3715.3154s
Epoch: 2 cost time: 38.0903902053833
Epoch: 2, Steps: 233 Train Loss: 31.7638 (Forecasting Loss:0.4167 + XiCon Loss:3.1347 x Lambda(10.0)), Vali MSE Loss: 0.2716 Test MSE Loss: 0.1655
Validation loss decreased (0.311720 --> 0.271612).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8948097
	speed: 0.1657s/iter; left time: 3766.4837s
	iters: 200, epoch: 3 | loss: 30.8104725
	speed: 0.1629s/iter; left time: 3687.2311s
Epoch: 3 cost time: 38.06817650794983
Epoch: 3, Steps: 233 Train Loss: 31.1464 (Forecasting Loss:0.3849 + XiCon Loss:3.0761 x Lambda(10.0)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1626
Validation loss decreased (0.271612 --> 0.258598).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0724964
	speed: 0.1674s/iter; left time: 3766.1983s
	iters: 200, epoch: 4 | loss: 30.8259449
	speed: 0.1637s/iter; left time: 3667.1685s
Epoch: 4 cost time: 38.413331031799316
Epoch: 4, Steps: 233 Train Loss: 30.8863 (Forecasting Loss:0.3664 + XiCon Loss:3.0520 x Lambda(10.0)), Vali MSE Loss: 0.2540 Test MSE Loss: 0.1674
Validation loss decreased (0.258598 --> 0.254025).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7172470
	speed: 0.1633s/iter; left time: 3637.6396s
	iters: 200, epoch: 5 | loss: 30.5839539
	speed: 0.1610s/iter; left time: 3570.2522s
Epoch: 5 cost time: 38.0455048084259
Epoch: 5, Steps: 233 Train Loss: 30.8137 (Forecasting Loss:0.3527 + XiCon Loss:3.0461 x Lambda(10.0)), Vali MSE Loss: 0.2562 Test MSE Loss: 0.1689
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5922527
	speed: 0.1695s/iter; left time: 3734.1452s
	iters: 200, epoch: 6 | loss: 30.8269882
	speed: 0.1564s/iter; left time: 3430.9524s
Epoch: 6 cost time: 38.19243383407593
Epoch: 6, Steps: 233 Train Loss: 30.7547 (Forecasting Loss:0.3464 + XiCon Loss:3.0408 x Lambda(10.0)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.1713
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.5620308
	speed: 0.1736s/iter; left time: 3784.8313s
	iters: 200, epoch: 7 | loss: 30.6963425
	speed: 0.1604s/iter; left time: 3480.5939s
Epoch: 7 cost time: 38.89354491233826
Epoch: 7, Steps: 233 Train Loss: 30.7217 (Forecasting Loss:0.3440 + XiCon Loss:3.0378 x Lambda(10.0)), Vali MSE Loss: 0.2561 Test MSE Loss: 0.1707
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.8063812
	speed: 0.1600s/iter; left time: 3450.3185s
	iters: 200, epoch: 8 | loss: 30.7712460
	speed: 0.1618s/iter; left time: 3473.1282s
Epoch: 8 cost time: 37.69568657875061
Epoch: 8, Steps: 233 Train Loss: 30.7137 (Forecasting Loss:0.3429 + XiCon Loss:3.0371 x Lambda(10.0)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.1605
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.9786072
	speed: 0.1620s/iter; left time: 3457.0751s
	iters: 200, epoch: 9 | loss: 30.9069347
	speed: 0.1638s/iter; left time: 3478.4607s
Epoch: 9 cost time: 38.13076901435852
Epoch: 9, Steps: 233 Train Loss: 30.6928 (Forecasting Loss:0.3418 + XiCon Loss:3.0351 x Lambda(10.0)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1619
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7637177
	speed: 0.1717s/iter; left time: 3622.5231s
	iters: 200, epoch: 10 | loss: 31.2555637
	speed: 0.1590s/iter; left time: 3338.6915s
Epoch: 10 cost time: 38.64401340484619
Epoch: 10, Steps: 233 Train Loss: 30.6841 (Forecasting Loss:0.3416 + XiCon Loss:3.0343 x Lambda(10.0)), Vali MSE Loss: 0.2611 Test MSE Loss: 0.1622
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5466614
	speed: 0.1702s/iter; left time: 3551.4832s
	iters: 200, epoch: 11 | loss: 31.0616283
	speed: 0.1605s/iter; left time: 3334.1590s
Epoch: 11 cost time: 38.41237664222717
Epoch: 11, Steps: 233 Train Loss: 30.6805 (Forecasting Loss:0.3419 + XiCon Loss:3.0339 x Lambda(10.0)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.1627
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5704403
	speed: 0.1701s/iter; left time: 3509.6298s
	iters: 200, epoch: 12 | loss: 30.8525276
	speed: 0.1666s/iter; left time: 3421.6681s
Epoch: 12 cost time: 38.92806625366211
Epoch: 12, Steps: 233 Train Loss: 30.6818 (Forecasting Loss:0.3420 + XiCon Loss:3.0340 x Lambda(10.0)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1619
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.0454788
	speed: 0.1677s/iter; left time: 3421.8327s
	iters: 200, epoch: 13 | loss: 30.6743774
	speed: 0.1639s/iter; left time: 3327.0175s
Epoch: 13 cost time: 38.69470000267029
Epoch: 13, Steps: 233 Train Loss: 30.6969 (Forecasting Loss:0.3419 + XiCon Loss:3.0355 x Lambda(10.0)), Vali MSE Loss: 0.2614 Test MSE Loss: 0.1620
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6902351
	speed: 0.1732s/iter; left time: 3493.2484s
	iters: 200, epoch: 14 | loss: 30.9490662
	speed: 0.1702s/iter; left time: 3417.1391s
Epoch: 14 cost time: 39.87964940071106
Epoch: 14, Steps: 233 Train Loss: 30.6954 (Forecasting Loss:0.3417 + XiCon Loss:3.0354 x Lambda(10.0)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1616
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.09271474182605743, mae:0.2420845925807953, mape:0.17077010869979858, mspe:0.04376677796244621 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 31.9672
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.0459366
	speed: 0.1556s/iter; left time: 3611.0672s
	iters: 200, epoch: 1 | loss: 33.1903000
	speed: 0.1480s/iter; left time: 3419.6358s
Epoch: 1 cost time: 35.05860996246338
Epoch: 1, Steps: 233 Train Loss: 33.7629 (Forecasting Loss:0.4481 + XiCon Loss:3.3315 x Lambda(10.0)), Vali MSE Loss: 0.2996 Test MSE Loss: 0.1927
Validation loss decreased (inf --> 0.299637).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7212887
	speed: 0.1687s/iter; left time: 3875.0567s
	iters: 200, epoch: 2 | loss: 31.5161495
	speed: 0.1784s/iter; left time: 4080.5819s
Epoch: 2 cost time: 40.570316791534424
Epoch: 2, Steps: 233 Train Loss: 31.8588 (Forecasting Loss:0.4337 + XiCon Loss:3.1425 x Lambda(10.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2005
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8391361
	speed: 0.1819s/iter; left time: 4134.3994s
	iters: 200, epoch: 3 | loss: 31.0184746
	speed: 0.1726s/iter; left time: 3906.2502s
Epoch: 3 cost time: 41.680734634399414
Epoch: 3, Steps: 233 Train Loss: 31.5839 (Forecasting Loss:0.3877 + XiCon Loss:3.1196 x Lambda(10.0)), Vali MSE Loss: 0.3015 Test MSE Loss: 0.2012
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.7562141
	speed: 0.1754s/iter; left time: 3946.2172s
	iters: 200, epoch: 4 | loss: 30.5189133
	speed: 0.1625s/iter; left time: 3641.2614s
Epoch: 4 cost time: 39.47947859764099
Epoch: 4, Steps: 233 Train Loss: 30.8792 (Forecasting Loss:0.3588 + XiCon Loss:3.0520 x Lambda(10.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.1782
Validation loss decreased (0.299637 --> 0.289045).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7323723
	speed: 0.1614s/iter; left time: 3594.9143s
	iters: 200, epoch: 5 | loss: 30.6618328
	speed: 0.1520s/iter; left time: 3370.5438s
Epoch: 5 cost time: 36.871588706970215
Epoch: 5, Steps: 233 Train Loss: 30.6001 (Forecasting Loss:0.3439 + XiCon Loss:3.0256 x Lambda(10.0)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.1724
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7118492
	speed: 0.1608s/iter; left time: 3543.5529s
	iters: 200, epoch: 6 | loss: 30.3637733
	speed: 0.1718s/iter; left time: 3769.4090s
Epoch: 6 cost time: 39.56534004211426
Epoch: 6, Steps: 233 Train Loss: 30.5210 (Forecasting Loss:0.3402 + XiCon Loss:3.0181 x Lambda(10.0)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.1724
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4374008
	speed: 0.1827s/iter; left time: 3984.1173s
	iters: 200, epoch: 7 | loss: 30.3687401
	speed: 0.1729s/iter; left time: 3752.8603s
Epoch: 7 cost time: 41.515381813049316
Epoch: 7, Steps: 233 Train Loss: 30.4656 (Forecasting Loss:0.3366 + XiCon Loss:3.0129 x Lambda(10.0)), Vali MSE Loss: 0.3170 Test MSE Loss: 0.1722
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5305119
	speed: 0.1790s/iter; left time: 3860.0746s
	iters: 200, epoch: 8 | loss: 30.4149437
	speed: 0.1735s/iter; left time: 3724.6806s
Epoch: 8 cost time: 40.93270564079285
Epoch: 8, Steps: 233 Train Loss: 30.4485 (Forecasting Loss:0.3350 + XiCon Loss:3.0114 x Lambda(10.0)), Vali MSE Loss: 0.3142 Test MSE Loss: 0.1725
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.8005104
	speed: 0.1788s/iter; left time: 3815.6257s
	iters: 200, epoch: 9 | loss: 30.4625835
	speed: 0.1728s/iter; left time: 3668.7173s
Epoch: 9 cost time: 41.048415660858154
Epoch: 9, Steps: 233 Train Loss: 30.4468 (Forecasting Loss:0.3350 + XiCon Loss:3.0112 x Lambda(10.0)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.1716
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.3593807
	speed: 0.1771s/iter; left time: 3737.6976s
	iters: 200, epoch: 10 | loss: 30.2563934
	speed: 0.1720s/iter; left time: 3612.9112s
Epoch: 10 cost time: 40.68141007423401
Epoch: 10, Steps: 233 Train Loss: 30.4496 (Forecasting Loss:0.3352 + XiCon Loss:3.0114 x Lambda(10.0)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.1714
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4337902
	speed: 0.1768s/iter; left time: 3690.7612s
	iters: 200, epoch: 11 | loss: 30.4243622
	speed: 0.1685s/iter; left time: 3498.8943s
Epoch: 11 cost time: 40.343828439712524
Epoch: 11, Steps: 233 Train Loss: 30.4451 (Forecasting Loss:0.3350 + XiCon Loss:3.0110 x Lambda(10.0)), Vali MSE Loss: 0.3110 Test MSE Loss: 0.1713
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6793537
	speed: 0.1801s/iter; left time: 3717.6377s
	iters: 200, epoch: 12 | loss: 30.5227375
	speed: 0.1675s/iter; left time: 3439.1927s
Epoch: 12 cost time: 40.463106632232666
Epoch: 12, Steps: 233 Train Loss: 30.4623 (Forecasting Loss:0.3354 + XiCon Loss:3.0127 x Lambda(10.0)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.1714
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.4051056
	speed: 0.1700s/iter; left time: 3469.7981s
	iters: 200, epoch: 13 | loss: 30.4331913
	speed: 0.1736s/iter; left time: 3524.0707s
Epoch: 13 cost time: 40.1281156539917
Epoch: 13, Steps: 233 Train Loss: 30.4689 (Forecasting Loss:0.3351 + XiCon Loss:3.0134 x Lambda(10.0)), Vali MSE Loss: 0.3119 Test MSE Loss: 0.1713
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3454342
	speed: 0.1751s/iter; left time: 3532.2993s
	iters: 200, epoch: 14 | loss: 30.2239990
	speed: 0.1687s/iter; left time: 3385.2049s
Epoch: 14 cost time: 40.38866901397705
Epoch: 14, Steps: 233 Train Loss: 30.4411 (Forecasting Loss:0.3346 + XiCon Loss:3.0106 x Lambda(10.0)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.1713
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.10203941911458969, mae:0.25429341197013855, mape:0.17758680880069733, mspe:0.0465475432574749 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 30.5486
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.4083939
	speed: 0.1557s/iter; left time: 3611.8997s
	iters: 200, epoch: 1 | loss: 33.4040909
	speed: 0.1432s/iter; left time: 3308.2271s
Epoch: 1 cost time: 34.78940725326538
Epoch: 1, Steps: 233 Train Loss: 34.0349 (Forecasting Loss:0.4499 + XiCon Loss:3.3585 x Lambda(10.0)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.1977
Validation loss decreased (inf --> 0.304968).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.9146957
	speed: 0.1736s/iter; left time: 3986.2017s
	iters: 200, epoch: 2 | loss: 31.5257072
	speed: 0.1654s/iter; left time: 3782.5456s
Epoch: 2 cost time: 39.53434753417969
Epoch: 2, Steps: 233 Train Loss: 31.8882 (Forecasting Loss:0.4319 + XiCon Loss:3.1456 x Lambda(10.0)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.1896
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0973721
	speed: 0.1773s/iter; left time: 4031.7394s
	iters: 200, epoch: 3 | loss: 31.9504128
	speed: 0.1672s/iter; left time: 3784.9359s
Epoch: 3 cost time: 39.86827778816223
Epoch: 3, Steps: 233 Train Loss: 31.6439 (Forecasting Loss:0.4011 + XiCon Loss:3.1243 x Lambda(10.0)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.2129
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5212574
	speed: 0.1668s/iter; left time: 3754.4016s
	iters: 200, epoch: 4 | loss: 31.5383968
	speed: 0.1649s/iter; left time: 3694.7361s
Epoch: 4 cost time: 38.722771644592285
Epoch: 4, Steps: 233 Train Loss: 31.2757 (Forecasting Loss:0.3756 + XiCon Loss:3.0900 x Lambda(10.0)), Vali MSE Loss: 0.3350 Test MSE Loss: 0.1918
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0599766
	speed: 0.1661s/iter; left time: 3699.4141s
	iters: 200, epoch: 5 | loss: 31.0763016
	speed: 0.1631s/iter; left time: 3615.8991s
Epoch: 5 cost time: 38.42370080947876
Epoch: 5, Steps: 233 Train Loss: 31.1339 (Forecasting Loss:0.3527 + XiCon Loss:3.0781 x Lambda(10.0)), Vali MSE Loss: 0.3287 Test MSE Loss: 0.1845
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.0701466
	speed: 0.1728s/iter; left time: 3807.4549s
	iters: 200, epoch: 6 | loss: 30.9922848
	speed: 0.1685s/iter; left time: 3695.8431s
Epoch: 6 cost time: 39.97646522521973
Epoch: 6, Steps: 233 Train Loss: 31.0931 (Forecasting Loss:0.3444 + XiCon Loss:3.0749 x Lambda(10.0)), Vali MSE Loss: 0.3593 Test MSE Loss: 0.1814
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6676064
	speed: 0.1743s/iter; left time: 3799.8068s
	iters: 200, epoch: 7 | loss: 31.0965214
	speed: 0.1652s/iter; left time: 3585.1580s
Epoch: 7 cost time: 39.76098585128784
Epoch: 7, Steps: 233 Train Loss: 31.1136 (Forecasting Loss:0.3414 + XiCon Loss:3.0772 x Lambda(10.0)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.1795
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.2836170
	speed: 0.1793s/iter; left time: 3867.7434s
	iters: 200, epoch: 8 | loss: 31.0044003
	speed: 0.1700s/iter; left time: 3650.4762s
Epoch: 8 cost time: 40.69288206100464
Epoch: 8, Steps: 233 Train Loss: 31.0600 (Forecasting Loss:0.3401 + XiCon Loss:3.0720 x Lambda(10.0)), Vali MSE Loss: 0.3680 Test MSE Loss: 0.1774
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.0728455
	speed: 0.1762s/iter; left time: 3759.2592s
	iters: 200, epoch: 9 | loss: 31.0994720
	speed: 0.1673s/iter; left time: 3553.3154s
Epoch: 9 cost time: 40.18555545806885
Epoch: 9, Steps: 233 Train Loss: 31.0695 (Forecasting Loss:0.3383 + XiCon Loss:3.0731 x Lambda(10.0)), Vali MSE Loss: 0.3649 Test MSE Loss: 0.1783
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.9517403
	speed: 0.1698s/iter; left time: 3583.6420s
	iters: 200, epoch: 10 | loss: 30.8409863
	speed: 0.1687s/iter; left time: 3542.8385s
Epoch: 10 cost time: 39.68017625808716
Epoch: 10, Steps: 233 Train Loss: 31.0717 (Forecasting Loss:0.3396 + XiCon Loss:3.0732 x Lambda(10.0)), Vali MSE Loss: 0.3654 Test MSE Loss: 0.1782
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.8880653
	speed: 0.1703s/iter; left time: 3554.6876s
	iters: 200, epoch: 11 | loss: 31.0191422
	speed: 0.1666s/iter; left time: 3459.6921s
Epoch: 11 cost time: 39.19262456893921
Epoch: 11, Steps: 233 Train Loss: 31.0358 (Forecasting Loss:0.3384 + XiCon Loss:3.0697 x Lambda(10.0)), Vali MSE Loss: 0.3659 Test MSE Loss: 0.1781
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.119529590010643, mae:0.2759154438972473, mape:0.1939937174320221, mspe:0.05602866783738136 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2913489
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 32.2971
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.0715446
	speed: 0.1509s/iter; left time: 3501.3847s
	iters: 200, epoch: 1 | loss: 33.5876884
	speed: 0.1430s/iter; left time: 3304.2774s
Epoch: 1 cost time: 34.3373384475708
Epoch: 1, Steps: 233 Train Loss: 34.0091 (Forecasting Loss:0.4465 + XiCon Loss:3.3563 x Lambda(10.0)), Vali MSE Loss: 0.2938 Test MSE Loss: 0.1870
Validation loss decreased (inf --> 0.293816).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.1236420
	speed: 0.1694s/iter; left time: 3890.9987s
	iters: 200, epoch: 2 | loss: 31.8670578
	speed: 0.1871s/iter; left time: 4279.3821s
Epoch: 2 cost time: 42.10371208190918
Epoch: 2, Steps: 233 Train Loss: 31.9585 (Forecasting Loss:0.4180 + XiCon Loss:3.1541 x Lambda(10.0)), Vali MSE Loss: 0.2674 Test MSE Loss: 0.1650
Validation loss decreased (0.293816 --> 0.267354).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7663383
	speed: 0.1756s/iter; left time: 3992.0449s
	iters: 200, epoch: 3 | loss: 31.9773884
	speed: 0.1619s/iter; left time: 3664.4783s
Epoch: 3 cost time: 39.54993462562561
Epoch: 3, Steps: 233 Train Loss: 31.6007 (Forecasting Loss:0.3805 + XiCon Loss:3.1220 x Lambda(10.0)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.2092
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.2722435
	speed: 0.1660s/iter; left time: 3734.9814s
	iters: 200, epoch: 4 | loss: 31.1563225
	speed: 0.1621s/iter; left time: 3631.1479s
Epoch: 4 cost time: 38.577683448791504
Epoch: 4, Steps: 233 Train Loss: 31.2389 (Forecasting Loss:0.3322 + XiCon Loss:3.0907 x Lambda(10.0)), Vali MSE Loss: 0.3600 Test MSE Loss: 0.1921
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.5614815
	speed: 0.1707s/iter; left time: 3802.3845s
	iters: 200, epoch: 5 | loss: 30.9466190
	speed: 0.1632s/iter; left time: 3617.6062s
Epoch: 5 cost time: 39.15917348861694
Epoch: 5, Steps: 233 Train Loss: 30.9913 (Forecasting Loss:0.3150 + XiCon Loss:3.0676 x Lambda(10.0)), Vali MSE Loss: 0.3767 Test MSE Loss: 0.1890
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.8638363
	speed: 0.1667s/iter; left time: 3673.8865s
	iters: 200, epoch: 6 | loss: 31.0562038
	speed: 0.1612s/iter; left time: 3537.1472s
Epoch: 6 cost time: 38.20353126525879
Epoch: 6, Steps: 233 Train Loss: 30.8835 (Forecasting Loss:0.3067 + XiCon Loss:3.0577 x Lambda(10.0)), Vali MSE Loss: 0.3739 Test MSE Loss: 0.1859
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.1152916
	speed: 0.1699s/iter; left time: 3703.3928s
	iters: 200, epoch: 7 | loss: 30.7702560
	speed: 0.1674s/iter; left time: 3632.7780s
Epoch: 7 cost time: 38.93154430389404
Epoch: 7, Steps: 233 Train Loss: 30.8570 (Forecasting Loss:0.3043 + XiCon Loss:3.0553 x Lambda(10.0)), Vali MSE Loss: 0.3748 Test MSE Loss: 0.1856
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.1016521
	speed: 0.1682s/iter; left time: 3627.0060s
	iters: 200, epoch: 8 | loss: 30.8725090
	speed: 0.1611s/iter; left time: 3458.2009s
Epoch: 8 cost time: 38.50321125984192
Epoch: 8, Steps: 233 Train Loss: 30.8274 (Forecasting Loss:0.3026 + XiCon Loss:3.0525 x Lambda(10.0)), Vali MSE Loss: 0.3627 Test MSE Loss: 0.1854
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7238064
	speed: 0.1721s/iter; left time: 3673.1409s
	iters: 200, epoch: 9 | loss: 31.0455265
	speed: 0.1663s/iter; left time: 3530.9924s
Epoch: 9 cost time: 39.53052306175232
Epoch: 9, Steps: 233 Train Loss: 30.8236 (Forecasting Loss:0.3020 + XiCon Loss:3.0522 x Lambda(10.0)), Vali MSE Loss: 0.3685 Test MSE Loss: 0.1851
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5852165
	speed: 0.1677s/iter; left time: 3539.3399s
	iters: 200, epoch: 10 | loss: 30.9332447
	speed: 0.1615s/iter; left time: 3392.2169s
Epoch: 10 cost time: 38.44193506240845
Epoch: 10, Steps: 233 Train Loss: 30.8182 (Forecasting Loss:0.3017 + XiCon Loss:3.0517 x Lambda(10.0)), Vali MSE Loss: 0.3744 Test MSE Loss: 0.1850
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1044388
	speed: 0.1635s/iter; left time: 3411.8516s
	iters: 200, epoch: 11 | loss: 30.7041759
	speed: 0.1651s/iter; left time: 3430.1804s
Epoch: 11 cost time: 38.02598547935486
Epoch: 11, Steps: 233 Train Loss: 30.8269 (Forecasting Loss:0.3016 + XiCon Loss:3.0525 x Lambda(10.0)), Vali MSE Loss: 0.3720 Test MSE Loss: 0.1850
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5132446
	speed: 0.1649s/iter; left time: 3402.5474s
	iters: 200, epoch: 12 | loss: 30.6316223
	speed: 0.1637s/iter; left time: 3362.0377s
Epoch: 12 cost time: 38.36601448059082
Epoch: 12, Steps: 233 Train Loss: 30.8198 (Forecasting Loss:0.3015 + XiCon Loss:3.0518 x Lambda(10.0)), Vali MSE Loss: 0.3716 Test MSE Loss: 0.1850
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl4320_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.08968652039766312, mae:0.24037115275859833, mape:0.17248903214931488, mspe:0.045335303992033005 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1033+-0.01579, MAE:0.2559+-0.01920, MAPE:0.1804+-0.01237, MSPE:0.0488+-0.00641, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 30.4537
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.0979614
	speed: 0.0997s/iter; left time: 2632.3416s
	iters: 200, epoch: 1 | loss: 32.3585320
	speed: 0.0921s/iter; left time: 2421.9802s
Epoch: 1 cost time: 25.106702089309692
Epoch: 1, Steps: 265 Train Loss: 32.8300 (Forecasting Loss:0.2280 + XiCon Loss:3.2602 x Lambda(10.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1683
Validation loss decreased (inf --> 0.209635).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7835770
	speed: 0.0943s/iter; left time: 2465.8531s
	iters: 200, epoch: 2 | loss: 30.8411064
	speed: 0.0986s/iter; left time: 2567.9022s
Epoch: 2 cost time: 25.089107036590576
Epoch: 2, Steps: 265 Train Loss: 31.3971 (Forecasting Loss:0.2089 + XiCon Loss:3.1188 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1669
Validation loss decreased (0.209635 --> 0.206510).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.0542679
	speed: 0.1016s/iter; left time: 2628.0841s
	iters: 200, epoch: 3 | loss: 30.3128605
	speed: 0.0888s/iter; left time: 2287.8687s
Epoch: 3 cost time: 24.755706071853638
Epoch: 3, Steps: 265 Train Loss: 30.4628 (Forecasting Loss:0.2010 + XiCon Loss:3.0262 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1618
Validation loss decreased (0.206510 --> 0.203345).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2003651
	speed: 0.0985s/iter; left time: 2520.9182s
	iters: 200, epoch: 4 | loss: 30.6520538
	speed: 0.0888s/iter; left time: 2264.1887s
Epoch: 4 cost time: 24.82848072052002
Epoch: 4, Steps: 265 Train Loss: 30.3951 (Forecasting Loss:0.1987 + XiCon Loss:3.0196 x Lambda(10.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1606
Validation loss decreased (0.203345 --> 0.200769).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.8819256
	speed: 0.0937s/iter; left time: 2374.7551s
	iters: 200, epoch: 5 | loss: 30.4007912
	speed: 0.0935s/iter; left time: 2361.2087s
Epoch: 5 cost time: 25.069085597991943
Epoch: 5, Steps: 265 Train Loss: 30.3603 (Forecasting Loss:0.1969 + XiCon Loss:3.0163 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1593
Validation loss decreased (0.200769 --> 0.198962).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.7488003
	speed: 0.0937s/iter; left time: 2350.4545s
	iters: 200, epoch: 6 | loss: 30.3991070
	speed: 0.0922s/iter; left time: 2302.4603s
Epoch: 6 cost time: 24.764273643493652
Epoch: 6, Steps: 265 Train Loss: 30.3341 (Forecasting Loss:0.1962 + XiCon Loss:3.0138 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1589
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.5119343
	speed: 0.0969s/iter; left time: 2403.4005s
	iters: 200, epoch: 7 | loss: 30.2850132
	speed: 0.0956s/iter; left time: 2362.8239s
Epoch: 7 cost time: 25.030917644500732
Epoch: 7, Steps: 265 Train Loss: 30.3575 (Forecasting Loss:0.1959 + XiCon Loss:3.0162 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1585
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5046825
	speed: 0.0932s/iter; left time: 2288.8879s
	iters: 200, epoch: 8 | loss: 30.3981037
	speed: 0.0880s/iter; left time: 2150.0922s
Epoch: 8 cost time: 24.470207452774048
Epoch: 8, Steps: 265 Train Loss: 30.3208 (Forecasting Loss:0.1957 + XiCon Loss:3.0125 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
Validation loss decreased (0.198962 --> 0.198929).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.4434509
	speed: 0.0960s/iter; left time: 2330.1942s
	iters: 200, epoch: 9 | loss: 30.6535645
	speed: 0.0892s/iter; left time: 2157.9412s
Epoch: 9 cost time: 24.3254873752594
Epoch: 9, Steps: 265 Train Loss: 30.3531 (Forecasting Loss:0.1955 + XiCon Loss:3.0158 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1584
Validation loss decreased (0.198929 --> 0.198797).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2581043
	speed: 0.0999s/iter; left time: 2399.2635s
	iters: 200, epoch: 10 | loss: 30.5075512
	speed: 0.0870s/iter; left time: 2080.2083s
Epoch: 10 cost time: 24.862297534942627
Epoch: 10, Steps: 265 Train Loss: 30.3119 (Forecasting Loss:0.1955 + XiCon Loss:3.0116 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1585
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1596737
	speed: 0.0929s/iter; left time: 2207.2199s
	iters: 200, epoch: 11 | loss: 30.0610313
	speed: 0.0861s/iter; left time: 2035.8289s
Epoch: 11 cost time: 23.843263864517212
Epoch: 11, Steps: 265 Train Loss: 30.3504 (Forecasting Loss:0.1956 + XiCon Loss:3.0155 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1584
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.1379528
	speed: 0.0996s/iter; left time: 2340.0348s
	iters: 200, epoch: 12 | loss: 30.8519478
	speed: 0.0927s/iter; left time: 2167.0944s
Epoch: 12 cost time: 24.8056161403656
Epoch: 12, Steps: 265 Train Loss: 30.3771 (Forecasting Loss:0.1955 + XiCon Loss:3.0182 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1584
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.1936073
	speed: 0.0953s/iter; left time: 2213.2944s
	iters: 200, epoch: 13 | loss: 30.0984478
	speed: 0.0932s/iter; left time: 2154.0701s
Epoch: 13 cost time: 24.817880630493164
Epoch: 13, Steps: 265 Train Loss: 30.3328 (Forecasting Loss:0.1954 + XiCon Loss:3.0137 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1585
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8894958
	speed: 0.0962s/iter; left time: 2207.7078s
	iters: 200, epoch: 14 | loss: 30.6425476
	speed: 0.0922s/iter; left time: 2107.4601s
Epoch: 14 cost time: 24.765602588653564
Epoch: 14, Steps: 265 Train Loss: 30.3214 (Forecasting Loss:0.1954 + XiCon Loss:3.0126 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1584
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.8487396
	speed: 0.0944s/iter; left time: 2141.2849s
	iters: 200, epoch: 15 | loss: 30.2641201
	speed: 0.0954s/iter; left time: 2156.2807s
Epoch: 15 cost time: 25.234960556030273
Epoch: 15, Steps: 265 Train Loss: 30.3429 (Forecasting Loss:0.1954 + XiCon Loss:3.0147 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1584
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.6443672
	speed: 0.0983s/iter; left time: 2203.6958s
	iters: 200, epoch: 16 | loss: 30.0921516
	speed: 0.0969s/iter; left time: 2164.1622s
Epoch: 16 cost time: 25.974735736846924
Epoch: 16, Steps: 265 Train Loss: 30.3262 (Forecasting Loss:0.1954 + XiCon Loss:3.0131 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1584
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.1095848
	speed: 0.1037s/iter; left time: 2297.8466s
	iters: 200, epoch: 17 | loss: 30.0506363
	speed: 0.0949s/iter; left time: 2092.9325s
Epoch: 17 cost time: 25.93311333656311
Epoch: 17, Steps: 265 Train Loss: 30.3088 (Forecasting Loss:0.1954 + XiCon Loss:3.0113 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1584
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.9233608
	speed: 0.0998s/iter; left time: 2185.5480s
	iters: 200, epoch: 18 | loss: 30.6877365
	speed: 0.0940s/iter; left time: 2049.4274s
Epoch: 18 cost time: 25.407808780670166
Epoch: 18, Steps: 265 Train Loss: 30.3313 (Forecasting Loss:0.1954 + XiCon Loss:3.0136 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1584
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.2379436
	speed: 0.0975s/iter; left time: 2109.8328s
	iters: 200, epoch: 19 | loss: 30.3012867
	speed: 0.0922s/iter; left time: 1986.0409s
Epoch: 19 cost time: 23.93115782737732
Epoch: 19, Steps: 265 Train Loss: 30.3232 (Forecasting Loss:0.1954 + XiCon Loss:3.0128 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1584
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0915042832493782, mae:0.2252402901649475, mape:0.5418656468391418, mspe:11.230932235717773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 28.0384
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.9439697
	speed: 0.0786s/iter; left time: 2075.1763s
	iters: 200, epoch: 1 | loss: 31.9309883
	speed: 0.0729s/iter; left time: 1918.5408s
Epoch: 1 cost time: 19.651296377182007
Epoch: 1, Steps: 265 Train Loss: 32.6858 (Forecasting Loss:0.2276 + XiCon Loss:3.2458 x Lambda(10.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1675
Validation loss decreased (inf --> 0.210618).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.9969597
	speed: 0.0761s/iter; left time: 1988.3947s
	iters: 200, epoch: 2 | loss: 31.4959412
	speed: 0.0711s/iter; left time: 1849.9409s
Epoch: 2 cost time: 19.408838748931885
Epoch: 2, Steps: 265 Train Loss: 31.8915 (Forecasting Loss:0.2075 + XiCon Loss:3.1684 x Lambda(10.0)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.1679
Validation loss decreased (0.210618 --> 0.206688).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.0918446
	speed: 0.0756s/iter; left time: 1956.8413s
	iters: 200, epoch: 3 | loss: 31.1391716
	speed: 0.0717s/iter; left time: 1847.2474s
Epoch: 3 cost time: 19.333463430404663
Epoch: 3, Steps: 265 Train Loss: 31.1618 (Forecasting Loss:0.2010 + XiCon Loss:3.0961 x Lambda(10.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1624
Validation loss decreased (0.206688 --> 0.205467).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6109314
	speed: 0.0731s/iter; left time: 1871.7368s
	iters: 200, epoch: 4 | loss: 30.4731331
	speed: 0.0758s/iter; left time: 1933.5980s
Epoch: 4 cost time: 19.902199506759644
Epoch: 4, Steps: 265 Train Loss: 30.5248 (Forecasting Loss:0.1988 + XiCon Loss:3.0326 x Lambda(10.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1611
Validation loss decreased (0.205467 --> 0.200791).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.2910786
	speed: 0.0756s/iter; left time: 1915.9572s
	iters: 200, epoch: 5 | loss: 30.3737373
	speed: 0.0727s/iter; left time: 1835.2487s
Epoch: 5 cost time: 19.416576862335205
Epoch: 5, Steps: 265 Train Loss: 30.3769 (Forecasting Loss:0.1972 + XiCon Loss:3.0180 x Lambda(10.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1602
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4017200
	speed: 0.0767s/iter; left time: 1924.2306s
	iters: 200, epoch: 6 | loss: 30.5460033
	speed: 0.0699s/iter; left time: 1746.0789s
Epoch: 6 cost time: 19.05704402923584
Epoch: 6, Steps: 265 Train Loss: 30.3088 (Forecasting Loss:0.1964 + XiCon Loss:3.0112 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1591
Validation loss decreased (0.200791 --> 0.198740).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1950397
	speed: 0.0821s/iter; left time: 2036.0052s
	iters: 200, epoch: 7 | loss: 30.1686802
	speed: 0.0727s/iter; left time: 1796.3129s
Epoch: 7 cost time: 20.225911855697632
Epoch: 7, Steps: 265 Train Loss: 30.2873 (Forecasting Loss:0.1962 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.1593
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.4212437
	speed: 0.0768s/iter; left time: 1883.9745s
	iters: 200, epoch: 8 | loss: 30.6004887
	speed: 0.0734s/iter; left time: 1794.6901s
Epoch: 8 cost time: 19.68607473373413
Epoch: 8, Steps: 265 Train Loss: 30.2732 (Forecasting Loss:0.1960 + XiCon Loss:3.0077 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8159599
	speed: 0.0775s/iter; left time: 1881.0481s
	iters: 200, epoch: 9 | loss: 30.0630798
	speed: 0.0717s/iter; left time: 1734.3181s
Epoch: 9 cost time: 19.48554515838623
Epoch: 9, Steps: 265 Train Loss: 30.2897 (Forecasting Loss:0.1959 + XiCon Loss:3.0094 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6657829
	speed: 0.0745s/iter; left time: 1788.8602s
	iters: 200, epoch: 10 | loss: 30.8837280
	speed: 0.0739s/iter; left time: 1768.2798s
Epoch: 10 cost time: 19.64499258995056
Epoch: 10, Steps: 265 Train Loss: 30.2871 (Forecasting Loss:0.1958 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1589
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.4168663
	speed: 0.0715s/iter; left time: 1697.4531s
	iters: 200, epoch: 11 | loss: 30.1103287
	speed: 0.0707s/iter; left time: 1673.0152s
Epoch: 11 cost time: 19.06677222251892
Epoch: 11, Steps: 265 Train Loss: 30.3079 (Forecasting Loss:0.1958 + XiCon Loss:3.0112 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1588
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3671722
	speed: 0.0748s/iter; left time: 1757.5705s
	iters: 200, epoch: 12 | loss: 30.0453358
	speed: 0.0756s/iter; left time: 1769.0322s
Epoch: 12 cost time: 19.866100072860718
Epoch: 12, Steps: 265 Train Loss: 30.2881 (Forecasting Loss:0.1957 + XiCon Loss:3.0092 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1588
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.6593037
	speed: 0.0771s/iter; left time: 1790.2140s
	iters: 200, epoch: 13 | loss: 30.2815971
	speed: 0.0730s/iter; left time: 1687.8886s
Epoch: 13 cost time: 19.56665563583374
Epoch: 13, Steps: 265 Train Loss: 30.2943 (Forecasting Loss:0.1958 + XiCon Loss:3.0099 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1587
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2938976
	speed: 0.0742s/iter; left time: 1703.2206s
	iters: 200, epoch: 14 | loss: 30.2466545
	speed: 0.0722s/iter; left time: 1651.1507s
Epoch: 14 cost time: 19.423566341400146
Epoch: 14, Steps: 265 Train Loss: 30.2866 (Forecasting Loss:0.1958 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1587
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.4742966
	speed: 0.1027s/iter; left time: 2330.9776s
	iters: 200, epoch: 15 | loss: 29.5500317
	speed: 0.0749s/iter; left time: 1691.9596s
Epoch: 15 cost time: 21.710442543029785
Epoch: 15, Steps: 265 Train Loss: 30.2696 (Forecasting Loss:0.1958 + XiCon Loss:3.0074 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1587
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0496140
	speed: 0.0635s/iter; left time: 1423.0362s
	iters: 200, epoch: 16 | loss: 30.0820560
	speed: 0.0653s/iter; left time: 1457.0135s
Epoch: 16 cost time: 17.297168254852295
Epoch: 16, Steps: 265 Train Loss: 30.2949 (Forecasting Loss:0.1957 + XiCon Loss:3.0099 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1587
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09226401150226593, mae:0.22601822018623352, mape:0.5438550114631653, mspe:11.247979164123535 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.4617
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.5148277
	speed: 0.0686s/iter; left time: 1812.0692s
	iters: 200, epoch: 1 | loss: 32.5395737
	speed: 0.0662s/iter; left time: 1741.0245s
Epoch: 1 cost time: 17.9668607711792
Epoch: 1, Steps: 265 Train Loss: 33.0201 (Forecasting Loss:0.2259 + XiCon Loss:3.2794 x Lambda(10.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1670
Validation loss decreased (inf --> 0.210816).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7104034
	speed: 0.0690s/iter; left time: 1802.8889s
	iters: 200, epoch: 2 | loss: 33.4210968
	speed: 0.0649s/iter; left time: 1689.5985s
Epoch: 2 cost time: 17.96781826019287
Epoch: 2, Steps: 265 Train Loss: 32.5799 (Forecasting Loss:0.2084 + XiCon Loss:3.2371 x Lambda(10.0)), Vali MSE Loss: 0.2044 Test MSE Loss: 0.1648
Validation loss decreased (0.210816 --> 0.204432).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.9809761
	speed: 0.0709s/iter; left time: 1835.4140s
	iters: 200, epoch: 3 | loss: 31.4607086
	speed: 0.0631s/iter; left time: 1626.8280s
Epoch: 3 cost time: 17.41874623298645
Epoch: 3, Steps: 265 Train Loss: 32.4356 (Forecasting Loss:0.2014 + XiCon Loss:3.2234 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1624
Validation loss decreased (0.204432 --> 0.200727).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.5340729
	speed: 0.0739s/iter; left time: 1891.3578s
	iters: 200, epoch: 4 | loss: 31.7249241
	speed: 0.0676s/iter; left time: 1724.7972s
Epoch: 4 cost time: 18.6152184009552
Epoch: 4, Steps: 265 Train Loss: 32.0654 (Forecasting Loss:0.1983 + XiCon Loss:3.1867 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1618
Validation loss decreased (0.200727 --> 0.200400).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.6632347
	speed: 0.0672s/iter; left time: 1704.0058s
	iters: 200, epoch: 5 | loss: 32.6414146
	speed: 0.0635s/iter; left time: 1603.6752s
Epoch: 5 cost time: 16.91582155227661
Epoch: 5, Steps: 265 Train Loss: 31.9082 (Forecasting Loss:0.1969 + XiCon Loss:3.1711 x Lambda(10.0)), Vali MSE Loss: 0.1986 Test MSE Loss: 0.1595
Validation loss decreased (0.200400 --> 0.198635).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.8859043
	speed: 0.0759s/iter; left time: 1903.5348s
	iters: 200, epoch: 6 | loss: 31.0545712
	speed: 0.0633s/iter; left time: 1581.0182s
Epoch: 6 cost time: 17.995636224746704
Epoch: 6, Steps: 265 Train Loss: 31.8502 (Forecasting Loss:0.1966 + XiCon Loss:3.1654 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1595
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.9667320
	speed: 0.0670s/iter; left time: 1663.4916s
	iters: 200, epoch: 7 | loss: 31.8403111
	speed: 0.0618s/iter; left time: 1527.4813s
Epoch: 7 cost time: 17.198351860046387
Epoch: 7, Steps: 265 Train Loss: 31.8813 (Forecasting Loss:0.1961 + XiCon Loss:3.1685 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1595
Validation loss decreased (0.198635 --> 0.197674).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.3609810
	speed: 0.0692s/iter; left time: 1697.6631s
	iters: 200, epoch: 8 | loss: 31.1002445
	speed: 0.0648s/iter; left time: 1583.2504s
Epoch: 8 cost time: 18.068596601486206
Epoch: 8, Steps: 265 Train Loss: 31.8568 (Forecasting Loss:0.1959 + XiCon Loss:3.1661 x Lambda(10.0)), Vali MSE Loss: 0.1982 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.4146404
	speed: 0.0729s/iter; left time: 1769.7918s
	iters: 200, epoch: 9 | loss: 32.6218987
	speed: 0.0655s/iter; left time: 1583.2505s
Epoch: 9 cost time: 17.969319581985474
Epoch: 9, Steps: 265 Train Loss: 31.7815 (Forecasting Loss:0.1959 + XiCon Loss:3.1586 x Lambda(10.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.7820072
	speed: 0.0683s/iter; left time: 1639.4157s
	iters: 200, epoch: 10 | loss: 32.8618660
	speed: 0.0661s/iter; left time: 1580.4387s
Epoch: 10 cost time: 18.084747791290283
Epoch: 10, Steps: 265 Train Loss: 31.7282 (Forecasting Loss:0.1957 + XiCon Loss:3.1532 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1591
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.1813335
	speed: 0.0686s/iter; left time: 1628.8094s
	iters: 200, epoch: 11 | loss: 31.6755276
	speed: 0.0639s/iter; left time: 1512.3876s
Epoch: 11 cost time: 17.458521604537964
Epoch: 11, Steps: 265 Train Loss: 31.7833 (Forecasting Loss:0.1958 + XiCon Loss:3.1587 x Lambda(10.0)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1591
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.0620041
	speed: 0.0713s/iter; left time: 1675.0058s
	iters: 200, epoch: 12 | loss: 32.6773605
	speed: 0.0646s/iter; left time: 1511.8785s
Epoch: 12 cost time: 17.911657333374023
Epoch: 12, Steps: 265 Train Loss: 31.7969 (Forecasting Loss:0.1958 + XiCon Loss:3.1601 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.5229683
	speed: 0.0705s/iter; left time: 1637.7036s
	iters: 200, epoch: 13 | loss: 32.0923500
	speed: 0.0704s/iter; left time: 1628.5886s
Epoch: 13 cost time: 18.895943641662598
Epoch: 13, Steps: 265 Train Loss: 31.7693 (Forecasting Loss:0.1957 + XiCon Loss:3.1574 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 32.2403946
	speed: 0.0660s/iter; left time: 1514.0552s
	iters: 200, epoch: 14 | loss: 31.5052185
	speed: 0.0655s/iter; left time: 1498.0888s
Epoch: 14 cost time: 17.279786109924316
Epoch: 14, Steps: 265 Train Loss: 31.7934 (Forecasting Loss:0.1957 + XiCon Loss:3.1598 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.8268852
	speed: 0.0719s/iter; left time: 1631.9118s
	iters: 200, epoch: 15 | loss: 31.0680828
	speed: 0.0628s/iter; left time: 1417.7901s
Epoch: 15 cost time: 17.579655170440674
Epoch: 15, Steps: 265 Train Loss: 31.7660 (Forecasting Loss:0.1957 + XiCon Loss:3.1570 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1590
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.5946808
	speed: 0.0692s/iter; left time: 1552.9289s
	iters: 200, epoch: 16 | loss: 32.0515366
	speed: 0.0721s/iter; left time: 1610.7809s
Epoch: 16 cost time: 18.07742691040039
Epoch: 16, Steps: 265 Train Loss: 31.7606 (Forecasting Loss:0.1958 + XiCon Loss:3.1565 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1590
Validation loss decreased (0.197674 --> 0.197617).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.1626282
	speed: 0.0689s/iter; left time: 1526.0790s
	iters: 200, epoch: 17 | loss: 31.7007904
	speed: 0.0637s/iter; left time: 1405.2257s
Epoch: 17 cost time: 17.83311104774475
Epoch: 17, Steps: 265 Train Loss: 31.7802 (Forecasting Loss:0.1957 + XiCon Loss:3.1585 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 32.4220734
	speed: 0.0748s/iter; left time: 1637.0004s
	iters: 200, epoch: 18 | loss: 31.1022110
	speed: 0.0669s/iter; left time: 1458.3697s
Epoch: 18 cost time: 18.4565110206604
Epoch: 18, Steps: 265 Train Loss: 31.7923 (Forecasting Loss:0.1957 + XiCon Loss:3.1597 x Lambda(10.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.2755814
	speed: 0.0688s/iter; left time: 1487.2290s
	iters: 200, epoch: 19 | loss: 30.3638897
	speed: 0.0639s/iter; left time: 1375.0993s
Epoch: 19 cost time: 17.481855869293213
Epoch: 19, Steps: 265 Train Loss: 31.7496 (Forecasting Loss:0.1957 + XiCon Loss:3.1554 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.2048378
	speed: 0.0687s/iter; left time: 1468.4755s
	iters: 200, epoch: 20 | loss: 32.1083336
	speed: 0.0641s/iter; left time: 1362.2396s
Epoch: 20 cost time: 17.687671422958374
Epoch: 20, Steps: 265 Train Loss: 31.7895 (Forecasting Loss:0.1957 + XiCon Loss:3.1594 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1590
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.4819412
	speed: 0.0695s/iter; left time: 1467.3863s
	iters: 200, epoch: 21 | loss: 31.6742687
	speed: 0.0625s/iter; left time: 1312.9800s
Epoch: 21 cost time: 17.664263248443604
Epoch: 21, Steps: 265 Train Loss: 31.7873 (Forecasting Loss:0.1957 + XiCon Loss:3.1592 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.7785912
	speed: 0.0665s/iter; left time: 1386.5889s
	iters: 200, epoch: 22 | loss: 33.1389351
	speed: 0.0723s/iter; left time: 1499.5596s
Epoch: 22 cost time: 17.945510387420654
Epoch: 22, Steps: 265 Train Loss: 31.8269 (Forecasting Loss:0.1958 + XiCon Loss:3.1631 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1590
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 32.0732269
	speed: 0.0692s/iter; left time: 1423.8207s
	iters: 200, epoch: 23 | loss: 31.5639648
	speed: 0.0650s/iter; left time: 1330.0176s
Epoch: 23 cost time: 17.614611864089966
Epoch: 23, Steps: 265 Train Loss: 31.7937 (Forecasting Loss:0.1957 + XiCon Loss:3.1598 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1590
Validation loss decreased (0.197617 --> 0.197586).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.3087921
	speed: 0.0706s/iter; left time: 1432.7714s
	iters: 200, epoch: 24 | loss: 31.6207027
	speed: 0.0666s/iter; left time: 1344.8483s
Epoch: 24 cost time: 18.191332817077637
Epoch: 24, Steps: 265 Train Loss: 31.8127 (Forecasting Loss:0.1957 + XiCon Loss:3.1617 x Lambda(10.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1590
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 32.2166672
	speed: 0.0731s/iter; left time: 1464.2540s
	iters: 200, epoch: 25 | loss: 31.1429634
	speed: 0.0661s/iter; left time: 1318.3040s
Epoch: 25 cost time: 17.983606576919556
Epoch: 25, Steps: 265 Train Loss: 31.7556 (Forecasting Loss:0.1957 + XiCon Loss:3.1560 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.4169655
	speed: 0.0702s/iter; left time: 1388.4776s
	iters: 200, epoch: 26 | loss: 31.7389450
	speed: 0.0642s/iter; left time: 1264.0078s
Epoch: 26 cost time: 17.997091054916382
Epoch: 26, Steps: 265 Train Loss: 31.7387 (Forecasting Loss:0.1958 + XiCon Loss:3.1543 x Lambda(10.0)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.1590
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 32.4612350
	speed: 0.0702s/iter; left time: 1370.3646s
	iters: 200, epoch: 27 | loss: 31.1985664
	speed: 0.0686s/iter; left time: 1331.0542s
Epoch: 27 cost time: 18.13693928718567
Epoch: 27, Steps: 265 Train Loss: 31.7789 (Forecasting Loss:0.1957 + XiCon Loss:3.1583 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 32.0205040
	speed: 0.0739s/iter; left time: 1422.9653s
	iters: 200, epoch: 28 | loss: 31.0876217
	speed: 0.0680s/iter; left time: 1302.3279s
Epoch: 28 cost time: 18.267261028289795
Epoch: 28, Steps: 265 Train Loss: 31.8322 (Forecasting Loss:0.1957 + XiCon Loss:3.1637 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1590
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 32.5592384
	speed: 0.0706s/iter; left time: 1339.8689s
	iters: 200, epoch: 29 | loss: 31.2935715
	speed: 0.0822s/iter; left time: 1551.0751s
Epoch: 29 cost time: 23.650325298309326
Epoch: 29, Steps: 265 Train Loss: 31.8000 (Forecasting Loss:0.1957 + XiCon Loss:3.1604 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1590
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 32.6918907
	speed: 0.0687s/iter; left time: 1286.3860s
	iters: 200, epoch: 30 | loss: 31.8891983
	speed: 0.0643s/iter; left time: 1196.4671s
Epoch: 30 cost time: 17.587991952896118
Epoch: 30, Steps: 265 Train Loss: 31.8212 (Forecasting Loss:0.1957 + XiCon Loss:3.1626 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1590
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 32.2978554
	speed: 0.0707s/iter; left time: 1304.8824s
	iters: 200, epoch: 31 | loss: 32.6496277
	speed: 0.0680s/iter; left time: 1247.9758s
Epoch: 31 cost time: 18.577869653701782
Epoch: 31, Steps: 265 Train Loss: 31.7890 (Forecasting Loss:0.1957 + XiCon Loss:3.1593 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 31.0456257
	speed: 0.0672s/iter; left time: 1221.9370s
	iters: 200, epoch: 32 | loss: 31.2475395
	speed: 0.0676s/iter; left time: 1222.1728s
Epoch: 32 cost time: 17.81151509284973
Epoch: 32, Steps: 265 Train Loss: 31.7654 (Forecasting Loss:0.1957 + XiCon Loss:3.1570 x Lambda(10.0)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1590
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 30.7652149
	speed: 0.0718s/iter; left time: 1287.1758s
	iters: 200, epoch: 33 | loss: 31.1533604
	speed: 0.0671s/iter; left time: 1196.4941s
Epoch: 33 cost time: 18.46037983894348
Epoch: 33, Steps: 265 Train Loss: 31.7481 (Forecasting Loss:0.1958 + XiCon Loss:3.1552 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1590
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09200410544872284, mae:0.2260708510875702, mape:0.5484363436698914, mspe:11.499058723449707 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.3710
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 32.8699837
	speed: 0.0735s/iter; left time: 1941.2782s
	iters: 200, epoch: 1 | loss: 31.9833145
	speed: 0.0667s/iter; left time: 1754.1527s
Epoch: 1 cost time: 18.018526554107666
Epoch: 1, Steps: 265 Train Loss: 32.7079 (Forecasting Loss:0.2285 + XiCon Loss:3.2479 x Lambda(10.0)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1678
Validation loss decreased (inf --> 0.209859).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.6222191
	speed: 0.0701s/iter; left time: 1831.7717s
	iters: 200, epoch: 2 | loss: 30.7731590
	speed: 0.0660s/iter; left time: 1717.1663s
Epoch: 2 cost time: 17.792776346206665
Epoch: 2, Steps: 265 Train Loss: 31.4806 (Forecasting Loss:0.2072 + XiCon Loss:3.1273 x Lambda(10.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1675
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.2676640
	speed: 0.0697s/iter; left time: 1804.2131s
	iters: 200, epoch: 3 | loss: 30.5590134
	speed: 0.0642s/iter; left time: 1654.8875s
Epoch: 3 cost time: 17.621272087097168
Epoch: 3, Steps: 265 Train Loss: 30.7098 (Forecasting Loss:0.2011 + XiCon Loss:3.0509 x Lambda(10.0)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.1617
Validation loss decreased (0.209859 --> 0.201236).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.8637104
	speed: 0.0726s/iter; left time: 1860.2197s
	iters: 200, epoch: 4 | loss: 30.8220253
	speed: 0.0653s/iter; left time: 1666.0505s
Epoch: 4 cost time: 17.680480003356934
Epoch: 4, Steps: 265 Train Loss: 30.5612 (Forecasting Loss:0.1985 + XiCon Loss:3.0363 x Lambda(10.0)), Vali MSE Loss: 0.1999 Test MSE Loss: 0.1608
Validation loss decreased (0.201236 --> 0.199862).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1671219
	speed: 0.0702s/iter; left time: 1779.3974s
	iters: 200, epoch: 5 | loss: 30.3951092
	speed: 0.0666s/iter; left time: 1681.6697s
Epoch: 5 cost time: 17.997666835784912
Epoch: 5, Steps: 265 Train Loss: 30.4858 (Forecasting Loss:0.1973 + XiCon Loss:3.0288 x Lambda(10.0)), Vali MSE Loss: 0.2013 Test MSE Loss: 0.1614
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.3484497
	speed: 0.0682s/iter; left time: 1710.7309s
	iters: 200, epoch: 6 | loss: 30.9381638
	speed: 0.0648s/iter; left time: 1617.8771s
Epoch: 6 cost time: 17.337704181671143
Epoch: 6, Steps: 265 Train Loss: 30.4852 (Forecasting Loss:0.1966 + XiCon Loss:3.0289 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1595
Validation loss decreased (0.199862 --> 0.199476).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0712585
	speed: 0.0723s/iter; left time: 1794.2632s
	iters: 200, epoch: 7 | loss: 30.3623486
	speed: 0.0659s/iter; left time: 1627.5288s
Epoch: 7 cost time: 17.81958246231079
Epoch: 7, Steps: 265 Train Loss: 30.4498 (Forecasting Loss:0.1961 + XiCon Loss:3.0254 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1590
Validation loss decreased (0.199476 --> 0.199444).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.5202522
	speed: 0.0668s/iter; left time: 1639.8920s
	iters: 200, epoch: 8 | loss: 29.9961281
	speed: 0.0620s/iter; left time: 1515.0464s
Epoch: 8 cost time: 17.3393132686615
Epoch: 8, Steps: 265 Train Loss: 30.4349 (Forecasting Loss:0.1960 + XiCon Loss:3.0239 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1591
Validation loss decreased (0.199444 --> 0.199191).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.3117390
	speed: 0.0705s/iter; left time: 1711.4100s
	iters: 200, epoch: 9 | loss: 30.3417301
	speed: 0.0652s/iter; left time: 1577.4420s
Epoch: 9 cost time: 17.839901447296143
Epoch: 9, Steps: 265 Train Loss: 30.4523 (Forecasting Loss:0.1958 + XiCon Loss:3.0257 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1586
Validation loss decreased (0.199191 --> 0.199067).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.0079346
	speed: 0.0706s/iter; left time: 1696.1416s
	iters: 200, epoch: 10 | loss: 31.0106277
	speed: 0.0975s/iter; left time: 2331.2131s
Epoch: 10 cost time: 22.533671379089355
Epoch: 10, Steps: 265 Train Loss: 30.4212 (Forecasting Loss:0.1957 + XiCon Loss:3.0226 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1588
Validation loss decreased (0.199067 --> 0.198898).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3974895
	speed: 0.0551s/iter; left time: 1309.1575s
	iters: 200, epoch: 11 | loss: 30.8023624
	speed: 0.0660s/iter; left time: 1562.1245s
Epoch: 11 cost time: 16.527360677719116
Epoch: 11, Steps: 265 Train Loss: 30.4467 (Forecasting Loss:0.1957 + XiCon Loss:3.0251 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1588
Validation loss decreased (0.198898 --> 0.198891).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7947617
	speed: 0.0689s/iter; left time: 1617.2033s
	iters: 200, epoch: 12 | loss: 30.3813076
	speed: 0.0686s/iter; left time: 1605.0346s
Epoch: 12 cost time: 18.049763917922974
Epoch: 12, Steps: 265 Train Loss: 30.4428 (Forecasting Loss:0.1957 + XiCon Loss:3.0247 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.8673935
	speed: 0.0734s/iter; left time: 1704.2365s
	iters: 200, epoch: 13 | loss: 30.3560162
	speed: 0.0710s/iter; left time: 1642.1909s
Epoch: 13 cost time: 19.339257955551147
Epoch: 13, Steps: 265 Train Loss: 30.4279 (Forecasting Loss:0.1959 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
Validation loss decreased (0.198891 --> 0.198878).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.3879051
	speed: 0.0751s/iter; left time: 1724.9862s
	iters: 200, epoch: 14 | loss: 30.3215904
	speed: 0.0711s/iter; left time: 1625.9634s
Epoch: 14 cost time: 19.561595916748047
Epoch: 14, Steps: 265 Train Loss: 30.4142 (Forecasting Loss:0.1957 + XiCon Loss:3.0218 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
Validation loss decreased (0.198878 --> 0.198709).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.7957325
	speed: 0.0755s/iter; left time: 1712.9455s
	iters: 200, epoch: 15 | loss: 30.3137989
	speed: 0.0733s/iter; left time: 1656.6413s
Epoch: 15 cost time: 19.707030057907104
Epoch: 15, Steps: 265 Train Loss: 30.4749 (Forecasting Loss:0.1957 + XiCon Loss:3.0279 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4388065
	speed: 0.0752s/iter; left time: 1686.3765s
	iters: 200, epoch: 16 | loss: 30.2238979
	speed: 0.0731s/iter; left time: 1632.7557s
Epoch: 16 cost time: 19.137698888778687
Epoch: 16, Steps: 265 Train Loss: 30.4279 (Forecasting Loss:0.1957 + XiCon Loss:3.0232 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3979301
	speed: 0.0797s/iter; left time: 1766.1193s
	iters: 200, epoch: 17 | loss: 30.3670826
	speed: 0.0702s/iter; left time: 1547.7998s
Epoch: 17 cost time: 19.704564332962036
Epoch: 17, Steps: 265 Train Loss: 30.4189 (Forecasting Loss:0.1956 + XiCon Loss:3.0223 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.2598515
	speed: 0.0738s/iter; left time: 1615.2664s
	iters: 200, epoch: 18 | loss: 30.9218807
	speed: 0.0699s/iter; left time: 1523.6414s
Epoch: 18 cost time: 19.301192045211792
Epoch: 18, Steps: 265 Train Loss: 30.4335 (Forecasting Loss:0.1957 + XiCon Loss:3.0238 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.1862221
	speed: 0.0742s/iter; left time: 1604.9502s
	iters: 200, epoch: 19 | loss: 30.6299744
	speed: 0.0712s/iter; left time: 1533.6528s
Epoch: 19 cost time: 19.198702573776245
Epoch: 19, Steps: 265 Train Loss: 30.4380 (Forecasting Loss:0.1958 + XiCon Loss:3.0242 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.0747356
	speed: 0.0802s/iter; left time: 1712.7963s
	iters: 200, epoch: 20 | loss: 30.1885681
	speed: 0.0706s/iter; left time: 1501.4348s
Epoch: 20 cost time: 19.849289178848267
Epoch: 20, Steps: 265 Train Loss: 30.4070 (Forecasting Loss:0.1957 + XiCon Loss:3.0211 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.5082817
	speed: 0.0741s/iter; left time: 1563.4687s
	iters: 200, epoch: 21 | loss: 30.8950424
	speed: 0.0764s/iter; left time: 1604.9339s
Epoch: 21 cost time: 19.67404556274414
Epoch: 21, Steps: 265 Train Loss: 30.4603 (Forecasting Loss:0.1957 + XiCon Loss:3.0265 x Lambda(10.0)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1587
Validation loss decreased (0.198709 --> 0.198674).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.6600475
	speed: 0.0772s/iter; left time: 1608.0988s
	iters: 200, epoch: 22 | loss: 30.0162487
	speed: 0.0722s/iter; left time: 1496.1631s
Epoch: 22 cost time: 19.65128445625305
Epoch: 22, Steps: 265 Train Loss: 30.4255 (Forecasting Loss:0.1958 + XiCon Loss:3.0230 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.4501057
	speed: 0.0778s/iter; left time: 1599.4501s
	iters: 200, epoch: 23 | loss: 30.2756176
	speed: 0.0706s/iter; left time: 1445.7363s
Epoch: 23 cost time: 19.407812118530273
Epoch: 23, Steps: 265 Train Loss: 30.4238 (Forecasting Loss:0.1957 + XiCon Loss:3.0228 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.6495190
	speed: 0.0778s/iter; left time: 1579.3154s
	iters: 200, epoch: 24 | loss: 30.1832886
	speed: 0.0737s/iter; left time: 1488.9198s
Epoch: 24 cost time: 20.023646593093872
Epoch: 24, Steps: 265 Train Loss: 30.4110 (Forecasting Loss:0.1957 + XiCon Loss:3.0215 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.0840206
	speed: 0.0760s/iter; left time: 1522.7490s
	iters: 200, epoch: 25 | loss: 30.2648773
	speed: 0.0673s/iter; left time: 1343.0132s
Epoch: 25 cost time: 19.486058235168457
Epoch: 25, Steps: 265 Train Loss: 30.4229 (Forecasting Loss:0.1956 + XiCon Loss:3.0227 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.3628216
	speed: 0.0764s/iter; left time: 1510.5547s
	iters: 200, epoch: 26 | loss: 30.3007755
	speed: 0.0753s/iter; left time: 1481.1692s
Epoch: 26 cost time: 20.23500633239746
Epoch: 26, Steps: 265 Train Loss: 30.4288 (Forecasting Loss:0.1957 + XiCon Loss:3.0233 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 30.8701763
	speed: 0.0799s/iter; left time: 1559.3455s
	iters: 200, epoch: 27 | loss: 30.2776318
	speed: 0.0762s/iter; left time: 1479.0910s
Epoch: 27 cost time: 20.37905263900757
Epoch: 27, Steps: 265 Train Loss: 30.4241 (Forecasting Loss:0.1957 + XiCon Loss:3.0228 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.2772694
	speed: 0.0757s/iter; left time: 1457.4968s
	iters: 200, epoch: 28 | loss: 31.0862656
	speed: 0.0705s/iter; left time: 1350.3427s
Epoch: 28 cost time: 19.796995162963867
Epoch: 28, Steps: 265 Train Loss: 30.4117 (Forecasting Loss:0.1956 + XiCon Loss:3.0216 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.5471096
	speed: 0.0772s/iter; left time: 1465.8920s
	iters: 200, epoch: 29 | loss: 30.4210014
	speed: 0.0766s/iter; left time: 1446.3947s
Epoch: 29 cost time: 20.03627061843872
Epoch: 29, Steps: 265 Train Loss: 30.4233 (Forecasting Loss:0.1957 + XiCon Loss:3.0228 x Lambda(10.0)), Vali MSE Loss: 0.1990 Test MSE Loss: 0.1587
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 30.2770424
	speed: 0.0801s/iter; left time: 1498.7618s
	iters: 200, epoch: 30 | loss: 30.5433044
	speed: 0.0678s/iter; left time: 1262.2857s
Epoch: 30 cost time: 19.465423345565796
Epoch: 30, Steps: 265 Train Loss: 30.4251 (Forecasting Loss:0.1956 + XiCon Loss:3.0229 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 30.3324375
	speed: 0.0763s/iter; left time: 1408.5737s
	iters: 200, epoch: 31 | loss: 30.5978546
	speed: 0.0720s/iter; left time: 1321.2024s
Epoch: 31 cost time: 19.823641777038574
Epoch: 31, Steps: 265 Train Loss: 30.4396 (Forecasting Loss:0.1957 + XiCon Loss:3.0244 x Lambda(10.0)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1587
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09187374264001846, mae:0.22561398148536682, mape:0.5454113483428955, mspe:11.406502723693848 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.9718
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 33.4586792
	speed: 0.0758s/iter; left time: 2001.4077s
	iters: 200, epoch: 1 | loss: 32.0354042
	speed: 0.0677s/iter; left time: 1780.6344s
Epoch: 1 cost time: 19.15284824371338
Epoch: 1, Steps: 265 Train Loss: 33.0192 (Forecasting Loss:0.2282 + XiCon Loss:3.2791 x Lambda(10.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1665
Validation loss decreased (inf --> 0.209268).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.3500481
	speed: 0.0754s/iter; left time: 1970.4520s
	iters: 200, epoch: 2 | loss: 34.0563545
	speed: 0.0708s/iter; left time: 1842.0848s
Epoch: 2 cost time: 19.596017122268677
Epoch: 2, Steps: 265 Train Loss: 32.4813 (Forecasting Loss:0.2111 + XiCon Loss:3.2270 x Lambda(10.0)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1659
Validation loss decreased (0.209268 --> 0.204959).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.5885849
	speed: 0.0803s/iter; left time: 2077.6802s
	iters: 200, epoch: 3 | loss: 31.3488941
	speed: 0.0771s/iter; left time: 1987.8528s
Epoch: 3 cost time: 20.233410835266113
Epoch: 3, Steps: 265 Train Loss: 31.6264 (Forecasting Loss:0.2010 + XiCon Loss:3.1425 x Lambda(10.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.1620
Validation loss decreased (0.204959 --> 0.202127).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6925411
	speed: 0.0803s/iter; left time: 2055.6909s
	iters: 200, epoch: 4 | loss: 31.0874386
	speed: 0.0714s/iter; left time: 1820.9858s
Epoch: 4 cost time: 19.439472436904907
Epoch: 4, Steps: 265 Train Loss: 31.1241 (Forecasting Loss:0.1987 + XiCon Loss:3.0925 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1605
Validation loss decreased (0.202127 --> 0.199838).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.0015869
	speed: 0.0751s/iter; left time: 1904.0715s
	iters: 200, epoch: 5 | loss: 31.0516224
	speed: 0.0708s/iter; left time: 1787.1840s
Epoch: 5 cost time: 19.604450464248657
Epoch: 5, Steps: 265 Train Loss: 31.0224 (Forecasting Loss:0.1971 + XiCon Loss:3.0825 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1599
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.9854469
	speed: 0.0782s/iter; left time: 1960.3721s
	iters: 200, epoch: 6 | loss: 31.2049561
	speed: 0.0761s/iter; left time: 1900.7269s
Epoch: 6 cost time: 20.32149624824524
Epoch: 6, Steps: 265 Train Loss: 30.9518 (Forecasting Loss:0.1966 + XiCon Loss:3.0755 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1596
Validation loss decreased (0.199838 --> 0.199648).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.6803722
	speed: 0.0831s/iter; left time: 2062.2678s
	iters: 200, epoch: 7 | loss: 30.8430042
	speed: 0.0711s/iter; left time: 1756.5075s
Epoch: 7 cost time: 20.475220680236816
Epoch: 7, Steps: 265 Train Loss: 30.9201 (Forecasting Loss:0.1963 + XiCon Loss:3.0724 x Lambda(10.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1592
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.0838013
	speed: 0.0774s/iter; left time: 1898.7985s
	iters: 200, epoch: 8 | loss: 30.8813591
	speed: 0.0746s/iter; left time: 1824.0342s
Epoch: 8 cost time: 20.144221305847168
Epoch: 8, Steps: 265 Train Loss: 30.9485 (Forecasting Loss:0.1961 + XiCon Loss:3.0752 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1587
Validation loss decreased (0.199648 --> 0.199607).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7289600
	speed: 0.0744s/iter; left time: 1807.4060s
	iters: 200, epoch: 9 | loss: 30.6721935
	speed: 0.0711s/iter; left time: 1718.1183s
Epoch: 9 cost time: 18.905752897262573
Epoch: 9, Steps: 265 Train Loss: 30.9401 (Forecasting Loss:0.1960 + XiCon Loss:3.0744 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
Validation loss decreased (0.199607 --> 0.199424).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.1290302
	speed: 0.0768s/iter; left time: 1844.0099s
	iters: 200, epoch: 10 | loss: 30.5084076
	speed: 0.0686s/iter; left time: 1639.6990s
Epoch: 10 cost time: 19.27899432182312
Epoch: 10, Steps: 265 Train Loss: 30.9123 (Forecasting Loss:0.1959 + XiCon Loss:3.0716 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1588
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.3390770
	speed: 0.0760s/iter; left time: 1805.4186s
	iters: 200, epoch: 11 | loss: 31.5769005
	speed: 0.0716s/iter; left time: 1692.6224s
Epoch: 11 cost time: 19.612984895706177
Epoch: 11, Steps: 265 Train Loss: 30.9379 (Forecasting Loss:0.1959 + XiCon Loss:3.0742 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1587
Validation loss decreased (0.199424 --> 0.198896).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.6770496
	speed: 0.0759s/iter; left time: 1781.8501s
	iters: 200, epoch: 12 | loss: 31.2152119
	speed: 0.0682s/iter; left time: 1594.1154s
Epoch: 12 cost time: 19.056575298309326
Epoch: 12, Steps: 265 Train Loss: 30.9215 (Forecasting Loss:0.1958 + XiCon Loss:3.0726 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1587
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7327938
	speed: 0.0807s/iter; left time: 1873.8443s
	iters: 200, epoch: 13 | loss: 30.7548256
	speed: 0.0722s/iter; left time: 1668.8707s
Epoch: 13 cost time: 20.172040939331055
Epoch: 13, Steps: 265 Train Loss: 30.9233 (Forecasting Loss:0.1959 + XiCon Loss:3.0727 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1587
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.8001213
	speed: 0.0728s/iter; left time: 1671.4946s
	iters: 200, epoch: 14 | loss: 30.8755722
	speed: 0.0727s/iter; left time: 1662.7666s
Epoch: 14 cost time: 19.55379366874695
Epoch: 14, Steps: 265 Train Loss: 30.9332 (Forecasting Loss:0.1959 + XiCon Loss:3.0737 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1587
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.2393036
	speed: 0.1115s/iter; left time: 2528.9439s
	iters: 200, epoch: 15 | loss: 31.1697807
	speed: 0.0862s/iter; left time: 1946.9201s
Epoch: 15 cost time: 23.214866399765015
Epoch: 15, Steps: 265 Train Loss: 30.9183 (Forecasting Loss:0.1959 + XiCon Loss:3.0722 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1587
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.9227066
	speed: 0.0755s/iter; left time: 1692.4212s
	iters: 200, epoch: 16 | loss: 31.0136528
	speed: 0.0688s/iter; left time: 1536.8601s
Epoch: 16 cost time: 18.800455808639526
Epoch: 16, Steps: 265 Train Loss: 30.9584 (Forecasting Loss:0.1957 + XiCon Loss:3.0763 x Lambda(10.0)), Vali MSE Loss: 0.1995 Test MSE Loss: 0.1587
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.4303722
	speed: 0.0773s/iter; left time: 1713.3715s
	iters: 200, epoch: 17 | loss: 30.7368755
	speed: 0.0716s/iter; left time: 1580.1301s
Epoch: 17 cost time: 19.673428535461426
Epoch: 17, Steps: 265 Train Loss: 30.9025 (Forecasting Loss:0.1958 + XiCon Loss:3.0707 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1587
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.7878304
	speed: 0.0745s/iter; left time: 1631.3654s
	iters: 200, epoch: 18 | loss: 30.6003876
	speed: 0.0689s/iter; left time: 1501.6916s
Epoch: 18 cost time: 19.13232111930847
Epoch: 18, Steps: 265 Train Loss: 30.9626 (Forecasting Loss:0.1958 + XiCon Loss:3.0767 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1587
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.8032570
	speed: 0.0737s/iter; left time: 1593.4750s
	iters: 200, epoch: 19 | loss: 31.1759930
	speed: 0.0729s/iter; left time: 1568.8993s
Epoch: 19 cost time: 19.429703950881958
Epoch: 19, Steps: 265 Train Loss: 30.9612 (Forecasting Loss:0.1958 + XiCon Loss:3.0765 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1587
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.5662460
	speed: 0.0768s/iter; left time: 1640.5567s
	iters: 200, epoch: 20 | loss: 31.2100639
	speed: 0.0729s/iter; left time: 1549.3247s
Epoch: 20 cost time: 19.721418142318726
Epoch: 20, Steps: 265 Train Loss: 30.9412 (Forecasting Loss:0.1959 + XiCon Loss:3.0745 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1587
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.7544136
	speed: 0.0624s/iter; left time: 1317.7295s
	iters: 200, epoch: 21 | loss: 30.4264946
	speed: 0.0692s/iter; left time: 1453.2602s
Epoch: 21 cost time: 18.18733549118042
Epoch: 21, Steps: 265 Train Loss: 30.9235 (Forecasting Loss:0.1958 + XiCon Loss:3.0728 x Lambda(10.0)), Vali MSE Loss: 0.1993 Test MSE Loss: 0.1587
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09189276397228241, mae:0.22555050253868103, mape:0.5429208278656006, mspe:11.227971076965332 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0919+-0.00034, MAE:0.2257+-0.00043, MAPE:0.5445+-0.00318, MSPE:11.3225+-0.15346, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.1773
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 34.0392227
	speed: 0.1006s/iter; left time: 2565.7153s
	iters: 200, epoch: 1 | loss: 34.2690887
	speed: 0.0939s/iter; left time: 2386.0895s
Epoch: 1 cost time: 24.454633235931396
Epoch: 1, Steps: 256 Train Loss: 34.1868 (Forecasting Loss:0.4343 + XiCon Loss:3.3752 x Lambda(10.0)), Vali MSE Loss: 0.4134 Test MSE Loss: 0.3834
Validation loss decreased (inf --> 0.413449).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 33.4227371
	speed: 0.0924s/iter; left time: 2332.4547s
	iters: 200, epoch: 2 | loss: 33.0839157
	speed: 0.0861s/iter; left time: 2165.2760s
Epoch: 2 cost time: 23.183143854141235
Epoch: 2, Steps: 256 Train Loss: 33.5019 (Forecasting Loss:0.3476 + XiCon Loss:3.3154 x Lambda(10.0)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.3020
Validation loss decreased (0.413449 --> 0.328351).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.8549271
	speed: 0.0934s/iter; left time: 2334.2063s
	iters: 200, epoch: 3 | loss: 32.1544952
	speed: 0.0895s/iter; left time: 2226.8254s
Epoch: 3 cost time: 23.36965274810791
Epoch: 3, Steps: 256 Train Loss: 32.4501 (Forecasting Loss:0.3259 + XiCon Loss:3.2124 x Lambda(10.0)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.3002
Validation loss decreased (0.328351 --> 0.318425).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 32.1465149
	speed: 0.0928s/iter; left time: 2295.1855s
	iters: 200, epoch: 4 | loss: 32.2241096
	speed: 0.0919s/iter; left time: 2264.9611s
Epoch: 4 cost time: 23.163191318511963
Epoch: 4, Steps: 256 Train Loss: 32.0891 (Forecasting Loss:0.3249 + XiCon Loss:3.1764 x Lambda(10.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.3000
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 31.8036900
	speed: 0.0898s/iter; left time: 2199.0560s
	iters: 200, epoch: 5 | loss: 32.2394142
	speed: 0.0855s/iter; left time: 2085.1653s
Epoch: 5 cost time: 22.575905323028564
Epoch: 5, Steps: 256 Train Loss: 31.9079 (Forecasting Loss:0.3266 + XiCon Loss:3.1581 x Lambda(10.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.3008
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 31.6664238
	speed: 0.0943s/iter; left time: 2285.1841s
	iters: 200, epoch: 6 | loss: 32.0108566
	speed: 0.0892s/iter; left time: 2151.4138s
Epoch: 6 cost time: 23.539697408676147
Epoch: 6, Steps: 256 Train Loss: 31.8322 (Forecasting Loss:0.3291 + XiCon Loss:3.1503 x Lambda(10.0)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.3030
Validation loss decreased (0.318425 --> 0.318286).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.9195728
	speed: 0.0936s/iter; left time: 2243.2941s
	iters: 200, epoch: 7 | loss: 31.8308258
	speed: 0.0858s/iter; left time: 2048.5574s
Epoch: 7 cost time: 23.08191227912903
Epoch: 7, Steps: 256 Train Loss: 31.8132 (Forecasting Loss:0.3303 + XiCon Loss:3.1483 x Lambda(10.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.3022
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 31.7831440
	speed: 0.0912s/iter; left time: 2162.3250s
	iters: 200, epoch: 8 | loss: 31.8629532
	speed: 0.0900s/iter; left time: 2124.1887s
Epoch: 8 cost time: 23.060901880264282
Epoch: 8, Steps: 256 Train Loss: 31.8072 (Forecasting Loss:0.3305 + XiCon Loss:3.1477 x Lambda(10.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.3024
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.9945011
	speed: 0.0952s/iter; left time: 2233.0375s
	iters: 200, epoch: 9 | loss: 32.0158577
	speed: 0.0889s/iter; left time: 2075.6065s
Epoch: 9 cost time: 23.4647855758667
Epoch: 9, Steps: 256 Train Loss: 31.8131 (Forecasting Loss:0.3307 + XiCon Loss:3.1482 x Lambda(10.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.3023
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 31.8132915
	speed: 0.0906s/iter; left time: 2102.6166s
	iters: 200, epoch: 10 | loss: 31.8560448
	speed: 0.0903s/iter; left time: 2086.2662s
Epoch: 10 cost time: 22.9780490398407
Epoch: 10, Steps: 256 Train Loss: 31.8037 (Forecasting Loss:0.3307 + XiCon Loss:3.1473 x Lambda(10.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.3022
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.8925648
	speed: 0.0956s/iter; left time: 2193.1124s
	iters: 200, epoch: 11 | loss: 31.7165222
	speed: 0.0884s/iter; left time: 2020.0836s
Epoch: 11 cost time: 23.421040296554565
Epoch: 11, Steps: 256 Train Loss: 31.8137 (Forecasting Loss:0.3307 + XiCon Loss:3.1483 x Lambda(10.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.3022
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.8555126
	speed: 0.0929s/iter; left time: 2107.8551s
	iters: 200, epoch: 12 | loss: 31.7391243
	speed: 0.0842s/iter; left time: 1901.6609s
Epoch: 12 cost time: 22.97983145713806
Epoch: 12, Steps: 256 Train Loss: 31.8058 (Forecasting Loss:0.3307 + XiCon Loss:3.1475 x Lambda(10.0)), Vali MSE Loss: 0.3196 Test MSE Loss: 0.3022
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 31.7716236
	speed: 0.0932s/iter; left time: 2090.1881s
	iters: 200, epoch: 13 | loss: 32.0133476
	speed: 0.0846s/iter; left time: 1888.3721s
Epoch: 13 cost time: 22.691163063049316
Epoch: 13, Steps: 256 Train Loss: 31.8120 (Forecasting Loss:0.3306 + XiCon Loss:3.1481 x Lambda(10.0)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.3022
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 31.9965649
	speed: 0.0915s/iter; left time: 2029.2466s
	iters: 200, epoch: 14 | loss: 31.8630428
	speed: 0.0856s/iter; left time: 1889.1845s
Epoch: 14 cost time: 22.564345359802246
Epoch: 14, Steps: 256 Train Loss: 31.8039 (Forecasting Loss:0.3307 + XiCon Loss:3.1473 x Lambda(10.0)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.3021
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 31.7286739
	speed: 0.0979s/iter; left time: 2145.0279s
	iters: 200, epoch: 15 | loss: 31.7352600
	speed: 0.0877s/iter; left time: 1912.6790s
Epoch: 15 cost time: 23.490716457366943
Epoch: 15, Steps: 256 Train Loss: 31.8038 (Forecasting Loss:0.3306 + XiCon Loss:3.1473 x Lambda(10.0)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.3021
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 31.9843693
	speed: 0.0920s/iter; left time: 1993.6629s
	iters: 200, epoch: 16 | loss: 31.6223717
	speed: 0.0849s/iter; left time: 1830.8075s
Epoch: 16 cost time: 22.881529331207275
Epoch: 16, Steps: 256 Train Loss: 31.8022 (Forecasting Loss:0.3308 + XiCon Loss:3.1471 x Lambda(10.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.3021
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22928015887737274, mae:0.3766271471977234, mape:0.803514301776886, mspe:22.2470760345459 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 27.3382
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 33.9498940
	speed: 0.0844s/iter; left time: 2152.8447s
	iters: 200, epoch: 1 | loss: 33.8804245
	speed: 0.0804s/iter; left time: 2042.9264s
Epoch: 1 cost time: 20.593425035476685
Epoch: 1, Steps: 256 Train Loss: 34.0474 (Forecasting Loss:0.4375 + XiCon Loss:3.3610 x Lambda(10.0)), Vali MSE Loss: 0.4230 Test MSE Loss: 0.3914
Validation loss decreased (inf --> 0.422977).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 33.4465027
	speed: 0.0926s/iter; left time: 2337.7084s
	iters: 200, epoch: 2 | loss: 33.0462494
	speed: 0.0840s/iter; left time: 2111.5682s
Epoch: 2 cost time: 22.54929828643799
Epoch: 2, Steps: 256 Train Loss: 33.2717 (Forecasting Loss:0.3530 + XiCon Loss:3.2919 x Lambda(10.0)), Vali MSE Loss: 0.3399 Test MSE Loss: 0.3047
Validation loss decreased (0.422977 --> 0.339898).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.4961014
	speed: 0.0877s/iter; left time: 2191.9096s
	iters: 200, epoch: 3 | loss: 32.0265388
	speed: 0.0839s/iter; left time: 2087.7277s
Epoch: 3 cost time: 21.84134030342102
Epoch: 3, Steps: 256 Train Loss: 32.1680 (Forecasting Loss:0.3353 + XiCon Loss:3.1833 x Lambda(10.0)), Vali MSE Loss: 0.3373 Test MSE Loss: 0.3045
Validation loss decreased (0.339898 --> 0.337253).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 31.7570229
	speed: 0.0861s/iter; left time: 2130.5943s
	iters: 200, epoch: 4 | loss: 32.0200081
	speed: 0.0816s/iter; left time: 2009.0588s
Epoch: 4 cost time: 21.370391130447388
Epoch: 4, Steps: 256 Train Loss: 31.9796 (Forecasting Loss:0.3334 + XiCon Loss:3.1646 x Lambda(10.0)), Vali MSE Loss: 0.3349 Test MSE Loss: 0.3026
Validation loss decreased (0.337253 --> 0.334892).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 31.8900738
	speed: 0.0841s/iter; left time: 2059.7168s
	iters: 200, epoch: 5 | loss: 31.9690495
	speed: 0.0830s/iter; left time: 2024.2870s
Epoch: 5 cost time: 21.668139219284058
Epoch: 5, Steps: 256 Train Loss: 31.9554 (Forecasting Loss:0.3327 + XiCon Loss:3.1623 x Lambda(10.0)), Vali MSE Loss: 0.3367 Test MSE Loss: 0.3044
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 32.0591545
	speed: 0.0920s/iter; left time: 2228.7236s
	iters: 200, epoch: 6 | loss: 31.8829269
	speed: 0.0789s/iter; left time: 1902.8194s
Epoch: 6 cost time: 21.90608310699463
Epoch: 6, Steps: 256 Train Loss: 31.9655 (Forecasting Loss:0.3323 + XiCon Loss:3.1633 x Lambda(10.0)), Vali MSE Loss: 0.3358 Test MSE Loss: 0.3036
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.9423313
	speed: 0.0852s/iter; left time: 2040.6371s
	iters: 200, epoch: 7 | loss: 31.9253254
	speed: 0.0836s/iter; left time: 1995.3285s
Epoch: 7 cost time: 21.25928020477295
Epoch: 7, Steps: 256 Train Loss: 31.9832 (Forecasting Loss:0.3321 + XiCon Loss:3.1651 x Lambda(10.0)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.3031
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.0953026
	speed: 0.0848s/iter; left time: 2011.4047s
	iters: 200, epoch: 8 | loss: 31.9880543
	speed: 0.0809s/iter; left time: 1909.4843s
Epoch: 8 cost time: 21.315717935562134
Epoch: 8, Steps: 256 Train Loss: 31.9743 (Forecasting Loss:0.3321 + XiCon Loss:3.1642 x Lambda(10.0)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3035
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.8634529
	speed: 0.0874s/iter; left time: 2050.3534s
	iters: 200, epoch: 9 | loss: 31.7764416
	speed: 0.0813s/iter; left time: 1897.7922s
Epoch: 9 cost time: 21.414993286132812
Epoch: 9, Steps: 256 Train Loss: 31.9829 (Forecasting Loss:0.3320 + XiCon Loss:3.1651 x Lambda(10.0)), Vali MSE Loss: 0.3357 Test MSE Loss: 0.3034
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 31.7823887
	speed: 0.0894s/iter; left time: 2073.0697s
	iters: 200, epoch: 10 | loss: 31.9519215
	speed: 0.0812s/iter; left time: 1876.2364s
Epoch: 10 cost time: 21.872750997543335
Epoch: 10, Steps: 256 Train Loss: 31.9800 (Forecasting Loss:0.3320 + XiCon Loss:3.1648 x Lambda(10.0)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3035
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.9560509
	speed: 0.0801s/iter; left time: 1837.8630s
	iters: 200, epoch: 11 | loss: 31.6603966
	speed: 0.0829s/iter; left time: 1894.5571s
Epoch: 11 cost time: 20.882000207901
Epoch: 11, Steps: 256 Train Loss: 31.9957 (Forecasting Loss:0.3319 + XiCon Loss:3.1664 x Lambda(10.0)), Vali MSE Loss: 0.3352 Test MSE Loss: 0.3034
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.9004879
	speed: 0.0855s/iter; left time: 1939.6950s
	iters: 200, epoch: 12 | loss: 31.9417934
	speed: 0.0810s/iter; left time: 1828.9763s
Epoch: 12 cost time: 21.093974590301514
Epoch: 12, Steps: 256 Train Loss: 31.9962 (Forecasting Loss:0.3320 + XiCon Loss:3.1664 x Lambda(10.0)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3034
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 32.1647987
	speed: 0.0876s/iter; left time: 1965.3328s
	iters: 200, epoch: 13 | loss: 32.2291222
	speed: 0.0774s/iter; left time: 1728.4878s
Epoch: 13 cost time: 20.80734610557556
Epoch: 13, Steps: 256 Train Loss: 31.9959 (Forecasting Loss:0.3320 + XiCon Loss:3.1664 x Lambda(10.0)), Vali MSE Loss: 0.3355 Test MSE Loss: 0.3034
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 32.2839432
	speed: 0.0872s/iter; left time: 1932.4821s
	iters: 200, epoch: 14 | loss: 32.3361359
	speed: 0.0821s/iter; left time: 1812.7622s
Epoch: 14 cost time: 21.302139282226562
Epoch: 14, Steps: 256 Train Loss: 31.9978 (Forecasting Loss:0.3321 + XiCon Loss:3.1666 x Lambda(10.0)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.3034
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22521156072616577, mae:0.3799912929534912, mape:0.7195940017700195, mspe:18.484399795532227 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 27.3740
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 34.3026085
	speed: 0.0878s/iter; left time: 2239.7571s
	iters: 200, epoch: 1 | loss: 34.3051643
	speed: 0.0782s/iter; left time: 1986.9225s
Epoch: 1 cost time: 21.287384033203125
Epoch: 1, Steps: 256 Train Loss: 34.1176 (Forecasting Loss:0.4355 + XiCon Loss:3.3682 x Lambda(10.0)), Vali MSE Loss: 0.4187 Test MSE Loss: 0.3877
Validation loss decreased (inf --> 0.418700).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 33.7641678
	speed: 0.0820s/iter; left time: 2070.8714s
	iters: 200, epoch: 2 | loss: 32.7815933
	speed: 0.0574s/iter; left time: 1442.1075s
Epoch: 2 cost time: 20.164374828338623
Epoch: 2, Steps: 256 Train Loss: 33.4097 (Forecasting Loss:0.3526 + XiCon Loss:3.3057 x Lambda(10.0)), Vali MSE Loss: 0.3479 Test MSE Loss: 0.3139
Validation loss decreased (0.418700 --> 0.347909).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.5240860
	speed: 0.0679s/iter; left time: 1697.2226s
	iters: 200, epoch: 3 | loss: 32.2843285
	speed: 0.0744s/iter; left time: 1852.3215s
Epoch: 3 cost time: 18.419358730316162
Epoch: 3, Steps: 256 Train Loss: 32.2631 (Forecasting Loss:0.3355 + XiCon Loss:3.1928 x Lambda(10.0)), Vali MSE Loss: 0.3402 Test MSE Loss: 0.3033
Validation loss decreased (0.347909 --> 0.340158).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 31.9996929
	speed: 0.0811s/iter; left time: 2005.1323s
	iters: 200, epoch: 4 | loss: 32.0383186
	speed: 0.0830s/iter; left time: 2045.7154s
Epoch: 4 cost time: 20.83396077156067
Epoch: 4, Steps: 256 Train Loss: 32.0190 (Forecasting Loss:0.3319 + XiCon Loss:3.1687 x Lambda(10.0)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.3016
Validation loss decreased (0.340158 --> 0.339307).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 32.0831375
	speed: 0.0862s/iter; left time: 2110.6271s
	iters: 200, epoch: 5 | loss: 31.7628098
	speed: 0.0772s/iter; left time: 1882.3480s
Epoch: 5 cost time: 20.692947387695312
Epoch: 5, Steps: 256 Train Loss: 31.9076 (Forecasting Loss:0.3303 + XiCon Loss:3.1577 x Lambda(10.0)), Vali MSE Loss: 0.3373 Test MSE Loss: 0.2996
Validation loss decreased (0.339307 --> 0.337253).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 31.9929180
	speed: 0.0796s/iter; left time: 1928.3822s
	iters: 200, epoch: 6 | loss: 31.7306995
	speed: 0.0756s/iter; left time: 1822.4268s
Epoch: 6 cost time: 19.887104272842407
Epoch: 6, Steps: 256 Train Loss: 31.8788 (Forecasting Loss:0.3294 + XiCon Loss:3.1549 x Lambda(10.0)), Vali MSE Loss: 0.3379 Test MSE Loss: 0.3000
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.8193264
	speed: 0.0882s/iter; left time: 2113.8988s
	iters: 200, epoch: 7 | loss: 31.8021336
	speed: 0.0755s/iter; left time: 1801.7867s
Epoch: 7 cost time: 20.695753574371338
Epoch: 7, Steps: 256 Train Loss: 31.8545 (Forecasting Loss:0.3291 + XiCon Loss:3.1525 x Lambda(10.0)), Vali MSE Loss: 0.3367 Test MSE Loss: 0.2990
Validation loss decreased (0.337253 --> 0.336727).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.0984192
	speed: 0.0807s/iter; left time: 1912.1312s
	iters: 200, epoch: 8 | loss: 31.8622265
	speed: 0.0759s/iter; left time: 1790.9102s
Epoch: 8 cost time: 20.1435604095459
Epoch: 8, Steps: 256 Train Loss: 31.8594 (Forecasting Loss:0.3288 + XiCon Loss:3.1531 x Lambda(10.0)), Vali MSE Loss: 0.3366 Test MSE Loss: 0.2990
Validation loss decreased (0.336727 --> 0.336619).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 31.8176670
	speed: 0.0828s/iter; left time: 1940.8706s
	iters: 200, epoch: 9 | loss: 31.7352390
	speed: 0.0793s/iter; left time: 1850.9296s
Epoch: 9 cost time: 20.534337043762207
Epoch: 9, Steps: 256 Train Loss: 31.8539 (Forecasting Loss:0.3289 + XiCon Loss:3.1525 x Lambda(10.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2991
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 31.7917252
	speed: 0.0875s/iter; left time: 2029.7856s
	iters: 200, epoch: 10 | loss: 31.8619308
	speed: 0.0789s/iter; left time: 1822.4043s
Epoch: 10 cost time: 21.11466884613037
Epoch: 10, Steps: 256 Train Loss: 31.8509 (Forecasting Loss:0.3288 + XiCon Loss:3.1522 x Lambda(10.0)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2990
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 31.8570194
	speed: 0.0835s/iter; left time: 1915.6998s
	iters: 200, epoch: 11 | loss: 31.8533649
	speed: 0.0795s/iter; left time: 1814.9991s
Epoch: 11 cost time: 20.945603132247925
Epoch: 11, Steps: 256 Train Loss: 31.8356 (Forecasting Loss:0.3288 + XiCon Loss:3.1507 x Lambda(10.0)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.2990
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.7913132
	speed: 0.0876s/iter; left time: 1986.6486s
	iters: 200, epoch: 12 | loss: 31.9446545
	speed: 0.0761s/iter; left time: 1719.6420s
Epoch: 12 cost time: 20.583298921585083
Epoch: 12, Steps: 256 Train Loss: 31.8424 (Forecasting Loss:0.3288 + XiCon Loss:3.1514 x Lambda(10.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2990
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 31.6947517
	speed: 0.0831s/iter; left time: 1863.5330s
	iters: 200, epoch: 13 | loss: 31.7669907
	speed: 0.0788s/iter; left time: 1759.3473s
Epoch: 13 cost time: 20.242481231689453
Epoch: 13, Steps: 256 Train Loss: 31.8376 (Forecasting Loss:0.3287 + XiCon Loss:3.1509 x Lambda(10.0)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.2990
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 31.8301411
	speed: 0.0858s/iter; left time: 1902.6709s
	iters: 200, epoch: 14 | loss: 31.6536694
	speed: 0.0781s/iter; left time: 1723.5259s
Epoch: 14 cost time: 20.605523109436035
Epoch: 14, Steps: 256 Train Loss: 31.8470 (Forecasting Loss:0.3287 + XiCon Loss:3.1518 x Lambda(10.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2990
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 31.8450260
	speed: 0.0835s/iter; left time: 1829.8054s
	iters: 200, epoch: 15 | loss: 31.9409370
	speed: 0.0789s/iter; left time: 1722.4168s
Epoch: 15 cost time: 20.498724460601807
Epoch: 15, Steps: 256 Train Loss: 31.8294 (Forecasting Loss:0.3287 + XiCon Loss:3.1501 x Lambda(10.0)), Vali MSE Loss: 0.3370 Test MSE Loss: 0.2990
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 31.7915764
	speed: 0.0828s/iter; left time: 1792.6633s
	iters: 200, epoch: 16 | loss: 31.7664490
	speed: 0.0808s/iter; left time: 1742.8200s
Epoch: 16 cost time: 20.73734951019287
Epoch: 16, Steps: 256 Train Loss: 31.8428 (Forecasting Loss:0.3287 + XiCon Loss:3.1514 x Lambda(10.0)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.2990
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 32.1193695
	speed: 0.0791s/iter; left time: 1692.7363s
	iters: 200, epoch: 17 | loss: 31.8755779
	speed: 0.0782s/iter; left time: 1666.8220s
Epoch: 17 cost time: 20.18525528907776
Epoch: 17, Steps: 256 Train Loss: 31.8404 (Forecasting Loss:0.3287 + XiCon Loss:3.1512 x Lambda(10.0)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.2990
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 32.0319901
	speed: 0.0868s/iter; left time: 1835.5918s
	iters: 200, epoch: 18 | loss: 31.9659214
	speed: 0.0788s/iter; left time: 1658.0964s
Epoch: 18 cost time: 20.98444437980652
Epoch: 18, Steps: 256 Train Loss: 31.8579 (Forecasting Loss:0.3286 + XiCon Loss:3.1529 x Lambda(10.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2990
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.22212108969688416, mae:0.3757794499397278, mape:0.7207669019699097, mspe:18.695476531982422 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.3409
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 34.0385094
	speed: 0.0806s/iter; left time: 2054.8996s
	iters: 200, epoch: 1 | loss: 34.2224846
	speed: 0.0747s/iter; left time: 1897.1138s
Epoch: 1 cost time: 19.684953927993774
Epoch: 1, Steps: 256 Train Loss: 34.1538 (Forecasting Loss:0.4330 + XiCon Loss:3.3721 x Lambda(10.0)), Vali MSE Loss: 0.4104 Test MSE Loss: 0.3797
Validation loss decreased (inf --> 0.410443).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 33.5514069
	speed: 0.0807s/iter; left time: 2036.8355s
	iters: 200, epoch: 2 | loss: 32.5444870
	speed: 0.0748s/iter; left time: 1882.0585s
Epoch: 2 cost time: 19.96054983139038
Epoch: 2, Steps: 256 Train Loss: 33.2139 (Forecasting Loss:0.3531 + XiCon Loss:3.2861 x Lambda(10.0)), Vali MSE Loss: 0.3369 Test MSE Loss: 0.3065
Validation loss decreased (0.410443 --> 0.336875).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 31.9379444
	speed: 0.0784s/iter; left time: 1959.8271s
	iters: 200, epoch: 3 | loss: 32.5694885
	speed: 0.0763s/iter; left time: 1898.8416s
Epoch: 3 cost time: 19.449076175689697
Epoch: 3, Steps: 256 Train Loss: 32.1328 (Forecasting Loss:0.3335 + XiCon Loss:3.1799 x Lambda(10.0)), Vali MSE Loss: 0.3361 Test MSE Loss: 0.3124
Validation loss decreased (0.336875 --> 0.336087).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 32.3060837
	speed: 0.0828s/iter; left time: 2047.0780s
	iters: 200, epoch: 4 | loss: 32.5103455
	speed: 0.0809s/iter; left time: 1993.8275s
Epoch: 4 cost time: 20.70287275314331
Epoch: 4, Steps: 256 Train Loss: 32.2725 (Forecasting Loss:0.3287 + XiCon Loss:3.1944 x Lambda(10.0)), Vali MSE Loss: 0.3338 Test MSE Loss: 0.3107
Validation loss decreased (0.336087 --> 0.333796).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 32.4837723
	speed: 0.0757s/iter; left time: 1853.9722s
	iters: 200, epoch: 5 | loss: 32.0891190
	speed: 0.0782s/iter; left time: 1905.2231s
Epoch: 5 cost time: 19.430175304412842
Epoch: 5, Steps: 256 Train Loss: 32.3228 (Forecasting Loss:0.3270 + XiCon Loss:3.1996 x Lambda(10.0)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.3098
Validation loss decreased (0.333796 --> 0.332482).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 32.5202179
	speed: 0.0820s/iter; left time: 1985.3191s
	iters: 200, epoch: 6 | loss: 32.3094978
	speed: 0.0738s/iter; left time: 1779.5259s
Epoch: 6 cost time: 19.58613109588623
Epoch: 6, Steps: 256 Train Loss: 32.3906 (Forecasting Loss:0.3262 + XiCon Loss:3.2064 x Lambda(10.0)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.3093
Validation loss decreased (0.332482 --> 0.331521).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 32.4176636
	speed: 0.0796s/iter; left time: 1907.9467s
	iters: 200, epoch: 7 | loss: 32.1747055
	speed: 0.0774s/iter; left time: 1848.0203s
Epoch: 7 cost time: 19.810713052749634
Epoch: 7, Steps: 256 Train Loss: 32.3884 (Forecasting Loss:0.3259 + XiCon Loss:3.2062 x Lambda(10.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.3090
Validation loss decreased (0.331521 --> 0.330892).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.2523117
	speed: 0.0833s/iter; left time: 1975.5258s
	iters: 200, epoch: 8 | loss: 32.3587532
	speed: 0.0756s/iter; left time: 1783.8768s
Epoch: 8 cost time: 19.65949511528015
Epoch: 8, Steps: 256 Train Loss: 32.3567 (Forecasting Loss:0.3257 + XiCon Loss:3.2031 x Lambda(10.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.3089
Validation loss decreased (0.330892 --> 0.330630).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 32.3977776
	speed: 0.0805s/iter; left time: 1888.1999s
	iters: 200, epoch: 9 | loss: 32.1533165
	speed: 0.0756s/iter; left time: 1765.5517s
Epoch: 9 cost time: 20.15406560897827
Epoch: 9, Steps: 256 Train Loss: 32.4047 (Forecasting Loss:0.3256 + XiCon Loss:3.2079 x Lambda(10.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.3089
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 32.2082100
	speed: 0.0785s/iter; left time: 1819.9919s
	iters: 200, epoch: 10 | loss: 32.3588409
	speed: 0.0753s/iter; left time: 1739.0273s
Epoch: 10 cost time: 19.17699432373047
Epoch: 10, Steps: 256 Train Loss: 32.4108 (Forecasting Loss:0.3255 + XiCon Loss:3.2085 x Lambda(10.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.3088
Validation loss decreased (0.330630 --> 0.330599).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 32.3148613
	speed: 0.0813s/iter; left time: 1865.1724s
	iters: 200, epoch: 11 | loss: 32.5655899
	speed: 0.0742s/iter; left time: 1695.8475s
Epoch: 11 cost time: 19.703771352767944
Epoch: 11, Steps: 256 Train Loss: 32.3938 (Forecasting Loss:0.3255 + XiCon Loss:3.2068 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 32.1996193
	speed: 0.0811s/iter; left time: 1840.3234s
	iters: 200, epoch: 12 | loss: 32.6404037
	speed: 0.0736s/iter; left time: 1661.8569s
Epoch: 12 cost time: 19.731271982192993
Epoch: 12, Steps: 256 Train Loss: 32.4061 (Forecasting Loss:0.3256 + XiCon Loss:3.2081 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 32.3313217
	speed: 0.1119s/iter; left time: 2510.1001s
	iters: 200, epoch: 13 | loss: 32.3335800
	speed: 0.0827s/iter; left time: 1846.2353s
Epoch: 13 cost time: 24.033228874206543
Epoch: 13, Steps: 256 Train Loss: 32.3921 (Forecasting Loss:0.3255 + XiCon Loss:3.2067 x Lambda(10.0)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.3088
Validation loss decreased (0.330599 --> 0.330437).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 32.4379387
	speed: 0.0833s/iter; left time: 1847.2861s
	iters: 200, epoch: 14 | loss: 32.8472252
	speed: 0.0748s/iter; left time: 1650.4754s
Epoch: 14 cost time: 20.22983717918396
Epoch: 14, Steps: 256 Train Loss: 32.3976 (Forecasting Loss:0.3255 + XiCon Loss:3.2072 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 32.2726593
	speed: 0.0859s/iter; left time: 1882.4558s
	iters: 200, epoch: 15 | loss: 33.0242729
	speed: 0.0823s/iter; left time: 1794.7744s
Epoch: 15 cost time: 21.06917428970337
Epoch: 15, Steps: 256 Train Loss: 32.3811 (Forecasting Loss:0.3255 + XiCon Loss:3.2056 x Lambda(10.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.3088
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 32.3433075
	speed: 0.0779s/iter; left time: 1688.1599s
	iters: 200, epoch: 16 | loss: 32.6563492
	speed: 0.0737s/iter; left time: 1589.7403s
Epoch: 16 cost time: 19.19775915145874
Epoch: 16, Steps: 256 Train Loss: 32.4246 (Forecasting Loss:0.3255 + XiCon Loss:3.2099 x Lambda(10.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.3088
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 32.5459023
	speed: 0.0832s/iter; left time: 1781.1722s
	iters: 200, epoch: 17 | loss: 32.3162079
	speed: 0.0742s/iter; left time: 1580.6971s
Epoch: 17 cost time: 20.20720601081848
Epoch: 17, Steps: 256 Train Loss: 32.3971 (Forecasting Loss:0.3255 + XiCon Loss:3.2072 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 32.3693085
	speed: 0.0764s/iter; left time: 1616.8246s
	iters: 200, epoch: 18 | loss: 32.0582123
	speed: 0.0745s/iter; left time: 1567.2781s
Epoch: 18 cost time: 19.15963649749756
Epoch: 18, Steps: 256 Train Loss: 32.3856 (Forecasting Loss:0.3255 + XiCon Loss:3.2060 x Lambda(10.0)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.3088
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 32.2899323
	speed: 0.0786s/iter; left time: 1642.6323s
	iters: 200, epoch: 19 | loss: 32.3459587
	speed: 0.0746s/iter; left time: 1552.1655s
Epoch: 19 cost time: 19.558439254760742
Epoch: 19, Steps: 256 Train Loss: 32.4122 (Forecasting Loss:0.3255 + XiCon Loss:3.2087 x Lambda(10.0)), Vali MSE Loss: 0.3308 Test MSE Loss: 0.3088
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 32.4950752
	speed: 0.0768s/iter; left time: 1584.1324s
	iters: 200, epoch: 20 | loss: 31.9888363
	speed: 0.0784s/iter; left time: 1609.5774s
Epoch: 20 cost time: 19.682770252227783
Epoch: 20, Steps: 256 Train Loss: 32.3995 (Forecasting Loss:0.3255 + XiCon Loss:3.2074 x Lambda(10.0)), Vali MSE Loss: 0.3306 Test MSE Loss: 0.3088
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 32.8263702
	speed: 0.0826s/iter; left time: 1683.3325s
	iters: 200, epoch: 21 | loss: 32.7173080
	speed: 0.0758s/iter; left time: 1536.6844s
Epoch: 21 cost time: 19.724124431610107
Epoch: 21, Steps: 256 Train Loss: 32.3989 (Forecasting Loss:0.3255 + XiCon Loss:3.2073 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 32.1844025
	speed: 0.0804s/iter; left time: 1617.1039s
	iters: 200, epoch: 22 | loss: 33.0356178
	speed: 0.0751s/iter; left time: 1503.1330s
Epoch: 22 cost time: 19.607028245925903
Epoch: 22, Steps: 256 Train Loss: 32.3846 (Forecasting Loss:0.3254 + XiCon Loss:3.2059 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 32.2046738
	speed: 0.0815s/iter; left time: 1619.3572s
	iters: 200, epoch: 23 | loss: 32.4800186
	speed: 0.0791s/iter; left time: 1564.6688s
Epoch: 23 cost time: 22.07121729850769
Epoch: 23, Steps: 256 Train Loss: 32.3804 (Forecasting Loss:0.3255 + XiCon Loss:3.2055 x Lambda(10.0)), Vali MSE Loss: 0.3307 Test MSE Loss: 0.3088
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.23458139598369598, mae:0.38306814432144165, mape:0.7147167325019836, mspe:17.667123794555664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:979073
train 32785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.4998
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 32785
val 10081
test 10081
	iters: 100, epoch: 1 | loss: 34.1901321
	speed: 0.0829s/iter; left time: 2114.2512s
	iters: 200, epoch: 1 | loss: 34.3543015
	speed: 0.0806s/iter; left time: 2046.8222s
Epoch: 1 cost time: 21.025066137313843
Epoch: 1, Steps: 256 Train Loss: 34.2706 (Forecasting Loss:0.4370 + XiCon Loss:3.3834 x Lambda(10.0)), Vali MSE Loss: 0.4013 Test MSE Loss: 0.3733
Validation loss decreased (inf --> 0.401304).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 34.0221367
	speed: 0.0837s/iter; left time: 2112.9592s
	iters: 200, epoch: 2 | loss: 33.2265739
	speed: 0.0773s/iter; left time: 1943.3819s
Epoch: 2 cost time: 20.364652633666992
Epoch: 2, Steps: 256 Train Loss: 33.4925 (Forecasting Loss:0.3520 + XiCon Loss:3.3141 x Lambda(10.0)), Vali MSE Loss: 0.3407 Test MSE Loss: 0.3051
Validation loss decreased (0.401304 --> 0.340672).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 32.5930443
	speed: 0.0818s/iter; left time: 2044.4088s
	iters: 200, epoch: 3 | loss: 32.3272705
	speed: 0.0783s/iter; left time: 1948.4850s
Epoch: 3 cost time: 20.527575969696045
Epoch: 3, Steps: 256 Train Loss: 32.4289 (Forecasting Loss:0.3336 + XiCon Loss:3.2095 x Lambda(10.0)), Vali MSE Loss: 0.3393 Test MSE Loss: 0.3027
Validation loss decreased (0.340672 --> 0.339308).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 32.4011002
	speed: 0.0837s/iter; left time: 2071.1225s
	iters: 200, epoch: 4 | loss: 32.3687210
	speed: 0.0791s/iter; left time: 1948.0223s
Epoch: 4 cost time: 20.462063550949097
Epoch: 4, Steps: 256 Train Loss: 32.1438 (Forecasting Loss:0.3302 + XiCon Loss:3.1814 x Lambda(10.0)), Vali MSE Loss: 0.3397 Test MSE Loss: 0.3027
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 32.0377731
	speed: 0.0832s/iter; left time: 2035.4960s
	iters: 200, epoch: 5 | loss: 31.9800987
	speed: 0.0781s/iter; left time: 1904.1002s
Epoch: 5 cost time: 20.1507511138916
Epoch: 5, Steps: 256 Train Loss: 32.0451 (Forecasting Loss:0.3291 + XiCon Loss:3.1716 x Lambda(10.0)), Vali MSE Loss: 0.3387 Test MSE Loss: 0.3020
Validation loss decreased (0.339308 --> 0.338746).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 31.8630829
	speed: 0.0820s/iter; left time: 1985.6891s
	iters: 200, epoch: 6 | loss: 32.0977554
	speed: 0.0768s/iter; left time: 1851.3606s
Epoch: 6 cost time: 19.74623441696167
Epoch: 6, Steps: 256 Train Loss: 32.0274 (Forecasting Loss:0.3285 + XiCon Loss:3.1699 x Lambda(10.0)), Vali MSE Loss: 0.3389 Test MSE Loss: 0.3020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 31.8388863
	speed: 0.0811s/iter; left time: 1943.9968s
	iters: 200, epoch: 7 | loss: 32.0087891
	speed: 0.0769s/iter; left time: 1835.8681s
Epoch: 7 cost time: 20.266024351119995
Epoch: 7, Steps: 256 Train Loss: 32.0039 (Forecasting Loss:0.3283 + XiCon Loss:3.1676 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
Validation loss decreased (0.338746 --> 0.338464).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 32.0232811
	speed: 0.0870s/iter; left time: 2062.3215s
	iters: 200, epoch: 8 | loss: 32.1647568
	speed: 0.0778s/iter; left time: 1836.6208s
Epoch: 8 cost time: 21.1890869140625
Epoch: 8, Steps: 256 Train Loss: 31.9950 (Forecasting Loss:0.3282 + XiCon Loss:3.1667 x Lambda(10.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3020
Validation loss decreased (0.338464 --> 0.338297).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 32.1146469
	speed: 0.0835s/iter; left time: 1957.3724s
	iters: 200, epoch: 9 | loss: 32.0119438
	speed: 0.0796s/iter; left time: 1858.5227s
Epoch: 9 cost time: 20.83831262588501
Epoch: 9, Steps: 256 Train Loss: 32.0046 (Forecasting Loss:0.3280 + XiCon Loss:3.1677 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 32.0641899
	speed: 0.0823s/iter; left time: 1909.3478s
	iters: 200, epoch: 10 | loss: 32.0660095
	speed: 0.0758s/iter; left time: 1750.7682s
Epoch: 10 cost time: 20.272616386413574
Epoch: 10, Steps: 256 Train Loss: 31.9824 (Forecasting Loss:0.3281 + XiCon Loss:3.1654 x Lambda(10.0)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.3020
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 32.2591324
	speed: 0.0763s/iter; left time: 1751.3032s
	iters: 200, epoch: 11 | loss: 32.2306023
	speed: 0.0748s/iter; left time: 1708.5249s
Epoch: 11 cost time: 19.29488182067871
Epoch: 11, Steps: 256 Train Loss: 31.9924 (Forecasting Loss:0.3280 + XiCon Loss:3.1664 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 31.9491920
	speed: 0.0835s/iter; left time: 1893.6619s
	iters: 200, epoch: 12 | loss: 31.9746723
	speed: 0.0788s/iter; left time: 1780.3869s
Epoch: 12 cost time: 20.435400247573853
Epoch: 12, Steps: 256 Train Loss: 31.9961 (Forecasting Loss:0.3280 + XiCon Loss:3.1668 x Lambda(10.0)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.3020
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 32.2318459
	speed: 0.0780s/iter; left time: 1749.1046s
	iters: 200, epoch: 13 | loss: 31.9063835
	speed: 0.0802s/iter; left time: 1790.9374s
Epoch: 13 cost time: 19.939897060394287
Epoch: 13, Steps: 256 Train Loss: 31.9761 (Forecasting Loss:0.3281 + XiCon Loss:3.1648 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 31.9742107
	speed: 0.0861s/iter; left time: 1908.0803s
	iters: 200, epoch: 14 | loss: 32.1095619
	speed: 0.0790s/iter; left time: 1743.3666s
Epoch: 14 cost time: 20.946590662002563
Epoch: 14, Steps: 256 Train Loss: 31.9873 (Forecasting Loss:0.3280 + XiCon Loss:3.1659 x Lambda(10.0)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.3020
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 31.8637676
	speed: 0.0802s/iter; left time: 1758.6694s
	iters: 200, epoch: 15 | loss: 31.8830147
	speed: 0.0783s/iter; left time: 1709.0883s
Epoch: 15 cost time: 19.956235885620117
Epoch: 15, Steps: 256 Train Loss: 31.9868 (Forecasting Loss:0.3280 + XiCon Loss:3.1659 x Lambda(10.0)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.3020
Validation loss decreased (0.338297 --> 0.338226).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 32.0611000
	speed: 0.0823s/iter; left time: 1781.9702s
	iters: 200, epoch: 16 | loss: 32.0605011
	speed: 0.0802s/iter; left time: 1729.4416s
Epoch: 16 cost time: 20.704404592514038
Epoch: 16, Steps: 256 Train Loss: 31.9930 (Forecasting Loss:0.3280 + XiCon Loss:3.1665 x Lambda(10.0)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.3020
Validation loss decreased (0.338226 --> 0.338197).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 31.7927036
	speed: 0.0833s/iter; left time: 1783.3344s
	iters: 200, epoch: 17 | loss: 32.0848618
	speed: 0.0746s/iter; left time: 1588.5594s
Epoch: 17 cost time: 20.159070253372192
Epoch: 17, Steps: 256 Train Loss: 31.9973 (Forecasting Loss:0.3279 + XiCon Loss:3.1669 x Lambda(10.0)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.3020
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 31.9736099
	speed: 0.0862s/iter; left time: 1822.0278s
	iters: 200, epoch: 18 | loss: 31.9790287
	speed: 0.0789s/iter; left time: 1659.9607s
Epoch: 18 cost time: 21.611079692840576
Epoch: 18, Steps: 256 Train Loss: 31.9861 (Forecasting Loss:0.3279 + XiCon Loss:3.1658 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 31.9944401
	speed: 0.0812s/iter; left time: 1696.1595s
	iters: 200, epoch: 19 | loss: 31.8986111
	speed: 0.0744s/iter; left time: 1546.9026s
Epoch: 19 cost time: 19.816638946533203
Epoch: 19, Steps: 256 Train Loss: 32.0022 (Forecasting Loss:0.3281 + XiCon Loss:3.1674 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 31.6746635
	speed: 0.0892s/iter; left time: 1840.8167s
	iters: 200, epoch: 20 | loss: 32.1407509
	speed: 0.0754s/iter; left time: 1548.5214s
Epoch: 20 cost time: 20.685364246368408
Epoch: 20, Steps: 256 Train Loss: 31.9839 (Forecasting Loss:0.3280 + XiCon Loss:3.1656 x Lambda(10.0)), Vali MSE Loss: 0.3385 Test MSE Loss: 0.3020
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 31.6303234
	speed: 0.0807s/iter; left time: 1644.1393s
	iters: 200, epoch: 21 | loss: 31.8748989
	speed: 0.0770s/iter; left time: 1561.3145s
Epoch: 21 cost time: 20.03575348854065
Epoch: 21, Steps: 256 Train Loss: 31.9844 (Forecasting Loss:0.3279 + XiCon Loss:3.1656 x Lambda(10.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3020
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 31.8140049
	speed: 0.0812s/iter; left time: 1634.1368s
	iters: 200, epoch: 22 | loss: 31.9817410
	speed: 0.0763s/iter; left time: 1527.0856s
Epoch: 22 cost time: 20.61427617073059
Epoch: 22, Steps: 256 Train Loss: 31.9881 (Forecasting Loss:0.3280 + XiCon Loss:3.1660 x Lambda(10.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3020
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 32.3701477
	speed: 0.0802s/iter; left time: 1592.7593s
	iters: 200, epoch: 23 | loss: 31.8810425
	speed: 0.0768s/iter; left time: 1518.0453s
Epoch: 23 cost time: 19.900997638702393
Epoch: 23, Steps: 256 Train Loss: 31.9871 (Forecasting Loss:0.3281 + XiCon Loss:3.1659 x Lambda(10.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3020
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 31.6274757
	speed: 0.0793s/iter; left time: 1554.9515s
	iters: 200, epoch: 24 | loss: 31.8910046
	speed: 0.0733s/iter; left time: 1429.7234s
Epoch: 24 cost time: 19.73132634162903
Epoch: 24, Steps: 256 Train Loss: 31.9853 (Forecasting Loss:0.3279 + XiCon Loss:3.1657 x Lambda(10.0)), Vali MSE Loss: 0.3382 Test MSE Loss: 0.3020
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 32.2071724
	speed: 0.0847s/iter; left time: 1639.7427s
	iters: 200, epoch: 25 | loss: 32.1336670
	speed: 0.0763s/iter; left time: 1469.3887s
Epoch: 25 cost time: 20.333574056625366
Epoch: 25, Steps: 256 Train Loss: 31.9979 (Forecasting Loss:0.3280 + XiCon Loss:3.1670 x Lambda(10.0)), Vali MSE Loss: 0.3384 Test MSE Loss: 0.3020
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 31.8534870
	speed: 0.0798s/iter; left time: 1524.2021s
	iters: 200, epoch: 26 | loss: 32.0555420
	speed: 0.0762s/iter; left time: 1448.0922s
Epoch: 26 cost time: 19.79619002342224
Epoch: 26, Steps: 256 Train Loss: 31.9905 (Forecasting Loss:0.3280 + XiCon Loss:3.1663 x Lambda(10.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.3020
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl1440_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10081
test shape: (78, 128, 1440, 1) (78, 128, 1440, 1)
test shape: (9984, 1440, 1) (9984, 1440, 1)
mse:0.2247333526611328, mae:0.37918516993522644, mape:0.7130499482154846, mspe:17.87582778930664 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2272+-0.00604, MAE:0.3789+-0.00360, MAPE:0.7343+-0.04819, MSPE:18.9940+-2.31814, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2880, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.2292
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 33.9750710
	speed: 0.1201s/iter; left time: 2919.7021s
	iters: 200, epoch: 1 | loss: 34.0516281
	speed: 0.1129s/iter; left time: 2733.1767s
Epoch: 1 cost time: 28.730037212371826
Epoch: 1, Steps: 244 Train Loss: 34.1721 (Forecasting Loss:0.4577 + XiCon Loss:3.3714 x Lambda(10.0)), Vali MSE Loss: 0.4565 Test MSE Loss: 0.3581
Validation loss decreased (inf --> 0.456514).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.2472801
	speed: 0.1161s/iter; left time: 2793.4216s
	iters: 200, epoch: 2 | loss: 32.3867264
	speed: 0.1148s/iter; left time: 2750.2870s
Epoch: 2 cost time: 27.965041160583496
Epoch: 2, Steps: 244 Train Loss: 32.6862 (Forecasting Loss:0.3805 + XiCon Loss:3.2306 x Lambda(10.0)), Vali MSE Loss: 0.3797 Test MSE Loss: 0.2908
Validation loss decreased (0.456514 --> 0.379688).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 32.7176361
	speed: 0.1183s/iter; left time: 2816.4657s
	iters: 200, epoch: 3 | loss: 32.9035988
	speed: 0.1126s/iter; left time: 2670.9955s
Epoch: 3 cost time: 28.287035703659058
Epoch: 3, Steps: 244 Train Loss: 32.7462 (Forecasting Loss:0.3635 + XiCon Loss:3.2383 x Lambda(10.0)), Vali MSE Loss: 0.3814 Test MSE Loss: 0.2986
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.4873772
	speed: 0.1186s/iter; left time: 2796.4139s
	iters: 200, epoch: 4 | loss: 32.2285271
	speed: 0.1156s/iter; left time: 2712.3794s
Epoch: 4 cost time: 28.346428632736206
Epoch: 4, Steps: 244 Train Loss: 32.6068 (Forecasting Loss:0.3587 + XiCon Loss:3.2248 x Lambda(10.0)), Vali MSE Loss: 0.3780 Test MSE Loss: 0.2996
Validation loss decreased (0.379688 --> 0.378048).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.6490059
	speed: 0.1178s/iter; left time: 2748.5264s
	iters: 200, epoch: 5 | loss: 32.8570671
	speed: 0.1142s/iter; left time: 2651.9571s
Epoch: 5 cost time: 28.337793827056885
Epoch: 5, Steps: 244 Train Loss: 32.4887 (Forecasting Loss:0.3564 + XiCon Loss:3.2132 x Lambda(10.0)), Vali MSE Loss: 0.3769 Test MSE Loss: 0.3010
Validation loss decreased (0.378048 --> 0.376933).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.5456696
	speed: 0.1530s/iter; left time: 3531.0543s
	iters: 200, epoch: 6 | loss: 32.6798515
	speed: 0.1176s/iter; left time: 2701.4932s
Epoch: 6 cost time: 31.86925721168518
Epoch: 6, Steps: 244 Train Loss: 32.4283 (Forecasting Loss:0.3553 + XiCon Loss:3.2073 x Lambda(10.0)), Vali MSE Loss: 0.3814 Test MSE Loss: 0.3021
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.2542076
	speed: 0.1152s/iter; left time: 2630.3974s
	iters: 200, epoch: 7 | loss: 32.3439369
	speed: 0.1115s/iter; left time: 2535.3044s
Epoch: 7 cost time: 27.25990319252014
Epoch: 7, Steps: 244 Train Loss: 32.3838 (Forecasting Loss:0.3553 + XiCon Loss:3.2029 x Lambda(10.0)), Vali MSE Loss: 0.3778 Test MSE Loss: 0.3016
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.0079422
	speed: 0.1177s/iter; left time: 2659.7304s
	iters: 200, epoch: 8 | loss: 32.8607903
	speed: 0.1118s/iter; left time: 2515.0078s
Epoch: 8 cost time: 28.15570092201233
Epoch: 8, Steps: 244 Train Loss: 32.3890 (Forecasting Loss:0.3544 + XiCon Loss:3.2035 x Lambda(10.0)), Vali MSE Loss: 0.3798 Test MSE Loss: 0.3022
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 31.9906082
	speed: 0.1181s/iter; left time: 2639.4655s
	iters: 200, epoch: 9 | loss: 32.3895912
	speed: 0.1129s/iter; left time: 2511.6855s
Epoch: 9 cost time: 28.34832191467285
Epoch: 9, Steps: 244 Train Loss: 32.3677 (Forecasting Loss:0.3543 + XiCon Loss:3.2013 x Lambda(10.0)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.3020
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.9995041
	speed: 0.1207s/iter; left time: 2668.0552s
	iters: 200, epoch: 10 | loss: 32.0737228
	speed: 0.1150s/iter; left time: 2529.5317s
Epoch: 10 cost time: 28.85707712173462
Epoch: 10, Steps: 244 Train Loss: 32.3591 (Forecasting Loss:0.3542 + XiCon Loss:3.2005 x Lambda(10.0)), Vali MSE Loss: 0.3790 Test MSE Loss: 0.3020
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.7518845
	speed: 0.1224s/iter; left time: 2676.7405s
	iters: 200, epoch: 11 | loss: 32.1316414
	speed: 0.1164s/iter; left time: 2531.9582s
Epoch: 11 cost time: 29.112843990325928
Epoch: 11, Steps: 244 Train Loss: 32.3685 (Forecasting Loss:0.3542 + XiCon Loss:3.2014 x Lambda(10.0)), Vali MSE Loss: 0.3790 Test MSE Loss: 0.3020
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.3823433
	speed: 0.1216s/iter; left time: 2629.0282s
	iters: 200, epoch: 12 | loss: 32.1222649
	speed: 0.1189s/iter; left time: 2557.6243s
Epoch: 12 cost time: 28.87054944038391
Epoch: 12, Steps: 244 Train Loss: 32.3425 (Forecasting Loss:0.3546 + XiCon Loss:3.1988 x Lambda(10.0)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.3020
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 32.4970322
	speed: 0.1151s/iter; left time: 2459.9696s
	iters: 200, epoch: 13 | loss: 32.0511131
	speed: 0.1163s/iter; left time: 2474.9145s
Epoch: 13 cost time: 28.39862608909607
Epoch: 13, Steps: 244 Train Loss: 32.3794 (Forecasting Loss:0.3537 + XiCon Loss:3.2026 x Lambda(10.0)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.3020
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 32.1465492
	speed: 0.1247s/iter; left time: 2634.1534s
	iters: 200, epoch: 14 | loss: 33.0445938
	speed: 0.1106s/iter; left time: 2326.0722s
Epoch: 14 cost time: 28.80854368209839
Epoch: 14, Steps: 244 Train Loss: 32.3085 (Forecasting Loss:0.3542 + XiCon Loss:3.1954 x Lambda(10.0)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.3020
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 32.9332275
	speed: 0.1204s/iter; left time: 2513.8260s
	iters: 200, epoch: 15 | loss: 32.3712273
	speed: 0.1163s/iter; left time: 2418.2152s
Epoch: 15 cost time: 28.76218819618225
Epoch: 15, Steps: 244 Train Loss: 32.3399 (Forecasting Loss:0.3543 + XiCon Loss:3.1986 x Lambda(10.0)), Vali MSE Loss: 0.3790 Test MSE Loss: 0.3020
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22370845079421997, mae:0.3782588839530945, mape:0.6725695133209229, mspe:17.63617515563965 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.7683
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 33.8709679
	speed: 0.1079s/iter; left time: 2622.2155s
	iters: 200, epoch: 1 | loss: 34.0573273
	speed: 0.1004s/iter; left time: 2430.0452s
Epoch: 1 cost time: 25.488401651382446
Epoch: 1, Steps: 244 Train Loss: 34.1123 (Forecasting Loss:0.4646 + XiCon Loss:3.3648 x Lambda(10.0)), Vali MSE Loss: 0.4799 Test MSE Loss: 0.3858
Validation loss decreased (inf --> 0.479918).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.3093109
	speed: 0.1077s/iter; left time: 2591.9835s
	iters: 200, epoch: 2 | loss: 32.0328827
	speed: 0.1011s/iter; left time: 2421.7568s
Epoch: 2 cost time: 25.155088663101196
Epoch: 2, Steps: 244 Train Loss: 32.4267 (Forecasting Loss:0.3991 + XiCon Loss:3.2028 x Lambda(10.0)), Vali MSE Loss: 0.4191 Test MSE Loss: 0.3254
Validation loss decreased (0.479918 --> 0.419109).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 31.7808533
	speed: 0.1146s/iter; left time: 2728.1993s
	iters: 200, epoch: 3 | loss: 32.2705421
	speed: 0.1058s/iter; left time: 2510.0026s
Epoch: 3 cost time: 26.99219036102295
Epoch: 3, Steps: 244 Train Loss: 32.0507 (Forecasting Loss:0.3925 + XiCon Loss:3.1658 x Lambda(10.0)), Vali MSE Loss: 0.4215 Test MSE Loss: 0.3258
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.7373276
	speed: 0.1177s/iter; left time: 2775.1796s
	iters: 200, epoch: 4 | loss: 32.4720230
	speed: 0.1104s/iter; left time: 2591.5867s
Epoch: 4 cost time: 27.612711668014526
Epoch: 4, Steps: 244 Train Loss: 32.5113 (Forecasting Loss:0.3913 + XiCon Loss:3.2120 x Lambda(10.0)), Vali MSE Loss: 0.4278 Test MSE Loss: 0.3319
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.1352615
	speed: 0.1128s/iter; left time: 2632.0537s
	iters: 200, epoch: 5 | loss: 32.6797981
	speed: 0.1016s/iter; left time: 2360.4848s
Epoch: 5 cost time: 26.356693029403687
Epoch: 5, Steps: 244 Train Loss: 32.3978 (Forecasting Loss:0.3935 + XiCon Loss:3.2004 x Lambda(10.0)), Vali MSE Loss: 0.4303 Test MSE Loss: 0.3329
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 33.1772919
	speed: 0.1079s/iter; left time: 2490.2213s
	iters: 200, epoch: 6 | loss: 32.8056221
	speed: 0.0994s/iter; left time: 2283.8398s
Epoch: 6 cost time: 25.658418655395508
Epoch: 6, Steps: 244 Train Loss: 32.8480 (Forecasting Loss:0.3931 + XiCon Loss:3.2455 x Lambda(10.0)), Vali MSE Loss: 0.4235 Test MSE Loss: 0.3241
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.9353714
	speed: 0.1040s/iter; left time: 2374.5949s
	iters: 200, epoch: 7 | loss: 33.0389366
	speed: 0.1057s/iter; left time: 2404.3975s
Epoch: 7 cost time: 25.55539298057556
Epoch: 7, Steps: 244 Train Loss: 32.8485 (Forecasting Loss:0.3928 + XiCon Loss:3.2456 x Lambda(10.0)), Vali MSE Loss: 0.4226 Test MSE Loss: 0.3236
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.4839172
	speed: 0.1111s/iter; left time: 2510.7268s
	iters: 200, epoch: 8 | loss: 32.8437462
	speed: 0.1050s/iter; left time: 2362.8444s
Epoch: 8 cost time: 26.170637607574463
Epoch: 8, Steps: 244 Train Loss: 32.8558 (Forecasting Loss:0.3922 + XiCon Loss:3.2464 x Lambda(10.0)), Vali MSE Loss: 0.4204 Test MSE Loss: 0.3213
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.6728668
	speed: 0.1067s/iter; left time: 2384.9467s
	iters: 200, epoch: 9 | loss: 33.0508728
	speed: 0.1046s/iter; left time: 2326.2257s
Epoch: 9 cost time: 25.621304273605347
Epoch: 9, Steps: 244 Train Loss: 32.8566 (Forecasting Loss:0.3916 + XiCon Loss:3.2465 x Lambda(10.0)), Vali MSE Loss: 0.4213 Test MSE Loss: 0.3225
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.3372040
	speed: 0.1069s/iter; left time: 2364.1107s
	iters: 200, epoch: 10 | loss: 33.2560959
	speed: 0.1060s/iter; left time: 2332.4190s
Epoch: 10 cost time: 26.0719633102417
Epoch: 10, Steps: 244 Train Loss: 32.8766 (Forecasting Loss:0.3915 + XiCon Loss:3.2485 x Lambda(10.0)), Vali MSE Loss: 0.4208 Test MSE Loss: 0.3219
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 33.0493507
	speed: 0.1067s/iter; left time: 2332.3869s
	iters: 200, epoch: 11 | loss: 32.5868568
	speed: 0.1034s/iter; left time: 2249.4585s
Epoch: 11 cost time: 25.627812385559082
Epoch: 11, Steps: 244 Train Loss: 32.9159 (Forecasting Loss:0.3917 + XiCon Loss:3.2524 x Lambda(10.0)), Vali MSE Loss: 0.4207 Test MSE Loss: 0.3217
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.8626900
	speed: 0.1106s/iter; left time: 2390.4422s
	iters: 200, epoch: 12 | loss: 32.5103302
	speed: 0.1027s/iter; left time: 2209.3033s
Epoch: 12 cost time: 25.7297580242157
Epoch: 12, Steps: 244 Train Loss: 32.8634 (Forecasting Loss:0.3916 + XiCon Loss:3.2472 x Lambda(10.0)), Vali MSE Loss: 0.4203 Test MSE Loss: 0.3213
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.24985896050930023, mae:0.4009597897529602, mape:0.6679593324661255, mspe:14.824724197387695 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.3814
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 33.9840927
	speed: 0.1060s/iter; left time: 2576.9397s
	iters: 200, epoch: 1 | loss: 34.5659599
	speed: 0.1081s/iter; left time: 2617.0901s
Epoch: 1 cost time: 25.88365364074707
Epoch: 1, Steps: 244 Train Loss: 34.1199 (Forecasting Loss:0.4589 + XiCon Loss:3.3661 x Lambda(10.0)), Vali MSE Loss: 0.4505 Test MSE Loss: 0.3524
Validation loss decreased (inf --> 0.450523).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.0130959
	speed: 0.1046s/iter; left time: 2516.1747s
	iters: 200, epoch: 2 | loss: 31.2954502
	speed: 0.0997s/iter; left time: 2389.6575s
Epoch: 2 cost time: 25.015132904052734
Epoch: 2, Steps: 244 Train Loss: 32.2826 (Forecasting Loss:0.3914 + XiCon Loss:3.1891 x Lambda(10.0)), Vali MSE Loss: 0.4062 Test MSE Loss: 0.3070
Validation loss decreased (0.450523 --> 0.406193).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 33.0050812
	speed: 0.1069s/iter; left time: 2546.6179s
	iters: 200, epoch: 3 | loss: 32.2166023
	speed: 0.1230s/iter; left time: 2917.2054s
Epoch: 3 cost time: 28.65296745300293
Epoch: 3, Steps: 244 Train Loss: 32.4781 (Forecasting Loss:0.3783 + XiCon Loss:3.2100 x Lambda(10.0)), Vali MSE Loss: 0.4181 Test MSE Loss: 0.3267
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.6527100
	speed: 0.0987s/iter; left time: 2325.1238s
	iters: 200, epoch: 4 | loss: 32.2455902
	speed: 0.1029s/iter; left time: 2414.7589s
Epoch: 4 cost time: 24.55171823501587
Epoch: 4, Steps: 244 Train Loss: 32.2203 (Forecasting Loss:0.3783 + XiCon Loss:3.1842 x Lambda(10.0)), Vali MSE Loss: 0.4111 Test MSE Loss: 0.3232
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.9704628
	speed: 0.1072s/iter; left time: 2499.7669s
	iters: 200, epoch: 5 | loss: 32.3621674
	speed: 0.0985s/iter; left time: 2286.5643s
Epoch: 5 cost time: 24.93576169013977
Epoch: 5, Steps: 244 Train Loss: 32.0663 (Forecasting Loss:0.3746 + XiCon Loss:3.1692 x Lambda(10.0)), Vali MSE Loss: 0.4172 Test MSE Loss: 0.3297
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.0859032
	speed: 0.1098s/iter; left time: 2533.5899s
	iters: 200, epoch: 6 | loss: 32.0622139
	speed: 0.0999s/iter; left time: 2296.6280s
Epoch: 6 cost time: 25.235360860824585
Epoch: 6, Steps: 244 Train Loss: 31.9890 (Forecasting Loss:0.3737 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.4112 Test MSE Loss: 0.3245
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 31.9002762
	speed: 0.1068s/iter; left time: 2438.4737s
	iters: 200, epoch: 7 | loss: 31.7358322
	speed: 0.1016s/iter; left time: 2310.4223s
Epoch: 7 cost time: 25.463364601135254
Epoch: 7, Steps: 244 Train Loss: 31.9888 (Forecasting Loss:0.3738 + XiCon Loss:3.1615 x Lambda(10.0)), Vali MSE Loss: 0.4142 Test MSE Loss: 0.3288
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 31.2722721
	speed: 0.1072s/iter; left time: 2421.6544s
	iters: 200, epoch: 8 | loss: 32.2478256
	speed: 0.1023s/iter; left time: 2301.1300s
Epoch: 8 cost time: 25.815015077590942
Epoch: 8, Steps: 244 Train Loss: 31.9579 (Forecasting Loss:0.3741 + XiCon Loss:3.1584 x Lambda(10.0)), Vali MSE Loss: 0.4071 Test MSE Loss: 0.3224
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 31.6318398
	speed: 0.1101s/iter; left time: 2460.6573s
	iters: 200, epoch: 9 | loss: 31.7993488
	speed: 0.1050s/iter; left time: 2335.2471s
Epoch: 9 cost time: 26.404162645339966
Epoch: 9, Steps: 244 Train Loss: 31.9236 (Forecasting Loss:0.3739 + XiCon Loss:3.1550 x Lambda(10.0)), Vali MSE Loss: 0.4091 Test MSE Loss: 0.3242
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.7388153
	speed: 0.1088s/iter; left time: 2406.1159s
	iters: 200, epoch: 10 | loss: 31.8297806
	speed: 0.1034s/iter; left time: 2274.6987s
Epoch: 10 cost time: 25.67919921875
Epoch: 10, Steps: 244 Train Loss: 31.9000 (Forecasting Loss:0.3741 + XiCon Loss:3.1526 x Lambda(10.0)), Vali MSE Loss: 0.4077 Test MSE Loss: 0.3236
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 31.7026596
	speed: 0.1062s/iter; left time: 2322.6513s
	iters: 200, epoch: 11 | loss: 31.7633457
	speed: 0.1037s/iter; left time: 2256.0494s
Epoch: 11 cost time: 25.429112195968628
Epoch: 11, Steps: 244 Train Loss: 31.9271 (Forecasting Loss:0.3742 + XiCon Loss:3.1553 x Lambda(10.0)), Vali MSE Loss: 0.4082 Test MSE Loss: 0.3241
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 31.7759304
	speed: 0.1091s/iter; left time: 2358.7031s
	iters: 200, epoch: 12 | loss: 31.5077801
	speed: 0.1000s/iter; left time: 2151.7787s
Epoch: 12 cost time: 25.108882188796997
Epoch: 12, Steps: 244 Train Loss: 31.9235 (Forecasting Loss:0.3739 + XiCon Loss:3.1550 x Lambda(10.0)), Vali MSE Loss: 0.4084 Test MSE Loss: 0.3242
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22881905734539032, mae:0.3851107060909271, mape:0.6723093390464783, mspe:17.093616485595703 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.3493
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 34.4209175
	speed: 0.1006s/iter; left time: 2445.1308s
	iters: 200, epoch: 1 | loss: 34.2499924
	speed: 0.1059s/iter; left time: 2564.0235s
Epoch: 1 cost time: 25.545717477798462
Epoch: 1, Steps: 244 Train Loss: 34.2052 (Forecasting Loss:0.4623 + XiCon Loss:3.3743 x Lambda(10.0)), Vali MSE Loss: 0.4625 Test MSE Loss: 0.3670
Validation loss decreased (inf --> 0.462503).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.0955963
	speed: 0.1078s/iter; left time: 2592.2493s
	iters: 200, epoch: 2 | loss: 33.0057487
	speed: 0.1018s/iter; left time: 2439.6993s
Epoch: 2 cost time: 25.33937978744507
Epoch: 2, Steps: 244 Train Loss: 32.6334 (Forecasting Loss:0.3996 + XiCon Loss:3.2234 x Lambda(10.0)), Vali MSE Loss: 0.4447 Test MSE Loss: 0.3566
Validation loss decreased (0.462503 --> 0.444740).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 33.0665779
	speed: 0.1022s/iter; left time: 2432.6879s
	iters: 200, epoch: 3 | loss: 33.8548851
	speed: 0.1002s/iter; left time: 2377.0844s
Epoch: 3 cost time: 24.69046139717102
Epoch: 3, Steps: 244 Train Loss: 33.3155 (Forecasting Loss:0.3711 + XiCon Loss:3.2944 x Lambda(10.0)), Vali MSE Loss: 0.3839 Test MSE Loss: 0.3516
Validation loss decreased (0.444740 --> 0.383868).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.8073502
	speed: 0.0983s/iter; left time: 2316.0104s
	iters: 200, epoch: 4 | loss: 32.8968315
	speed: 0.1009s/iter; left time: 2368.8720s
Epoch: 4 cost time: 24.39457678794861
Epoch: 4, Steps: 244 Train Loss: 33.0581 (Forecasting Loss:0.3614 + XiCon Loss:3.2697 x Lambda(10.0)), Vali MSE Loss: 0.3713 Test MSE Loss: 0.3452
Validation loss decreased (0.383868 --> 0.371301).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.7655487
	speed: 0.1101s/iter; left time: 2567.3300s
	iters: 200, epoch: 5 | loss: 32.3546562
	speed: 0.1003s/iter; left time: 2329.0286s
Epoch: 5 cost time: 25.330766439437866
Epoch: 5, Steps: 244 Train Loss: 32.9111 (Forecasting Loss:0.3586 + XiCon Loss:3.2552 x Lambda(10.0)), Vali MSE Loss: 0.3645 Test MSE Loss: 0.3555
Validation loss decreased (0.371301 --> 0.364469).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.8239975
	speed: 0.1025s/iter; left time: 2366.3875s
	iters: 200, epoch: 6 | loss: 32.9264259
	speed: 0.1026s/iter; left time: 2358.2167s
Epoch: 6 cost time: 25.15579581260681
Epoch: 6, Steps: 244 Train Loss: 32.8616 (Forecasting Loss:0.3575 + XiCon Loss:3.2504 x Lambda(10.0)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.3473
Validation loss decreased (0.364469 --> 0.360442).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 33.4152145
	speed: 0.1061s/iter; left time: 2422.1788s
	iters: 200, epoch: 7 | loss: 32.9958916
	speed: 0.0991s/iter; left time: 2252.1025s
Epoch: 7 cost time: 24.883501768112183
Epoch: 7, Steps: 244 Train Loss: 32.8422 (Forecasting Loss:0.3572 + XiCon Loss:3.2485 x Lambda(10.0)), Vali MSE Loss: 0.3671 Test MSE Loss: 0.3513
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 33.1045265
	speed: 0.1081s/iter; left time: 2442.4948s
	iters: 200, epoch: 8 | loss: 32.2376175
	speed: 0.0940s/iter; left time: 2115.1668s
Epoch: 8 cost time: 24.333104610443115
Epoch: 8, Steps: 244 Train Loss: 32.8085 (Forecasting Loss:0.3559 + XiCon Loss:3.2453 x Lambda(10.0)), Vali MSE Loss: 0.3699 Test MSE Loss: 0.3515
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 33.3028145
	speed: 0.0999s/iter; left time: 2232.5179s
	iters: 200, epoch: 9 | loss: 32.6308594
	speed: 0.0920s/iter; left time: 2046.0685s
Epoch: 9 cost time: 23.122775077819824
Epoch: 9, Steps: 244 Train Loss: 32.8198 (Forecasting Loss:0.3551 + XiCon Loss:3.2465 x Lambda(10.0)), Vali MSE Loss: 0.3714 Test MSE Loss: 0.3508
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.3910789
	speed: 0.1030s/iter; left time: 2275.9369s
	iters: 200, epoch: 10 | loss: 32.4168320
	speed: 0.0907s/iter; left time: 1995.4001s
Epoch: 10 cost time: 23.555212259292603
Epoch: 10, Steps: 244 Train Loss: 32.7701 (Forecasting Loss:0.3558 + XiCon Loss:3.2414 x Lambda(10.0)), Vali MSE Loss: 0.3707 Test MSE Loss: 0.3501
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 33.0370712
	speed: 0.0976s/iter; left time: 2133.2666s
	iters: 200, epoch: 11 | loss: 32.7873840
	speed: 0.0924s/iter; left time: 2010.0685s
Epoch: 11 cost time: 23.51468324661255
Epoch: 11, Steps: 244 Train Loss: 32.7821 (Forecasting Loss:0.3563 + XiCon Loss:3.2426 x Lambda(10.0)), Vali MSE Loss: 0.3707 Test MSE Loss: 0.3507
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.0418167
	speed: 0.0945s/iter; left time: 2042.9818s
	iters: 200, epoch: 12 | loss: 32.1389885
	speed: 0.0961s/iter; left time: 2067.9710s
Epoch: 12 cost time: 23.166917324066162
Epoch: 12, Steps: 244 Train Loss: 32.7821 (Forecasting Loss:0.3563 + XiCon Loss:3.2426 x Lambda(10.0)), Vali MSE Loss: 0.3711 Test MSE Loss: 0.3508
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 32.7256279
	speed: 0.1022s/iter; left time: 2184.5726s
	iters: 200, epoch: 13 | loss: 33.3566666
	speed: 0.0968s/iter; left time: 2058.4830s
Epoch: 13 cost time: 24.085705995559692
Epoch: 13, Steps: 244 Train Loss: 32.7913 (Forecasting Loss:0.3566 + XiCon Loss:3.2435 x Lambda(10.0)), Vali MSE Loss: 0.3711 Test MSE Loss: 0.3509
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 33.8237381
	speed: 0.1030s/iter; left time: 2177.1214s
	iters: 200, epoch: 14 | loss: 32.9178352
	speed: 0.0929s/iter; left time: 1954.3489s
Epoch: 14 cost time: 23.877042055130005
Epoch: 14, Steps: 244 Train Loss: 32.8229 (Forecasting Loss:0.3558 + XiCon Loss:3.2467 x Lambda(10.0)), Vali MSE Loss: 0.3711 Test MSE Loss: 0.3509
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 33.5398865
	speed: 0.1022s/iter; left time: 2135.0462s
	iters: 200, epoch: 15 | loss: 32.6785278
	speed: 0.0935s/iter; left time: 1944.1723s
Epoch: 15 cost time: 23.5632381439209
Epoch: 15, Steps: 244 Train Loss: 32.7905 (Forecasting Loss:0.3557 + XiCon Loss:3.2435 x Lambda(10.0)), Vali MSE Loss: 0.3710 Test MSE Loss: 0.3508
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 32.6868782
	speed: 0.1026s/iter; left time: 2117.6216s
	iters: 200, epoch: 16 | loss: 32.6240768
	speed: 0.0978s/iter; left time: 2009.6957s
Epoch: 16 cost time: 24.034022092819214
Epoch: 16, Steps: 244 Train Loss: 32.7992 (Forecasting Loss:0.3562 + XiCon Loss:3.2443 x Lambda(10.0)), Vali MSE Loss: 0.3709 Test MSE Loss: 0.3508
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.2735369801521301, mae:0.4210779070854187, mape:0.6797369122505188, mspe:14.657414436340332 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1949633
train 31345
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 24.7401
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31345
val 8641
test 8641
	iters: 100, epoch: 1 | loss: 34.4619904
	speed: 0.1008s/iter; left time: 2448.4852s
	iters: 200, epoch: 1 | loss: 33.9943619
	speed: 0.0928s/iter; left time: 2245.1806s
Epoch: 1 cost time: 23.32482385635376
Epoch: 1, Steps: 244 Train Loss: 34.2536 (Forecasting Loss:0.4649 + XiCon Loss:3.3789 x Lambda(10.0)), Vali MSE Loss: 0.4782 Test MSE Loss: 0.3847
Validation loss decreased (inf --> 0.478209).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.1815414
	speed: 0.1276s/iter; left time: 3069.8452s
	iters: 200, epoch: 2 | loss: 31.9474716
	speed: 0.1062s/iter; left time: 2543.4842s
Epoch: 2 cost time: 27.153069019317627
Epoch: 2, Steps: 244 Train Loss: 32.2792 (Forecasting Loss:0.3798 + XiCon Loss:3.1899 x Lambda(10.0)), Vali MSE Loss: 0.3799 Test MSE Loss: 0.3185
Validation loss decreased (0.478209 --> 0.379884).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 31.6208420
	speed: 0.0995s/iter; left time: 2369.9311s
	iters: 200, epoch: 3 | loss: 32.0027351
	speed: 0.0963s/iter; left time: 2283.3711s
Epoch: 3 cost time: 23.985337734222412
Epoch: 3, Steps: 244 Train Loss: 31.7530 (Forecasting Loss:0.3709 + XiCon Loss:3.1382 x Lambda(10.0)), Vali MSE Loss: 0.3656 Test MSE Loss: 0.3056
Validation loss decreased (0.379884 --> 0.365578).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.3862457
	speed: 0.1007s/iter; left time: 2372.5498s
	iters: 200, epoch: 4 | loss: 32.2888260
	speed: 0.0987s/iter; left time: 2315.4479s
Epoch: 4 cost time: 24.236014366149902
Epoch: 4, Steps: 244 Train Loss: 32.2280 (Forecasting Loss:0.3789 + XiCon Loss:3.1849 x Lambda(10.0)), Vali MSE Loss: 0.3998 Test MSE Loss: 0.3177
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.4114113
	speed: 0.1009s/iter; left time: 2354.4102s
	iters: 200, epoch: 5 | loss: 32.4123993
	speed: 0.0951s/iter; left time: 2208.0756s
Epoch: 5 cost time: 23.756868839263916
Epoch: 5, Steps: 244 Train Loss: 32.5600 (Forecasting Loss:0.3754 + XiCon Loss:3.2185 x Lambda(10.0)), Vali MSE Loss: 0.4101 Test MSE Loss: 0.3162
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.7159424
	speed: 0.1042s/iter; left time: 2404.0691s
	iters: 200, epoch: 6 | loss: 32.3577003
	speed: 0.0965s/iter; left time: 2217.9227s
Epoch: 6 cost time: 24.25636625289917
Epoch: 6, Steps: 244 Train Loss: 32.6609 (Forecasting Loss:0.3742 + XiCon Loss:3.2287 x Lambda(10.0)), Vali MSE Loss: 0.4091 Test MSE Loss: 0.3147
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.5938644
	speed: 0.0989s/iter; left time: 2258.1376s
	iters: 200, epoch: 7 | loss: 33.1190033
	speed: 0.0932s/iter; left time: 2118.4428s
Epoch: 7 cost time: 23.56131911277771
Epoch: 7, Steps: 244 Train Loss: 32.7139 (Forecasting Loss:0.3742 + XiCon Loss:3.2340 x Lambda(10.0)), Vali MSE Loss: 0.4065 Test MSE Loss: 0.3105
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 33.1522064
	speed: 0.0969s/iter; left time: 2189.6811s
	iters: 200, epoch: 8 | loss: 32.7700691
	speed: 0.0945s/iter; left time: 2125.4796s
Epoch: 8 cost time: 23.352564573287964
Epoch: 8, Steps: 244 Train Loss: 32.7458 (Forecasting Loss:0.3731 + XiCon Loss:3.2373 x Lambda(10.0)), Vali MSE Loss: 0.4049 Test MSE Loss: 0.3100
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.8379860
	speed: 0.1010s/iter; left time: 2258.3456s
	iters: 200, epoch: 9 | loss: 32.7448540
	speed: 0.0963s/iter; left time: 2141.5961s
Epoch: 9 cost time: 24.16168189048767
Epoch: 9, Steps: 244 Train Loss: 32.7307 (Forecasting Loss:0.3734 + XiCon Loss:3.2357 x Lambda(10.0)), Vali MSE Loss: 0.4063 Test MSE Loss: 0.3104
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 33.1303329
	speed: 0.0976s/iter; left time: 2157.1652s
	iters: 200, epoch: 10 | loss: 33.4173126
	speed: 0.0989s/iter; left time: 2177.0124s
Epoch: 10 cost time: 23.666284799575806
Epoch: 10, Steps: 244 Train Loss: 32.7728 (Forecasting Loss:0.3733 + XiCon Loss:3.2400 x Lambda(10.0)), Vali MSE Loss: 0.4063 Test MSE Loss: 0.3098
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.8822975
	speed: 0.0997s/iter; left time: 2178.7011s
	iters: 200, epoch: 11 | loss: 32.6459618
	speed: 0.0950s/iter; left time: 2066.5771s
Epoch: 11 cost time: 23.719193935394287
Epoch: 11, Steps: 244 Train Loss: 32.7135 (Forecasting Loss:0.3731 + XiCon Loss:3.2340 x Lambda(10.0)), Vali MSE Loss: 0.4068 Test MSE Loss: 0.3102
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.7439346
	speed: 0.1031s/iter; left time: 2229.7202s
	iters: 200, epoch: 12 | loss: 32.3710709
	speed: 0.0939s/iter; left time: 2020.7501s
Epoch: 12 cost time: 24.109071493148804
Epoch: 12, Steps: 244 Train Loss: 32.7410 (Forecasting Loss:0.3728 + XiCon Loss:3.2368 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.3102
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 33.3586273
	speed: 0.1009s/iter; left time: 2155.6221s
	iters: 200, epoch: 13 | loss: 32.9047813
	speed: 0.0960s/iter; left time: 2042.0342s
Epoch: 13 cost time: 23.557469367980957
Epoch: 13, Steps: 244 Train Loss: 32.7841 (Forecasting Loss:0.3730 + XiCon Loss:3.2411 x Lambda(10.0)), Vali MSE Loss: 0.4066 Test MSE Loss: 0.3103
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl2880_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8641
test shape: (67, 128, 2880, 1) (67, 128, 2880, 1)
test shape: (8576, 2880, 1) (8576, 2880, 1)
mse:0.22848793864250183, mae:0.38275590538978577, mape:0.7285948395729065, mspe:20.51660919189453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2409+-0.02590, MAE:0.3936+-0.02181, MAPE:0.6842+-0.03123, MSPE:16.9457+-2.97642, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=4320, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.3693
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.2435989
	speed: 0.1913s/iter; left time: 4438.7200s
	iters: 200, epoch: 1 | loss: 34.3674278
	speed: 0.1817s/iter; left time: 4197.8720s
Epoch: 1 cost time: 43.53259778022766
Epoch: 1, Steps: 233 Train Loss: 34.3596 (Forecasting Loss:0.5487 + XiCon Loss:3.3811 x Lambda(10.0)), Vali MSE Loss: 0.5273 Test MSE Loss: 0.4308
Validation loss decreased (inf --> 0.527322).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.1917915
	speed: 0.1852s/iter; left time: 4254.7883s
	iters: 200, epoch: 2 | loss: 32.9366951
	speed: 0.1851s/iter; left time: 4233.5534s
Epoch: 2 cost time: 42.97218728065491
Epoch: 2, Steps: 233 Train Loss: 32.8812 (Forecasting Loss:0.4433 + XiCon Loss:3.2438 x Lambda(10.0)), Vali MSE Loss: 0.3884 Test MSE Loss: 0.2882
Validation loss decreased (0.527322 --> 0.388388).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 33.0014458
	speed: 0.1882s/iter; left time: 4279.2523s
	iters: 200, epoch: 3 | loss: 32.4985275
	speed: 0.1858s/iter; left time: 4206.6022s
Epoch: 3 cost time: 43.63318347930908
Epoch: 3, Steps: 233 Train Loss: 32.6058 (Forecasting Loss:0.4109 + XiCon Loss:3.2195 x Lambda(10.0)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2847
Validation loss decreased (0.388388 --> 0.376777).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.1494484
	speed: 0.1913s/iter; left time: 4305.2402s
	iters: 200, epoch: 4 | loss: 32.3582039
	speed: 0.1863s/iter; left time: 4173.1300s
Epoch: 4 cost time: 44.15931510925293
Epoch: 4, Steps: 233 Train Loss: 32.3829 (Forecasting Loss:0.3989 + XiCon Loss:3.1984 x Lambda(10.0)), Vali MSE Loss: 0.3615 Test MSE Loss: 0.2838
Validation loss decreased (0.376777 --> 0.361483).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.8226700
	speed: 0.1872s/iter; left time: 4169.6491s
	iters: 200, epoch: 5 | loss: 32.6426468
	speed: 0.1878s/iter; left time: 4162.8692s
Epoch: 5 cost time: 43.842324018478394
Epoch: 5, Steps: 233 Train Loss: 32.2354 (Forecasting Loss:0.3940 + XiCon Loss:3.1841 x Lambda(10.0)), Vali MSE Loss: 0.3607 Test MSE Loss: 0.2858
Validation loss decreased (0.361483 --> 0.360690).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.2454414
	speed: 0.1867s/iter; left time: 4114.7933s
	iters: 200, epoch: 6 | loss: 32.2072029
	speed: 0.1927s/iter; left time: 4228.1207s
Epoch: 6 cost time: 44.45065188407898
Epoch: 6, Steps: 233 Train Loss: 32.1607 (Forecasting Loss:0.3916 + XiCon Loss:3.1769 x Lambda(10.0)), Vali MSE Loss: 0.3656 Test MSE Loss: 0.2859
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.2122116
	speed: 0.1896s/iter; left time: 4132.7589s
	iters: 200, epoch: 7 | loss: 31.5832005
	speed: 0.1895s/iter; left time: 4112.9582s
Epoch: 7 cost time: 43.8183159828186
Epoch: 7, Steps: 233 Train Loss: 32.1623 (Forecasting Loss:0.3903 + XiCon Loss:3.1772 x Lambda(10.0)), Vali MSE Loss: 0.3634 Test MSE Loss: 0.2851
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.1838264
	speed: 0.1820s/iter; left time: 3925.3484s
	iters: 200, epoch: 8 | loss: 31.9520988
	speed: 0.1878s/iter; left time: 4032.3330s
Epoch: 8 cost time: 43.27953290939331
Epoch: 8, Steps: 233 Train Loss: 32.1552 (Forecasting Loss:0.3902 + XiCon Loss:3.1765 x Lambda(10.0)), Vali MSE Loss: 0.3614 Test MSE Loss: 0.2855
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.5511093
	speed: 0.1860s/iter; left time: 3969.6342s
	iters: 200, epoch: 9 | loss: 32.2478676
	speed: 0.1835s/iter; left time: 3897.0794s
Epoch: 9 cost time: 43.395946741104126
Epoch: 9, Steps: 233 Train Loss: 32.1078 (Forecasting Loss:0.3898 + XiCon Loss:3.1718 x Lambda(10.0)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.2852
Validation loss decreased (0.360690 --> 0.360411).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.4987793
	speed: 0.1833s/iter; left time: 3867.7578s
	iters: 200, epoch: 10 | loss: 32.2207184
	speed: 0.1873s/iter; left time: 3933.6538s
Epoch: 10 cost time: 43.47792100906372
Epoch: 10, Steps: 233 Train Loss: 32.1191 (Forecasting Loss:0.3893 + XiCon Loss:3.1730 x Lambda(10.0)), Vali MSE Loss: 0.3602 Test MSE Loss: 0.2850
Validation loss decreased (0.360411 --> 0.360207).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 32.2796516
	speed: 0.1872s/iter; left time: 3906.2555s
	iters: 200, epoch: 11 | loss: 32.4095306
	speed: 0.1841s/iter; left time: 3823.5221s
Epoch: 11 cost time: 43.261558532714844
Epoch: 11, Steps: 233 Train Loss: 32.1100 (Forecasting Loss:0.3894 + XiCon Loss:3.1721 x Lambda(10.0)), Vali MSE Loss: 0.3603 Test MSE Loss: 0.2851
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.4800034
	speed: 0.1901s/iter; left time: 3923.4652s
	iters: 200, epoch: 12 | loss: 32.0457344
	speed: 0.1856s/iter; left time: 3812.2449s
Epoch: 12 cost time: 43.81604290008545
Epoch: 12, Steps: 233 Train Loss: 32.1018 (Forecasting Loss:0.3896 + XiCon Loss:3.1712 x Lambda(10.0)), Vali MSE Loss: 0.3601 Test MSE Loss: 0.2851
Validation loss decreased (0.360207 --> 0.360079).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.9830341
	speed: 0.1871s/iter; left time: 3817.4465s
	iters: 200, epoch: 13 | loss: 32.5159264
	speed: 0.1870s/iter; left time: 3797.3337s
Epoch: 13 cost time: 43.43291425704956
Epoch: 13, Steps: 233 Train Loss: 32.0965 (Forecasting Loss:0.3894 + XiCon Loss:3.1707 x Lambda(10.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.2851
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 32.3363724
	speed: 0.1890s/iter; left time: 3812.3785s
	iters: 200, epoch: 14 | loss: 32.2590332
	speed: 0.1822s/iter; left time: 3657.4049s
Epoch: 14 cost time: 43.09781503677368
Epoch: 14, Steps: 233 Train Loss: 32.1075 (Forecasting Loss:0.3894 + XiCon Loss:3.1718 x Lambda(10.0)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.2852
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 31.8785496
	speed: 0.1894s/iter; left time: 3775.9802s
	iters: 200, epoch: 15 | loss: 31.7735176
	speed: 0.1884s/iter; left time: 3737.7102s
Epoch: 15 cost time: 43.894232988357544
Epoch: 15, Steps: 233 Train Loss: 32.0973 (Forecasting Loss:0.3891 + XiCon Loss:3.1708 x Lambda(10.0)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.2851
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 31.9242420
	speed: 0.1877s/iter; left time: 3699.2359s
	iters: 200, epoch: 16 | loss: 32.3102913
	speed: 0.1880s/iter; left time: 3686.6190s
Epoch: 16 cost time: 43.96678924560547
Epoch: 16, Steps: 233 Train Loss: 32.1235 (Forecasting Loss:0.3892 + XiCon Loss:3.1734 x Lambda(10.0)), Vali MSE Loss: 0.3604 Test MSE Loss: 0.2851
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 32.1266899
	speed: 0.1898s/iter; left time: 3696.2706s
	iters: 200, epoch: 17 | loss: 31.9422092
	speed: 0.1860s/iter; left time: 3602.8762s
Epoch: 17 cost time: 44.148110151290894
Epoch: 17, Steps: 233 Train Loss: 32.1139 (Forecasting Loss:0.3893 + XiCon Loss:3.1725 x Lambda(10.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.2851
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 31.9856262
	speed: 0.1881s/iter; left time: 3618.6358s
	iters: 200, epoch: 18 | loss: 31.8650513
	speed: 0.1887s/iter; left time: 3611.9687s
Epoch: 18 cost time: 43.978039264678955
Epoch: 18, Steps: 233 Train Loss: 32.0970 (Forecasting Loss:0.3894 + XiCon Loss:3.1708 x Lambda(10.0)), Vali MSE Loss: 0.3606 Test MSE Loss: 0.2851
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 32.2268906
	speed: 0.1833s/iter; left time: 3483.5439s
	iters: 200, epoch: 19 | loss: 32.2466469
	speed: 0.1868s/iter; left time: 3532.7578s
Epoch: 19 cost time: 43.31734538078308
Epoch: 19, Steps: 233 Train Loss: 32.1075 (Forecasting Loss:0.3893 + XiCon Loss:3.1718 x Lambda(10.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.2851
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 31.8072243
	speed: 0.1865s/iter; left time: 3502.2486s
	iters: 200, epoch: 20 | loss: 32.3048210
	speed: 0.1872s/iter; left time: 3495.1062s
Epoch: 20 cost time: 43.637932538986206
Epoch: 20, Steps: 233 Train Loss: 32.0959 (Forecasting Loss:0.3893 + XiCon Loss:3.1707 x Lambda(10.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.2851
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 32.1737099
	speed: 0.2118s/iter; left time: 3926.1535s
	iters: 200, epoch: 21 | loss: 32.5442352
	speed: 0.1747s/iter; left time: 3221.6222s
Epoch: 21 cost time: 44.74537801742554
Epoch: 21, Steps: 233 Train Loss: 32.0776 (Forecasting Loss:0.3894 + XiCon Loss:3.1688 x Lambda(10.0)), Vali MSE Loss: 0.3605 Test MSE Loss: 0.2851
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 31.8283958
	speed: 0.1853s/iter; left time: 3393.1002s
	iters: 200, epoch: 22 | loss: 32.3139915
	speed: 0.1870s/iter; left time: 3404.8070s
Epoch: 22 cost time: 43.43152117729187
Epoch: 22, Steps: 233 Train Loss: 32.0914 (Forecasting Loss:0.3896 + XiCon Loss:3.1702 x Lambda(10.0)), Vali MSE Loss: 0.3606 Test MSE Loss: 0.2851
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.20527996122837067, mae:0.3649439811706543, mape:0.6424726247787476, mspe:17.167444229125977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.1730
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.0806808
	speed: 0.1803s/iter; left time: 4184.0284s
	iters: 200, epoch: 1 | loss: 34.2328415
	speed: 0.1725s/iter; left time: 3984.5079s
Epoch: 1 cost time: 41.08955264091492
Epoch: 1, Steps: 233 Train Loss: 34.2563 (Forecasting Loss:0.5501 + XiCon Loss:3.3706 x Lambda(10.0)), Vali MSE Loss: 0.5042 Test MSE Loss: 0.4098
Validation loss decreased (inf --> 0.504216).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.5068436
	speed: 0.1818s/iter; left time: 4175.1598s
	iters: 200, epoch: 2 | loss: 32.0682755
	speed: 0.1821s/iter; left time: 4164.3258s
Epoch: 2 cost time: 42.44867181777954
Epoch: 2, Steps: 233 Train Loss: 32.4484 (Forecasting Loss:0.4872 + XiCon Loss:3.1961 x Lambda(10.0)), Vali MSE Loss: 0.4696 Test MSE Loss: 0.3747
Validation loss decreased (0.504216 --> 0.469572).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 31.8942070
	speed: 0.1840s/iter; left time: 4184.2743s
	iters: 200, epoch: 3 | loss: 31.7477570
	speed: 0.1825s/iter; left time: 4130.3588s
Epoch: 3 cost time: 42.56823778152466
Epoch: 3, Steps: 233 Train Loss: 31.8431 (Forecasting Loss:0.4716 + XiCon Loss:3.1372 x Lambda(10.0)), Vali MSE Loss: 0.4962 Test MSE Loss: 0.3751
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 31.4682465
	speed: 0.1819s/iter; left time: 4093.4805s
	iters: 200, epoch: 4 | loss: 31.7949848
	speed: 0.1792s/iter; left time: 4014.2898s
Epoch: 4 cost time: 42.385870695114136
Epoch: 4, Steps: 233 Train Loss: 31.6471 (Forecasting Loss:0.4522 + XiCon Loss:3.1195 x Lambda(10.0)), Vali MSE Loss: 0.4954 Test MSE Loss: 0.4042
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.1490746
	speed: 0.1851s/iter; left time: 4121.5164s
	iters: 200, epoch: 5 | loss: 32.5705795
	speed: 0.1870s/iter; left time: 4145.5837s
Epoch: 5 cost time: 43.14046263694763
Epoch: 5, Steps: 233 Train Loss: 32.4834 (Forecasting Loss:0.4550 + XiCon Loss:3.2028 x Lambda(10.0)), Vali MSE Loss: 0.5065 Test MSE Loss: 0.3993
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 33.0047493
	speed: 0.1806s/iter; left time: 3979.6789s
	iters: 200, epoch: 6 | loss: 33.0451050
	speed: 0.1832s/iter; left time: 4018.2506s
Epoch: 6 cost time: 42.61190629005432
Epoch: 6, Steps: 233 Train Loss: 32.9480 (Forecasting Loss:0.4427 + XiCon Loss:3.2505 x Lambda(10.0)), Vali MSE Loss: 0.4937 Test MSE Loss: 0.3877
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.6249771
	speed: 0.1772s/iter; left time: 3863.4220s
	iters: 200, epoch: 7 | loss: 34.0008202
	speed: 0.1845s/iter; left time: 4005.0487s
Epoch: 7 cost time: 42.17844104766846
Epoch: 7, Steps: 233 Train Loss: 33.0754 (Forecasting Loss:0.4405 + XiCon Loss:3.2635 x Lambda(10.0)), Vali MSE Loss: 0.4921 Test MSE Loss: 0.3858
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 33.2083664
	speed: 0.1810s/iter; left time: 3904.8969s
	iters: 200, epoch: 8 | loss: 33.7835617
	speed: 0.1806s/iter; left time: 3877.7665s
Epoch: 8 cost time: 42.02226281166077
Epoch: 8, Steps: 233 Train Loss: 33.1547 (Forecasting Loss:0.4400 + XiCon Loss:3.2715 x Lambda(10.0)), Vali MSE Loss: 0.4978 Test MSE Loss: 0.3883
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 33.2786140
	speed: 0.1811s/iter; left time: 3865.1776s
	iters: 200, epoch: 9 | loss: 32.6614609
	speed: 0.1816s/iter; left time: 3856.9085s
Epoch: 9 cost time: 42.544376611709595
Epoch: 9, Steps: 233 Train Loss: 33.1286 (Forecasting Loss:0.4405 + XiCon Loss:3.2688 x Lambda(10.0)), Vali MSE Loss: 0.4968 Test MSE Loss: 0.3875
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.7038307
	speed: 0.1843s/iter; left time: 3889.4845s
	iters: 200, epoch: 10 | loss: 33.0129166
	speed: 0.1848s/iter; left time: 3882.5279s
Epoch: 10 cost time: 43.99499464035034
Epoch: 10, Steps: 233 Train Loss: 33.1728 (Forecasting Loss:0.4400 + XiCon Loss:3.2733 x Lambda(10.0)), Vali MSE Loss: 0.4969 Test MSE Loss: 0.3873
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 33.3140793
	speed: 0.1727s/iter; left time: 3605.2771s
	iters: 200, epoch: 11 | loss: 33.1946487
	speed: 0.1833s/iter; left time: 3807.7199s
Epoch: 11 cost time: 41.47993063926697
Epoch: 11, Steps: 233 Train Loss: 33.1346 (Forecasting Loss:0.4397 + XiCon Loss:3.2695 x Lambda(10.0)), Vali MSE Loss: 0.4968 Test MSE Loss: 0.3871
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 33.0276909
	speed: 0.1775s/iter; left time: 3663.5760s
	iters: 200, epoch: 12 | loss: 33.8145409
	speed: 0.1828s/iter; left time: 3754.1919s
Epoch: 12 cost time: 42.31910300254822
Epoch: 12, Steps: 233 Train Loss: 33.1460 (Forecasting Loss:0.4400 + XiCon Loss:3.2706 x Lambda(10.0)), Vali MSE Loss: 0.4963 Test MSE Loss: 0.3869
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.30277255177497864, mae:0.4465542733669281, mape:0.6536006927490234, mspe:12.274002075195312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 26.2990
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.1273956
	speed: 0.1782s/iter; left time: 4133.4787s
	iters: 200, epoch: 1 | loss: 34.1597748
	speed: 0.1710s/iter; left time: 3951.1398s
Epoch: 1 cost time: 40.89205765724182
Epoch: 1, Steps: 233 Train Loss: 34.2797 (Forecasting Loss:0.5494 + XiCon Loss:3.3730 x Lambda(10.0)), Vali MSE Loss: 0.5209 Test MSE Loss: 0.4271
Validation loss decreased (inf --> 0.520876).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.2968521
	speed: 0.1738s/iter; left time: 3992.3605s
	iters: 200, epoch: 2 | loss: 32.5432663
	speed: 0.1843s/iter; left time: 4214.7277s
Epoch: 2 cost time: 42.277003049850464
Epoch: 2, Steps: 233 Train Loss: 32.5349 (Forecasting Loss:0.4660 + XiCon Loss:3.2069 x Lambda(10.0)), Vali MSE Loss: 0.4057 Test MSE Loss: 0.2973
Validation loss decreased (0.520876 --> 0.405724).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 32.8407669
	speed: 0.1828s/iter; left time: 4156.5851s
	iters: 200, epoch: 3 | loss: 32.5203552
	speed: 0.1899s/iter; left time: 4298.5406s
Epoch: 3 cost time: 43.610230684280396
Epoch: 3, Steps: 233 Train Loss: 32.9001 (Forecasting Loss:0.4190 + XiCon Loss:3.2481 x Lambda(10.0)), Vali MSE Loss: 0.4124 Test MSE Loss: 0.3014
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 33.1982727
	speed: 0.1863s/iter; left time: 4191.6873s
	iters: 200, epoch: 4 | loss: 32.0917168
	speed: 0.1918s/iter; left time: 4296.3137s
Epoch: 4 cost time: 44.36016082763672
Epoch: 4, Steps: 233 Train Loss: 32.5387 (Forecasting Loss:0.4114 + XiCon Loss:3.2127 x Lambda(10.0)), Vali MSE Loss: 0.4002 Test MSE Loss: 0.2953
Validation loss decreased (0.405724 --> 0.400213).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.0238419
	speed: 0.1898s/iter; left time: 4225.9614s
	iters: 200, epoch: 5 | loss: 31.9716778
	speed: 0.2008s/iter; left time: 4450.6642s
Epoch: 5 cost time: 45.719502210617065
Epoch: 5, Steps: 233 Train Loss: 32.2227 (Forecasting Loss:0.3986 + XiCon Loss:3.1824 x Lambda(10.0)), Vali MSE Loss: 0.3956 Test MSE Loss: 0.2948
Validation loss decreased (0.400213 --> 0.395567).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.2161598
	speed: 0.2014s/iter; left time: 4437.3776s
	iters: 200, epoch: 6 | loss: 32.2357826
	speed: 0.2034s/iter; left time: 4462.6406s
Epoch: 6 cost time: 47.441776752471924
Epoch: 6, Steps: 233 Train Loss: 32.1516 (Forecasting Loss:0.3949 + XiCon Loss:3.1757 x Lambda(10.0)), Vali MSE Loss: 0.4013 Test MSE Loss: 0.2961
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 32.2013206
	speed: 0.2004s/iter; left time: 4368.9790s
	iters: 200, epoch: 7 | loss: 32.9144287
	speed: 0.2039s/iter; left time: 4424.6415s
Epoch: 7 cost time: 47.471896171569824
Epoch: 7, Steps: 233 Train Loss: 32.1125 (Forecasting Loss:0.3935 + XiCon Loss:3.1719 x Lambda(10.0)), Vali MSE Loss: 0.3983 Test MSE Loss: 0.2953
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 31.8484859
	speed: 0.2031s/iter; left time: 4380.8459s
	iters: 200, epoch: 8 | loss: 32.2241173
	speed: 0.2060s/iter; left time: 4423.5490s
Epoch: 8 cost time: 47.910250663757324
Epoch: 8, Steps: 233 Train Loss: 32.1104 (Forecasting Loss:0.3919 + XiCon Loss:3.1718 x Lambda(10.0)), Vali MSE Loss: 0.3994 Test MSE Loss: 0.2953
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.7654572
	speed: 0.2040s/iter; left time: 4353.4370s
	iters: 200, epoch: 9 | loss: 32.1738701
	speed: 0.2055s/iter; left time: 4365.0566s
Epoch: 9 cost time: 47.883129835128784
Epoch: 9, Steps: 233 Train Loss: 32.0973 (Forecasting Loss:0.3920 + XiCon Loss:3.1705 x Lambda(10.0)), Vali MSE Loss: 0.3978 Test MSE Loss: 0.2952
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 32.2381058
	speed: 0.2044s/iter; left time: 4313.8242s
	iters: 200, epoch: 10 | loss: 32.3058891
	speed: 0.2065s/iter; left time: 4337.6851s
Epoch: 10 cost time: 47.96820831298828
Epoch: 10, Steps: 233 Train Loss: 32.1085 (Forecasting Loss:0.3915 + XiCon Loss:3.1717 x Lambda(10.0)), Vali MSE Loss: 0.3969 Test MSE Loss: 0.2950
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 31.9938164
	speed: 0.2189s/iter; left time: 4568.6066s
	iters: 200, epoch: 11 | loss: 32.1061783
	speed: 0.2038s/iter; left time: 4233.4136s
Epoch: 11 cost time: 49.149850368499756
Epoch: 11, Steps: 233 Train Loss: 32.1045 (Forecasting Loss:0.3916 + XiCon Loss:3.1713 x Lambda(10.0)), Vali MSE Loss: 0.3972 Test MSE Loss: 0.2951
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 31.7924519
	speed: 0.2049s/iter; left time: 4228.2312s
	iters: 200, epoch: 12 | loss: 32.7713737
	speed: 0.2033s/iter; left time: 4176.0342s
Epoch: 12 cost time: 47.880249977111816
Epoch: 12, Steps: 233 Train Loss: 32.1036 (Forecasting Loss:0.3919 + XiCon Loss:3.1712 x Lambda(10.0)), Vali MSE Loss: 0.3972 Test MSE Loss: 0.2951
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 31.9392681
	speed: 0.2094s/iter; left time: 4273.8144s
	iters: 200, epoch: 13 | loss: 31.6790810
	speed: 0.2026s/iter; left time: 4113.6674s
Epoch: 13 cost time: 48.149375438690186
Epoch: 13, Steps: 233 Train Loss: 32.0888 (Forecasting Loss:0.3921 + XiCon Loss:3.1697 x Lambda(10.0)), Vali MSE Loss: 0.3972 Test MSE Loss: 0.2951
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 31.9229069
	speed: 0.2020s/iter; left time: 4075.3066s
	iters: 200, epoch: 14 | loss: 31.9225674
	speed: 0.2057s/iter; left time: 4128.6927s
Epoch: 14 cost time: 47.50144839286804
Epoch: 14, Steps: 233 Train Loss: 32.1014 (Forecasting Loss:0.3917 + XiCon Loss:3.1710 x Lambda(10.0)), Vali MSE Loss: 0.3973 Test MSE Loss: 0.2951
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 31.7855129
	speed: 0.2052s/iter; left time: 4092.0526s
	iters: 200, epoch: 15 | loss: 31.9143047
	speed: 0.2105s/iter; left time: 4176.9584s
Epoch: 15 cost time: 48.3290114402771
Epoch: 15, Steps: 233 Train Loss: 32.1027 (Forecasting Loss:0.3923 + XiCon Loss:3.1710 x Lambda(10.0)), Vali MSE Loss: 0.3972 Test MSE Loss: 0.2951
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.21656545996665955, mae:0.3730315864086151, mape:0.6570219397544861, mspe:18.34211540222168 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.4323
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.6741982
	speed: 0.1779s/iter; left time: 4127.8429s
	iters: 200, epoch: 1 | loss: 34.3919830
	speed: 0.1680s/iter; left time: 3882.0928s
Epoch: 1 cost time: 40.376457929611206
Epoch: 1, Steps: 233 Train Loss: 34.4736 (Forecasting Loss:0.5525 + XiCon Loss:3.3921 x Lambda(10.0)), Vali MSE Loss: 0.5328 Test MSE Loss: 0.4433
Validation loss decreased (inf --> 0.532846).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.0158310
	speed: 0.1731s/iter; left time: 3974.6680s
	iters: 200, epoch: 2 | loss: 32.6976280
	speed: 0.1820s/iter; left time: 4162.1416s
Epoch: 2 cost time: 41.5798065662384
Epoch: 2, Steps: 233 Train Loss: 32.6284 (Forecasting Loss:0.4329 + XiCon Loss:3.2196 x Lambda(10.0)), Vali MSE Loss: 0.3662 Test MSE Loss: 0.3255
Validation loss decreased (0.532846 --> 0.366176).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 32.7096672
	speed: 0.1789s/iter; left time: 4067.4059s
	iters: 200, epoch: 3 | loss: 32.3496399
	speed: 0.1785s/iter; left time: 4041.3727s
Epoch: 3 cost time: 41.675315618515015
Epoch: 3, Steps: 233 Train Loss: 32.8190 (Forecasting Loss:0.3862 + XiCon Loss:3.2433 x Lambda(10.0)), Vali MSE Loss: 0.3916 Test MSE Loss: 0.2889
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 32.5631943
	speed: 0.1808s/iter; left time: 4068.7777s
	iters: 200, epoch: 4 | loss: 32.4298592
	speed: 0.1783s/iter; left time: 3994.0085s
Epoch: 4 cost time: 41.808690309524536
Epoch: 4, Steps: 233 Train Loss: 32.4232 (Forecasting Loss:0.3747 + XiCon Loss:3.2049 x Lambda(10.0)), Vali MSE Loss: 0.3858 Test MSE Loss: 0.2896
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.2510033
	speed: 0.1798s/iter; left time: 4002.9481s
	iters: 200, epoch: 5 | loss: 32.1409721
	speed: 0.1812s/iter; left time: 4017.8925s
Epoch: 5 cost time: 42.19205904006958
Epoch: 5, Steps: 233 Train Loss: 32.2807 (Forecasting Loss:0.3727 + XiCon Loss:3.1908 x Lambda(10.0)), Vali MSE Loss: 0.3897 Test MSE Loss: 0.2889
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.2383537
	speed: 0.1810s/iter; left time: 3988.0773s
	iters: 200, epoch: 6 | loss: 32.3050270
	speed: 0.1928s/iter; left time: 4228.3852s
Epoch: 6 cost time: 43.92361927032471
Epoch: 6, Steps: 233 Train Loss: 32.1864 (Forecasting Loss:0.3710 + XiCon Loss:3.1815 x Lambda(10.0)), Vali MSE Loss: 0.3892 Test MSE Loss: 0.2892
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 31.7285099
	speed: 0.1805s/iter; left time: 3936.4846s
	iters: 200, epoch: 7 | loss: 32.1980362
	speed: 0.1804s/iter; left time: 3915.5789s
Epoch: 7 cost time: 42.199122190475464
Epoch: 7, Steps: 233 Train Loss: 32.1415 (Forecasting Loss:0.3705 + XiCon Loss:3.1771 x Lambda(10.0)), Vali MSE Loss: 0.3841 Test MSE Loss: 0.2895
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 32.6017227
	speed: 0.1855s/iter; left time: 4000.9967s
	iters: 200, epoch: 8 | loss: 31.9456787
	speed: 0.1759s/iter; left time: 3776.7332s
Epoch: 8 cost time: 42.01002025604248
Epoch: 8, Steps: 233 Train Loss: 32.1075 (Forecasting Loss:0.3703 + XiCon Loss:3.1737 x Lambda(10.0)), Vali MSE Loss: 0.3876 Test MSE Loss: 0.2889
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.0648689
	speed: 0.1759s/iter; left time: 3753.9172s
	iters: 200, epoch: 9 | loss: 32.5340195
	speed: 0.1780s/iter; left time: 3779.1775s
Epoch: 9 cost time: 41.248175859451294
Epoch: 9, Steps: 233 Train Loss: 32.1058 (Forecasting Loss:0.3701 + XiCon Loss:3.1736 x Lambda(10.0)), Vali MSE Loss: 0.3854 Test MSE Loss: 0.2896
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.7356472
	speed: 0.1819s/iter; left time: 3837.8119s
	iters: 200, epoch: 10 | loss: 32.2653275
	speed: 0.1789s/iter; left time: 3758.5905s
Epoch: 10 cost time: 41.89706301689148
Epoch: 10, Steps: 233 Train Loss: 32.0942 (Forecasting Loss:0.3700 + XiCon Loss:3.1724 x Lambda(10.0)), Vali MSE Loss: 0.3855 Test MSE Loss: 0.2893
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 31.9233494
	speed: 0.1823s/iter; left time: 3804.1907s
	iters: 200, epoch: 11 | loss: 31.9349594
	speed: 0.1791s/iter; left time: 3720.0483s
Epoch: 11 cost time: 42.02918887138367
Epoch: 11, Steps: 233 Train Loss: 32.0979 (Forecasting Loss:0.3703 + XiCon Loss:3.1728 x Lambda(10.0)), Vali MSE Loss: 0.3852 Test MSE Loss: 0.2891
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.4891777
	speed: 0.1808s/iter; left time: 3732.1254s
	iters: 200, epoch: 12 | loss: 32.1688805
	speed: 0.1803s/iter; left time: 3702.9449s
Epoch: 12 cost time: 41.866206645965576
Epoch: 12, Steps: 233 Train Loss: 32.1025 (Forecasting Loss:0.3701 + XiCon Loss:3.1732 x Lambda(10.0)), Vali MSE Loss: 0.3853 Test MSE Loss: 0.2890
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.25305798649787903, mae:0.3979291021823883, mape:0.757352352142334, mspe:25.28483009338379 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:2920193
train 29905
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 25.2566
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29905
val 7201
test 7201
	iters: 100, epoch: 1 | loss: 34.3989754
	speed: 0.1731s/iter; left time: 4016.3526s
	iters: 200, epoch: 1 | loss: 33.9217453
	speed: 0.1718s/iter; left time: 3969.7327s
Epoch: 1 cost time: 40.11741232872009
Epoch: 1, Steps: 233 Train Loss: 34.4269 (Forecasting Loss:0.5502 + XiCon Loss:3.3877 x Lambda(10.0)), Vali MSE Loss: 0.5166 Test MSE Loss: 0.4243
Validation loss decreased (inf --> 0.516616).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 32.3649864
	speed: 0.1787s/iter; left time: 4103.3310s
	iters: 200, epoch: 2 | loss: 32.3540764
	speed: 0.1806s/iter; left time: 4129.1973s
Epoch: 2 cost time: 42.406041860580444
Epoch: 2, Steps: 233 Train Loss: 32.6511 (Forecasting Loss:0.4692 + XiCon Loss:3.2182 x Lambda(10.0)), Vali MSE Loss: 0.3938 Test MSE Loss: 0.3134
Validation loss decreased (0.516616 --> 0.393843).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 32.2526665
	speed: 0.1914s/iter; left time: 4352.5863s
	iters: 200, epoch: 3 | loss: 32.1540260
	speed: 0.1962s/iter; left time: 4439.8884s
Epoch: 3 cost time: 45.272775411605835
Epoch: 3, Steps: 233 Train Loss: 32.7468 (Forecasting Loss:0.4140 + XiCon Loss:3.2333 x Lambda(10.0)), Vali MSE Loss: 0.4312 Test MSE Loss: 0.3161
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 33.1374016
	speed: 0.2024s/iter; left time: 4555.1683s
	iters: 200, epoch: 4 | loss: 32.6828613
	speed: 0.2049s/iter; left time: 4590.9875s
Epoch: 4 cost time: 47.677260398864746
Epoch: 4, Steps: 233 Train Loss: 32.6438 (Forecasting Loss:0.4146 + XiCon Loss:3.2229 x Lambda(10.0)), Vali MSE Loss: 0.3849 Test MSE Loss: 0.3046
Validation loss decreased (0.393843 --> 0.384861).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 32.3797874
	speed: 0.2025s/iter; left time: 4510.0276s
	iters: 200, epoch: 5 | loss: 32.5685158
	speed: 0.2074s/iter; left time: 4597.5672s
Epoch: 5 cost time: 47.963356256484985
Epoch: 5, Steps: 233 Train Loss: 32.5067 (Forecasting Loss:0.4115 + XiCon Loss:3.2095 x Lambda(10.0)), Vali MSE Loss: 0.3892 Test MSE Loss: 0.3061
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 32.2639656
	speed: 0.1922s/iter; left time: 4234.5936s
	iters: 200, epoch: 6 | loss: 33.1032906
	speed: 0.1821s/iter; left time: 3994.2766s
Epoch: 6 cost time: 43.612319231033325
Epoch: 6, Steps: 233 Train Loss: 32.4444 (Forecasting Loss:0.4101 + XiCon Loss:3.2034 x Lambda(10.0)), Vali MSE Loss: 0.3876 Test MSE Loss: 0.3052
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 33.1609535
	speed: 0.1916s/iter; left time: 4176.9137s
	iters: 200, epoch: 7 | loss: 32.3593559
	speed: 0.1788s/iter; left time: 3880.4293s
Epoch: 7 cost time: 42.80812931060791
Epoch: 7, Steps: 233 Train Loss: 32.4368 (Forecasting Loss:0.4092 + XiCon Loss:3.2028 x Lambda(10.0)), Vali MSE Loss: 0.3919 Test MSE Loss: 0.3067
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 33.0261879
	speed: 0.1825s/iter; left time: 3937.2492s
	iters: 200, epoch: 8 | loss: 32.9224854
	speed: 0.1834s/iter; left time: 3937.4369s
Epoch: 8 cost time: 42.69248366355896
Epoch: 8, Steps: 233 Train Loss: 32.4135 (Forecasting Loss:0.4095 + XiCon Loss:3.2004 x Lambda(10.0)), Vali MSE Loss: 0.3888 Test MSE Loss: 0.3056
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 32.0604172
	speed: 0.1844s/iter; left time: 3934.6160s
	iters: 200, epoch: 9 | loss: 32.8782616
	speed: 0.1870s/iter; left time: 3972.0249s
Epoch: 9 cost time: 43.510701179504395
Epoch: 9, Steps: 233 Train Loss: 32.4004 (Forecasting Loss:0.4090 + XiCon Loss:3.1991 x Lambda(10.0)), Vali MSE Loss: 0.3890 Test MSE Loss: 0.3056
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 31.8797626
	speed: 0.1805s/iter; left time: 3810.2190s
	iters: 200, epoch: 10 | loss: 32.3915749
	speed: 0.1908s/iter; left time: 4006.9606s
Epoch: 10 cost time: 43.36427450180054
Epoch: 10, Steps: 233 Train Loss: 32.4171 (Forecasting Loss:0.4091 + XiCon Loss:3.2008 x Lambda(10.0)), Vali MSE Loss: 0.3889 Test MSE Loss: 0.3056
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 33.3365822
	speed: 0.1839s/iter; left time: 3837.2276s
	iters: 200, epoch: 11 | loss: 32.2093735
	speed: 0.1760s/iter; left time: 3656.0209s
Epoch: 11 cost time: 42.1507031917572
Epoch: 11, Steps: 233 Train Loss: 32.4188 (Forecasting Loss:0.4092 + XiCon Loss:3.2010 x Lambda(10.0)), Vali MSE Loss: 0.3888 Test MSE Loss: 0.3055
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 32.4660645
	speed: 0.1792s/iter; left time: 3698.2955s
	iters: 200, epoch: 12 | loss: 33.0529442
	speed: 0.1827s/iter; left time: 3753.1564s
Epoch: 12 cost time: 42.08977723121643
Epoch: 12, Steps: 233 Train Loss: 32.3948 (Forecasting Loss:0.4090 + XiCon Loss:3.1986 x Lambda(10.0)), Vali MSE Loss: 0.3889 Test MSE Loss: 0.3055
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 32.0677605
	speed: 0.1862s/iter; left time: 3800.3956s
	iters: 200, epoch: 13 | loss: 32.2849083
	speed: 0.1814s/iter; left time: 3683.9163s
Epoch: 13 cost time: 42.5148389339447
Epoch: 13, Steps: 233 Train Loss: 32.3900 (Forecasting Loss:0.4088 + XiCon Loss:3.1981 x Lambda(10.0)), Vali MSE Loss: 0.3889 Test MSE Loss: 0.3055
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 33.1780319
	speed: 0.1836s/iter; left time: 3702.8080s
	iters: 200, epoch: 14 | loss: 32.8411980
	speed: 0.1800s/iter; left time: 3613.2143s
Epoch: 14 cost time: 42.38216042518616
Epoch: 14, Steps: 233 Train Loss: 32.4058 (Forecasting Loss:0.4093 + XiCon Loss:3.1997 x Lambda(10.0)), Vali MSE Loss: 0.3887 Test MSE Loss: 0.3055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl4320_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 7201
test shape: (56, 128, 4320, 1) (56, 128, 4320, 1)
test shape: (7168, 4320, 1) (7168, 4320, 1)
mse:0.22709788382053375, mae:0.3821711838245392, mape:0.639759361743927, mspe:16.667890548706055 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2410+-0.04820, MAE:0.3929+-0.04021, MAPE:0.6700+-0.06127, MSPE:17.9473+-5.83802, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
