Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5100
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6109510
	speed: 0.0159s/iter; left time: 378.9054s
	iters: 200, epoch: 1 | loss: 0.5754265
	speed: 0.0106s/iter; left time: 250.7981s
Epoch: 1 cost time: 3.0847573280334473
Epoch: 1, Steps: 239 Train Loss: 0.6528 (Forecasting Loss:0.6226 + XiCon Loss:3.0190 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.4445
Validation loss decreased (inf --> 0.327659).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3284381
	speed: 0.0139s/iter; left time: 327.5006s
	iters: 200, epoch: 2 | loss: 0.2996329
	speed: 0.0116s/iter; left time: 272.3140s
Epoch: 2 cost time: 2.9870450496673584
Epoch: 2, Steps: 239 Train Loss: 0.3423 (Forecasting Loss:0.3123 + XiCon Loss:3.0026 x Lambda(0.01)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.2790
Validation loss decreased (0.327659 --> 0.206026).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2974974
	speed: 0.0124s/iter; left time: 289.7570s
	iters: 200, epoch: 3 | loss: 0.3141996
	speed: 0.0103s/iter; left time: 239.5251s
Epoch: 3 cost time: 2.6719751358032227
Epoch: 3, Steps: 239 Train Loss: 0.3024 (Forecasting Loss:0.2725 + XiCon Loss:2.9883 x Lambda(0.01)), Vali MSE Loss: 0.1973 Test MSE Loss: 0.2692
Validation loss decreased (0.206026 --> 0.197347).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2759439
	speed: 0.0122s/iter; left time: 281.8594s
	iters: 200, epoch: 4 | loss: 0.2775520
	speed: 0.0106s/iter; left time: 242.9082s
Epoch: 4 cost time: 2.7227137088775635
Epoch: 4, Steps: 239 Train Loss: 0.2959 (Forecasting Loss:0.2661 + XiCon Loss:2.9830 x Lambda(0.01)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.2661
Validation loss decreased (0.197347 --> 0.195273).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3164428
	speed: 0.0122s/iter; left time: 279.4171s
	iters: 200, epoch: 5 | loss: 0.2853910
	speed: 0.0101s/iter; left time: 229.2222s
Epoch: 5 cost time: 2.650989055633545
Epoch: 5, Steps: 239 Train Loss: 0.2928 (Forecasting Loss:0.2630 + XiCon Loss:2.9782 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2657
Validation loss decreased (0.195273 --> 0.193797).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2840312
	speed: 0.0115s/iter; left time: 259.8851s
	iters: 200, epoch: 6 | loss: 0.2841925
	speed: 0.0101s/iter; left time: 227.1338s
Epoch: 6 cost time: 2.6161632537841797
Epoch: 6, Steps: 239 Train Loss: 0.2915 (Forecasting Loss:0.2617 + XiCon Loss:2.9784 x Lambda(0.01)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.2639
Validation loss decreased (0.193797 --> 0.193140).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3003050
	speed: 0.0125s/iter; left time: 278.7865s
	iters: 200, epoch: 7 | loss: 0.2996380
	speed: 0.0110s/iter; left time: 244.4993s
Epoch: 7 cost time: 2.7533388137817383
Epoch: 7, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2606 + XiCon Loss:2.9783 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.2636
Validation loss decreased (0.193140 --> 0.192643).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2462687
	speed: 0.0118s/iter; left time: 261.0310s
	iters: 200, epoch: 8 | loss: 0.2883605
	speed: 0.0105s/iter; left time: 230.2452s
Epoch: 8 cost time: 2.6378235816955566
Epoch: 8, Steps: 239 Train Loss: 0.2900 (Forecasting Loss:0.2602 + XiCon Loss:2.9780 x Lambda(0.01)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2633
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2558753
	speed: 0.0129s/iter; left time: 283.3656s
	iters: 200, epoch: 9 | loss: 0.3195526
	speed: 0.0107s/iter; left time: 232.5049s
Epoch: 9 cost time: 2.798922300338745
Epoch: 9, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2604 + XiCon Loss:2.9771 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2633
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2741444
	speed: 0.0117s/iter; left time: 253.3947s
	iters: 200, epoch: 10 | loss: 0.3065548
	speed: 0.0095s/iter; left time: 205.2778s
Epoch: 10 cost time: 2.5276169776916504
Epoch: 10, Steps: 239 Train Loss: 0.2895 (Forecasting Loss:0.2597 + XiCon Loss:2.9770 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2819105
	speed: 0.0125s/iter; left time: 267.8978s
	iters: 200, epoch: 11 | loss: 0.2783577
	speed: 0.0095s/iter; left time: 203.2429s
Epoch: 11 cost time: 2.61678409576416
Epoch: 11, Steps: 239 Train Loss: 0.2897 (Forecasting Loss:0.2599 + XiCon Loss:2.9769 x Lambda(0.01)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.2632
Validation loss decreased (0.192643 --> 0.192227).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3167595
	speed: 0.0128s/iter; left time: 270.5946s
	iters: 200, epoch: 12 | loss: 0.2749462
	speed: 0.0105s/iter; left time: 221.5189s
Epoch: 12 cost time: 2.791077136993408
Epoch: 12, Steps: 239 Train Loss: 0.2898 (Forecasting Loss:0.2601 + XiCon Loss:2.9764 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2781421
	speed: 0.0117s/iter; left time: 244.6541s
	iters: 200, epoch: 13 | loss: 0.2895562
	speed: 0.0098s/iter; left time: 203.8893s
Epoch: 13 cost time: 2.5525033473968506
Epoch: 13, Steps: 239 Train Loss: 0.2897 (Forecasting Loss:0.2600 + XiCon Loss:2.9779 x Lambda(0.01)), Vali MSE Loss: 0.1927 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2951463
	speed: 0.0128s/iter; left time: 264.3610s
	iters: 200, epoch: 14 | loss: 0.2806010
	speed: 0.0103s/iter; left time: 211.2329s
Epoch: 14 cost time: 2.743239641189575
Epoch: 14, Steps: 239 Train Loss: 0.2899 (Forecasting Loss:0.2601 + XiCon Loss:2.9776 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3194572
	speed: 0.0130s/iter; left time: 266.2570s
	iters: 200, epoch: 15 | loss: 0.2350533
	speed: 0.0101s/iter; left time: 206.3489s
Epoch: 15 cost time: 2.7465877532958984
Epoch: 15, Steps: 239 Train Loss: 0.2901 (Forecasting Loss:0.2603 + XiCon Loss:2.9765 x Lambda(0.01)), Vali MSE Loss: 0.1928 Test MSE Loss: 0.2632
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3015102
	speed: 0.0119s/iter; left time: 240.1780s
	iters: 200, epoch: 16 | loss: 0.2735709
	speed: 0.0094s/iter; left time: 188.6241s
Epoch: 16 cost time: 2.5289306640625
Epoch: 16, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2597 + XiCon Loss:2.9777 x Lambda(0.01)), Vali MSE Loss: 0.1924 Test MSE Loss: 0.2632
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2653916
	speed: 0.0123s/iter; left time: 245.6978s
	iters: 200, epoch: 17 | loss: 0.2802284
	speed: 0.0097s/iter; left time: 192.3261s
Epoch: 17 cost time: 2.6092605590820312
Epoch: 17, Steps: 239 Train Loss: 0.2895 (Forecasting Loss:0.2598 + XiCon Loss:2.9773 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2816291
	speed: 0.0121s/iter; left time: 239.8143s
	iters: 200, epoch: 18 | loss: 0.2962100
	speed: 0.0100s/iter; left time: 196.8116s
Epoch: 18 cost time: 2.629863977432251
Epoch: 18, Steps: 239 Train Loss: 0.2896 (Forecasting Loss:0.2599 + XiCon Loss:2.9775 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3075215
	speed: 0.0122s/iter; left time: 237.2453s
	iters: 200, epoch: 19 | loss: 0.3298510
	speed: 0.0096s/iter; left time: 186.5657s
Epoch: 19 cost time: 2.5963525772094727
Epoch: 19, Steps: 239 Train Loss: 0.2896 (Forecasting Loss:0.2598 + XiCon Loss:2.9779 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.2632
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3019592
	speed: 0.0123s/iter; left time: 237.2830s
	iters: 200, epoch: 20 | loss: 0.3077736
	speed: 0.0098s/iter; left time: 187.7119s
Epoch: 20 cost time: 2.6887590885162354
Epoch: 20, Steps: 239 Train Loss: 0.2897 (Forecasting Loss:0.2599 + XiCon Loss:2.9776 x Lambda(0.01)), Vali MSE Loss: 0.1923 Test MSE Loss: 0.2632
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2984862
	speed: 0.0124s/iter; left time: 236.2356s
	iters: 200, epoch: 21 | loss: 0.2743481
	speed: 0.0096s/iter; left time: 181.8827s
Epoch: 21 cost time: 2.6251380443573
Epoch: 21, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2597 + XiCon Loss:2.9770 x Lambda(0.01)), Vali MSE Loss: 0.1925 Test MSE Loss: 0.2632
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.2061823010444641, mae:0.32025718688964844, mape:2.334078550338745, mspe:3206.02734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4108
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6301959
	speed: 0.0126s/iter; left time: 299.5694s
	iters: 200, epoch: 1 | loss: 0.4904204
	speed: 0.0100s/iter; left time: 236.6118s
Epoch: 1 cost time: 2.6777992248535156
Epoch: 1, Steps: 239 Train Loss: 0.6424 (Forecasting Loss:0.6124 + XiCon Loss:3.0086 x Lambda(0.01)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.4345
Validation loss decreased (inf --> 0.322186).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3489681
	speed: 0.0132s/iter; left time: 311.1874s
	iters: 200, epoch: 2 | loss: 0.2870166
	speed: 0.0101s/iter; left time: 238.0338s
Epoch: 2 cost time: 2.735826253890991
Epoch: 2, Steps: 239 Train Loss: 0.3422 (Forecasting Loss:0.3121 + XiCon Loss:3.0097 x Lambda(0.01)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.2778
Validation loss decreased (0.322186 --> 0.202058).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2927786
	speed: 0.0121s/iter; left time: 282.7874s
	iters: 200, epoch: 3 | loss: 0.2727102
	speed: 0.0106s/iter; left time: 246.4118s
Epoch: 3 cost time: 2.6861093044281006
Epoch: 3, Steps: 239 Train Loss: 0.3029 (Forecasting Loss:0.2728 + XiCon Loss:3.0148 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2713
Validation loss decreased (0.202058 --> 0.194390).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2319598
	speed: 0.0124s/iter; left time: 285.9142s
	iters: 200, epoch: 4 | loss: 0.2885915
	speed: 0.0097s/iter; left time: 223.4578s
Epoch: 4 cost time: 2.6462745666503906
Epoch: 4, Steps: 239 Train Loss: 0.2960 (Forecasting Loss:0.2659 + XiCon Loss:3.0162 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2650
Validation loss decreased (0.194390 --> 0.191257).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2876272
	speed: 0.0122s/iter; left time: 278.9580s
	iters: 200, epoch: 5 | loss: 0.2984490
	speed: 0.0098s/iter; left time: 222.1328s
Epoch: 5 cost time: 2.6308441162109375
Epoch: 5, Steps: 239 Train Loss: 0.2925 (Forecasting Loss:0.2623 + XiCon Loss:3.0171 x Lambda(0.01)), Vali MSE Loss: 0.1898 Test MSE Loss: 0.2638
Validation loss decreased (0.191257 --> 0.189822).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2820130
	speed: 0.0117s/iter; left time: 265.1550s
	iters: 200, epoch: 6 | loss: 0.3126899
	speed: 0.0100s/iter; left time: 224.3972s
Epoch: 6 cost time: 2.573169708251953
Epoch: 6, Steps: 239 Train Loss: 0.2908 (Forecasting Loss:0.2606 + XiCon Loss:3.0134 x Lambda(0.01)), Vali MSE Loss: 0.1886 Test MSE Loss: 0.2628
Validation loss decreased (0.189822 --> 0.188635).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2760382
	speed: 0.0120s/iter; left time: 267.3037s
	iters: 200, epoch: 7 | loss: 0.2712395
	speed: 0.0109s/iter; left time: 242.1226s
Epoch: 7 cost time: 2.6824862957000732
Epoch: 7, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2602 + XiCon Loss:3.0146 x Lambda(0.01)), Vali MSE Loss: 0.1887 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2735799
	speed: 0.0132s/iter; left time: 291.8295s
	iters: 200, epoch: 8 | loss: 0.3435544
	speed: 0.0109s/iter; left time: 239.9974s
Epoch: 8 cost time: 2.8418192863464355
Epoch: 8, Steps: 239 Train Loss: 0.2898 (Forecasting Loss:0.2597 + XiCon Loss:3.0145 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2623
Validation loss decreased (0.188635 --> 0.188020).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3023496
	speed: 0.0123s/iter; left time: 268.7209s
	iters: 200, epoch: 9 | loss: 0.3026225
	speed: 0.0100s/iter; left time: 217.1617s
Epoch: 9 cost time: 2.6410913467407227
Epoch: 9, Steps: 239 Train Loss: 0.2892 (Forecasting Loss:0.2590 + XiCon Loss:3.0157 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2621
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2827595
	speed: 0.0123s/iter; left time: 267.0173s
	iters: 200, epoch: 10 | loss: 0.3132567
	speed: 0.0096s/iter; left time: 207.5971s
Epoch: 10 cost time: 2.600674867630005
Epoch: 10, Steps: 239 Train Loss: 0.2893 (Forecasting Loss:0.2592 + XiCon Loss:3.0132 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2620
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2841915
	speed: 0.0120s/iter; left time: 257.8552s
	iters: 200, epoch: 11 | loss: 0.2962197
	speed: 0.0101s/iter; left time: 216.0648s
Epoch: 11 cost time: 2.636906862258911
Epoch: 11, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2593 + XiCon Loss:3.0116 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2620
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3052657
	speed: 0.0126s/iter; left time: 265.9093s
	iters: 200, epoch: 12 | loss: 0.2938764
	speed: 0.0102s/iter; left time: 214.3565s
Epoch: 12 cost time: 2.7096478939056396
Epoch: 12, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2588 + XiCon Loss:3.0132 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.2619
Validation loss decreased (0.188020 --> 0.187953).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2974442
	speed: 0.0118s/iter; left time: 247.6115s
	iters: 200, epoch: 13 | loss: 0.3041562
	speed: 0.0100s/iter; left time: 209.3510s
Epoch: 13 cost time: 2.5714354515075684
Epoch: 13, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2589 + XiCon Loss:3.0141 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2620
Validation loss decreased (0.187953 --> 0.187890).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2856494
	speed: 0.0124s/iter; left time: 255.8724s
	iters: 200, epoch: 14 | loss: 0.2871644
	speed: 0.0098s/iter; left time: 201.0920s
Epoch: 14 cost time: 2.664181709289551
Epoch: 14, Steps: 239 Train Loss: 0.2893 (Forecasting Loss:0.2592 + XiCon Loss:3.0142 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2620
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3177833
	speed: 0.0130s/iter; left time: 266.1723s
	iters: 200, epoch: 15 | loss: 0.2741829
	speed: 0.0105s/iter; left time: 212.8517s
Epoch: 15 cost time: 2.7802069187164307
Epoch: 15, Steps: 239 Train Loss: 0.2888 (Forecasting Loss:0.2587 + XiCon Loss:3.0140 x Lambda(0.01)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.2620
Validation loss decreased (0.187890 --> 0.187793).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2862121
	speed: 0.0123s/iter; left time: 249.0583s
	iters: 200, epoch: 16 | loss: 0.2938730
	speed: 0.0102s/iter; left time: 206.0757s
Epoch: 16 cost time: 2.694782257080078
Epoch: 16, Steps: 239 Train Loss: 0.2890 (Forecasting Loss:0.2589 + XiCon Loss:3.0155 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2620
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2633387
	speed: 0.0129s/iter; left time: 256.8390s
	iters: 200, epoch: 17 | loss: 0.2958371
	speed: 0.0104s/iter; left time: 206.9231s
Epoch: 17 cost time: 2.7685670852661133
Epoch: 17, Steps: 239 Train Loss: 0.2895 (Forecasting Loss:0.2594 + XiCon Loss:3.0150 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2620
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.3004876
	speed: 0.0127s/iter; left time: 250.2198s
	iters: 200, epoch: 18 | loss: 0.3026459
	speed: 0.0102s/iter; left time: 200.2742s
Epoch: 18 cost time: 2.795658588409424
Epoch: 18, Steps: 239 Train Loss: 0.2893 (Forecasting Loss:0.2592 + XiCon Loss:3.0140 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2620
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3318025
	speed: 0.0125s/iter; left time: 243.7523s
	iters: 200, epoch: 19 | loss: 0.3092667
	speed: 0.0102s/iter; left time: 198.1834s
Epoch: 19 cost time: 2.7195701599121094
Epoch: 19, Steps: 239 Train Loss: 0.2897 (Forecasting Loss:0.2595 + XiCon Loss:3.0152 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.2620
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.2774697
	speed: 0.0123s/iter; left time: 236.2733s
	iters: 200, epoch: 20 | loss: 0.2710877
	speed: 0.0104s/iter; left time: 199.9144s
Epoch: 20 cost time: 2.7315447330474854
Epoch: 20, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2592 + XiCon Loss:3.0144 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2620
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.3219273
	speed: 0.0124s/iter; left time: 235.9517s
	iters: 200, epoch: 21 | loss: 0.3229389
	speed: 0.0099s/iter; left time: 187.7181s
Epoch: 21 cost time: 2.6659739017486572
Epoch: 21, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2593 + XiCon Loss:3.0152 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.2620
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2671518
	speed: 0.0139s/iter; left time: 260.1367s
	iters: 200, epoch: 22 | loss: 0.2641118
	speed: 0.0105s/iter; left time: 196.7212s
Epoch: 22 cost time: 2.8584117889404297
Epoch: 22, Steps: 239 Train Loss: 0.2891 (Forecasting Loss:0.2589 + XiCon Loss:3.0131 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2620
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2789989
	speed: 0.0116s/iter; left time: 214.2554s
	iters: 200, epoch: 23 | loss: 0.3113549
	speed: 0.0101s/iter; left time: 186.1019s
Epoch: 23 cost time: 2.6115949153900146
Epoch: 23, Steps: 239 Train Loss: 0.2893 (Forecasting Loss:0.2591 + XiCon Loss:3.0120 x Lambda(0.01)), Vali MSE Loss: 0.1884 Test MSE Loss: 0.2620
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2801683
	speed: 0.0122s/iter; left time: 222.7136s
	iters: 200, epoch: 24 | loss: 0.2715066
	speed: 0.0102s/iter; left time: 185.6716s
Epoch: 24 cost time: 2.673804521560669
Epoch: 24, Steps: 239 Train Loss: 0.2894 (Forecasting Loss:0.2593 + XiCon Loss:3.0128 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.2620
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.3130677
	speed: 0.0122s/iter; left time: 220.8598s
	iters: 200, epoch: 25 | loss: 0.2790483
	speed: 0.0097s/iter; left time: 173.6968s
Epoch: 25 cost time: 2.6132123470306396
Epoch: 25, Steps: 239 Train Loss: 0.2889 (Forecasting Loss:0.2588 + XiCon Loss:3.0143 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.2620
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20344914495944977, mae:0.32045862078666687, mape:2.5401923656463623, mspe:4545.03857421875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3822
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6069711
	speed: 0.0129s/iter; left time: 307.9125s
	iters: 200, epoch: 1 | loss: 0.6394567
	speed: 0.0104s/iter; left time: 247.0721s
Epoch: 1 cost time: 2.750516653060913
Epoch: 1, Steps: 239 Train Loss: 0.6743 (Forecasting Loss:0.6435 + XiCon Loss:3.0740 x Lambda(0.01)), Vali MSE Loss: 0.3319 Test MSE Loss: 0.4547
Validation loss decreased (inf --> 0.331918).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3492408
	speed: 0.0121s/iter; left time: 286.0466s
	iters: 200, epoch: 2 | loss: 0.3304403
	speed: 0.0096s/iter; left time: 225.1335s
Epoch: 2 cost time: 2.594994068145752
Epoch: 2, Steps: 239 Train Loss: 0.3467 (Forecasting Loss:0.3161 + XiCon Loss:3.0645 x Lambda(0.01)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.2813
Validation loss decreased (0.331918 --> 0.205673).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3200680
	speed: 0.0121s/iter; left time: 281.2485s
	iters: 200, epoch: 3 | loss: 0.3373611
	speed: 0.0100s/iter; left time: 232.6886s
Epoch: 3 cost time: 2.605076313018799
Epoch: 3, Steps: 239 Train Loss: 0.3093 (Forecasting Loss:0.2789 + XiCon Loss:3.0439 x Lambda(0.01)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.2748
Validation loss decreased (0.205673 --> 0.200447).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3237360
	speed: 0.0124s/iter; left time: 285.9053s
	iters: 200, epoch: 4 | loss: 0.3123797
	speed: 0.0099s/iter; left time: 227.3455s
Epoch: 4 cost time: 2.6525027751922607
Epoch: 4, Steps: 239 Train Loss: 0.3031 (Forecasting Loss:0.2727 + XiCon Loss:3.0366 x Lambda(0.01)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2722
Validation loss decreased (0.200447 --> 0.197937).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3015434
	speed: 0.0125s/iter; left time: 285.7919s
	iters: 200, epoch: 5 | loss: 0.3168358
	speed: 0.0106s/iter; left time: 241.6479s
Epoch: 5 cost time: 2.6818952560424805
Epoch: 5, Steps: 239 Train Loss: 0.3001 (Forecasting Loss:0.2697 + XiCon Loss:3.0301 x Lambda(0.01)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.2690
Validation loss decreased (0.197937 --> 0.196248).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2987870
	speed: 0.0120s/iter; left time: 271.2868s
	iters: 200, epoch: 6 | loss: 0.2689524
	speed: 0.0099s/iter; left time: 222.9683s
Epoch: 6 cost time: 2.596999406814575
Epoch: 6, Steps: 239 Train Loss: 0.2982 (Forecasting Loss:0.2679 + XiCon Loss:3.0258 x Lambda(0.01)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.2684
Validation loss decreased (0.196248 --> 0.195460).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2808120
	speed: 0.0125s/iter; left time: 280.6447s
	iters: 200, epoch: 7 | loss: 0.3065867
	speed: 0.0105s/iter; left time: 233.8662s
Epoch: 7 cost time: 2.7551708221435547
Epoch: 7, Steps: 239 Train Loss: 0.2978 (Forecasting Loss:0.2675 + XiCon Loss:3.0265 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2677
Validation loss decreased (0.195460 --> 0.195232).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2961501
	speed: 0.0123s/iter; left time: 271.1860s
	iters: 200, epoch: 8 | loss: 0.3237742
	speed: 0.0102s/iter; left time: 224.6834s
Epoch: 8 cost time: 2.711811065673828
Epoch: 8, Steps: 239 Train Loss: 0.2972 (Forecasting Loss:0.2670 + XiCon Loss:3.0258 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2675
Validation loss decreased (0.195232 --> 0.194631).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2484793
	speed: 0.0115s/iter; left time: 252.6961s
	iters: 200, epoch: 9 | loss: 0.2823120
	speed: 0.0095s/iter; left time: 206.4499s
Epoch: 9 cost time: 2.515162467956543
Epoch: 9, Steps: 239 Train Loss: 0.2968 (Forecasting Loss:0.2666 + XiCon Loss:3.0231 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
Validation loss decreased (0.194631 --> 0.194522).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3013338
	speed: 0.0124s/iter; left time: 267.7478s
	iters: 200, epoch: 10 | loss: 0.3200338
	speed: 0.0098s/iter; left time: 212.0579s
Epoch: 10 cost time: 2.639759063720703
Epoch: 10, Steps: 239 Train Loss: 0.2966 (Forecasting Loss:0.2664 + XiCon Loss:3.0260 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2512503
	speed: 0.0129s/iter; left time: 275.6482s
	iters: 200, epoch: 11 | loss: 0.3316447
	speed: 0.0108s/iter; left time: 231.1429s
Epoch: 11 cost time: 2.796349048614502
Epoch: 11, Steps: 239 Train Loss: 0.2965 (Forecasting Loss:0.2662 + XiCon Loss:3.0249 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2739917
	speed: 0.0126s/iter; left time: 266.2627s
	iters: 200, epoch: 12 | loss: 0.2893433
	speed: 0.0100s/iter; left time: 211.7232s
Epoch: 12 cost time: 2.7000842094421387
Epoch: 12, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2665 + XiCon Loss:3.0248 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2535251
	speed: 0.0124s/iter; left time: 260.1116s
	iters: 200, epoch: 13 | loss: 0.3187310
	speed: 0.0102s/iter; left time: 212.6962s
Epoch: 13 cost time: 2.69116473197937
Epoch: 13, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2664 + XiCon Loss:3.0231 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2974124
	speed: 0.0120s/iter; left time: 247.7855s
	iters: 200, epoch: 14 | loss: 0.3050839
	speed: 0.0094s/iter; left time: 193.0026s
Epoch: 14 cost time: 2.5389885902404785
Epoch: 14, Steps: 239 Train Loss: 0.2964 (Forecasting Loss:0.2661 + XiCon Loss:3.0242 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2869003
	speed: 0.0120s/iter; left time: 245.0057s
	iters: 200, epoch: 15 | loss: 0.3093014
	speed: 0.0098s/iter; left time: 198.8883s
Epoch: 15 cost time: 2.5808520317077637
Epoch: 15, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2665 + XiCon Loss:3.0221 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3131728
	speed: 0.0132s/iter; left time: 266.5904s
	iters: 200, epoch: 16 | loss: 0.2690867
	speed: 0.0105s/iter; left time: 210.4701s
Epoch: 16 cost time: 2.7683451175689697
Epoch: 16, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2664 + XiCon Loss:3.0245 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2895521
	speed: 0.0117s/iter; left time: 233.2812s
	iters: 200, epoch: 17 | loss: 0.2982565
	speed: 0.0096s/iter; left time: 189.8987s
Epoch: 17 cost time: 2.5664381980895996
Epoch: 17, Steps: 239 Train Loss: 0.2966 (Forecasting Loss:0.2664 + XiCon Loss:3.0219 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2998943
	speed: 0.0121s/iter; left time: 239.0011s
	iters: 200, epoch: 18 | loss: 0.3262417
	speed: 0.0099s/iter; left time: 195.3498s
Epoch: 18 cost time: 2.6203725337982178
Epoch: 18, Steps: 239 Train Loss: 0.2963 (Forecasting Loss:0.2661 + XiCon Loss:3.0229 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.2674
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2841937
	speed: 0.0128s/iter; left time: 249.7136s
	iters: 200, epoch: 19 | loss: 0.2871329
	speed: 0.0096s/iter; left time: 186.6166s
Epoch: 19 cost time: 2.6730639934539795
Epoch: 19, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2664 + XiCon Loss:3.0274 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
Validation loss decreased (0.194522 --> 0.194507).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3090122
	speed: 0.0120s/iter; left time: 231.0439s
	iters: 200, epoch: 20 | loss: 0.2870518
	speed: 0.0098s/iter; left time: 187.7562s
Epoch: 20 cost time: 2.5826804637908936
Epoch: 20, Steps: 239 Train Loss: 0.2966 (Forecasting Loss:0.2663 + XiCon Loss:3.0226 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2735762
	speed: 0.0130s/iter; left time: 247.6993s
	iters: 200, epoch: 21 | loss: 0.3106651
	speed: 0.0104s/iter; left time: 197.5088s
Epoch: 21 cost time: 2.7820301055908203
Epoch: 21, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2665 + XiCon Loss:3.0239 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3062302
	speed: 0.0131s/iter; left time: 245.2881s
	iters: 200, epoch: 22 | loss: 0.3086317
	speed: 0.0104s/iter; left time: 193.9152s
Epoch: 22 cost time: 2.777528762817383
Epoch: 22, Steps: 239 Train Loss: 0.2968 (Forecasting Loss:0.2665 + XiCon Loss:3.0258 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2775894
	speed: 0.0130s/iter; left time: 241.8590s
	iters: 200, epoch: 23 | loss: 0.3056509
	speed: 0.0099s/iter; left time: 182.7060s
Epoch: 23 cost time: 2.6996407508850098
Epoch: 23, Steps: 239 Train Loss: 0.2965 (Forecasting Loss:0.2662 + XiCon Loss:3.0252 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2674
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2885773
	speed: 0.0116s/iter; left time: 213.1092s
	iters: 200, epoch: 24 | loss: 0.2963305
	speed: 0.0100s/iter; left time: 181.6354s
Epoch: 24 cost time: 2.5810980796813965
Epoch: 24, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2664 + XiCon Loss:3.0284 x Lambda(0.01)), Vali MSE Loss: 0.1950 Test MSE Loss: 0.2674
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2956676
	speed: 0.0119s/iter; left time: 214.5574s
	iters: 200, epoch: 25 | loss: 0.3379525
	speed: 0.0111s/iter; left time: 198.9664s
Epoch: 25 cost time: 2.7503275871276855
Epoch: 25, Steps: 239 Train Loss: 0.2963 (Forecasting Loss:0.2661 + XiCon Loss:3.0221 x Lambda(0.01)), Vali MSE Loss: 0.1947 Test MSE Loss: 0.2674
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.3098645
	speed: 0.0122s/iter; left time: 217.6155s
	iters: 200, epoch: 26 | loss: 0.2561791
	speed: 0.0101s/iter; left time: 179.5256s
Epoch: 26 cost time: 2.664717435836792
Epoch: 26, Steps: 239 Train Loss: 0.2966 (Forecasting Loss:0.2664 + XiCon Loss:3.0221 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2674
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.3003624
	speed: 0.0125s/iter; left time: 219.0909s
	iters: 200, epoch: 27 | loss: 0.2873508
	speed: 0.0100s/iter; left time: 175.0103s
Epoch: 27 cost time: 2.6895387172698975
Epoch: 27, Steps: 239 Train Loss: 0.2967 (Forecasting Loss:0.2664 + XiCon Loss:3.0219 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.3282494
	speed: 0.0126s/iter; left time: 219.2265s
	iters: 200, epoch: 28 | loss: 0.2796718
	speed: 0.0105s/iter; left time: 181.8669s
Epoch: 28 cost time: 2.755547523498535
Epoch: 28, Steps: 239 Train Loss: 0.2962 (Forecasting Loss:0.2660 + XiCon Loss:3.0247 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.2526453
	speed: 0.0121s/iter; left time: 207.6303s
	iters: 200, epoch: 29 | loss: 0.2993908
	speed: 0.0105s/iter; left time: 177.7505s
Epoch: 29 cost time: 2.69602632522583
Epoch: 29, Steps: 239 Train Loss: 0.2965 (Forecasting Loss:0.2663 + XiCon Loss:3.0251 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2674
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.21019108593463898, mae:0.32458388805389404, mape:2.3907644748687744, mspe:3021.382080078125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5661
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6592023
	speed: 0.0129s/iter; left time: 308.1474s
	iters: 200, epoch: 1 | loss: 0.6022214
	speed: 0.0102s/iter; left time: 242.2247s
Epoch: 1 cost time: 2.7669074535369873
Epoch: 1, Steps: 239 Train Loss: 0.6475 (Forecasting Loss:0.6176 + XiCon Loss:2.9909 x Lambda(0.01)), Vali MSE Loss: 0.3184 Test MSE Loss: 0.4338
Validation loss decreased (inf --> 0.318375).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3492230
	speed: 0.0123s/iter; left time: 289.1117s
	iters: 200, epoch: 2 | loss: 0.3205495
	speed: 0.0096s/iter; left time: 225.8684s
Epoch: 2 cost time: 2.6130824089050293
Epoch: 2, Steps: 239 Train Loss: 0.3437 (Forecasting Loss:0.3139 + XiCon Loss:2.9795 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.2827
Validation loss decreased (0.318375 --> 0.207234).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3093323
	speed: 0.0126s/iter; left time: 292.8079s
	iters: 200, epoch: 3 | loss: 0.3295258
	speed: 0.0099s/iter; left time: 230.7606s
Epoch: 3 cost time: 2.6797292232513428
Epoch: 3, Steps: 239 Train Loss: 0.3073 (Forecasting Loss:0.2776 + XiCon Loss:2.9726 x Lambda(0.01)), Vali MSE Loss: 0.2012 Test MSE Loss: 0.2733
Validation loss decreased (0.207234 --> 0.201176).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2806216
	speed: 0.0129s/iter; left time: 296.8223s
	iters: 200, epoch: 4 | loss: 0.3538500
	speed: 0.0101s/iter; left time: 232.8894s
Epoch: 4 cost time: 2.7153618335723877
Epoch: 4, Steps: 239 Train Loss: 0.3003 (Forecasting Loss:0.2706 + XiCon Loss:2.9689 x Lambda(0.01)), Vali MSE Loss: 0.1952 Test MSE Loss: 0.2679
Validation loss decreased (0.201176 --> 0.195238).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3033247
	speed: 0.0128s/iter; left time: 292.3409s
	iters: 200, epoch: 5 | loss: 0.2851254
	speed: 0.0098s/iter; left time: 223.6961s
Epoch: 5 cost time: 2.6907315254211426
Epoch: 5, Steps: 239 Train Loss: 0.2968 (Forecasting Loss:0.2671 + XiCon Loss:2.9668 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.2670
Validation loss decreased (0.195238 --> 0.194927).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3074259
	speed: 0.0129s/iter; left time: 291.1467s
	iters: 200, epoch: 6 | loss: 0.2960843
	speed: 0.0108s/iter; left time: 242.6529s
Epoch: 6 cost time: 2.8282976150512695
Epoch: 6, Steps: 239 Train Loss: 0.2951 (Forecasting Loss:0.2654 + XiCon Loss:2.9638 x Lambda(0.01)), Vali MSE Loss: 0.1948 Test MSE Loss: 0.2654
Validation loss decreased (0.194927 --> 0.194826).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2969307
	speed: 0.0122s/iter; left time: 272.1510s
	iters: 200, epoch: 7 | loss: 0.2575196
	speed: 0.0098s/iter; left time: 218.7756s
Epoch: 7 cost time: 2.6090493202209473
Epoch: 7, Steps: 239 Train Loss: 0.2944 (Forecasting Loss:0.2648 + XiCon Loss:2.9645 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.2649
Validation loss decreased (0.194826 --> 0.193867).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2635734
	speed: 0.0121s/iter; left time: 267.6955s
	iters: 200, epoch: 8 | loss: 0.2820541
	speed: 0.0095s/iter; left time: 209.2737s
Epoch: 8 cost time: 2.585773229598999
Epoch: 8, Steps: 239 Train Loss: 0.2938 (Forecasting Loss:0.2641 + XiCon Loss:2.9676 x Lambda(0.01)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2649
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3020247
	speed: 0.0128s/iter; left time: 279.9307s
	iters: 200, epoch: 9 | loss: 0.2976080
	speed: 0.0099s/iter; left time: 215.3410s
Epoch: 9 cost time: 2.698065757751465
Epoch: 9, Steps: 239 Train Loss: 0.2934 (Forecasting Loss:0.2637 + XiCon Loss:2.9645 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
Validation loss decreased (0.193867 --> 0.193742).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3092285
	speed: 0.0120s/iter; left time: 258.7398s
	iters: 200, epoch: 10 | loss: 0.3071923
	speed: 0.0095s/iter; left time: 203.7087s
Epoch: 10 cost time: 2.5467193126678467
Epoch: 10, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2637 + XiCon Loss:2.9632 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3229233
	speed: 0.0132s/iter; left time: 283.1376s
	iters: 200, epoch: 11 | loss: 0.3011489
	speed: 0.0100s/iter; left time: 212.3924s
Epoch: 11 cost time: 2.7331671714782715
Epoch: 11, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2637 + XiCon Loss:2.9661 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
Validation loss decreased (0.193742 --> 0.193730).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3263939
	speed: 0.0122s/iter; left time: 259.2545s
	iters: 200, epoch: 12 | loss: 0.2637853
	speed: 0.0096s/iter; left time: 202.6724s
Epoch: 12 cost time: 2.6185710430145264
Epoch: 12, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2637 + XiCon Loss:2.9675 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193730 --> 0.193392).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2895169
	speed: 0.0125s/iter; left time: 260.8315s
	iters: 200, epoch: 13 | loss: 0.2759093
	speed: 0.0109s/iter; left time: 226.8552s
Epoch: 13 cost time: 2.806795835494995
Epoch: 13, Steps: 239 Train Loss: 0.2929 (Forecasting Loss:0.2633 + XiCon Loss:2.9638 x Lambda(0.01)), Vali MSE Loss: 0.1940 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2722589
	speed: 0.0125s/iter; left time: 258.0749s
	iters: 200, epoch: 14 | loss: 0.3062638
	speed: 0.0102s/iter; left time: 210.3635s
Epoch: 14 cost time: 2.7131783962249756
Epoch: 14, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2635 + XiCon Loss:2.9664 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2744453
	speed: 0.0122s/iter; left time: 249.6613s
	iters: 200, epoch: 15 | loss: 0.2850273
	speed: 0.0096s/iter; left time: 194.6894s
Epoch: 15 cost time: 2.590350866317749
Epoch: 15, Steps: 239 Train Loss: 0.2934 (Forecasting Loss:0.2637 + XiCon Loss:2.9633 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2677615
	speed: 0.0120s/iter; left time: 243.1698s
	iters: 200, epoch: 16 | loss: 0.2973495
	speed: 0.0090s/iter; left time: 181.9032s
Epoch: 16 cost time: 2.5326695442199707
Epoch: 16, Steps: 239 Train Loss: 0.2931 (Forecasting Loss:0.2635 + XiCon Loss:2.9653 x Lambda(0.01)), Vali MSE Loss: 0.1935 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2996725
	speed: 0.0126s/iter; left time: 251.7967s
	iters: 200, epoch: 17 | loss: 0.2748772
	speed: 0.0100s/iter; left time: 198.0346s
Epoch: 17 cost time: 2.7541372776031494
Epoch: 17, Steps: 239 Train Loss: 0.2937 (Forecasting Loss:0.2641 + XiCon Loss:2.9632 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2873195
	speed: 0.0125s/iter; left time: 246.5249s
	iters: 200, epoch: 18 | loss: 0.3025542
	speed: 0.0102s/iter; left time: 201.1436s
Epoch: 18 cost time: 2.690772771835327
Epoch: 18, Steps: 239 Train Loss: 0.2935 (Forecasting Loss:0.2638 + XiCon Loss:2.9653 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193392 --> 0.193388).  Saving model ...
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2817045
	speed: 0.0123s/iter; left time: 239.0584s
	iters: 200, epoch: 19 | loss: 0.3041389
	speed: 0.0102s/iter; left time: 197.1933s
Epoch: 19 cost time: 2.6433751583099365
Epoch: 19, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2636 + XiCon Loss:2.9668 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3158359
	speed: 0.0131s/iter; left time: 252.4328s
	iters: 200, epoch: 20 | loss: 0.2897028
	speed: 0.0105s/iter; left time: 202.1174s
Epoch: 20 cost time: 2.7634971141815186
Epoch: 20, Steps: 239 Train Loss: 0.2934 (Forecasting Loss:0.2637 + XiCon Loss:2.9665 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2901604
	speed: 0.0123s/iter; left time: 233.1589s
	iters: 200, epoch: 21 | loss: 0.3223405
	speed: 0.0097s/iter; left time: 182.6228s
Epoch: 21 cost time: 2.6382806301116943
Epoch: 21, Steps: 239 Train Loss: 0.2931 (Forecasting Loss:0.2634 + XiCon Loss:2.9658 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3070565
	speed: 0.0127s/iter; left time: 239.3187s
	iters: 200, epoch: 22 | loss: 0.3076387
	speed: 0.0109s/iter; left time: 203.6345s
Epoch: 22 cost time: 2.7924859523773193
Epoch: 22, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2636 + XiCon Loss:2.9644 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2658252
	speed: 0.0119s/iter; left time: 220.8694s
	iters: 200, epoch: 23 | loss: 0.2794345
	speed: 0.0101s/iter; left time: 186.9244s
Epoch: 23 cost time: 2.6208832263946533
Epoch: 23, Steps: 239 Train Loss: 0.2929 (Forecasting Loss:0.2632 + XiCon Loss:2.9674 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.3131981
	speed: 0.0122s/iter; left time: 224.2230s
	iters: 200, epoch: 24 | loss: 0.2895534
	speed: 0.0104s/iter; left time: 189.8706s
Epoch: 24 cost time: 2.6933815479278564
Epoch: 24, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2635 + XiCon Loss:2.9653 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
Validation loss decreased (0.193388 --> 0.193383).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2821129
	speed: 0.0125s/iter; left time: 226.1152s
	iters: 200, epoch: 25 | loss: 0.2922769
	speed: 0.0101s/iter; left time: 181.1539s
Epoch: 25 cost time: 2.6445343494415283
Epoch: 25, Steps: 239 Train Loss: 0.2931 (Forecasting Loss:0.2634 + XiCon Loss:2.9660 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2791077
	speed: 0.0124s/iter; left time: 220.5610s
	iters: 200, epoch: 26 | loss: 0.3001633
	speed: 0.0103s/iter; left time: 183.3277s
Epoch: 26 cost time: 2.729290723800659
Epoch: 26, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2635 + XiCon Loss:2.9665 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2887621
	speed: 0.0124s/iter; left time: 218.7851s
	iters: 200, epoch: 27 | loss: 0.2877974
	speed: 0.0109s/iter; left time: 191.0931s
Epoch: 27 cost time: 2.7594690322875977
Epoch: 27, Steps: 239 Train Loss: 0.2929 (Forecasting Loss:0.2632 + XiCon Loss:2.9672 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2791143
	speed: 0.0125s/iter; left time: 216.8433s
	iters: 200, epoch: 28 | loss: 0.2946790
	speed: 0.0103s/iter; left time: 178.2133s
Epoch: 28 cost time: 2.7097859382629395
Epoch: 28, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2636 + XiCon Loss:2.9630 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.3108159
	speed: 0.0124s/iter; left time: 212.7774s
	iters: 200, epoch: 29 | loss: 0.3062131
	speed: 0.0098s/iter; left time: 166.9832s
Epoch: 29 cost time: 2.6576285362243652
Epoch: 29, Steps: 239 Train Loss: 0.2927 (Forecasting Loss:0.2630 + XiCon Loss:2.9666 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.2620060
	speed: 0.0122s/iter; left time: 205.3593s
	iters: 200, epoch: 30 | loss: 0.2750702
	speed: 0.0099s/iter; left time: 165.8839s
Epoch: 30 cost time: 2.6012377738952637
Epoch: 30, Steps: 239 Train Loss: 0.2934 (Forecasting Loss:0.2638 + XiCon Loss:2.9642 x Lambda(0.01)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.2647
Validation loss decreased (0.193383 --> 0.193207).  Saving model ...
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3044200
	speed: 0.0127s/iter; left time: 211.0438s
	iters: 200, epoch: 31 | loss: 0.2724584
	speed: 0.0100s/iter; left time: 166.1106s
Epoch: 31 cost time: 2.7048163414001465
Epoch: 31, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2636 + XiCon Loss:2.9666 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.2647
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.2536954
	speed: 0.0130s/iter; left time: 213.1846s
	iters: 200, epoch: 32 | loss: 0.2615820
	speed: 0.0103s/iter; left time: 168.2508s
Epoch: 32 cost time: 2.7905466556549072
Epoch: 32, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2637 + XiCon Loss:2.9631 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 0.2842775
	speed: 0.0124s/iter; left time: 200.0278s
	iters: 200, epoch: 33 | loss: 0.3089489
	speed: 0.0101s/iter; left time: 161.6563s
Epoch: 33 cost time: 2.6620776653289795
Epoch: 33, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2636 + XiCon Loss:2.9634 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 0.2766870
	speed: 0.0126s/iter; left time: 200.7915s
	iters: 200, epoch: 34 | loss: 0.3423333
	speed: 0.0100s/iter; left time: 158.5331s
Epoch: 34 cost time: 2.6728458404541016
Epoch: 34, Steps: 239 Train Loss: 0.2930 (Forecasting Loss:0.2634 + XiCon Loss:2.9647 x Lambda(0.01)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.2647
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 0.2827189
	speed: 0.0122s/iter; left time: 191.7862s
	iters: 200, epoch: 35 | loss: 0.3263510
	speed: 0.0100s/iter; left time: 156.1566s
Epoch: 35 cost time: 2.626594305038452
Epoch: 35, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2637 + XiCon Loss:2.9654 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 0.2774139
	speed: 0.0124s/iter; left time: 190.9764s
	iters: 200, epoch: 36 | loss: 0.3086641
	speed: 0.0102s/iter; left time: 155.7756s
Epoch: 36 cost time: 2.6706554889678955
Epoch: 36, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2636 + XiCon Loss:2.9653 x Lambda(0.01)), Vali MSE Loss: 0.1938 Test MSE Loss: 0.2647
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 0.2824559
	speed: 0.0118s/iter; left time: 179.4804s
	iters: 200, epoch: 37 | loss: 0.3179605
	speed: 0.0103s/iter; left time: 155.5976s
Epoch: 37 cost time: 2.7009263038635254
Epoch: 37, Steps: 239 Train Loss: 0.2935 (Forecasting Loss:0.2638 + XiCon Loss:2.9653 x Lambda(0.01)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.2647
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 0.2790447
	speed: 0.0122s/iter; left time: 183.1692s
	iters: 200, epoch: 38 | loss: 0.3415803
	speed: 0.0095s/iter; left time: 140.7595s
Epoch: 38 cost time: 2.5992071628570557
Epoch: 38, Steps: 239 Train Loss: 0.2933 (Forecasting Loss:0.2636 + XiCon Loss:2.9647 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 0.2970612
	speed: 0.0123s/iter; left time: 181.6740s
	iters: 200, epoch: 39 | loss: 0.2871411
	speed: 0.0101s/iter; left time: 148.3147s
Epoch: 39 cost time: 2.708317756652832
Epoch: 39, Steps: 239 Train Loss: 0.2932 (Forecasting Loss:0.2636 + XiCon Loss:2.9652 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-15
	iters: 100, epoch: 40 | loss: 0.3003199
	speed: 0.0135s/iter; left time: 195.0974s
	iters: 200, epoch: 40 | loss: 0.2825422
	speed: 0.0102s/iter; left time: 146.0497s
Epoch: 40 cost time: 2.7955360412597656
Epoch: 40, Steps: 239 Train Loss: 0.2930 (Forecasting Loss:0.2633 + XiCon Loss:2.9644 x Lambda(0.01)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.2647
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.20759862661361694, mae:0.32172009348869324, mape:2.3990695476531982, mspe:3328.510009765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 15351
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3370
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 15351
val 5167
test 5165
	iters: 100, epoch: 1 | loss: 0.6375006
	speed: 0.0121s/iter; left time: 287.6885s
	iters: 200, epoch: 1 | loss: 0.5379612
	speed: 0.0104s/iter; left time: 247.1240s
Epoch: 1 cost time: 2.6835832595825195
Epoch: 1, Steps: 239 Train Loss: 0.6667 (Forecasting Loss:0.6367 + XiCon Loss:2.9965 x Lambda(0.01)), Vali MSE Loss: 0.3275 Test MSE Loss: 0.4405
Validation loss decreased (inf --> 0.327542).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3519899
	speed: 0.0133s/iter; left time: 312.6728s
	iters: 200, epoch: 2 | loss: 0.3176746
	speed: 0.0104s/iter; left time: 243.9788s
Epoch: 2 cost time: 2.7992746829986572
Epoch: 2, Steps: 239 Train Loss: 0.3464 (Forecasting Loss:0.3165 + XiCon Loss:2.9871 x Lambda(0.01)), Vali MSE Loss: 0.2067 Test MSE Loss: 0.2812
Validation loss decreased (0.327542 --> 0.206719).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3412048
	speed: 0.0130s/iter; left time: 303.5527s
	iters: 200, epoch: 3 | loss: 0.2942137
	speed: 0.0110s/iter; left time: 254.3040s
Epoch: 3 cost time: 2.796572685241699
Epoch: 3, Steps: 239 Train Loss: 0.3075 (Forecasting Loss:0.2777 + XiCon Loss:2.9860 x Lambda(0.01)), Vali MSE Loss: 0.1979 Test MSE Loss: 0.2705
Validation loss decreased (0.206719 --> 0.197879).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3002521
	speed: 0.0121s/iter; left time: 280.2010s
	iters: 200, epoch: 4 | loss: 0.2796459
	speed: 0.0102s/iter; left time: 235.1013s
Epoch: 4 cost time: 2.667363166809082
Epoch: 4, Steps: 239 Train Loss: 0.2985 (Forecasting Loss:0.2686 + XiCon Loss:2.9925 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.2668
Validation loss decreased (0.197879 --> 0.194354).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3445558
	speed: 0.0122s/iter; left time: 278.2227s
	iters: 200, epoch: 5 | loss: 0.3040633
	speed: 0.0103s/iter; left time: 235.0214s
Epoch: 5 cost time: 2.7282936573028564
Epoch: 5, Steps: 239 Train Loss: 0.2943 (Forecasting Loss:0.2643 + XiCon Loss:2.9997 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.2650
Validation loss decreased (0.194354 --> 0.192889).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2807373
	speed: 0.0125s/iter; left time: 282.7682s
	iters: 200, epoch: 6 | loss: 0.2697608
	speed: 0.0103s/iter; left time: 231.9029s
Epoch: 6 cost time: 2.7480950355529785
Epoch: 6, Steps: 239 Train Loss: 0.2922 (Forecasting Loss:0.2622 + XiCon Loss:3.0029 x Lambda(0.01)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.2633
Validation loss decreased (0.192889 --> 0.192106).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3136177
	speed: 0.0121s/iter; left time: 270.3478s
	iters: 200, epoch: 7 | loss: 0.2790939
	speed: 0.0103s/iter; left time: 229.4035s
Epoch: 7 cost time: 2.661562204360962
Epoch: 7, Steps: 239 Train Loss: 0.2912 (Forecasting Loss:0.2612 + XiCon Loss:3.0015 x Lambda(0.01)), Vali MSE Loss: 0.1917 Test MSE Loss: 0.2629
Validation loss decreased (0.192106 --> 0.191704).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3026387
	speed: 0.0124s/iter; left time: 274.0898s
	iters: 200, epoch: 8 | loss: 0.3292351
	speed: 0.0103s/iter; left time: 226.2268s
Epoch: 8 cost time: 2.670637369155884
Epoch: 8, Steps: 239 Train Loss: 0.2909 (Forecasting Loss:0.2609 + XiCon Loss:3.0043 x Lambda(0.01)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.2627
Validation loss decreased (0.191704 --> 0.191585).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2853501
	speed: 0.0122s/iter; left time: 267.9270s
	iters: 200, epoch: 9 | loss: 0.2669103
	speed: 0.0103s/iter; left time: 225.1085s
Epoch: 9 cost time: 2.6809444427490234
Epoch: 9, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2601 + XiCon Loss:3.0057 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2625
Validation loss decreased (0.191585 --> 0.191203).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2779729
	speed: 0.0117s/iter; left time: 253.9179s
	iters: 200, epoch: 10 | loss: 0.2832689
	speed: 0.0102s/iter; left time: 219.8658s
Epoch: 10 cost time: 2.617433786392212
Epoch: 10, Steps: 239 Train Loss: 0.2906 (Forecasting Loss:0.2605 + XiCon Loss:3.0075 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3017260
	speed: 0.0127s/iter; left time: 272.6620s
	iters: 200, epoch: 11 | loss: 0.3335269
	speed: 0.0106s/iter; left time: 225.9230s
Epoch: 11 cost time: 2.7833635807037354
Epoch: 11, Steps: 239 Train Loss: 0.2900 (Forecasting Loss:0.2600 + XiCon Loss:3.0077 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
Validation loss decreased (0.191203 --> 0.191174).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2934816
	speed: 0.0117s/iter; left time: 248.6280s
	iters: 200, epoch: 12 | loss: 0.2923836
	speed: 0.0103s/iter; left time: 217.7946s
Epoch: 12 cost time: 2.597943067550659
Epoch: 12, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2604 + XiCon Loss:3.0043 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3055283
	speed: 0.0124s/iter; left time: 259.5667s
	iters: 200, epoch: 13 | loss: 0.3131922
	speed: 0.0104s/iter; left time: 217.1426s
Epoch: 13 cost time: 2.718872547149658
Epoch: 13, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2602 + XiCon Loss:3.0087 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2689738
	speed: 0.0122s/iter; left time: 251.8459s
	iters: 200, epoch: 14 | loss: 0.2693774
	speed: 0.0096s/iter; left time: 198.0288s
Epoch: 14 cost time: 2.6055145263671875
Epoch: 14, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2602 + XiCon Loss:3.0084 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2881090
	speed: 0.0125s/iter; left time: 255.0518s
	iters: 200, epoch: 15 | loss: 0.3007482
	speed: 0.0099s/iter; left time: 201.6954s
Epoch: 15 cost time: 2.660700559616089
Epoch: 15, Steps: 239 Train Loss: 0.2905 (Forecasting Loss:0.2604 + XiCon Loss:3.0048 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2952679
	speed: 0.0124s/iter; left time: 249.9133s
	iters: 200, epoch: 16 | loss: 0.3252398
	speed: 0.0102s/iter; left time: 205.3538s
Epoch: 16 cost time: 2.67690372467041
Epoch: 16, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2602 + XiCon Loss:3.0043 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.3011750
	speed: 0.0123s/iter; left time: 245.9090s
	iters: 200, epoch: 17 | loss: 0.2936376
	speed: 0.0102s/iter; left time: 201.8048s
Epoch: 17 cost time: 2.673569679260254
Epoch: 17, Steps: 239 Train Loss: 0.2901 (Forecasting Loss:0.2601 + XiCon Loss:3.0044 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
Validation loss decreased (0.191174 --> 0.191161).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2954994
	speed: 0.0119s/iter; left time: 234.7448s
	iters: 200, epoch: 18 | loss: 0.2762408
	speed: 0.0092s/iter; left time: 180.2139s
Epoch: 18 cost time: 2.538111448287964
Epoch: 18, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2602 + XiCon Loss:3.0084 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.2937535
	speed: 0.0122s/iter; left time: 238.3423s
	iters: 200, epoch: 19 | loss: 0.3057536
	speed: 0.0101s/iter; left time: 196.8181s
Epoch: 19 cost time: 2.672912836074829
Epoch: 19, Steps: 239 Train Loss: 0.2900 (Forecasting Loss:0.2599 + XiCon Loss:3.0091 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3018858
	speed: 0.0120s/iter; left time: 231.8874s
	iters: 200, epoch: 20 | loss: 0.2393080
	speed: 0.0103s/iter; left time: 198.3009s
Epoch: 20 cost time: 2.637410879135132
Epoch: 20, Steps: 239 Train Loss: 0.2907 (Forecasting Loss:0.2607 + XiCon Loss:3.0065 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2908840
	speed: 0.0122s/iter; left time: 232.3971s
	iters: 200, epoch: 21 | loss: 0.2923212
	speed: 0.0103s/iter; left time: 194.6259s
Epoch: 21 cost time: 2.683236598968506
Epoch: 21, Steps: 239 Train Loss: 0.2906 (Forecasting Loss:0.2606 + XiCon Loss:3.0080 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
Validation loss decreased (0.191161 --> 0.191065).  Saving model ...
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2956946
	speed: 0.0130s/iter; left time: 244.1964s
	iters: 200, epoch: 22 | loss: 0.3073183
	speed: 0.0095s/iter; left time: 177.6051s
Epoch: 22 cost time: 2.67407488822937
Epoch: 22, Steps: 239 Train Loss: 0.2901 (Forecasting Loss:0.2601 + XiCon Loss:3.0055 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2956315
	speed: 0.0119s/iter; left time: 220.5149s
	iters: 200, epoch: 23 | loss: 0.2788381
	speed: 0.0106s/iter; left time: 194.6544s
Epoch: 23 cost time: 2.6714775562286377
Epoch: 23, Steps: 239 Train Loss: 0.2898 (Forecasting Loss:0.2598 + XiCon Loss:3.0045 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.3000927
	speed: 0.0122s/iter; left time: 224.0712s
	iters: 200, epoch: 24 | loss: 0.2626055
	speed: 0.0104s/iter; left time: 188.8555s
Epoch: 24 cost time: 2.703136682510376
Epoch: 24, Steps: 239 Train Loss: 0.2901 (Forecasting Loss:0.2601 + XiCon Loss:3.0026 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.2643164
	speed: 0.0121s/iter; left time: 218.7015s
	iters: 200, epoch: 25 | loss: 0.2827213
	speed: 0.0099s/iter; left time: 177.0964s
Epoch: 25 cost time: 2.6202189922332764
Epoch: 25, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2603 + XiCon Loss:3.0042 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2550594
	speed: 0.0123s/iter; left time: 219.4499s
	iters: 200, epoch: 26 | loss: 0.2948248
	speed: 0.0102s/iter; left time: 181.5791s
Epoch: 26 cost time: 2.6833138465881348
Epoch: 26, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2603 + XiCon Loss:3.0057 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2598295
	speed: 0.0121s/iter; left time: 212.5650s
	iters: 200, epoch: 27 | loss: 0.3122914
	speed: 0.0105s/iter; left time: 182.7559s
Epoch: 27 cost time: 2.667954206466675
Epoch: 27, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2601 + XiCon Loss:3.0047 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2896472
	speed: 0.0118s/iter; left time: 203.8854s
	iters: 200, epoch: 28 | loss: 0.3035063
	speed: 0.0099s/iter; left time: 171.3055s
Epoch: 28 cost time: 2.6578469276428223
Epoch: 28, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2604 + XiCon Loss:3.0037 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.2751290
	speed: 0.0122s/iter; left time: 208.6468s
	iters: 200, epoch: 29 | loss: 0.2888445
	speed: 0.0097s/iter; left time: 164.8386s
Epoch: 29 cost time: 2.577033758163452
Epoch: 29, Steps: 239 Train Loss: 0.2904 (Forecasting Loss:0.2603 + XiCon Loss:3.0050 x Lambda(0.01)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.2624
Validation loss decreased (0.191065 --> 0.190920).  Saving model ...
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.3113157
	speed: 0.0120s/iter; left time: 202.7010s
	iters: 200, epoch: 30 | loss: 0.2844313
	speed: 0.0100s/iter; left time: 167.4158s
Epoch: 30 cost time: 2.6126816272735596
Epoch: 30, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2602 + XiCon Loss:3.0054 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3118741
	speed: 0.0124s/iter; left time: 205.8857s
	iters: 200, epoch: 31 | loss: 0.2983349
	speed: 0.0102s/iter; left time: 169.1508s
Epoch: 31 cost time: 2.679326295852661
Epoch: 31, Steps: 239 Train Loss: 0.2901 (Forecasting Loss:0.2601 + XiCon Loss:3.0052 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.3379847
	speed: 0.0128s/iter; left time: 209.4006s
	iters: 200, epoch: 32 | loss: 0.2650136
	speed: 0.0100s/iter; left time: 163.6924s
Epoch: 32 cost time: 2.7324979305267334
Epoch: 32, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2601 + XiCon Loss:3.0068 x Lambda(0.01)), Vali MSE Loss: 0.1914 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 33 | loss: 0.3012319
	speed: 0.0124s/iter; left time: 199.8203s
	iters: 200, epoch: 33 | loss: 0.2628904
	speed: 0.0104s/iter; left time: 167.4225s
Epoch: 33 cost time: 2.721904754638672
Epoch: 33, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2602 + XiCon Loss:3.0039 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 34 | loss: 0.2869925
	speed: 0.0124s/iter; left time: 198.0196s
	iters: 200, epoch: 34 | loss: 0.2553766
	speed: 0.0100s/iter; left time: 158.1120s
Epoch: 34 cost time: 2.6656620502471924
Epoch: 34, Steps: 239 Train Loss: 0.2902 (Forecasting Loss:0.2602 + XiCon Loss:3.0062 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1641532182693482e-13
	iters: 100, epoch: 35 | loss: 0.2642314
	speed: 0.0131s/iter; left time: 205.3890s
	iters: 200, epoch: 35 | loss: 0.2908182
	speed: 0.0101s/iter; left time: 157.4024s
Epoch: 35 cost time: 2.7417211532592773
Epoch: 35, Steps: 239 Train Loss: 0.2900 (Forecasting Loss:0.2600 + XiCon Loss:3.0041 x Lambda(0.01)), Vali MSE Loss: 0.1912 Test MSE Loss: 0.2624
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.820766091346741e-14
	iters: 100, epoch: 36 | loss: 0.3016139
	speed: 0.0122s/iter; left time: 187.5950s
	iters: 200, epoch: 36 | loss: 0.2858496
	speed: 0.0103s/iter; left time: 158.6151s
Epoch: 36 cost time: 2.6770520210266113
Epoch: 36, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2603 + XiCon Loss:3.0064 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.2624
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9103830456733704e-14
	iters: 100, epoch: 37 | loss: 0.2858945
	speed: 0.0129s/iter; left time: 195.8551s
	iters: 200, epoch: 37 | loss: 0.2967985
	speed: 0.0106s/iter; left time: 159.8920s
Epoch: 37 cost time: 2.7575769424438477
Epoch: 37, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2603 + XiCon Loss:3.0036 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4551915228366852e-14
	iters: 100, epoch: 38 | loss: 0.2649151
	speed: 0.0127s/iter; left time: 190.5432s
	iters: 200, epoch: 38 | loss: 0.3125496
	speed: 0.0095s/iter; left time: 141.8885s
Epoch: 38 cost time: 2.661120891571045
Epoch: 38, Steps: 239 Train Loss: 0.2903 (Forecasting Loss:0.2602 + XiCon Loss:3.0048 x Lambda(0.01)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.2624
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.275957614183426e-15
	iters: 100, epoch: 39 | loss: 0.3358999
	speed: 0.0121s/iter; left time: 177.4128s
	iters: 200, epoch: 39 | loss: 0.3094587
	speed: 0.0109s/iter; left time: 158.9314s
Epoch: 39 cost time: 2.7478790283203125
Epoch: 39, Steps: 239 Train Loss: 0.2900 (Forecasting Loss:0.2599 + XiCon Loss:3.0064 x Lambda(0.01)), Vali MSE Loss: 0.1911 Test MSE Loss: 0.2624
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 5165
test shape: (80, 64, 96, 1) (80, 64, 96, 1)
test shape: (5120, 96, 1) (5120, 96, 1)
mse:0.205026313662529, mae:0.3197873830795288, mape:2.4717864990234375, mspe:4039.04052734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2065+-0.00319, MAE:0.3214+-0.00241, MAPE:2.4272+-0.09923, MSPE:3627.9995+-796.42234, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4800
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6911650
	speed: 0.0169s/iter; left time: 388.0358s
	iters: 200, epoch: 1 | loss: 3.5976229
	speed: 0.0111s/iter; left time: 253.7466s
Epoch: 1 cost time: 3.1804099082946777
Epoch: 1, Steps: 230 Train Loss: 3.6710 (Forecasting Loss:0.7227 + XiCon Loss:2.9483 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.5301
Validation loss decreased (inf --> 0.330920).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.1948469
	speed: 0.0138s/iter; left time: 312.3054s
	iters: 200, epoch: 2 | loss: 3.1336315
	speed: 0.0116s/iter; left time: 262.5972s
Epoch: 2 cost time: 2.919703245162964
Epoch: 2, Steps: 230 Train Loss: 3.2679 (Forecasting Loss:0.4231 + XiCon Loss:2.8447 x Lambda(1.0)), Vali MSE Loss: 0.2160 Test MSE Loss: 0.3764
Validation loss decreased (0.330920 --> 0.216035).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1629992
	speed: 0.0144s/iter; left time: 323.9329s
	iters: 200, epoch: 3 | loss: 3.1489830
	speed: 0.0119s/iter; left time: 265.3033s
Epoch: 3 cost time: 3.017244338989258
Epoch: 3, Steps: 230 Train Loss: 3.1536 (Forecasting Loss:0.3798 + XiCon Loss:2.7738 x Lambda(1.0)), Vali MSE Loss: 0.2057 Test MSE Loss: 0.3655
Validation loss decreased (0.216035 --> 0.205681).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1179523
	speed: 0.0136s/iter; left time: 301.4801s
	iters: 200, epoch: 4 | loss: 3.1436365
	speed: 0.0116s/iter; left time: 255.4429s
Epoch: 4 cost time: 2.894859790802002
Epoch: 4, Steps: 230 Train Loss: 3.1349 (Forecasting Loss:0.3715 + XiCon Loss:2.7634 x Lambda(1.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.3620
Validation loss decreased (0.205681 --> 0.203699).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2064953
	speed: 0.0141s/iter; left time: 308.9789s
	iters: 200, epoch: 5 | loss: 3.1191294
	speed: 0.0114s/iter; left time: 248.5734s
Epoch: 5 cost time: 2.93949031829834
Epoch: 5, Steps: 230 Train Loss: 3.1293 (Forecasting Loss:0.3683 + XiCon Loss:2.7611 x Lambda(1.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.3618
Validation loss decreased (0.203699 --> 0.203202).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1664448
	speed: 0.0140s/iter; left time: 303.9726s
	iters: 200, epoch: 6 | loss: 3.1496115
	speed: 0.0117s/iter; left time: 253.6618s
Epoch: 6 cost time: 2.9420487880706787
Epoch: 6, Steps: 230 Train Loss: 3.1267 (Forecasting Loss:0.3665 + XiCon Loss:2.7602 x Lambda(1.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.3598
Validation loss decreased (0.203202 --> 0.202686).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1569090
	speed: 0.0146s/iter; left time: 313.9632s
	iters: 200, epoch: 7 | loss: 3.1299934
	speed: 0.0125s/iter; left time: 267.3541s
Epoch: 7 cost time: 3.1121654510498047
Epoch: 7, Steps: 230 Train Loss: 3.1242 (Forecasting Loss:0.3655 + XiCon Loss:2.7588 x Lambda(1.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.3586
Validation loss decreased (0.202686 --> 0.202565).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1821489
	speed: 0.0138s/iter; left time: 293.1935s
	iters: 200, epoch: 8 | loss: 3.1404686
	speed: 0.0117s/iter; left time: 247.8122s
Epoch: 8 cost time: 2.9379162788391113
Epoch: 8, Steps: 230 Train Loss: 3.1255 (Forecasting Loss:0.3647 + XiCon Loss:2.7607 x Lambda(1.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.3579
Validation loss decreased (0.202565 --> 0.202303).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1087968
	speed: 0.0144s/iter; left time: 302.6699s
	iters: 200, epoch: 9 | loss: 3.1442475
	speed: 0.0120s/iter; left time: 252.0714s
Epoch: 9 cost time: 3.0166125297546387
Epoch: 9, Steps: 230 Train Loss: 3.1225 (Forecasting Loss:0.3645 + XiCon Loss:2.7580 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
Validation loss decreased (0.202303 --> 0.202095).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0954297
	speed: 0.0140s/iter; left time: 292.1101s
	iters: 200, epoch: 10 | loss: 3.1621220
	speed: 0.0117s/iter; left time: 243.5820s
Epoch: 10 cost time: 2.9551572799682617
Epoch: 10, Steps: 230 Train Loss: 3.1222 (Forecasting Loss:0.3643 + XiCon Loss:2.7578 x Lambda(1.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.3580
Validation loss decreased (0.202095 --> 0.202032).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.0707669
	speed: 0.0143s/iter; left time: 293.7740s
	iters: 200, epoch: 11 | loss: 3.1160450
	speed: 0.0124s/iter; left time: 253.9250s
Epoch: 11 cost time: 3.068100690841675
Epoch: 11, Steps: 230 Train Loss: 3.1202 (Forecasting Loss:0.3640 + XiCon Loss:2.7563 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3580
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.0976009
	speed: 0.0143s/iter; left time: 290.7723s
	iters: 200, epoch: 12 | loss: 3.1343219
	speed: 0.0119s/iter; left time: 240.4405s
Epoch: 12 cost time: 3.005782127380371
Epoch: 12, Steps: 230 Train Loss: 3.1248 (Forecasting Loss:0.3652 + XiCon Loss:2.7596 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1033561
	speed: 0.0136s/iter; left time: 273.0697s
	iters: 200, epoch: 13 | loss: 3.0848699
	speed: 0.0118s/iter; left time: 236.5650s
Epoch: 13 cost time: 2.89135479927063
Epoch: 13, Steps: 230 Train Loss: 3.1197 (Forecasting Loss:0.3646 + XiCon Loss:2.7551 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3580
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1265211
	speed: 0.0146s/iter; left time: 291.6267s
	iters: 200, epoch: 14 | loss: 3.1250565
	speed: 0.0114s/iter; left time: 225.7914s
Epoch: 14 cost time: 2.9597301483154297
Epoch: 14, Steps: 230 Train Loss: 3.1218 (Forecasting Loss:0.3641 + XiCon Loss:2.7578 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3579
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1416636
	speed: 0.0141s/iter; left time: 277.6102s
	iters: 200, epoch: 15 | loss: 3.0917377
	speed: 0.0120s/iter; left time: 233.9997s
Epoch: 15 cost time: 3.0219509601593018
Epoch: 15, Steps: 230 Train Loss: 3.1228 (Forecasting Loss:0.3646 + XiCon Loss:2.7581 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3579
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1226630
	speed: 0.0147s/iter; left time: 286.3804s
	iters: 200, epoch: 16 | loss: 3.1008284
	speed: 0.0117s/iter; left time: 226.4322s
Epoch: 16 cost time: 3.0262248516082764
Epoch: 16, Steps: 230 Train Loss: 3.1208 (Forecasting Loss:0.3646 + XiCon Loss:2.7562 x Lambda(1.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.3579
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.0839615
	speed: 0.0144s/iter; left time: 276.1415s
	iters: 200, epoch: 17 | loss: 3.1129031
	speed: 0.0116s/iter; left time: 221.6509s
Epoch: 17 cost time: 2.98067569732666
Epoch: 17, Steps: 230 Train Loss: 3.1230 (Forecasting Loss:0.3642 + XiCon Loss:2.7588 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3579
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.0952239
	speed: 0.0142s/iter; left time: 270.2476s
	iters: 200, epoch: 18 | loss: 3.1734297
	speed: 0.0116s/iter; left time: 220.0309s
Epoch: 18 cost time: 2.9675991535186768
Epoch: 18, Steps: 230 Train Loss: 3.1223 (Forecasting Loss:0.3640 + XiCon Loss:2.7583 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3579
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.0793939
	speed: 0.0141s/iter; left time: 263.7055s
	iters: 200, epoch: 19 | loss: 3.1077983
	speed: 0.0117s/iter; left time: 218.8309s
Epoch: 19 cost time: 2.9537601470947266
Epoch: 19, Steps: 230 Train Loss: 3.1220 (Forecasting Loss:0.3644 + XiCon Loss:2.7576 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3579
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.0859537
	speed: 0.0138s/iter; left time: 255.4374s
	iters: 200, epoch: 20 | loss: 3.1623533
	speed: 0.0115s/iter; left time: 211.6082s
Epoch: 20 cost time: 2.900876998901367
Epoch: 20, Steps: 230 Train Loss: 3.1244 (Forecasting Loss:0.3644 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2021 Test MSE Loss: 0.3579
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.30776986479759216, mae:0.4081912338733673, mape:4.268780708312988, mspe:28454.13671875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3590
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.7648876
	speed: 0.0149s/iter; left time: 340.8950s
	iters: 200, epoch: 1 | loss: 3.5402246
	speed: 0.0114s/iter; left time: 260.6154s
Epoch: 1 cost time: 3.0162365436553955
Epoch: 1, Steps: 230 Train Loss: 3.6974 (Forecasting Loss:0.7213 + XiCon Loss:2.9761 x Lambda(1.0)), Vali MSE Loss: 0.3289 Test MSE Loss: 0.5349
Validation loss decreased (inf --> 0.328931).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3119864
	speed: 0.0144s/iter; left time: 326.3006s
	iters: 200, epoch: 2 | loss: 3.1823456
	speed: 0.0118s/iter; left time: 266.5747s
Epoch: 2 cost time: 3.0074219703674316
Epoch: 2, Steps: 230 Train Loss: 3.2731 (Forecasting Loss:0.4222 + XiCon Loss:2.8509 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.3642
Validation loss decreased (0.328931 --> 0.213129).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1601143
	speed: 0.0142s/iter; left time: 319.4378s
	iters: 200, epoch: 3 | loss: 3.1831126
	speed: 0.0123s/iter; left time: 274.4744s
Epoch: 3 cost time: 3.0452847480773926
Epoch: 3, Steps: 230 Train Loss: 3.1538 (Forecasting Loss:0.3755 + XiCon Loss:2.7783 x Lambda(1.0)), Vali MSE Loss: 0.2064 Test MSE Loss: 0.3547
Validation loss decreased (0.213129 --> 0.206370).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1659701
	speed: 0.0143s/iter; left time: 317.6755s
	iters: 200, epoch: 4 | loss: 3.1731806
	speed: 0.0120s/iter; left time: 264.5736s
Epoch: 4 cost time: 3.011875629425049
Epoch: 4, Steps: 230 Train Loss: 3.1385 (Forecasting Loss:0.3667 + XiCon Loss:2.7718 x Lambda(1.0)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.3509
Validation loss decreased (0.206370 --> 0.204788).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1189485
	speed: 0.0135s/iter; left time: 297.7136s
	iters: 200, epoch: 5 | loss: 3.0813758
	speed: 0.0121s/iter; left time: 263.8375s
Epoch: 5 cost time: 2.9434337615966797
Epoch: 5, Steps: 230 Train Loss: 3.1315 (Forecasting Loss:0.3628 + XiCon Loss:2.7687 x Lambda(1.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.3484
Validation loss decreased (0.204788 --> 0.204317).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1207561
	speed: 0.0145s/iter; left time: 314.8267s
	iters: 200, epoch: 6 | loss: 3.1073232
	speed: 0.0120s/iter; left time: 260.3805s
Epoch: 6 cost time: 3.0347838401794434
Epoch: 6, Steps: 230 Train Loss: 3.1282 (Forecasting Loss:0.3601 + XiCon Loss:2.7680 x Lambda(1.0)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.3473
Validation loss decreased (0.204317 --> 0.203642).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1366773
	speed: 0.0140s/iter; left time: 302.3382s
	iters: 200, epoch: 7 | loss: 3.1637807
	speed: 0.0117s/iter; left time: 250.5170s
Epoch: 7 cost time: 2.9521570205688477
Epoch: 7, Steps: 230 Train Loss: 3.1259 (Forecasting Loss:0.3594 + XiCon Loss:2.7665 x Lambda(1.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.3477
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1281607
	speed: 0.0138s/iter; left time: 294.6102s
	iters: 200, epoch: 8 | loss: 3.1426191
	speed: 0.0121s/iter; left time: 255.9931s
Epoch: 8 cost time: 2.9686970710754395
Epoch: 8, Steps: 230 Train Loss: 3.1249 (Forecasting Loss:0.3586 + XiCon Loss:2.7664 x Lambda(1.0)), Vali MSE Loss: 0.2052 Test MSE Loss: 0.3478
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1037691
	speed: 0.0145s/iter; left time: 306.2704s
	iters: 200, epoch: 9 | loss: 3.0845633
	speed: 0.0119s/iter; left time: 249.6039s
Epoch: 9 cost time: 3.0066845417022705
Epoch: 9, Steps: 230 Train Loss: 3.1223 (Forecasting Loss:0.3584 + XiCon Loss:2.7639 x Lambda(1.0)), Vali MSE Loss: 0.2044 Test MSE Loss: 0.3473
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.0670433
	speed: 0.0139s/iter; left time: 289.3581s
	iters: 200, epoch: 10 | loss: 3.1173303
	speed: 0.0112s/iter; left time: 232.6615s
Epoch: 10 cost time: 2.882805585861206
Epoch: 10, Steps: 230 Train Loss: 3.1192 (Forecasting Loss:0.3584 + XiCon Loss:2.7607 x Lambda(1.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.3472
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1167359
	speed: 0.0139s/iter; left time: 285.7162s
	iters: 200, epoch: 11 | loss: 3.1701059
	speed: 0.0116s/iter; left time: 237.0330s
Epoch: 11 cost time: 2.9378318786621094
Epoch: 11, Steps: 230 Train Loss: 3.1206 (Forecasting Loss:0.3578 + XiCon Loss:2.7628 x Lambda(1.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.3472
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1443887
	speed: 0.0140s/iter; left time: 284.6915s
	iters: 200, epoch: 12 | loss: 3.1271186
	speed: 0.0115s/iter; left time: 232.8685s
Epoch: 12 cost time: 2.9289376735687256
Epoch: 12, Steps: 230 Train Loss: 3.1218 (Forecasting Loss:0.3583 + XiCon Loss:2.7635 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.3472
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1183758
	speed: 0.0143s/iter; left time: 287.4449s
	iters: 200, epoch: 13 | loss: 3.1448824
	speed: 0.0112s/iter; left time: 224.2787s
Epoch: 13 cost time: 2.919487476348877
Epoch: 13, Steps: 230 Train Loss: 3.1223 (Forecasting Loss:0.3581 + XiCon Loss:2.7642 x Lambda(1.0)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.3472
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1065300
	speed: 0.0143s/iter; left time: 284.7166s
	iters: 200, epoch: 14 | loss: 3.1113322
	speed: 0.0114s/iter; left time: 226.3580s
Epoch: 14 cost time: 2.928985118865967
Epoch: 14, Steps: 230 Train Loss: 3.1228 (Forecasting Loss:0.3583 + XiCon Loss:2.7645 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.3472
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1206107
	speed: 0.0146s/iter; left time: 286.4825s
	iters: 200, epoch: 15 | loss: 3.1776018
	speed: 0.0115s/iter; left time: 225.5820s
Epoch: 15 cost time: 3.0402672290802
Epoch: 15, Steps: 230 Train Loss: 3.1239 (Forecasting Loss:0.3584 + XiCon Loss:2.7654 x Lambda(1.0)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.3472
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1684179
	speed: 0.0140s/iter; left time: 273.2514s
	iters: 200, epoch: 16 | loss: 3.0554407
	speed: 0.0115s/iter; left time: 222.4273s
Epoch: 16 cost time: 2.9313440322875977
Epoch: 16, Steps: 230 Train Loss: 3.1237 (Forecasting Loss:0.3584 + XiCon Loss:2.7653 x Lambda(1.0)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.3472
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.29486528038978577, mae:0.39979901909828186, mape:4.062678337097168, mspe:25814.94921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3402
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.7361894
	speed: 0.0144s/iter; left time: 330.5318s
	iters: 200, epoch: 1 | loss: 3.5822380
	speed: 0.0121s/iter; left time: 276.7866s
Epoch: 1 cost time: 3.055996894836426
Epoch: 1, Steps: 230 Train Loss: 3.6818 (Forecasting Loss:0.7257 + XiCon Loss:2.9562 x Lambda(1.0)), Vali MSE Loss: 0.3316 Test MSE Loss: 0.5382
Validation loss decreased (inf --> 0.331612).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2464621
	speed: 0.0143s/iter; left time: 323.6533s
	iters: 200, epoch: 2 | loss: 3.1757452
	speed: 0.0118s/iter; left time: 266.0566s
Epoch: 2 cost time: 3.001734733581543
Epoch: 2, Steps: 230 Train Loss: 3.2716 (Forecasting Loss:0.4349 + XiCon Loss:2.8366 x Lambda(1.0)), Vali MSE Loss: 0.2206 Test MSE Loss: 0.3895
Validation loss decreased (0.331612 --> 0.220566).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1137180
	speed: 0.0141s/iter; left time: 316.6141s
	iters: 200, epoch: 3 | loss: 3.1515441
	speed: 0.0114s/iter; left time: 255.5994s
Epoch: 3 cost time: 2.9285147190093994
Epoch: 3, Steps: 230 Train Loss: 3.1647 (Forecasting Loss:0.3945 + XiCon Loss:2.7702 x Lambda(1.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.3802
Validation loss decreased (0.220566 --> 0.215710).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1680138
	speed: 0.0139s/iter; left time: 308.8729s
	iters: 200, epoch: 4 | loss: 3.1373062
	speed: 0.0115s/iter; left time: 253.3955s
Epoch: 4 cost time: 2.905916213989258
Epoch: 4, Steps: 230 Train Loss: 3.1432 (Forecasting Loss:0.3795 + XiCon Loss:2.7637 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.3691
Validation loss decreased (0.215710 --> 0.210036).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1316457
	speed: 0.0142s/iter; left time: 312.8801s
	iters: 200, epoch: 5 | loss: 3.1552393
	speed: 0.0114s/iter; left time: 249.2941s
Epoch: 5 cost time: 2.930532693862915
Epoch: 5, Steps: 230 Train Loss: 3.1329 (Forecasting Loss:0.3704 + XiCon Loss:2.7625 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.3694
Validation loss decreased (0.210036 --> 0.209559).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1333814
	speed: 0.0147s/iter; left time: 318.6564s
	iters: 200, epoch: 6 | loss: 3.1618962
	speed: 0.0120s/iter; left time: 260.8734s
Epoch: 6 cost time: 3.054219961166382
Epoch: 6, Steps: 230 Train Loss: 3.1311 (Forecasting Loss:0.3668 + XiCon Loss:2.7642 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.3672
Validation loss decreased (0.209559 --> 0.208885).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.0908978
	speed: 0.0147s/iter; left time: 315.4716s
	iters: 200, epoch: 7 | loss: 3.1579146
	speed: 0.0120s/iter; left time: 257.5533s
Epoch: 7 cost time: 3.05507755279541
Epoch: 7, Steps: 230 Train Loss: 3.1257 (Forecasting Loss:0.3657 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3671
Validation loss decreased (0.208885 --> 0.208623).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1399450
	speed: 0.0143s/iter; left time: 303.5492s
	iters: 200, epoch: 8 | loss: 3.0943360
	speed: 0.0117s/iter; left time: 247.2645s
Epoch: 8 cost time: 2.9861276149749756
Epoch: 8, Steps: 230 Train Loss: 3.1247 (Forecasting Loss:0.3651 + XiCon Loss:2.7596 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3675
Validation loss decreased (0.208623 --> 0.208599).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1736217
	speed: 0.0141s/iter; left time: 297.6143s
	iters: 200, epoch: 9 | loss: 3.1681838
	speed: 0.0121s/iter; left time: 253.5040s
Epoch: 9 cost time: 2.993199110031128
Epoch: 9, Steps: 230 Train Loss: 3.1232 (Forecasting Loss:0.3650 + XiCon Loss:2.7582 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3677
Validation loss decreased (0.208599 --> 0.208556).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1414502
	speed: 0.0144s/iter; left time: 299.8897s
	iters: 200, epoch: 10 | loss: 3.1652920
	speed: 0.0116s/iter; left time: 240.8978s
Epoch: 10 cost time: 2.9904327392578125
Epoch: 10, Steps: 230 Train Loss: 3.1252 (Forecasting Loss:0.3643 + XiCon Loss:2.7610 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.3675
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1265821
	speed: 0.0142s/iter; left time: 292.1592s
	iters: 200, epoch: 11 | loss: 3.1067832
	speed: 0.0116s/iter; left time: 237.7131s
Epoch: 11 cost time: 2.9544754028320312
Epoch: 11, Steps: 230 Train Loss: 3.1218 (Forecasting Loss:0.3642 + XiCon Loss:2.7575 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1802294
	speed: 0.0143s/iter; left time: 291.3024s
	iters: 200, epoch: 12 | loss: 3.1185017
	speed: 0.0119s/iter; left time: 240.5884s
Epoch: 12 cost time: 2.974341869354248
Epoch: 12, Steps: 230 Train Loss: 3.1235 (Forecasting Loss:0.3645 + XiCon Loss:2.7590 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
Validation loss decreased (0.208556 --> 0.208555).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1298263
	speed: 0.0142s/iter; left time: 285.3567s
	iters: 200, epoch: 13 | loss: 3.1174026
	speed: 0.0113s/iter; left time: 226.8093s
Epoch: 13 cost time: 2.919701337814331
Epoch: 13, Steps: 230 Train Loss: 3.1244 (Forecasting Loss:0.3644 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.3673
Validation loss decreased (0.208555 --> 0.208535).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1055374
	speed: 0.0136s/iter; left time: 270.0937s
	iters: 200, epoch: 14 | loss: 3.1109087
	speed: 0.0114s/iter; left time: 226.5933s
Epoch: 14 cost time: 2.8704612255096436
Epoch: 14, Steps: 230 Train Loss: 3.1229 (Forecasting Loss:0.3641 + XiCon Loss:2.7587 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3673
Validation loss decreased (0.208535 --> 0.208411).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1152439
	speed: 0.0139s/iter; left time: 273.6759s
	iters: 200, epoch: 15 | loss: 3.1181347
	speed: 0.0116s/iter; left time: 226.5321s
Epoch: 15 cost time: 2.9206624031066895
Epoch: 15, Steps: 230 Train Loss: 3.1246 (Forecasting Loss:0.3638 + XiCon Loss:2.7609 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3673
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.0571709
	speed: 0.0149s/iter; left time: 289.8612s
	iters: 200, epoch: 16 | loss: 3.0666337
	speed: 0.0113s/iter; left time: 218.4335s
Epoch: 16 cost time: 2.990870237350464
Epoch: 16, Steps: 230 Train Loss: 3.1228 (Forecasting Loss:0.3644 + XiCon Loss:2.7584 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3674
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.0889020
	speed: 0.0140s/iter; left time: 268.1915s
	iters: 200, epoch: 17 | loss: 3.1111934
	speed: 0.0118s/iter; left time: 226.4391s
Epoch: 17 cost time: 2.9607274532318115
Epoch: 17, Steps: 230 Train Loss: 3.1224 (Forecasting Loss:0.3643 + XiCon Loss:2.7581 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3674
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.0679610
	speed: 0.0141s/iter; left time: 268.5225s
	iters: 200, epoch: 18 | loss: 3.1042569
	speed: 0.0120s/iter; left time: 227.1684s
Epoch: 18 cost time: 3.0075790882110596
Epoch: 18, Steps: 230 Train Loss: 3.1268 (Forecasting Loss:0.3632 + XiCon Loss:2.7635 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3674
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.0866392
	speed: 0.0149s/iter; left time: 279.8087s
	iters: 200, epoch: 19 | loss: 3.1636155
	speed: 0.0118s/iter; left time: 219.9895s
Epoch: 19 cost time: 3.0556201934814453
Epoch: 19, Steps: 230 Train Loss: 3.1239 (Forecasting Loss:0.3641 + XiCon Loss:2.7598 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3674
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1153381
	speed: 0.0138s/iter; left time: 255.9985s
	iters: 200, epoch: 20 | loss: 3.1168799
	speed: 0.0120s/iter; left time: 221.9885s
Epoch: 20 cost time: 2.979069948196411
Epoch: 20, Steps: 230 Train Loss: 3.1217 (Forecasting Loss:0.3642 + XiCon Loss:2.7575 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.3674
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1151521
	speed: 0.0148s/iter; left time: 270.8446s
	iters: 200, epoch: 21 | loss: 3.1327846
	speed: 0.0115s/iter; left time: 209.0576s
Epoch: 21 cost time: 3.000105857849121
Epoch: 21, Steps: 230 Train Loss: 3.1224 (Forecasting Loss:0.3640 + XiCon Loss:2.7584 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3674
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1173985
	speed: 0.0142s/iter; left time: 255.7850s
	iters: 200, epoch: 22 | loss: 3.1012540
	speed: 0.0120s/iter; left time: 215.6362s
Epoch: 22 cost time: 2.992908000946045
Epoch: 22, Steps: 230 Train Loss: 3.1239 (Forecasting Loss:0.3640 + XiCon Loss:2.7600 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3674
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.1162555
	speed: 0.0145s/iter; left time: 258.6368s
	iters: 200, epoch: 23 | loss: 3.1159282
	speed: 0.0118s/iter; left time: 208.7560s
Epoch: 23 cost time: 2.9941160678863525
Epoch: 23, Steps: 230 Train Loss: 3.1224 (Forecasting Loss:0.3640 + XiCon Loss:2.7585 x Lambda(1.0)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.3674
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.1511538
	speed: 0.0137s/iter; left time: 240.8683s
	iters: 200, epoch: 24 | loss: 3.1357963
	speed: 0.0117s/iter; left time: 204.2835s
Epoch: 24 cost time: 2.9165847301483154
Epoch: 24, Steps: 230 Train Loss: 3.1243 (Forecasting Loss:0.3642 + XiCon Loss:2.7601 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.3674
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.31900638341903687, mae:0.41567492485046387, mape:3.8273138999938965, mspe:19511.97265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3707
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6483619
	speed: 0.0140s/iter; left time: 320.7218s
	iters: 200, epoch: 1 | loss: 3.5119314
	speed: 0.0115s/iter; left time: 261.7880s
Epoch: 1 cost time: 2.9222066402435303
Epoch: 1, Steps: 230 Train Loss: 3.6773 (Forecasting Loss:0.7225 + XiCon Loss:2.9548 x Lambda(1.0)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.5303
Validation loss decreased (inf --> 0.329727).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2308674
	speed: 0.0153s/iter; left time: 347.7278s
	iters: 200, epoch: 2 | loss: 3.1468782
	speed: 0.0128s/iter; left time: 288.2198s
Epoch: 2 cost time: 3.2187323570251465
Epoch: 2, Steps: 230 Train Loss: 3.2834 (Forecasting Loss:0.4280 + XiCon Loss:2.8554 x Lambda(1.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 0.3643
Validation loss decreased (0.329727 --> 0.215639).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1072586
	speed: 0.0141s/iter; left time: 316.0042s
	iters: 200, epoch: 3 | loss: 3.2161908
	speed: 0.0112s/iter; left time: 250.3232s
Epoch: 3 cost time: 2.883256435394287
Epoch: 3, Steps: 230 Train Loss: 3.1594 (Forecasting Loss:0.3849 + XiCon Loss:2.7744 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.3627
Validation loss decreased (0.215639 --> 0.213608).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2503908
	speed: 0.0143s/iter; left time: 317.5722s
	iters: 200, epoch: 4 | loss: 3.2233624
	speed: 0.0118s/iter; left time: 261.6247s
Epoch: 4 cost time: 2.979071617126465
Epoch: 4, Steps: 230 Train Loss: 3.1984 (Forecasting Loss:0.3791 + XiCon Loss:2.8193 x Lambda(1.0)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.3469
Validation loss decreased (0.213608 --> 0.204669).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1440036
	speed: 0.0139s/iter; left time: 305.3672s
	iters: 200, epoch: 5 | loss: 3.1850898
	speed: 0.0122s/iter; left time: 265.9773s
Epoch: 5 cost time: 2.9918363094329834
Epoch: 5, Steps: 230 Train Loss: 3.1911 (Forecasting Loss:0.3706 + XiCon Loss:2.8205 x Lambda(1.0)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.3425
Validation loss decreased (0.204669 --> 0.202210).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1241012
	speed: 0.0141s/iter; left time: 306.4188s
	iters: 200, epoch: 6 | loss: 3.1691172
	speed: 0.0116s/iter; left time: 252.0546s
Epoch: 6 cost time: 2.954136371612549
Epoch: 6, Steps: 230 Train Loss: 3.1837 (Forecasting Loss:0.3678 + XiCon Loss:2.8160 x Lambda(1.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.3409
Validation loss decreased (0.202210 --> 0.200849).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2195201
	speed: 0.0141s/iter; left time: 303.6300s
	iters: 200, epoch: 7 | loss: 3.1305373
	speed: 0.0116s/iter; left time: 247.6233s
Epoch: 7 cost time: 2.9404375553131104
Epoch: 7, Steps: 230 Train Loss: 3.1785 (Forecasting Loss:0.3662 + XiCon Loss:2.8123 x Lambda(1.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.3408
Validation loss decreased (0.200849 --> 0.200372).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1885195
	speed: 0.0137s/iter; left time: 291.9520s
	iters: 200, epoch: 8 | loss: 3.1681998
	speed: 0.0113s/iter; left time: 239.6945s
Epoch: 8 cost time: 2.8815078735351562
Epoch: 8, Steps: 230 Train Loss: 3.1761 (Forecasting Loss:0.3656 + XiCon Loss:2.8105 x Lambda(1.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.3401
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1372466
	speed: 0.0137s/iter; left time: 289.4355s
	iters: 200, epoch: 9 | loss: 3.2027879
	speed: 0.0114s/iter; left time: 239.3001s
Epoch: 9 cost time: 2.901432514190674
Epoch: 9, Steps: 230 Train Loss: 3.1796 (Forecasting Loss:0.3653 + XiCon Loss:2.8143 x Lambda(1.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.3401
Validation loss decreased (0.200372 --> 0.200366).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2142944
	speed: 0.0135s/iter; left time: 281.9438s
	iters: 200, epoch: 10 | loss: 3.1102564
	speed: 0.0112s/iter; left time: 231.2039s
Epoch: 10 cost time: 2.827249765396118
Epoch: 10, Steps: 230 Train Loss: 3.1804 (Forecasting Loss:0.3652 + XiCon Loss:2.8152 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3400
Validation loss decreased (0.200366 --> 0.200240).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1454539
	speed: 0.0142s/iter; left time: 292.4995s
	iters: 200, epoch: 11 | loss: 3.2112050
	speed: 0.0116s/iter; left time: 236.9613s
Epoch: 11 cost time: 2.949347972869873
Epoch: 11, Steps: 230 Train Loss: 3.1767 (Forecasting Loss:0.3654 + XiCon Loss:2.8113 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3399
Validation loss decreased (0.200240 --> 0.200201).  Saving model ...
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1299462
	speed: 0.0139s/iter; left time: 284.0261s
	iters: 200, epoch: 12 | loss: 3.2084277
	speed: 0.0117s/iter; left time: 237.3909s
Epoch: 12 cost time: 2.930304527282715
Epoch: 12, Steps: 230 Train Loss: 3.1737 (Forecasting Loss:0.3651 + XiCon Loss:2.8085 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3399
Validation loss decreased (0.200201 --> 0.200169).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1478720
	speed: 0.0143s/iter; left time: 288.1235s
	iters: 200, epoch: 13 | loss: 3.1990669
	speed: 0.0115s/iter; left time: 230.4010s
Epoch: 13 cost time: 2.9607410430908203
Epoch: 13, Steps: 230 Train Loss: 3.1771 (Forecasting Loss:0.3652 + XiCon Loss:2.8119 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.3399
Validation loss decreased (0.200169 --> 0.200086).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1505249
	speed: 0.0143s/iter; left time: 285.1045s
	iters: 200, epoch: 14 | loss: 3.1532021
	speed: 0.0116s/iter; left time: 230.6754s
Epoch: 14 cost time: 2.98232364654541
Epoch: 14, Steps: 230 Train Loss: 3.1775 (Forecasting Loss:0.3650 + XiCon Loss:2.8125 x Lambda(1.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.3399
Validation loss decreased (0.200086 --> 0.199766).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.1239913
	speed: 0.0140s/iter; left time: 275.3994s
	iters: 200, epoch: 15 | loss: 3.1808212
	speed: 0.0121s/iter; left time: 236.9328s
Epoch: 15 cost time: 2.987623453140259
Epoch: 15, Steps: 230 Train Loss: 3.1746 (Forecasting Loss:0.3651 + XiCon Loss:2.8095 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.3399
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1257048
	speed: 0.0134s/iter; left time: 259.7537s
	iters: 200, epoch: 16 | loss: 3.1836019
	speed: 0.0112s/iter; left time: 216.5297s
Epoch: 16 cost time: 2.819552421569824
Epoch: 16, Steps: 230 Train Loss: 3.1772 (Forecasting Loss:0.3651 + XiCon Loss:2.8120 x Lambda(1.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.3399
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.1927402
	speed: 0.0137s/iter; left time: 264.1058s
	iters: 200, epoch: 17 | loss: 3.1189077
	speed: 0.0129s/iter; left time: 247.4611s
Epoch: 17 cost time: 3.049661159515381
Epoch: 17, Steps: 230 Train Loss: 3.1774 (Forecasting Loss:0.3653 + XiCon Loss:2.8121 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.3399
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1574116
	speed: 0.0143s/iter; left time: 272.4842s
	iters: 200, epoch: 18 | loss: 3.1421874
	speed: 0.0115s/iter; left time: 217.9427s
Epoch: 18 cost time: 2.9580461978912354
Epoch: 18, Steps: 230 Train Loss: 3.1760 (Forecasting Loss:0.3650 + XiCon Loss:2.8110 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3399
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.2011075
	speed: 0.0145s/iter; left time: 271.2393s
	iters: 200, epoch: 19 | loss: 3.1378746
	speed: 0.0125s/iter; left time: 232.5396s
Epoch: 19 cost time: 3.0925612449645996
Epoch: 19, Steps: 230 Train Loss: 3.1769 (Forecasting Loss:0.3652 + XiCon Loss:2.8118 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3399
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.1487226
	speed: 0.0140s/iter; left time: 260.0930s
	iters: 200, epoch: 20 | loss: 3.2264633
	speed: 0.0112s/iter; left time: 206.9711s
Epoch: 20 cost time: 2.9275319576263428
Epoch: 20, Steps: 230 Train Loss: 3.1784 (Forecasting Loss:0.3650 + XiCon Loss:2.8134 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3399
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.1608429
	speed: 0.0139s/iter; left time: 253.7380s
	iters: 200, epoch: 21 | loss: 3.2088938
	speed: 0.0119s/iter; left time: 216.3100s
Epoch: 21 cost time: 2.9653522968292236
Epoch: 21, Steps: 230 Train Loss: 3.1767 (Forecasting Loss:0.3652 + XiCon Loss:2.8115 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.3399
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.1692257
	speed: 0.0141s/iter; left time: 254.5545s
	iters: 200, epoch: 22 | loss: 3.2018464
	speed: 0.0113s/iter; left time: 203.7960s
Epoch: 22 cost time: 2.9202640056610107
Epoch: 22, Steps: 230 Train Loss: 3.1785 (Forecasting Loss:0.3652 + XiCon Loss:2.8133 x Lambda(1.0)), Vali MSE Loss: 0.2001 Test MSE Loss: 0.3399
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.1480565
	speed: 0.0145s/iter; left time: 259.1501s
	iters: 200, epoch: 23 | loss: 3.1866636
	speed: 0.0118s/iter; left time: 208.7194s
Epoch: 23 cost time: 2.9955098628997803
Epoch: 23, Steps: 230 Train Loss: 3.1772 (Forecasting Loss:0.3651 + XiCon Loss:2.8122 x Lambda(1.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.3399
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.1594152
	speed: 0.0140s/iter; left time: 247.3674s
	iters: 200, epoch: 24 | loss: 3.1870432
	speed: 0.0110s/iter; left time: 191.8788s
Epoch: 24 cost time: 2.873609781265259
Epoch: 24, Steps: 230 Train Loss: 3.1786 (Forecasting Loss:0.3651 + XiCon Loss:2.8135 x Lambda(1.0)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.3399
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.28690391778945923, mae:0.392954558134079, mape:3.8748137950897217, mspe:20760.37890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:486689
train 14727
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4053
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14727
val 4543
test 4541
	iters: 100, epoch: 1 | loss: 3.6293559
	speed: 0.0141s/iter; left time: 323.5127s
	iters: 200, epoch: 1 | loss: 3.5896869
	speed: 0.0121s/iter; left time: 276.0427s
Epoch: 1 cost time: 3.0036585330963135
Epoch: 1, Steps: 230 Train Loss: 3.6779 (Forecasting Loss:0.7221 + XiCon Loss:2.9557 x Lambda(1.0)), Vali MSE Loss: 0.3318 Test MSE Loss: 0.5328
Validation loss decreased (inf --> 0.331815).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3019340
	speed: 0.0143s/iter; left time: 324.4495s
	iters: 200, epoch: 2 | loss: 3.2350070
	speed: 0.0122s/iter; left time: 276.0496s
Epoch: 2 cost time: 3.0553383827209473
Epoch: 2, Steps: 230 Train Loss: 3.2807 (Forecasting Loss:0.4324 + XiCon Loss:2.8483 x Lambda(1.0)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.3601
Validation loss decreased (0.331815 --> 0.214367).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1940277
	speed: 0.0136s/iter; left time: 305.0464s
	iters: 200, epoch: 3 | loss: 3.0694714
	speed: 0.0112s/iter; left time: 250.6865s
Epoch: 3 cost time: 2.852280855178833
Epoch: 3, Steps: 230 Train Loss: 3.1484 (Forecasting Loss:0.3753 + XiCon Loss:2.7731 x Lambda(1.0)), Vali MSE Loss: 0.2069 Test MSE Loss: 0.3599
Validation loss decreased (0.214367 --> 0.206856).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.1641741
	speed: 0.0143s/iter; left time: 316.7249s
	iters: 200, epoch: 4 | loss: 3.1262681
	speed: 0.0121s/iter; left time: 266.6878s
Epoch: 4 cost time: 3.024169921875
Epoch: 4, Steps: 230 Train Loss: 3.1171 (Forecasting Loss:0.3655 + XiCon Loss:2.7516 x Lambda(1.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.3618
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1370747
	speed: 0.0146s/iter; left time: 320.0092s
	iters: 200, epoch: 5 | loss: 3.1027076
	speed: 0.0117s/iter; left time: 255.0475s
Epoch: 5 cost time: 2.984259605407715
Epoch: 5, Steps: 230 Train Loss: 3.1348 (Forecasting Loss:0.3664 + XiCon Loss:2.7684 x Lambda(1.0)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.3470
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1432800
	speed: 0.0140s/iter; left time: 304.9065s
	iters: 200, epoch: 6 | loss: 3.2210944
	speed: 0.0114s/iter; left time: 247.3545s
Epoch: 6 cost time: 2.926943302154541
Epoch: 6, Steps: 230 Train Loss: 3.1533 (Forecasting Loss:0.3668 + XiCon Loss:2.7865 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.3471
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1901407
	speed: 0.0144s/iter; left time: 310.0756s
	iters: 200, epoch: 7 | loss: 3.2150638
	speed: 0.0120s/iter; left time: 258.0630s
Epoch: 7 cost time: 3.042320728302002
Epoch: 7, Steps: 230 Train Loss: 3.1610 (Forecasting Loss:0.3654 + XiCon Loss:2.7956 x Lambda(1.0)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.3468
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1341295
	speed: 0.0137s/iter; left time: 292.0071s
	iters: 200, epoch: 8 | loss: 3.2468789
	speed: 0.0116s/iter; left time: 245.5715s
Epoch: 8 cost time: 2.906205177307129
Epoch: 8, Steps: 230 Train Loss: 3.1615 (Forecasting Loss:0.3656 + XiCon Loss:2.7959 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3482
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2083027
	speed: 0.0139s/iter; left time: 291.8232s
	iters: 200, epoch: 9 | loss: 3.1227622
	speed: 0.0114s/iter; left time: 238.2755s
Epoch: 9 cost time: 2.892735719680786
Epoch: 9, Steps: 230 Train Loss: 3.1591 (Forecasting Loss:0.3649 + XiCon Loss:2.7942 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3483
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.1393316
	speed: 0.0137s/iter; left time: 284.3638s
	iters: 200, epoch: 10 | loss: 3.1694787
	speed: 0.0119s/iter; left time: 246.7545s
Epoch: 10 cost time: 2.931551694869995
Epoch: 10, Steps: 230 Train Loss: 3.1608 (Forecasting Loss:0.3644 + XiCon Loss:2.7964 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3482
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1622233
	speed: 0.0144s/iter; left time: 297.0517s
	iters: 200, epoch: 11 | loss: 3.1320858
	speed: 0.0119s/iter; left time: 244.2223s
Epoch: 11 cost time: 3.0207221508026123
Epoch: 11, Steps: 230 Train Loss: 3.1599 (Forecasting Loss:0.3644 + XiCon Loss:2.7956 x Lambda(1.0)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.3483
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1296597
	speed: 0.0138s/iter; left time: 280.7115s
	iters: 200, epoch: 12 | loss: 3.2270396
	speed: 0.0118s/iter; left time: 239.7509s
Epoch: 12 cost time: 2.94846773147583
Epoch: 12, Steps: 230 Train Loss: 3.1628 (Forecasting Loss:0.3645 + XiCon Loss:2.7983 x Lambda(1.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.3483
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1291497
	speed: 0.0140s/iter; left time: 282.0460s
	iters: 200, epoch: 13 | loss: 3.0882189
	speed: 0.0115s/iter; left time: 230.1104s
Epoch: 13 cost time: 2.9211366176605225
Epoch: 13, Steps: 230 Train Loss: 3.1593 (Forecasting Loss:0.3637 + XiCon Loss:2.7956 x Lambda(1.0)), Vali MSE Loss: 0.2076 Test MSE Loss: 0.3483
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl720_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 4541
test shape: (70, 64, 720, 1) (70, 64, 720, 1)
test shape: (4480, 720, 1) (4480, 720, 1)
mse:0.30848684906959534, mae:0.4113951027393341, mape:4.0912766456604, mspe:23557.697265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3034+-0.01563, MAE:0.4056+-0.01137, MAPE:4.0250+-0.22114, MSPE:23619.8262+-4530.11227, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.3799
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7191629
	speed: 0.0238s/iter; left time: 516.5169s
	iters: 200, epoch: 1 | loss: 3.7735538
	speed: 0.0177s/iter; left time: 381.3590s
Epoch: 1 cost time: 4.494771480560303
Epoch: 1, Steps: 218 Train Loss: 3.8068 (Forecasting Loss:0.8373 + XiCon Loss:2.9695 x Lambda(1.0)), Vali MSE Loss: 0.3363 Test MSE Loss: 0.6849
Validation loss decreased (inf --> 0.336285).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3055770
	speed: 0.0204s/iter; left time: 439.3086s
	iters: 200, epoch: 2 | loss: 3.2609558
	speed: 0.0176s/iter; left time: 376.5646s
Epoch: 2 cost time: 4.191771745681763
Epoch: 2, Steps: 218 Train Loss: 3.3344 (Forecasting Loss:0.4993 + XiCon Loss:2.8351 x Lambda(1.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.4201
Validation loss decreased (0.336285 --> 0.215654).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1720016
	speed: 0.0197s/iter; left time: 419.4018s
	iters: 200, epoch: 3 | loss: 3.1404018
	speed: 0.0182s/iter; left time: 385.5045s
Epoch: 3 cost time: 4.1552956104278564
Epoch: 3, Steps: 218 Train Loss: 3.2005 (Forecasting Loss:0.4232 + XiCon Loss:2.7772 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.4304
Validation loss decreased (0.215654 --> 0.214970).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2016220
	speed: 0.0202s/iter; left time: 424.9192s
	iters: 200, epoch: 4 | loss: 3.1153195
	speed: 0.0179s/iter; left time: 375.6402s
Epoch: 4 cost time: 4.168853998184204
Epoch: 4, Steps: 218 Train Loss: 3.1529 (Forecasting Loss:0.3986 + XiCon Loss:2.7543 x Lambda(1.0)), Vali MSE Loss: 0.2281 Test MSE Loss: 0.4006
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1778402
	speed: 0.0204s/iter; left time: 425.8528s
	iters: 200, epoch: 5 | loss: 3.1390529
	speed: 0.0179s/iter; left time: 370.7754s
Epoch: 5 cost time: 4.187397480010986
Epoch: 5, Steps: 218 Train Loss: 3.1268 (Forecasting Loss:0.3906 + XiCon Loss:2.7363 x Lambda(1.0)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.3883
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1380248
	speed: 0.0201s/iter; left time: 415.0639s
	iters: 200, epoch: 6 | loss: 3.1692822
	speed: 0.0179s/iter; left time: 367.1543s
Epoch: 6 cost time: 4.156845331192017
Epoch: 6, Steps: 218 Train Loss: 3.1449 (Forecasting Loss:0.3899 + XiCon Loss:2.7551 x Lambda(1.0)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.3831
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1433604
	speed: 0.0203s/iter; left time: 413.4739s
	iters: 200, epoch: 7 | loss: 3.1858826
	speed: 0.0183s/iter; left time: 372.3522s
Epoch: 7 cost time: 4.207616090774536
Epoch: 7, Steps: 218 Train Loss: 3.1770 (Forecasting Loss:0.3905 + XiCon Loss:2.7865 x Lambda(1.0)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.3815
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.1528735
	speed: 0.0200s/iter; left time: 403.6664s
	iters: 200, epoch: 8 | loss: 3.1983278
	speed: 0.0174s/iter; left time: 349.8583s
Epoch: 8 cost time: 4.087928295135498
Epoch: 8, Steps: 218 Train Loss: 3.1962 (Forecasting Loss:0.3920 + XiCon Loss:2.8043 x Lambda(1.0)), Vali MSE Loss: 0.2258 Test MSE Loss: 0.3850
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.1291001
	speed: 0.0204s/iter; left time: 406.8678s
	iters: 200, epoch: 9 | loss: 3.1782265
	speed: 0.0178s/iter; left time: 353.1188s
Epoch: 9 cost time: 4.15814471244812
Epoch: 9, Steps: 218 Train Loss: 3.2059 (Forecasting Loss:0.3925 + XiCon Loss:2.8135 x Lambda(1.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.3815
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2231278
	speed: 0.0202s/iter; left time: 398.4718s
	iters: 200, epoch: 10 | loss: 3.2586741
	speed: 0.0180s/iter; left time: 353.6270s
Epoch: 10 cost time: 4.175176382064819
Epoch: 10, Steps: 218 Train Loss: 3.2059 (Forecasting Loss:0.3920 + XiCon Loss:2.8139 x Lambda(1.0)), Vali MSE Loss: 0.2283 Test MSE Loss: 0.3806
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2221282
	speed: 0.0200s/iter; left time: 390.6761s
	iters: 200, epoch: 11 | loss: 3.2453449
	speed: 0.0176s/iter; left time: 341.8107s
Epoch: 11 cost time: 4.115798711776733
Epoch: 11, Steps: 218 Train Loss: 3.2118 (Forecasting Loss:0.3921 + XiCon Loss:2.8197 x Lambda(1.0)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.3812
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2212791
	speed: 0.0199s/iter; left time: 384.1226s
	iters: 200, epoch: 12 | loss: 3.1891513
	speed: 0.0179s/iter; left time: 344.6577s
Epoch: 12 cost time: 4.138224840164185
Epoch: 12, Steps: 218 Train Loss: 3.2078 (Forecasting Loss:0.3920 + XiCon Loss:2.8158 x Lambda(1.0)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.3816
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2054806
	speed: 0.0199s/iter; left time: 379.7748s
	iters: 200, epoch: 13 | loss: 3.2282405
	speed: 0.0181s/iter; left time: 343.2794s
Epoch: 13 cost time: 4.147676467895508
Epoch: 13, Steps: 218 Train Loss: 3.2093 (Forecasting Loss:0.3918 + XiCon Loss:2.8175 x Lambda(1.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.3815
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3845294713973999, mae:0.47619950771331787, mape:6.029086112976074, mspe:97537.140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5961
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7999287
	speed: 0.0208s/iter; left time: 451.4257s
	iters: 200, epoch: 1 | loss: 3.6442389
	speed: 0.0177s/iter; left time: 382.7192s
Epoch: 1 cost time: 4.215260744094849
Epoch: 1, Steps: 218 Train Loss: 3.7840 (Forecasting Loss:0.8368 + XiCon Loss:2.9472 x Lambda(1.0)), Vali MSE Loss: 0.3329 Test MSE Loss: 0.6596
Validation loss decreased (inf --> 0.332856).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2477629
	speed: 0.0204s/iter; left time: 437.7392s
	iters: 200, epoch: 2 | loss: 3.2492690
	speed: 0.0178s/iter; left time: 381.4897s
Epoch: 2 cost time: 4.182039976119995
Epoch: 2, Steps: 218 Train Loss: 3.3263 (Forecasting Loss:0.4737 + XiCon Loss:2.8526 x Lambda(1.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5161
Validation loss decreased (0.332856 --> 0.219723).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.2378783
	speed: 0.0204s/iter; left time: 433.5409s
	iters: 200, epoch: 3 | loss: 3.2500861
	speed: 0.0178s/iter; left time: 377.1024s
Epoch: 3 cost time: 4.169223785400391
Epoch: 3, Steps: 218 Train Loss: 3.2701 (Forecasting Loss:0.4120 + XiCon Loss:2.8580 x Lambda(1.0)), Vali MSE Loss: 0.2235 Test MSE Loss: 0.4043
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2387655
	speed: 0.0200s/iter; left time: 420.9616s
	iters: 200, epoch: 4 | loss: 3.2895598
	speed: 0.0180s/iter; left time: 377.6312s
Epoch: 4 cost time: 4.15786075592041
Epoch: 4, Steps: 218 Train Loss: 3.2873 (Forecasting Loss:0.3946 + XiCon Loss:2.8927 x Lambda(1.0)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.4063
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.3378763
	speed: 0.0203s/iter; left time: 421.9496s
	iters: 200, epoch: 5 | loss: 3.3466301
	speed: 0.0179s/iter; left time: 371.0706s
Epoch: 5 cost time: 4.198584794998169
Epoch: 5, Steps: 218 Train Loss: 3.2838 (Forecasting Loss:0.3826 + XiCon Loss:2.9012 x Lambda(1.0)), Vali MSE Loss: 0.2228 Test MSE Loss: 0.4063
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.1883664
	speed: 0.0200s/iter; left time: 412.0010s
	iters: 200, epoch: 6 | loss: 3.1636827
	speed: 0.0185s/iter; left time: 378.4523s
Epoch: 6 cost time: 4.216525316238403
Epoch: 6, Steps: 218 Train Loss: 3.2770 (Forecasting Loss:0.3783 + XiCon Loss:2.8986 x Lambda(1.0)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.3989
Validation loss decreased (0.219723 --> 0.218270).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2812109
	speed: 0.0199s/iter; left time: 406.6541s
	iters: 200, epoch: 7 | loss: 3.1644843
	speed: 0.0179s/iter; left time: 363.0139s
Epoch: 7 cost time: 4.139824151992798
Epoch: 7, Steps: 218 Train Loss: 3.2722 (Forecasting Loss:0.3764 + XiCon Loss:2.8958 x Lambda(1.0)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.3983
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3574519
	speed: 0.0199s/iter; left time: 402.0377s
	iters: 200, epoch: 8 | loss: 3.1997452
	speed: 0.0177s/iter; left time: 354.7807s
Epoch: 8 cost time: 4.1204304695129395
Epoch: 8, Steps: 218 Train Loss: 3.2713 (Forecasting Loss:0.3756 + XiCon Loss:2.8957 x Lambda(1.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.3984
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2430704
	speed: 0.0200s/iter; left time: 398.2789s
	iters: 200, epoch: 9 | loss: 3.2669497
	speed: 0.0178s/iter; left time: 354.2621s
Epoch: 9 cost time: 4.133880376815796
Epoch: 9, Steps: 218 Train Loss: 3.2679 (Forecasting Loss:0.3748 + XiCon Loss:2.8931 x Lambda(1.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.3987
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2450981
	speed: 0.0204s/iter; left time: 402.8715s
	iters: 200, epoch: 10 | loss: 3.2101769
	speed: 0.0180s/iter; left time: 353.4990s
Epoch: 10 cost time: 4.195030927658081
Epoch: 10, Steps: 218 Train Loss: 3.2725 (Forecasting Loss:0.3745 + XiCon Loss:2.8980 x Lambda(1.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.3994
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2591527
	speed: 0.0205s/iter; left time: 400.9273s
	iters: 200, epoch: 11 | loss: 3.2705555
	speed: 0.0179s/iter; left time: 347.0281s
Epoch: 11 cost time: 4.201883554458618
Epoch: 11, Steps: 218 Train Loss: 3.2724 (Forecasting Loss:0.3747 + XiCon Loss:2.8977 x Lambda(1.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.3992
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2947812
	speed: 0.0207s/iter; left time: 399.4388s
	iters: 200, epoch: 12 | loss: 3.2615955
	speed: 0.0177s/iter; left time: 339.1357s
Epoch: 12 cost time: 4.185423851013184
Epoch: 12, Steps: 218 Train Loss: 3.2714 (Forecasting Loss:0.3743 + XiCon Loss:2.8971 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3994
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2724037
	speed: 0.0202s/iter; left time: 386.1637s
	iters: 200, epoch: 13 | loss: 3.3614521
	speed: 0.0180s/iter; left time: 341.6511s
Epoch: 13 cost time: 4.1791746616363525
Epoch: 13, Steps: 218 Train Loss: 3.2714 (Forecasting Loss:0.3743 + XiCon Loss:2.8971 x Lambda(1.0)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.3992
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.1757293
	speed: 0.0204s/iter; left time: 384.8520s
	iters: 200, epoch: 14 | loss: 3.2254803
	speed: 0.0183s/iter; left time: 343.0197s
Epoch: 14 cost time: 4.229588747024536
Epoch: 14, Steps: 218 Train Loss: 3.2743 (Forecasting Loss:0.3746 + XiCon Loss:2.8997 x Lambda(1.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.3993
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2868636
	speed: 0.0201s/iter; left time: 373.9149s
	iters: 200, epoch: 15 | loss: 3.3613157
	speed: 0.0179s/iter; left time: 331.1191s
Epoch: 15 cost time: 4.1326634883880615
Epoch: 15, Steps: 218 Train Loss: 3.2684 (Forecasting Loss:0.3748 + XiCon Loss:2.8936 x Lambda(1.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.3992
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.1639326
	speed: 0.0205s/iter; left time: 378.1823s
	iters: 200, epoch: 16 | loss: 3.2568545
	speed: 0.0179s/iter; left time: 328.9647s
Epoch: 16 cost time: 4.196753263473511
Epoch: 16, Steps: 218 Train Loss: 3.2686 (Forecasting Loss:0.3746 + XiCon Loss:2.8940 x Lambda(1.0)), Vali MSE Loss: 0.2184 Test MSE Loss: 0.3993
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.3495466709136963, mae:0.4482440650463104, mape:5.344283580780029, mspe:72655.7890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.4685
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7465720
	speed: 0.0208s/iter; left time: 451.2721s
	iters: 200, epoch: 1 | loss: 3.7061539
	speed: 0.0180s/iter; left time: 388.7602s
Epoch: 1 cost time: 4.224319219589233
Epoch: 1, Steps: 218 Train Loss: 3.7931 (Forecasting Loss:0.8322 + XiCon Loss:2.9610 x Lambda(1.0)), Vali MSE Loss: 0.3326 Test MSE Loss: 0.6611
Validation loss decreased (inf --> 0.332570).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2931473
	speed: 0.0210s/iter; left time: 451.2516s
	iters: 200, epoch: 2 | loss: 3.1801906
	speed: 0.0177s/iter; left time: 378.1486s
Epoch: 2 cost time: 4.2449305057525635
Epoch: 2, Steps: 218 Train Loss: 3.3242 (Forecasting Loss:0.5059 + XiCon Loss:2.8183 x Lambda(1.0)), Vali MSE Loss: 0.2357 Test MSE Loss: 0.4948
Validation loss decreased (0.332570 --> 0.235697).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1581686
	speed: 0.0203s/iter; left time: 431.8513s
	iters: 200, epoch: 3 | loss: 3.2909319
	speed: 0.0177s/iter; left time: 374.9462s
Epoch: 3 cost time: 4.152789831161499
Epoch: 3, Steps: 218 Train Loss: 3.1866 (Forecasting Loss:0.4206 + XiCon Loss:2.7660 x Lambda(1.0)), Vali MSE Loss: 0.2272 Test MSE Loss: 0.4184
Validation loss decreased (0.235697 --> 0.227160).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2787137
	speed: 0.0201s/iter; left time: 423.8193s
	iters: 200, epoch: 4 | loss: 3.1933839
	speed: 0.0175s/iter; left time: 367.0441s
Epoch: 4 cost time: 4.1154279708862305
Epoch: 4, Steps: 218 Train Loss: 3.2632 (Forecasting Loss:0.4108 + XiCon Loss:2.8524 x Lambda(1.0)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.3970
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2679877
	speed: 0.0203s/iter; left time: 423.1685s
	iters: 200, epoch: 5 | loss: 3.1500993
	speed: 0.0176s/iter; left time: 365.7169s
Epoch: 5 cost time: 4.146184682846069
Epoch: 5, Steps: 218 Train Loss: 3.2768 (Forecasting Loss:0.4014 + XiCon Loss:2.8755 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.4052
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.3297462
	speed: 0.0200s/iter; left time: 411.3399s
	iters: 200, epoch: 6 | loss: 3.2713017
	speed: 0.0177s/iter; left time: 363.7934s
Epoch: 6 cost time: 4.149875164031982
Epoch: 6, Steps: 218 Train Loss: 3.2650 (Forecasting Loss:0.3971 + XiCon Loss:2.8679 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.4079
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2035387
	speed: 0.0206s/iter; left time: 419.4174s
	iters: 200, epoch: 7 | loss: 3.2002594
	speed: 0.0182s/iter; left time: 369.0002s
Epoch: 7 cost time: 4.221470594406128
Epoch: 7, Steps: 218 Train Loss: 3.2699 (Forecasting Loss:0.3948 + XiCon Loss:2.8752 x Lambda(1.0)), Vali MSE Loss: 0.2504 Test MSE Loss: 0.4069
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2694755
	speed: 0.0200s/iter; left time: 404.4515s
	iters: 200, epoch: 8 | loss: 3.2676463
	speed: 0.0179s/iter; left time: 358.3715s
Epoch: 8 cost time: 4.1604485511779785
Epoch: 8, Steps: 218 Train Loss: 3.2712 (Forecasting Loss:0.3940 + XiCon Loss:2.8772 x Lambda(1.0)), Vali MSE Loss: 0.2559 Test MSE Loss: 0.4134
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2773473
	speed: 0.0204s/iter; left time: 406.9837s
	iters: 200, epoch: 9 | loss: 3.3139420
	speed: 0.0179s/iter; left time: 355.2611s
Epoch: 9 cost time: 4.20215630531311
Epoch: 9, Steps: 218 Train Loss: 3.2663 (Forecasting Loss:0.3930 + XiCon Loss:2.8732 x Lambda(1.0)), Vali MSE Loss: 0.2573 Test MSE Loss: 0.4145
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.3171864
	speed: 0.0203s/iter; left time: 400.1560s
	iters: 200, epoch: 10 | loss: 3.2172196
	speed: 0.0179s/iter; left time: 351.0583s
Epoch: 10 cost time: 4.191467761993408
Epoch: 10, Steps: 218 Train Loss: 3.2702 (Forecasting Loss:0.3928 + XiCon Loss:2.8774 x Lambda(1.0)), Vali MSE Loss: 0.2576 Test MSE Loss: 0.4155
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2699337
	speed: 0.0203s/iter; left time: 396.5121s
	iters: 200, epoch: 11 | loss: 3.2017896
	speed: 0.0180s/iter; left time: 350.0467s
Epoch: 11 cost time: 4.183816194534302
Epoch: 11, Steps: 218 Train Loss: 3.2685 (Forecasting Loss:0.3927 + XiCon Loss:2.8757 x Lambda(1.0)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.4151
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.3285060
	speed: 0.0196s/iter; left time: 378.4636s
	iters: 200, epoch: 12 | loss: 3.2645149
	speed: 0.0176s/iter; left time: 338.7143s
Epoch: 12 cost time: 4.06983757019043
Epoch: 12, Steps: 218 Train Loss: 3.2675 (Forecasting Loss:0.3925 + XiCon Loss:2.8750 x Lambda(1.0)), Vali MSE Loss: 0.2578 Test MSE Loss: 0.4152
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.1718884
	speed: 0.0203s/iter; left time: 386.5173s
	iters: 200, epoch: 13 | loss: 3.3073096
	speed: 0.0179s/iter; left time: 339.1598s
Epoch: 13 cost time: 4.1712915897369385
Epoch: 13, Steps: 218 Train Loss: 3.2680 (Forecasting Loss:0.3927 + XiCon Loss:2.8753 x Lambda(1.0)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.4149
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.37166595458984375, mae:0.4651066064834595, mape:5.719417095184326, mspe:83646.25 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5284
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.9136038
	speed: 0.0209s/iter; left time: 454.1299s
	iters: 200, epoch: 1 | loss: 3.6326957
	speed: 0.0181s/iter; left time: 391.5952s
Epoch: 1 cost time: 4.254924058914185
Epoch: 1, Steps: 218 Train Loss: 3.7965 (Forecasting Loss:0.8320 + XiCon Loss:2.9645 x Lambda(1.0)), Vali MSE Loss: 0.3327 Test MSE Loss: 0.6645
Validation loss decreased (inf --> 0.332741).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.2263536
	speed: 0.0200s/iter; left time: 430.2685s
	iters: 200, epoch: 2 | loss: 3.2333434
	speed: 0.0180s/iter; left time: 385.8177s
Epoch: 2 cost time: 4.174412488937378
Epoch: 2, Steps: 218 Train Loss: 3.3185 (Forecasting Loss:0.5025 + XiCon Loss:2.8161 x Lambda(1.0)), Vali MSE Loss: 0.2242 Test MSE Loss: 0.4238
Validation loss decreased (0.332741 --> 0.224165).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.3365011
	speed: 0.0205s/iter; left time: 435.9069s
	iters: 200, epoch: 3 | loss: 3.3605478
	speed: 0.0175s/iter; left time: 371.0201s
Epoch: 3 cost time: 4.162488222122192
Epoch: 3, Steps: 218 Train Loss: 3.2898 (Forecasting Loss:0.4259 + XiCon Loss:2.8639 x Lambda(1.0)), Vali MSE Loss: 0.2171 Test MSE Loss: 0.4322
Validation loss decreased (0.224165 --> 0.217139).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.2553518
	speed: 0.0202s/iter; left time: 425.8083s
	iters: 200, epoch: 4 | loss: 3.2299161
	speed: 0.0179s/iter; left time: 374.6651s
Epoch: 4 cost time: 4.162142038345337
Epoch: 4, Steps: 218 Train Loss: 3.2715 (Forecasting Loss:0.4141 + XiCon Loss:2.8574 x Lambda(1.0)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.4274
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.1823838
	speed: 0.0201s/iter; left time: 418.2476s
	iters: 200, epoch: 5 | loss: 3.2641284
	speed: 0.0185s/iter; left time: 383.1726s
Epoch: 5 cost time: 4.221613883972168
Epoch: 5, Steps: 218 Train Loss: 3.2590 (Forecasting Loss:0.4082 + XiCon Loss:2.8508 x Lambda(1.0)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.4215
Validation loss decreased (0.217139 --> 0.214731).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.3029759
	speed: 0.0204s/iter; left time: 420.7423s
	iters: 200, epoch: 6 | loss: 3.3160255
	speed: 0.0180s/iter; left time: 368.8376s
Epoch: 6 cost time: 4.201521873474121
Epoch: 6, Steps: 218 Train Loss: 3.2502 (Forecasting Loss:0.4047 + XiCon Loss:2.8455 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.4240
Validation loss decreased (0.214731 --> 0.214230).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.2799153
	speed: 0.0203s/iter; left time: 413.8164s
	iters: 200, epoch: 7 | loss: 3.2322314
	speed: 0.0179s/iter; left time: 363.7861s
Epoch: 7 cost time: 4.175929546356201
Epoch: 7, Steps: 218 Train Loss: 3.2441 (Forecasting Loss:0.4028 + XiCon Loss:2.8413 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4226
Validation loss decreased (0.214230 --> 0.212836).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.2431464
	speed: 0.0203s/iter; left time: 410.5097s
	iters: 200, epoch: 8 | loss: 3.1921177
	speed: 0.0177s/iter; left time: 355.5765s
Epoch: 8 cost time: 4.176177501678467
Epoch: 8, Steps: 218 Train Loss: 3.2501 (Forecasting Loss:0.4013 + XiCon Loss:2.8488 x Lambda(1.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.4253
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2027502
	speed: 0.0201s/iter; left time: 400.6904s
	iters: 200, epoch: 9 | loss: 3.2710984
	speed: 0.0184s/iter; left time: 365.0249s
Epoch: 9 cost time: 4.210118055343628
Epoch: 9, Steps: 218 Train Loss: 3.2480 (Forecasting Loss:0.4017 + XiCon Loss:2.8463 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.4268
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2278447
	speed: 0.0202s/iter; left time: 398.1531s
	iters: 200, epoch: 10 | loss: 3.2712450
	speed: 0.0179s/iter; left time: 352.2600s
Epoch: 10 cost time: 4.16840124130249
Epoch: 10, Steps: 218 Train Loss: 3.2386 (Forecasting Loss:0.4015 + XiCon Loss:2.8371 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4267
Validation loss decreased (0.212836 --> 0.212812).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.2149417
	speed: 0.0204s/iter; left time: 398.8047s
	iters: 200, epoch: 11 | loss: 3.2967982
	speed: 0.0178s/iter; left time: 345.0384s
Epoch: 11 cost time: 4.177967309951782
Epoch: 11, Steps: 218 Train Loss: 3.2423 (Forecasting Loss:0.4001 + XiCon Loss:2.8422 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.4265
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.1870670
	speed: 0.0203s/iter; left time: 391.2259s
	iters: 200, epoch: 12 | loss: 3.1992624
	speed: 0.0183s/iter; left time: 351.0762s
Epoch: 12 cost time: 4.208745718002319
Epoch: 12, Steps: 218 Train Loss: 3.2532 (Forecasting Loss:0.4013 + XiCon Loss:2.8519 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4265
Validation loss decreased (0.212812 --> 0.212751).  Saving model ...
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2358968
	speed: 0.0201s/iter; left time: 384.5148s
	iters: 200, epoch: 13 | loss: 3.3724446
	speed: 0.0176s/iter; left time: 333.8263s
Epoch: 13 cost time: 4.125651836395264
Epoch: 13, Steps: 218 Train Loss: 3.2432 (Forecasting Loss:0.4004 + XiCon Loss:2.8428 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.4266
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 3.2708933
	speed: 0.0206s/iter; left time: 389.3267s
	iters: 200, epoch: 14 | loss: 3.2227423
	speed: 0.0177s/iter; left time: 331.5195s
Epoch: 14 cost time: 4.178059339523315
Epoch: 14, Steps: 218 Train Loss: 3.2454 (Forecasting Loss:0.4007 + XiCon Loss:2.8447 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.4266
Validation loss decreased (0.212751 --> 0.212645).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 3.2793584
	speed: 0.0204s/iter; left time: 379.6190s
	iters: 200, epoch: 15 | loss: 3.1969523
	speed: 0.0183s/iter; left time: 338.9928s
Epoch: 15 cost time: 4.22617769241333
Epoch: 15, Steps: 218 Train Loss: 3.2465 (Forecasting Loss:0.4005 + XiCon Loss:2.8460 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4266
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 3.2975779
	speed: 0.0211s/iter; left time: 388.0463s
	iters: 200, epoch: 16 | loss: 3.2108748
	speed: 0.0182s/iter; left time: 333.3981s
Epoch: 16 cost time: 4.271474123001099
Epoch: 16, Steps: 218 Train Loss: 3.2423 (Forecasting Loss:0.4010 + XiCon Loss:2.8413 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4266
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 3.2503514
	speed: 0.0204s/iter; left time: 370.8977s
	iters: 200, epoch: 17 | loss: 3.2243097
	speed: 0.0181s/iter; left time: 328.2946s
Epoch: 17 cost time: 4.206719160079956
Epoch: 17, Steps: 218 Train Loss: 3.2456 (Forecasting Loss:0.4011 + XiCon Loss:2.8445 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.4266
Validation loss decreased (0.212645 --> 0.212561).  Saving model ...
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 3.1487882
	speed: 0.0209s/iter; left time: 376.5239s
	iters: 200, epoch: 18 | loss: 3.2411599
	speed: 0.0177s/iter; left time: 316.1789s
Epoch: 18 cost time: 4.21651816368103
Epoch: 18, Steps: 218 Train Loss: 3.2403 (Forecasting Loss:0.4012 + XiCon Loss:2.8391 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.4266
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 3.1627324
	speed: 0.0199s/iter; left time: 354.5141s
	iters: 200, epoch: 19 | loss: 3.1626303
	speed: 0.0178s/iter; left time: 314.3491s
Epoch: 19 cost time: 4.136555433273315
Epoch: 19, Steps: 218 Train Loss: 3.2510 (Forecasting Loss:0.4010 + XiCon Loss:2.8500 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.4266
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 3.2528286
	speed: 0.0200s/iter; left time: 351.5072s
	iters: 200, epoch: 20 | loss: 3.2733457
	speed: 0.0185s/iter; left time: 323.8566s
Epoch: 20 cost time: 4.225726366043091
Epoch: 20, Steps: 218 Train Loss: 3.2490 (Forecasting Loss:0.4014 + XiCon Loss:2.8476 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.4266
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 3.3117542
	speed: 0.0200s/iter; left time: 346.8398s
	iters: 200, epoch: 21 | loss: 3.2166123
	speed: 0.0178s/iter; left time: 306.6445s
Epoch: 21 cost time: 4.140202522277832
Epoch: 21, Steps: 218 Train Loss: 3.2509 (Forecasting Loss:0.4016 + XiCon Loss:2.8493 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4266
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 3.2516403
	speed: 0.0201s/iter; left time: 344.6188s
	iters: 200, epoch: 22 | loss: 3.3095403
	speed: 0.0181s/iter; left time: 308.8759s
Epoch: 22 cost time: 4.177883625030518
Epoch: 22, Steps: 218 Train Loss: 3.2450 (Forecasting Loss:0.4010 + XiCon Loss:2.8440 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.4266
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 3.1350985
	speed: 0.0204s/iter; left time: 345.2914s
	iters: 200, epoch: 23 | loss: 3.2952695
	speed: 0.0178s/iter; left time: 299.3767s
Epoch: 23 cost time: 4.1959922313690186
Epoch: 23, Steps: 218 Train Loss: 3.2456 (Forecasting Loss:0.4008 + XiCon Loss:2.8448 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.4266
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 3.2754128
	speed: 0.0203s/iter; left time: 338.7535s
	iters: 200, epoch: 24 | loss: 3.1361244
	speed: 0.0181s/iter; left time: 299.8660s
Epoch: 24 cost time: 4.190589904785156
Epoch: 24, Steps: 218 Train Loss: 3.2473 (Forecasting Loss:0.4011 + XiCon Loss:2.8462 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4266
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 3.2422411
	speed: 0.0199s/iter; left time: 327.2768s
	iters: 200, epoch: 25 | loss: 3.2033696
	speed: 0.0180s/iter; left time: 294.0379s
Epoch: 25 cost time: 4.131793975830078
Epoch: 25, Steps: 218 Train Loss: 3.2432 (Forecasting Loss:0.4007 + XiCon Loss:2.8426 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.4266
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 3.2221072
	speed: 0.0202s/iter; left time: 328.8994s
	iters: 200, epoch: 26 | loss: 3.2411528
	speed: 0.0180s/iter; left time: 290.9071s
Epoch: 26 cost time: 4.1792802810668945
Epoch: 26, Steps: 218 Train Loss: 3.2411 (Forecasting Loss:0.4002 + XiCon Loss:2.8409 x Lambda(1.0)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.4266
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 3.2055547
	speed: 0.0203s/iter; left time: 325.4015s
	iters: 200, epoch: 27 | loss: 3.2545857
	speed: 0.0180s/iter; left time: 287.0839s
Epoch: 27 cost time: 4.183152675628662
Epoch: 27, Steps: 218 Train Loss: 3.2395 (Forecasting Loss:0.4011 + XiCon Loss:2.8384 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.4266
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.37871620059013367, mae:0.47440147399902344, mape:4.431222438812256, mspe:33740.9140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:975937
train 14007
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99981463] ~ [0.00025037 0.00012523]
Xi-correlation values:[0.99980992 0.99577667] ~ [0. 1.]
Autocorrelation calculation time: 4.5145
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 14007
val 3823
test 3821
	iters: 100, epoch: 1 | loss: 3.7086329
	speed: 0.0209s/iter; left time: 453.4488s
	iters: 200, epoch: 1 | loss: 3.6375105
	speed: 0.0178s/iter; left time: 383.7508s
Epoch: 1 cost time: 4.223906993865967
Epoch: 1, Steps: 218 Train Loss: 3.7974 (Forecasting Loss:0.8401 + XiCon Loss:2.9573 x Lambda(1.0)), Vali MSE Loss: 0.3337 Test MSE Loss: 0.6519
Validation loss decreased (inf --> 0.333719).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 3.3008308
	speed: 0.0199s/iter; left time: 428.1398s
	iters: 200, epoch: 2 | loss: 3.2525580
	speed: 0.0177s/iter; left time: 378.2471s
Epoch: 2 cost time: 4.109131813049316
Epoch: 2, Steps: 218 Train Loss: 3.3166 (Forecasting Loss:0.4754 + XiCon Loss:2.8413 x Lambda(1.0)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.4660
Validation loss decreased (0.333719 --> 0.229528).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 3.1663494
	speed: 0.0202s/iter; left time: 429.6275s
	iters: 200, epoch: 3 | loss: 3.3261850
	speed: 0.0184s/iter; left time: 389.9344s
Epoch: 3 cost time: 4.21566915512085
Epoch: 3, Steps: 218 Train Loss: 3.1961 (Forecasting Loss:0.4178 + XiCon Loss:2.7784 x Lambda(1.0)), Vali MSE Loss: 0.2255 Test MSE Loss: 0.4439
Validation loss decreased (0.229528 --> 0.225487).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 3.3233895
	speed: 0.0204s/iter; left time: 430.3171s
	iters: 200, epoch: 4 | loss: 3.3409503
	speed: 0.0178s/iter; left time: 372.2062s
Epoch: 4 cost time: 4.172743082046509
Epoch: 4, Steps: 218 Train Loss: 3.2623 (Forecasting Loss:0.4093 + XiCon Loss:2.8530 x Lambda(1.0)), Vali MSE Loss: 0.2412 Test MSE Loss: 0.4183
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 3.2878637
	speed: 0.0202s/iter; left time: 420.0514s
	iters: 200, epoch: 5 | loss: 3.2158785
	speed: 0.0180s/iter; left time: 372.6557s
Epoch: 5 cost time: 4.179575443267822
Epoch: 5, Steps: 218 Train Loss: 3.2576 (Forecasting Loss:0.4007 + XiCon Loss:2.8570 x Lambda(1.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.3957
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 3.2676916
	speed: 0.0203s/iter; left time: 417.4621s
	iters: 200, epoch: 6 | loss: 3.2734368
	speed: 0.0185s/iter; left time: 378.6279s
Epoch: 6 cost time: 4.224111795425415
Epoch: 6, Steps: 218 Train Loss: 3.2599 (Forecasting Loss:0.3958 + XiCon Loss:2.8640 x Lambda(1.0)), Vali MSE Loss: 0.2331 Test MSE Loss: 0.3960
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 3.1857464
	speed: 0.0202s/iter; left time: 412.3438s
	iters: 200, epoch: 7 | loss: 3.3201380
	speed: 0.0181s/iter; left time: 367.6312s
Epoch: 7 cost time: 4.177721738815308
Epoch: 7, Steps: 218 Train Loss: 3.2481 (Forecasting Loss:0.3919 + XiCon Loss:2.8563 x Lambda(1.0)), Vali MSE Loss: 0.2381 Test MSE Loss: 0.3952
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 3.3115239
	speed: 0.0207s/iter; left time: 417.8730s
	iters: 200, epoch: 8 | loss: 3.2152269
	speed: 0.0183s/iter; left time: 366.4663s
Epoch: 8 cost time: 4.2641518115997314
Epoch: 8, Steps: 218 Train Loss: 3.2501 (Forecasting Loss:0.3903 + XiCon Loss:2.8599 x Lambda(1.0)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.4072
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 3.2754972
	speed: 0.0201s/iter; left time: 400.6225s
	iters: 200, epoch: 9 | loss: 3.3198009
	speed: 0.0176s/iter; left time: 349.4551s
Epoch: 9 cost time: 4.136566877365112
Epoch: 9, Steps: 218 Train Loss: 3.2487 (Forecasting Loss:0.3894 + XiCon Loss:2.8593 x Lambda(1.0)), Vali MSE Loss: 0.2314 Test MSE Loss: 0.4027
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 3.2444243
	speed: 0.0201s/iter; left time: 396.5180s
	iters: 200, epoch: 10 | loss: 3.2212489
	speed: 0.0178s/iter; left time: 348.8627s
Epoch: 10 cost time: 4.136152029037476
Epoch: 10, Steps: 218 Train Loss: 3.2478 (Forecasting Loss:0.3888 + XiCon Loss:2.8590 x Lambda(1.0)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.4018
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 3.1672921
	speed: 0.0203s/iter; left time: 396.0660s
	iters: 200, epoch: 11 | loss: 3.4055245
	speed: 0.0179s/iter; left time: 348.0891s
Epoch: 11 cost time: 4.173131465911865
Epoch: 11, Steps: 218 Train Loss: 3.2503 (Forecasting Loss:0.3886 + XiCon Loss:2.8617 x Lambda(1.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 0.4025
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 3.2615209
	speed: 0.0201s/iter; left time: 387.8480s
	iters: 200, epoch: 12 | loss: 3.2525849
	speed: 0.0179s/iter; left time: 343.6961s
Epoch: 12 cost time: 4.162858963012695
Epoch: 12, Steps: 218 Train Loss: 3.2460 (Forecasting Loss:0.3885 + XiCon Loss:2.8574 x Lambda(1.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.4029
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 3.2819581
	speed: 0.0204s/iter; left time: 390.1729s
	iters: 200, epoch: 13 | loss: 3.2762349
	speed: 0.0179s/iter; left time: 339.0865s
Epoch: 13 cost time: 4.194239854812622
Epoch: 13, Steps: 218 Train Loss: 3.2484 (Forecasting Loss:0.3888 + XiCon Loss:2.8596 x Lambda(1.0)), Vali MSE Loss: 0.2314 Test MSE Loss: 0.4027
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl336_ll48_pl1440_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3821
test shape: (59, 64, 1440, 1) (59, 64, 1440, 1)
test shape: (3776, 1440, 1) (3776, 1440, 1)
mse:0.40427249670028687, mae:0.48355191946029663, mape:5.766745567321777, mspe:78400.953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.3777+-0.02470, MAE:0.4695+-0.01686, MAPE:5.4582+-0.77467, MSPE:73196.2109+-29681.91240, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='electricity', root_path='./dataset/electricity', data_path='electricity.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=168, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.5990
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.7475948
	speed: 0.0193s/iter; left time: 404.3729s
	iters: 200, epoch: 1 | loss: 25.3295727
	speed: 0.0137s/iter; left time: 285.5666s
Epoch: 1 cost time: 3.4682018756866455
Epoch: 1, Steps: 210 Train Loss: 25.5362 (Forecasting Loss:0.8384 + XiCon Loss:2.4698 x Lambda(10.0)), Vali MSE Loss: 0.2800 Test MSE Loss: 0.6958
Validation loss decreased (inf --> 0.279981).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 24.1474781
	speed: 0.0170s/iter; left time: 352.1618s
	iters: 200, epoch: 2 | loss: 23.5964813
	speed: 0.0143s/iter; left time: 294.7709s
Epoch: 2 cost time: 3.317507028579712
Epoch: 2, Steps: 210 Train Loss: 23.5702 (Forecasting Loss:0.5787 + XiCon Loss:2.2992 x Lambda(10.0)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.5042
Validation loss decreased (0.279981 --> 0.266156).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 23.6826801
	speed: 0.0176s/iter; left time: 360.5563s
	iters: 200, epoch: 3 | loss: 23.0907116
	speed: 0.0155s/iter; left time: 315.7288s
Epoch: 3 cost time: 3.4931552410125732
Epoch: 3, Steps: 210 Train Loss: 23.2446 (Forecasting Loss:0.5089 + XiCon Loss:2.2736 x Lambda(10.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.5925
Validation loss decreased (0.266156 --> 0.249304).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 22.6111412
	speed: 0.0182s/iter; left time: 368.4215s
	iters: 200, epoch: 4 | loss: 22.6230621
	speed: 0.0154s/iter; left time: 310.8542s
Epoch: 4 cost time: 3.546130895614624
Epoch: 4, Steps: 210 Train Loss: 23.3891 (Forecasting Loss:0.4901 + XiCon Loss:2.2899 x Lambda(10.0)), Vali MSE Loss: 0.2321 Test MSE Loss: 0.4962
Validation loss decreased (0.249304 --> 0.232063).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.6306057
	speed: 0.0176s/iter; left time: 353.8558s
	iters: 200, epoch: 5 | loss: 22.8202534
	speed: 0.0158s/iter; left time: 314.8458s
Epoch: 5 cost time: 3.5310521125793457
Epoch: 5, Steps: 210 Train Loss: 23.1955 (Forecasting Loss:0.4741 + XiCon Loss:2.2721 x Lambda(10.0)), Vali MSE Loss: 0.2280 Test MSE Loss: 0.4611
Validation loss decreased (0.232063 --> 0.228012).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 23.3372269
	speed: 0.0181s/iter; left time: 358.9662s
	iters: 200, epoch: 6 | loss: 23.5219059
	speed: 0.0153s/iter; left time: 303.0187s
Epoch: 6 cost time: 3.528888463973999
Epoch: 6, Steps: 210 Train Loss: 23.0727 (Forecasting Loss:0.4614 + XiCon Loss:2.2611 x Lambda(10.0)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.4804
Validation loss decreased (0.228012 --> 0.222233).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 22.9076996
	speed: 0.0178s/iter; left time: 350.2544s
	iters: 200, epoch: 7 | loss: 23.3621044
	speed: 0.0157s/iter; left time: 307.5023s
Epoch: 7 cost time: 3.5382041931152344
Epoch: 7, Steps: 210 Train Loss: 23.0134 (Forecasting Loss:0.4608 + XiCon Loss:2.2553 x Lambda(10.0)), Vali MSE Loss: 0.2393 Test MSE Loss: 0.4739
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 22.9871216
	speed: 0.0181s/iter; left time: 350.7323s
	iters: 200, epoch: 8 | loss: 23.9734402
	speed: 0.0153s/iter; left time: 295.3674s
Epoch: 8 cost time: 3.525670051574707
Epoch: 8, Steps: 210 Train Loss: 23.0060 (Forecasting Loss:0.4568 + XiCon Loss:2.2549 x Lambda(10.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.4733
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 22.6503010
	speed: 0.0176s/iter; left time: 337.5490s
	iters: 200, epoch: 9 | loss: 22.4585457
	speed: 0.0158s/iter; left time: 302.2181s
Epoch: 9 cost time: 3.5252163410186768
Epoch: 9, Steps: 210 Train Loss: 23.0101 (Forecasting Loss:0.4572 + XiCon Loss:2.2553 x Lambda(10.0)), Vali MSE Loss: 0.2320 Test MSE Loss: 0.4761
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.6934738
	speed: 0.0178s/iter; left time: 337.4497s
	iters: 200, epoch: 10 | loss: 22.3194084
	speed: 0.0157s/iter; left time: 296.6361s
Epoch: 10 cost time: 3.533684730529785
Epoch: 10, Steps: 210 Train Loss: 22.9843 (Forecasting Loss:0.4562 + XiCon Loss:2.2528 x Lambda(10.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.4768
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 23.2454739
	speed: 0.0180s/iter; left time: 338.2585s
	iters: 200, epoch: 11 | loss: 23.0587158
	speed: 0.0156s/iter; left time: 291.6692s
Epoch: 11 cost time: 3.5538418292999268
Epoch: 11, Steps: 210 Train Loss: 22.9648 (Forecasting Loss:0.4569 + XiCon Loss:2.2508 x Lambda(10.0)), Vali MSE Loss: 0.2330 Test MSE Loss: 0.4789
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 23.2098255
	speed: 0.0180s/iter; left time: 333.7493s
	iters: 200, epoch: 12 | loss: 22.7750912
	speed: 0.0154s/iter; left time: 285.4585s
Epoch: 12 cost time: 3.5210611820220947
Epoch: 12, Steps: 210 Train Loss: 22.9803 (Forecasting Loss:0.4559 + XiCon Loss:2.2524 x Lambda(10.0)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.4796
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 22.3936958
	speed: 0.0182s/iter; left time: 334.6349s
	iters: 200, epoch: 13 | loss: 23.9847412
	speed: 0.0156s/iter; left time: 284.8469s
Epoch: 13 cost time: 3.5759670734405518
Epoch: 13, Steps: 210 Train Loss: 22.9598 (Forecasting Loss:0.4550 + XiCon Loss:2.2505 x Lambda(10.0)), Vali MSE Loss: 0.2341 Test MSE Loss: 0.4796
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 22.5740662
	speed: 0.0178s/iter; left time: 323.0867s
	iters: 200, epoch: 14 | loss: 23.2377834
	speed: 0.0153s/iter; left time: 276.1576s
Epoch: 14 cost time: 3.4949514865875244
Epoch: 14, Steps: 210 Train Loss: 22.9658 (Forecasting Loss:0.4559 + XiCon Loss:2.2510 x Lambda(10.0)), Vali MSE Loss: 0.2338 Test MSE Loss: 0.4796
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 22.2575493
	speed: 0.0181s/iter; left time: 324.6318s
	iters: 200, epoch: 15 | loss: 23.0956554
	speed: 0.0158s/iter; left time: 282.5055s
Epoch: 15 cost time: 3.5743472576141357
Epoch: 15, Steps: 210 Train Loss: 22.9918 (Forecasting Loss:0.4564 + XiCon Loss:2.2535 x Lambda(10.0)), Vali MSE Loss: 0.2340 Test MSE Loss: 0.4795
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 23.4594421
	speed: 0.0183s/iter; left time: 324.4151s
	iters: 200, epoch: 16 | loss: 22.5599499
	speed: 0.0158s/iter; left time: 278.4751s
Epoch: 16 cost time: 3.5933258533477783
Epoch: 16, Steps: 210 Train Loss: 22.9350 (Forecasting Loss:0.4550 + XiCon Loss:2.2480 x Lambda(10.0)), Vali MSE Loss: 0.2339 Test MSE Loss: 0.4795
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.4464004337787628, mae:0.5144805312156677, mape:3.81231427192688, mspe:19707.126953125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.5574
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.6173458
	speed: 0.0169s/iter; left time: 354.2181s
	iters: 200, epoch: 1 | loss: 24.7304764
	speed: 0.0138s/iter; left time: 286.9849s
Epoch: 1 cost time: 3.2420554161071777
Epoch: 1, Steps: 210 Train Loss: 25.4594 (Forecasting Loss:0.8412 + XiCon Loss:2.4618 x Lambda(10.0)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.6754
Validation loss decreased (inf --> 0.280553).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 23.7547588
	speed: 0.0190s/iter; left time: 392.2313s
	iters: 200, epoch: 2 | loss: 25.2134247
	speed: 0.0166s/iter; left time: 342.4649s
Epoch: 2 cost time: 3.744988203048706
Epoch: 2, Steps: 210 Train Loss: 24.0200 (Forecasting Loss:0.6831 + XiCon Loss:2.3337 x Lambda(10.0)), Vali MSE Loss: 0.2643 Test MSE Loss: 0.5558
Validation loss decreased (0.280553 --> 0.264349).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 24.7367229
	speed: 0.0184s/iter; left time: 377.8268s
	iters: 200, epoch: 3 | loss: 24.3771000
	speed: 0.0169s/iter; left time: 343.4925s
Epoch: 3 cost time: 3.7225613594055176
Epoch: 3, Steps: 210 Train Loss: 24.4765 (Forecasting Loss:0.5200 + XiCon Loss:2.3956 x Lambda(10.0)), Vali MSE Loss: 0.2376 Test MSE Loss: 0.5598
Validation loss decreased (0.264349 --> 0.237572).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 22.6833477
	speed: 0.0186s/iter; left time: 376.3085s
	iters: 200, epoch: 4 | loss: 23.4632092
	speed: 0.0165s/iter; left time: 331.8338s
Epoch: 4 cost time: 3.700113534927368
Epoch: 4, Steps: 210 Train Loss: 23.8919 (Forecasting Loss:0.4913 + XiCon Loss:2.3401 x Lambda(10.0)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.5632
Validation loss decreased (0.237572 --> 0.227147).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.8463917
	speed: 0.0191s/iter; left time: 382.4969s
	iters: 200, epoch: 5 | loss: 24.8682842
	speed: 0.0165s/iter; left time: 329.8152s
Epoch: 5 cost time: 3.7527365684509277
Epoch: 5, Steps: 210 Train Loss: 23.6412 (Forecasting Loss:0.4778 + XiCon Loss:2.3163 x Lambda(10.0)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.6012
Validation loss decreased (0.227147 --> 0.218895).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 23.7296371
	speed: 0.0193s/iter; left time: 382.5274s
	iters: 200, epoch: 6 | loss: 22.4792728
	speed: 0.0162s/iter; left time: 320.5524s
Epoch: 6 cost time: 3.759544610977173
Epoch: 6, Steps: 210 Train Loss: 23.5790 (Forecasting Loss:0.4713 + XiCon Loss:2.3108 x Lambda(10.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.5786
Validation loss decreased (0.218895 --> 0.218672).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 23.7242260
	speed: 0.0189s/iter; left time: 371.0629s
	iters: 200, epoch: 7 | loss: 23.4216137
	speed: 0.0159s/iter; left time: 310.0159s
Epoch: 7 cost time: 3.688061237335205
Epoch: 7, Steps: 210 Train Loss: 23.5456 (Forecasting Loss:0.4680 + XiCon Loss:2.3078 x Lambda(10.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.5766
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 23.5275841
	speed: 0.0185s/iter; left time: 358.5900s
	iters: 200, epoch: 8 | loss: 23.8746090
	speed: 0.0168s/iter; left time: 324.4331s
Epoch: 8 cost time: 3.7459335327148438
Epoch: 8, Steps: 210 Train Loss: 23.5617 (Forecasting Loss:0.4665 + XiCon Loss:2.3095 x Lambda(10.0)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.5803
Validation loss decreased (0.218672 --> 0.218541).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 23.1714001
	speed: 0.0188s/iter; left time: 362.0754s
	iters: 200, epoch: 9 | loss: 23.8105278
	speed: 0.0167s/iter; left time: 319.0191s
Epoch: 9 cost time: 3.7483839988708496
Epoch: 9, Steps: 210 Train Loss: 23.5593 (Forecasting Loss:0.4673 + XiCon Loss:2.3092 x Lambda(10.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5772
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 22.8254204
	speed: 0.0189s/iter; left time: 359.8879s
	iters: 200, epoch: 10 | loss: 23.5091381
	speed: 0.0164s/iter; left time: 309.8485s
Epoch: 10 cost time: 3.732027053833008
Epoch: 10, Steps: 210 Train Loss: 23.5138 (Forecasting Loss:0.4658 + XiCon Loss:2.3048 x Lambda(10.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.5792
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 23.1341438
	speed: 0.0186s/iter; left time: 349.4751s
	iters: 200, epoch: 11 | loss: 23.2200031
	speed: 0.0163s/iter; left time: 304.8116s
Epoch: 11 cost time: 3.677534580230713
Epoch: 11, Steps: 210 Train Loss: 23.5288 (Forecasting Loss:0.4646 + XiCon Loss:2.3064 x Lambda(10.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5786
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 23.6013584
	speed: 0.0187s/iter; left time: 346.9329s
	iters: 200, epoch: 12 | loss: 23.4301033
	speed: 0.0162s/iter; left time: 300.4637s
Epoch: 12 cost time: 3.6817822456359863
Epoch: 12, Steps: 210 Train Loss: 23.5670 (Forecasting Loss:0.4648 + XiCon Loss:2.3102 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.5796
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 22.6821671
	speed: 0.0189s/iter; left time: 346.7880s
	iters: 200, epoch: 13 | loss: 22.9401875
	speed: 0.0161s/iter; left time: 294.2170s
Epoch: 13 cost time: 3.6963231563568115
Epoch: 13, Steps: 210 Train Loss: 23.5000 (Forecasting Loss:0.4654 + XiCon Loss:2.3035 x Lambda(10.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.5797
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 23.2675343
	speed: 0.0184s/iter; left time: 334.6535s
	iters: 200, epoch: 14 | loss: 23.1904659
	speed: 0.0163s/iter; left time: 295.3101s
Epoch: 14 cost time: 3.6977407932281494
Epoch: 14, Steps: 210 Train Loss: 23.4472 (Forecasting Loss:0.4646 + XiCon Loss:2.2983 x Lambda(10.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.5796
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 23.8099823
	speed: 0.0186s/iter; left time: 334.2018s
	iters: 200, epoch: 15 | loss: 23.5297775
	speed: 0.0164s/iter; left time: 293.2803s
Epoch: 15 cost time: 3.6969242095947266
Epoch: 15, Steps: 210 Train Loss: 23.4321 (Forecasting Loss:0.4654 + XiCon Loss:2.2967 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.5795
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 24.1970959
	speed: 0.0188s/iter; left time: 333.3239s
	iters: 200, epoch: 16 | loss: 22.8090839
	speed: 0.0168s/iter; left time: 296.1040s
Epoch: 16 cost time: 3.7559874057769775
Epoch: 16, Steps: 210 Train Loss: 23.5046 (Forecasting Loss:0.4643 + XiCon Loss:2.3040 x Lambda(10.0)), Vali MSE Loss: 0.2195 Test MSE Loss: 0.5797
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 23.4426498
	speed: 0.0186s/iter; left time: 325.6092s
	iters: 200, epoch: 17 | loss: 23.9139538
	speed: 0.0163s/iter; left time: 283.7645s
Epoch: 17 cost time: 3.686835289001465
Epoch: 17, Steps: 210 Train Loss: 23.5195 (Forecasting Loss:0.4650 + XiCon Loss:2.3055 x Lambda(10.0)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.5797
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 23.5049934
	speed: 0.0187s/iter; left time: 324.8146s
	iters: 200, epoch: 18 | loss: 24.3691158
	speed: 0.0165s/iter; left time: 284.1013s
Epoch: 18 cost time: 3.7155704498291016
Epoch: 18, Steps: 210 Train Loss: 23.5837 (Forecasting Loss:0.4658 + XiCon Loss:2.3118 x Lambda(10.0)), Vali MSE Loss: 0.2196 Test MSE Loss: 0.5797
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5688533186912537, mae:0.5918417572975159, mape:3.2873644828796387, mspe:1873.1873779296875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.5957
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.4296551
	speed: 0.0169s/iter; left time: 353.0728s
	iters: 200, epoch: 1 | loss: 24.8068333
	speed: 0.0139s/iter; left time: 288.4713s
Epoch: 1 cost time: 3.245107650756836
Epoch: 1, Steps: 210 Train Loss: 25.2952 (Forecasting Loss:0.8416 + XiCon Loss:2.4454 x Lambda(10.0)), Vali MSE Loss: 0.2791 Test MSE Loss: 0.6910
Validation loss decreased (inf --> 0.279107).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 23.6540279
	speed: 0.0185s/iter; left time: 383.2839s
	iters: 200, epoch: 2 | loss: 24.8151913
	speed: 0.0164s/iter; left time: 337.9182s
Epoch: 2 cost time: 3.6965525150299072
Epoch: 2, Steps: 210 Train Loss: 23.9955 (Forecasting Loss:0.6853 + XiCon Loss:2.3310 x Lambda(10.0)), Vali MSE Loss: 0.2423 Test MSE Loss: 0.5464
Validation loss decreased (0.279107 --> 0.242314).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 24.7792988
	speed: 0.0192s/iter; left time: 393.2454s
	iters: 200, epoch: 3 | loss: 23.8672447
	speed: 0.0168s/iter; left time: 342.8824s
Epoch: 3 cost time: 3.7997183799743652
Epoch: 3, Steps: 210 Train Loss: 24.7781 (Forecasting Loss:0.5280 + XiCon Loss:2.4250 x Lambda(10.0)), Vali MSE Loss: 0.2469 Test MSE Loss: 0.5394
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 24.0743980
	speed: 0.0194s/iter; left time: 392.2682s
	iters: 200, epoch: 4 | loss: 24.4181290
	speed: 0.0171s/iter; left time: 344.0710s
Epoch: 4 cost time: 3.8399863243103027
Epoch: 4, Steps: 210 Train Loss: 24.2495 (Forecasting Loss:0.5053 + XiCon Loss:2.3744 x Lambda(10.0)), Vali MSE Loss: 0.2386 Test MSE Loss: 0.5301
Validation loss decreased (0.242314 --> 0.238633).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 23.4903412
	speed: 0.0194s/iter; left time: 389.3507s
	iters: 200, epoch: 5 | loss: 23.9145718
	speed: 0.0169s/iter; left time: 336.5275s
Epoch: 5 cost time: 3.822625160217285
Epoch: 5, Steps: 210 Train Loss: 24.0940 (Forecasting Loss:0.4980 + XiCon Loss:2.3596 x Lambda(10.0)), Vali MSE Loss: 0.2344 Test MSE Loss: 0.5311
Validation loss decreased (0.238633 --> 0.234441).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 24.1051788
	speed: 0.0188s/iter; left time: 372.3688s
	iters: 200, epoch: 6 | loss: 24.5596199
	speed: 0.0163s/iter; left time: 322.7952s
Epoch: 6 cost time: 3.7252418994903564
Epoch: 6, Steps: 210 Train Loss: 23.9515 (Forecasting Loss:0.4931 + XiCon Loss:2.3458 x Lambda(10.0)), Vali MSE Loss: 0.2355 Test MSE Loss: 0.5322
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 23.8484306
	speed: 0.0189s/iter; left time: 370.6945s
	iters: 200, epoch: 7 | loss: 24.1893768
	speed: 0.0167s/iter; left time: 326.9902s
Epoch: 7 cost time: 3.7583820819854736
Epoch: 7, Steps: 210 Train Loss: 23.9926 (Forecasting Loss:0.4899 + XiCon Loss:2.3503 x Lambda(10.0)), Vali MSE Loss: 0.2345 Test MSE Loss: 0.5311
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 23.9754562
	speed: 0.0188s/iter; left time: 364.6167s
	iters: 200, epoch: 8 | loss: 24.7385311
	speed: 0.0162s/iter; left time: 312.2588s
Epoch: 8 cost time: 3.7104995250701904
Epoch: 8, Steps: 210 Train Loss: 23.9765 (Forecasting Loss:0.4885 + XiCon Loss:2.3488 x Lambda(10.0)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.5314
Validation loss decreased (0.234441 --> 0.231860).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 24.1601925
	speed: 0.0187s/iter; left time: 358.9352s
	iters: 200, epoch: 9 | loss: 23.8636398
	speed: 0.0164s/iter; left time: 313.2250s
Epoch: 9 cost time: 3.7074105739593506
Epoch: 9, Steps: 210 Train Loss: 23.9226 (Forecasting Loss:0.4873 + XiCon Loss:2.3435 x Lambda(10.0)), Vali MSE Loss: 0.2307 Test MSE Loss: 0.5304
Validation loss decreased (0.231860 --> 0.230691).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 23.6816139
	speed: 0.0189s/iter; left time: 360.1531s
	iters: 200, epoch: 10 | loss: 24.2454338
	speed: 0.0165s/iter; left time: 311.1122s
Epoch: 10 cost time: 3.7311811447143555
Epoch: 10, Steps: 210 Train Loss: 23.9029 (Forecasting Loss:0.4866 + XiCon Loss:2.3416 x Lambda(10.0)), Vali MSE Loss: 0.2322 Test MSE Loss: 0.5307
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 24.1906605
	speed: 0.0184s/iter; left time: 346.8210s
	iters: 200, epoch: 11 | loss: 24.5951176
	speed: 0.0165s/iter; left time: 308.2627s
Epoch: 11 cost time: 3.6945061683654785
Epoch: 11, Steps: 210 Train Loss: 23.9059 (Forecasting Loss:0.4870 + XiCon Loss:2.3419 x Lambda(10.0)), Vali MSE Loss: 0.2308 Test MSE Loss: 0.5306
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 22.6352940
	speed: 0.0183s/iter; left time: 341.0987s
	iters: 200, epoch: 12 | loss: 23.9202213
	speed: 0.0161s/iter; left time: 298.4869s
Epoch: 12 cost time: 3.6592695713043213
Epoch: 12, Steps: 210 Train Loss: 23.9016 (Forecasting Loss:0.4865 + XiCon Loss:2.3415 x Lambda(10.0)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.5306
Validation loss decreased (0.230691 --> 0.230544).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 23.7246780
	speed: 0.0186s/iter; left time: 342.3588s
	iters: 200, epoch: 13 | loss: 23.5478725
	speed: 0.0168s/iter; left time: 307.1408s
Epoch: 13 cost time: 3.7369320392608643
Epoch: 13, Steps: 210 Train Loss: 23.9244 (Forecasting Loss:0.4865 + XiCon Loss:2.3438 x Lambda(10.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.5307
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 23.4962864
	speed: 0.0194s/iter; left time: 351.9954s
	iters: 200, epoch: 14 | loss: 24.3235645
	speed: 0.0164s/iter; left time: 295.5940s
Epoch: 14 cost time: 3.768265724182129
Epoch: 14, Steps: 210 Train Loss: 23.9308 (Forecasting Loss:0.4867 + XiCon Loss:2.3444 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 22.9771175
	speed: 0.0187s/iter; left time: 335.3052s
	iters: 200, epoch: 15 | loss: 23.8163033
	speed: 0.0164s/iter; left time: 292.9785s
Epoch: 15 cost time: 3.708627223968506
Epoch: 15, Steps: 210 Train Loss: 23.9275 (Forecasting Loss:0.4862 + XiCon Loss:2.3441 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 24.0413475
	speed: 0.0188s/iter; left time: 333.2082s
	iters: 200, epoch: 16 | loss: 24.2134514
	speed: 0.0167s/iter; left time: 295.4639s
Epoch: 16 cost time: 3.748938798904419
Epoch: 16, Steps: 210 Train Loss: 23.8510 (Forecasting Loss:0.4867 + XiCon Loss:2.3364 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 24.2210293
	speed: 0.0190s/iter; left time: 333.3785s
	iters: 200, epoch: 17 | loss: 24.3436623
	speed: 0.0166s/iter; left time: 289.2656s
Epoch: 17 cost time: 3.7526967525482178
Epoch: 17, Steps: 210 Train Loss: 23.8248 (Forecasting Loss:0.4865 + XiCon Loss:2.3338 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 22.6971569
	speed: 0.0184s/iter; left time: 318.8767s
	iters: 200, epoch: 18 | loss: 24.5650425
	speed: 0.0172s/iter; left time: 296.2287s
Epoch: 18 cost time: 3.749882221221924
Epoch: 18, Steps: 210 Train Loss: 23.9744 (Forecasting Loss:0.4866 + XiCon Loss:2.3488 x Lambda(10.0)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.5307
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 23.7699814
	speed: 0.0186s/iter; left time: 318.6240s
	iters: 200, epoch: 19 | loss: 23.5177917
	speed: 0.0162s/iter; left time: 275.5819s
Epoch: 19 cost time: 3.671599864959717
Epoch: 19, Steps: 210 Train Loss: 23.8640 (Forecasting Loss:0.4865 + XiCon Loss:2.3378 x Lambda(10.0)), Vali MSE Loss: 0.2313 Test MSE Loss: 0.5307
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 24.9732475
	speed: 0.0183s/iter; left time: 309.5470s
	iters: 200, epoch: 20 | loss: 23.8251553
	speed: 0.0166s/iter; left time: 279.4608s
Epoch: 20 cost time: 3.6867799758911133
Epoch: 20, Steps: 210 Train Loss: 23.9233 (Forecasting Loss:0.4863 + XiCon Loss:2.3437 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 23.6361694
	speed: 0.0188s/iter; left time: 314.7106s
	iters: 200, epoch: 21 | loss: 23.2731400
	speed: 0.0166s/iter; left time: 276.2220s
Epoch: 21 cost time: 3.7497682571411133
Epoch: 21, Steps: 210 Train Loss: 23.8670 (Forecasting Loss:0.4866 + XiCon Loss:2.3380 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 24.9492645
	speed: 0.0187s/iter; left time: 307.8442s
	iters: 200, epoch: 22 | loss: 24.8619957
	speed: 0.0166s/iter; left time: 271.9255s
Epoch: 22 cost time: 3.7229418754577637
Epoch: 22, Steps: 210 Train Loss: 23.8569 (Forecasting Loss:0.4866 + XiCon Loss:2.3370 x Lambda(10.0)), Vali MSE Loss: 0.2311 Test MSE Loss: 0.5307
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.5057738423347473, mae:0.5554679036140442, mape:3.6203811168670654, mspe:8443.4326171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.7862
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.2809868
	speed: 0.0199s/iter; left time: 415.6887s
	iters: 200, epoch: 1 | loss: 24.8276596
	speed: 0.0138s/iter; left time: 286.3230s
Epoch: 1 cost time: 3.5426199436187744
Epoch: 1, Steps: 210 Train Loss: 25.3341 (Forecasting Loss:0.8312 + XiCon Loss:2.4503 x Lambda(10.0)), Vali MSE Loss: 0.2779 Test MSE Loss: 0.6639
Validation loss decreased (inf --> 0.277864).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 25.1085739
	speed: 0.0186s/iter; left time: 384.8213s
	iters: 200, epoch: 2 | loss: 24.2050438
	speed: 0.0154s/iter; left time: 316.8427s
Epoch: 2 cost time: 3.585702896118164
Epoch: 2, Steps: 210 Train Loss: 24.7718 (Forecasting Loss:0.5944 + XiCon Loss:2.4177 x Lambda(10.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.5928
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 25.0412941
	speed: 0.0177s/iter; left time: 363.2137s
	iters: 200, epoch: 3 | loss: 24.4931908
	speed: 0.0159s/iter; left time: 323.3335s
Epoch: 3 cost time: 3.5539071559906006
Epoch: 3, Steps: 210 Train Loss: 24.5479 (Forecasting Loss:0.5257 + XiCon Loss:2.4022 x Lambda(10.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.5743
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 24.1973763
	speed: 0.0183s/iter; left time: 371.2323s
	iters: 200, epoch: 4 | loss: 24.3067188
	speed: 0.0158s/iter; left time: 317.8982s
Epoch: 4 cost time: 3.595069408416748
Epoch: 4, Steps: 210 Train Loss: 24.1124 (Forecasting Loss:0.5127 + XiCon Loss:2.3600 x Lambda(10.0)), Vali MSE Loss: 0.2952 Test MSE Loss: 0.5663
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 23.5834866
	speed: 0.0191s/iter; left time: 382.2942s
	iters: 200, epoch: 5 | loss: 24.3370247
	speed: 0.0158s/iter; left time: 314.7271s
Epoch: 5 cost time: 3.683284044265747
Epoch: 5, Steps: 210 Train Loss: 23.9136 (Forecasting Loss:0.5115 + XiCon Loss:2.3402 x Lambda(10.0)), Vali MSE Loss: 0.2939 Test MSE Loss: 0.5326
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 23.9006500
	speed: 0.0187s/iter; left time: 370.5656s
	iters: 200, epoch: 6 | loss: 24.3690529
	speed: 0.0159s/iter; left time: 314.3263s
Epoch: 6 cost time: 3.6526410579681396
Epoch: 6, Steps: 210 Train Loss: 23.8842 (Forecasting Loss:0.5111 + XiCon Loss:2.3373 x Lambda(10.0)), Vali MSE Loss: 0.2919 Test MSE Loss: 0.5427
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 24.7470207
	speed: 0.0185s/iter; left time: 362.4417s
	iters: 200, epoch: 7 | loss: 23.6546364
	speed: 0.0161s/iter; left time: 315.5669s
Epoch: 7 cost time: 3.6626691818237305
Epoch: 7, Steps: 210 Train Loss: 23.7629 (Forecasting Loss:0.5167 + XiCon Loss:2.3246 x Lambda(10.0)), Vali MSE Loss: 0.2911 Test MSE Loss: 0.5267
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 24.8796024
	speed: 0.0184s/iter; left time: 357.9662s
	iters: 200, epoch: 8 | loss: 24.6504002
	speed: 0.0162s/iter; left time: 312.3300s
Epoch: 8 cost time: 3.649078130722046
Epoch: 8, Steps: 210 Train Loss: 23.7727 (Forecasting Loss:0.5157 + XiCon Loss:2.3257 x Lambda(10.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.5304
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 24.0719738
	speed: 0.0185s/iter; left time: 355.3293s
	iters: 200, epoch: 9 | loss: 23.2792664
	speed: 0.0161s/iter; left time: 308.2330s
Epoch: 9 cost time: 3.656270980834961
Epoch: 9, Steps: 210 Train Loss: 23.7500 (Forecasting Loss:0.5162 + XiCon Loss:2.3234 x Lambda(10.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.5301
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 23.8054905
	speed: 0.0185s/iter; left time: 352.3369s
	iters: 200, epoch: 10 | loss: 23.8043194
	speed: 0.0165s/iter; left time: 311.3442s
Epoch: 10 cost time: 3.6939728260040283
Epoch: 10, Steps: 210 Train Loss: 23.7957 (Forecasting Loss:0.5162 + XiCon Loss:2.3279 x Lambda(10.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.5295
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 23.6086349
	speed: 0.0187s/iter; left time: 352.1241s
	iters: 200, epoch: 11 | loss: 24.1847725
	speed: 0.0163s/iter; left time: 305.5582s
Epoch: 11 cost time: 3.6995835304260254
Epoch: 11, Steps: 210 Train Loss: 23.7282 (Forecasting Loss:0.5153 + XiCon Loss:2.3213 x Lambda(10.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.5302
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.6790762543678284, mae:0.6487959027290344, mape:6.311988830566406, mspe:96302.7578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:735457
train 13455
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99980268] ~ [1.83286448e-04 9.23152030e-05]
Xi-correlation values:[0.99980992 0.99304875] ~ [0. 1.]
Autocorrelation calculation time: 4.6181
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 13455
val 3103
test 3101
	iters: 100, epoch: 1 | loss: 25.8320217
	speed: 0.0164s/iter; left time: 342.0459s
	iters: 200, epoch: 1 | loss: 25.0940361
	speed: 0.0144s/iter; left time: 298.6982s
Epoch: 1 cost time: 3.2456703186035156
Epoch: 1, Steps: 210 Train Loss: 25.3601 (Forecasting Loss:0.8455 + XiCon Loss:2.4515 x Lambda(10.0)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.6821
Validation loss decreased (inf --> 0.279657).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 22.9261932
	speed: 0.0185s/iter; left time: 383.4679s
	iters: 200, epoch: 2 | loss: 25.4502487
	speed: 0.0166s/iter; left time: 340.8531s
Epoch: 2 cost time: 3.7088003158569336
Epoch: 2, Steps: 210 Train Loss: 23.9908 (Forecasting Loss:0.7102 + XiCon Loss:2.3281 x Lambda(10.0)), Vali MSE Loss: 0.2435 Test MSE Loss: 0.6301
Validation loss decreased (0.279657 --> 0.243542).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 25.1854362
	speed: 0.0186s/iter; left time: 380.6408s
	iters: 200, epoch: 3 | loss: 24.5544415
	speed: 0.0167s/iter; left time: 339.4181s
Epoch: 3 cost time: 3.7400946617126465
Epoch: 3, Steps: 210 Train Loss: 24.9849 (Forecasting Loss:0.6178 + XiCon Loss:2.4367 x Lambda(10.0)), Vali MSE Loss: 0.2318 Test MSE Loss: 0.5195
Validation loss decreased (0.243542 --> 0.231814).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 25.1854496
	speed: 0.0194s/iter; left time: 393.9522s
	iters: 200, epoch: 4 | loss: 25.1825981
	speed: 0.0174s/iter; left time: 351.0062s
Epoch: 4 cost time: 3.8928699493408203
Epoch: 4, Steps: 210 Train Loss: 24.4521 (Forecasting Loss:0.5527 + XiCon Loss:2.3899 x Lambda(10.0)), Vali MSE Loss: 0.2274 Test MSE Loss: 0.5032
Validation loss decreased (0.231814 --> 0.227380).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 22.8640118
	speed: 0.0193s/iter; left time: 387.0679s
	iters: 200, epoch: 5 | loss: 25.0939198
	speed: 0.0172s/iter; left time: 343.4762s
Epoch: 5 cost time: 3.8678431510925293
Epoch: 5, Steps: 210 Train Loss: 24.2237 (Forecasting Loss:0.5344 + XiCon Loss:2.3689 x Lambda(10.0)), Vali MSE Loss: 0.2275 Test MSE Loss: 0.5047
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 24.0524597
	speed: 0.0190s/iter; left time: 376.8252s
	iters: 200, epoch: 6 | loss: 23.3693981
	speed: 0.0169s/iter; left time: 333.6670s
Epoch: 6 cost time: 3.7862536907196045
Epoch: 6, Steps: 210 Train Loss: 24.1641 (Forecasting Loss:0.5271 + XiCon Loss:2.3637 x Lambda(10.0)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.5047
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 23.4568329
	speed: 0.0194s/iter; left time: 381.6929s
	iters: 200, epoch: 7 | loss: 23.8092155
	speed: 0.0176s/iter; left time: 343.4213s
Epoch: 7 cost time: 3.9069478511810303
Epoch: 7, Steps: 210 Train Loss: 24.1074 (Forecasting Loss:0.5236 + XiCon Loss:2.3584 x Lambda(10.0)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.5067
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 23.3192024
	speed: 0.0193s/iter; left time: 375.1123s
	iters: 200, epoch: 8 | loss: 24.7220249
	speed: 0.0168s/iter; left time: 323.8955s
Epoch: 8 cost time: 3.805159091949463
Epoch: 8, Steps: 210 Train Loss: 24.0775 (Forecasting Loss:0.5217 + XiCon Loss:2.3556 x Lambda(10.0)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.5050
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 24.1501789
	speed: 0.0190s/iter; left time: 365.2597s
	iters: 200, epoch: 9 | loss: 24.0969810
	speed: 0.0167s/iter; left time: 319.8257s
Epoch: 9 cost time: 3.7790088653564453
Epoch: 9, Steps: 210 Train Loss: 24.0423 (Forecasting Loss:0.5207 + XiCon Loss:2.3522 x Lambda(10.0)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.5049
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 24.3152218
	speed: 0.0190s/iter; left time: 361.9229s
	iters: 200, epoch: 10 | loss: 23.3829060
	speed: 0.0168s/iter; left time: 317.0640s
Epoch: 10 cost time: 3.7821435928344727
Epoch: 10, Steps: 210 Train Loss: 24.0310 (Forecasting Loss:0.5202 + XiCon Loss:2.3511 x Lambda(10.0)), Vali MSE Loss: 0.2285 Test MSE Loss: 0.5053
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 22.8535805
	speed: 0.0195s/iter; left time: 367.0141s
	iters: 200, epoch: 11 | loss: 24.0305748
	speed: 0.0169s/iter; left time: 316.0676s
Epoch: 11 cost time: 3.8529744148254395
Epoch: 11, Steps: 210 Train Loss: 24.0391 (Forecasting Loss:0.5199 + XiCon Loss:2.3519 x Lambda(10.0)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.5054
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 24.3557568
	speed: 0.0195s/iter; left time: 362.7519s
	iters: 200, epoch: 12 | loss: 24.6362877
	speed: 0.0172s/iter; left time: 317.4208s
Epoch: 12 cost time: 3.8674967288970947
Epoch: 12, Steps: 210 Train Loss: 24.0514 (Forecasting Loss:0.5197 + XiCon Loss:2.3532 x Lambda(10.0)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.5056
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 23.3274498
	speed: 0.0195s/iter; left time: 358.6967s
	iters: 200, epoch: 13 | loss: 25.2316036
	speed: 0.0169s/iter; left time: 309.2293s
Epoch: 13 cost time: 3.845032215118408
Epoch: 13, Steps: 210 Train Loss: 24.0654 (Forecasting Loss:0.5197 + XiCon Loss:2.3546 x Lambda(10.0)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.5057
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 23.3012810
	speed: 0.0191s/iter; left time: 346.5498s
	iters: 200, epoch: 14 | loss: 24.9342651
	speed: 0.0167s/iter; left time: 302.1427s
Epoch: 14 cost time: 3.7848241329193115
Epoch: 14, Steps: 210 Train Loss: 24.0313 (Forecasting Loss:0.5196 + XiCon Loss:2.3512 x Lambda(10.0)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.5057
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_electricity_ftS_sl168_ll48_pl2160_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 3101
test shape: (48, 64, 2160, 1) (48, 64, 2160, 1)
test shape: (3072, 2160, 1) (3072, 2160, 1)
mse:0.47955334186553955, mae:0.5269082188606262, mape:4.8561015129089355, mspe:46377.03125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5359+-0.11393, MAE:0.5675+-0.06745, MAPE:4.3776+-1.52734, MSPE:34540.7070+-47779.54592, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
