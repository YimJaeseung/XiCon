Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[14], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=14, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2825
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.9966528415679932
Epoch: 1, Steps: 38 Train Loss: 16.4718 (Forecasting Loss:0.4221 + XiCon Loss:1.6050 x Lambda(10.0)), Vali MSE Loss: 0.2642 Test MSE Loss: 1.0760
Validation loss decreased (inf --> 0.264180).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7155435085296631
Epoch: 2, Steps: 38 Train Loss: 15.6824 (Forecasting Loss:0.2651 + XiCon Loss:1.5417 x Lambda(10.0)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.5661
Validation loss decreased (0.264180 --> 0.172462).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6730899810791016
Epoch: 3, Steps: 38 Train Loss: 14.7931 (Forecasting Loss:0.1691 + XiCon Loss:1.4624 x Lambda(10.0)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6359
Validation loss decreased (0.172462 --> 0.117374).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.713383674621582
Epoch: 4, Steps: 38 Train Loss: 14.6745 (Forecasting Loss:0.1360 + XiCon Loss:1.4539 x Lambda(10.0)), Vali MSE Loss: 0.1108 Test MSE Loss: 0.5703
Validation loss decreased (0.117374 --> 0.110836).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6213648319244385
Epoch: 5, Steps: 38 Train Loss: 14.3015 (Forecasting Loss:0.1302 + XiCon Loss:1.4171 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5956
Validation loss decreased (0.110836 --> 0.107461).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.609576940536499
Epoch: 6, Steps: 38 Train Loss: 14.1902 (Forecasting Loss:0.1266 + XiCon Loss:1.4064 x Lambda(10.0)), Vali MSE Loss: 0.1058 Test MSE Loss: 0.5942
Validation loss decreased (0.107461 --> 0.105776).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6966440677642822
Epoch: 7, Steps: 38 Train Loss: 14.0853 (Forecasting Loss:0.1264 + XiCon Loss:1.3959 x Lambda(10.0)), Vali MSE Loss: 0.1053 Test MSE Loss: 0.5895
Validation loss decreased (0.105776 --> 0.105330).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6603751182556152
Epoch: 8, Steps: 38 Train Loss: 13.9810 (Forecasting Loss:0.1246 + XiCon Loss:1.3856 x Lambda(10.0)), Vali MSE Loss: 0.1052 Test MSE Loss: 0.5910
Validation loss decreased (0.105330 --> 0.105221).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6604921817779541
Epoch: 9, Steps: 38 Train Loss: 14.0277 (Forecasting Loss:0.1254 + XiCon Loss:1.3902 x Lambda(10.0)), Vali MSE Loss: 0.1052 Test MSE Loss: 0.5907
Validation loss decreased (0.105221 --> 0.105169).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6599256992340088
Epoch: 10, Steps: 38 Train Loss: 13.8579 (Forecasting Loss:0.1249 + XiCon Loss:1.3733 x Lambda(10.0)), Vali MSE Loss: 0.1051 Test MSE Loss: 0.5904
Validation loss decreased (0.105169 --> 0.105061).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6553785800933838
Epoch: 11, Steps: 38 Train Loss: 13.9581 (Forecasting Loss:0.1245 + XiCon Loss:1.3834 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.5902
Validation loss decreased (0.105061 --> 0.103932).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7238681316375732
Epoch: 12, Steps: 38 Train Loss: 13.9772 (Forecasting Loss:0.1237 + XiCon Loss:1.3854 x Lambda(10.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.5902
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6902682781219482
Epoch: 13, Steps: 38 Train Loss: 13.8470 (Forecasting Loss:0.1245 + XiCon Loss:1.3722 x Lambda(10.0)), Vali MSE Loss: 0.1049 Test MSE Loss: 0.5902
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7411861419677734
Epoch: 14, Steps: 38 Train Loss: 13.8809 (Forecasting Loss:0.1245 + XiCon Loss:1.3756 x Lambda(10.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.5902
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7346904277801514
Epoch: 15, Steps: 38 Train Loss: 13.9838 (Forecasting Loss:0.1248 + XiCon Loss:1.3859 x Lambda(10.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.5902
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6878213882446289
Epoch: 16, Steps: 38 Train Loss: 13.9679 (Forecasting Loss:0.1248 + XiCon Loss:1.3843 x Lambda(10.0)), Vali MSE Loss: 0.1051 Test MSE Loss: 0.5902
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7243845462799072
Epoch: 17, Steps: 38 Train Loss: 13.9392 (Forecasting Loss:0.1239 + XiCon Loss:1.3815 x Lambda(10.0)), Vali MSE Loss: 0.1049 Test MSE Loss: 0.5902
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6736948490142822
Epoch: 18, Steps: 38 Train Loss: 13.9607 (Forecasting Loss:0.1236 + XiCon Loss:1.3837 x Lambda(10.0)), Vali MSE Loss: 0.1050 Test MSE Loss: 0.5902
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7699501514434814
Epoch: 19, Steps: 38 Train Loss: 13.9359 (Forecasting Loss:0.1240 + XiCon Loss:1.3812 x Lambda(10.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.5902
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6628003120422363
Epoch: 20, Steps: 38 Train Loss: 13.8201 (Forecasting Loss:0.1248 + XiCon Loss:1.3695 x Lambda(10.0)), Vali MSE Loss: 0.1051 Test MSE Loss: 0.5902
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6958184242248535
Epoch: 21, Steps: 38 Train Loss: 14.0203 (Forecasting Loss:0.1247 + XiCon Loss:1.3896 x Lambda(10.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.5902
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.635634183883667, mae:0.5447505116462708, mape:0.2126031070947647, mspe:0.17687936127185822 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3544
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.746964693069458
Epoch: 1, Steps: 38 Train Loss: 16.5732 (Forecasting Loss:0.4904 + XiCon Loss:1.6083 x Lambda(10.0)), Vali MSE Loss: 0.3050 Test MSE Loss: 1.2943
Validation loss decreased (inf --> 0.305042).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7522780895233154
Epoch: 2, Steps: 38 Train Loss: 15.8414 (Forecasting Loss:0.2743 + XiCon Loss:1.5567 x Lambda(10.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.6419
Validation loss decreased (0.305042 --> 0.163801).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7191832065582275
Epoch: 3, Steps: 38 Train Loss: 15.0020 (Forecasting Loss:0.1689 + XiCon Loss:1.4833 x Lambda(10.0)), Vali MSE Loss: 0.1205 Test MSE Loss: 0.6406
Validation loss decreased (0.163801 --> 0.120472).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.765815258026123
Epoch: 4, Steps: 38 Train Loss: 14.8025 (Forecasting Loss:0.1379 + XiCon Loss:1.4665 x Lambda(10.0)), Vali MSE Loss: 0.1083 Test MSE Loss: 0.5952
Validation loss decreased (0.120472 --> 0.108342).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7118010520935059
Epoch: 5, Steps: 38 Train Loss: 14.7999 (Forecasting Loss:0.1304 + XiCon Loss:1.4669 x Lambda(10.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.5891
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7431132793426514
Epoch: 6, Steps: 38 Train Loss: 14.8355 (Forecasting Loss:0.1272 + XiCon Loss:1.4708 x Lambda(10.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.5971
Validation loss decreased (0.108342 --> 0.107797).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.735145092010498
Epoch: 7, Steps: 38 Train Loss: 14.7275 (Forecasting Loss:0.1258 + XiCon Loss:1.4602 x Lambda(10.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.5988
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6766026020050049
Epoch: 8, Steps: 38 Train Loss: 14.6234 (Forecasting Loss:0.1241 + XiCon Loss:1.4499 x Lambda(10.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.5963
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7915141582489014
Epoch: 9, Steps: 38 Train Loss: 14.9216 (Forecasting Loss:0.1223 + XiCon Loss:1.4799 x Lambda(10.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.5962
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7516219615936279
Epoch: 10, Steps: 38 Train Loss: 14.7274 (Forecasting Loss:0.1236 + XiCon Loss:1.4604 x Lambda(10.0)), Vali MSE Loss: 0.1090 Test MSE Loss: 0.5968
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7727198600769043
Epoch: 11, Steps: 38 Train Loss: 14.8262 (Forecasting Loss:0.1246 + XiCon Loss:1.4702 x Lambda(10.0)), Vali MSE Loss: 0.1092 Test MSE Loss: 0.5969
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7456808090209961
Epoch: 12, Steps: 38 Train Loss: 14.8057 (Forecasting Loss:0.1228 + XiCon Loss:1.4683 x Lambda(10.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.5971
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7191348075866699
Epoch: 13, Steps: 38 Train Loss: 15.0114 (Forecasting Loss:0.1227 + XiCon Loss:1.4889 x Lambda(10.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.5971
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.711418628692627
Epoch: 14, Steps: 38 Train Loss: 14.8129 (Forecasting Loss:0.1232 + XiCon Loss:1.4690 x Lambda(10.0)), Vali MSE Loss: 0.1087 Test MSE Loss: 0.5971
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7366769313812256
Epoch: 15, Steps: 38 Train Loss: 14.8530 (Forecasting Loss:0.1225 + XiCon Loss:1.4730 x Lambda(10.0)), Vali MSE Loss: 0.1089 Test MSE Loss: 0.5971
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7746031284332275
Epoch: 16, Steps: 38 Train Loss: 14.9948 (Forecasting Loss:0.1235 + XiCon Loss:1.4871 x Lambda(10.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.5971
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6547527313232422, mae:0.5393754243850708, mape:0.21239234507083893, mspe:0.1881006807088852 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3743
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7715537548065186
Epoch: 1, Steps: 38 Train Loss: 16.4309 (Forecasting Loss:0.5029 + XiCon Loss:1.5928 x Lambda(10.0)), Vali MSE Loss: 0.3003 Test MSE Loss: 1.4154
Validation loss decreased (inf --> 0.300347).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7506422996520996
Epoch: 2, Steps: 38 Train Loss: 15.7437 (Forecasting Loss:0.2884 + XiCon Loss:1.5455 x Lambda(10.0)), Vali MSE Loss: 0.1618 Test MSE Loss: 0.6368
Validation loss decreased (0.300347 --> 0.161765).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7575736045837402
Epoch: 3, Steps: 38 Train Loss: 14.8448 (Forecasting Loss:0.1650 + XiCon Loss:1.4680 x Lambda(10.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6291
Validation loss decreased (0.161765 --> 0.115618).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8192334175109863
Epoch: 4, Steps: 38 Train Loss: 14.6348 (Forecasting Loss:0.1395 + XiCon Loss:1.4495 x Lambda(10.0)), Vali MSE Loss: 0.1091 Test MSE Loss: 0.5943
Validation loss decreased (0.115618 --> 0.109124).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7206277847290039
Epoch: 5, Steps: 38 Train Loss: 14.7160 (Forecasting Loss:0.1313 + XiCon Loss:1.4585 x Lambda(10.0)), Vali MSE Loss: 0.1053 Test MSE Loss: 0.5940
Validation loss decreased (0.109124 --> 0.105310).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7083585262298584
Epoch: 6, Steps: 38 Train Loss: 14.5432 (Forecasting Loss:0.1293 + XiCon Loss:1.4414 x Lambda(10.0)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.6048
Validation loss decreased (0.105310 --> 0.104049).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6669998168945312
Epoch: 7, Steps: 38 Train Loss: 14.5418 (Forecasting Loss:0.1275 + XiCon Loss:1.4414 x Lambda(10.0)), Vali MSE Loss: 0.1044 Test MSE Loss: 0.5991
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.719745397567749
Epoch: 8, Steps: 38 Train Loss: 14.5118 (Forecasting Loss:0.1270 + XiCon Loss:1.4385 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5973
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7371203899383545
Epoch: 9, Steps: 38 Train Loss: 14.4763 (Forecasting Loss:0.1270 + XiCon Loss:1.4349 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5956
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7219302654266357
Epoch: 10, Steps: 38 Train Loss: 14.5698 (Forecasting Loss:0.1262 + XiCon Loss:1.4444 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.5961
Validation loss decreased (0.104049 --> 0.103904).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7326600551605225
Epoch: 11, Steps: 38 Train Loss: 14.4376 (Forecasting Loss:0.1268 + XiCon Loss:1.4311 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
Validation loss decreased (0.103904 --> 0.103794).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7467536926269531
Epoch: 12, Steps: 38 Train Loss: 14.4267 (Forecasting Loss:0.1261 + XiCon Loss:1.4301 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5960
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7589356899261475
Epoch: 13, Steps: 38 Train Loss: 14.5003 (Forecasting Loss:0.1261 + XiCon Loss:1.4374 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
Validation loss decreased (0.103794 --> 0.103768).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7891829013824463
Epoch: 14, Steps: 38 Train Loss: 14.6051 (Forecasting Loss:0.1268 + XiCon Loss:1.4478 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.5960
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7386589050292969
Epoch: 15, Steps: 38 Train Loss: 14.4336 (Forecasting Loss:0.1244 + XiCon Loss:1.4309 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7175028324127197
Epoch: 16, Steps: 38 Train Loss: 14.4830 (Forecasting Loss:0.1267 + XiCon Loss:1.4356 x Lambda(10.0)), Vali MSE Loss: 0.1036 Test MSE Loss: 0.5960
Validation loss decreased (0.103768 --> 0.103643).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7434241771697998
Epoch: 17, Steps: 38 Train Loss: 14.4653 (Forecasting Loss:0.1263 + XiCon Loss:1.4339 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7664263248443604
Epoch: 18, Steps: 38 Train Loss: 14.4277 (Forecasting Loss:0.1266 + XiCon Loss:1.4301 x Lambda(10.0)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.5960
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7585537433624268
Epoch: 19, Steps: 38 Train Loss: 14.5332 (Forecasting Loss:0.1273 + XiCon Loss:1.4406 x Lambda(10.0)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.5960
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6553022861480713
Epoch: 20, Steps: 38 Train Loss: 14.4669 (Forecasting Loss:0.1266 + XiCon Loss:1.4340 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6761429309844971
Epoch: 21, Steps: 38 Train Loss: 14.3712 (Forecasting Loss:0.1263 + XiCon Loss:1.4245 x Lambda(10.0)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.5960
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.8129568099975586
Epoch: 22, Steps: 38 Train Loss: 14.4591 (Forecasting Loss:0.1257 + XiCon Loss:1.4333 x Lambda(10.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.5960
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6977813243865967
Epoch: 23, Steps: 38 Train Loss: 14.4564 (Forecasting Loss:0.1261 + XiCon Loss:1.4330 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.5960
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7173960208892822
Epoch: 24, Steps: 38 Train Loss: 14.5209 (Forecasting Loss:0.1266 + XiCon Loss:1.4394 x Lambda(10.0)), Vali MSE Loss: 0.1033 Test MSE Loss: 0.5960
Validation loss decreased (0.103643 --> 0.103281).  Saving model ...
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7222237586975098
Epoch: 25, Steps: 38 Train Loss: 14.4253 (Forecasting Loss:0.1262 + XiCon Loss:1.4299 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.5960
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.6716976165771484
Epoch: 26, Steps: 38 Train Loss: 14.4488 (Forecasting Loss:0.1256 + XiCon Loss:1.4323 x Lambda(10.0)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.5960
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7467975616455078
Epoch: 27, Steps: 38 Train Loss: 14.5135 (Forecasting Loss:0.1259 + XiCon Loss:1.4388 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.6996943950653076
Epoch: 28, Steps: 38 Train Loss: 14.4777 (Forecasting Loss:0.1267 + XiCon Loss:1.4351 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.5960
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.7349193096160889
Epoch: 29, Steps: 38 Train Loss: 14.4483 (Forecasting Loss:0.1258 + XiCon Loss:1.4323 x Lambda(10.0)), Vali MSE Loss: 0.1034 Test MSE Loss: 0.5960
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7416307926177979
Epoch: 30, Steps: 38 Train Loss: 14.4736 (Forecasting Loss:0.1263 + XiCon Loss:1.4347 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5960
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.7401039600372314
Epoch: 31, Steps: 38 Train Loss: 14.4536 (Forecasting Loss:0.1257 + XiCon Loss:1.4328 x Lambda(10.0)), Vali MSE Loss: 0.1035 Test MSE Loss: 0.5960
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-12
Epoch: 32 cost time: 0.7611851692199707
Epoch: 32, Steps: 38 Train Loss: 14.5908 (Forecasting Loss:0.1266 + XiCon Loss:1.4464 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.5960
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386963e-12
Epoch: 33 cost time: 0.759136438369751
Epoch: 33, Steps: 38 Train Loss: 14.5093 (Forecasting Loss:0.1265 + XiCon Loss:1.4383 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.5960
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-12
Epoch: 34 cost time: 0.7162554264068604
Epoch: 34, Steps: 38 Train Loss: 14.5048 (Forecasting Loss:0.1257 + XiCon Loss:1.4379 x Lambda(10.0)), Vali MSE Loss: 0.1038 Test MSE Loss: 0.5960
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6498315334320068, mae:0.5421910285949707, mape:0.21399788558483124, mspe:0.18686585128307343 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3557
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.7083284854888916
Epoch: 1, Steps: 38 Train Loss: 16.5658 (Forecasting Loss:0.5319 + XiCon Loss:1.6034 x Lambda(10.0)), Vali MSE Loss: 0.3339 Test MSE Loss: 1.3750
Validation loss decreased (inf --> 0.333863).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7274577617645264
Epoch: 2, Steps: 38 Train Loss: 15.7162 (Forecasting Loss:0.2827 + XiCon Loss:1.5434 x Lambda(10.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.6454
Validation loss decreased (0.333863 --> 0.165453).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7601737976074219
Epoch: 3, Steps: 38 Train Loss: 14.6407 (Forecasting Loss:0.1658 + XiCon Loss:1.4475 x Lambda(10.0)), Vali MSE Loss: 0.1203 Test MSE Loss: 0.6127
Validation loss decreased (0.165453 --> 0.120271).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.8055064678192139
Epoch: 4, Steps: 38 Train Loss: 14.4930 (Forecasting Loss:0.1368 + XiCon Loss:1.4356 x Lambda(10.0)), Vali MSE Loss: 0.1110 Test MSE Loss: 0.6049
Validation loss decreased (0.120271 --> 0.111026).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7225832939147949
Epoch: 5, Steps: 38 Train Loss: 14.5351 (Forecasting Loss:0.1315 + XiCon Loss:1.4404 x Lambda(10.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6093
Validation loss decreased (0.111026 --> 0.107967).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.69305419921875
Epoch: 6, Steps: 38 Train Loss: 14.4208 (Forecasting Loss:0.1291 + XiCon Loss:1.4292 x Lambda(10.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.6069
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7734670639038086
Epoch: 7, Steps: 38 Train Loss: 14.5678 (Forecasting Loss:0.1270 + XiCon Loss:1.4441 x Lambda(10.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.6012
Validation loss decreased (0.107967 --> 0.107835).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7559666633605957
Epoch: 8, Steps: 38 Train Loss: 14.3764 (Forecasting Loss:0.1270 + XiCon Loss:1.4249 x Lambda(10.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.6003
Validation loss decreased (0.107835 --> 0.107381).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7209086418151855
Epoch: 9, Steps: 38 Train Loss: 14.4173 (Forecasting Loss:0.1262 + XiCon Loss:1.4291 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.5992
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6891708374023438
Epoch: 10, Steps: 38 Train Loss: 14.4807 (Forecasting Loss:0.1249 + XiCon Loss:1.4356 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5991
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7416036128997803
Epoch: 11, Steps: 38 Train Loss: 14.4922 (Forecasting Loss:0.1240 + XiCon Loss:1.4368 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.5995
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7749800682067871
Epoch: 12, Steps: 38 Train Loss: 14.4289 (Forecasting Loss:0.1242 + XiCon Loss:1.4305 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.5997
Validation loss decreased (0.107381 --> 0.107296).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7674546241760254
Epoch: 13, Steps: 38 Train Loss: 14.5368 (Forecasting Loss:0.1259 + XiCon Loss:1.4411 x Lambda(10.0)), Vali MSE Loss: 0.1065 Test MSE Loss: 0.5998
Validation loss decreased (0.107296 --> 0.106489).  Saving model ...
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7799460887908936
Epoch: 14, Steps: 38 Train Loss: 14.4960 (Forecasting Loss:0.1247 + XiCon Loss:1.4371 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.5998
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7890970706939697
Epoch: 15, Steps: 38 Train Loss: 14.4123 (Forecasting Loss:0.1262 + XiCon Loss:1.4286 x Lambda(10.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.5998
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6994767189025879
Epoch: 16, Steps: 38 Train Loss: 14.4852 (Forecasting Loss:0.1246 + XiCon Loss:1.4361 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5997
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6972348690032959
Epoch: 17, Steps: 38 Train Loss: 14.5219 (Forecasting Loss:0.1232 + XiCon Loss:1.4399 x Lambda(10.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.5997
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7168776988983154
Epoch: 18, Steps: 38 Train Loss: 14.4176 (Forecasting Loss:0.1258 + XiCon Loss:1.4292 x Lambda(10.0)), Vali MSE Loss: 0.1066 Test MSE Loss: 0.5997
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7995610237121582
Epoch: 19, Steps: 38 Train Loss: 14.6160 (Forecasting Loss:0.1263 + XiCon Loss:1.4490 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5997
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6954188346862793
Epoch: 20, Steps: 38 Train Loss: 14.4484 (Forecasting Loss:0.1239 + XiCon Loss:1.4325 x Lambda(10.0)), Vali MSE Loss: 0.1070 Test MSE Loss: 0.5997
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.752356767654419
Epoch: 21, Steps: 38 Train Loss: 14.4401 (Forecasting Loss:0.1247 + XiCon Loss:1.4315 x Lambda(10.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.5997
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7488889694213867
Epoch: 22, Steps: 38 Train Loss: 14.4613 (Forecasting Loss:0.1249 + XiCon Loss:1.4336 x Lambda(10.0)), Vali MSE Loss: 0.1069 Test MSE Loss: 0.5997
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6707520484924316
Epoch: 23, Steps: 38 Train Loss: 14.4885 (Forecasting Loss:0.1260 + XiCon Loss:1.4363 x Lambda(10.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.5997
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6596368551254272, mae:0.5399439930915833, mape:0.21374046802520752, mspe:0.18888722360134125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:11453
train 462
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3357
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 462
val 181
test 180
Epoch: 1 cost time: 0.6790857315063477
Epoch: 1, Steps: 38 Train Loss: 16.4444 (Forecasting Loss:0.4985 + XiCon Loss:1.5946 x Lambda(10.0)), Vali MSE Loss: 0.2790 Test MSE Loss: 1.4707
Validation loss decreased (inf --> 0.279049).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6357860565185547
Epoch: 2, Steps: 38 Train Loss: 15.5355 (Forecasting Loss:0.2682 + XiCon Loss:1.5267 x Lambda(10.0)), Vali MSE Loss: 0.1494 Test MSE Loss: 0.6272
Validation loss decreased (0.279049 --> 0.149435).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7163126468658447
Epoch: 3, Steps: 38 Train Loss: 14.6292 (Forecasting Loss:0.1672 + XiCon Loss:1.4462 x Lambda(10.0)), Vali MSE Loss: 0.1272 Test MSE Loss: 0.6268
Validation loss decreased (0.149435 --> 0.127182).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6458823680877686
Epoch: 4, Steps: 38 Train Loss: 14.3437 (Forecasting Loss:0.1411 + XiCon Loss:1.4203 x Lambda(10.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.6222
Validation loss decreased (0.127182 --> 0.108232).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.628638744354248
Epoch: 5, Steps: 38 Train Loss: 14.1147 (Forecasting Loss:0.1322 + XiCon Loss:1.3982 x Lambda(10.0)), Vali MSE Loss: 0.1062 Test MSE Loss: 0.6006
Validation loss decreased (0.108232 --> 0.106169).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.736868143081665
Epoch: 6, Steps: 38 Train Loss: 13.9049 (Forecasting Loss:0.1278 + XiCon Loss:1.3777 x Lambda(10.0)), Vali MSE Loss: 0.1048 Test MSE Loss: 0.6073
Validation loss decreased (0.106169 --> 0.104756).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7471990585327148
Epoch: 7, Steps: 38 Train Loss: 14.0558 (Forecasting Loss:0.1260 + XiCon Loss:1.3930 x Lambda(10.0)), Vali MSE Loss: 0.1045 Test MSE Loss: 0.6041
Validation loss decreased (0.104756 --> 0.104549).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7291417121887207
Epoch: 8, Steps: 38 Train Loss: 13.8481 (Forecasting Loss:0.1255 + XiCon Loss:1.3723 x Lambda(10.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.6046
Validation loss decreased (0.104549 --> 0.104339).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.735346794128418
Epoch: 9, Steps: 38 Train Loss: 13.7670 (Forecasting Loss:0.1239 + XiCon Loss:1.3643 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6052
Validation loss decreased (0.104339 --> 0.104092).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7669482231140137
Epoch: 10, Steps: 38 Train Loss: 13.8591 (Forecasting Loss:0.1246 + XiCon Loss:1.3734 x Lambda(10.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.6052
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.744239091873169
Epoch: 11, Steps: 38 Train Loss: 13.8345 (Forecasting Loss:0.1250 + XiCon Loss:1.3709 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6054
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6995751857757568
Epoch: 12, Steps: 38 Train Loss: 13.7827 (Forecasting Loss:0.1249 + XiCon Loss:1.3658 x Lambda(10.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.6053
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7777116298675537
Epoch: 13, Steps: 38 Train Loss: 13.9037 (Forecasting Loss:0.1241 + XiCon Loss:1.3780 x Lambda(10.0)), Vali MSE Loss: 0.1043 Test MSE Loss: 0.6053
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7888712882995605
Epoch: 14, Steps: 38 Train Loss: 13.8965 (Forecasting Loss:0.1233 + XiCon Loss:1.3773 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6052
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7834923267364502
Epoch: 15, Steps: 38 Train Loss: 13.9896 (Forecasting Loss:0.1235 + XiCon Loss:1.3866 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6052
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7620744705200195
Epoch: 16, Steps: 38 Train Loss: 13.9041 (Forecasting Loss:0.1240 + XiCon Loss:1.3780 x Lambda(10.0)), Vali MSE Loss: 0.1034 Test MSE Loss: 0.6052
Validation loss decreased (0.104092 --> 0.103379).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6815600395202637
Epoch: 17, Steps: 38 Train Loss: 13.8821 (Forecasting Loss:0.1246 + XiCon Loss:1.3758 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6052
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.747450590133667
Epoch: 18, Steps: 38 Train Loss: 13.8991 (Forecasting Loss:0.1256 + XiCon Loss:1.3773 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6052
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.8105416297912598
Epoch: 19, Steps: 38 Train Loss: 13.9426 (Forecasting Loss:0.1239 + XiCon Loss:1.3819 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6052
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7143235206604004
Epoch: 20, Steps: 38 Train Loss: 13.8558 (Forecasting Loss:0.1244 + XiCon Loss:1.3731 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6052
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6997463703155518
Epoch: 21, Steps: 38 Train Loss: 13.8707 (Forecasting Loss:0.1239 + XiCon Loss:1.3747 x Lambda(10.0)), Vali MSE Loss: 0.1031 Test MSE Loss: 0.6052
Validation loss decreased (0.103379 --> 0.103084).  Saving model ...
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7203307151794434
Epoch: 22, Steps: 38 Train Loss: 13.7309 (Forecasting Loss:0.1234 + XiCon Loss:1.3607 x Lambda(10.0)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6052
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6992127895355225
Epoch: 23, Steps: 38 Train Loss: 13.8260 (Forecasting Loss:0.1235 + XiCon Loss:1.3703 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6052
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7529327869415283
Epoch: 24, Steps: 38 Train Loss: 13.9110 (Forecasting Loss:0.1246 + XiCon Loss:1.3786 x Lambda(10.0)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6052
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.637523889541626
Epoch: 25, Steps: 38 Train Loss: 13.7855 (Forecasting Loss:0.1250 + XiCon Loss:1.3660 x Lambda(10.0)), Vali MSE Loss: 0.1040 Test MSE Loss: 0.6052
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7923650741577148
Epoch: 26, Steps: 38 Train Loss: 13.8927 (Forecasting Loss:0.1251 + XiCon Loss:1.3768 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6052
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7210924625396729
Epoch: 27, Steps: 38 Train Loss: 13.7761 (Forecasting Loss:0.1241 + XiCon Loss:1.3652 x Lambda(10.0)), Vali MSE Loss: 0.1039 Test MSE Loss: 0.6052
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7305521965026855
Epoch: 28, Steps: 38 Train Loss: 13.8749 (Forecasting Loss:0.1238 + XiCon Loss:1.3751 x Lambda(10.0)), Vali MSE Loss: 0.1042 Test MSE Loss: 0.6052
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.8308954238891602
Epoch: 29, Steps: 38 Train Loss: 13.7987 (Forecasting Loss:0.1246 + XiCon Loss:1.3674 x Lambda(10.0)), Vali MSE Loss: 0.1037 Test MSE Loss: 0.6052
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7343595027923584
Epoch: 30, Steps: 38 Train Loss: 13.8459 (Forecasting Loss:0.1241 + XiCon Loss:1.3722 x Lambda(10.0)), Vali MSE Loss: 0.1041 Test MSE Loss: 0.6052
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-12
Epoch: 31 cost time: 0.696385383605957
Epoch: 31, Steps: 38 Train Loss: 13.9192 (Forecasting Loss:0.1234 + XiCon Loss:1.3796 x Lambda(10.0)), Vali MSE Loss: 0.1032 Test MSE Loss: 0.6052
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl14_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 180
test shape: (15, 12, 14, 1) (15, 12, 14, 1)
test shape: (180, 14, 1) (180, 14, 1)
mse:0.6680814027786255, mae:0.5423585772514343, mape:0.21403615176677704, mspe:0.18933509290218353 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.6536+-0.01501, MAE:0.5417+-0.00267, MAPE:0.2134+-0.00099, MSPE:0.1860+-0.00645, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[28], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=28, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2802
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 1.007565975189209
Epoch: 1, Steps: 37 Train Loss: 16.5932 (Forecasting Loss:0.4943 + XiCon Loss:1.6099 x Lambda(10.0)), Vali MSE Loss: 0.3095 Test MSE Loss: 1.2471
Validation loss decreased (inf --> 0.309475).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6816284656524658
Epoch: 2, Steps: 37 Train Loss: 15.6535 (Forecasting Loss:0.3076 + XiCon Loss:1.5346 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.7379
Validation loss decreased (0.309475 --> 0.202261).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6400961875915527
Epoch: 3, Steps: 37 Train Loss: 14.8317 (Forecasting Loss:0.2017 + XiCon Loss:1.4630 x Lambda(10.0)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.7464
Validation loss decreased (0.202261 --> 0.123476).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7091193199157715
Epoch: 4, Steps: 37 Train Loss: 14.7541 (Forecasting Loss:0.1554 + XiCon Loss:1.4599 x Lambda(10.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6796
Validation loss decreased (0.123476 --> 0.115715).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6385748386383057
Epoch: 5, Steps: 37 Train Loss: 14.7778 (Forecasting Loss:0.1477 + XiCon Loss:1.4630 x Lambda(10.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6714
Validation loss decreased (0.115715 --> 0.115713).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7387216091156006
Epoch: 6, Steps: 37 Train Loss: 14.6584 (Forecasting Loss:0.1454 + XiCon Loss:1.4513 x Lambda(10.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6637
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7923328876495361
Epoch: 7, Steps: 37 Train Loss: 14.6212 (Forecasting Loss:0.1432 + XiCon Loss:1.4478 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6684
Validation loss decreased (0.115713 --> 0.113183).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7473440170288086
Epoch: 8, Steps: 37 Train Loss: 14.6508 (Forecasting Loss:0.1442 + XiCon Loss:1.4507 x Lambda(10.0)), Vali MSE Loss: 0.1131 Test MSE Loss: 0.6712
Validation loss decreased (0.113183 --> 0.113116).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7177541255950928
Epoch: 9, Steps: 37 Train Loss: 14.5946 (Forecasting Loss:0.1429 + XiCon Loss:1.4452 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6714
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7371382713317871
Epoch: 10, Steps: 37 Train Loss: 14.6391 (Forecasting Loss:0.1433 + XiCon Loss:1.4496 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6719
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7199671268463135
Epoch: 11, Steps: 37 Train Loss: 14.6038 (Forecasting Loss:0.1428 + XiCon Loss:1.4461 x Lambda(10.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6720
Validation loss decreased (0.113116 --> 0.112999).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7355105876922607
Epoch: 12, Steps: 37 Train Loss: 14.6191 (Forecasting Loss:0.1434 + XiCon Loss:1.4476 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7007958889007568
Epoch: 13, Steps: 37 Train Loss: 14.5925 (Forecasting Loss:0.1422 + XiCon Loss:1.4450 x Lambda(10.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6651721000671387
Epoch: 14, Steps: 37 Train Loss: 14.6788 (Forecasting Loss:0.1428 + XiCon Loss:1.4536 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6721
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7216827869415283
Epoch: 15, Steps: 37 Train Loss: 14.6423 (Forecasting Loss:0.1434 + XiCon Loss:1.4499 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6721
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7163748741149902
Epoch: 16, Steps: 37 Train Loss: 14.6452 (Forecasting Loss:0.1416 + XiCon Loss:1.4504 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6721
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7499101161956787
Epoch: 17, Steps: 37 Train Loss: 14.6134 (Forecasting Loss:0.1418 + XiCon Loss:1.4472 x Lambda(10.0)), Vali MSE Loss: 0.1138 Test MSE Loss: 0.6721
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7270264625549316
Epoch: 18, Steps: 37 Train Loss: 14.5998 (Forecasting Loss:0.1439 + XiCon Loss:1.4456 x Lambda(10.0)), Vali MSE Loss: 0.1116 Test MSE Loss: 0.6721
Validation loss decreased (0.112999 --> 0.111647).  Saving model ...
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7352936267852783
Epoch: 19, Steps: 37 Train Loss: 14.6187 (Forecasting Loss:0.1435 + XiCon Loss:1.4475 x Lambda(10.0)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.6721
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.756558895111084
Epoch: 20, Steps: 37 Train Loss: 14.5818 (Forecasting Loss:0.1435 + XiCon Loss:1.4438 x Lambda(10.0)), Vali MSE Loss: 0.1155 Test MSE Loss: 0.6721
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7291789054870605
Epoch: 21, Steps: 37 Train Loss: 14.7508 (Forecasting Loss:0.1429 + XiCon Loss:1.4608 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6721
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7078254222869873
Epoch: 22, Steps: 37 Train Loss: 14.6378 (Forecasting Loss:0.1432 + XiCon Loss:1.4495 x Lambda(10.0)), Vali MSE Loss: 0.1147 Test MSE Loss: 0.6721
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7273797988891602
Epoch: 23, Steps: 37 Train Loss: 14.6686 (Forecasting Loss:0.1436 + XiCon Loss:1.4525 x Lambda(10.0)), Vali MSE Loss: 0.1123 Test MSE Loss: 0.6721
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7024617195129395
Epoch: 24, Steps: 37 Train Loss: 14.6409 (Forecasting Loss:0.1433 + XiCon Loss:1.4498 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6721
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.7324187755584717
Epoch: 25, Steps: 37 Train Loss: 14.6106 (Forecasting Loss:0.1422 + XiCon Loss:1.4468 x Lambda(10.0)), Vali MSE Loss: 0.1129 Test MSE Loss: 0.6721
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.7207992076873779
Epoch: 26, Steps: 37 Train Loss: 14.6114 (Forecasting Loss:0.1430 + XiCon Loss:1.4468 x Lambda(10.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6721
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.7298600673675537
Epoch: 27, Steps: 37 Train Loss: 14.6602 (Forecasting Loss:0.1428 + XiCon Loss:1.4517 x Lambda(10.0)), Vali MSE Loss: 0.1126 Test MSE Loss: 0.6721
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.7196636199951172
Epoch: 28, Steps: 37 Train Loss: 14.6482 (Forecasting Loss:0.1432 + XiCon Loss:1.4505 x Lambda(10.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6721
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7264741063117981, mae:0.6176983118057251, mape:0.24356073141098022, mspe:0.20398065447807312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3494
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.7044162750244141
Epoch: 1, Steps: 37 Train Loss: 16.4562 (Forecasting Loss:0.4602 + XiCon Loss:1.5996 x Lambda(10.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 1.2219
Validation loss decreased (inf --> 0.296758).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.728830099105835
Epoch: 2, Steps: 37 Train Loss: 15.6108 (Forecasting Loss:0.2974 + XiCon Loss:1.5313 x Lambda(10.0)), Vali MSE Loss: 0.1626 Test MSE Loss: 0.7222
Validation loss decreased (0.296758 --> 0.162598).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.647423505783081
Epoch: 3, Steps: 37 Train Loss: 14.9343 (Forecasting Loss:0.1783 + XiCon Loss:1.4756 x Lambda(10.0)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.7081
Validation loss decreased (0.162598 --> 0.123562).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6174836158752441
Epoch: 4, Steps: 37 Train Loss: 14.8003 (Forecasting Loss:0.1521 + XiCon Loss:1.4648 x Lambda(10.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6557
Validation loss decreased (0.123562 --> 0.117921).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7457845211029053
Epoch: 5, Steps: 37 Train Loss: 14.6247 (Forecasting Loss:0.1476 + XiCon Loss:1.4477 x Lambda(10.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.6654
Validation loss decreased (0.117921 --> 0.114879).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6917252540588379
Epoch: 6, Steps: 37 Train Loss: 14.6550 (Forecasting Loss:0.1439 + XiCon Loss:1.4511 x Lambda(10.0)), Vali MSE Loss: 0.1145 Test MSE Loss: 0.6694
Validation loss decreased (0.114879 --> 0.114487).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7174623012542725
Epoch: 7, Steps: 37 Train Loss: 14.7087 (Forecasting Loss:0.1440 + XiCon Loss:1.4565 x Lambda(10.0)), Vali MSE Loss: 0.1122 Test MSE Loss: 0.6683
Validation loss decreased (0.114487 --> 0.112243).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.74259352684021
Epoch: 8, Steps: 37 Train Loss: 14.6607 (Forecasting Loss:0.1429 + XiCon Loss:1.4518 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6686
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6912312507629395
Epoch: 9, Steps: 37 Train Loss: 14.6356 (Forecasting Loss:0.1421 + XiCon Loss:1.4494 x Lambda(10.0)), Vali MSE Loss: 0.1115 Test MSE Loss: 0.6685
Validation loss decreased (0.112243 --> 0.111548).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7887430191040039
Epoch: 10, Steps: 37 Train Loss: 14.6612 (Forecasting Loss:0.1426 + XiCon Loss:1.4519 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6688
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6314878463745117
Epoch: 11, Steps: 37 Train Loss: 14.5663 (Forecasting Loss:0.1430 + XiCon Loss:1.4423 x Lambda(10.0)), Vali MSE Loss: 0.1131 Test MSE Loss: 0.6691
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7311503887176514
Epoch: 12, Steps: 37 Train Loss: 14.6087 (Forecasting Loss:0.1423 + XiCon Loss:1.4466 x Lambda(10.0)), Vali MSE Loss: 0.1107 Test MSE Loss: 0.6690
Validation loss decreased (0.111548 --> 0.110656).  Saving model ...
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6969819068908691
Epoch: 13, Steps: 37 Train Loss: 14.5632 (Forecasting Loss:0.1422 + XiCon Loss:1.4421 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7218050956726074
Epoch: 14, Steps: 37 Train Loss: 14.6034 (Forecasting Loss:0.1423 + XiCon Loss:1.4461 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6690
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7496566772460938
Epoch: 15, Steps: 37 Train Loss: 14.6467 (Forecasting Loss:0.1425 + XiCon Loss:1.4504 x Lambda(10.0)), Vali MSE Loss: 0.1120 Test MSE Loss: 0.6690
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.738955020904541
Epoch: 16, Steps: 37 Train Loss: 14.7425 (Forecasting Loss:0.1404 + XiCon Loss:1.4602 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6690
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7369749546051025
Epoch: 17, Steps: 37 Train Loss: 14.6298 (Forecasting Loss:0.1432 + XiCon Loss:1.4487 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6690
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7041633129119873
Epoch: 18, Steps: 37 Train Loss: 14.7179 (Forecasting Loss:0.1431 + XiCon Loss:1.4575 x Lambda(10.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6690
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.653496503829956
Epoch: 19, Steps: 37 Train Loss: 14.7319 (Forecasting Loss:0.1431 + XiCon Loss:1.4589 x Lambda(10.0)), Vali MSE Loss: 0.1129 Test MSE Loss: 0.6690
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.732337474822998
Epoch: 20, Steps: 37 Train Loss: 14.6617 (Forecasting Loss:0.1429 + XiCon Loss:1.4519 x Lambda(10.0)), Vali MSE Loss: 0.1134 Test MSE Loss: 0.6690
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7176427841186523
Epoch: 21, Steps: 37 Train Loss: 14.6905 (Forecasting Loss:0.1429 + XiCon Loss:1.4548 x Lambda(10.0)), Vali MSE Loss: 0.1125 Test MSE Loss: 0.6690
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6853961944580078
Epoch: 22, Steps: 37 Train Loss: 14.6217 (Forecasting Loss:0.1428 + XiCon Loss:1.4479 x Lambda(10.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.6690
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7180211544036865, mae:0.6199750304222107, mape:0.24472454190254211, mspe:0.20540833473205566 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3436
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.674163818359375
Epoch: 1, Steps: 37 Train Loss: 16.5649 (Forecasting Loss:0.5340 + XiCon Loss:1.6031 x Lambda(10.0)), Vali MSE Loss: 0.3161 Test MSE Loss: 1.3993
Validation loss decreased (inf --> 0.316147).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6781916618347168
Epoch: 2, Steps: 37 Train Loss: 15.8406 (Forecasting Loss:0.3283 + XiCon Loss:1.5512 x Lambda(10.0)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.6876
Validation loss decreased (0.316147 --> 0.186871).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7096109390258789
Epoch: 3, Steps: 37 Train Loss: 14.6237 (Forecasting Loss:0.1899 + XiCon Loss:1.4434 x Lambda(10.0)), Vali MSE Loss: 0.1316 Test MSE Loss: 0.7205
Validation loss decreased (0.186871 --> 0.131597).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6769497394561768
Epoch: 4, Steps: 37 Train Loss: 14.2712 (Forecasting Loss:0.1587 + XiCon Loss:1.4112 x Lambda(10.0)), Vali MSE Loss: 0.1241 Test MSE Loss: 0.6379
Validation loss decreased (0.131597 --> 0.124141).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6367123126983643
Epoch: 5, Steps: 37 Train Loss: 14.0674 (Forecasting Loss:0.1503 + XiCon Loss:1.3917 x Lambda(10.0)), Vali MSE Loss: 0.1201 Test MSE Loss: 0.6548
Validation loss decreased (0.124141 --> 0.120114).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6461846828460693
Epoch: 6, Steps: 37 Train Loss: 13.9784 (Forecasting Loss:0.1479 + XiCon Loss:1.3831 x Lambda(10.0)), Vali MSE Loss: 0.1173 Test MSE Loss: 0.6747
Validation loss decreased (0.120114 --> 0.117327).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.694587230682373
Epoch: 7, Steps: 37 Train Loss: 13.8340 (Forecasting Loss:0.1454 + XiCon Loss:1.3689 x Lambda(10.0)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6708
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6893126964569092
Epoch: 8, Steps: 37 Train Loss: 13.8902 (Forecasting Loss:0.1451 + XiCon Loss:1.3745 x Lambda(10.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.6688
Validation loss decreased (0.117327 --> 0.115277).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6536495685577393
Epoch: 9, Steps: 37 Train Loss: 13.8562 (Forecasting Loss:0.1462 + XiCon Loss:1.3710 x Lambda(10.0)), Vali MSE Loss: 0.1174 Test MSE Loss: 0.6680
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6183860301971436
Epoch: 10, Steps: 37 Train Loss: 13.9196 (Forecasting Loss:0.1425 + XiCon Loss:1.3777 x Lambda(10.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6674
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5930936336517334
Epoch: 11, Steps: 37 Train Loss: 13.9216 (Forecasting Loss:0.1456 + XiCon Loss:1.3776 x Lambda(10.0)), Vali MSE Loss: 0.1175 Test MSE Loss: 0.6673
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.656627893447876
Epoch: 12, Steps: 37 Train Loss: 13.9518 (Forecasting Loss:0.1435 + XiCon Loss:1.3808 x Lambda(10.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6671
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6569983959197998
Epoch: 13, Steps: 37 Train Loss: 13.9479 (Forecasting Loss:0.1446 + XiCon Loss:1.3803 x Lambda(10.0)), Vali MSE Loss: 0.1167 Test MSE Loss: 0.6670
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6846299171447754
Epoch: 14, Steps: 37 Train Loss: 13.8875 (Forecasting Loss:0.1433 + XiCon Loss:1.3744 x Lambda(10.0)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.6669
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.5947399139404297
Epoch: 15, Steps: 37 Train Loss: 13.8665 (Forecasting Loss:0.1446 + XiCon Loss:1.3722 x Lambda(10.0)), Vali MSE Loss: 0.1151 Test MSE Loss: 0.6669
Validation loss decreased (0.115277 --> 0.115087).  Saving model ...
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6649198532104492
Epoch: 16, Steps: 37 Train Loss: 13.9210 (Forecasting Loss:0.1438 + XiCon Loss:1.3777 x Lambda(10.0)), Vali MSE Loss: 0.1181 Test MSE Loss: 0.6669
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7373685836791992
Epoch: 17, Steps: 37 Train Loss: 13.9512 (Forecasting Loss:0.1440 + XiCon Loss:1.3807 x Lambda(10.0)), Vali MSE Loss: 0.1169 Test MSE Loss: 0.6669
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.733224630355835
Epoch: 18, Steps: 37 Train Loss: 13.8712 (Forecasting Loss:0.1449 + XiCon Loss:1.3726 x Lambda(10.0)), Vali MSE Loss: 0.1182 Test MSE Loss: 0.6669
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.7107501029968262
Epoch: 19, Steps: 37 Train Loss: 13.9448 (Forecasting Loss:0.1445 + XiCon Loss:1.3800 x Lambda(10.0)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.6669
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7448632717132568
Epoch: 20, Steps: 37 Train Loss: 13.9509 (Forecasting Loss:0.1443 + XiCon Loss:1.3807 x Lambda(10.0)), Vali MSE Loss: 0.1157 Test MSE Loss: 0.6669
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7287461757659912
Epoch: 21, Steps: 37 Train Loss: 13.9326 (Forecasting Loss:0.1439 + XiCon Loss:1.3789 x Lambda(10.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6669
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7538731098175049
Epoch: 22, Steps: 37 Train Loss: 13.9715 (Forecasting Loss:0.1437 + XiCon Loss:1.3828 x Lambda(10.0)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.6669
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.7104253768920898
Epoch: 23, Steps: 37 Train Loss: 13.9828 (Forecasting Loss:0.1443 + XiCon Loss:1.3839 x Lambda(10.0)), Vali MSE Loss: 0.1179 Test MSE Loss: 0.6669
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.7011158466339111
Epoch: 24, Steps: 37 Train Loss: 13.9186 (Forecasting Loss:0.1434 + XiCon Loss:1.3775 x Lambda(10.0)), Vali MSE Loss: 0.1156 Test MSE Loss: 0.6669
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6998510360717773
Epoch: 25, Steps: 37 Train Loss: 13.8934 (Forecasting Loss:0.1441 + XiCon Loss:1.3749 x Lambda(10.0)), Vali MSE Loss: 0.1168 Test MSE Loss: 0.6669
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7219395041465759, mae:0.6119228601455688, mape:0.24260926246643066, mspe:0.20815256237983704 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3151
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.6694092750549316
Epoch: 1, Steps: 37 Train Loss: 16.4952 (Forecasting Loss:0.5384 + XiCon Loss:1.5957 x Lambda(10.0)), Vali MSE Loss: 0.3176 Test MSE Loss: 1.4634
Validation loss decreased (inf --> 0.317635).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7396886348724365
Epoch: 2, Steps: 37 Train Loss: 15.5198 (Forecasting Loss:0.3210 + XiCon Loss:1.5199 x Lambda(10.0)), Vali MSE Loss: 0.1766 Test MSE Loss: 0.7465
Validation loss decreased (0.317635 --> 0.176640).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7481222152709961
Epoch: 3, Steps: 37 Train Loss: 14.8320 (Forecasting Loss:0.1903 + XiCon Loss:1.4642 x Lambda(10.0)), Vali MSE Loss: 0.1320 Test MSE Loss: 0.6736
Validation loss decreased (0.176640 --> 0.131997).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6770572662353516
Epoch: 4, Steps: 37 Train Loss: 14.5012 (Forecasting Loss:0.1574 + XiCon Loss:1.4344 x Lambda(10.0)), Vali MSE Loss: 0.1185 Test MSE Loss: 0.6687
Validation loss decreased (0.131997 --> 0.118465).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7172636985778809
Epoch: 5, Steps: 37 Train Loss: 14.4299 (Forecasting Loss:0.1491 + XiCon Loss:1.4281 x Lambda(10.0)), Vali MSE Loss: 0.1161 Test MSE Loss: 0.6590
Validation loss decreased (0.118465 --> 0.116141).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.7496447563171387
Epoch: 6, Steps: 37 Train Loss: 14.2828 (Forecasting Loss:0.1440 + XiCon Loss:1.4139 x Lambda(10.0)), Vali MSE Loss: 0.1170 Test MSE Loss: 0.6449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7363195419311523
Epoch: 7, Steps: 37 Train Loss: 14.3631 (Forecasting Loss:0.1437 + XiCon Loss:1.4219 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6572
Validation loss decreased (0.116141 --> 0.114005).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7015936374664307
Epoch: 8, Steps: 37 Train Loss: 14.2673 (Forecasting Loss:0.1435 + XiCon Loss:1.4124 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6647
Validation loss decreased (0.114005 --> 0.113212).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7169189453125
Epoch: 9, Steps: 37 Train Loss: 14.3730 (Forecasting Loss:0.1424 + XiCon Loss:1.4231 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6631
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7486867904663086
Epoch: 10, Steps: 37 Train Loss: 14.1602 (Forecasting Loss:0.1422 + XiCon Loss:1.4018 x Lambda(10.0)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.6620
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.7831776142120361
Epoch: 11, Steps: 37 Train Loss: 14.2015 (Forecasting Loss:0.1414 + XiCon Loss:1.4060 x Lambda(10.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.6622
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.8188245296478271
Epoch: 12, Steps: 37 Train Loss: 14.2302 (Forecasting Loss:0.1424 + XiCon Loss:1.4088 x Lambda(10.0)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.6619
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7170374393463135
Epoch: 13, Steps: 37 Train Loss: 14.2435 (Forecasting Loss:0.1409 + XiCon Loss:1.4103 x Lambda(10.0)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.6618
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7511775493621826
Epoch: 14, Steps: 37 Train Loss: 14.2876 (Forecasting Loss:0.1417 + XiCon Loss:1.4146 x Lambda(10.0)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.6618
Validation loss decreased (0.113212 --> 0.111693).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.7438783645629883
Epoch: 15, Steps: 37 Train Loss: 14.2747 (Forecasting Loss:0.1420 + XiCon Loss:1.4133 x Lambda(10.0)), Vali MSE Loss: 0.1121 Test MSE Loss: 0.6619
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7835571765899658
Epoch: 16, Steps: 37 Train Loss: 14.1564 (Forecasting Loss:0.1415 + XiCon Loss:1.4015 x Lambda(10.0)), Vali MSE Loss: 0.1120 Test MSE Loss: 0.6619
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7062597274780273
Epoch: 17, Steps: 37 Train Loss: 14.2610 (Forecasting Loss:0.1421 + XiCon Loss:1.4119 x Lambda(10.0)), Vali MSE Loss: 0.1128 Test MSE Loss: 0.6619
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7310020923614502
Epoch: 18, Steps: 37 Train Loss: 14.1966 (Forecasting Loss:0.1419 + XiCon Loss:1.4055 x Lambda(10.0)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.6619
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6993870735168457
Epoch: 19, Steps: 37 Train Loss: 14.1886 (Forecasting Loss:0.1429 + XiCon Loss:1.4046 x Lambda(10.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.6619
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.7196929454803467
Epoch: 20, Steps: 37 Train Loss: 14.2002 (Forecasting Loss:0.1414 + XiCon Loss:1.4059 x Lambda(10.0)), Vali MSE Loss: 0.1134 Test MSE Loss: 0.6619
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.6780049800872803
Epoch: 21, Steps: 37 Train Loss: 14.1871 (Forecasting Loss:0.1425 + XiCon Loss:1.4045 x Lambda(10.0)), Vali MSE Loss: 0.1130 Test MSE Loss: 0.6619
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.7360310554504395
Epoch: 22, Steps: 37 Train Loss: 14.3326 (Forecasting Loss:0.1426 + XiCon Loss:1.4190 x Lambda(10.0)), Vali MSE Loss: 0.1132 Test MSE Loss: 0.6619
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6614749431610107
Epoch: 23, Steps: 37 Train Loss: 14.2393 (Forecasting Loss:0.1420 + XiCon Loss:1.4097 x Lambda(10.0)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.6619
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.658320426940918
Epoch: 24, Steps: 37 Train Loss: 14.1825 (Forecasting Loss:0.1416 + XiCon Loss:1.4041 x Lambda(10.0)), Vali MSE Loss: 0.1122 Test MSE Loss: 0.6619
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.7170374393463135, mae:0.6066597104072571, mape:0.2411571890115738, mspe:0.20860327780246735 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:14393
train 448
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3459
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 448
val 167
test 166
Epoch: 1 cost time: 0.681171178817749
Epoch: 1, Steps: 37 Train Loss: 16.5740 (Forecasting Loss:0.5092 + XiCon Loss:1.6065 x Lambda(10.0)), Vali MSE Loss: 0.3132 Test MSE Loss: 1.3193
Validation loss decreased (inf --> 0.313219).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6921229362487793
Epoch: 2, Steps: 37 Train Loss: 15.7031 (Forecasting Loss:0.2915 + XiCon Loss:1.5412 x Lambda(10.0)), Vali MSE Loss: 0.1832 Test MSE Loss: 0.8475
Validation loss decreased (0.313219 --> 0.183240).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.649101972579956
Epoch: 3, Steps: 37 Train Loss: 14.9179 (Forecasting Loss:0.2022 + XiCon Loss:1.4716 x Lambda(10.0)), Vali MSE Loss: 0.1468 Test MSE Loss: 0.6940
Validation loss decreased (0.183240 --> 0.146780).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6687219142913818
Epoch: 4, Steps: 37 Train Loss: 14.4787 (Forecasting Loss:0.1635 + XiCon Loss:1.4315 x Lambda(10.0)), Vali MSE Loss: 0.1294 Test MSE Loss: 0.6459
Validation loss decreased (0.146780 --> 0.129407).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.7164311408996582
Epoch: 5, Steps: 37 Train Loss: 14.2024 (Forecasting Loss:0.1572 + XiCon Loss:1.4045 x Lambda(10.0)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.6669
Validation loss decreased (0.129407 --> 0.123361).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6562070846557617
Epoch: 6, Steps: 37 Train Loss: 14.1596 (Forecasting Loss:0.1516 + XiCon Loss:1.4008 x Lambda(10.0)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.6376
Validation loss decreased (0.123361 --> 0.123179).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.691819429397583
Epoch: 7, Steps: 37 Train Loss: 14.0186 (Forecasting Loss:0.1510 + XiCon Loss:1.3868 x Lambda(10.0)), Vali MSE Loss: 0.1211 Test MSE Loss: 0.6578
Validation loss decreased (0.123179 --> 0.121051).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7409322261810303
Epoch: 8, Steps: 37 Train Loss: 14.1413 (Forecasting Loss:0.1494 + XiCon Loss:1.3992 x Lambda(10.0)), Vali MSE Loss: 0.1209 Test MSE Loss: 0.6551
Validation loss decreased (0.121051 --> 0.120909).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.7214250564575195
Epoch: 9, Steps: 37 Train Loss: 14.1310 (Forecasting Loss:0.1503 + XiCon Loss:1.3981 x Lambda(10.0)), Vali MSE Loss: 0.1201 Test MSE Loss: 0.6536
Validation loss decreased (0.120909 --> 0.120134).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6905951499938965
Epoch: 10, Steps: 37 Train Loss: 14.0517 (Forecasting Loss:0.1486 + XiCon Loss:1.3903 x Lambda(10.0)), Vali MSE Loss: 0.1192 Test MSE Loss: 0.6500
Validation loss decreased (0.120134 --> 0.119159).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.743095874786377
Epoch: 11, Steps: 37 Train Loss: 14.1271 (Forecasting Loss:0.1517 + XiCon Loss:1.3975 x Lambda(10.0)), Vali MSE Loss: 0.1184 Test MSE Loss: 0.6492
Validation loss decreased (0.119159 --> 0.118378).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.7082314491271973
Epoch: 12, Steps: 37 Train Loss: 14.0898 (Forecasting Loss:0.1501 + XiCon Loss:1.3940 x Lambda(10.0)), Vali MSE Loss: 0.1193 Test MSE Loss: 0.6487
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.730445146560669
Epoch: 13, Steps: 37 Train Loss: 14.0950 (Forecasting Loss:0.1487 + XiCon Loss:1.3946 x Lambda(10.0)), Vali MSE Loss: 0.1206 Test MSE Loss: 0.6482
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.7130746841430664
Epoch: 14, Steps: 37 Train Loss: 14.0837 (Forecasting Loss:0.1512 + XiCon Loss:1.3933 x Lambda(10.0)), Vali MSE Loss: 0.1203 Test MSE Loss: 0.6480
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6527514457702637
Epoch: 15, Steps: 37 Train Loss: 13.9934 (Forecasting Loss:0.1517 + XiCon Loss:1.3842 x Lambda(10.0)), Vali MSE Loss: 0.1195 Test MSE Loss: 0.6481
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7491950988769531
Epoch: 16, Steps: 37 Train Loss: 14.0013 (Forecasting Loss:0.1492 + XiCon Loss:1.3852 x Lambda(10.0)), Vali MSE Loss: 0.1208 Test MSE Loss: 0.6481
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7504317760467529
Epoch: 17, Steps: 37 Train Loss: 13.9648 (Forecasting Loss:0.1516 + XiCon Loss:1.3813 x Lambda(10.0)), Vali MSE Loss: 0.1191 Test MSE Loss: 0.6480
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6451950073242188
Epoch: 18, Steps: 37 Train Loss: 14.1032 (Forecasting Loss:0.1475 + XiCon Loss:1.3956 x Lambda(10.0)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.6480
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.688387393951416
Epoch: 19, Steps: 37 Train Loss: 14.1382 (Forecasting Loss:0.1488 + XiCon Loss:1.3989 x Lambda(10.0)), Vali MSE Loss: 0.1196 Test MSE Loss: 0.6480
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6664924621582031
Epoch: 20, Steps: 37 Train Loss: 14.1649 (Forecasting Loss:0.1500 + XiCon Loss:1.4015 x Lambda(10.0)), Vali MSE Loss: 0.1216 Test MSE Loss: 0.6480
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7696952819824219
Epoch: 21, Steps: 37 Train Loss: 13.9393 (Forecasting Loss:0.1473 + XiCon Loss:1.3792 x Lambda(10.0)), Vali MSE Loss: 0.1203 Test MSE Loss: 0.6480
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl28_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 166
test shape: (13, 12, 28, 1) (13, 12, 28, 1)
test shape: (156, 28, 1) (156, 28, 1)
mse:0.6867856979370117, mae:0.6116408705711365, mape:0.24295435845851898, mspe:0.199598491191864 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7141+-0.01948, MAE:0.6136+-0.00658, MAPE:0.2430+-0.00162, MSPE:0.2051+-0.00453, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[56], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=56, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2990
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.9375207424163818
Epoch: 1, Steps: 35 Train Loss: 16.4023 (Forecasting Loss:0.5299 + XiCon Loss:1.5872 x Lambda(10.0)), Vali MSE Loss: 0.2966 Test MSE Loss: 1.4806
Validation loss decreased (inf --> 0.296644).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.7056708335876465
Epoch: 2, Steps: 35 Train Loss: 14.5916 (Forecasting Loss:0.3354 + XiCon Loss:1.4256 x Lambda(10.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.6916
Validation loss decreased (0.296644 --> 0.208714).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6327884197235107
Epoch: 3, Steps: 35 Train Loss: 15.7685 (Forecasting Loss:0.2233 + XiCon Loss:1.5545 x Lambda(10.0)), Vali MSE Loss: 0.1379 Test MSE Loss: 0.7634
Validation loss decreased (0.208714 --> 0.137921).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7366659641265869
Epoch: 4, Steps: 35 Train Loss: 19.1912 (Forecasting Loss:0.1953 + XiCon Loss:1.8996 x Lambda(10.0)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.7097
Validation loss decreased (0.137921 --> 0.126319).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6270720958709717
Epoch: 5, Steps: 35 Train Loss: 21.8553 (Forecasting Loss:0.1828 + XiCon Loss:2.1672 x Lambda(10.0)), Vali MSE Loss: 0.1282 Test MSE Loss: 0.6888
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5786032676696777
Epoch: 6, Steps: 35 Train Loss: 20.1470 (Forecasting Loss:0.1788 + XiCon Loss:1.9968 x Lambda(10.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6893
Validation loss decreased (0.126319 --> 0.126008).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6888926029205322
Epoch: 7, Steps: 35 Train Loss: 21.2083 (Forecasting Loss:0.1782 + XiCon Loss:2.1030 x Lambda(10.0)), Vali MSE Loss: 0.1264 Test MSE Loss: 0.6876
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6565051078796387
Epoch: 8, Steps: 35 Train Loss: 20.4221 (Forecasting Loss:0.1752 + XiCon Loss:2.0247 x Lambda(10.0)), Vali MSE Loss: 0.1261 Test MSE Loss: 0.6908
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.674323558807373
Epoch: 9, Steps: 35 Train Loss: 20.8137 (Forecasting Loss:0.1740 + XiCon Loss:2.0640 x Lambda(10.0)), Vali MSE Loss: 0.1262 Test MSE Loss: 0.6902
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6570460796356201
Epoch: 10, Steps: 35 Train Loss: 21.1481 (Forecasting Loss:0.1739 + XiCon Loss:2.0974 x Lambda(10.0)), Vali MSE Loss: 0.1258 Test MSE Loss: 0.6897
Validation loss decreased (0.126008 --> 0.125805).  Saving model ...
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6378002166748047
Epoch: 11, Steps: 35 Train Loss: 22.4605 (Forecasting Loss:0.1732 + XiCon Loss:2.2287 x Lambda(10.0)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.6897
Validation loss decreased (0.125805 --> 0.125749).  Saving model ...
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.669689416885376
Epoch: 12, Steps: 35 Train Loss: 22.8556 (Forecasting Loss:0.1739 + XiCon Loss:2.2682 x Lambda(10.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6897
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6727385520935059
Epoch: 13, Steps: 35 Train Loss: 22.1888 (Forecasting Loss:0.1748 + XiCon Loss:2.2014 x Lambda(10.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6895
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6451592445373535
Epoch: 14, Steps: 35 Train Loss: 22.0610 (Forecasting Loss:0.1738 + XiCon Loss:2.1887 x Lambda(10.0)), Vali MSE Loss: 0.1251 Test MSE Loss: 0.6895
Validation loss decreased (0.125749 --> 0.125094).  Saving model ...
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6591198444366455
Epoch: 15, Steps: 35 Train Loss: 22.6539 (Forecasting Loss:0.1751 + XiCon Loss:2.2479 x Lambda(10.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6894
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7139599323272705
Epoch: 16, Steps: 35 Train Loss: 21.6503 (Forecasting Loss:0.1731 + XiCon Loss:2.1477 x Lambda(10.0)), Vali MSE Loss: 0.1261 Test MSE Loss: 0.6894
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7325103282928467
Epoch: 17, Steps: 35 Train Loss: 23.6029 (Forecasting Loss:0.1733 + XiCon Loss:2.3430 x Lambda(10.0)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.6894
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6626291275024414
Epoch: 18, Steps: 35 Train Loss: 22.5195 (Forecasting Loss:0.1737 + XiCon Loss:2.2346 x Lambda(10.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6894
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6316161155700684
Epoch: 19, Steps: 35 Train Loss: 22.7721 (Forecasting Loss:0.1739 + XiCon Loss:2.2598 x Lambda(10.0)), Vali MSE Loss: 0.1248 Test MSE Loss: 0.6894
Validation loss decreased (0.125094 --> 0.124785).  Saving model ...
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6308486461639404
Epoch: 20, Steps: 35 Train Loss: 21.7191 (Forecasting Loss:0.1738 + XiCon Loss:2.1545 x Lambda(10.0)), Vali MSE Loss: 0.1248 Test MSE Loss: 0.6894
Validation loss decreased (0.124785 --> 0.124752).  Saving model ...
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7163641452789307
Epoch: 21, Steps: 35 Train Loss: 23.3037 (Forecasting Loss:0.1738 + XiCon Loss:2.3130 x Lambda(10.0)), Vali MSE Loss: 0.1261 Test MSE Loss: 0.6894
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6375036239624023
Epoch: 22, Steps: 35 Train Loss: 21.4669 (Forecasting Loss:0.1741 + XiCon Loss:2.1293 x Lambda(10.0)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.6894
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6514484882354736
Epoch: 23, Steps: 35 Train Loss: 21.9524 (Forecasting Loss:0.1743 + XiCon Loss:2.1778 x Lambda(10.0)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.6894
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6981215476989746
Epoch: 24, Steps: 35 Train Loss: 22.4925 (Forecasting Loss:0.1737 + XiCon Loss:2.2319 x Lambda(10.0)), Vali MSE Loss: 0.1263 Test MSE Loss: 0.6894
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.5983531475067139
Epoch: 25, Steps: 35 Train Loss: 22.1601 (Forecasting Loss:0.1737 + XiCon Loss:2.1986 x Lambda(10.0)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.6894
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.6502771377563477
Epoch: 26, Steps: 35 Train Loss: 21.9771 (Forecasting Loss:0.1741 + XiCon Loss:2.1803 x Lambda(10.0)), Vali MSE Loss: 0.1249 Test MSE Loss: 0.6894
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
Epoch: 27 cost time: 0.6608297824859619
Epoch: 27, Steps: 35 Train Loss: 22.2009 (Forecasting Loss:0.1735 + XiCon Loss:2.2027 x Lambda(10.0)), Vali MSE Loss: 0.1249 Test MSE Loss: 0.6894
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
Epoch: 28 cost time: 0.560302734375
Epoch: 28, Steps: 35 Train Loss: 20.9810 (Forecasting Loss:0.1742 + XiCon Loss:2.0807 x Lambda(10.0)), Vali MSE Loss: 0.1266 Test MSE Loss: 0.6894
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
Epoch: 29 cost time: 0.728905439376831
Epoch: 29, Steps: 35 Train Loss: 23.0246 (Forecasting Loss:0.1735 + XiCon Loss:2.2851 x Lambda(10.0)), Vali MSE Loss: 0.1266 Test MSE Loss: 0.6894
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
Epoch: 30 cost time: 0.7049717903137207
Epoch: 30, Steps: 35 Train Loss: 21.6842 (Forecasting Loss:0.1738 + XiCon Loss:2.1510 x Lambda(10.0)), Vali MSE Loss: 0.1254 Test MSE Loss: 0.6894
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7125943303108215, mae:0.6661736369132996, mape:0.26006099581718445, mspe:0.1906549334526062 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3212
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6498653888702393
Epoch: 1, Steps: 35 Train Loss: 16.3591 (Forecasting Loss:0.4968 + XiCon Loss:1.5862 x Lambda(10.0)), Vali MSE Loss: 0.3660 Test MSE Loss: 1.0654
Validation loss decreased (inf --> 0.366024).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6401214599609375
Epoch: 2, Steps: 35 Train Loss: 14.4767 (Forecasting Loss:0.3645 + XiCon Loss:1.4112 x Lambda(10.0)), Vali MSE Loss: 0.1826 Test MSE Loss: 0.7653
Validation loss decreased (0.366024 --> 0.182559).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.560511589050293
Epoch: 3, Steps: 35 Train Loss: 16.3326 (Forecasting Loss:0.2380 + XiCon Loss:1.6095 x Lambda(10.0)), Vali MSE Loss: 0.1622 Test MSE Loss: 0.7125
Validation loss decreased (0.182559 --> 0.162167).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6058754920959473
Epoch: 4, Steps: 35 Train Loss: 20.5890 (Forecasting Loss:0.1990 + XiCon Loss:2.0390 x Lambda(10.0)), Vali MSE Loss: 0.1402 Test MSE Loss: 0.7010
Validation loss decreased (0.162167 --> 0.140207).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6101644039154053
Epoch: 5, Steps: 35 Train Loss: 22.5162 (Forecasting Loss:0.1861 + XiCon Loss:2.2330 x Lambda(10.0)), Vali MSE Loss: 0.1311 Test MSE Loss: 0.7080
Validation loss decreased (0.140207 --> 0.131094).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6535584926605225
Epoch: 6, Steps: 35 Train Loss: 22.3385 (Forecasting Loss:0.1779 + XiCon Loss:2.2161 x Lambda(10.0)), Vali MSE Loss: 0.1304 Test MSE Loss: 0.7062
Validation loss decreased (0.131094 --> 0.130381).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5744359493255615
Epoch: 7, Steps: 35 Train Loss: 22.0575 (Forecasting Loss:0.1763 + XiCon Loss:2.1881 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.6983
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.586606502532959
Epoch: 8, Steps: 35 Train Loss: 23.9125 (Forecasting Loss:0.1786 + XiCon Loss:2.3734 x Lambda(10.0)), Vali MSE Loss: 0.1356 Test MSE Loss: 0.7031
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6032586097717285
Epoch: 9, Steps: 35 Train Loss: 22.9548 (Forecasting Loss:0.1762 + XiCon Loss:2.2779 x Lambda(10.0)), Vali MSE Loss: 0.1404 Test MSE Loss: 0.7008
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.7051012516021729
Epoch: 10, Steps: 35 Train Loss: 22.3578 (Forecasting Loss:0.1720 + XiCon Loss:2.2186 x Lambda(10.0)), Vali MSE Loss: 0.1402 Test MSE Loss: 0.7001
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6862549781799316
Epoch: 11, Steps: 35 Train Loss: 21.8463 (Forecasting Loss:0.1732 + XiCon Loss:2.1673 x Lambda(10.0)), Vali MSE Loss: 0.1385 Test MSE Loss: 0.7005
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6710412502288818
Epoch: 12, Steps: 35 Train Loss: 23.0280 (Forecasting Loss:0.1735 + XiCon Loss:2.2855 x Lambda(10.0)), Vali MSE Loss: 0.1398 Test MSE Loss: 0.7007
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.7275433540344238
Epoch: 13, Steps: 35 Train Loss: 24.0315 (Forecasting Loss:0.1745 + XiCon Loss:2.3857 x Lambda(10.0)), Vali MSE Loss: 0.1399 Test MSE Loss: 0.7008
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6567208766937256
Epoch: 14, Steps: 35 Train Loss: 24.2908 (Forecasting Loss:0.1731 + XiCon Loss:2.4118 x Lambda(10.0)), Vali MSE Loss: 0.1401 Test MSE Loss: 0.7009
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6300804615020752
Epoch: 15, Steps: 35 Train Loss: 22.7093 (Forecasting Loss:0.1712 + XiCon Loss:2.2538 x Lambda(10.0)), Vali MSE Loss: 0.1381 Test MSE Loss: 0.7008
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6513314247131348
Epoch: 16, Steps: 35 Train Loss: 21.5842 (Forecasting Loss:0.1747 + XiCon Loss:2.1409 x Lambda(10.0)), Vali MSE Loss: 0.1398 Test MSE Loss: 0.7008
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7235342860221863, mae:0.6888048648834229, mape:0.2661724090576172, mspe:0.18666665256023407 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3154
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.671220064163208
Epoch: 1, Steps: 35 Train Loss: 16.4145 (Forecasting Loss:0.5320 + XiCon Loss:1.5882 x Lambda(10.0)), Vali MSE Loss: 0.3108 Test MSE Loss: 1.4638
Validation loss decreased (inf --> 0.310813).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6358685493469238
Epoch: 2, Steps: 35 Train Loss: 14.9728 (Forecasting Loss:0.3454 + XiCon Loss:1.4627 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.6998
Validation loss decreased (0.310813 --> 0.199635).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6636123657226562
Epoch: 3, Steps: 35 Train Loss: 14.3895 (Forecasting Loss:0.2214 + XiCon Loss:1.4168 x Lambda(10.0)), Vali MSE Loss: 0.1383 Test MSE Loss: 0.7754
Validation loss decreased (0.199635 --> 0.138345).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5628535747528076
Epoch: 4, Steps: 35 Train Loss: 17.4845 (Forecasting Loss:0.1938 + XiCon Loss:1.7291 x Lambda(10.0)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.7431
Validation loss decreased (0.138345 --> 0.123151).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6829378604888916
Epoch: 5, Steps: 35 Train Loss: 18.1021 (Forecasting Loss:0.1847 + XiCon Loss:1.7917 x Lambda(10.0)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.7339
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.774085283279419
Epoch: 6, Steps: 35 Train Loss: 17.1829 (Forecasting Loss:0.1802 + XiCon Loss:1.7003 x Lambda(10.0)), Vali MSE Loss: 0.1248 Test MSE Loss: 0.7125
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6424469947814941
Epoch: 7, Steps: 35 Train Loss: 17.0461 (Forecasting Loss:0.1785 + XiCon Loss:1.6868 x Lambda(10.0)), Vali MSE Loss: 0.1234 Test MSE Loss: 0.7033
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.7170817852020264
Epoch: 8, Steps: 35 Train Loss: 16.9892 (Forecasting Loss:0.1775 + XiCon Loss:1.6812 x Lambda(10.0)), Vali MSE Loss: 0.1246 Test MSE Loss: 0.7011
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6779029369354248
Epoch: 9, Steps: 35 Train Loss: 17.1481 (Forecasting Loss:0.1776 + XiCon Loss:1.6970 x Lambda(10.0)), Vali MSE Loss: 0.1253 Test MSE Loss: 0.6992
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6437408924102783
Epoch: 10, Steps: 35 Train Loss: 17.7035 (Forecasting Loss:0.1774 + XiCon Loss:1.7526 x Lambda(10.0)), Vali MSE Loss: 0.1254 Test MSE Loss: 0.6982
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.666581392288208
Epoch: 11, Steps: 35 Train Loss: 17.9983 (Forecasting Loss:0.1765 + XiCon Loss:1.7822 x Lambda(10.0)), Vali MSE Loss: 0.1242 Test MSE Loss: 0.6977
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6926639080047607
Epoch: 12, Steps: 35 Train Loss: 17.5879 (Forecasting Loss:0.1764 + XiCon Loss:1.7412 x Lambda(10.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6975
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6635892391204834
Epoch: 13, Steps: 35 Train Loss: 17.0554 (Forecasting Loss:0.1762 + XiCon Loss:1.6879 x Lambda(10.0)), Vali MSE Loss: 0.1254 Test MSE Loss: 0.6974
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6738338470458984
Epoch: 14, Steps: 35 Train Loss: 18.1378 (Forecasting Loss:0.1764 + XiCon Loss:1.7961 x Lambda(10.0)), Vali MSE Loss: 0.1250 Test MSE Loss: 0.6973
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7662286162376404, mae:0.7200347185134888, mape:0.2732729911804199, mspe:0.18403902649879456 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3187
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.6508712768554688
Epoch: 1, Steps: 35 Train Loss: 16.2889 (Forecasting Loss:0.5018 + XiCon Loss:1.5787 x Lambda(10.0)), Vali MSE Loss: 0.2981 Test MSE Loss: 1.2980
Validation loss decreased (inf --> 0.298069).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6731820106506348
Epoch: 2, Steps: 35 Train Loss: 14.3289 (Forecasting Loss:0.3577 + XiCon Loss:1.3971 x Lambda(10.0)), Vali MSE Loss: 0.1770 Test MSE Loss: 0.7318
Validation loss decreased (0.298069 --> 0.177041).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.7076535224914551
Epoch: 3, Steps: 35 Train Loss: 16.3357 (Forecasting Loss:0.2246 + XiCon Loss:1.6111 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.7455
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7174773216247559
Epoch: 4, Steps: 35 Train Loss: 22.5150 (Forecasting Loss:0.2087 + XiCon Loss:2.2306 x Lambda(10.0)), Vali MSE Loss: 0.1324 Test MSE Loss: 0.6803
Validation loss decreased (0.177041 --> 0.132382).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5941393375396729
Epoch: 5, Steps: 35 Train Loss: 21.7292 (Forecasting Loss:0.1893 + XiCon Loss:2.1540 x Lambda(10.0)), Vali MSE Loss: 0.1336 Test MSE Loss: 0.6830
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6443514823913574
Epoch: 6, Steps: 35 Train Loss: 21.9100 (Forecasting Loss:0.1790 + XiCon Loss:2.1731 x Lambda(10.0)), Vali MSE Loss: 0.1323 Test MSE Loss: 0.6917
Validation loss decreased (0.132382 --> 0.132324).  Saving model ...
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6276350021362305
Epoch: 7, Steps: 35 Train Loss: 23.0822 (Forecasting Loss:0.1760 + XiCon Loss:2.2906 x Lambda(10.0)), Vali MSE Loss: 0.1294 Test MSE Loss: 0.6940
Validation loss decreased (0.132324 --> 0.129402).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.5976908206939697
Epoch: 8, Steps: 35 Train Loss: 24.8052 (Forecasting Loss:0.1736 + XiCon Loss:2.4632 x Lambda(10.0)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6929
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5813033580780029
Epoch: 9, Steps: 35 Train Loss: 22.0338 (Forecasting Loss:0.1752 + XiCon Loss:2.1859 x Lambda(10.0)), Vali MSE Loss: 0.1294 Test MSE Loss: 0.6926
Validation loss decreased (0.129402 --> 0.129374).  Saving model ...
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6558358669281006
Epoch: 10, Steps: 35 Train Loss: 24.4610 (Forecasting Loss:0.1734 + XiCon Loss:2.4288 x Lambda(10.0)), Vali MSE Loss: 0.1310 Test MSE Loss: 0.6927
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6522305011749268
Epoch: 11, Steps: 35 Train Loss: 24.1555 (Forecasting Loss:0.1725 + XiCon Loss:2.3983 x Lambda(10.0)), Vali MSE Loss: 0.1315 Test MSE Loss: 0.6924
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6624770164489746
Epoch: 12, Steps: 35 Train Loss: 25.9824 (Forecasting Loss:0.1724 + XiCon Loss:2.5810 x Lambda(10.0)), Vali MSE Loss: 0.1301 Test MSE Loss: 0.6928
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.622248649597168
Epoch: 13, Steps: 35 Train Loss: 23.6972 (Forecasting Loss:0.1735 + XiCon Loss:2.3524 x Lambda(10.0)), Vali MSE Loss: 0.1306 Test MSE Loss: 0.6927
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6045782566070557
Epoch: 14, Steps: 35 Train Loss: 24.8472 (Forecasting Loss:0.1740 + XiCon Loss:2.4673 x Lambda(10.0)), Vali MSE Loss: 0.1316 Test MSE Loss: 0.6927
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6882555484771729
Epoch: 15, Steps: 35 Train Loss: 24.3278 (Forecasting Loss:0.1734 + XiCon Loss:2.4154 x Lambda(10.0)), Vali MSE Loss: 0.1311 Test MSE Loss: 0.6927
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.7647395133972168
Epoch: 16, Steps: 35 Train Loss: 22.8269 (Forecasting Loss:0.1733 + XiCon Loss:2.2654 x Lambda(10.0)), Vali MSE Loss: 0.1302 Test MSE Loss: 0.6927
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6401290893554688
Epoch: 17, Steps: 35 Train Loss: 22.0156 (Forecasting Loss:0.1729 + XiCon Loss:2.1843 x Lambda(10.0)), Vali MSE Loss: 0.1311 Test MSE Loss: 0.6927
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.7367589473724365
Epoch: 18, Steps: 35 Train Loss: 24.6314 (Forecasting Loss:0.1708 + XiCon Loss:2.4461 x Lambda(10.0)), Vali MSE Loss: 0.1318 Test MSE Loss: 0.6927
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.6625509262084961
Epoch: 19, Steps: 35 Train Loss: 23.4534 (Forecasting Loss:0.1729 + XiCon Loss:2.3281 x Lambda(10.0)), Vali MSE Loss: 0.1316 Test MSE Loss: 0.6927
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7164729237556458, mae:0.668822169303894, mape:0.261336088180542, mspe:0.19489191472530365 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:440049
train 420
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3395
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 420
val 139
test 138
Epoch: 1 cost time: 0.696603536605835
Epoch: 1, Steps: 35 Train Loss: 16.4012 (Forecasting Loss:0.5335 + XiCon Loss:1.5868 x Lambda(10.0)), Vali MSE Loss: 0.2944 Test MSE Loss: 1.5287
Validation loss decreased (inf --> 0.294431).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.5886452198028564
Epoch: 2, Steps: 35 Train Loss: 14.7923 (Forecasting Loss:0.3295 + XiCon Loss:1.4463 x Lambda(10.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.7308
Validation loss decreased (0.294431 --> 0.211593).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6607916355133057
Epoch: 3, Steps: 35 Train Loss: 14.3780 (Forecasting Loss:0.2292 + XiCon Loss:1.4149 x Lambda(10.0)), Vali MSE Loss: 0.1352 Test MSE Loss: 0.7894
Validation loss decreased (0.211593 --> 0.135159).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.7137234210968018
Epoch: 4, Steps: 35 Train Loss: 16.1850 (Forecasting Loss:0.1904 + XiCon Loss:1.5995 x Lambda(10.0)), Vali MSE Loss: 0.1257 Test MSE Loss: 0.7237
Validation loss decreased (0.135159 --> 0.125739).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6652045249938965
Epoch: 5, Steps: 35 Train Loss: 17.7663 (Forecasting Loss:0.1818 + XiCon Loss:1.7585 x Lambda(10.0)), Vali MSE Loss: 0.1254 Test MSE Loss: 0.7055
Validation loss decreased (0.125739 --> 0.125436).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.672370433807373
Epoch: 6, Steps: 35 Train Loss: 18.9604 (Forecasting Loss:0.1790 + XiCon Loss:1.8781 x Lambda(10.0)), Vali MSE Loss: 0.1262 Test MSE Loss: 0.6943
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.7242293357849121
Epoch: 7, Steps: 35 Train Loss: 19.9490 (Forecasting Loss:0.1777 + XiCon Loss:1.9771 x Lambda(10.0)), Vali MSE Loss: 0.1252 Test MSE Loss: 0.6939
Validation loss decreased (0.125436 --> 0.125205).  Saving model ...
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.647552490234375
Epoch: 8, Steps: 35 Train Loss: 20.2053 (Forecasting Loss:0.1785 + XiCon Loss:2.0027 x Lambda(10.0)), Vali MSE Loss: 0.1262 Test MSE Loss: 0.6926
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6456849575042725
Epoch: 9, Steps: 35 Train Loss: 19.5708 (Forecasting Loss:0.1771 + XiCon Loss:1.9394 x Lambda(10.0)), Vali MSE Loss: 0.1258 Test MSE Loss: 0.6918
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6744785308837891
Epoch: 10, Steps: 35 Train Loss: 19.4319 (Forecasting Loss:0.1773 + XiCon Loss:1.9255 x Lambda(10.0)), Vali MSE Loss: 0.1252 Test MSE Loss: 0.6915
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6676778793334961
Epoch: 11, Steps: 35 Train Loss: 20.7773 (Forecasting Loss:0.1780 + XiCon Loss:2.0599 x Lambda(10.0)), Vali MSE Loss: 0.1260 Test MSE Loss: 0.6914
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.6308443546295166
Epoch: 12, Steps: 35 Train Loss: 22.1970 (Forecasting Loss:0.1767 + XiCon Loss:2.2020 x Lambda(10.0)), Vali MSE Loss: 0.1265 Test MSE Loss: 0.6912
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6698181629180908
Epoch: 13, Steps: 35 Train Loss: 18.1813 (Forecasting Loss:0.1771 + XiCon Loss:1.8004 x Lambda(10.0)), Vali MSE Loss: 0.1267 Test MSE Loss: 0.6911
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6754553318023682
Epoch: 14, Steps: 35 Train Loss: 19.8962 (Forecasting Loss:0.1772 + XiCon Loss:1.9719 x Lambda(10.0)), Vali MSE Loss: 0.1265 Test MSE Loss: 0.6911
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.640373945236206
Epoch: 15, Steps: 35 Train Loss: 20.4047 (Forecasting Loss:0.1780 + XiCon Loss:2.0227 x Lambda(10.0)), Vali MSE Loss: 0.1259 Test MSE Loss: 0.6911
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6572661399841309
Epoch: 16, Steps: 35 Train Loss: 20.1925 (Forecasting Loss:0.1772 + XiCon Loss:2.0015 x Lambda(10.0)), Vali MSE Loss: 0.1249 Test MSE Loss: 0.6911
Validation loss decreased (0.125205 --> 0.124891).  Saving model ...
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.7204976081848145
Epoch: 17, Steps: 35 Train Loss: 19.7126 (Forecasting Loss:0.1773 + XiCon Loss:1.9535 x Lambda(10.0)), Vali MSE Loss: 0.1258 Test MSE Loss: 0.6911
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.6323332786560059
Epoch: 18, Steps: 35 Train Loss: 20.1719 (Forecasting Loss:0.1778 + XiCon Loss:1.9994 x Lambda(10.0)), Vali MSE Loss: 0.1268 Test MSE Loss: 0.6911
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
Epoch: 19 cost time: 0.5903956890106201
Epoch: 19, Steps: 35 Train Loss: 20.3597 (Forecasting Loss:0.1778 + XiCon Loss:2.0182 x Lambda(10.0)), Vali MSE Loss: 0.1262 Test MSE Loss: 0.6911
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
Epoch: 20 cost time: 0.6668469905853271
Epoch: 20, Steps: 35 Train Loss: 20.5993 (Forecasting Loss:0.1766 + XiCon Loss:2.0423 x Lambda(10.0)), Vali MSE Loss: 0.1274 Test MSE Loss: 0.6911
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
Epoch: 21 cost time: 0.7646491527557373
Epoch: 21, Steps: 35 Train Loss: 20.6315 (Forecasting Loss:0.1779 + XiCon Loss:2.0454 x Lambda(10.0)), Vali MSE Loss: 0.1269 Test MSE Loss: 0.6911
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
Epoch: 22 cost time: 0.6474599838256836
Epoch: 22, Steps: 35 Train Loss: 20.4901 (Forecasting Loss:0.1767 + XiCon Loss:2.0313 x Lambda(10.0)), Vali MSE Loss: 0.1267 Test MSE Loss: 0.6911
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
Epoch: 23 cost time: 0.6535120010375977
Epoch: 23, Steps: 35 Train Loss: 20.4673 (Forecasting Loss:0.1774 + XiCon Loss:2.0290 x Lambda(10.0)), Vali MSE Loss: 0.1269 Test MSE Loss: 0.6911
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
Epoch: 24 cost time: 0.6189932823181152
Epoch: 24, Steps: 35 Train Loss: 21.0308 (Forecasting Loss:0.1776 + XiCon Loss:2.0853 x Lambda(10.0)), Vali MSE Loss: 0.1277 Test MSE Loss: 0.6911
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
Epoch: 25 cost time: 0.6284573078155518
Epoch: 25, Steps: 35 Train Loss: 19.9857 (Forecasting Loss:0.1780 + XiCon Loss:1.9808 x Lambda(10.0)), Vali MSE Loss: 0.1270 Test MSE Loss: 0.6911
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
Epoch: 26 cost time: 0.6753194332122803
Epoch: 26, Steps: 35 Train Loss: 19.4949 (Forecasting Loss:0.1771 + XiCon Loss:1.9318 x Lambda(10.0)), Vali MSE Loss: 0.1269 Test MSE Loss: 0.6911
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl56_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 138
test shape: (11, 12, 56, 1) (11, 12, 56, 1)
test shape: (132, 56, 1) (132, 56, 1)
mse:0.7154753804206848, mae:0.6666764616966248, mape:0.26070430874824524, mspe:0.19355472922325134 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.7269+-0.02778, MAE:0.6821+-0.02880, MAPE:0.2643+-0.00691, MSPE:0.1900+-0.00568, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[112], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='national_illness', root_path='./dataset/illness', data_path='national_illness.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=104, label_len=7, pred_len=112, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=128, n_heads=8, e_layers=3, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=12, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.95, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.2636
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.8512289524078369
Epoch: 1, Steps: 30 Train Loss: 16.6672 (Forecasting Loss:0.7755 + XiCon Loss:1.5892 x Lambda(10.0)), Vali MSE Loss: 0.3553 Test MSE Loss: 2.4943
Validation loss decreased (inf --> 0.355286).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6410207748413086
Epoch: 2, Steps: 30 Train Loss: 14.7614 (Forecasting Loss:0.4612 + XiCon Loss:1.4300 x Lambda(10.0)), Vali MSE Loss: 0.3979 Test MSE Loss: 0.8458
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5519156455993652
Epoch: 3, Steps: 30 Train Loss: 14.8530 (Forecasting Loss:0.3189 + XiCon Loss:1.4534 x Lambda(10.0)), Vali MSE Loss: 0.2583 Test MSE Loss: 1.0730
Validation loss decreased (0.355286 --> 0.258301).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5972871780395508
Epoch: 4, Steps: 30 Train Loss: 16.8684 (Forecasting Loss:0.2777 + XiCon Loss:1.6591 x Lambda(10.0)), Vali MSE Loss: 0.2218 Test MSE Loss: 1.2786
Validation loss decreased (0.258301 --> 0.221774).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5705001354217529
Epoch: 5, Steps: 30 Train Loss: 19.6850 (Forecasting Loss:0.2408 + XiCon Loss:1.9444 x Lambda(10.0)), Vali MSE Loss: 0.2866 Test MSE Loss: 1.2552
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6058242321014404
Epoch: 6, Steps: 30 Train Loss: 16.5758 (Forecasting Loss:0.2283 + XiCon Loss:1.6348 x Lambda(10.0)), Vali MSE Loss: 0.2706 Test MSE Loss: 1.1041
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6218290328979492
Epoch: 7, Steps: 30 Train Loss: 20.9330 (Forecasting Loss:0.2234 + XiCon Loss:2.0710 x Lambda(10.0)), Vali MSE Loss: 0.2571 Test MSE Loss: 1.1384
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6085941791534424
Epoch: 8, Steps: 30 Train Loss: 20.2686 (Forecasting Loss:0.2187 + XiCon Loss:2.0050 x Lambda(10.0)), Vali MSE Loss: 0.3005 Test MSE Loss: 1.0981
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5773200988769531
Epoch: 9, Steps: 30 Train Loss: 20.1220 (Forecasting Loss:0.2244 + XiCon Loss:1.9898 x Lambda(10.0)), Vali MSE Loss: 0.2865 Test MSE Loss: 1.1290
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5854811668395996
Epoch: 10, Steps: 30 Train Loss: 20.4334 (Forecasting Loss:0.2096 + XiCon Loss:2.0224 x Lambda(10.0)), Vali MSE Loss: 0.2918 Test MSE Loss: 1.1322
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.6007387638092041
Epoch: 11, Steps: 30 Train Loss: 21.1188 (Forecasting Loss:0.2206 + XiCon Loss:2.0898 x Lambda(10.0)), Vali MSE Loss: 0.2697 Test MSE Loss: 1.1338
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.587151288986206
Epoch: 12, Steps: 30 Train Loss: 20.3831 (Forecasting Loss:0.2182 + XiCon Loss:2.0165 x Lambda(10.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 1.1310
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.6288831233978271
Epoch: 13, Steps: 30 Train Loss: 19.3242 (Forecasting Loss:0.2154 + XiCon Loss:1.9109 x Lambda(10.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 1.1284
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5515084266662598
Epoch: 14, Steps: 30 Train Loss: 20.9551 (Forecasting Loss:0.2138 + XiCon Loss:2.0741 x Lambda(10.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 1.1275
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.5057058334350586, mae:1.051458477973938, mape:0.3360072076320648, mspe:0.1575300693511963 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3078
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.5759804248809814
Epoch: 1, Steps: 30 Train Loss: 16.5818 (Forecasting Loss:0.7488 + XiCon Loss:1.5833 x Lambda(10.0)), Vali MSE Loss: 0.3341 Test MSE Loss: 2.4453
Validation loss decreased (inf --> 0.334097).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6355774402618408
Epoch: 2, Steps: 30 Train Loss: 15.1273 (Forecasting Loss:0.4987 + XiCon Loss:1.4629 x Lambda(10.0)), Vali MSE Loss: 0.2219 Test MSE Loss: 1.1490
Validation loss decreased (0.334097 --> 0.221929).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6661620140075684
Epoch: 3, Steps: 30 Train Loss: 14.6605 (Forecasting Loss:0.3422 + XiCon Loss:1.4318 x Lambda(10.0)), Vali MSE Loss: 0.2386 Test MSE Loss: 1.1804
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5721745491027832
Epoch: 4, Steps: 30 Train Loss: 16.7819 (Forecasting Loss:0.3135 + XiCon Loss:1.6468 x Lambda(10.0)), Vali MSE Loss: 0.1578 Test MSE Loss: 1.4174
Validation loss decreased (0.221929 --> 0.157834).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.6341519355773926
Epoch: 5, Steps: 30 Train Loss: 18.5625 (Forecasting Loss:0.2797 + XiCon Loss:1.8283 x Lambda(10.0)), Vali MSE Loss: 0.1927 Test MSE Loss: 1.3229
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5812795162200928
Epoch: 6, Steps: 30 Train Loss: 19.7217 (Forecasting Loss:0.2622 + XiCon Loss:1.9459 x Lambda(10.0)), Vali MSE Loss: 0.1899 Test MSE Loss: 1.1907
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5867915153503418
Epoch: 7, Steps: 30 Train Loss: 20.5153 (Forecasting Loss:0.2666 + XiCon Loss:2.0249 x Lambda(10.0)), Vali MSE Loss: 0.1826 Test MSE Loss: 1.2618
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.5711650848388672
Epoch: 8, Steps: 30 Train Loss: 19.4620 (Forecasting Loss:0.2506 + XiCon Loss:1.9211 x Lambda(10.0)), Vali MSE Loss: 0.2037 Test MSE Loss: 1.1715
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6144044399261475
Epoch: 9, Steps: 30 Train Loss: 20.0912 (Forecasting Loss:0.2435 + XiCon Loss:1.9848 x Lambda(10.0)), Vali MSE Loss: 0.1825 Test MSE Loss: 1.2218
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5567526817321777
Epoch: 10, Steps: 30 Train Loss: 20.4363 (Forecasting Loss:0.2467 + XiCon Loss:2.0190 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 1.2013
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.620290994644165
Epoch: 11, Steps: 30 Train Loss: 20.1579 (Forecasting Loss:0.2514 + XiCon Loss:1.9906 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 1.1847
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5602240562438965
Epoch: 12, Steps: 30 Train Loss: 21.5367 (Forecasting Loss:0.2469 + XiCon Loss:2.1290 x Lambda(10.0)), Vali MSE Loss: 0.1950 Test MSE Loss: 1.1819
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5737011432647705
Epoch: 13, Steps: 30 Train Loss: 21.8776 (Forecasting Loss:0.2491 + XiCon Loss:2.1629 x Lambda(10.0)), Vali MSE Loss: 0.1963 Test MSE Loss: 1.1826
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.6132514476776123
Epoch: 14, Steps: 30 Train Loss: 20.7969 (Forecasting Loss:0.2467 + XiCon Loss:2.0550 x Lambda(10.0)), Vali MSE Loss: 0.1953 Test MSE Loss: 1.1826
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.6960723400115967, mae:1.1386317014694214, mape:0.3611133396625519, mspe:0.16986124217510223 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3074
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.5956559181213379
Epoch: 1, Steps: 30 Train Loss: 16.5204 (Forecasting Loss:0.6787 + XiCon Loss:1.5842 x Lambda(10.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 2.1903
Validation loss decreased (inf --> 0.319884).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6263148784637451
Epoch: 2, Steps: 30 Train Loss: 15.2275 (Forecasting Loss:0.4779 + XiCon Loss:1.4750 x Lambda(10.0)), Vali MSE Loss: 0.2714 Test MSE Loss: 1.0658
Validation loss decreased (0.319884 --> 0.271417).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5489070415496826
Epoch: 3, Steps: 30 Train Loss: 14.6800 (Forecasting Loss:0.3201 + XiCon Loss:1.4360 x Lambda(10.0)), Vali MSE Loss: 0.3326 Test MSE Loss: 1.2632
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5779857635498047
Epoch: 4, Steps: 30 Train Loss: 16.9058 (Forecasting Loss:0.2740 + XiCon Loss:1.6632 x Lambda(10.0)), Vali MSE Loss: 0.2791 Test MSE Loss: 1.3519
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5242452621459961
Epoch: 5, Steps: 30 Train Loss: 18.9305 (Forecasting Loss:0.2734 + XiCon Loss:1.8657 x Lambda(10.0)), Vali MSE Loss: 0.1521 Test MSE Loss: 1.3621
Validation loss decreased (0.271417 --> 0.152110).  Saving model ...
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.5703682899475098
Epoch: 6, Steps: 30 Train Loss: 18.5609 (Forecasting Loss:0.2678 + XiCon Loss:1.8293 x Lambda(10.0)), Vali MSE Loss: 0.1540 Test MSE Loss: 1.3415
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6174137592315674
Epoch: 7, Steps: 30 Train Loss: 19.1618 (Forecasting Loss:0.2624 + XiCon Loss:1.8899 x Lambda(10.0)), Vali MSE Loss: 0.1576 Test MSE Loss: 1.3177
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.5220615863800049
Epoch: 8, Steps: 30 Train Loss: 19.9748 (Forecasting Loss:0.2612 + XiCon Loss:1.9714 x Lambda(10.0)), Vali MSE Loss: 0.1473 Test MSE Loss: 1.3343
Validation loss decreased (0.152110 --> 0.147321).  Saving model ...
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.6013548374176025
Epoch: 9, Steps: 30 Train Loss: 19.7139 (Forecasting Loss:0.2597 + XiCon Loss:1.9454 x Lambda(10.0)), Vali MSE Loss: 0.1554 Test MSE Loss: 1.3241
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.5351314544677734
Epoch: 10, Steps: 30 Train Loss: 18.9755 (Forecasting Loss:0.2602 + XiCon Loss:1.8715 x Lambda(10.0)), Vali MSE Loss: 0.1506 Test MSE Loss: 1.3254
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5744037628173828
Epoch: 11, Steps: 30 Train Loss: 19.9470 (Forecasting Loss:0.2586 + XiCon Loss:1.9688 x Lambda(10.0)), Vali MSE Loss: 0.1535 Test MSE Loss: 1.3242
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5725834369659424
Epoch: 12, Steps: 30 Train Loss: 19.2924 (Forecasting Loss:0.2595 + XiCon Loss:1.9033 x Lambda(10.0)), Vali MSE Loss: 0.1558 Test MSE Loss: 1.3240
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.621586799621582
Epoch: 13, Steps: 30 Train Loss: 18.9943 (Forecasting Loss:0.2564 + XiCon Loss:1.8738 x Lambda(10.0)), Vali MSE Loss: 0.1561 Test MSE Loss: 1.3238
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5482707023620605
Epoch: 14, Steps: 30 Train Loss: 19.7454 (Forecasting Loss:0.2611 + XiCon Loss:1.9484 x Lambda(10.0)), Vali MSE Loss: 0.1532 Test MSE Loss: 1.3236
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
Epoch: 15 cost time: 0.6271483898162842
Epoch: 15, Steps: 30 Train Loss: 19.7081 (Forecasting Loss:0.2602 + XiCon Loss:1.9448 x Lambda(10.0)), Vali MSE Loss: 0.1533 Test MSE Loss: 1.3236
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
Epoch: 16 cost time: 0.6096656322479248
Epoch: 16, Steps: 30 Train Loss: 19.4568 (Forecasting Loss:0.2580 + XiCon Loss:1.9199 x Lambda(10.0)), Vali MSE Loss: 0.1533 Test MSE Loss: 1.3236
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
Epoch: 17 cost time: 0.6081240177154541
Epoch: 17, Steps: 30 Train Loss: 18.6730 (Forecasting Loss:0.2598 + XiCon Loss:1.8413 x Lambda(10.0)), Vali MSE Loss: 0.1557 Test MSE Loss: 1.3236
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
Epoch: 18 cost time: 0.5847012996673584
Epoch: 18, Steps: 30 Train Loss: 18.9873 (Forecasting Loss:0.2596 + XiCon Loss:1.8728 x Lambda(10.0)), Vali MSE Loss: 0.1559 Test MSE Loss: 1.3236
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.57515549659729, mae:1.0934642553329468, mape:0.3480219542980194, mspe:0.16222098469734192 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3103
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.5865461826324463
Epoch: 1, Steps: 30 Train Loss: 16.4512 (Forecasting Loss:0.6955 + XiCon Loss:1.5756 x Lambda(10.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 2.0520
Validation loss decreased (inf --> 0.321762).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.6066069602966309
Epoch: 2, Steps: 30 Train Loss: 14.9690 (Forecasting Loss:0.5007 + XiCon Loss:1.4468 x Lambda(10.0)), Vali MSE Loss: 0.1903 Test MSE Loss: 1.2861
Validation loss decreased (0.321762 --> 0.190319).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.5605378150939941
Epoch: 3, Steps: 30 Train Loss: 15.1564 (Forecasting Loss:0.3408 + XiCon Loss:1.4816 x Lambda(10.0)), Vali MSE Loss: 0.1908 Test MSE Loss: 1.2133
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.5791387557983398
Epoch: 4, Steps: 30 Train Loss: 16.9175 (Forecasting Loss:0.3002 + XiCon Loss:1.6617 x Lambda(10.0)), Vali MSE Loss: 0.1681 Test MSE Loss: 1.2627
Validation loss decreased (0.190319 --> 0.168056).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.642733097076416
Epoch: 5, Steps: 30 Train Loss: 18.8619 (Forecasting Loss:0.2884 + XiCon Loss:1.8573 x Lambda(10.0)), Vali MSE Loss: 0.1996 Test MSE Loss: 1.1826
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6371917724609375
Epoch: 6, Steps: 30 Train Loss: 20.6611 (Forecasting Loss:0.2831 + XiCon Loss:2.0378 x Lambda(10.0)), Vali MSE Loss: 0.2156 Test MSE Loss: 1.1481
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.5706322193145752
Epoch: 7, Steps: 30 Train Loss: 21.1277 (Forecasting Loss:0.2770 + XiCon Loss:2.0851 x Lambda(10.0)), Vali MSE Loss: 0.2356 Test MSE Loss: 1.1125
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6703958511352539
Epoch: 8, Steps: 30 Train Loss: 24.5846 (Forecasting Loss:0.2713 + XiCon Loss:2.4313 x Lambda(10.0)), Vali MSE Loss: 0.2244 Test MSE Loss: 1.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.5836892127990723
Epoch: 9, Steps: 30 Train Loss: 21.5736 (Forecasting Loss:0.2748 + XiCon Loss:2.1299 x Lambda(10.0)), Vali MSE Loss: 0.2340 Test MSE Loss: 1.1110
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6142666339874268
Epoch: 10, Steps: 30 Train Loss: 22.6045 (Forecasting Loss:0.2774 + XiCon Loss:2.2327 x Lambda(10.0)), Vali MSE Loss: 0.2389 Test MSE Loss: 1.1069
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5915055274963379
Epoch: 11, Steps: 30 Train Loss: 24.4937 (Forecasting Loss:0.2713 + XiCon Loss:2.4222 x Lambda(10.0)), Vali MSE Loss: 0.2253 Test MSE Loss: 1.1043
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.5971863269805908
Epoch: 12, Steps: 30 Train Loss: 22.7149 (Forecasting Loss:0.2698 + XiCon Loss:2.2445 x Lambda(10.0)), Vali MSE Loss: 0.2316 Test MSE Loss: 1.1058
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5938370227813721
Epoch: 13, Steps: 30 Train Loss: 22.0335 (Forecasting Loss:0.2725 + XiCon Loss:2.1761 x Lambda(10.0)), Vali MSE Loss: 0.2350 Test MSE Loss: 1.1057
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5932464599609375
Epoch: 14, Steps: 30 Train Loss: 22.8397 (Forecasting Loss:0.2716 + XiCon Loss:2.2568 x Lambda(10.0)), Vali MSE Loss: 0.2351 Test MSE Loss: 1.1055
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.470711350440979, mae:1.0546950101852417, mape:0.34322935342788696, mspe:0.1664046347141266 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:451809
train 364
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99579261] ~ [-0.00830431 -0.00416403]
Xi-correlation values:[0.99482759 0.98258816] ~ [0. 1.]
Autocorrelation calculation time: 0.3298
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 364
val 83
test 82
Epoch: 1 cost time: 0.6479206085205078
Epoch: 1, Steps: 30 Train Loss: 16.4105 (Forecasting Loss:0.6012 + XiCon Loss:1.5809 x Lambda(10.0)), Vali MSE Loss: 0.5148 Test MSE Loss: 1.4020
Validation loss decreased (inf --> 0.514805).  Saving model ...
Updating learning rate to 0.005
Epoch: 2 cost time: 0.56656813621521
Epoch: 2, Steps: 30 Train Loss: 14.7334 (Forecasting Loss:0.4867 + XiCon Loss:1.4247 x Lambda(10.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 1.2215
Validation loss decreased (0.514805 --> 0.252648).  Saving model ...
Updating learning rate to 0.0025
Epoch: 3 cost time: 0.6295568943023682
Epoch: 3, Steps: 30 Train Loss: 14.8576 (Forecasting Loss:0.2989 + XiCon Loss:1.4559 x Lambda(10.0)), Vali MSE Loss: 0.1699 Test MSE Loss: 1.3148
Validation loss decreased (0.252648 --> 0.169930).  Saving model ...
Updating learning rate to 0.00125
Epoch: 4 cost time: 0.6825850009918213
Epoch: 4, Steps: 30 Train Loss: 16.4268 (Forecasting Loss:0.3110 + XiCon Loss:1.6116 x Lambda(10.0)), Vali MSE Loss: 0.1591 Test MSE Loss: 1.4078
Validation loss decreased (0.169930 --> 0.159138).  Saving model ...
Updating learning rate to 0.000625
Epoch: 5 cost time: 0.5223784446716309
Epoch: 5, Steps: 30 Train Loss: 20.4087 (Forecasting Loss:0.2995 + XiCon Loss:2.0109 x Lambda(10.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 1.2597
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
Epoch: 6 cost time: 0.6270315647125244
Epoch: 6, Steps: 30 Train Loss: 19.1842 (Forecasting Loss:0.2881 + XiCon Loss:1.8896 x Lambda(10.0)), Vali MSE Loss: 0.1823 Test MSE Loss: 1.2214
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
Epoch: 7 cost time: 0.6383121013641357
Epoch: 7, Steps: 30 Train Loss: 22.4808 (Forecasting Loss:0.2799 + XiCon Loss:2.2201 x Lambda(10.0)), Vali MSE Loss: 0.1970 Test MSE Loss: 1.1803
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
Epoch: 8 cost time: 0.6147205829620361
Epoch: 8, Steps: 30 Train Loss: 20.9927 (Forecasting Loss:0.2675 + XiCon Loss:2.0725 x Lambda(10.0)), Vali MSE Loss: 0.1683 Test MSE Loss: 1.2369
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
Epoch: 9 cost time: 0.634333610534668
Epoch: 9, Steps: 30 Train Loss: 22.5563 (Forecasting Loss:0.2640 + XiCon Loss:2.2292 x Lambda(10.0)), Vali MSE Loss: 0.1767 Test MSE Loss: 1.2087
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
Epoch: 10 cost time: 0.6434659957885742
Epoch: 10, Steps: 30 Train Loss: 21.1564 (Forecasting Loss:0.2683 + XiCon Loss:2.0888 x Lambda(10.0)), Vali MSE Loss: 0.1839 Test MSE Loss: 1.1921
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
Epoch: 11 cost time: 0.5615034103393555
Epoch: 11, Steps: 30 Train Loss: 21.3540 (Forecasting Loss:0.2686 + XiCon Loss:2.1085 x Lambda(10.0)), Vali MSE Loss: 0.1898 Test MSE Loss: 1.1886
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
Epoch: 12 cost time: 0.591062068939209
Epoch: 12, Steps: 30 Train Loss: 22.0241 (Forecasting Loss:0.2646 + XiCon Loss:2.1760 x Lambda(10.0)), Vali MSE Loss: 0.1888 Test MSE Loss: 1.1939
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
Epoch: 13 cost time: 0.5503940582275391
Epoch: 13, Steps: 30 Train Loss: 21.6822 (Forecasting Loss:0.2670 + XiCon Loss:2.1415 x Lambda(10.0)), Vali MSE Loss: 0.1813 Test MSE Loss: 1.1966
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
Epoch: 14 cost time: 0.5978991985321045
Epoch: 14, Steps: 30 Train Loss: 22.1360 (Forecasting Loss:0.2676 + XiCon Loss:2.1868 x Lambda(10.0)), Vali MSE Loss: 0.1795 Test MSE Loss: 1.1973
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_national_illness_ftS_sl104_ll7_pl112_dm128_nh8_el3_dl1_df128_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 82
test shape: (6, 12, 112, 1) (6, 12, 112, 1)
test shape: (72, 112, 1) (72, 112, 1)
mse:1.678976058959961, mae:1.1365872621536255, mape:0.36313560605049133, mspe:0.17044788599014282 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5853+-0.12512, MAE:1.0950+-0.05252, MAPE:0.3503+-0.01444, MSPE:0.1653+-0.00675, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
