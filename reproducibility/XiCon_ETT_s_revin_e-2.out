Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4569
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2732248
	speed: 0.0163s/iter; left time: 206.8722s
Epoch: 1 cost time: 1.9602272510528564
Epoch: 1, Steps: 128 Train Loss: 0.2748 (Forecasting Loss:0.2439 + XiCon Loss:3.0930 x Lambda(0.01)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1209
Validation loss decreased (inf --> 0.173820).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2889853
	speed: 0.0141s/iter; left time: 177.2394s
Epoch: 2 cost time: 1.743619680404663
Epoch: 2, Steps: 128 Train Loss: 0.2668 (Forecasting Loss:0.2364 + XiCon Loss:3.0362 x Lambda(0.01)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1398
Validation loss decreased (0.173820 --> 0.172655).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2078800
	speed: 0.0131s/iter; left time: 163.0821s
Epoch: 3 cost time: 1.6579036712646484
Epoch: 3, Steps: 128 Train Loss: 0.2320 (Forecasting Loss:0.2019 + XiCon Loss:3.0147 x Lambda(0.01)), Vali MSE Loss: 0.1601 Test MSE Loss: 0.1499
Validation loss decreased (0.172655 --> 0.160092).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1917923
	speed: 0.0135s/iter; left time: 166.3285s
Epoch: 4 cost time: 1.703399896621704
Epoch: 4, Steps: 128 Train Loss: 0.2119 (Forecasting Loss:0.1820 + XiCon Loss:2.9872 x Lambda(0.01)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1560
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2043556
	speed: 0.0140s/iter; left time: 170.6446s
Epoch: 5 cost time: 1.7397031784057617
Epoch: 5, Steps: 128 Train Loss: 0.2012 (Forecasting Loss:0.1714 + XiCon Loss:2.9768 x Lambda(0.01)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1551
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1934104
	speed: 0.0140s/iter; left time: 168.7627s
Epoch: 6 cost time: 1.7436606884002686
Epoch: 6, Steps: 128 Train Loss: 0.1950 (Forecasting Loss:0.1653 + XiCon Loss:2.9687 x Lambda(0.01)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1601
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1753167
	speed: 0.0147s/iter; left time: 175.6688s
Epoch: 7 cost time: 1.8646183013916016
Epoch: 7, Steps: 128 Train Loss: 0.1915 (Forecasting Loss:0.1618 + XiCon Loss:2.9697 x Lambda(0.01)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1625
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1898486
	speed: 0.0136s/iter; left time: 160.1962s
Epoch: 8 cost time: 1.7429215908050537
Epoch: 8, Steps: 128 Train Loss: 0.1897 (Forecasting Loss:0.1600 + XiCon Loss:2.9683 x Lambda(0.01)), Vali MSE Loss: 0.1751 Test MSE Loss: 0.1618
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2037413
	speed: 0.0138s/iter; left time: 160.9241s
Epoch: 9 cost time: 1.699697732925415
Epoch: 9, Steps: 128 Train Loss: 0.1888 (Forecasting Loss:0.1591 + XiCon Loss:2.9673 x Lambda(0.01)), Vali MSE Loss: 0.1747 Test MSE Loss: 0.1608
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1981511
	speed: 0.0143s/iter; left time: 164.7465s
Epoch: 10 cost time: 1.7549240589141846
Epoch: 10, Steps: 128 Train Loss: 0.1886 (Forecasting Loss:0.1589 + XiCon Loss:2.9649 x Lambda(0.01)), Vali MSE Loss: 0.1757 Test MSE Loss: 0.1615
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1877803
	speed: 0.0138s/iter; left time: 157.5417s
Epoch: 11 cost time: 1.7196311950683594
Epoch: 11, Steps: 128 Train Loss: 0.1882 (Forecasting Loss:0.1585 + XiCon Loss:2.9666 x Lambda(0.01)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1615
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1951215
	speed: 0.0150s/iter; left time: 169.9078s
Epoch: 12 cost time: 1.8321928977966309
Epoch: 12, Steps: 128 Train Loss: 0.1882 (Forecasting Loss:0.1585 + XiCon Loss:2.9694 x Lambda(0.01)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1615
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1914901
	speed: 0.0145s/iter; left time: 161.4515s
Epoch: 13 cost time: 1.7760825157165527
Epoch: 13, Steps: 128 Train Loss: 0.1878 (Forecasting Loss:0.1581 + XiCon Loss:2.9680 x Lambda(0.01)), Vali MSE Loss: 0.1753 Test MSE Loss: 0.1615
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.08240771293640137, mae:0.21733641624450684, mape:0.17329102754592896, mspe:0.05895847827196121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3119
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2660083
	speed: 0.0138s/iter; left time: 174.7586s
Epoch: 1 cost time: 1.7097535133361816
Epoch: 1, Steps: 128 Train Loss: 0.2733 (Forecasting Loss:0.2425 + XiCon Loss:3.0788 x Lambda(0.01)), Vali MSE Loss: 0.1830 Test MSE Loss: 0.1248
Validation loss decreased (inf --> 0.182956).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.3117032
	speed: 0.0142s/iter; left time: 178.7871s
Epoch: 2 cost time: 1.7615911960601807
Epoch: 2, Steps: 128 Train Loss: 0.2759 (Forecasting Loss:0.2454 + XiCon Loss:3.0454 x Lambda(0.01)), Vali MSE Loss: 0.1752 Test MSE Loss: 0.1306
Validation loss decreased (0.182956 --> 0.175195).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2594333
	speed: 0.0136s/iter; left time: 168.8685s
Epoch: 3 cost time: 1.6952946186065674
Epoch: 3, Steps: 128 Train Loss: 0.2448 (Forecasting Loss:0.2148 + XiCon Loss:3.0024 x Lambda(0.01)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1247
Validation loss decreased (0.175195 --> 0.171696).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2333972
	speed: 0.0135s/iter; left time: 166.6182s
Epoch: 4 cost time: 1.7025527954101562
Epoch: 4, Steps: 128 Train Loss: 0.2166 (Forecasting Loss:0.1866 + XiCon Loss:3.0007 x Lambda(0.01)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1388
Validation loss decreased (0.171696 --> 0.170962).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1894702
	speed: 0.0132s/iter; left time: 161.0186s
Epoch: 5 cost time: 1.6520867347717285
Epoch: 5, Steps: 128 Train Loss: 0.1950 (Forecasting Loss:0.1649 + XiCon Loss:3.0100 x Lambda(0.01)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1359
Validation loss decreased (0.170962 --> 0.170917).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2026165
	speed: 0.0134s/iter; left time: 161.8925s
Epoch: 6 cost time: 1.6662318706512451
Epoch: 6, Steps: 128 Train Loss: 0.1864 (Forecasting Loss:0.1563 + XiCon Loss:3.0118 x Lambda(0.01)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1425
Validation loss decreased (0.170917 --> 0.170590).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1761139
	speed: 0.0142s/iter; left time: 170.0130s
Epoch: 7 cost time: 1.771846055984497
Epoch: 7, Steps: 128 Train Loss: 0.1820 (Forecasting Loss:0.1518 + XiCon Loss:3.0119 x Lambda(0.01)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1417
Validation loss decreased (0.170590 --> 0.169672).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1747507
	speed: 0.0142s/iter; left time: 167.3605s
Epoch: 8 cost time: 1.8212556838989258
Epoch: 8, Steps: 128 Train Loss: 0.1802 (Forecasting Loss:0.1501 + XiCon Loss:3.0131 x Lambda(0.01)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1440
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1788395
	speed: 0.0130s/iter; left time: 152.3588s
Epoch: 9 cost time: 1.6590864658355713
Epoch: 9, Steps: 128 Train Loss: 0.1795 (Forecasting Loss:0.1494 + XiCon Loss:3.0127 x Lambda(0.01)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1435
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1649743
	speed: 0.0132s/iter; left time: 152.4446s
Epoch: 10 cost time: 1.6450073719024658
Epoch: 10, Steps: 128 Train Loss: 0.1785 (Forecasting Loss:0.1484 + XiCon Loss:3.0135 x Lambda(0.01)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1428
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1721986
	speed: 0.0138s/iter; left time: 158.0485s
Epoch: 11 cost time: 1.736487627029419
Epoch: 11, Steps: 128 Train Loss: 0.1784 (Forecasting Loss:0.1482 + XiCon Loss:3.0136 x Lambda(0.01)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1431
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1769198
	speed: 0.0136s/iter; left time: 153.6334s
Epoch: 12 cost time: 1.6800732612609863
Epoch: 12, Steps: 128 Train Loss: 0.1782 (Forecasting Loss:0.1480 + XiCon Loss:3.0149 x Lambda(0.01)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1438
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1678113
	speed: 0.0137s/iter; left time: 152.7659s
Epoch: 13 cost time: 1.7098913192749023
Epoch: 13, Steps: 128 Train Loss: 0.1780 (Forecasting Loss:0.1478 + XiCon Loss:3.0184 x Lambda(0.01)), Vali MSE Loss: 0.1722 Test MSE Loss: 0.1438
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.1740010
	speed: 0.0137s/iter; left time: 150.8982s
Epoch: 14 cost time: 1.7483916282653809
Epoch: 14, Steps: 128 Train Loss: 0.1782 (Forecasting Loss:0.1481 + XiCon Loss:3.0152 x Lambda(0.01)), Vali MSE Loss: 0.1721 Test MSE Loss: 0.1438
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.1802144
	speed: 0.0132s/iter; left time: 143.4642s
Epoch: 15 cost time: 1.654308557510376
Epoch: 15, Steps: 128 Train Loss: 0.1784 (Forecasting Loss:0.1482 + XiCon Loss:3.0140 x Lambda(0.01)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1437
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.1761259
	speed: 0.0138s/iter; left time: 149.2829s
Epoch: 16 cost time: 1.7393403053283691
Epoch: 16, Steps: 128 Train Loss: 0.1783 (Forecasting Loss:0.1482 + XiCon Loss:3.0146 x Lambda(0.01)), Vali MSE Loss: 0.1720 Test MSE Loss: 0.1437
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.1660611
	speed: 0.0135s/iter; left time: 143.4921s
Epoch: 17 cost time: 1.6742959022521973
Epoch: 17, Steps: 128 Train Loss: 0.1782 (Forecasting Loss:0.1480 + XiCon Loss:3.0132 x Lambda(0.01)), Vali MSE Loss: 0.1722 Test MSE Loss: 0.1437
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.07359492778778076, mae:0.20986613631248474, mape:0.16942913830280304, mspe:0.05815568193793297 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2865
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2378476
	speed: 0.0141s/iter; left time: 179.2610s
Epoch: 1 cost time: 1.7438311576843262
Epoch: 1, Steps: 128 Train Loss: 0.2741 (Forecasting Loss:0.2433 + XiCon Loss:3.0752 x Lambda(0.01)), Vali MSE Loss: 0.1875 Test MSE Loss: 0.1287
Validation loss decreased (inf --> 0.187524).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2579816
	speed: 0.0142s/iter; left time: 178.6194s
Epoch: 2 cost time: 1.7660908699035645
Epoch: 2, Steps: 128 Train Loss: 0.2615 (Forecasting Loss:0.2308 + XiCon Loss:3.0689 x Lambda(0.01)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1425
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.1934407
	speed: 0.0141s/iter; left time: 174.9701s
Epoch: 3 cost time: 1.778569221496582
Epoch: 3, Steps: 128 Train Loss: 0.2110 (Forecasting Loss:0.1807 + XiCon Loss:3.0306 x Lambda(0.01)), Vali MSE Loss: 0.1832 Test MSE Loss: 0.1606
Validation loss decreased (0.187524 --> 0.183202).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1702789
	speed: 0.0138s/iter; left time: 169.5264s
Epoch: 4 cost time: 1.7719733715057373
Epoch: 4, Steps: 128 Train Loss: 0.1789 (Forecasting Loss:0.1488 + XiCon Loss:3.0099 x Lambda(0.01)), Vali MSE Loss: 0.1891 Test MSE Loss: 0.1726
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1868320
	speed: 0.0146s/iter; left time: 177.4259s
Epoch: 5 cost time: 1.798238754272461
Epoch: 5, Steps: 128 Train Loss: 0.1667 (Forecasting Loss:0.1367 + XiCon Loss:3.0026 x Lambda(0.01)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1789
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1628314
	speed: 0.0132s/iter; left time: 158.9926s
Epoch: 6 cost time: 1.6444883346557617
Epoch: 6, Steps: 128 Train Loss: 0.1612 (Forecasting Loss:0.1311 + XiCon Loss:3.0025 x Lambda(0.01)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1809
Validation loss decreased (0.183202 --> 0.181251).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1597349
	speed: 0.0136s/iter; left time: 162.4622s
Epoch: 7 cost time: 1.7201731204986572
Epoch: 7, Steps: 128 Train Loss: 0.1585 (Forecasting Loss:0.1285 + XiCon Loss:2.9998 x Lambda(0.01)), Vali MSE Loss: 0.1819 Test MSE Loss: 0.1835
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1581273
	speed: 0.0148s/iter; left time: 174.9083s
Epoch: 8 cost time: 1.8158531188964844
Epoch: 8, Steps: 128 Train Loss: 0.1571 (Forecasting Loss:0.1272 + XiCon Loss:2.9988 x Lambda(0.01)), Vali MSE Loss: 0.1824 Test MSE Loss: 0.1847
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1497806
	speed: 0.0134s/iter; left time: 155.9467s
Epoch: 9 cost time: 1.682741641998291
Epoch: 9, Steps: 128 Train Loss: 0.1566 (Forecasting Loss:0.1266 + XiCon Loss:2.9984 x Lambda(0.01)), Vali MSE Loss: 0.1814 Test MSE Loss: 0.1845
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1545182
	speed: 0.0134s/iter; left time: 154.7329s
Epoch: 10 cost time: 1.6853070259094238
Epoch: 10, Steps: 128 Train Loss: 0.1562 (Forecasting Loss:0.1262 + XiCon Loss:2.9992 x Lambda(0.01)), Vali MSE Loss: 0.1817 Test MSE Loss: 0.1840
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1605943
	speed: 0.0133s/iter; left time: 151.5768s
Epoch: 11 cost time: 1.6869738101959229
Epoch: 11, Steps: 128 Train Loss: 0.1558 (Forecasting Loss:0.1258 + XiCon Loss:3.0005 x Lambda(0.01)), Vali MSE Loss: 0.1814 Test MSE Loss: 0.1846
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1538144
	speed: 0.0134s/iter; left time: 150.9483s
Epoch: 12 cost time: 1.6772961616516113
Epoch: 12, Steps: 128 Train Loss: 0.1559 (Forecasting Loss:0.1259 + XiCon Loss:2.9998 x Lambda(0.01)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1844
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1621665
	speed: 0.0137s/iter; left time: 153.2142s
Epoch: 13 cost time: 1.6989927291870117
Epoch: 13, Steps: 128 Train Loss: 0.1558 (Forecasting Loss:0.1258 + XiCon Loss:3.0002 x Lambda(0.01)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1846
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.1578690
	speed: 0.0138s/iter; left time: 152.1630s
Epoch: 14 cost time: 1.74265456199646
Epoch: 14, Steps: 128 Train Loss: 0.1557 (Forecasting Loss:0.1257 + XiCon Loss:2.9999 x Lambda(0.01)), Vali MSE Loss: 0.1817 Test MSE Loss: 0.1846
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.1623599
	speed: 0.0142s/iter; left time: 155.1523s
Epoch: 15 cost time: 1.7868680953979492
Epoch: 15, Steps: 128 Train Loss: 0.1559 (Forecasting Loss:0.1259 + XiCon Loss:3.0001 x Lambda(0.01)), Vali MSE Loss: 0.1816 Test MSE Loss: 0.1846
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.1529769
	speed: 0.0141s/iter; left time: 152.2110s
Epoch: 16 cost time: 1.7595045566558838
Epoch: 16, Steps: 128 Train Loss: 0.1557 (Forecasting Loss:0.1257 + XiCon Loss:2.9988 x Lambda(0.01)), Vali MSE Loss: 0.1814 Test MSE Loss: 0.1847
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.10804874449968338, mae:0.2536519765853882, mape:0.2125059962272644, mspe:0.1021769568324089 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3038
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2544281
	speed: 0.0139s/iter; left time: 176.3890s
Epoch: 1 cost time: 1.7311298847198486
Epoch: 1, Steps: 128 Train Loss: 0.2757 (Forecasting Loss:0.2450 + XiCon Loss:3.0777 x Lambda(0.01)), Vali MSE Loss: 0.1730 Test MSE Loss: 0.1190
Validation loss decreased (inf --> 0.173019).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2683359
	speed: 0.0137s/iter; left time: 172.3684s
Epoch: 2 cost time: 1.7119815349578857
Epoch: 2, Steps: 128 Train Loss: 0.2658 (Forecasting Loss:0.2355 + XiCon Loss:3.0303 x Lambda(0.01)), Vali MSE Loss: 0.1786 Test MSE Loss: 0.1420
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2206106
	speed: 0.0137s/iter; left time: 171.1000s
Epoch: 3 cost time: 1.7226531505584717
Epoch: 3, Steps: 128 Train Loss: 0.2278 (Forecasting Loss:0.1980 + XiCon Loss:2.9750 x Lambda(0.01)), Vali MSE Loss: 0.1735 Test MSE Loss: 0.1489
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2109995
	speed: 0.0133s/iter; left time: 164.4071s
Epoch: 4 cost time: 1.6562378406524658
Epoch: 4, Steps: 128 Train Loss: 0.1982 (Forecasting Loss:0.1688 + XiCon Loss:2.9457 x Lambda(0.01)), Vali MSE Loss: 0.1829 Test MSE Loss: 0.1647
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1750295
	speed: 0.0136s/iter; left time: 165.6015s
Epoch: 5 cost time: 1.693284273147583
Epoch: 5, Steps: 128 Train Loss: 0.1858 (Forecasting Loss:0.1565 + XiCon Loss:2.9304 x Lambda(0.01)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1676
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1881622
	speed: 0.0130s/iter; left time: 156.4597s
Epoch: 6 cost time: 1.6316766738891602
Epoch: 6, Steps: 128 Train Loss: 0.1804 (Forecasting Loss:0.1511 + XiCon Loss:2.9260 x Lambda(0.01)), Vali MSE Loss: 0.1901 Test MSE Loss: 0.1697
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1755508
	speed: 0.0133s/iter; left time: 159.0803s
Epoch: 7 cost time: 1.6528325080871582
Epoch: 7, Steps: 128 Train Loss: 0.1777 (Forecasting Loss:0.1485 + XiCon Loss:2.9256 x Lambda(0.01)), Vali MSE Loss: 0.1920 Test MSE Loss: 0.1697
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1868688
	speed: 0.0139s/iter; left time: 164.4545s
Epoch: 8 cost time: 1.741058588027954
Epoch: 8, Steps: 128 Train Loss: 0.1767 (Forecasting Loss:0.1475 + XiCon Loss:2.9236 x Lambda(0.01)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1700
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1835977
	speed: 0.0143s/iter; left time: 167.2731s
Epoch: 9 cost time: 1.7973079681396484
Epoch: 9, Steps: 128 Train Loss: 0.1759 (Forecasting Loss:0.1467 + XiCon Loss:2.9207 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.1714
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1757207
	speed: 0.0141s/iter; left time: 163.3754s
Epoch: 10 cost time: 1.7784483432769775
Epoch: 10, Steps: 128 Train Loss: 0.1753 (Forecasting Loss:0.1462 + XiCon Loss:2.9184 x Lambda(0.01)), Vali MSE Loss: 0.1916 Test MSE Loss: 0.1715
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1976968
	speed: 0.0143s/iter; left time: 162.7700s
Epoch: 11 cost time: 1.8023624420166016
Epoch: 11, Steps: 128 Train Loss: 0.1755 (Forecasting Loss:0.1463 + XiCon Loss:2.9209 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.1704
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05625811591744423, mae:0.1817770153284073, mape:0.144710510969162, mspe:0.039331965148448944 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3156
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2571528
	speed: 0.0134s/iter; left time: 170.5407s
Epoch: 1 cost time: 1.7337322235107422
Epoch: 1, Steps: 128 Train Loss: 0.2735 (Forecasting Loss:0.2426 + XiCon Loss:3.0960 x Lambda(0.01)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.1323
Validation loss decreased (inf --> 0.186866).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2780512
	speed: 0.0147s/iter; left time: 185.3203s
Epoch: 2 cost time: 1.8502464294433594
Epoch: 2, Steps: 128 Train Loss: 0.2772 (Forecasting Loss:0.2464 + XiCon Loss:3.0812 x Lambda(0.01)), Vali MSE Loss: 0.1783 Test MSE Loss: 0.1232
Validation loss decreased (0.186866 --> 0.178275).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2632875
	speed: 0.0137s/iter; left time: 170.3390s
Epoch: 3 cost time: 1.7033028602600098
Epoch: 3, Steps: 128 Train Loss: 0.2604 (Forecasting Loss:0.2303 + XiCon Loss:3.0136 x Lambda(0.01)), Vali MSE Loss: 0.1781 Test MSE Loss: 0.1204
Validation loss decreased (0.178275 --> 0.178129).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2881390
	speed: 0.0132s/iter; left time: 162.3320s
Epoch: 4 cost time: 1.7131977081298828
Epoch: 4, Steps: 128 Train Loss: 0.2531 (Forecasting Loss:0.2234 + XiCon Loss:2.9736 x Lambda(0.01)), Vali MSE Loss: 0.1674 Test MSE Loss: 0.1149
Validation loss decreased (0.178129 --> 0.167435).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.2585638
	speed: 0.0136s/iter; left time: 165.9816s
Epoch: 5 cost time: 1.7034962177276611
Epoch: 5, Steps: 128 Train Loss: 0.2470 (Forecasting Loss:0.2178 + XiCon Loss:2.9265 x Lambda(0.01)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1168
Validation loss decreased (0.167435 --> 0.164676).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.2488866
	speed: 0.0139s/iter; left time: 167.3434s
Epoch: 6 cost time: 1.7261755466461182
Epoch: 6, Steps: 128 Train Loss: 0.2448 (Forecasting Loss:0.2157 + XiCon Loss:2.9112 x Lambda(0.01)), Vali MSE Loss: 0.1628 Test MSE Loss: 0.1162
Validation loss decreased (0.164676 --> 0.162787).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.2503770
	speed: 0.0144s/iter; left time: 171.3581s
Epoch: 7 cost time: 1.7806026935577393
Epoch: 7, Steps: 128 Train Loss: 0.2438 (Forecasting Loss:0.2148 + XiCon Loss:2.9025 x Lambda(0.01)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.2475320
	speed: 0.0132s/iter; left time: 156.1431s
Epoch: 8 cost time: 1.6627440452575684
Epoch: 8, Steps: 128 Train Loss: 0.2429 (Forecasting Loss:0.2139 + XiCon Loss:2.8956 x Lambda(0.01)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1161
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.2214985
	speed: 0.0136s/iter; left time: 158.7172s
Epoch: 9 cost time: 1.7013609409332275
Epoch: 9, Steps: 128 Train Loss: 0.2427 (Forecasting Loss:0.2137 + XiCon Loss:2.8953 x Lambda(0.01)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1162
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.2380693
	speed: 0.0132s/iter; left time: 151.9489s
Epoch: 10 cost time: 1.6889116764068604
Epoch: 10, Steps: 128 Train Loss: 0.2424 (Forecasting Loss:0.2135 + XiCon Loss:2.8911 x Lambda(0.01)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1162
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.2805955
	speed: 0.0134s/iter; left time: 152.7557s
Epoch: 11 cost time: 1.663414716720581
Epoch: 11, Steps: 128 Train Loss: 0.2423 (Forecasting Loss:0.2133 + XiCon Loss:2.8928 x Lambda(0.01)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1162
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.2323652
	speed: 0.0137s/iter; left time: 154.4298s
Epoch: 12 cost time: 1.7090027332305908
Epoch: 12, Steps: 128 Train Loss: 0.2423 (Forecasting Loss:0.2134 + XiCon Loss:2.8897 x Lambda(0.01)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1162
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.2339768
	speed: 0.0136s/iter; left time: 152.1641s
Epoch: 13 cost time: 1.723236083984375
Epoch: 13, Steps: 128 Train Loss: 0.2421 (Forecasting Loss:0.2132 + XiCon Loss:2.8909 x Lambda(0.01)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1162
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.2543465
	speed: 0.0150s/iter; left time: 165.4752s
Epoch: 14 cost time: 1.8494689464569092
Epoch: 14, Steps: 128 Train Loss: 0.2422 (Forecasting Loss:0.2133 + XiCon Loss:2.8897 x Lambda(0.01)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1162
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.2637371
	speed: 0.0139s/iter; left time: 151.9734s
Epoch: 15 cost time: 1.721400499343872
Epoch: 15, Steps: 128 Train Loss: 0.2422 (Forecasting Loss:0.2133 + XiCon Loss:2.8892 x Lambda(0.01)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1162
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.2313221
	speed: 0.0136s/iter; left time: 146.6297s
Epoch: 16 cost time: 1.695307731628418
Epoch: 16, Steps: 128 Train Loss: 0.2421 (Forecasting Loss:0.2132 + XiCon Loss:2.8917 x Lambda(0.01)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1162
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05469450727105141, mae:0.17777717113494873, mape:0.1407797932624817, mspe:0.036965541541576385 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0750+-0.02715, MAE:0.2081+-0.03815, MAPE:0.1681+-0.03563, MSPE:0.0591+-0.03248, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3698
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.2612113
	speed: 0.0171s/iter; left time: 214.0592s
Epoch: 1 cost time: 2.058267116546631
Epoch: 1, Steps: 126 Train Loss: 0.3072 (Forecasting Loss:0.2764 + XiCon Loss:3.0780 x Lambda(0.01)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1435
Validation loss decreased (inf --> 0.196830).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2722835
	speed: 0.0147s/iter; left time: 181.5682s
Epoch: 2 cost time: 1.8313136100769043
Epoch: 2, Steps: 126 Train Loss: 0.2766 (Forecasting Loss:0.2464 + XiCon Loss:3.0180 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1586
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2241748
	speed: 0.0152s/iter; left time: 186.4668s
Epoch: 3 cost time: 1.8749656677246094
Epoch: 3, Steps: 126 Train Loss: 0.2324 (Forecasting Loss:0.2028 + XiCon Loss:2.9613 x Lambda(0.01)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.1641
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2063504
	speed: 0.0159s/iter; left time: 192.9311s
Epoch: 4 cost time: 1.968909502029419
Epoch: 4, Steps: 126 Train Loss: 0.2162 (Forecasting Loss:0.1867 + XiCon Loss:2.9553 x Lambda(0.01)), Vali MSE Loss: 0.2261 Test MSE Loss: 0.1650
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1963623
	speed: 0.0154s/iter; left time: 184.8360s
Epoch: 5 cost time: 1.9339804649353027
Epoch: 5, Steps: 126 Train Loss: 0.2112 (Forecasting Loss:0.1816 + XiCon Loss:2.9566 x Lambda(0.01)), Vali MSE Loss: 0.2217 Test MSE Loss: 0.1679
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1875184
	speed: 0.0156s/iter; left time: 185.2169s
Epoch: 6 cost time: 1.9343891143798828
Epoch: 6, Steps: 126 Train Loss: 0.2089 (Forecasting Loss:0.1794 + XiCon Loss:2.9545 x Lambda(0.01)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.1684
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2021306
	speed: 0.0160s/iter; left time: 187.5523s
Epoch: 7 cost time: 1.958179235458374
Epoch: 7, Steps: 126 Train Loss: 0.2076 (Forecasting Loss:0.1781 + XiCon Loss:2.9539 x Lambda(0.01)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.1688
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2217873
	speed: 0.0159s/iter; left time: 184.6727s
Epoch: 8 cost time: 1.9591164588928223
Epoch: 8, Steps: 126 Train Loss: 0.2071 (Forecasting Loss:0.1775 + XiCon Loss:2.9524 x Lambda(0.01)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.1683
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2023519
	speed: 0.0164s/iter; left time: 188.1365s
Epoch: 9 cost time: 2.0171549320220947
Epoch: 9, Steps: 126 Train Loss: 0.2068 (Forecasting Loss:0.1772 + XiCon Loss:2.9560 x Lambda(0.01)), Vali MSE Loss: 0.2282 Test MSE Loss: 0.1683
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2138816
	speed: 0.0160s/iter; left time: 182.1661s
Epoch: 10 cost time: 1.9901273250579834
Epoch: 10, Steps: 126 Train Loss: 0.2066 (Forecasting Loss:0.1770 + XiCon Loss:2.9555 x Lambda(0.01)), Vali MSE Loss: 0.2288 Test MSE Loss: 0.1684
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2012228
	speed: 0.0157s/iter; left time: 176.4619s
Epoch: 11 cost time: 1.9353506565093994
Epoch: 11, Steps: 126 Train Loss: 0.2066 (Forecasting Loss:0.1771 + XiCon Loss:2.9592 x Lambda(0.01)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.1687
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07454586029052734, mae:0.2124466449022293, mape:0.1624477356672287, mspe:0.04513414204120636 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3751
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3129810
	speed: 0.0145s/iter; left time: 180.9304s
Epoch: 1 cost time: 1.7808973789215088
Epoch: 1, Steps: 126 Train Loss: 0.3059 (Forecasting Loss:0.2752 + XiCon Loss:3.0765 x Lambda(0.01)), Vali MSE Loss: 0.1970 Test MSE Loss: 0.1450
Validation loss decreased (inf --> 0.196999).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2566237
	speed: 0.0148s/iter; left time: 183.6643s
Epoch: 2 cost time: 1.8458244800567627
Epoch: 2, Steps: 126 Train Loss: 0.2785 (Forecasting Loss:0.2482 + XiCon Loss:3.0267 x Lambda(0.01)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1536
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2250499
	speed: 0.0164s/iter; left time: 200.4431s
Epoch: 3 cost time: 2.008894681930542
Epoch: 3, Steps: 126 Train Loss: 0.2395 (Forecasting Loss:0.2096 + XiCon Loss:2.9938 x Lambda(0.01)), Vali MSE Loss: 0.2310 Test MSE Loss: 0.1730
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2141913
	speed: 0.0153s/iter; left time: 185.2176s
Epoch: 4 cost time: 1.9231350421905518
Epoch: 4, Steps: 126 Train Loss: 0.2212 (Forecasting Loss:0.1911 + XiCon Loss:3.0106 x Lambda(0.01)), Vali MSE Loss: 0.2331 Test MSE Loss: 0.1826
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2221131
	speed: 0.0163s/iter; left time: 195.1667s
Epoch: 5 cost time: 2.0055108070373535
Epoch: 5, Steps: 126 Train Loss: 0.2139 (Forecasting Loss:0.1838 + XiCon Loss:3.0142 x Lambda(0.01)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.1857
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2083570
	speed: 0.0155s/iter; left time: 184.0098s
Epoch: 6 cost time: 1.9589436054229736
Epoch: 6, Steps: 126 Train Loss: 0.2112 (Forecasting Loss:0.1810 + XiCon Loss:3.0189 x Lambda(0.01)), Vali MSE Loss: 0.2422 Test MSE Loss: 0.1906
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2178218
	speed: 0.0155s/iter; left time: 182.1049s
Epoch: 7 cost time: 1.9156296253204346
Epoch: 7, Steps: 126 Train Loss: 0.2100 (Forecasting Loss:0.1798 + XiCon Loss:3.0158 x Lambda(0.01)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1907
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2019614
	speed: 0.0160s/iter; left time: 185.8717s
Epoch: 8 cost time: 1.9838378429412842
Epoch: 8, Steps: 126 Train Loss: 0.2089 (Forecasting Loss:0.1787 + XiCon Loss:3.0220 x Lambda(0.01)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1906
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2181061
	speed: 0.0157s/iter; left time: 180.8336s
Epoch: 9 cost time: 1.9533073902130127
Epoch: 9, Steps: 126 Train Loss: 0.2090 (Forecasting Loss:0.1788 + XiCon Loss:3.0208 x Lambda(0.01)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1906
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1989781
	speed: 0.0157s/iter; left time: 178.6547s
Epoch: 10 cost time: 1.9566221237182617
Epoch: 10, Steps: 126 Train Loss: 0.2088 (Forecasting Loss:0.1786 + XiCon Loss:3.0221 x Lambda(0.01)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1907
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2031803
	speed: 0.0159s/iter; left time: 178.5806s
Epoch: 11 cost time: 1.9410018920898438
Epoch: 11, Steps: 126 Train Loss: 0.2087 (Forecasting Loss:0.1785 + XiCon Loss:3.0201 x Lambda(0.01)), Vali MSE Loss: 0.2464 Test MSE Loss: 0.1907
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07569046318531036, mae:0.21436594426631927, mape:0.16411550343036652, mspe:0.04633036628365517 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2844
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3008625
	speed: 0.0147s/iter; left time: 184.0118s
Epoch: 1 cost time: 1.8410019874572754
Epoch: 1, Steps: 126 Train Loss: 0.3068 (Forecasting Loss:0.2761 + XiCon Loss:3.0736 x Lambda(0.01)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1413
Validation loss decreased (inf --> 0.196600).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2750365
	speed: 0.0141s/iter; left time: 174.1680s
Epoch: 2 cost time: 1.7636957168579102
Epoch: 2, Steps: 126 Train Loss: 0.2842 (Forecasting Loss:0.2539 + XiCon Loss:3.0214 x Lambda(0.01)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1373
Validation loss decreased (0.196600 --> 0.189510).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2497572
	speed: 0.0149s/iter; left time: 182.3378s
Epoch: 3 cost time: 1.8763444423675537
Epoch: 3, Steps: 126 Train Loss: 0.2496 (Forecasting Loss:0.2198 + XiCon Loss:2.9802 x Lambda(0.01)), Vali MSE Loss: 0.1801 Test MSE Loss: 0.1555
Validation loss decreased (0.189510 --> 0.180144).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2365319
	speed: 0.0152s/iter; left time: 184.2806s
Epoch: 4 cost time: 1.8666810989379883
Epoch: 4, Steps: 126 Train Loss: 0.2284 (Forecasting Loss:0.1987 + XiCon Loss:2.9708 x Lambda(0.01)), Vali MSE Loss: 0.1821 Test MSE Loss: 0.1503
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2116835
	speed: 0.0151s/iter; left time: 181.3585s
Epoch: 5 cost time: 1.8968842029571533
Epoch: 5, Steps: 126 Train Loss: 0.2196 (Forecasting Loss:0.1898 + XiCon Loss:2.9750 x Lambda(0.01)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1542
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2122583
	speed: 0.0160s/iter; left time: 189.8836s
Epoch: 6 cost time: 1.9804108142852783
Epoch: 6, Steps: 126 Train Loss: 0.2166 (Forecasting Loss:0.1868 + XiCon Loss:2.9755 x Lambda(0.01)), Vali MSE Loss: 0.1901 Test MSE Loss: 0.1537
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2109371
	speed: 0.0150s/iter; left time: 176.7586s
Epoch: 7 cost time: 1.863339900970459
Epoch: 7, Steps: 126 Train Loss: 0.2153 (Forecasting Loss:0.1855 + XiCon Loss:2.9770 x Lambda(0.01)), Vali MSE Loss: 0.1891 Test MSE Loss: 0.1535
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2046965
	speed: 0.0157s/iter; left time: 182.0247s
Epoch: 8 cost time: 1.9437901973724365
Epoch: 8, Steps: 126 Train Loss: 0.2145 (Forecasting Loss:0.1847 + XiCon Loss:2.9815 x Lambda(0.01)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.1544
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2325398
	speed: 0.0155s/iter; left time: 177.7863s
Epoch: 9 cost time: 1.9196128845214844
Epoch: 9, Steps: 126 Train Loss: 0.2139 (Forecasting Loss:0.1840 + XiCon Loss:2.9847 x Lambda(0.01)), Vali MSE Loss: 0.1887 Test MSE Loss: 0.1548
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2231232
	speed: 0.0167s/iter; left time: 189.5624s
Epoch: 10 cost time: 2.058354139328003
Epoch: 10, Steps: 126 Train Loss: 0.2136 (Forecasting Loss:0.1838 + XiCon Loss:2.9795 x Lambda(0.01)), Vali MSE Loss: 0.1878 Test MSE Loss: 0.1550
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2112544
	speed: 0.0163s/iter; left time: 183.4153s
Epoch: 11 cost time: 2.05721378326416
Epoch: 11, Steps: 126 Train Loss: 0.2136 (Forecasting Loss:0.1838 + XiCon Loss:2.9814 x Lambda(0.01)), Vali MSE Loss: 0.1882 Test MSE Loss: 0.1546
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1977036
	speed: 0.0155s/iter; left time: 172.7148s
Epoch: 12 cost time: 1.9187781810760498
Epoch: 12, Steps: 126 Train Loss: 0.2133 (Forecasting Loss:0.1835 + XiCon Loss:2.9794 x Lambda(0.01)), Vali MSE Loss: 0.1883 Test MSE Loss: 0.1547
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2070927
	speed: 0.0162s/iter; left time: 177.9121s
Epoch: 13 cost time: 2.0064070224761963
Epoch: 13, Steps: 126 Train Loss: 0.2136 (Forecasting Loss:0.1838 + XiCon Loss:2.9803 x Lambda(0.01)), Vali MSE Loss: 0.1885 Test MSE Loss: 0.1545
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.08375126868486404, mae:0.2273322492837906, mape:0.18688085675239563, mspe:0.07615682482719421 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2829
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3001197
	speed: 0.0149s/iter; left time: 186.1117s
Epoch: 1 cost time: 1.8367598056793213
Epoch: 1, Steps: 126 Train Loss: 0.3048 (Forecasting Loss:0.2742 + XiCon Loss:3.0597 x Lambda(0.01)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1438
Validation loss decreased (inf --> 0.195989).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2489255
	speed: 0.0144s/iter; left time: 178.2052s
Epoch: 2 cost time: 1.800506830215454
Epoch: 2, Steps: 126 Train Loss: 0.2860 (Forecasting Loss:0.2557 + XiCon Loss:3.0287 x Lambda(0.01)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1401
Validation loss decreased (0.195989 --> 0.194241).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2611298
	speed: 0.0171s/iter; left time: 209.5045s
Epoch: 3 cost time: 2.08367919921875
Epoch: 3, Steps: 126 Train Loss: 0.2530 (Forecasting Loss:0.2228 + XiCon Loss:3.0255 x Lambda(0.01)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1476
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2204925
	speed: 0.0161s/iter; left time: 194.8238s
Epoch: 4 cost time: 2.013878583908081
Epoch: 4, Steps: 126 Train Loss: 0.2316 (Forecasting Loss:0.2012 + XiCon Loss:3.0413 x Lambda(0.01)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1653
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2102427
	speed: 0.0168s/iter; left time: 201.4924s
Epoch: 5 cost time: 2.102018117904663
Epoch: 5, Steps: 126 Train Loss: 0.2225 (Forecasting Loss:0.1920 + XiCon Loss:3.0504 x Lambda(0.01)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1691
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2143347
	speed: 0.0161s/iter; left time: 191.5571s
Epoch: 6 cost time: 1.9979314804077148
Epoch: 6, Steps: 126 Train Loss: 0.2184 (Forecasting Loss:0.1879 + XiCon Loss:3.0515 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1701
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2178308
	speed: 0.0161s/iter; left time: 189.0714s
Epoch: 7 cost time: 2.0118234157562256
Epoch: 7, Steps: 126 Train Loss: 0.2166 (Forecasting Loss:0.1861 + XiCon Loss:3.0443 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1707
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2128980
	speed: 0.0162s/iter; left time: 188.3278s
Epoch: 8 cost time: 2.0450899600982666
Epoch: 8, Steps: 126 Train Loss: 0.2155 (Forecasting Loss:0.1850 + XiCon Loss:3.0546 x Lambda(0.01)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1720
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1973481
	speed: 0.0158s/iter; left time: 181.5260s
Epoch: 9 cost time: 1.9553368091583252
Epoch: 9, Steps: 126 Train Loss: 0.2152 (Forecasting Loss:0.1847 + XiCon Loss:3.0563 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1716
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2123521
	speed: 0.0160s/iter; left time: 181.8770s
Epoch: 10 cost time: 1.9992680549621582
Epoch: 10, Steps: 126 Train Loss: 0.2149 (Forecasting Loss:0.1843 + XiCon Loss:3.0530 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1719
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2040944
	speed: 0.0166s/iter; left time: 186.8146s
Epoch: 11 cost time: 2.059537172317505
Epoch: 11, Steps: 126 Train Loss: 0.2149 (Forecasting Loss:0.1842 + XiCon Loss:3.0656 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1719
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2199966
	speed: 0.0161s/iter; left time: 178.7447s
Epoch: 12 cost time: 1.9853835105895996
Epoch: 12, Steps: 126 Train Loss: 0.2147 (Forecasting Loss:0.1842 + XiCon Loss:3.0503 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1718
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07207190990447998, mae:0.20808926224708557, mape:0.16487227380275726, mspe:0.05515929311513901 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3721
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3032263
	speed: 0.0148s/iter; left time: 184.9090s
Epoch: 1 cost time: 1.8328027725219727
Epoch: 1, Steps: 126 Train Loss: 0.3078 (Forecasting Loss:0.2773 + XiCon Loss:3.0538 x Lambda(0.01)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1440
Validation loss decreased (inf --> 0.195994).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2884165
	speed: 0.0155s/iter; left time: 191.6402s
Epoch: 2 cost time: 1.9188921451568604
Epoch: 2, Steps: 126 Train Loss: 0.2816 (Forecasting Loss:0.2516 + XiCon Loss:3.0024 x Lambda(0.01)), Vali MSE Loss: 0.1985 Test MSE Loss: 0.1411
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2573554
	speed: 0.0157s/iter; left time: 192.9095s
Epoch: 3 cost time: 1.9264729022979736
Epoch: 3, Steps: 126 Train Loss: 0.2498 (Forecasting Loss:0.2197 + XiCon Loss:3.0089 x Lambda(0.01)), Vali MSE Loss: 0.1832 Test MSE Loss: 0.1419
Validation loss decreased (0.195994 --> 0.183183).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2182608
	speed: 0.0158s/iter; left time: 191.7788s
Epoch: 4 cost time: 1.9671874046325684
Epoch: 4, Steps: 126 Train Loss: 0.2292 (Forecasting Loss:0.1988 + XiCon Loss:3.0335 x Lambda(0.01)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.1465
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2233456
	speed: 0.0154s/iter; left time: 184.8102s
Epoch: 5 cost time: 1.9097115993499756
Epoch: 5, Steps: 126 Train Loss: 0.2201 (Forecasting Loss:0.1898 + XiCon Loss:3.0348 x Lambda(0.01)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1453
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2177892
	speed: 0.0158s/iter; left time: 187.0665s
Epoch: 6 cost time: 1.930656909942627
Epoch: 6, Steps: 126 Train Loss: 0.2158 (Forecasting Loss:0.1854 + XiCon Loss:3.0396 x Lambda(0.01)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1439
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2123639
	speed: 0.0148s/iter; left time: 173.6997s
Epoch: 7 cost time: 1.8458173274993896
Epoch: 7, Steps: 126 Train Loss: 0.2140 (Forecasting Loss:0.1836 + XiCon Loss:3.0414 x Lambda(0.01)), Vali MSE Loss: 0.1850 Test MSE Loss: 0.1447
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1858993
	speed: 0.0158s/iter; left time: 183.5434s
Epoch: 8 cost time: 1.9757814407348633
Epoch: 8, Steps: 126 Train Loss: 0.2134 (Forecasting Loss:0.1830 + XiCon Loss:3.0396 x Lambda(0.01)), Vali MSE Loss: 0.1856 Test MSE Loss: 0.1444
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2089602
	speed: 0.0153s/iter; left time: 175.7884s
Epoch: 9 cost time: 1.870561122894287
Epoch: 9, Steps: 126 Train Loss: 0.2122 (Forecasting Loss:0.1819 + XiCon Loss:3.0337 x Lambda(0.01)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.1443
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2235413
	speed: 0.0154s/iter; left time: 174.9061s
Epoch: 10 cost time: 1.9373266696929932
Epoch: 10, Steps: 126 Train Loss: 0.2123 (Forecasting Loss:0.1820 + XiCon Loss:3.0386 x Lambda(0.01)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1448
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2211897
	speed: 0.0155s/iter; left time: 173.6845s
Epoch: 11 cost time: 1.9054555892944336
Epoch: 11, Steps: 126 Train Loss: 0.2119 (Forecasting Loss:0.1815 + XiCon Loss:3.0377 x Lambda(0.01)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1446
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2026309
	speed: 0.0152s/iter; left time: 168.4671s
Epoch: 12 cost time: 1.8569536209106445
Epoch: 12, Steps: 126 Train Loss: 0.2120 (Forecasting Loss:0.1816 + XiCon Loss:3.0386 x Lambda(0.01)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1445
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2241256
	speed: 0.0148s/iter; left time: 162.2706s
Epoch: 13 cost time: 1.8491225242614746
Epoch: 13, Steps: 126 Train Loss: 0.2119 (Forecasting Loss:0.1816 + XiCon Loss:3.0340 x Lambda(0.01)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1446
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.0722057968378067, mae:0.211614727973938, mape:0.1643235832452774, mspe:0.049160026013851166 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0757+-0.00594, MAE:0.2148+-0.00917, MAPE:0.1685+-0.01279, MSPE:0.0544+-0.01586, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4452
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3083541
	speed: 0.0234s/iter; left time: 288.1077s
Epoch: 1 cost time: 2.7865147590637207
Epoch: 1, Steps: 124 Train Loss: 0.3225 (Forecasting Loss:0.2918 + XiCon Loss:3.0649 x Lambda(0.01)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1576
Validation loss decreased (inf --> 0.216261).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2889294
	speed: 0.0197s/iter; left time: 239.3844s
Epoch: 2 cost time: 2.417084217071533
Epoch: 2, Steps: 124 Train Loss: 0.3002 (Forecasting Loss:0.2699 + XiCon Loss:3.0323 x Lambda(0.01)), Vali MSE Loss: 0.1945 Test MSE Loss: 0.1707
Validation loss decreased (0.216261 --> 0.194507).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2597558
	speed: 0.0193s/iter; left time: 233.1514s
Epoch: 3 cost time: 2.353374719619751
Epoch: 3, Steps: 124 Train Loss: 0.2739 (Forecasting Loss:0.2438 + XiCon Loss:3.0065 x Lambda(0.01)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1604
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2558230
	speed: 0.0198s/iter; left time: 236.2182s
Epoch: 4 cost time: 2.4101719856262207
Epoch: 4, Steps: 124 Train Loss: 0.2567 (Forecasting Loss:0.2268 + XiCon Loss:2.9926 x Lambda(0.01)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1553
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2404624
	speed: 0.0198s/iter; left time: 233.7042s
Epoch: 5 cost time: 2.4356675148010254
Epoch: 5, Steps: 124 Train Loss: 0.2462 (Forecasting Loss:0.2163 + XiCon Loss:2.9906 x Lambda(0.01)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1542
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2392978
	speed: 0.0201s/iter; left time: 234.3082s
Epoch: 6 cost time: 2.441926956176758
Epoch: 6, Steps: 124 Train Loss: 0.2411 (Forecasting Loss:0.2113 + XiCon Loss:2.9884 x Lambda(0.01)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1511
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2251433
	speed: 0.0193s/iter; left time: 223.0132s
Epoch: 7 cost time: 2.351902961730957
Epoch: 7, Steps: 124 Train Loss: 0.2389 (Forecasting Loss:0.2090 + XiCon Loss:2.9883 x Lambda(0.01)), Vali MSE Loss: 0.2070 Test MSE Loss: 0.1539
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2387838
	speed: 0.0192s/iter; left time: 219.3613s
Epoch: 8 cost time: 2.3901171684265137
Epoch: 8, Steps: 124 Train Loss: 0.2379 (Forecasting Loss:0.2080 + XiCon Loss:2.9865 x Lambda(0.01)), Vali MSE Loss: 0.2118 Test MSE Loss: 0.1535
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2343907
	speed: 0.0192s/iter; left time: 216.8856s
Epoch: 9 cost time: 2.367098808288574
Epoch: 9, Steps: 124 Train Loss: 0.2379 (Forecasting Loss:0.2080 + XiCon Loss:2.9874 x Lambda(0.01)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1546
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2278375
	speed: 0.0199s/iter; left time: 222.0315s
Epoch: 10 cost time: 2.4223971366882324
Epoch: 10, Steps: 124 Train Loss: 0.2377 (Forecasting Loss:0.2079 + XiCon Loss:2.9860 x Lambda(0.01)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1533
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2253304
	speed: 0.0194s/iter; left time: 214.7629s
Epoch: 11 cost time: 2.3729207515716553
Epoch: 11, Steps: 124 Train Loss: 0.2375 (Forecasting Loss:0.2076 + XiCon Loss:2.9864 x Lambda(0.01)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1534
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2361130
	speed: 0.0198s/iter; left time: 216.7059s
Epoch: 12 cost time: 2.4415290355682373
Epoch: 12, Steps: 124 Train Loss: 0.2373 (Forecasting Loss:0.2075 + XiCon Loss:2.9843 x Lambda(0.01)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1538
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.09601138532161713, mae:0.24548643827438354, mape:0.19284377992153168, mspe:0.06889716535806656 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3743
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3394273
	speed: 0.0196s/iter; left time: 240.5922s
Epoch: 1 cost time: 2.4124996662139893
Epoch: 1, Steps: 124 Train Loss: 0.3254 (Forecasting Loss:0.2947 + XiCon Loss:3.0710 x Lambda(0.01)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1617
Validation loss decreased (inf --> 0.216549).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3258567
	speed: 0.0262s/iter; left time: 319.2398s
Epoch: 2 cost time: 3.214327573776245
Epoch: 2, Steps: 124 Train Loss: 0.2971 (Forecasting Loss:0.2667 + XiCon Loss:3.0408 x Lambda(0.01)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1511
Validation loss decreased (0.216549 --> 0.216372).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2333816
	speed: 0.0288s/iter; left time: 346.9901s
Epoch: 3 cost time: 3.514427423477173
Epoch: 3, Steps: 124 Train Loss: 0.2568 (Forecasting Loss:0.2268 + XiCon Loss:3.0014 x Lambda(0.01)), Vali MSE Loss: 0.2174 Test MSE Loss: 0.1503
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2512726
	speed: 0.0287s/iter; left time: 342.8586s
Epoch: 4 cost time: 3.504338026046753
Epoch: 4, Steps: 124 Train Loss: 0.2419 (Forecasting Loss:0.2120 + XiCon Loss:2.9888 x Lambda(0.01)), Vali MSE Loss: 0.2278 Test MSE Loss: 0.1527
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2262421
	speed: 0.0275s/iter; left time: 324.9193s
Epoch: 5 cost time: 3.4130773544311523
Epoch: 5, Steps: 124 Train Loss: 0.2364 (Forecasting Loss:0.2066 + XiCon Loss:2.9799 x Lambda(0.01)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1558
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2392009
	speed: 0.0261s/iter; left time: 305.3247s
Epoch: 6 cost time: 3.2734904289245605
Epoch: 6, Steps: 124 Train Loss: 0.2337 (Forecasting Loss:0.2040 + XiCon Loss:2.9761 x Lambda(0.01)), Vali MSE Loss: 0.2273 Test MSE Loss: 0.1554
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2111785
	speed: 0.0268s/iter; left time: 310.0878s
Epoch: 7 cost time: 3.2730917930603027
Epoch: 7, Steps: 124 Train Loss: 0.2324 (Forecasting Loss:0.2026 + XiCon Loss:2.9753 x Lambda(0.01)), Vali MSE Loss: 0.2289 Test MSE Loss: 0.1552
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2277671
	speed: 0.0268s/iter; left time: 306.2271s
Epoch: 8 cost time: 3.28170108795166
Epoch: 8, Steps: 124 Train Loss: 0.2316 (Forecasting Loss:0.2019 + XiCon Loss:2.9726 x Lambda(0.01)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1556
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2314562
	speed: 0.0263s/iter; left time: 297.7283s
Epoch: 9 cost time: 3.235424518585205
Epoch: 9, Steps: 124 Train Loss: 0.2312 (Forecasting Loss:0.2015 + XiCon Loss:2.9716 x Lambda(0.01)), Vali MSE Loss: 0.2284 Test MSE Loss: 0.1562
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2412733
	speed: 0.0264s/iter; left time: 295.3591s
Epoch: 10 cost time: 3.2416625022888184
Epoch: 10, Steps: 124 Train Loss: 0.2310 (Forecasting Loss:0.2013 + XiCon Loss:2.9732 x Lambda(0.01)), Vali MSE Loss: 0.2287 Test MSE Loss: 0.1563
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2357133
	speed: 0.0268s/iter; left time: 296.1820s
Epoch: 11 cost time: 3.2770252227783203
Epoch: 11, Steps: 124 Train Loss: 0.2309 (Forecasting Loss:0.2012 + XiCon Loss:2.9732 x Lambda(0.01)), Vali MSE Loss: 0.2292 Test MSE Loss: 0.1560
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2453497
	speed: 0.0268s/iter; left time: 292.6270s
Epoch: 12 cost time: 3.289057970046997
Epoch: 12, Steps: 124 Train Loss: 0.2309 (Forecasting Loss:0.2012 + XiCon Loss:2.9716 x Lambda(0.01)), Vali MSE Loss: 0.2291 Test MSE Loss: 0.1563
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07796289026737213, mae:0.2242709994316101, mape:0.17524316906929016, mspe:0.058677319437265396 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2876
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3030179
	speed: 0.0202s/iter; left time: 248.3948s
Epoch: 1 cost time: 2.4505372047424316
Epoch: 1, Steps: 124 Train Loss: 0.3268 (Forecasting Loss:0.2961 + XiCon Loss:3.0706 x Lambda(0.01)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.1575
Validation loss decreased (inf --> 0.214721).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2806090
	speed: 0.0198s/iter; left time: 240.9412s
Epoch: 2 cost time: 2.4103281497955322
Epoch: 2, Steps: 124 Train Loss: 0.2976 (Forecasting Loss:0.2673 + XiCon Loss:3.0288 x Lambda(0.01)), Vali MSE Loss: 0.1980 Test MSE Loss: 0.1529
Validation loss decreased (0.214721 --> 0.198001).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2494916
	speed: 0.0194s/iter; left time: 233.9419s
Epoch: 3 cost time: 2.3714101314544678
Epoch: 3, Steps: 124 Train Loss: 0.2693 (Forecasting Loss:0.2393 + XiCon Loss:3.0002 x Lambda(0.01)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1547
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2511631
	speed: 0.0195s/iter; left time: 232.6363s
Epoch: 4 cost time: 2.3923566341400146
Epoch: 4, Steps: 124 Train Loss: 0.2540 (Forecasting Loss:0.2241 + XiCon Loss:2.9965 x Lambda(0.01)), Vali MSE Loss: 0.2186 Test MSE Loss: 0.1490
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2469446
	speed: 0.0195s/iter; left time: 230.2459s
Epoch: 5 cost time: 2.396458387374878
Epoch: 5, Steps: 124 Train Loss: 0.2461 (Forecasting Loss:0.2162 + XiCon Loss:2.9964 x Lambda(0.01)), Vali MSE Loss: 0.2201 Test MSE Loss: 0.1475
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2385193
	speed: 0.0198s/iter; left time: 230.8366s
Epoch: 6 cost time: 2.4034063816070557
Epoch: 6, Steps: 124 Train Loss: 0.2425 (Forecasting Loss:0.2126 + XiCon Loss:2.9969 x Lambda(0.01)), Vali MSE Loss: 0.2197 Test MSE Loss: 0.1493
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2391217
	speed: 0.0198s/iter; left time: 229.2262s
Epoch: 7 cost time: 2.410459041595459
Epoch: 7, Steps: 124 Train Loss: 0.2400 (Forecasting Loss:0.2100 + XiCon Loss:2.9961 x Lambda(0.01)), Vali MSE Loss: 0.2202 Test MSE Loss: 0.1484
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2323666
	speed: 0.0202s/iter; left time: 230.9108s
Epoch: 8 cost time: 2.4635090827941895
Epoch: 8, Steps: 124 Train Loss: 0.2394 (Forecasting Loss:0.2094 + XiCon Loss:2.9987 x Lambda(0.01)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.1490
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2177279
	speed: 0.0199s/iter; left time: 224.8038s
Epoch: 9 cost time: 2.429546356201172
Epoch: 9, Steps: 124 Train Loss: 0.2384 (Forecasting Loss:0.2084 + XiCon Loss:2.9984 x Lambda(0.01)), Vali MSE Loss: 0.2225 Test MSE Loss: 0.1495
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2532875
	speed: 0.0200s/iter; left time: 223.3885s
Epoch: 10 cost time: 2.423396587371826
Epoch: 10, Steps: 124 Train Loss: 0.2384 (Forecasting Loss:0.2084 + XiCon Loss:2.9977 x Lambda(0.01)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1488
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2463837
	speed: 0.0196s/iter; left time: 216.9916s
Epoch: 11 cost time: 2.4240610599517822
Epoch: 11, Steps: 124 Train Loss: 0.2380 (Forecasting Loss:0.2080 + XiCon Loss:2.9995 x Lambda(0.01)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1488
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2310703
	speed: 0.0198s/iter; left time: 216.4465s
Epoch: 12 cost time: 2.4032986164093018
Epoch: 12, Steps: 124 Train Loss: 0.2383 (Forecasting Loss:0.2083 + XiCon Loss:2.9974 x Lambda(0.01)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1488
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08251718431711197, mae:0.22319328784942627, mape:0.17114531993865967, mspe:0.05210087448358536 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2831
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.2846700
	speed: 0.0201s/iter; left time: 247.1317s
Epoch: 1 cost time: 2.4466328620910645
Epoch: 1, Steps: 124 Train Loss: 0.3243 (Forecasting Loss:0.2938 + XiCon Loss:3.0524 x Lambda(0.01)), Vali MSE Loss: 0.2154 Test MSE Loss: 0.1600
Validation loss decreased (inf --> 0.215433).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3086542
	speed: 0.0240s/iter; left time: 292.6965s
Epoch: 2 cost time: 3.0039734840393066
Epoch: 2, Steps: 124 Train Loss: 0.2890 (Forecasting Loss:0.2588 + XiCon Loss:3.0188 x Lambda(0.01)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.1534
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2426677
	speed: 0.0278s/iter; left time: 335.0879s
Epoch: 3 cost time: 3.3899552822113037
Epoch: 3, Steps: 124 Train Loss: 0.2533 (Forecasting Loss:0.2233 + XiCon Loss:3.0010 x Lambda(0.01)), Vali MSE Loss: 0.2646 Test MSE Loss: 0.1613
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2286396
	speed: 0.0271s/iter; left time: 323.4522s
Epoch: 4 cost time: 3.2860422134399414
Epoch: 4, Steps: 124 Train Loss: 0.2404 (Forecasting Loss:0.2105 + XiCon Loss:2.9848 x Lambda(0.01)), Vali MSE Loss: 0.2557 Test MSE Loss: 0.1630
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2398026
	speed: 0.0265s/iter; left time: 313.2764s
Epoch: 5 cost time: 3.288478374481201
Epoch: 5, Steps: 124 Train Loss: 0.2352 (Forecasting Loss:0.2054 + XiCon Loss:2.9841 x Lambda(0.01)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1706
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2473576
	speed: 0.0257s/iter; left time: 300.5864s
Epoch: 6 cost time: 3.208345890045166
Epoch: 6, Steps: 124 Train Loss: 0.2329 (Forecasting Loss:0.2032 + XiCon Loss:2.9785 x Lambda(0.01)), Vali MSE Loss: 0.2549 Test MSE Loss: 0.1692
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2428185
	speed: 0.0262s/iter; left time: 303.3093s
Epoch: 7 cost time: 3.2089505195617676
Epoch: 7, Steps: 124 Train Loss: 0.2318 (Forecasting Loss:0.2020 + XiCon Loss:2.9847 x Lambda(0.01)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.1701
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2294880
	speed: 0.0257s/iter; left time: 294.3588s
Epoch: 8 cost time: 3.144773483276367
Epoch: 8, Steps: 124 Train Loss: 0.2314 (Forecasting Loss:0.2015 + XiCon Loss:2.9888 x Lambda(0.01)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.1691
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2282635
	speed: 0.0260s/iter; left time: 294.3414s
Epoch: 9 cost time: 3.211045265197754
Epoch: 9, Steps: 124 Train Loss: 0.2312 (Forecasting Loss:0.2013 + XiCon Loss:2.9881 x Lambda(0.01)), Vali MSE Loss: 0.2577 Test MSE Loss: 0.1688
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2264905
	speed: 0.0263s/iter; left time: 294.4785s
Epoch: 10 cost time: 3.220649242401123
Epoch: 10, Steps: 124 Train Loss: 0.2311 (Forecasting Loss:0.2012 + XiCon Loss:2.9884 x Lambda(0.01)), Vali MSE Loss: 0.2580 Test MSE Loss: 0.1687
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2289289
	speed: 0.0255s/iter; left time: 282.2320s
Epoch: 11 cost time: 3.143460750579834
Epoch: 11, Steps: 124 Train Loss: 0.2308 (Forecasting Loss:0.2009 + XiCon Loss:2.9867 x Lambda(0.01)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1692
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08606388419866562, mae:0.23384244740009308, mape:0.17542362213134766, mspe:0.05003401264548302 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3301
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3011743
	speed: 0.0196s/iter; left time: 240.6853s
Epoch: 1 cost time: 2.4247801303863525
Epoch: 1, Steps: 124 Train Loss: 0.3290 (Forecasting Loss:0.2982 + XiCon Loss:3.0747 x Lambda(0.01)), Vali MSE Loss: 0.2171 Test MSE Loss: 0.1628
Validation loss decreased (inf --> 0.217069).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2617247
	speed: 0.0234s/iter; left time: 285.0435s
Epoch: 2 cost time: 3.019388198852539
Epoch: 2, Steps: 124 Train Loss: 0.2896 (Forecasting Loss:0.2595 + XiCon Loss:3.0083 x Lambda(0.01)), Vali MSE Loss: 0.2211 Test MSE Loss: 0.1502
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2478894
	speed: 0.0290s/iter; left time: 349.1325s
Epoch: 3 cost time: 3.586052656173706
Epoch: 3, Steps: 124 Train Loss: 0.2540 (Forecasting Loss:0.2243 + XiCon Loss:2.9710 x Lambda(0.01)), Vali MSE Loss: 0.2391 Test MSE Loss: 0.1601
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2376104
	speed: 0.0302s/iter; left time: 359.8559s
Epoch: 4 cost time: 3.7225239276885986
Epoch: 4, Steps: 124 Train Loss: 0.2418 (Forecasting Loss:0.2122 + XiCon Loss:2.9559 x Lambda(0.01)), Vali MSE Loss: 0.2557 Test MSE Loss: 0.1627
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2365078
	speed: 0.0285s/iter; left time: 336.3589s
Epoch: 5 cost time: 3.5220634937286377
Epoch: 5, Steps: 124 Train Loss: 0.2368 (Forecasting Loss:0.2073 + XiCon Loss:2.9500 x Lambda(0.01)), Vali MSE Loss: 0.2605 Test MSE Loss: 0.1622
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2423626
	speed: 0.0297s/iter; left time: 346.7640s
Epoch: 6 cost time: 3.63466215133667
Epoch: 6, Steps: 124 Train Loss: 0.2346 (Forecasting Loss:0.2051 + XiCon Loss:2.9458 x Lambda(0.01)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.1650
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2410186
	speed: 0.0291s/iter; left time: 336.6925s
Epoch: 7 cost time: 3.5756595134735107
Epoch: 7, Steps: 124 Train Loss: 0.2334 (Forecasting Loss:0.2040 + XiCon Loss:2.9457 x Lambda(0.01)), Vali MSE Loss: 0.2619 Test MSE Loss: 0.1662
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2277112
	speed: 0.0290s/iter; left time: 331.7818s
Epoch: 8 cost time: 3.537883758544922
Epoch: 8, Steps: 124 Train Loss: 0.2325 (Forecasting Loss:0.2031 + XiCon Loss:2.9404 x Lambda(0.01)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.1642
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2309669
	speed: 0.0286s/iter; left time: 322.9906s
Epoch: 9 cost time: 3.5278303623199463
Epoch: 9, Steps: 124 Train Loss: 0.2323 (Forecasting Loss:0.2029 + XiCon Loss:2.9386 x Lambda(0.01)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.1648
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2149955
	speed: 0.0289s/iter; left time: 323.0245s
Epoch: 10 cost time: 3.563157320022583
Epoch: 10, Steps: 124 Train Loss: 0.2322 (Forecasting Loss:0.2028 + XiCon Loss:2.9401 x Lambda(0.01)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.1653
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2378598
	speed: 0.0286s/iter; left time: 316.1637s
Epoch: 11 cost time: 3.525214672088623
Epoch: 11, Steps: 124 Train Loss: 0.2320 (Forecasting Loss:0.2025 + XiCon Loss:2.9430 x Lambda(0.01)), Vali MSE Loss: 0.2617 Test MSE Loss: 0.1653
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08833658695220947, mae:0.2372007817029953, mape:0.1769760400056839, mspe:0.05009347200393677 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0862+-0.00838, MAE:0.2328+-0.01156, MAPE:0.1783+-0.01043, MSPE:0.0560+-0.00999, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4242
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3990442
	speed: 0.0485s/iter; left time: 567.0060s
Epoch: 1 cost time: 5.635685682296753
Epoch: 1, Steps: 118 Train Loss: 0.3912 (Forecasting Loss:0.3594 + XiCon Loss:3.1788 x Lambda(0.01)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.258894).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3047173
	speed: 0.0448s/iter; left time: 518.4889s
Epoch: 2 cost time: 5.440858602523804
Epoch: 2, Steps: 118 Train Loss: 0.3281 (Forecasting Loss:0.2965 + XiCon Loss:3.1519 x Lambda(0.01)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.1490
Validation loss decreased (0.258894 --> 0.247110).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2657661
	speed: 0.0636s/iter; left time: 729.3638s
Epoch: 3 cost time: 7.685759544372559
Epoch: 3, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2345 + XiCon Loss:3.1242 x Lambda(0.01)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.1446
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2437704
	speed: 0.0706s/iter; left time: 800.7758s
Epoch: 4 cost time: 8.285778284072876
Epoch: 4, Steps: 118 Train Loss: 0.2517 (Forecasting Loss:0.2206 + XiCon Loss:3.1043 x Lambda(0.01)), Vali MSE Loss: 0.2425 Test MSE Loss: 0.1491
Validation loss decreased (0.247110 --> 0.242460).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2390600
	speed: 0.0655s/iter; left time: 735.9044s
Epoch: 5 cost time: 7.766813516616821
Epoch: 5, Steps: 118 Train Loss: 0.2461 (Forecasting Loss:0.2151 + XiCon Loss:3.0971 x Lambda(0.01)), Vali MSE Loss: 0.2466 Test MSE Loss: 0.1449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2488020
	speed: 0.0650s/iter; left time: 722.0793s
Epoch: 6 cost time: 7.708342552185059
Epoch: 6, Steps: 118 Train Loss: 0.2438 (Forecasting Loss:0.2128 + XiCon Loss:3.0942 x Lambda(0.01)), Vali MSE Loss: 0.2470 Test MSE Loss: 0.1462
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2413498
	speed: 0.0763s/iter; left time: 838.2878s
Epoch: 7 cost time: 8.9043550491333
Epoch: 7, Steps: 118 Train Loss: 0.2425 (Forecasting Loss:0.2116 + XiCon Loss:3.0914 x Lambda(0.01)), Vali MSE Loss: 0.2460 Test MSE Loss: 0.1471
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2438847
	speed: 0.0681s/iter; left time: 740.0692s
Epoch: 8 cost time: 7.9717490673065186
Epoch: 8, Steps: 118 Train Loss: 0.2419 (Forecasting Loss:0.2110 + XiCon Loss:3.0887 x Lambda(0.01)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1463
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2338146
	speed: 0.0701s/iter; left time: 753.6144s
Epoch: 9 cost time: 8.225008249282837
Epoch: 9, Steps: 118 Train Loss: 0.2413 (Forecasting Loss:0.2104 + XiCon Loss:3.0895 x Lambda(0.01)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.1462
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2505924
	speed: 0.0701s/iter; left time: 746.2669s
Epoch: 10 cost time: 8.250122785568237
Epoch: 10, Steps: 118 Train Loss: 0.2414 (Forecasting Loss:0.2105 + XiCon Loss:3.0881 x Lambda(0.01)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.1464
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2531233
	speed: 0.0690s/iter; left time: 725.6891s
Epoch: 11 cost time: 8.110751152038574
Epoch: 11, Steps: 118 Train Loss: 0.2412 (Forecasting Loss:0.2103 + XiCon Loss:3.0893 x Lambda(0.01)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1463
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2352841
	speed: 0.0712s/iter; left time: 740.3364s
Epoch: 12 cost time: 8.346036672592163
Epoch: 12, Steps: 118 Train Loss: 0.2411 (Forecasting Loss:0.2102 + XiCon Loss:3.0875 x Lambda(0.01)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1464
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2309807
	speed: 0.0667s/iter; left time: 685.5766s
Epoch: 13 cost time: 7.849731683731079
Epoch: 13, Steps: 118 Train Loss: 0.2410 (Forecasting Loss:0.2101 + XiCon Loss:3.0887 x Lambda(0.01)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1465
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2542506
	speed: 0.0646s/iter; left time: 657.1086s
Epoch: 14 cost time: 7.607972621917725
Epoch: 14, Steps: 118 Train Loss: 0.2408 (Forecasting Loss:0.2100 + XiCon Loss:3.0876 x Lambda(0.01)), Vali MSE Loss: 0.2478 Test MSE Loss: 0.1464
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07658877223730087, mae:0.2215827852487564, mape:0.16628234088420868, mspe:0.04726908728480339 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2805
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3649905
	speed: 0.0459s/iter; left time: 537.1612s
Epoch: 1 cost time: 5.401866436004639
Epoch: 1, Steps: 118 Train Loss: 0.3892 (Forecasting Loss:0.3575 + XiCon Loss:3.1773 x Lambda(0.01)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.1675
Validation loss decreased (inf --> 0.259276).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2733090
	speed: 0.0647s/iter; left time: 749.7369s
Epoch: 2 cost time: 7.9083287715911865
Epoch: 2, Steps: 118 Train Loss: 0.3097 (Forecasting Loss:0.2785 + XiCon Loss:3.1220 x Lambda(0.01)), Vali MSE Loss: 0.3809 Test MSE Loss: 0.1452
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2465967
	speed: 0.0846s/iter; left time: 970.2601s
Epoch: 3 cost time: 9.846449136734009
Epoch: 3, Steps: 118 Train Loss: 0.2581 (Forecasting Loss:0.2272 + XiCon Loss:3.0923 x Lambda(0.01)), Vali MSE Loss: 0.3050 Test MSE Loss: 0.1437
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2495048
	speed: 0.0821s/iter; left time: 931.0419s
Epoch: 4 cost time: 9.611213207244873
Epoch: 4, Steps: 118 Train Loss: 0.2485 (Forecasting Loss:0.2177 + XiCon Loss:3.0826 x Lambda(0.01)), Vali MSE Loss: 0.3336 Test MSE Loss: 0.1428
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2481099
	speed: 0.0816s/iter; left time: 916.0352s
Epoch: 5 cost time: 9.550925970077515
Epoch: 5, Steps: 118 Train Loss: 0.2427 (Forecasting Loss:0.2120 + XiCon Loss:3.0711 x Lambda(0.01)), Vali MSE Loss: 0.3407 Test MSE Loss: 0.1441
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2533493
	speed: 0.0797s/iter; left time: 885.9272s
Epoch: 6 cost time: 9.471869707107544
Epoch: 6, Steps: 118 Train Loss: 0.2405 (Forecasting Loss:0.2098 + XiCon Loss:3.0650 x Lambda(0.01)), Vali MSE Loss: 0.3568 Test MSE Loss: 0.1443
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2398591
	speed: 0.0818s/iter; left time: 899.1155s
Epoch: 7 cost time: 9.803519487380981
Epoch: 7, Steps: 118 Train Loss: 0.2393 (Forecasting Loss:0.2087 + XiCon Loss:3.0636 x Lambda(0.01)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.1435
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2480249
	speed: 0.0824s/iter; left time: 895.6437s
Epoch: 8 cost time: 9.78768515586853
Epoch: 8, Steps: 118 Train Loss: 0.2389 (Forecasting Loss:0.2083 + XiCon Loss:3.0604 x Lambda(0.01)), Vali MSE Loss: 0.3451 Test MSE Loss: 0.1437
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2465806
	speed: 0.0777s/iter; left time: 835.5468s
Epoch: 9 cost time: 9.146303415298462
Epoch: 9, Steps: 118 Train Loss: 0.2386 (Forecasting Loss:0.2080 + XiCon Loss:3.0603 x Lambda(0.01)), Vali MSE Loss: 0.3479 Test MSE Loss: 0.1438
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2354853
	speed: 0.0786s/iter; left time: 836.7068s
Epoch: 10 cost time: 9.236731767654419
Epoch: 10, Steps: 118 Train Loss: 0.2384 (Forecasting Loss:0.2078 + XiCon Loss:3.0588 x Lambda(0.01)), Vali MSE Loss: 0.3446 Test MSE Loss: 0.1438
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2388456
	speed: 0.0789s/iter; left time: 829.6170s
Epoch: 11 cost time: 9.293078184127808
Epoch: 11, Steps: 118 Train Loss: 0.2382 (Forecasting Loss:0.2076 + XiCon Loss:3.0600 x Lambda(0.01)), Vali MSE Loss: 0.3449 Test MSE Loss: 0.1438
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0934690311551094, mae:0.2415311634540558, mape:0.17696227133274078, mspe:0.050612471997737885 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3547
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3729718
	speed: 0.0468s/iter; left time: 547.5447s
Epoch: 1 cost time: 5.481170892715454
Epoch: 1, Steps: 118 Train Loss: 0.3904 (Forecasting Loss:0.3586 + XiCon Loss:3.1773 x Lambda(0.01)), Vali MSE Loss: 0.2562 Test MSE Loss: 0.1653
Validation loss decreased (inf --> 0.256159).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2858570
	speed: 0.0709s/iter; left time: 820.7517s
Epoch: 2 cost time: 8.469361305236816
Epoch: 2, Steps: 118 Train Loss: 0.3032 (Forecasting Loss:0.2722 + XiCon Loss:3.0974 x Lambda(0.01)), Vali MSE Loss: 0.3109 Test MSE Loss: 0.1523
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2548790
	speed: 0.0752s/iter; left time: 861.8287s
Epoch: 3 cost time: 8.885104179382324
Epoch: 3, Steps: 118 Train Loss: 0.2631 (Forecasting Loss:0.2323 + XiCon Loss:3.0842 x Lambda(0.01)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.1474
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2543368
	speed: 0.0872s/iter; left time: 989.0289s
Epoch: 4 cost time: 10.26001501083374
Epoch: 4, Steps: 118 Train Loss: 0.2509 (Forecasting Loss:0.2200 + XiCon Loss:3.0929 x Lambda(0.01)), Vali MSE Loss: 0.3073 Test MSE Loss: 0.1470
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2457780
	speed: 0.0742s/iter; left time: 832.8309s
Epoch: 5 cost time: 8.870718479156494
Epoch: 5, Steps: 118 Train Loss: 0.2456 (Forecasting Loss:0.2146 + XiCon Loss:3.1046 x Lambda(0.01)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.1472
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2530383
	speed: 0.0788s/iter; left time: 875.3045s
Epoch: 6 cost time: 9.34543228149414
Epoch: 6, Steps: 118 Train Loss: 0.2436 (Forecasting Loss:0.2125 + XiCon Loss:3.1131 x Lambda(0.01)), Vali MSE Loss: 0.3036 Test MSE Loss: 0.1470
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2390608
	speed: 0.0804s/iter; left time: 884.1520s
Epoch: 7 cost time: 9.61172890663147
Epoch: 7, Steps: 118 Train Loss: 0.2422 (Forecasting Loss:0.2111 + XiCon Loss:3.1125 x Lambda(0.01)), Vali MSE Loss: 0.2999 Test MSE Loss: 0.1464
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2430203
	speed: 0.0781s/iter; left time: 849.5328s
Epoch: 8 cost time: 9.131473064422607
Epoch: 8, Steps: 118 Train Loss: 0.2417 (Forecasting Loss:0.2105 + XiCon Loss:3.1154 x Lambda(0.01)), Vali MSE Loss: 0.3041 Test MSE Loss: 0.1459
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2392449
	speed: 0.0752s/iter; left time: 809.1000s
Epoch: 9 cost time: 8.911067724227905
Epoch: 9, Steps: 118 Train Loss: 0.2413 (Forecasting Loss:0.2102 + XiCon Loss:3.1175 x Lambda(0.01)), Vali MSE Loss: 0.3026 Test MSE Loss: 0.1460
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2586934
	speed: 0.0813s/iter; left time: 865.2655s
Epoch: 10 cost time: 9.526071548461914
Epoch: 10, Steps: 118 Train Loss: 0.2410 (Forecasting Loss:0.2099 + XiCon Loss:3.1167 x Lambda(0.01)), Vali MSE Loss: 0.3031 Test MSE Loss: 0.1458
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2456556
	speed: 0.0776s/iter; left time: 816.3665s
Epoch: 11 cost time: 9.300908088684082
Epoch: 11, Steps: 118 Train Loss: 0.2412 (Forecasting Loss:0.2100 + XiCon Loss:3.1207 x Lambda(0.01)), Vali MSE Loss: 0.3037 Test MSE Loss: 0.1458
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.09144386649131775, mae:0.23908467590808868, mape:0.1756574809551239, mspe:0.05009268969297409 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3513
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3525584
	speed: 0.0479s/iter; left time: 560.9939s
Epoch: 1 cost time: 5.579149961471558
Epoch: 1, Steps: 118 Train Loss: 0.3838 (Forecasting Loss:0.3520 + XiCon Loss:3.1744 x Lambda(0.01)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1589
Validation loss decreased (inf --> 0.255543).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2919568
	speed: 0.0489s/iter; left time: 566.6589s
Epoch: 2 cost time: 5.844434976577759
Epoch: 2, Steps: 118 Train Loss: 0.3455 (Forecasting Loss:0.3141 + XiCon Loss:3.1394 x Lambda(0.01)), Vali MSE Loss: 0.2342 Test MSE Loss: 0.1495
Validation loss decreased (0.255543 --> 0.234246).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2713174
	speed: 0.0564s/iter; left time: 646.6501s
Epoch: 3 cost time: 6.721097946166992
Epoch: 3, Steps: 118 Train Loss: 0.2749 (Forecasting Loss:0.2441 + XiCon Loss:3.0766 x Lambda(0.01)), Vali MSE Loss: 0.2446 Test MSE Loss: 0.1430
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2569075
	speed: 0.0595s/iter; left time: 674.7811s
Epoch: 4 cost time: 7.1176064014434814
Epoch: 4, Steps: 118 Train Loss: 0.2564 (Forecasting Loss:0.2259 + XiCon Loss:3.0524 x Lambda(0.01)), Vali MSE Loss: 0.2390 Test MSE Loss: 0.1428
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2598675
	speed: 0.0599s/iter; left time: 673.0057s
Epoch: 5 cost time: 7.065737962722778
Epoch: 5, Steps: 118 Train Loss: 0.2502 (Forecasting Loss:0.2197 + XiCon Loss:3.0472 x Lambda(0.01)), Vali MSE Loss: 0.2388 Test MSE Loss: 0.1436
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2380872
	speed: 0.0593s/iter; left time: 658.6392s
Epoch: 6 cost time: 6.976187705993652
Epoch: 6, Steps: 118 Train Loss: 0.2470 (Forecasting Loss:0.2166 + XiCon Loss:3.0443 x Lambda(0.01)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.1403
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2416458
	speed: 0.0602s/iter; left time: 661.3471s
Epoch: 7 cost time: 7.055209398269653
Epoch: 7, Steps: 118 Train Loss: 0.2455 (Forecasting Loss:0.2151 + XiCon Loss:3.0462 x Lambda(0.01)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1410
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2498328
	speed: 0.0602s/iter; left time: 654.3463s
Epoch: 8 cost time: 7.089469909667969
Epoch: 8, Steps: 118 Train Loss: 0.2448 (Forecasting Loss:0.2144 + XiCon Loss:3.0450 x Lambda(0.01)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1418
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2500306
	speed: 0.0652s/iter; left time: 701.7604s
Epoch: 9 cost time: 7.65742564201355
Epoch: 9, Steps: 118 Train Loss: 0.2444 (Forecasting Loss:0.2140 + XiCon Loss:3.0434 x Lambda(0.01)), Vali MSE Loss: 0.2450 Test MSE Loss: 0.1415
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2497304
	speed: 0.0607s/iter; left time: 645.5412s
Epoch: 10 cost time: 7.1409876346588135
Epoch: 10, Steps: 118 Train Loss: 0.2443 (Forecasting Loss:0.2139 + XiCon Loss:3.0422 x Lambda(0.01)), Vali MSE Loss: 0.2463 Test MSE Loss: 0.1409
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2477229
	speed: 0.0593s/iter; left time: 623.5862s
Epoch: 11 cost time: 6.965372800827026
Epoch: 11, Steps: 118 Train Loss: 0.2440 (Forecasting Loss:0.2135 + XiCon Loss:3.0434 x Lambda(0.01)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1413
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2412625
	speed: 0.0661s/iter; left time: 687.2150s
Epoch: 12 cost time: 7.738122940063477
Epoch: 12, Steps: 118 Train Loss: 0.2438 (Forecasting Loss:0.2133 + XiCon Loss:3.0466 x Lambda(0.01)), Vali MSE Loss: 0.2462 Test MSE Loss: 0.1410
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0783684179186821, mae:0.2206198275089264, mape:0.15971513092517853, mspe:0.04161093384027481 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2859
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3436723
	speed: 0.0458s/iter; left time: 536.2345s
Epoch: 1 cost time: 5.359272480010986
Epoch: 1, Steps: 118 Train Loss: 0.3897 (Forecasting Loss:0.3579 + XiCon Loss:3.1851 x Lambda(0.01)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.1657
Validation loss decreased (inf --> 0.259882).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2941818
	speed: 0.0458s/iter; left time: 530.6682s
Epoch: 2 cost time: 5.369915723800659
Epoch: 2, Steps: 118 Train Loss: 0.3346 (Forecasting Loss:0.3033 + XiCon Loss:3.1344 x Lambda(0.01)), Vali MSE Loss: 0.2237 Test MSE Loss: 0.1408
Validation loss decreased (0.259882 --> 0.223704).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2647049
	speed: 0.0503s/iter; left time: 576.6106s
Epoch: 3 cost time: 5.920825242996216
Epoch: 3, Steps: 118 Train Loss: 0.2677 (Forecasting Loss:0.2371 + XiCon Loss:3.0609 x Lambda(0.01)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1392
Validation loss decreased (0.223704 --> 0.216486).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2451737
	speed: 0.0515s/iter; left time: 584.2994s
Epoch: 4 cost time: 5.985671281814575
Epoch: 4, Steps: 118 Train Loss: 0.2526 (Forecasting Loss:0.2222 + XiCon Loss:3.0456 x Lambda(0.01)), Vali MSE Loss: 0.2213 Test MSE Loss: 0.1417
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2472340
	speed: 0.0507s/iter; left time: 569.8705s
Epoch: 5 cost time: 5.949376583099365
Epoch: 5, Steps: 118 Train Loss: 0.2465 (Forecasting Loss:0.2160 + XiCon Loss:3.0473 x Lambda(0.01)), Vali MSE Loss: 0.2223 Test MSE Loss: 0.1399
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2437149
	speed: 0.0490s/iter; left time: 543.8983s
Epoch: 6 cost time: 5.76108455657959
Epoch: 6, Steps: 118 Train Loss: 0.2440 (Forecasting Loss:0.2135 + XiCon Loss:3.0474 x Lambda(0.01)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.1374
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2313271
	speed: 0.0510s/iter; left time: 560.5195s
Epoch: 7 cost time: 6.004071235656738
Epoch: 7, Steps: 118 Train Loss: 0.2426 (Forecasting Loss:0.2121 + XiCon Loss:3.0507 x Lambda(0.01)), Vali MSE Loss: 0.2245 Test MSE Loss: 0.1386
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2308822
	speed: 0.0468s/iter; left time: 508.4237s
Epoch: 8 cost time: 5.574328184127808
Epoch: 8, Steps: 118 Train Loss: 0.2419 (Forecasting Loss:0.2114 + XiCon Loss:3.0510 x Lambda(0.01)), Vali MSE Loss: 0.2239 Test MSE Loss: 0.1394
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2332182
	speed: 0.0565s/iter; left time: 608.1432s
Epoch: 9 cost time: 6.620464086532593
Epoch: 9, Steps: 118 Train Loss: 0.2416 (Forecasting Loss:0.2111 + XiCon Loss:3.0526 x Lambda(0.01)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.1386
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2287289
	speed: 0.0493s/iter; left time: 525.0303s
Epoch: 10 cost time: 5.897180080413818
Epoch: 10, Steps: 118 Train Loss: 0.2415 (Forecasting Loss:0.2110 + XiCon Loss:3.0498 x Lambda(0.01)), Vali MSE Loss: 0.2250 Test MSE Loss: 0.1391
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2346361
	speed: 0.0509s/iter; left time: 535.5856s
Epoch: 11 cost time: 6.0209126472473145
Epoch: 11, Steps: 118 Train Loss: 0.2414 (Forecasting Loss:0.2109 + XiCon Loss:3.0511 x Lambda(0.01)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.1392
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2288650
	speed: 0.0512s/iter; left time: 532.2745s
Epoch: 12 cost time: 5.963547229766846
Epoch: 12, Steps: 118 Train Loss: 0.2413 (Forecasting Loss:0.2108 + XiCon Loss:3.0504 x Lambda(0.01)), Vali MSE Loss: 0.2249 Test MSE Loss: 0.1391
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2473735
	speed: 0.0554s/iter; left time: 569.6460s
Epoch: 13 cost time: 6.447157382965088
Epoch: 13, Steps: 118 Train Loss: 0.2412 (Forecasting Loss:0.2107 + XiCon Loss:3.0491 x Lambda(0.01)), Vali MSE Loss: 0.2252 Test MSE Loss: 0.1391
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.06945332139730453, mae:0.2088690996170044, mape:0.15510328114032745, mspe:0.04133954644203186 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0819+-0.01273, MAE:0.2263+-0.01704, MAPE:0.1667+-0.01193, MSPE:0.0462+-0.00557, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3894
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2643574
	speed: 0.0168s/iter; left time: 212.9960s
Epoch: 1 cost time: 2.034233570098877
Epoch: 1, Steps: 128 Train Loss: 0.3230 (Forecasting Loss:0.2922 + XiCon Loss:3.0783 x Lambda(0.01)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.2309
Validation loss decreased (inf --> 0.274890).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2371270
	speed: 0.0151s/iter; left time: 190.2517s
Epoch: 2 cost time: 1.8896386623382568
Epoch: 2, Steps: 128 Train Loss: 0.2655 (Forecasting Loss:0.2352 + XiCon Loss:3.0311 x Lambda(0.01)), Vali MSE Loss: 0.2754 Test MSE Loss: 0.2740
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2088234
	speed: 0.0152s/iter; left time: 189.5972s
Epoch: 3 cost time: 1.9106431007385254
Epoch: 3, Steps: 128 Train Loss: 0.2151 (Forecasting Loss:0.1851 + XiCon Loss:3.0035 x Lambda(0.01)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.3145
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1846426
	speed: 0.0141s/iter; left time: 173.6345s
Epoch: 4 cost time: 1.7607667446136475
Epoch: 4, Steps: 128 Train Loss: 0.1908 (Forecasting Loss:0.1609 + XiCon Loss:2.9849 x Lambda(0.01)), Vali MSE Loss: 0.2960 Test MSE Loss: 0.3235
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1847388
	speed: 0.0141s/iter; left time: 172.2510s
Epoch: 5 cost time: 1.7603063583374023
Epoch: 5, Steps: 128 Train Loss: 0.1813 (Forecasting Loss:0.1515 + XiCon Loss:2.9781 x Lambda(0.01)), Vali MSE Loss: 0.2934 Test MSE Loss: 0.3311
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1820097
	speed: 0.0140s/iter; left time: 168.9853s
Epoch: 6 cost time: 1.7704730033874512
Epoch: 6, Steps: 128 Train Loss: 0.1771 (Forecasting Loss:0.1473 + XiCon Loss:2.9734 x Lambda(0.01)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.3352
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1885926
	speed: 0.0145s/iter; left time: 173.0058s
Epoch: 7 cost time: 1.8540990352630615
Epoch: 7, Steps: 128 Train Loss: 0.1748 (Forecasting Loss:0.1451 + XiCon Loss:2.9708 x Lambda(0.01)), Vali MSE Loss: 0.2928 Test MSE Loss: 0.3401
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1796273
	speed: 0.0134s/iter; left time: 158.0561s
Epoch: 8 cost time: 1.6846823692321777
Epoch: 8, Steps: 128 Train Loss: 0.1740 (Forecasting Loss:0.1443 + XiCon Loss:2.9701 x Lambda(0.01)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.3396
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1733735
	speed: 0.0143s/iter; left time: 167.4525s
Epoch: 9 cost time: 1.7758443355560303
Epoch: 9, Steps: 128 Train Loss: 0.1734 (Forecasting Loss:0.1437 + XiCon Loss:2.9700 x Lambda(0.01)), Vali MSE Loss: 0.2930 Test MSE Loss: 0.3413
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1626970
	speed: 0.0151s/iter; left time: 173.9435s
Epoch: 10 cost time: 1.8600447177886963
Epoch: 10, Steps: 128 Train Loss: 0.1729 (Forecasting Loss:0.1432 + XiCon Loss:2.9701 x Lambda(0.01)), Vali MSE Loss: 0.2936 Test MSE Loss: 0.3416
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1732123
	speed: 0.0150s/iter; left time: 170.9723s
Epoch: 11 cost time: 1.9016590118408203
Epoch: 11, Steps: 128 Train Loss: 0.1730 (Forecasting Loss:0.1433 + XiCon Loss:2.9696 x Lambda(0.01)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.3414
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15322431921958923, mae:0.3085324168205261, mape:0.7093802690505981, mspe:22.069303512573242 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3325
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.3158976
	speed: 0.0133s/iter; left time: 169.4327s
Epoch: 1 cost time: 1.67437744140625
Epoch: 1, Steps: 128 Train Loss: 0.3220 (Forecasting Loss:0.2913 + XiCon Loss:3.0731 x Lambda(0.01)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2238
Validation loss decreased (inf --> 0.278700).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2508686
	speed: 0.0137s/iter; left time: 172.5900s
Epoch: 2 cost time: 1.7429425716400146
Epoch: 2, Steps: 128 Train Loss: 0.2680 (Forecasting Loss:0.2377 + XiCon Loss:3.0302 x Lambda(0.01)), Vali MSE Loss: 0.2876 Test MSE Loss: 0.2449
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2196209
	speed: 0.0140s/iter; left time: 173.6164s
Epoch: 3 cost time: 1.7435967922210693
Epoch: 3, Steps: 128 Train Loss: 0.2237 (Forecasting Loss:0.1935 + XiCon Loss:3.0169 x Lambda(0.01)), Vali MSE Loss: 0.2931 Test MSE Loss: 0.2627
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1782660
	speed: 0.0136s/iter; left time: 167.2664s
Epoch: 4 cost time: 1.6906487941741943
Epoch: 4, Steps: 128 Train Loss: 0.1962 (Forecasting Loss:0.1663 + XiCon Loss:2.9925 x Lambda(0.01)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2873
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2038026
	speed: 0.0140s/iter; left time: 170.1356s
Epoch: 5 cost time: 1.7535178661346436
Epoch: 5, Steps: 128 Train Loss: 0.1838 (Forecasting Loss:0.1539 + XiCon Loss:2.9872 x Lambda(0.01)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.3009
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1687983
	speed: 0.0151s/iter; left time: 182.7189s
Epoch: 6 cost time: 1.9361305236816406
Epoch: 6, Steps: 128 Train Loss: 0.1787 (Forecasting Loss:0.1489 + XiCon Loss:2.9844 x Lambda(0.01)), Vali MSE Loss: 0.3290 Test MSE Loss: 0.3055
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1631371
	speed: 0.0143s/iter; left time: 170.3689s
Epoch: 7 cost time: 1.7783172130584717
Epoch: 7, Steps: 128 Train Loss: 0.1762 (Forecasting Loss:0.1464 + XiCon Loss:2.9825 x Lambda(0.01)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.3050
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1807506
	speed: 0.0140s/iter; left time: 165.4059s
Epoch: 8 cost time: 1.7726366519927979
Epoch: 8, Steps: 128 Train Loss: 0.1743 (Forecasting Loss:0.1445 + XiCon Loss:2.9813 x Lambda(0.01)), Vali MSE Loss: 0.3349 Test MSE Loss: 0.3081
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1749406
	speed: 0.0138s/iter; left time: 160.6918s
Epoch: 9 cost time: 1.7600266933441162
Epoch: 9, Steps: 128 Train Loss: 0.1740 (Forecasting Loss:0.1442 + XiCon Loss:2.9811 x Lambda(0.01)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.3082
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1715496
	speed: 0.0132s/iter; left time: 152.3281s
Epoch: 10 cost time: 1.679793119430542
Epoch: 10, Steps: 128 Train Loss: 0.1740 (Forecasting Loss:0.1441 + XiCon Loss:2.9826 x Lambda(0.01)), Vali MSE Loss: 0.3325 Test MSE Loss: 0.3085
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1645246
	speed: 0.0143s/iter; left time: 163.2631s
Epoch: 11 cost time: 1.771207571029663
Epoch: 11, Steps: 128 Train Loss: 0.1737 (Forecasting Loss:0.1439 + XiCon Loss:2.9815 x Lambda(0.01)), Vali MSE Loss: 0.3333 Test MSE Loss: 0.3093
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.14576534926891327, mae:0.3018489181995392, mape:0.7110822200775146, mspe:22.30120849609375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4099
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2964692
	speed: 0.0146s/iter; left time: 185.2261s
Epoch: 1 cost time: 1.8192589282989502
Epoch: 1, Steps: 128 Train Loss: 0.3227 (Forecasting Loss:0.2919 + XiCon Loss:3.0808 x Lambda(0.01)), Vali MSE Loss: 0.2758 Test MSE Loss: 0.2240
Validation loss decreased (inf --> 0.275822).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2750083
	speed: 0.0147s/iter; left time: 185.2850s
Epoch: 2 cost time: 1.8705189228057861
Epoch: 2, Steps: 128 Train Loss: 0.2682 (Forecasting Loss:0.2378 + XiCon Loss:3.0410 x Lambda(0.01)), Vali MSE Loss: 0.2610 Test MSE Loss: 0.2308
Validation loss decreased (0.275822 --> 0.260961).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2069975
	speed: 0.0148s/iter; left time: 184.6164s
Epoch: 3 cost time: 1.8461229801177979
Epoch: 3, Steps: 128 Train Loss: 0.2314 (Forecasting Loss:0.2011 + XiCon Loss:3.0241 x Lambda(0.01)), Vali MSE Loss: 0.3100 Test MSE Loss: 0.2373
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1995063
	speed: 0.0148s/iter; left time: 182.3796s
Epoch: 4 cost time: 1.8450241088867188
Epoch: 4, Steps: 128 Train Loss: 0.2083 (Forecasting Loss:0.1781 + XiCon Loss:3.0127 x Lambda(0.01)), Vali MSE Loss: 0.3252 Test MSE Loss: 0.2579
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2028201
	speed: 0.0135s/iter; left time: 164.4231s
Epoch: 5 cost time: 1.7012722492218018
Epoch: 5, Steps: 128 Train Loss: 0.1959 (Forecasting Loss:0.1658 + XiCon Loss:3.0111 x Lambda(0.01)), Vali MSE Loss: 0.3409 Test MSE Loss: 0.2579
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1761665
	speed: 0.0142s/iter; left time: 170.7557s
Epoch: 6 cost time: 1.808894157409668
Epoch: 6, Steps: 128 Train Loss: 0.1904 (Forecasting Loss:0.1603 + XiCon Loss:3.0083 x Lambda(0.01)), Vali MSE Loss: 0.3399 Test MSE Loss: 0.2677
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1836764
	speed: 0.0148s/iter; left time: 176.4506s
Epoch: 7 cost time: 1.83787202835083
Epoch: 7, Steps: 128 Train Loss: 0.1878 (Forecasting Loss:0.1577 + XiCon Loss:3.0043 x Lambda(0.01)), Vali MSE Loss: 0.3424 Test MSE Loss: 0.2657
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1865223
	speed: 0.0139s/iter; left time: 164.3727s
Epoch: 8 cost time: 1.7401409149169922
Epoch: 8, Steps: 128 Train Loss: 0.1865 (Forecasting Loss:0.1564 + XiCon Loss:3.0050 x Lambda(0.01)), Vali MSE Loss: 0.3441 Test MSE Loss: 0.2676
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2008741
	speed: 0.0143s/iter; left time: 167.5561s
Epoch: 9 cost time: 1.7850866317749023
Epoch: 9, Steps: 128 Train Loss: 0.1861 (Forecasting Loss:0.1560 + XiCon Loss:3.0058 x Lambda(0.01)), Vali MSE Loss: 0.3442 Test MSE Loss: 0.2679
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1874420
	speed: 0.0145s/iter; left time: 167.7224s
Epoch: 10 cost time: 1.7900049686431885
Epoch: 10, Steps: 128 Train Loss: 0.1857 (Forecasting Loss:0.1556 + XiCon Loss:3.0054 x Lambda(0.01)), Vali MSE Loss: 0.3453 Test MSE Loss: 0.2695
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1785236
	speed: 0.0137s/iter; left time: 155.9452s
Epoch: 11 cost time: 1.7111411094665527
Epoch: 11, Steps: 128 Train Loss: 0.1854 (Forecasting Loss:0.1553 + XiCon Loss:3.0056 x Lambda(0.01)), Vali MSE Loss: 0.3442 Test MSE Loss: 0.2693
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1841745
	speed: 0.0137s/iter; left time: 154.3560s
Epoch: 12 cost time: 1.7162363529205322
Epoch: 12, Steps: 128 Train Loss: 0.1854 (Forecasting Loss:0.1554 + XiCon Loss:3.0057 x Lambda(0.01)), Vali MSE Loss: 0.3451 Test MSE Loss: 0.2696
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15463051199913025, mae:0.30691108107566833, mape:0.7600640058517456, mspe:25.350021362304688 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3700
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2480861
	speed: 0.0142s/iter; left time: 180.9294s
Epoch: 1 cost time: 1.8274917602539062
Epoch: 1, Steps: 128 Train Loss: 0.3260 (Forecasting Loss:0.2953 + XiCon Loss:3.0671 x Lambda(0.01)), Vali MSE Loss: 0.2715 Test MSE Loss: 0.2279
Validation loss decreased (inf --> 0.271540).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2806501
	speed: 0.0139s/iter; left time: 174.3062s
Epoch: 2 cost time: 1.7358336448669434
Epoch: 2, Steps: 128 Train Loss: 0.2726 (Forecasting Loss:0.2418 + XiCon Loss:3.0772 x Lambda(0.01)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.2311
Validation loss decreased (0.271540 --> 0.258500).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2283694
	speed: 0.0146s/iter; left time: 181.4097s
Epoch: 3 cost time: 1.7963342666625977
Epoch: 3, Steps: 128 Train Loss: 0.2273 (Forecasting Loss:0.1971 + XiCon Loss:3.0183 x Lambda(0.01)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.3129
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1876260
	speed: 0.0148s/iter; left time: 182.8663s
Epoch: 4 cost time: 1.8399627208709717
Epoch: 4, Steps: 128 Train Loss: 0.1973 (Forecasting Loss:0.1672 + XiCon Loss:3.0077 x Lambda(0.01)), Vali MSE Loss: 0.2742 Test MSE Loss: 0.3084
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1770790
	speed: 0.0149s/iter; left time: 181.8448s
Epoch: 5 cost time: 1.8392062187194824
Epoch: 5, Steps: 128 Train Loss: 0.1848 (Forecasting Loss:0.1547 + XiCon Loss:3.0074 x Lambda(0.01)), Vali MSE Loss: 0.2725 Test MSE Loss: 0.3181
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1725553
	speed: 0.0146s/iter; left time: 176.3537s
Epoch: 6 cost time: 1.8108537197113037
Epoch: 6, Steps: 128 Train Loss: 0.1789 (Forecasting Loss:0.1488 + XiCon Loss:3.0040 x Lambda(0.01)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.3241
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1844215
	speed: 0.0136s/iter; left time: 162.3779s
Epoch: 7 cost time: 1.7289478778839111
Epoch: 7, Steps: 128 Train Loss: 0.1763 (Forecasting Loss:0.1462 + XiCon Loss:3.0030 x Lambda(0.01)), Vali MSE Loss: 0.2735 Test MSE Loss: 0.3213
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1825556
	speed: 0.0139s/iter; left time: 163.8784s
Epoch: 8 cost time: 1.7272295951843262
Epoch: 8, Steps: 128 Train Loss: 0.1756 (Forecasting Loss:0.1455 + XiCon Loss:3.0006 x Lambda(0.01)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.3226
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1891721
	speed: 0.0134s/iter; left time: 156.4544s
Epoch: 9 cost time: 1.71514892578125
Epoch: 9, Steps: 128 Train Loss: 0.1749 (Forecasting Loss:0.1449 + XiCon Loss:3.0021 x Lambda(0.01)), Vali MSE Loss: 0.2756 Test MSE Loss: 0.3249
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1847685
	speed: 0.0139s/iter; left time: 160.7707s
Epoch: 10 cost time: 1.7607197761535645
Epoch: 10, Steps: 128 Train Loss: 0.1746 (Forecasting Loss:0.1446 + XiCon Loss:3.0021 x Lambda(0.01)), Vali MSE Loss: 0.2749 Test MSE Loss: 0.3242
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1767038
	speed: 0.0148s/iter; left time: 168.9829s
Epoch: 11 cost time: 1.8278512954711914
Epoch: 11, Steps: 128 Train Loss: 0.1744 (Forecasting Loss:0.1444 + XiCon Loss:3.0015 x Lambda(0.01)), Vali MSE Loss: 0.2746 Test MSE Loss: 0.3269
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1712209
	speed: 0.0148s/iter; left time: 167.0369s
Epoch: 12 cost time: 1.8357884883880615
Epoch: 12, Steps: 128 Train Loss: 0.1741 (Forecasting Loss:0.1441 + XiCon Loss:3.0020 x Lambda(0.01)), Vali MSE Loss: 0.2740 Test MSE Loss: 0.3255
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.15258319675922394, mae:0.30965831875801086, mape:0.7869632244110107, mspe:25.87730598449707 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2930
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 0.2711397
	speed: 0.0146s/iter; left time: 186.0034s
Epoch: 1 cost time: 1.8360278606414795
Epoch: 1, Steps: 128 Train Loss: 0.3254 (Forecasting Loss:0.2948 + XiCon Loss:3.0632 x Lambda(0.01)), Vali MSE Loss: 0.2737 Test MSE Loss: 0.2262
Validation loss decreased (inf --> 0.273720).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2326079
	speed: 0.0149s/iter; left time: 187.8214s
Epoch: 2 cost time: 1.8838446140289307
Epoch: 2, Steps: 128 Train Loss: 0.2745 (Forecasting Loss:0.2442 + XiCon Loss:3.0348 x Lambda(0.01)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2771
Validation loss decreased (0.273720 --> 0.252355).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2443420
	speed: 0.0142s/iter; left time: 176.1231s
Epoch: 3 cost time: 1.7648725509643555
Epoch: 3, Steps: 128 Train Loss: 0.2381 (Forecasting Loss:0.2078 + XiCon Loss:3.0302 x Lambda(0.01)), Vali MSE Loss: 0.2592 Test MSE Loss: 0.2637
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2096338
	speed: 0.0144s/iter; left time: 177.6408s
Epoch: 4 cost time: 1.8424055576324463
Epoch: 4, Steps: 128 Train Loss: 0.2163 (Forecasting Loss:0.1859 + XiCon Loss:3.0360 x Lambda(0.01)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.2997
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2088042
	speed: 0.0139s/iter; left time: 169.1202s
Epoch: 5 cost time: 1.7410554885864258
Epoch: 5, Steps: 128 Train Loss: 0.2064 (Forecasting Loss:0.1759 + XiCon Loss:3.0439 x Lambda(0.01)), Vali MSE Loss: 0.2698 Test MSE Loss: 0.2977
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1990967
	speed: 0.0140s/iter; left time: 168.9187s
Epoch: 6 cost time: 1.7639148235321045
Epoch: 6, Steps: 128 Train Loss: 0.2012 (Forecasting Loss:0.1708 + XiCon Loss:3.0439 x Lambda(0.01)), Vali MSE Loss: 0.2784 Test MSE Loss: 0.3113
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1986333
	speed: 0.0139s/iter; left time: 165.4747s
Epoch: 7 cost time: 1.7496638298034668
Epoch: 7, Steps: 128 Train Loss: 0.1983 (Forecasting Loss:0.1679 + XiCon Loss:3.0445 x Lambda(0.01)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.3083
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1913515
	speed: 0.0141s/iter; left time: 166.3377s
Epoch: 8 cost time: 1.7473549842834473
Epoch: 8, Steps: 128 Train Loss: 0.1967 (Forecasting Loss:0.1662 + XiCon Loss:3.0441 x Lambda(0.01)), Vali MSE Loss: 0.2806 Test MSE Loss: 0.3149
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2116624
	speed: 0.0142s/iter; left time: 165.5089s
Epoch: 9 cost time: 1.8234553337097168
Epoch: 9, Steps: 128 Train Loss: 0.1959 (Forecasting Loss:0.1654 + XiCon Loss:3.0474 x Lambda(0.01)), Vali MSE Loss: 0.2826 Test MSE Loss: 0.3145
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1937978
	speed: 0.0138s/iter; left time: 159.7949s
Epoch: 10 cost time: 1.729485273361206
Epoch: 10, Steps: 128 Train Loss: 0.1958 (Forecasting Loss:0.1654 + XiCon Loss:3.0432 x Lambda(0.01)), Vali MSE Loss: 0.2830 Test MSE Loss: 0.3173
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1846942
	speed: 0.0146s/iter; left time: 166.6132s
Epoch: 11 cost time: 1.8862700462341309
Epoch: 11, Steps: 128 Train Loss: 0.1955 (Forecasting Loss:0.1650 + XiCon Loss:3.0481 x Lambda(0.01)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.3179
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2034578
	speed: 0.0144s/iter; left time: 162.2618s
Epoch: 12 cost time: 1.8065283298492432
Epoch: 12, Steps: 128 Train Loss: 0.1956 (Forecasting Loss:0.1652 + XiCon Loss:3.0420 x Lambda(0.01)), Vali MSE Loss: 0.2833 Test MSE Loss: 0.3175
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.2125364989042282, mae:0.3417564034461975, mape:0.7170875072479248, mspe:19.35028076171875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1637+-0.03413, MAE:0.3137+-0.01980, MAPE:0.7369+-0.04328, MSPE:22.9896+-3.31293, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4862
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3435582
	speed: 0.0182s/iter; left time: 227.6669s
Epoch: 1 cost time: 2.178194999694824
Epoch: 1, Steps: 126 Train Loss: 0.3509 (Forecasting Loss:0.3201 + XiCon Loss:3.0807 x Lambda(0.01)), Vali MSE Loss: 0.3067 Test MSE Loss: 0.2656
Validation loss decreased (inf --> 0.306682).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2853644
	speed: 0.0165s/iter; left time: 204.2783s
Epoch: 2 cost time: 2.089937686920166
Epoch: 2, Steps: 126 Train Loss: 0.2993 (Forecasting Loss:0.2688 + XiCon Loss:3.0488 x Lambda(0.01)), Vali MSE Loss: 0.2975 Test MSE Loss: 0.3048
Validation loss decreased (0.306682 --> 0.297524).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2337996
	speed: 0.0190s/iter; left time: 232.7496s
Epoch: 3 cost time: 2.331394672393799
Epoch: 3, Steps: 126 Train Loss: 0.2548 (Forecasting Loss:0.2247 + XiCon Loss:3.0074 x Lambda(0.01)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.3268
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2244688
	speed: 0.0180s/iter; left time: 218.4486s
Epoch: 4 cost time: 2.221118688583374
Epoch: 4, Steps: 126 Train Loss: 0.2346 (Forecasting Loss:0.2048 + XiCon Loss:2.9804 x Lambda(0.01)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.3441
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2273142
	speed: 0.0176s/iter; left time: 211.5505s
Epoch: 5 cost time: 2.192730188369751
Epoch: 5, Steps: 126 Train Loss: 0.2288 (Forecasting Loss:0.1991 + XiCon Loss:2.9682 x Lambda(0.01)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.3415
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2105275
	speed: 0.0172s/iter; left time: 204.3959s
Epoch: 6 cost time: 2.1500155925750732
Epoch: 6, Steps: 126 Train Loss: 0.2259 (Forecasting Loss:0.1963 + XiCon Loss:2.9605 x Lambda(0.01)), Vali MSE Loss: 0.3138 Test MSE Loss: 0.3455
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2141004
	speed: 0.0176s/iter; left time: 206.5811s
Epoch: 7 cost time: 2.1730692386627197
Epoch: 7, Steps: 126 Train Loss: 0.2245 (Forecasting Loss:0.1949 + XiCon Loss:2.9572 x Lambda(0.01)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.3432
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2265666
	speed: 0.0179s/iter; left time: 208.0584s
Epoch: 8 cost time: 2.2100162506103516
Epoch: 8, Steps: 126 Train Loss: 0.2239 (Forecasting Loss:0.1943 + XiCon Loss:2.9572 x Lambda(0.01)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.3458
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2382718
	speed: 0.0175s/iter; left time: 201.6294s
Epoch: 9 cost time: 2.1833341121673584
Epoch: 9, Steps: 126 Train Loss: 0.2235 (Forecasting Loss:0.1939 + XiCon Loss:2.9557 x Lambda(0.01)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.3470
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2242293
	speed: 0.0185s/iter; left time: 209.9642s
Epoch: 10 cost time: 2.280673027038574
Epoch: 10, Steps: 126 Train Loss: 0.2232 (Forecasting Loss:0.1937 + XiCon Loss:2.9564 x Lambda(0.01)), Vali MSE Loss: 0.3141 Test MSE Loss: 0.3469
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2319430
	speed: 0.0177s/iter; left time: 198.6721s
Epoch: 11 cost time: 2.1946983337402344
Epoch: 11, Steps: 126 Train Loss: 0.2234 (Forecasting Loss:0.1939 + XiCon Loss:2.9550 x Lambda(0.01)), Vali MSE Loss: 0.3141 Test MSE Loss: 0.3465
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2142983
	speed: 0.0180s/iter; left time: 199.5801s
Epoch: 12 cost time: 2.270766258239746
Epoch: 12, Steps: 126 Train Loss: 0.2231 (Forecasting Loss:0.1936 + XiCon Loss:2.9555 x Lambda(0.01)), Vali MSE Loss: 0.3139 Test MSE Loss: 0.3469
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.22920921444892883, mae:0.38036689162254333, mape:0.8099092841148376, mspe:23.694679260253906 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3435
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3199484
	speed: 0.0156s/iter; left time: 194.4041s
Epoch: 1 cost time: 1.953183650970459
Epoch: 1, Steps: 126 Train Loss: 0.3486 (Forecasting Loss:0.3177 + XiCon Loss:3.0874 x Lambda(0.01)), Vali MSE Loss: 0.3070 Test MSE Loss: 0.2669
Validation loss decreased (inf --> 0.307008).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2998779
	speed: 0.0156s/iter; left time: 193.3462s
Epoch: 2 cost time: 1.9965572357177734
Epoch: 2, Steps: 126 Train Loss: 0.2991 (Forecasting Loss:0.2689 + XiCon Loss:3.0218 x Lambda(0.01)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.2793
Validation loss decreased (0.307008 --> 0.282369).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2450120
	speed: 0.0172s/iter; left time: 210.4540s
Epoch: 3 cost time: 2.1174511909484863
Epoch: 3, Steps: 126 Train Loss: 0.2559 (Forecasting Loss:0.2259 + XiCon Loss:3.0039 x Lambda(0.01)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.2638
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2269236
	speed: 0.0175s/iter; left time: 212.2683s
Epoch: 4 cost time: 2.1876413822174072
Epoch: 4, Steps: 126 Train Loss: 0.2371 (Forecasting Loss:0.2071 + XiCon Loss:2.9987 x Lambda(0.01)), Vali MSE Loss: 0.3366 Test MSE Loss: 0.2772
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2228437
	speed: 0.0178s/iter; left time: 213.5666s
Epoch: 5 cost time: 2.173384666442871
Epoch: 5, Steps: 126 Train Loss: 0.2296 (Forecasting Loss:0.1997 + XiCon Loss:2.9946 x Lambda(0.01)), Vali MSE Loss: 0.3481 Test MSE Loss: 0.2728
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2273425
	speed: 0.0182s/iter; left time: 215.5148s
Epoch: 6 cost time: 2.2577428817749023
Epoch: 6, Steps: 126 Train Loss: 0.2262 (Forecasting Loss:0.1963 + XiCon Loss:2.9903 x Lambda(0.01)), Vali MSE Loss: 0.3476 Test MSE Loss: 0.2772
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2369456
	speed: 0.0182s/iter; left time: 214.2636s
Epoch: 7 cost time: 2.2309346199035645
Epoch: 7, Steps: 126 Train Loss: 0.2249 (Forecasting Loss:0.1950 + XiCon Loss:2.9860 x Lambda(0.01)), Vali MSE Loss: 0.3443 Test MSE Loss: 0.2791
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2278079
	speed: 0.0176s/iter; left time: 205.0327s
Epoch: 8 cost time: 2.1863622665405273
Epoch: 8, Steps: 126 Train Loss: 0.2241 (Forecasting Loss:0.1942 + XiCon Loss:2.9854 x Lambda(0.01)), Vali MSE Loss: 0.3472 Test MSE Loss: 0.2768
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2106810
	speed: 0.0176s/iter; left time: 202.0390s
Epoch: 9 cost time: 2.202016592025757
Epoch: 9, Steps: 126 Train Loss: 0.2239 (Forecasting Loss:0.1940 + XiCon Loss:2.9871 x Lambda(0.01)), Vali MSE Loss: 0.3456 Test MSE Loss: 0.2774
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2366555
	speed: 0.0172s/iter; left time: 195.3290s
Epoch: 10 cost time: 2.1308963298797607
Epoch: 10, Steps: 126 Train Loss: 0.2232 (Forecasting Loss:0.1933 + XiCon Loss:2.9828 x Lambda(0.01)), Vali MSE Loss: 0.3466 Test MSE Loss: 0.2780
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2086866
	speed: 0.0172s/iter; left time: 193.1193s
Epoch: 11 cost time: 2.1430909633636475
Epoch: 11, Steps: 126 Train Loss: 0.2234 (Forecasting Loss:0.1936 + XiCon Loss:2.9872 x Lambda(0.01)), Vali MSE Loss: 0.3461 Test MSE Loss: 0.2776
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2085396
	speed: 0.0178s/iter; left time: 198.1198s
Epoch: 12 cost time: 2.1977155208587646
Epoch: 12, Steps: 126 Train Loss: 0.2232 (Forecasting Loss:0.1934 + XiCon Loss:2.9854 x Lambda(0.01)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2775
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.19972512125968933, mae:0.3588888347148895, mape:0.7554510831832886, mspe:20.795461654663086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2636
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3112814
	speed: 0.0152s/iter; left time: 189.7108s
Epoch: 1 cost time: 1.8902270793914795
Epoch: 1, Steps: 126 Train Loss: 0.3466 (Forecasting Loss:0.3158 + XiCon Loss:3.0814 x Lambda(0.01)), Vali MSE Loss: 0.3054 Test MSE Loss: 0.2611
Validation loss decreased (inf --> 0.305415).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3017488
	speed: 0.0159s/iter; left time: 196.7789s
Epoch: 2 cost time: 1.9739656448364258
Epoch: 2, Steps: 126 Train Loss: 0.3107 (Forecasting Loss:0.2800 + XiCon Loss:3.0644 x Lambda(0.01)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2857
Validation loss decreased (0.305415 --> 0.289196).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2453787
	speed: 0.0165s/iter; left time: 202.6766s
Epoch: 3 cost time: 2.044705629348755
Epoch: 3, Steps: 126 Train Loss: 0.2703 (Forecasting Loss:0.2401 + XiCon Loss:3.0238 x Lambda(0.01)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2826
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2594430
	speed: 0.0175s/iter; left time: 211.9045s
Epoch: 4 cost time: 2.1719183921813965
Epoch: 4, Steps: 126 Train Loss: 0.2505 (Forecasting Loss:0.2205 + XiCon Loss:3.0010 x Lambda(0.01)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2758
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2141047
	speed: 0.0169s/iter; left time: 202.5398s
Epoch: 5 cost time: 2.121553897857666
Epoch: 5, Steps: 126 Train Loss: 0.2422 (Forecasting Loss:0.2123 + XiCon Loss:2.9883 x Lambda(0.01)), Vali MSE Loss: 0.3121 Test MSE Loss: 0.2835
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2360651
	speed: 0.0166s/iter; left time: 197.0039s
Epoch: 6 cost time: 2.089606523513794
Epoch: 6, Steps: 126 Train Loss: 0.2377 (Forecasting Loss:0.2079 + XiCon Loss:2.9814 x Lambda(0.01)), Vali MSE Loss: 0.3083 Test MSE Loss: 0.2889
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2209179
	speed: 0.0171s/iter; left time: 200.8422s
Epoch: 7 cost time: 2.102909564971924
Epoch: 7, Steps: 126 Train Loss: 0.2359 (Forecasting Loss:0.2061 + XiCon Loss:2.9779 x Lambda(0.01)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2876
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2130610
	speed: 0.0167s/iter; left time: 193.8980s
Epoch: 8 cost time: 2.0956509113311768
Epoch: 8, Steps: 126 Train Loss: 0.2348 (Forecasting Loss:0.2050 + XiCon Loss:2.9766 x Lambda(0.01)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2910
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2236897
	speed: 0.0181s/iter; left time: 208.4079s
Epoch: 9 cost time: 2.230637550354004
Epoch: 9, Steps: 126 Train Loss: 0.2341 (Forecasting Loss:0.2044 + XiCon Loss:2.9748 x Lambda(0.01)), Vali MSE Loss: 0.3170 Test MSE Loss: 0.2910
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2295322
	speed: 0.0171s/iter; left time: 194.8231s
Epoch: 10 cost time: 2.1141645908355713
Epoch: 10, Steps: 126 Train Loss: 0.2341 (Forecasting Loss:0.2043 + XiCon Loss:2.9750 x Lambda(0.01)), Vali MSE Loss: 0.3197 Test MSE Loss: 0.2908
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2208830
	speed: 0.0171s/iter; left time: 191.9781s
Epoch: 11 cost time: 2.1053249835968018
Epoch: 11, Steps: 126 Train Loss: 0.2338 (Forecasting Loss:0.2041 + XiCon Loss:2.9735 x Lambda(0.01)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2910
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2214372
	speed: 0.0176s/iter; left time: 195.5280s
Epoch: 12 cost time: 2.176406145095825
Epoch: 12, Steps: 126 Train Loss: 0.2337 (Forecasting Loss:0.2039 + XiCon Loss:2.9757 x Lambda(0.01)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2914
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.20838041603565216, mae:0.3630984425544739, mape:0.7375521659851074, mspe:21.56324005126953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2948
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3311624
	speed: 0.0157s/iter; left time: 195.6597s
Epoch: 1 cost time: 1.974609375
Epoch: 1, Steps: 126 Train Loss: 0.3504 (Forecasting Loss:0.3196 + XiCon Loss:3.0795 x Lambda(0.01)), Vali MSE Loss: 0.3106 Test MSE Loss: 0.2685
Validation loss decreased (inf --> 0.310634).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3102710
	speed: 0.0161s/iter; left time: 199.7391s
Epoch: 2 cost time: 2.0122854709625244
Epoch: 2, Steps: 126 Train Loss: 0.3122 (Forecasting Loss:0.2816 + XiCon Loss:3.0602 x Lambda(0.01)), Vali MSE Loss: 0.2808 Test MSE Loss: 0.2774
Validation loss decreased (0.310634 --> 0.280821).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2347245
	speed: 0.0162s/iter; left time: 197.8669s
Epoch: 3 cost time: 2.0267231464385986
Epoch: 3, Steps: 126 Train Loss: 0.2673 (Forecasting Loss:0.2370 + XiCon Loss:3.0319 x Lambda(0.01)), Vali MSE Loss: 0.2837 Test MSE Loss: 0.2641
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2380122
	speed: 0.0170s/iter; left time: 205.6382s
Epoch: 4 cost time: 2.0931105613708496
Epoch: 4, Steps: 126 Train Loss: 0.2481 (Forecasting Loss:0.2180 + XiCon Loss:3.0045 x Lambda(0.01)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.2784
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2277620
	speed: 0.0169s/iter; left time: 202.2208s
Epoch: 5 cost time: 2.1243884563446045
Epoch: 5, Steps: 126 Train Loss: 0.2399 (Forecasting Loss:0.2100 + XiCon Loss:2.9838 x Lambda(0.01)), Vali MSE Loss: 0.2942 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2520986
	speed: 0.0177s/iter; left time: 210.5309s
Epoch: 6 cost time: 2.201043128967285
Epoch: 6, Steps: 126 Train Loss: 0.2353 (Forecasting Loss:0.2056 + XiCon Loss:2.9723 x Lambda(0.01)), Vali MSE Loss: 0.2881 Test MSE Loss: 0.2675
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2184942
	speed: 0.0175s/iter; left time: 205.8572s
Epoch: 7 cost time: 2.1697258949279785
Epoch: 7, Steps: 126 Train Loss: 0.2333 (Forecasting Loss:0.2036 + XiCon Loss:2.9688 x Lambda(0.01)), Vali MSE Loss: 0.2930 Test MSE Loss: 0.2660
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2211261
	speed: 0.0175s/iter; left time: 203.8359s
Epoch: 8 cost time: 2.1809229850769043
Epoch: 8, Steps: 126 Train Loss: 0.2323 (Forecasting Loss:0.2026 + XiCon Loss:2.9678 x Lambda(0.01)), Vali MSE Loss: 0.2868 Test MSE Loss: 0.2656
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2600648
	speed: 0.0180s/iter; left time: 207.4139s
Epoch: 9 cost time: 2.2193684577941895
Epoch: 9, Steps: 126 Train Loss: 0.2318 (Forecasting Loss:0.2022 + XiCon Loss:2.9660 x Lambda(0.01)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2649
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2295183
	speed: 0.0171s/iter; left time: 194.2959s
Epoch: 10 cost time: 2.133625030517578
Epoch: 10, Steps: 126 Train Loss: 0.2317 (Forecasting Loss:0.2020 + XiCon Loss:2.9648 x Lambda(0.01)), Vali MSE Loss: 0.2870 Test MSE Loss: 0.2650
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2429170
	speed: 0.0178s/iter; left time: 199.5480s
Epoch: 11 cost time: 2.173858642578125
Epoch: 11, Steps: 126 Train Loss: 0.2312 (Forecasting Loss:0.2015 + XiCon Loss:2.9633 x Lambda(0.01)), Vali MSE Loss: 0.2871 Test MSE Loss: 0.2647
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2362126
	speed: 0.0169s/iter; left time: 188.2711s
Epoch: 12 cost time: 2.088357925415039
Epoch: 12, Steps: 126 Train Loss: 0.2314 (Forecasting Loss:0.2017 + XiCon Loss:2.9659 x Lambda(0.01)), Vali MSE Loss: 0.2867 Test MSE Loss: 0.2648
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1993187516927719, mae:0.3554147481918335, mape:0.7253537178039551, mspe:22.428668975830078 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3581
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 0.3150965
	speed: 0.0155s/iter; left time: 193.2984s
Epoch: 1 cost time: 1.8945281505584717
Epoch: 1, Steps: 126 Train Loss: 0.3447 (Forecasting Loss:0.3140 + XiCon Loss:3.0654 x Lambda(0.01)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2598
Validation loss decreased (inf --> 0.313167).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3418790
	speed: 0.0157s/iter; left time: 193.7221s
Epoch: 2 cost time: 1.931694507598877
Epoch: 2, Steps: 126 Train Loss: 0.3111 (Forecasting Loss:0.2803 + XiCon Loss:3.0798 x Lambda(0.01)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2848
Validation loss decreased (0.313167 --> 0.289714).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2767175
	speed: 0.0157s/iter; left time: 191.8527s
Epoch: 3 cost time: 1.949195146560669
Epoch: 3, Steps: 126 Train Loss: 0.2694 (Forecasting Loss:0.2390 + XiCon Loss:3.0475 x Lambda(0.01)), Vali MSE Loss: 0.3008 Test MSE Loss: 0.2693
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2650429
	speed: 0.0163s/iter; left time: 198.2063s
Epoch: 4 cost time: 2.0237066745758057
Epoch: 4, Steps: 126 Train Loss: 0.2486 (Forecasting Loss:0.2182 + XiCon Loss:3.0443 x Lambda(0.01)), Vali MSE Loss: 0.3097 Test MSE Loss: 0.2894
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2449086
	speed: 0.0165s/iter; left time: 198.2165s
Epoch: 5 cost time: 2.0620245933532715
Epoch: 5, Steps: 126 Train Loss: 0.2383 (Forecasting Loss:0.2079 + XiCon Loss:3.0389 x Lambda(0.01)), Vali MSE Loss: 0.3144 Test MSE Loss: 0.2840
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2329703
	speed: 0.0168s/iter; left time: 198.9090s
Epoch: 6 cost time: 2.0680863857269287
Epoch: 6, Steps: 126 Train Loss: 0.2340 (Forecasting Loss:0.2036 + XiCon Loss:3.0342 x Lambda(0.01)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.2925
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2269379
	speed: 0.0163s/iter; left time: 191.8217s
Epoch: 7 cost time: 2.067234516143799
Epoch: 7, Steps: 126 Train Loss: 0.2322 (Forecasting Loss:0.2019 + XiCon Loss:3.0325 x Lambda(0.01)), Vali MSE Loss: 0.3151 Test MSE Loss: 0.2960
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2044181
	speed: 0.0167s/iter; left time: 194.5639s
Epoch: 8 cost time: 2.0789525508880615
Epoch: 8, Steps: 126 Train Loss: 0.2310 (Forecasting Loss:0.2007 + XiCon Loss:3.0314 x Lambda(0.01)), Vali MSE Loss: 0.3141 Test MSE Loss: 0.2975
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2250477
	speed: 0.0167s/iter; left time: 192.1955s
Epoch: 9 cost time: 2.099855899810791
Epoch: 9, Steps: 126 Train Loss: 0.2304 (Forecasting Loss:0.2000 + XiCon Loss:3.0319 x Lambda(0.01)), Vali MSE Loss: 0.3154 Test MSE Loss: 0.2997
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2400120
	speed: 0.0169s/iter; left time: 191.9680s
Epoch: 10 cost time: 2.112259864807129
Epoch: 10, Steps: 126 Train Loss: 0.2302 (Forecasting Loss:0.1999 + XiCon Loss:3.0283 x Lambda(0.01)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2992
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2255613
	speed: 0.0171s/iter; left time: 191.9116s
Epoch: 11 cost time: 2.092600107192993
Epoch: 11, Steps: 126 Train Loss: 0.2301 (Forecasting Loss:0.1998 + XiCon Loss:3.0310 x Lambda(0.01)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.2994
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2399708
	speed: 0.0165s/iter; left time: 183.2248s
Epoch: 12 cost time: 2.049502372741699
Epoch: 12, Steps: 126 Train Loss: 0.2299 (Forecasting Loss:0.1996 + XiCon Loss:3.0297 x Lambda(0.01)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2995
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.20890167355537415, mae:0.3607180118560791, mape:0.8079560995101929, mspe:22.378507614135742 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2091+-0.01506, MAE:0.3637+-0.01208, MAPE:0.7672+-0.04909, MSPE:22.1721+-1.34486, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4289
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3384415
	speed: 0.0194s/iter; left time: 239.2107s
Epoch: 1 cost time: 2.340550661087036
Epoch: 1, Steps: 124 Train Loss: 0.3702 (Forecasting Loss:0.3396 + XiCon Loss:3.0596 x Lambda(0.01)), Vali MSE Loss: 0.3408 Test MSE Loss: 0.2852
Validation loss decreased (inf --> 0.340826).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2807229
	speed: 0.0208s/iter; left time: 253.0415s
Epoch: 2 cost time: 2.538588523864746
Epoch: 2, Steps: 124 Train Loss: 0.3061 (Forecasting Loss:0.2756 + XiCon Loss:3.0506 x Lambda(0.01)), Vali MSE Loss: 0.3273 Test MSE Loss: 0.3063
Validation loss decreased (0.340826 --> 0.327286).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2657056
	speed: 0.0219s/iter; left time: 263.4276s
Epoch: 3 cost time: 2.6855993270874023
Epoch: 3, Steps: 124 Train Loss: 0.2670 (Forecasting Loss:0.2369 + XiCon Loss:3.0032 x Lambda(0.01)), Vali MSE Loss: 0.2855 Test MSE Loss: 0.3061
Validation loss decreased (0.327286 --> 0.285525).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2597423
	speed: 0.0217s/iter; left time: 258.6710s
Epoch: 4 cost time: 2.663581609725952
Epoch: 4, Steps: 124 Train Loss: 0.2526 (Forecasting Loss:0.2228 + XiCon Loss:2.9814 x Lambda(0.01)), Vali MSE Loss: 0.3090 Test MSE Loss: 0.2838
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2497963
	speed: 0.0217s/iter; left time: 256.2277s
Epoch: 5 cost time: 2.6466758251190186
Epoch: 5, Steps: 124 Train Loss: 0.2457 (Forecasting Loss:0.2160 + XiCon Loss:2.9677 x Lambda(0.01)), Vali MSE Loss: 0.3143 Test MSE Loss: 0.2822
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2326539
	speed: 0.0212s/iter; left time: 247.8794s
Epoch: 6 cost time: 2.595167875289917
Epoch: 6, Steps: 124 Train Loss: 0.2424 (Forecasting Loss:0.2127 + XiCon Loss:2.9625 x Lambda(0.01)), Vali MSE Loss: 0.3150 Test MSE Loss: 0.2839
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2375529
	speed: 0.0209s/iter; left time: 241.0130s
Epoch: 7 cost time: 2.592395544052124
Epoch: 7, Steps: 124 Train Loss: 0.2408 (Forecasting Loss:0.2112 + XiCon Loss:2.9577 x Lambda(0.01)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.2796
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2219149
	speed: 0.0214s/iter; left time: 245.2071s
Epoch: 8 cost time: 2.6054022312164307
Epoch: 8, Steps: 124 Train Loss: 0.2400 (Forecasting Loss:0.2105 + XiCon Loss:2.9586 x Lambda(0.01)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2802
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2296674
	speed: 0.0214s/iter; left time: 241.5590s
Epoch: 9 cost time: 2.5991597175598145
Epoch: 9, Steps: 124 Train Loss: 0.2397 (Forecasting Loss:0.2101 + XiCon Loss:2.9581 x Lambda(0.01)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2800
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2522665
	speed: 0.0209s/iter; left time: 233.9168s
Epoch: 10 cost time: 2.589932441711426
Epoch: 10, Steps: 124 Train Loss: 0.2395 (Forecasting Loss:0.2099 + XiCon Loss:2.9561 x Lambda(0.01)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2796
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2461848
	speed: 0.0210s/iter; left time: 232.2526s
Epoch: 11 cost time: 2.5633630752563477
Epoch: 11, Steps: 124 Train Loss: 0.2391 (Forecasting Loss:0.2096 + XiCon Loss:2.9547 x Lambda(0.01)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2784
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2293405
	speed: 0.0219s/iter; left time: 239.3860s
Epoch: 12 cost time: 2.646569013595581
Epoch: 12, Steps: 124 Train Loss: 0.2392 (Forecasting Loss:0.2096 + XiCon Loss:2.9588 x Lambda(0.01)), Vali MSE Loss: 0.3207 Test MSE Loss: 0.2783
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2692111
	speed: 0.0217s/iter; left time: 234.4151s
Epoch: 13 cost time: 2.6217429637908936
Epoch: 13, Steps: 124 Train Loss: 0.2392 (Forecasting Loss:0.2096 + XiCon Loss:2.9572 x Lambda(0.01)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2785
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.22879260778427124, mae:0.3833753764629364, mape:0.8875899910926819, mspe:28.191112518310547 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3099974
	speed: 0.0173s/iter; left time: 213.2056s
Epoch: 1 cost time: 2.1022372245788574
Epoch: 1, Steps: 124 Train Loss: 0.3715 (Forecasting Loss:0.3408 + XiCon Loss:3.0769 x Lambda(0.01)), Vali MSE Loss: 0.3446 Test MSE Loss: 0.2862
Validation loss decreased (inf --> 0.344554).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2749283
	speed: 0.0168s/iter; left time: 204.5106s
Epoch: 2 cost time: 2.121128797531128
Epoch: 2, Steps: 124 Train Loss: 0.3280 (Forecasting Loss:0.2978 + XiCon Loss:3.0290 x Lambda(0.01)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2753
Validation loss decreased (0.344554 --> 0.316063).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2627767
	speed: 0.0166s/iter; left time: 200.5545s
Epoch: 3 cost time: 2.0149292945861816
Epoch: 3, Steps: 124 Train Loss: 0.2842 (Forecasting Loss:0.2544 + XiCon Loss:2.9802 x Lambda(0.01)), Vali MSE Loss: 0.3048 Test MSE Loss: 0.2770
Validation loss decreased (0.316063 --> 0.304778).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2486835
	speed: 0.0171s/iter; left time: 203.7810s
Epoch: 4 cost time: 2.0903961658477783
Epoch: 4, Steps: 124 Train Loss: 0.2592 (Forecasting Loss:0.2294 + XiCon Loss:2.9790 x Lambda(0.01)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2621
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2463638
	speed: 0.0179s/iter; left time: 211.2893s
Epoch: 5 cost time: 2.1866984367370605
Epoch: 5, Steps: 124 Train Loss: 0.2504 (Forecasting Loss:0.2207 + XiCon Loss:2.9726 x Lambda(0.01)), Vali MSE Loss: 0.3108 Test MSE Loss: 0.2677
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2573984
	speed: 0.0172s/iter; left time: 201.4150s
Epoch: 6 cost time: 2.0954782962799072
Epoch: 6, Steps: 124 Train Loss: 0.2467 (Forecasting Loss:0.2170 + XiCon Loss:2.9711 x Lambda(0.01)), Vali MSE Loss: 0.3025 Test MSE Loss: 0.2649
Validation loss decreased (0.304778 --> 0.302531).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2347907
	speed: 0.0173s/iter; left time: 199.5056s
Epoch: 7 cost time: 2.087317705154419
Epoch: 7, Steps: 124 Train Loss: 0.2444 (Forecasting Loss:0.2147 + XiCon Loss:2.9673 x Lambda(0.01)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.2746
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2366234
	speed: 0.0172s/iter; left time: 196.7376s
Epoch: 8 cost time: 2.093003273010254
Epoch: 8, Steps: 124 Train Loss: 0.2436 (Forecasting Loss:0.2140 + XiCon Loss:2.9675 x Lambda(0.01)), Vali MSE Loss: 0.3126 Test MSE Loss: 0.2760
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2310186
	speed: 0.0165s/iter; left time: 186.8960s
Epoch: 9 cost time: 2.0340688228607178
Epoch: 9, Steps: 124 Train Loss: 0.2430 (Forecasting Loss:0.2133 + XiCon Loss:2.9684 x Lambda(0.01)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.2752
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2704391
	speed: 0.0169s/iter; left time: 189.0563s
Epoch: 10 cost time: 2.0948073863983154
Epoch: 10, Steps: 124 Train Loss: 0.2426 (Forecasting Loss:0.2130 + XiCon Loss:2.9668 x Lambda(0.01)), Vali MSE Loss: 0.3118 Test MSE Loss: 0.2747
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2521390
	speed: 0.0175s/iter; left time: 193.4222s
Epoch: 11 cost time: 2.1542651653289795
Epoch: 11, Steps: 124 Train Loss: 0.2428 (Forecasting Loss:0.2131 + XiCon Loss:2.9684 x Lambda(0.01)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.2755
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2647909
	speed: 0.0169s/iter; left time: 184.8267s
Epoch: 12 cost time: 2.066204786300659
Epoch: 12, Steps: 124 Train Loss: 0.2425 (Forecasting Loss:0.2128 + XiCon Loss:2.9666 x Lambda(0.01)), Vali MSE Loss: 0.3115 Test MSE Loss: 0.2756
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2402638
	speed: 0.0171s/iter; left time: 184.4010s
Epoch: 13 cost time: 2.118962287902832
Epoch: 13, Steps: 124 Train Loss: 0.2423 (Forecasting Loss:0.2127 + XiCon Loss:2.9674 x Lambda(0.01)), Vali MSE Loss: 0.3111 Test MSE Loss: 0.2753
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2337353
	speed: 0.0174s/iter; left time: 185.9737s
Epoch: 14 cost time: 2.1171982288360596
Epoch: 14, Steps: 124 Train Loss: 0.2424 (Forecasting Loss:0.2127 + XiCon Loss:2.9702 x Lambda(0.01)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.2752
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2535243
	speed: 0.0172s/iter; left time: 181.9106s
Epoch: 15 cost time: 2.107468605041504
Epoch: 15, Steps: 124 Train Loss: 0.2425 (Forecasting Loss:0.2128 + XiCon Loss:2.9648 x Lambda(0.01)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2752
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2364562
	speed: 0.0171s/iter; left time: 178.2982s
Epoch: 16 cost time: 2.073513984680176
Epoch: 16, Steps: 124 Train Loss: 0.2425 (Forecasting Loss:0.2128 + XiCon Loss:2.9674 x Lambda(0.01)), Vali MSE Loss: 0.3112 Test MSE Loss: 0.2752
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1844366043806076, mae:0.3452959656715393, mape:0.7319145202636719, mspe:18.68048667907715 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3238
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3117967
	speed: 0.0169s/iter; left time: 207.8132s
Epoch: 1 cost time: 2.0655412673950195
Epoch: 1, Steps: 124 Train Loss: 0.3681 (Forecasting Loss:0.3376 + XiCon Loss:3.0455 x Lambda(0.01)), Vali MSE Loss: 0.3410 Test MSE Loss: 0.2793
Validation loss decreased (inf --> 0.341034).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2985659
	speed: 0.0172s/iter; left time: 209.2854s
Epoch: 2 cost time: 2.1663262844085693
Epoch: 2, Steps: 124 Train Loss: 0.3287 (Forecasting Loss:0.2984 + XiCon Loss:3.0221 x Lambda(0.01)), Vali MSE Loss: 0.3304 Test MSE Loss: 0.2872
Validation loss decreased (0.341034 --> 0.330444).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2737698
	speed: 0.0197s/iter; left time: 236.9022s
Epoch: 3 cost time: 2.444902181625366
Epoch: 3, Steps: 124 Train Loss: 0.2827 (Forecasting Loss:0.2526 + XiCon Loss:3.0121 x Lambda(0.01)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.3226
Validation loss decreased (0.330444 --> 0.291612).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2511096
	speed: 0.0209s/iter; left time: 248.7927s
Epoch: 4 cost time: 2.5144858360290527
Epoch: 4, Steps: 124 Train Loss: 0.2593 (Forecasting Loss:0.2292 + XiCon Loss:3.0142 x Lambda(0.01)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.3396
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2571807
	speed: 0.0204s/iter; left time: 240.5261s
Epoch: 5 cost time: 2.4858005046844482
Epoch: 5, Steps: 124 Train Loss: 0.2520 (Forecasting Loss:0.2219 + XiCon Loss:3.0106 x Lambda(0.01)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.3494
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2572277
	speed: 0.0204s/iter; left time: 238.1999s
Epoch: 6 cost time: 2.5100061893463135
Epoch: 6, Steps: 124 Train Loss: 0.2488 (Forecasting Loss:0.2187 + XiCon Loss:3.0073 x Lambda(0.01)), Vali MSE Loss: 0.3140 Test MSE Loss: 0.3621
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2598349
	speed: 0.0205s/iter; left time: 236.7214s
Epoch: 7 cost time: 2.5113189220428467
Epoch: 7, Steps: 124 Train Loss: 0.2471 (Forecasting Loss:0.2170 + XiCon Loss:3.0057 x Lambda(0.01)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.3605
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2395813
	speed: 0.0208s/iter; left time: 237.3482s
Epoch: 8 cost time: 2.529202699661255
Epoch: 8, Steps: 124 Train Loss: 0.2459 (Forecasting Loss:0.2159 + XiCon Loss:3.0031 x Lambda(0.01)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.3613
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2436320
	speed: 0.0203s/iter; left time: 230.0787s
Epoch: 9 cost time: 2.505397319793701
Epoch: 9, Steps: 124 Train Loss: 0.2455 (Forecasting Loss:0.2155 + XiCon Loss:3.0025 x Lambda(0.01)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.3631
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2462530
	speed: 0.0206s/iter; left time: 230.3454s
Epoch: 10 cost time: 2.5008721351623535
Epoch: 10, Steps: 124 Train Loss: 0.2455 (Forecasting Loss:0.2155 + XiCon Loss:3.0027 x Lambda(0.01)), Vali MSE Loss: 0.3198 Test MSE Loss: 0.3640
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2396577
	speed: 0.0202s/iter; left time: 223.7439s
Epoch: 11 cost time: 2.464045524597168
Epoch: 11, Steps: 124 Train Loss: 0.2451 (Forecasting Loss:0.2151 + XiCon Loss:3.0026 x Lambda(0.01)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.3643
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2466588
	speed: 0.0211s/iter; left time: 230.9461s
Epoch: 12 cost time: 2.5757691860198975
Epoch: 12, Steps: 124 Train Loss: 0.2451 (Forecasting Loss:0.2151 + XiCon Loss:3.0005 x Lambda(0.01)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.3641
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2347462
	speed: 0.0206s/iter; left time: 222.5519s
Epoch: 13 cost time: 2.5300965309143066
Epoch: 13, Steps: 124 Train Loss: 0.2451 (Forecasting Loss:0.2150 + XiCon Loss:3.0028 x Lambda(0.01)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.3643
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.24842102825641632, mae:0.3967711329460144, mape:0.7211226224899292, mspe:19.40892791748047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3225
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3940649
	speed: 0.0184s/iter; left time: 226.2044s
Epoch: 1 cost time: 2.2106053829193115
Epoch: 1, Steps: 124 Train Loss: 0.3662 (Forecasting Loss:0.3357 + XiCon Loss:3.0505 x Lambda(0.01)), Vali MSE Loss: 0.3403 Test MSE Loss: 0.2804
Validation loss decreased (inf --> 0.340296).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2918387
	speed: 0.0182s/iter; left time: 221.7007s
Epoch: 2 cost time: 2.278778314590454
Epoch: 2, Steps: 124 Train Loss: 0.3133 (Forecasting Loss:0.2829 + XiCon Loss:3.0469 x Lambda(0.01)), Vali MSE Loss: 0.2995 Test MSE Loss: 0.2905
Validation loss decreased (0.340296 --> 0.299457).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2616301
	speed: 0.0220s/iter; left time: 265.3266s
Epoch: 3 cost time: 2.653986692428589
Epoch: 3, Steps: 124 Train Loss: 0.2667 (Forecasting Loss:0.2366 + XiCon Loss:3.0139 x Lambda(0.01)), Vali MSE Loss: 0.3142 Test MSE Loss: 0.3089
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2243362
	speed: 0.0209s/iter; left time: 248.9208s
Epoch: 4 cost time: 2.561628580093384
Epoch: 4, Steps: 124 Train Loss: 0.2497 (Forecasting Loss:0.2197 + XiCon Loss:2.9984 x Lambda(0.01)), Vali MSE Loss: 0.3281 Test MSE Loss: 0.3038
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2160939
	speed: 0.0211s/iter; left time: 249.1258s
Epoch: 5 cost time: 2.5619142055511475
Epoch: 5, Steps: 124 Train Loss: 0.2434 (Forecasting Loss:0.2135 + XiCon Loss:2.9892 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.3034
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2435956
	speed: 0.0209s/iter; left time: 244.5335s
Epoch: 6 cost time: 2.586961269378662
Epoch: 6, Steps: 124 Train Loss: 0.2412 (Forecasting Loss:0.2113 + XiCon Loss:2.9877 x Lambda(0.01)), Vali MSE Loss: 0.3292 Test MSE Loss: 0.3122
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2585396
	speed: 0.0210s/iter; left time: 242.6739s
Epoch: 7 cost time: 2.5579495429992676
Epoch: 7, Steps: 124 Train Loss: 0.2396 (Forecasting Loss:0.2097 + XiCon Loss:2.9863 x Lambda(0.01)), Vali MSE Loss: 0.3284 Test MSE Loss: 0.3120
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2532198
	speed: 0.0210s/iter; left time: 240.1172s
Epoch: 8 cost time: 2.578559160232544
Epoch: 8, Steps: 124 Train Loss: 0.2392 (Forecasting Loss:0.2094 + XiCon Loss:2.9850 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.3091
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2457662
	speed: 0.0203s/iter; left time: 230.0146s
Epoch: 9 cost time: 2.49853253364563
Epoch: 9, Steps: 124 Train Loss: 0.2384 (Forecasting Loss:0.2085 + XiCon Loss:2.9836 x Lambda(0.01)), Vali MSE Loss: 0.3281 Test MSE Loss: 0.3104
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2322828
	speed: 0.0210s/iter; left time: 235.2111s
Epoch: 10 cost time: 2.570826292037964
Epoch: 10, Steps: 124 Train Loss: 0.2384 (Forecasting Loss:0.2086 + XiCon Loss:2.9822 x Lambda(0.01)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.3090
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2378684
	speed: 0.0216s/iter; left time: 239.4158s
Epoch: 11 cost time: 2.6331570148468018
Epoch: 11, Steps: 124 Train Loss: 0.2381 (Forecasting Loss:0.2082 + XiCon Loss:2.9844 x Lambda(0.01)), Vali MSE Loss: 0.3285 Test MSE Loss: 0.3102
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2385827
	speed: 0.0215s/iter; left time: 235.2096s
Epoch: 12 cost time: 2.6583433151245117
Epoch: 12, Steps: 124 Train Loss: 0.2382 (Forecasting Loss:0.2083 + XiCon Loss:2.9823 x Lambda(0.01)), Vali MSE Loss: 0.3287 Test MSE Loss: 0.3095
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.21020640432834625, mae:0.3707313537597656, mape:0.8356566429138184, mspe:23.825927734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3031
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 0.3732791
	speed: 0.0172s/iter; left time: 211.6197s
Epoch: 1 cost time: 2.142448663711548
Epoch: 1, Steps: 124 Train Loss: 0.3679 (Forecasting Loss:0.3375 + XiCon Loss:3.0394 x Lambda(0.01)), Vali MSE Loss: 0.3410 Test MSE Loss: 0.2847
Validation loss decreased (inf --> 0.340994).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3038320
	speed: 0.0195s/iter; left time: 237.7942s
Epoch: 2 cost time: 2.377962112426758
Epoch: 2, Steps: 124 Train Loss: 0.3195 (Forecasting Loss:0.2894 + XiCon Loss:3.0048 x Lambda(0.01)), Vali MSE Loss: 0.3092 Test MSE Loss: 0.2953
Validation loss decreased (0.340994 --> 0.309225).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2564986
	speed: 0.0185s/iter; left time: 222.4873s
Epoch: 3 cost time: 2.279212474822998
Epoch: 3, Steps: 124 Train Loss: 0.2775 (Forecasting Loss:0.2475 + XiCon Loss:2.9973 x Lambda(0.01)), Vali MSE Loss: 0.3328 Test MSE Loss: 0.2909
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2667260
	speed: 0.0200s/iter; left time: 238.5921s
Epoch: 4 cost time: 2.42781662940979
Epoch: 4, Steps: 124 Train Loss: 0.2594 (Forecasting Loss:0.2293 + XiCon Loss:3.0102 x Lambda(0.01)), Vali MSE Loss: 0.3080 Test MSE Loss: 0.2691
Validation loss decreased (0.309225 --> 0.308040).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2490970
	speed: 0.0200s/iter; left time: 236.6667s
Epoch: 5 cost time: 2.438011884689331
Epoch: 5, Steps: 124 Train Loss: 0.2509 (Forecasting Loss:0.2207 + XiCon Loss:3.0243 x Lambda(0.01)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2695
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2375685
	speed: 0.0204s/iter; left time: 238.5199s
Epoch: 6 cost time: 2.506697654724121
Epoch: 6, Steps: 124 Train Loss: 0.2473 (Forecasting Loss:0.2169 + XiCon Loss:3.0350 x Lambda(0.01)), Vali MSE Loss: 0.3264 Test MSE Loss: 0.2721
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2403875
	speed: 0.0207s/iter; left time: 239.6546s
Epoch: 7 cost time: 2.521986484527588
Epoch: 7, Steps: 124 Train Loss: 0.2456 (Forecasting Loss:0.2152 + XiCon Loss:3.0379 x Lambda(0.01)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2713
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2407881
	speed: 0.0204s/iter; left time: 233.0638s
Epoch: 8 cost time: 2.5101428031921387
Epoch: 8, Steps: 124 Train Loss: 0.2446 (Forecasting Loss:0.2142 + XiCon Loss:3.0399 x Lambda(0.01)), Vali MSE Loss: 0.3155 Test MSE Loss: 0.2717
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2319720
	speed: 0.0209s/iter; left time: 235.9418s
Epoch: 9 cost time: 2.5369815826416016
Epoch: 9, Steps: 124 Train Loss: 0.2441 (Forecasting Loss:0.2138 + XiCon Loss:3.0370 x Lambda(0.01)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2713
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2542482
	speed: 0.0203s/iter; left time: 227.0132s
Epoch: 10 cost time: 2.4720029830932617
Epoch: 10, Steps: 124 Train Loss: 0.2439 (Forecasting Loss:0.2135 + XiCon Loss:3.0382 x Lambda(0.01)), Vali MSE Loss: 0.3172 Test MSE Loss: 0.2709
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2441155
	speed: 0.0206s/iter; left time: 227.3727s
Epoch: 11 cost time: 2.5231571197509766
Epoch: 11, Steps: 124 Train Loss: 0.2439 (Forecasting Loss:0.2134 + XiCon Loss:3.0439 x Lambda(0.01)), Vali MSE Loss: 0.3179 Test MSE Loss: 0.2708
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2505344
	speed: 0.0202s/iter; left time: 221.1497s
Epoch: 12 cost time: 2.4807658195495605
Epoch: 12, Steps: 124 Train Loss: 0.2438 (Forecasting Loss:0.2133 + XiCon Loss:3.0418 x Lambda(0.01)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2709
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2492860
	speed: 0.0198s/iter; left time: 214.1723s
Epoch: 13 cost time: 2.4076781272888184
Epoch: 13, Steps: 124 Train Loss: 0.2438 (Forecasting Loss:0.2134 + XiCon Loss:3.0383 x Lambda(0.01)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2711
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2461684
	speed: 0.0209s/iter; left time: 223.0560s
Epoch: 14 cost time: 2.5352118015289307
Epoch: 14, Steps: 124 Train Loss: 0.2436 (Forecasting Loss:0.2132 + XiCon Loss:3.0436 x Lambda(0.01)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2711
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18515264987945557, mae:0.3530288338661194, mape:0.8378981351852417, mspe:24.90226173400879 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.2114+-0.03451, MAE:0.3698+-0.02630, MAPE:0.8028+-0.09039, MSPE:23.0017+-4.91997, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.4238
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4837357
	speed: 0.0207s/iter; left time: 242.3384s
Epoch: 1 cost time: 2.3671517372131348
Epoch: 1, Steps: 118 Train Loss: 0.5050 (Forecasting Loss:0.4735 + XiCon Loss:3.1492 x Lambda(0.01)), Vali MSE Loss: 0.4756 Test MSE Loss: 0.3610
Validation loss decreased (inf --> 0.475563).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3991278
	speed: 0.0183s/iter; left time: 211.8356s
Epoch: 2 cost time: 2.1177031993865967
Epoch: 2, Steps: 118 Train Loss: 0.3779 (Forecasting Loss:0.3465 + XiCon Loss:3.1384 x Lambda(0.01)), Vali MSE Loss: 0.3776 Test MSE Loss: 0.2878
Validation loss decreased (0.475563 --> 0.377617).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3346145
	speed: 0.0183s/iter; left time: 209.6832s
Epoch: 3 cost time: 2.140822172164917
Epoch: 3, Steps: 118 Train Loss: 0.3416 (Forecasting Loss:0.3103 + XiCon Loss:3.1310 x Lambda(0.01)), Vali MSE Loss: 0.3732 Test MSE Loss: 0.2783
Validation loss decreased (0.377617 --> 0.373248).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3472011
	speed: 0.0178s/iter; left time: 202.2261s
Epoch: 4 cost time: 2.094247579574585
Epoch: 4, Steps: 118 Train Loss: 0.3368 (Forecasting Loss:0.3055 + XiCon Loss:3.1263 x Lambda(0.01)), Vali MSE Loss: 0.3749 Test MSE Loss: 0.2803
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3392429
	speed: 0.0173s/iter; left time: 194.1565s
Epoch: 5 cost time: 2.0272786617279053
Epoch: 5, Steps: 118 Train Loss: 0.3346 (Forecasting Loss:0.3034 + XiCon Loss:3.1246 x Lambda(0.01)), Vali MSE Loss: 0.3830 Test MSE Loss: 0.2815
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3185963
	speed: 0.0178s/iter; left time: 197.2481s
Epoch: 6 cost time: 2.070162057876587
Epoch: 6, Steps: 118 Train Loss: 0.3336 (Forecasting Loss:0.3023 + XiCon Loss:3.1266 x Lambda(0.01)), Vali MSE Loss: 0.3786 Test MSE Loss: 0.2806
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3367908
	speed: 0.0175s/iter; left time: 192.7143s
Epoch: 7 cost time: 2.0379276275634766
Epoch: 7, Steps: 118 Train Loss: 0.3337 (Forecasting Loss:0.3025 + XiCon Loss:3.1250 x Lambda(0.01)), Vali MSE Loss: 0.3759 Test MSE Loss: 0.2809
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3178214
	speed: 0.0178s/iter; left time: 193.3876s
Epoch: 8 cost time: 2.0655457973480225
Epoch: 8, Steps: 118 Train Loss: 0.3327 (Forecasting Loss:0.3015 + XiCon Loss:3.1257 x Lambda(0.01)), Vali MSE Loss: 0.3754 Test MSE Loss: 0.2812
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3310211
	speed: 0.0174s/iter; left time: 187.1216s
Epoch: 9 cost time: 2.0460243225097656
Epoch: 9, Steps: 118 Train Loss: 0.3330 (Forecasting Loss:0.3017 + XiCon Loss:3.1261 x Lambda(0.01)), Vali MSE Loss: 0.3769 Test MSE Loss: 0.2812
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3344790
	speed: 0.0169s/iter; left time: 180.0405s
Epoch: 10 cost time: 1.978886604309082
Epoch: 10, Steps: 118 Train Loss: 0.3329 (Forecasting Loss:0.3016 + XiCon Loss:3.1262 x Lambda(0.01)), Vali MSE Loss: 0.3772 Test MSE Loss: 0.2812
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3240867
	speed: 0.0178s/iter; left time: 187.6362s
Epoch: 11 cost time: 2.072643518447876
Epoch: 11, Steps: 118 Train Loss: 0.3330 (Forecasting Loss:0.3017 + XiCon Loss:3.1264 x Lambda(0.01)), Vali MSE Loss: 0.3763 Test MSE Loss: 0.2812
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3446037
	speed: 0.0179s/iter; left time: 186.2564s
Epoch: 12 cost time: 2.113954782485962
Epoch: 12, Steps: 118 Train Loss: 0.3329 (Forecasting Loss:0.3016 + XiCon Loss:3.1277 x Lambda(0.01)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2812
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3217084
	speed: 0.0176s/iter; left time: 181.3296s
Epoch: 13 cost time: 2.065284490585327
Epoch: 13, Steps: 118 Train Loss: 0.3327 (Forecasting Loss:0.3015 + XiCon Loss:3.1246 x Lambda(0.01)), Vali MSE Loss: 0.3766 Test MSE Loss: 0.2812
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.198531374335289, mae:0.3580789566040039, mape:0.6948713064193726, mspe:23.45722007751465 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3310
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4649489
	speed: 0.0171s/iter; left time: 199.8408s
Epoch: 1 cost time: 2.0087623596191406
Epoch: 1, Steps: 118 Train Loss: 0.5001 (Forecasting Loss:0.4685 + XiCon Loss:3.1572 x Lambda(0.01)), Vali MSE Loss: 0.4890 Test MSE Loss: 0.3765
Validation loss decreased (inf --> 0.488979).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3282981
	speed: 0.0174s/iter; left time: 201.5895s
Epoch: 2 cost time: 2.0437300205230713
Epoch: 2, Steps: 118 Train Loss: 0.3761 (Forecasting Loss:0.3445 + XiCon Loss:3.1540 x Lambda(0.01)), Vali MSE Loss: 0.3567 Test MSE Loss: 0.2711
Validation loss decreased (0.488979 --> 0.356739).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3158836
	speed: 0.0178s/iter; left time: 204.2839s
Epoch: 3 cost time: 2.0860695838928223
Epoch: 3, Steps: 118 Train Loss: 0.3105 (Forecasting Loss:0.2790 + XiCon Loss:3.1569 x Lambda(0.01)), Vali MSE Loss: 0.3280 Test MSE Loss: 0.2657
Validation loss decreased (0.356739 --> 0.327973).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2889638
	speed: 0.0177s/iter; left time: 201.3522s
Epoch: 4 cost time: 2.114560842514038
Epoch: 4, Steps: 118 Train Loss: 0.3031 (Forecasting Loss:0.2716 + XiCon Loss:3.1513 x Lambda(0.01)), Vali MSE Loss: 0.3313 Test MSE Loss: 0.2646
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3010046
	speed: 0.0183s/iter; left time: 204.9497s
Epoch: 5 cost time: 2.1274333000183105
Epoch: 5, Steps: 118 Train Loss: 0.3002 (Forecasting Loss:0.2688 + XiCon Loss:3.1480 x Lambda(0.01)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2640
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2861103
	speed: 0.0183s/iter; left time: 203.7276s
Epoch: 6 cost time: 2.139460325241089
Epoch: 6, Steps: 118 Train Loss: 0.2985 (Forecasting Loss:0.2670 + XiCon Loss:3.1468 x Lambda(0.01)), Vali MSE Loss: 0.3298 Test MSE Loss: 0.2647
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3011980
	speed: 0.0180s/iter; left time: 197.9870s
Epoch: 7 cost time: 2.0955657958984375
Epoch: 7, Steps: 118 Train Loss: 0.2977 (Forecasting Loss:0.2662 + XiCon Loss:3.1452 x Lambda(0.01)), Vali MSE Loss: 0.3294 Test MSE Loss: 0.2648
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2870432
	speed: 0.0184s/iter; left time: 199.9295s
Epoch: 8 cost time: 2.1406021118164062
Epoch: 8, Steps: 118 Train Loss: 0.2973 (Forecasting Loss:0.2659 + XiCon Loss:3.1457 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2651
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2817597
	speed: 0.0180s/iter; left time: 193.8743s
Epoch: 9 cost time: 2.111168384552002
Epoch: 9, Steps: 118 Train Loss: 0.2974 (Forecasting Loss:0.2659 + XiCon Loss:3.1455 x Lambda(0.01)), Vali MSE Loss: 0.3293 Test MSE Loss: 0.2646
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3024323
	speed: 0.0184s/iter; left time: 195.3351s
Epoch: 10 cost time: 2.137974262237549
Epoch: 10, Steps: 118 Train Loss: 0.2974 (Forecasting Loss:0.2659 + XiCon Loss:3.1447 x Lambda(0.01)), Vali MSE Loss: 0.3298 Test MSE Loss: 0.2649
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3093977
	speed: 0.0184s/iter; left time: 194.0451s
Epoch: 11 cost time: 2.1675350666046143
Epoch: 11, Steps: 118 Train Loss: 0.2969 (Forecasting Loss:0.2655 + XiCon Loss:3.1455 x Lambda(0.01)), Vali MSE Loss: 0.3301 Test MSE Loss: 0.2649
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2850183
	speed: 0.0183s/iter; left time: 189.9206s
Epoch: 12 cost time: 2.1352436542510986
Epoch: 12, Steps: 118 Train Loss: 0.2969 (Forecasting Loss:0.2655 + XiCon Loss:3.1468 x Lambda(0.01)), Vali MSE Loss: 0.3297 Test MSE Loss: 0.2649
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3148064
	speed: 0.0193s/iter; left time: 198.3217s
Epoch: 13 cost time: 2.258331775665283
Epoch: 13, Steps: 118 Train Loss: 0.2969 (Forecasting Loss:0.2654 + XiCon Loss:3.1463 x Lambda(0.01)), Vali MSE Loss: 0.3298 Test MSE Loss: 0.2648
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18395870923995972, mae:0.34739598631858826, mape:0.6799800395965576, mspe:18.72870635986328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2942
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4406547
	speed: 0.0179s/iter; left time: 209.3538s
Epoch: 1 cost time: 2.0877163410186768
Epoch: 1, Steps: 118 Train Loss: 0.5007 (Forecasting Loss:0.4692 + XiCon Loss:3.1552 x Lambda(0.01)), Vali MSE Loss: 0.4668 Test MSE Loss: 0.3445
Validation loss decreased (inf --> 0.466846).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3244957
	speed: 0.0177s/iter; left time: 204.8916s
Epoch: 2 cost time: 2.0760278701782227
Epoch: 2, Steps: 118 Train Loss: 0.3686 (Forecasting Loss:0.3373 + XiCon Loss:3.1305 x Lambda(0.01)), Vali MSE Loss: 0.3339 Test MSE Loss: 0.2666
Validation loss decreased (0.466846 --> 0.333941).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2747708
	speed: 0.0181s/iter; left time: 207.4823s
Epoch: 3 cost time: 2.144672393798828
Epoch: 3, Steps: 118 Train Loss: 0.3084 (Forecasting Loss:0.2771 + XiCon Loss:3.1280 x Lambda(0.01)), Vali MSE Loss: 0.3127 Test MSE Loss: 0.2598
Validation loss decreased (0.333941 --> 0.312681).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3060741
	speed: 0.0175s/iter; left time: 198.8509s
Epoch: 4 cost time: 2.049220561981201
Epoch: 4, Steps: 118 Train Loss: 0.3010 (Forecasting Loss:0.2698 + XiCon Loss:3.1214 x Lambda(0.01)), Vali MSE Loss: 0.3095 Test MSE Loss: 0.2578
Validation loss decreased (0.312681 --> 0.309527).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2858211
	speed: 0.0181s/iter; left time: 203.1854s
Epoch: 5 cost time: 2.1185638904571533
Epoch: 5, Steps: 118 Train Loss: 0.2977 (Forecasting Loss:0.2665 + XiCon Loss:3.1170 x Lambda(0.01)), Vali MSE Loss: 0.3076 Test MSE Loss: 0.2591
Validation loss decreased (0.309527 --> 0.307587).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2960227
	speed: 0.0183s/iter; left time: 203.5927s
Epoch: 6 cost time: 2.132805109024048
Epoch: 6, Steps: 118 Train Loss: 0.2966 (Forecasting Loss:0.2655 + XiCon Loss:3.1174 x Lambda(0.01)), Vali MSE Loss: 0.3082 Test MSE Loss: 0.2599
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2957391
	speed: 0.0184s/iter; left time: 202.7534s
Epoch: 7 cost time: 2.153571605682373
Epoch: 7, Steps: 118 Train Loss: 0.2957 (Forecasting Loss:0.2645 + XiCon Loss:3.1164 x Lambda(0.01)), Vali MSE Loss: 0.3089 Test MSE Loss: 0.2603
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2897863
	speed: 0.0183s/iter; left time: 199.2813s
Epoch: 8 cost time: 2.1408262252807617
Epoch: 8, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2639 + XiCon Loss:3.1152 x Lambda(0.01)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2591
Validation loss decreased (0.307587 --> 0.306213).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3117040
	speed: 0.0184s/iter; left time: 197.6199s
Epoch: 9 cost time: 2.142868757247925
Epoch: 9, Steps: 118 Train Loss: 0.2953 (Forecasting Loss:0.2641 + XiCon Loss:3.1162 x Lambda(0.01)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.2593
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2925822
	speed: 0.0185s/iter; left time: 196.3999s
Epoch: 10 cost time: 2.1600849628448486
Epoch: 10, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2639 + XiCon Loss:3.1160 x Lambda(0.01)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.2592
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2866780
	speed: 0.0185s/iter; left time: 195.0489s
Epoch: 11 cost time: 2.165449380874634
Epoch: 11, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2639 + XiCon Loss:3.1137 x Lambda(0.01)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2592
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2998344
	speed: 0.0189s/iter; left time: 196.8563s
Epoch: 12 cost time: 2.2071173191070557
Epoch: 12, Steps: 118 Train Loss: 0.2953 (Forecasting Loss:0.2641 + XiCon Loss:3.1166 x Lambda(0.01)), Vali MSE Loss: 0.3067 Test MSE Loss: 0.2592
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2946110
	speed: 0.0183s/iter; left time: 188.3151s
Epoch: 13 cost time: 2.145273208618164
Epoch: 13, Steps: 118 Train Loss: 0.2948 (Forecasting Loss:0.2637 + XiCon Loss:3.1168 x Lambda(0.01)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2592
Validation loss decreased (0.306213 --> 0.306156).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2988001
	speed: 0.0182s/iter; left time: 185.2657s
Epoch: 14 cost time: 2.1388328075408936
Epoch: 14, Steps: 118 Train Loss: 0.2953 (Forecasting Loss:0.2641 + XiCon Loss:3.1156 x Lambda(0.01)), Vali MSE Loss: 0.3067 Test MSE Loss: 0.2592
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3044407
	speed: 0.0183s/iter; left time: 183.9080s
Epoch: 15 cost time: 2.1664888858795166
Epoch: 15, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2638 + XiCon Loss:3.1144 x Lambda(0.01)), Vali MSE Loss: 0.3068 Test MSE Loss: 0.2592
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3337167
	speed: 0.0187s/iter; left time: 185.3744s
Epoch: 16 cost time: 2.1795787811279297
Epoch: 16, Steps: 118 Train Loss: 0.2949 (Forecasting Loss:0.2638 + XiCon Loss:3.1160 x Lambda(0.01)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2592
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2698389
	speed: 0.0176s/iter; left time: 173.0887s
Epoch: 17 cost time: 2.0653347969055176
Epoch: 17, Steps: 118 Train Loss: 0.2952 (Forecasting Loss:0.2640 + XiCon Loss:3.1151 x Lambda(0.01)), Vali MSE Loss: 0.3065 Test MSE Loss: 0.2592
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2990799
	speed: 0.0183s/iter; left time: 177.0506s
Epoch: 18 cost time: 2.123162269592285
Epoch: 18, Steps: 118 Train Loss: 0.2951 (Forecasting Loss:0.2639 + XiCon Loss:3.1165 x Lambda(0.01)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.2592
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3037735
	speed: 0.0184s/iter; left time: 175.8528s
Epoch: 19 cost time: 2.138115644454956
Epoch: 19, Steps: 118 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1158 x Lambda(0.01)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2592
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.2886330
	speed: 0.0186s/iter; left time: 175.4754s
Epoch: 20 cost time: 2.183133602142334
Epoch: 20, Steps: 118 Train Loss: 0.2947 (Forecasting Loss:0.2635 + XiCon Loss:3.1153 x Lambda(0.01)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2592
Validation loss decreased (0.306156 --> 0.306018).  Saving model ...
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.2991256
	speed: 0.0187s/iter; left time: 174.6908s
Epoch: 21 cost time: 2.1785311698913574
Epoch: 21, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2639 + XiCon Loss:3.1157 x Lambda(0.01)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.2592
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.2996278
	speed: 0.0186s/iter; left time: 171.2852s
Epoch: 22 cost time: 2.161120891571045
Epoch: 22, Steps: 118 Train Loss: 0.2954 (Forecasting Loss:0.2642 + XiCon Loss:3.1157 x Lambda(0.01)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2592
Validation loss decreased (0.306018 --> 0.306008).  Saving model ...
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.2863372
	speed: 0.0182s/iter; left time: 165.3202s
Epoch: 23 cost time: 2.1265270709991455
Epoch: 23, Steps: 118 Train Loss: 0.2954 (Forecasting Loss:0.2642 + XiCon Loss:3.1143 x Lambda(0.01)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.2592
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.2885242
	speed: 0.0186s/iter; left time: 167.4846s
Epoch: 24 cost time: 2.1700315475463867
Epoch: 24, Steps: 118 Train Loss: 0.2949 (Forecasting Loss:0.2637 + XiCon Loss:3.1166 x Lambda(0.01)), Vali MSE Loss: 0.3063 Test MSE Loss: 0.2592
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.3035295
	speed: 0.0186s/iter; left time: 164.6231s
Epoch: 25 cost time: 2.188126564025879
Epoch: 25, Steps: 118 Train Loss: 0.2952 (Forecasting Loss:0.2640 + XiCon Loss:3.1182 x Lambda(0.01)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2592
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.2873331
	speed: 0.0180s/iter; left time: 157.9289s
Epoch: 26 cost time: 2.1038894653320312
Epoch: 26, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2639 + XiCon Loss:3.1170 x Lambda(0.01)), Vali MSE Loss: 0.3062 Test MSE Loss: 0.2592
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 27 | loss: 0.2962998
	speed: 0.0190s/iter; left time: 164.0722s
Epoch: 27 cost time: 2.2086915969848633
Epoch: 27, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2639 + XiCon Loss:3.1154 x Lambda(0.01)), Vali MSE Loss: 0.3064 Test MSE Loss: 0.2592
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 28 | loss: 0.2769824
	speed: 0.0183s/iter; left time: 155.8599s
Epoch: 28 cost time: 2.174212694168091
Epoch: 28, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2638 + XiCon Loss:3.1175 x Lambda(0.01)), Vali MSE Loss: 0.3069 Test MSE Loss: 0.2592
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 29 | loss: 0.3088003
	speed: 0.0179s/iter; left time: 150.3024s
Epoch: 29 cost time: 2.0890417098999023
Epoch: 29, Steps: 118 Train Loss: 0.2950 (Forecasting Loss:0.2638 + XiCon Loss:3.1171 x Lambda(0.01)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.2592
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 30 | loss: 0.3019117
	speed: 0.0185s/iter; left time: 152.8269s
Epoch: 30 cost time: 2.155322551727295
Epoch: 30, Steps: 118 Train Loss: 0.2947 (Forecasting Loss:0.2636 + XiCon Loss:3.1168 x Lambda(0.01)), Vali MSE Loss: 0.3067 Test MSE Loss: 0.2592
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 31 | loss: 0.3150596
	speed: 0.0187s/iter; left time: 152.6792s
Epoch: 31 cost time: 2.1756649017333984
Epoch: 31, Steps: 118 Train Loss: 0.2952 (Forecasting Loss:0.2641 + XiCon Loss:3.1157 x Lambda(0.01)), Vali MSE Loss: 0.3066 Test MSE Loss: 0.2592
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 32 | loss: 0.2789566
	speed: 0.0183s/iter; left time: 147.0263s
Epoch: 32 cost time: 2.165769338607788
Epoch: 32, Steps: 118 Train Loss: 0.2948 (Forecasting Loss:0.2637 + XiCon Loss:3.1166 x Lambda(0.01)), Vali MSE Loss: 0.3061 Test MSE Loss: 0.2592
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.17584386467933655, mae:0.3425549566745758, mape:0.6772817969322205, mspe:19.401811599731445 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3887
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4740395
	speed: 0.0177s/iter; left time: 207.4217s
Epoch: 1 cost time: 2.075856924057007
Epoch: 1, Steps: 118 Train Loss: 0.4957 (Forecasting Loss:0.4642 + XiCon Loss:3.1467 x Lambda(0.01)), Vali MSE Loss: 0.4730 Test MSE Loss: 0.3619
Validation loss decreased (inf --> 0.472978).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3752576
	speed: 0.0176s/iter; left time: 203.8633s
Epoch: 2 cost time: 2.1028614044189453
Epoch: 2, Steps: 118 Train Loss: 0.4080 (Forecasting Loss:0.3766 + XiCon Loss:3.1428 x Lambda(0.01)), Vali MSE Loss: 0.4250 Test MSE Loss: 0.3065
Validation loss decreased (0.472978 --> 0.424988).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3608347
	speed: 0.0180s/iter; left time: 206.5318s
Epoch: 3 cost time: 2.094390392303467
Epoch: 3, Steps: 118 Train Loss: 0.3590 (Forecasting Loss:0.3274 + XiCon Loss:3.1600 x Lambda(0.01)), Vali MSE Loss: 0.3791 Test MSE Loss: 0.2703
Validation loss decreased (0.424988 --> 0.379094).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3121632
	speed: 0.0174s/iter; left time: 197.4769s
Epoch: 4 cost time: 2.0391933917999268
Epoch: 4, Steps: 118 Train Loss: 0.3346 (Forecasting Loss:0.3030 + XiCon Loss:3.1634 x Lambda(0.01)), Vali MSE Loss: 0.3761 Test MSE Loss: 0.2807
Validation loss decreased (0.379094 --> 0.376120).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3223269
	speed: 0.0174s/iter; left time: 195.6846s
Epoch: 5 cost time: 2.0532989501953125
Epoch: 5, Steps: 118 Train Loss: 0.3282 (Forecasting Loss:0.2965 + XiCon Loss:3.1637 x Lambda(0.01)), Vali MSE Loss: 0.3700 Test MSE Loss: 0.2797
Validation loss decreased (0.376120 --> 0.369951).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3094374
	speed: 0.0175s/iter; left time: 194.6282s
Epoch: 6 cost time: 2.0443010330200195
Epoch: 6, Steps: 118 Train Loss: 0.3242 (Forecasting Loss:0.2926 + XiCon Loss:3.1640 x Lambda(0.01)), Vali MSE Loss: 0.3670 Test MSE Loss: 0.2786
Validation loss decreased (0.369951 --> 0.367021).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3428349
	speed: 0.0181s/iter; left time: 198.9893s
Epoch: 7 cost time: 2.1401100158691406
Epoch: 7, Steps: 118 Train Loss: 0.3226 (Forecasting Loss:0.2909 + XiCon Loss:3.1633 x Lambda(0.01)), Vali MSE Loss: 0.3645 Test MSE Loss: 0.2783
Validation loss decreased (0.367021 --> 0.364505).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3375869
	speed: 0.0174s/iter; left time: 188.7457s
Epoch: 8 cost time: 2.03987717628479
Epoch: 8, Steps: 118 Train Loss: 0.3216 (Forecasting Loss:0.2900 + XiCon Loss:3.1629 x Lambda(0.01)), Vali MSE Loss: 0.3633 Test MSE Loss: 0.2781
Validation loss decreased (0.364505 --> 0.363310).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3303268
	speed: 0.0182s/iter; left time: 195.3419s
Epoch: 9 cost time: 2.1206419467926025
Epoch: 9, Steps: 118 Train Loss: 0.3216 (Forecasting Loss:0.2900 + XiCon Loss:3.1615 x Lambda(0.01)), Vali MSE Loss: 0.3625 Test MSE Loss: 0.2781
Validation loss decreased (0.363310 --> 0.362514).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3298361
	speed: 0.0177s/iter; left time: 188.0640s
Epoch: 10 cost time: 2.070530414581299
Epoch: 10, Steps: 118 Train Loss: 0.3216 (Forecasting Loss:0.2900 + XiCon Loss:3.1622 x Lambda(0.01)), Vali MSE Loss: 0.3636 Test MSE Loss: 0.2780
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3346898
	speed: 0.0181s/iter; left time: 190.7873s
Epoch: 11 cost time: 2.1017022132873535
Epoch: 11, Steps: 118 Train Loss: 0.3208 (Forecasting Loss:0.2892 + XiCon Loss:3.1635 x Lambda(0.01)), Vali MSE Loss: 0.3645 Test MSE Loss: 0.2779
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3015768
	speed: 0.0177s/iter; left time: 184.3113s
Epoch: 12 cost time: 2.0697624683380127
Epoch: 12, Steps: 118 Train Loss: 0.3210 (Forecasting Loss:0.2894 + XiCon Loss:3.1643 x Lambda(0.01)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2779
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3253888
	speed: 0.0171s/iter; left time: 176.3450s
Epoch: 13 cost time: 2.019754648208618
Epoch: 13, Steps: 118 Train Loss: 0.3213 (Forecasting Loss:0.2896 + XiCon Loss:3.1637 x Lambda(0.01)), Vali MSE Loss: 0.3641 Test MSE Loss: 0.2779
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.3344893
	speed: 0.0173s/iter; left time: 176.1768s
Epoch: 14 cost time: 2.0234646797180176
Epoch: 14, Steps: 118 Train Loss: 0.3209 (Forecasting Loss:0.2893 + XiCon Loss:3.1647 x Lambda(0.01)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2779
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3514277
	speed: 0.0176s/iter; left time: 176.7155s
Epoch: 15 cost time: 2.0484087467193604
Epoch: 15, Steps: 118 Train Loss: 0.3211 (Forecasting Loss:0.2895 + XiCon Loss:3.1628 x Lambda(0.01)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.2779
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3240374
	speed: 0.0182s/iter; left time: 181.0538s
Epoch: 16 cost time: 2.1250081062316895
Epoch: 16, Steps: 118 Train Loss: 0.3212 (Forecasting Loss:0.2895 + XiCon Loss:3.1639 x Lambda(0.01)), Vali MSE Loss: 0.3615 Test MSE Loss: 0.2779
Validation loss decreased (0.362514 --> 0.361546).  Saving model ...
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.3248703
	speed: 0.0177s/iter; left time: 174.1346s
Epoch: 17 cost time: 2.0757319927215576
Epoch: 17, Steps: 118 Train Loss: 0.3209 (Forecasting Loss:0.2893 + XiCon Loss:3.1642 x Lambda(0.01)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.2779
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.3364425
	speed: 0.0180s/iter; left time: 174.2923s
Epoch: 18 cost time: 2.095942497253418
Epoch: 18, Steps: 118 Train Loss: 0.3212 (Forecasting Loss:0.2896 + XiCon Loss:3.1632 x Lambda(0.01)), Vali MSE Loss: 0.3638 Test MSE Loss: 0.2779
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 19 | loss: 0.3055619
	speed: 0.0171s/iter; left time: 163.5212s
Epoch: 19 cost time: 2.0201103687286377
Epoch: 19, Steps: 118 Train Loss: 0.3207 (Forecasting Loss:0.2891 + XiCon Loss:3.1622 x Lambda(0.01)), Vali MSE Loss: 0.3631 Test MSE Loss: 0.2779
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 20 | loss: 0.3151892
	speed: 0.0183s/iter; left time: 172.8111s
Epoch: 20 cost time: 2.119122266769409
Epoch: 20, Steps: 118 Train Loss: 0.3211 (Forecasting Loss:0.2894 + XiCon Loss:3.1628 x Lambda(0.01)), Vali MSE Loss: 0.3628 Test MSE Loss: 0.2779
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 21 | loss: 0.3157610
	speed: 0.0176s/iter; left time: 164.2659s
Epoch: 21 cost time: 2.055882215499878
Epoch: 21, Steps: 118 Train Loss: 0.3212 (Forecasting Loss:0.2895 + XiCon Loss:3.1630 x Lambda(0.01)), Vali MSE Loss: 0.3633 Test MSE Loss: 0.2779
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 22 | loss: 0.3232057
	speed: 0.0183s/iter; left time: 168.6231s
Epoch: 22 cost time: 2.137026309967041
Epoch: 22, Steps: 118 Train Loss: 0.3210 (Forecasting Loss:0.2894 + XiCon Loss:3.1626 x Lambda(0.01)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2779
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 23 | loss: 0.3221395
	speed: 0.0172s/iter; left time: 156.6935s
Epoch: 23 cost time: 2.0187783241271973
Epoch: 23, Steps: 118 Train Loss: 0.3205 (Forecasting Loss:0.2889 + XiCon Loss:3.1637 x Lambda(0.01)), Vali MSE Loss: 0.3638 Test MSE Loss: 0.2779
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 24 | loss: 0.3132234
	speed: 0.0183s/iter; left time: 164.0224s
Epoch: 24 cost time: 2.1315555572509766
Epoch: 24, Steps: 118 Train Loss: 0.3215 (Forecasting Loss:0.2899 + XiCon Loss:3.1629 x Lambda(0.01)), Vali MSE Loss: 0.3635 Test MSE Loss: 0.2779
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 25 | loss: 0.3465149
	speed: 0.0172s/iter; left time: 152.7769s
Epoch: 25 cost time: 2.027846574783325
Epoch: 25, Steps: 118 Train Loss: 0.3207 (Forecasting Loss:0.2891 + XiCon Loss:3.1623 x Lambda(0.01)), Vali MSE Loss: 0.3637 Test MSE Loss: 0.2779
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 26 | loss: 0.3408752
	speed: 0.0177s/iter; left time: 154.8837s
Epoch: 26 cost time: 2.070138692855835
Epoch: 26, Steps: 118 Train Loss: 0.3212 (Forecasting Loss:0.2896 + XiCon Loss:3.1627 x Lambda(0.01)), Vali MSE Loss: 0.3639 Test MSE Loss: 0.2779
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19717365503311157, mae:0.35863783955574036, mape:0.6754043698310852, mspe:19.814659118652344 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2809
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4787729
	speed: 0.0183s/iter; left time: 214.2048s
Epoch: 1 cost time: 2.1231791973114014
Epoch: 1, Steps: 118 Train Loss: 0.5292 (Forecasting Loss:0.4979 + XiCon Loss:3.1238 x Lambda(0.01)), Vali MSE Loss: 0.5537 Test MSE Loss: 0.4593
Validation loss decreased (inf --> 0.553736).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3649976
	speed: 0.0174s/iter; left time: 201.6620s
Epoch: 2 cost time: 2.0597822666168213
Epoch: 2, Steps: 118 Train Loss: 0.4030 (Forecasting Loss:0.3718 + XiCon Loss:3.1224 x Lambda(0.01)), Vali MSE Loss: 0.3872 Test MSE Loss: 0.2754
Validation loss decreased (0.553736 --> 0.387187).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3414401
	speed: 0.0176s/iter; left time: 202.0577s
Epoch: 3 cost time: 2.059568166732788
Epoch: 3, Steps: 118 Train Loss: 0.3456 (Forecasting Loss:0.3144 + XiCon Loss:3.1145 x Lambda(0.01)), Vali MSE Loss: 0.3801 Test MSE Loss: 0.2800
Validation loss decreased (0.387187 --> 0.380086).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3469434
	speed: 0.0174s/iter; left time: 197.4676s
Epoch: 4 cost time: 2.0308921337127686
Epoch: 4, Steps: 118 Train Loss: 0.3365 (Forecasting Loss:0.3054 + XiCon Loss:3.1124 x Lambda(0.01)), Vali MSE Loss: 0.3702 Test MSE Loss: 0.2875
Validation loss decreased (0.380086 --> 0.370212).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3103907
	speed: 0.0180s/iter; left time: 201.6623s
Epoch: 5 cost time: 2.097717046737671
Epoch: 5, Steps: 118 Train Loss: 0.3335 (Forecasting Loss:0.3024 + XiCon Loss:3.1098 x Lambda(0.01)), Vali MSE Loss: 0.3762 Test MSE Loss: 0.2827
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.3375412
	speed: 0.0170s/iter; left time: 189.2973s
Epoch: 6 cost time: 1.9930341243743896
Epoch: 6, Steps: 118 Train Loss: 0.3316 (Forecasting Loss:0.3005 + XiCon Loss:3.1114 x Lambda(0.01)), Vali MSE Loss: 0.3727 Test MSE Loss: 0.2844
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3527197
	speed: 0.0181s/iter; left time: 198.6893s
Epoch: 7 cost time: 2.1127378940582275
Epoch: 7, Steps: 118 Train Loss: 0.3302 (Forecasting Loss:0.2991 + XiCon Loss:3.1097 x Lambda(0.01)), Vali MSE Loss: 0.3682 Test MSE Loss: 0.2851
Validation loss decreased (0.370212 --> 0.368248).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.3433081
	speed: 0.0175s/iter; left time: 190.7952s
Epoch: 8 cost time: 2.0527780055999756
Epoch: 8, Steps: 118 Train Loss: 0.3306 (Forecasting Loss:0.2995 + XiCon Loss:3.1084 x Lambda(0.01)), Vali MSE Loss: 0.3738 Test MSE Loss: 0.2842
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3255393
	speed: 0.0180s/iter; left time: 193.5457s
Epoch: 9 cost time: 2.1033504009246826
Epoch: 9, Steps: 118 Train Loss: 0.3304 (Forecasting Loss:0.2993 + XiCon Loss:3.1075 x Lambda(0.01)), Vali MSE Loss: 0.3731 Test MSE Loss: 0.2844
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3267140
	speed: 0.0181s/iter; left time: 192.2372s
Epoch: 10 cost time: 2.1152184009552
Epoch: 10, Steps: 118 Train Loss: 0.3304 (Forecasting Loss:0.2993 + XiCon Loss:3.1108 x Lambda(0.01)), Vali MSE Loss: 0.3710 Test MSE Loss: 0.2845
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.3220157
	speed: 0.0178s/iter; left time: 186.7526s
Epoch: 11 cost time: 2.0855751037597656
Epoch: 11, Steps: 118 Train Loss: 0.3302 (Forecasting Loss:0.2991 + XiCon Loss:3.1119 x Lambda(0.01)), Vali MSE Loss: 0.3712 Test MSE Loss: 0.2845
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3269275
	speed: 0.0171s/iter; left time: 178.1350s
Epoch: 12 cost time: 2.0149877071380615
Epoch: 12, Steps: 118 Train Loss: 0.3299 (Forecasting Loss:0.2988 + XiCon Loss:3.1088 x Lambda(0.01)), Vali MSE Loss: 0.3717 Test MSE Loss: 0.2844
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3281103
	speed: 0.0185s/iter; left time: 190.5296s
Epoch: 13 cost time: 2.153167963027954
Epoch: 13, Steps: 118 Train Loss: 0.3295 (Forecasting Loss:0.2984 + XiCon Loss:3.1091 x Lambda(0.01)), Vali MSE Loss: 0.3721 Test MSE Loss: 0.2844
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.3562950
	speed: 0.0179s/iter; left time: 182.3244s
Epoch: 14 cost time: 2.090351104736328
Epoch: 14, Steps: 118 Train Loss: 0.3296 (Forecasting Loss:0.2986 + XiCon Loss:3.1080 x Lambda(0.01)), Vali MSE Loss: 0.3720 Test MSE Loss: 0.2844
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.3160346
	speed: 0.0177s/iter; left time: 177.8747s
Epoch: 15 cost time: 2.062021493911743
Epoch: 15, Steps: 118 Train Loss: 0.3300 (Forecasting Loss:0.2989 + XiCon Loss:3.1091 x Lambda(0.01)), Vali MSE Loss: 0.3722 Test MSE Loss: 0.2844
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.3456762
	speed: 0.0175s/iter; left time: 173.3386s
Epoch: 16 cost time: 2.0469210147857666
Epoch: 16, Steps: 118 Train Loss: 0.3304 (Forecasting Loss:0.2993 + XiCon Loss:3.1078 x Lambda(0.01)), Vali MSE Loss: 0.3721 Test MSE Loss: 0.2844
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.3212507
	speed: 0.0176s/iter; left time: 172.7002s
Epoch: 17 cost time: 2.05470871925354
Epoch: 17, Steps: 118 Train Loss: 0.3294 (Forecasting Loss:0.2983 + XiCon Loss:3.1102 x Lambda(0.01)), Vali MSE Loss: 0.3725 Test MSE Loss: 0.2844
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.20530927181243896, mae:0.3648616671562195, mape:0.7224329710006714, mspe:24.638242721557617 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1922+-0.01485, MAE:0.3543+-0.01128, MAPE:0.6900+-0.02445, MSPE:21.2081+-3.29545, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5797
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1890343
	speed: 0.0426s/iter; left time: 1129.1888s
	iters: 200, epoch: 1 | loss: 0.1740289
	speed: 0.0370s/iter; left time: 977.1621s
Epoch: 1 cost time: 10.406432867050171
Epoch: 1, Steps: 266 Train Loss: 0.1977 (Forecasting Loss:0.1642 + XiCon Loss:3.3520 x Lambda(0.01)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.0780
Validation loss decreased (inf --> 0.115301).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1778092
	speed: 0.0383s/iter; left time: 1005.0726s
	iters: 200, epoch: 2 | loss: 0.1682919
	speed: 0.0368s/iter; left time: 962.0330s
Epoch: 2 cost time: 9.885151147842407
Epoch: 2, Steps: 266 Train Loss: 0.1788 (Forecasting Loss:0.1463 + XiCon Loss:3.2550 x Lambda(0.01)), Vali MSE Loss: 0.1103 Test MSE Loss: 0.0784
Validation loss decreased (0.115301 --> 0.110320).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1616215
	speed: 0.0398s/iter; left time: 1032.7555s
	iters: 200, epoch: 3 | loss: 0.1688190
	speed: 0.0358s/iter; left time: 926.1748s
Epoch: 3 cost time: 10.026472330093384
Epoch: 3, Steps: 266 Train Loss: 0.1652 (Forecasting Loss:0.1317 + XiCon Loss:3.3455 x Lambda(0.01)), Vali MSE Loss: 0.1133 Test MSE Loss: 0.0840
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1440523
	speed: 0.0395s/iter; left time: 1016.4949s
	iters: 200, epoch: 4 | loss: 0.1448780
	speed: 0.0365s/iter; left time: 934.0425s
Epoch: 4 cost time: 10.02763557434082
Epoch: 4, Steps: 266 Train Loss: 0.1521 (Forecasting Loss:0.1178 + XiCon Loss:3.4373 x Lambda(0.01)), Vali MSE Loss: 0.1164 Test MSE Loss: 0.0931
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1402172
	speed: 0.0394s/iter; left time: 1001.6357s
	iters: 200, epoch: 5 | loss: 0.1445647
	speed: 0.0374s/iter; left time: 947.5728s
Epoch: 5 cost time: 10.116818904876709
Epoch: 5, Steps: 266 Train Loss: 0.1417 (Forecasting Loss:0.1070 + XiCon Loss:3.4707 x Lambda(0.01)), Vali MSE Loss: 0.1212 Test MSE Loss: 0.0991
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1522535
	speed: 0.0398s/iter; left time: 1002.8683s
	iters: 200, epoch: 6 | loss: 0.1341659
	speed: 0.0368s/iter; left time: 922.9234s
Epoch: 6 cost time: 9.998467445373535
Epoch: 6, Steps: 266 Train Loss: 0.1360 (Forecasting Loss:0.1011 + XiCon Loss:3.4861 x Lambda(0.01)), Vali MSE Loss: 0.1209 Test MSE Loss: 0.0977
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1340332
	speed: 0.0382s/iter; left time: 951.6300s
	iters: 200, epoch: 7 | loss: 0.1253616
	speed: 0.0376s/iter; left time: 933.2927s
Epoch: 7 cost time: 10.050033569335938
Epoch: 7, Steps: 266 Train Loss: 0.1330 (Forecasting Loss:0.0981 + XiCon Loss:3.4897 x Lambda(0.01)), Vali MSE Loss: 0.1202 Test MSE Loss: 0.0998
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1309513
	speed: 0.0395s/iter; left time: 972.3108s
	iters: 200, epoch: 8 | loss: 0.1406270
	speed: 0.0384s/iter; left time: 941.1250s
Epoch: 8 cost time: 10.271916151046753
Epoch: 8, Steps: 266 Train Loss: 0.1316 (Forecasting Loss:0.0967 + XiCon Loss:3.4892 x Lambda(0.01)), Vali MSE Loss: 0.1215 Test MSE Loss: 0.1015
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1290487
	speed: 0.0389s/iter; left time: 947.4028s
	iters: 200, epoch: 9 | loss: 0.1350966
	speed: 0.0372s/iter; left time: 903.4303s
Epoch: 9 cost time: 10.042479038238525
Epoch: 9, Steps: 266 Train Loss: 0.1309 (Forecasting Loss:0.0959 + XiCon Loss:3.4950 x Lambda(0.01)), Vali MSE Loss: 0.1221 Test MSE Loss: 0.1023
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1282524
	speed: 0.0387s/iter; left time: 933.2155s
	iters: 200, epoch: 10 | loss: 0.1316455
	speed: 0.0370s/iter; left time: 887.5669s
Epoch: 10 cost time: 10.006611585617065
Epoch: 10, Steps: 266 Train Loss: 0.1305 (Forecasting Loss:0.0956 + XiCon Loss:3.4929 x Lambda(0.01)), Vali MSE Loss: 0.1222 Test MSE Loss: 0.1017
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1333423
	speed: 0.0399s/iter; left time: 950.9529s
	iters: 200, epoch: 11 | loss: 0.1315559
	speed: 0.0373s/iter; left time: 885.6127s
Epoch: 11 cost time: 10.175933837890625
Epoch: 11, Steps: 266 Train Loss: 0.1305 (Forecasting Loss:0.0956 + XiCon Loss:3.4932 x Lambda(0.01)), Vali MSE Loss: 0.1219 Test MSE Loss: 0.1016
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1184751
	speed: 0.0390s/iter; left time: 920.0871s
	iters: 200, epoch: 12 | loss: 0.1301671
	speed: 0.0377s/iter; left time: 884.4914s
Epoch: 12 cost time: 10.131706237792969
Epoch: 12, Steps: 266 Train Loss: 0.1303 (Forecasting Loss:0.0954 + XiCon Loss:3.4930 x Lambda(0.01)), Vali MSE Loss: 0.1220 Test MSE Loss: 0.1019
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.028622932732105255, mae:0.1281498223543167, mape:0.10437842458486557, mspe:0.02203529328107834 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5134
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1817089
	speed: 0.0396s/iter; left time: 1048.1988s
	iters: 200, epoch: 1 | loss: 0.1821327
	speed: 0.0377s/iter; left time: 996.6376s
Epoch: 1 cost time: 10.16696310043335
Epoch: 1, Steps: 266 Train Loss: 0.1999 (Forecasting Loss:0.1665 + XiCon Loss:3.3419 x Lambda(0.01)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0782
Validation loss decreased (inf --> 0.115222).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1696062
	speed: 0.0387s/iter; left time: 1014.2739s
	iters: 200, epoch: 2 | loss: 0.1609933
	speed: 0.0374s/iter; left time: 976.4026s
Epoch: 2 cost time: 10.070025205612183
Epoch: 2, Steps: 266 Train Loss: 0.1794 (Forecasting Loss:0.1473 + XiCon Loss:3.2165 x Lambda(0.01)), Vali MSE Loss: 0.1159 Test MSE Loss: 0.0791
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1622103
	speed: 0.0376s/iter; left time: 975.7520s
	iters: 200, epoch: 3 | loss: 0.1607246
	speed: 0.0348s/iter; left time: 899.8439s
Epoch: 3 cost time: 9.8129141330719
Epoch: 3, Steps: 266 Train Loss: 0.1604 (Forecasting Loss:0.1291 + XiCon Loss:3.1258 x Lambda(0.01)), Vali MSE Loss: 0.1155 Test MSE Loss: 0.0807
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1420139
	speed: 0.0393s/iter; left time: 1010.6913s
	iters: 200, epoch: 4 | loss: 0.1320452
	speed: 0.0373s/iter; left time: 954.7670s
Epoch: 4 cost time: 10.189184665679932
Epoch: 4, Steps: 266 Train Loss: 0.1419 (Forecasting Loss:0.1109 + XiCon Loss:3.1003 x Lambda(0.01)), Vali MSE Loss: 0.1184 Test MSE Loss: 0.0837
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1289986
	speed: 0.0402s/iter; left time: 1022.5091s
	iters: 200, epoch: 5 | loss: 0.1306724
	speed: 0.0381s/iter; left time: 964.3647s
Epoch: 5 cost time: 10.369026184082031
Epoch: 5, Steps: 266 Train Loss: 0.1312 (Forecasting Loss:0.1001 + XiCon Loss:3.1020 x Lambda(0.01)), Vali MSE Loss: 0.1205 Test MSE Loss: 0.0901
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1330675
	speed: 0.0399s/iter; left time: 1005.3590s
	iters: 200, epoch: 6 | loss: 0.1241814
	speed: 0.0373s/iter; left time: 935.9332s
Epoch: 6 cost time: 10.249937772750854
Epoch: 6, Steps: 266 Train Loss: 0.1261 (Forecasting Loss:0.0950 + XiCon Loss:3.1109 x Lambda(0.01)), Vali MSE Loss: 0.1221 Test MSE Loss: 0.0937
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1334523
	speed: 0.0394s/iter; left time: 981.5286s
	iters: 200, epoch: 7 | loss: 0.1200601
	speed: 0.0384s/iter; left time: 951.3933s
Epoch: 7 cost time: 10.31545877456665
Epoch: 7, Steps: 266 Train Loss: 0.1236 (Forecasting Loss:0.0924 + XiCon Loss:3.1130 x Lambda(0.01)), Vali MSE Loss: 0.1221 Test MSE Loss: 0.0933
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1322453
	speed: 0.0409s/iter; left time: 1008.8591s
	iters: 200, epoch: 8 | loss: 0.1218745
	speed: 0.0384s/iter; left time: 941.6436s
Epoch: 8 cost time: 10.528570175170898
Epoch: 8, Steps: 266 Train Loss: 0.1224 (Forecasting Loss:0.0912 + XiCon Loss:3.1158 x Lambda(0.01)), Vali MSE Loss: 0.1220 Test MSE Loss: 0.0940
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1181297
	speed: 0.0398s/iter; left time: 969.2875s
	iters: 200, epoch: 9 | loss: 0.1132056
	speed: 0.0383s/iter; left time: 928.8803s
Epoch: 9 cost time: 10.360452890396118
Epoch: 9, Steps: 266 Train Loss: 0.1219 (Forecasting Loss:0.0907 + XiCon Loss:3.1172 x Lambda(0.01)), Vali MSE Loss: 0.1226 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1200333
	speed: 0.0391s/iter; left time: 942.7972s
	iters: 200, epoch: 10 | loss: 0.1228273
	speed: 0.0382s/iter; left time: 918.1149s
Epoch: 10 cost time: 10.312097072601318
Epoch: 10, Steps: 266 Train Loss: 0.1215 (Forecasting Loss:0.0903 + XiCon Loss:3.1176 x Lambda(0.01)), Vali MSE Loss: 0.1225 Test MSE Loss: 0.0943
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1212903
	speed: 0.0399s/iter; left time: 952.2688s
	iters: 200, epoch: 11 | loss: 0.1193261
	speed: 0.0382s/iter; left time: 906.6564s
Epoch: 11 cost time: 10.31882619857788
Epoch: 11, Steps: 266 Train Loss: 0.1214 (Forecasting Loss:0.0902 + XiCon Loss:3.1195 x Lambda(0.01)), Vali MSE Loss: 0.1224 Test MSE Loss: 0.0941
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.028290824964642525, mae:0.12811240553855896, mape:0.10305976867675781, mspe:0.02057570032775402 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.1121
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1785203
	speed: 0.0390s/iter; left time: 1034.3958s
	iters: 200, epoch: 1 | loss: 0.1691896
	speed: 0.0366s/iter; left time: 965.1905s
Epoch: 1 cost time: 10.051474809646606
Epoch: 1, Steps: 266 Train Loss: 0.1959 (Forecasting Loss:0.1623 + XiCon Loss:3.3524 x Lambda(0.01)), Vali MSE Loss: 0.1139 Test MSE Loss: 0.0764
Validation loss decreased (inf --> 0.113860).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1762439
	speed: 0.0396s/iter; left time: 1039.8233s
	iters: 200, epoch: 2 | loss: 0.1650397
	speed: 0.0370s/iter; left time: 966.1951s
Epoch: 2 cost time: 10.134899139404297
Epoch: 2, Steps: 266 Train Loss: 0.1780 (Forecasting Loss:0.1457 + XiCon Loss:3.2212 x Lambda(0.01)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.0793
Validation loss decreased (0.113860 --> 0.111728).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1640935
	speed: 0.0397s/iter; left time: 1031.9596s
	iters: 200, epoch: 3 | loss: 0.1658616
	speed: 0.0375s/iter; left time: 969.8806s
Epoch: 3 cost time: 10.253100633621216
Epoch: 3, Steps: 266 Train Loss: 0.1615 (Forecasting Loss:0.1284 + XiCon Loss:3.3062 x Lambda(0.01)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0854
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1497310
	speed: 0.0414s/iter; left time: 1064.1825s
	iters: 200, epoch: 4 | loss: 0.1469626
	speed: 0.0392s/iter; left time: 1004.5135s
Epoch: 4 cost time: 10.601895570755005
Epoch: 4, Steps: 266 Train Loss: 0.1468 (Forecasting Loss:0.1127 + XiCon Loss:3.4053 x Lambda(0.01)), Vali MSE Loss: 0.1223 Test MSE Loss: 0.0938
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1369757
	speed: 0.0405s/iter; left time: 1030.1651s
	iters: 200, epoch: 5 | loss: 0.1392656
	speed: 0.0395s/iter; left time: 1001.9150s
Epoch: 5 cost time: 10.5527822971344
Epoch: 5, Steps: 266 Train Loss: 0.1369 (Forecasting Loss:0.1026 + XiCon Loss:3.4341 x Lambda(0.01)), Vali MSE Loss: 0.1241 Test MSE Loss: 0.0967
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1254749
	speed: 0.0398s/iter; left time: 1001.2488s
	iters: 200, epoch: 6 | loss: 0.1267655
	speed: 0.0381s/iter; left time: 955.9451s
Epoch: 6 cost time: 10.297268629074097
Epoch: 6, Steps: 266 Train Loss: 0.1315 (Forecasting Loss:0.0972 + XiCon Loss:3.4247 x Lambda(0.01)), Vali MSE Loss: 0.1274 Test MSE Loss: 0.0994
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1242970
	speed: 0.0406s/iter; left time: 1011.5611s
	iters: 200, epoch: 7 | loss: 0.1277176
	speed: 0.0378s/iter; left time: 937.8454s
Epoch: 7 cost time: 10.393858194351196
Epoch: 7, Steps: 266 Train Loss: 0.1292 (Forecasting Loss:0.0950 + XiCon Loss:3.4177 x Lambda(0.01)), Vali MSE Loss: 0.1286 Test MSE Loss: 0.1005
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1270045
	speed: 0.0411s/iter; left time: 1011.4760s
	iters: 200, epoch: 8 | loss: 0.1220407
	speed: 0.0385s/iter; left time: 944.6917s
Epoch: 8 cost time: 10.426397562026978
Epoch: 8, Steps: 266 Train Loss: 0.1281 (Forecasting Loss:0.0938 + XiCon Loss:3.4315 x Lambda(0.01)), Vali MSE Loss: 0.1279 Test MSE Loss: 0.1003
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1325897
	speed: 0.0403s/iter; left time: 982.7777s
	iters: 200, epoch: 9 | loss: 0.1260992
	speed: 0.0390s/iter; left time: 945.9894s
Epoch: 9 cost time: 10.542256832122803
Epoch: 9, Steps: 266 Train Loss: 0.1275 (Forecasting Loss:0.0932 + XiCon Loss:3.4275 x Lambda(0.01)), Vali MSE Loss: 0.1276 Test MSE Loss: 0.1000
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1247966
	speed: 0.0396s/iter; left time: 954.3784s
	iters: 200, epoch: 10 | loss: 0.1267934
	speed: 0.0356s/iter; left time: 854.0797s
Epoch: 10 cost time: 9.942494630813599
Epoch: 10, Steps: 266 Train Loss: 0.1272 (Forecasting Loss:0.0930 + XiCon Loss:3.4243 x Lambda(0.01)), Vali MSE Loss: 0.1276 Test MSE Loss: 0.1004
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1229140
	speed: 0.0406s/iter; left time: 968.5873s
	iters: 200, epoch: 11 | loss: 0.1190930
	speed: 0.0387s/iter; left time: 918.1797s
Epoch: 11 cost time: 10.501522302627563
Epoch: 11, Steps: 266 Train Loss: 0.1273 (Forecasting Loss:0.0929 + XiCon Loss:3.4306 x Lambda(0.01)), Vali MSE Loss: 0.1282 Test MSE Loss: 0.1002
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1321853
	speed: 0.0404s/iter; left time: 951.7119s
	iters: 200, epoch: 12 | loss: 0.1336867
	speed: 0.0390s/iter; left time: 916.1646s
Epoch: 12 cost time: 10.518707036972046
Epoch: 12, Steps: 266 Train Loss: 0.1269 (Forecasting Loss:0.0926 + XiCon Loss:3.4277 x Lambda(0.01)), Vali MSE Loss: 0.1281 Test MSE Loss: 0.1003
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.029269661754369736, mae:0.12929686903953552, mape:0.10556207597255707, mspe:0.023138033226132393 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.2294
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1764794
	speed: 0.0397s/iter; left time: 1052.9172s
	iters: 200, epoch: 1 | loss: 0.2014486
	speed: 0.0369s/iter; left time: 973.3198s
Epoch: 1 cost time: 10.067323923110962
Epoch: 1, Steps: 266 Train Loss: 0.1990 (Forecasting Loss:0.1653 + XiCon Loss:3.3709 x Lambda(0.01)), Vali MSE Loss: 0.1148 Test MSE Loss: 0.0784
Validation loss decreased (inf --> 0.114829).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1783036
	speed: 0.0395s/iter; left time: 1035.9252s
	iters: 200, epoch: 2 | loss: 0.1866145
	speed: 0.0372s/iter; left time: 973.4738s
Epoch: 2 cost time: 10.133235454559326
Epoch: 2, Steps: 266 Train Loss: 0.1788 (Forecasting Loss:0.1467 + XiCon Loss:3.2069 x Lambda(0.01)), Vali MSE Loss: 0.1136 Test MSE Loss: 0.0789
Validation loss decreased (0.114829 --> 0.113607).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1705415
	speed: 0.0390s/iter; left time: 1012.9960s
	iters: 200, epoch: 3 | loss: 0.1541615
	speed: 0.0364s/iter; left time: 942.7253s
Epoch: 3 cost time: 9.957626104354858
Epoch: 3, Steps: 266 Train Loss: 0.1626 (Forecasting Loss:0.1306 + XiCon Loss:3.1974 x Lambda(0.01)), Vali MSE Loss: 0.1141 Test MSE Loss: 0.0833
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1453292
	speed: 0.0393s/iter; left time: 1009.5447s
	iters: 200, epoch: 4 | loss: 0.1453438
	speed: 0.0377s/iter; left time: 966.2868s
Epoch: 4 cost time: 10.212051153182983
Epoch: 4, Steps: 266 Train Loss: 0.1469 (Forecasting Loss:0.1139 + XiCon Loss:3.3014 x Lambda(0.01)), Vali MSE Loss: 0.1193 Test MSE Loss: 0.0919
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1335066
	speed: 0.0393s/iter; left time: 998.9381s
	iters: 200, epoch: 5 | loss: 0.1450201
	speed: 0.0379s/iter; left time: 959.6706s
Epoch: 5 cost time: 10.263333320617676
Epoch: 5, Steps: 266 Train Loss: 0.1352 (Forecasting Loss:0.1019 + XiCon Loss:3.3259 x Lambda(0.01)), Vali MSE Loss: 0.1214 Test MSE Loss: 0.0993
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1373852
	speed: 0.0397s/iter; left time: 998.9088s
	iters: 200, epoch: 6 | loss: 0.1241127
	speed: 0.0374s/iter; left time: 938.1233s
Epoch: 6 cost time: 10.08632516860962
Epoch: 6, Steps: 266 Train Loss: 0.1300 (Forecasting Loss:0.0966 + XiCon Loss:3.3355 x Lambda(0.01)), Vali MSE Loss: 0.1224 Test MSE Loss: 0.1024
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1270445
	speed: 0.0381s/iter; left time: 948.3106s
	iters: 200, epoch: 7 | loss: 0.1268055
	speed: 0.0380s/iter; left time: 941.4020s
Epoch: 7 cost time: 10.116402626037598
Epoch: 7, Steps: 266 Train Loss: 0.1272 (Forecasting Loss:0.0938 + XiCon Loss:3.3379 x Lambda(0.01)), Vali MSE Loss: 0.1228 Test MSE Loss: 0.1027
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1340975
	speed: 0.0402s/iter; left time: 991.5263s
	iters: 200, epoch: 8 | loss: 0.1209906
	speed: 0.0379s/iter; left time: 930.5436s
Epoch: 8 cost time: 10.412911653518677
Epoch: 8, Steps: 266 Train Loss: 0.1256 (Forecasting Loss:0.0923 + XiCon Loss:3.3358 x Lambda(0.01)), Vali MSE Loss: 0.1236 Test MSE Loss: 0.1032
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1216173
	speed: 0.0407s/iter; left time: 990.8632s
	iters: 200, epoch: 9 | loss: 0.1194051
	speed: 0.0380s/iter; left time: 922.9756s
Epoch: 9 cost time: 10.34528923034668
Epoch: 9, Steps: 266 Train Loss: 0.1252 (Forecasting Loss:0.0917 + XiCon Loss:3.3400 x Lambda(0.01)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.1029
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1301451
	speed: 0.0399s/iter; left time: 962.9431s
	iters: 200, epoch: 10 | loss: 0.1314590
	speed: 0.0382s/iter; left time: 917.2073s
Epoch: 10 cost time: 10.249085903167725
Epoch: 10, Steps: 266 Train Loss: 0.1248 (Forecasting Loss:0.0914 + XiCon Loss:3.3435 x Lambda(0.01)), Vali MSE Loss: 0.1233 Test MSE Loss: 0.1043
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1217618
	speed: 0.0408s/iter; left time: 972.5135s
	iters: 200, epoch: 11 | loss: 0.1187650
	speed: 0.0386s/iter; left time: 916.6837s
Epoch: 11 cost time: 10.473184823989868
Epoch: 11, Steps: 266 Train Loss: 0.1248 (Forecasting Loss:0.0914 + XiCon Loss:3.3425 x Lambda(0.01)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.1041
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1226761
	speed: 0.0402s/iter; left time: 948.2828s
	iters: 200, epoch: 12 | loss: 0.1237534
	speed: 0.0386s/iter; left time: 905.1686s
Epoch: 12 cost time: 10.337811470031738
Epoch: 12, Steps: 266 Train Loss: 0.1246 (Forecasting Loss:0.0912 + XiCon Loss:3.3424 x Lambda(0.01)), Vali MSE Loss: 0.1232 Test MSE Loss: 0.1041
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.028425924479961395, mae:0.12928207218647003, mape:0.10575372725725174, mspe:0.022523539140820503 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3400
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1877907
	speed: 0.0399s/iter; left time: 1056.3351s
	iters: 200, epoch: 1 | loss: 0.1871583
	speed: 0.0376s/iter; left time: 992.5290s
Epoch: 1 cost time: 10.146004915237427
Epoch: 1, Steps: 266 Train Loss: 0.1996 (Forecasting Loss:0.1660 + XiCon Loss:3.3518 x Lambda(0.01)), Vali MSE Loss: 0.1142 Test MSE Loss: 0.0783
Validation loss decreased (inf --> 0.114189).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1831698
	speed: 0.0399s/iter; left time: 1046.6929s
	iters: 200, epoch: 2 | loss: 0.1882121
	speed: 0.0379s/iter; left time: 989.6084s
Epoch: 2 cost time: 10.306739091873169
Epoch: 2, Steps: 266 Train Loss: 0.1758 (Forecasting Loss:0.1434 + XiCon Loss:3.2395 x Lambda(0.01)), Vali MSE Loss: 0.1162 Test MSE Loss: 0.0841
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1650465
	speed: 0.0376s/iter; left time: 975.5290s
	iters: 200, epoch: 3 | loss: 0.1535929
	speed: 0.0354s/iter; left time: 914.7149s
Epoch: 3 cost time: 9.851775884628296
Epoch: 3, Steps: 266 Train Loss: 0.1545 (Forecasting Loss:0.1217 + XiCon Loss:3.2782 x Lambda(0.01)), Vali MSE Loss: 0.1166 Test MSE Loss: 0.0936
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1396151
	speed: 0.0398s/iter; left time: 1022.8379s
	iters: 200, epoch: 4 | loss: 0.1445411
	speed: 0.0383s/iter; left time: 981.1491s
Epoch: 4 cost time: 10.38029670715332
Epoch: 4, Steps: 266 Train Loss: 0.1381 (Forecasting Loss:0.1047 + XiCon Loss:3.3444 x Lambda(0.01)), Vali MSE Loss: 0.1176 Test MSE Loss: 0.0967
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1273552
	speed: 0.0410s/iter; left time: 1042.9406s
	iters: 200, epoch: 5 | loss: 0.1343348
	speed: 0.0391s/iter; left time: 990.0563s
Epoch: 5 cost time: 10.461881637573242
Epoch: 5, Steps: 266 Train Loss: 0.1286 (Forecasting Loss:0.0949 + XiCon Loss:3.3735 x Lambda(0.01)), Vali MSE Loss: 0.1217 Test MSE Loss: 0.1007
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1133891
	speed: 0.0406s/iter; left time: 1022.7757s
	iters: 200, epoch: 6 | loss: 0.1272745
	speed: 0.0391s/iter; left time: 980.4432s
Epoch: 6 cost time: 10.480198621749878
Epoch: 6, Steps: 266 Train Loss: 0.1241 (Forecasting Loss:0.0903 + XiCon Loss:3.3824 x Lambda(0.01)), Vali MSE Loss: 0.1218 Test MSE Loss: 0.1024
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1264004
	speed: 0.0412s/iter; left time: 1025.1209s
	iters: 200, epoch: 7 | loss: 0.1186725
	speed: 0.0383s/iter; left time: 949.1935s
Epoch: 7 cost time: 10.443480491638184
Epoch: 7, Steps: 266 Train Loss: 0.1220 (Forecasting Loss:0.0882 + XiCon Loss:3.3856 x Lambda(0.01)), Vali MSE Loss: 0.1223 Test MSE Loss: 0.1038
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1309475
	speed: 0.0407s/iter; left time: 1002.2684s
	iters: 200, epoch: 8 | loss: 0.1265615
	speed: 0.0377s/iter; left time: 925.8745s
Epoch: 8 cost time: 10.429533958435059
Epoch: 8, Steps: 266 Train Loss: 0.1211 (Forecasting Loss:0.0873 + XiCon Loss:3.3852 x Lambda(0.01)), Vali MSE Loss: 0.1235 Test MSE Loss: 0.1037
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1206880
	speed: 0.0410s/iter; left time: 999.4102s
	iters: 200, epoch: 9 | loss: 0.1305906
	speed: 0.0385s/iter; left time: 935.4421s
Epoch: 9 cost time: 10.536303043365479
Epoch: 9, Steps: 266 Train Loss: 0.1206 (Forecasting Loss:0.0867 + XiCon Loss:3.3851 x Lambda(0.01)), Vali MSE Loss: 0.1233 Test MSE Loss: 0.1042
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1185634
	speed: 0.0407s/iter; left time: 980.7611s
	iters: 200, epoch: 10 | loss: 0.1142769
	speed: 0.0387s/iter; left time: 928.0286s
Epoch: 10 cost time: 10.532703161239624
Epoch: 10, Steps: 266 Train Loss: 0.1206 (Forecasting Loss:0.0867 + XiCon Loss:3.3894 x Lambda(0.01)), Vali MSE Loss: 0.1230 Test MSE Loss: 0.1042
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1214679
	speed: 0.0410s/iter; left time: 977.3314s
	iters: 200, epoch: 11 | loss: 0.1117170
	speed: 0.0384s/iter; left time: 912.7524s
Epoch: 11 cost time: 10.579431533813477
Epoch: 11, Steps: 266 Train Loss: 0.1203 (Forecasting Loss:0.0864 + XiCon Loss:3.3879 x Lambda(0.01)), Vali MSE Loss: 0.1231 Test MSE Loss: 0.1043
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.02826809324324131, mae:0.12828104197978973, mape:0.10388192534446716, mspe:0.021345870569348335 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0286+-0.00051, MAE:0.1286+-0.00076, MAPE:0.1045+-0.00141, MSPE:0.0219+-0.00124, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.8926
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2378364
	speed: 0.0528s/iter; left time: 1393.5312s
	iters: 200, epoch: 1 | loss: 0.2262597
	speed: 0.0476s/iter; left time: 1252.6124s
Epoch: 1 cost time: 13.10575795173645
Epoch: 1, Steps: 265 Train Loss: 0.2395 (Forecasting Loss:0.2068 + XiCon Loss:3.2625 x Lambda(0.01)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.145982).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2159665
	speed: 0.0540s/iter; left time: 1410.5665s
	iters: 200, epoch: 2 | loss: 0.2198208
	speed: 0.0520s/iter; left time: 1353.1754s
Epoch: 2 cost time: 13.93001413345337
Epoch: 2, Steps: 265 Train Loss: 0.2136 (Forecasting Loss:0.1817 + XiCon Loss:3.1907 x Lambda(0.01)), Vali MSE Loss: 0.1615 Test MSE Loss: 0.1155
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1592876
	speed: 0.0531s/iter; left time: 1374.1555s
	iters: 200, epoch: 3 | loss: 0.1492674
	speed: 0.0525s/iter; left time: 1352.2536s
Epoch: 3 cost time: 13.966896295547485
Epoch: 3, Steps: 265 Train Loss: 0.1620 (Forecasting Loss:0.1307 + XiCon Loss:3.1323 x Lambda(0.01)), Vali MSE Loss: 0.1656 Test MSE Loss: 0.1261
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1401146
	speed: 0.0552s/iter; left time: 1414.2411s
	iters: 200, epoch: 4 | loss: 0.1441667
	speed: 0.0524s/iter; left time: 1335.8182s
Epoch: 4 cost time: 14.127989768981934
Epoch: 4, Steps: 265 Train Loss: 0.1382 (Forecasting Loss:0.1073 + XiCon Loss:3.0995 x Lambda(0.01)), Vali MSE Loss: 0.1722 Test MSE Loss: 0.1328
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1274598
	speed: 0.0546s/iter; left time: 1384.3733s
	iters: 200, epoch: 5 | loss: 0.1305472
	speed: 0.0528s/iter; left time: 1332.2472s
Epoch: 5 cost time: 14.120088577270508
Epoch: 5, Steps: 265 Train Loss: 0.1307 (Forecasting Loss:0.0998 + XiCon Loss:3.0849 x Lambda(0.01)), Vali MSE Loss: 0.1776 Test MSE Loss: 0.1352
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1356423
	speed: 0.0554s/iter; left time: 1390.4443s
	iters: 200, epoch: 6 | loss: 0.1277290
	speed: 0.0531s/iter; left time: 1327.2680s
Epoch: 6 cost time: 14.322129726409912
Epoch: 6, Steps: 265 Train Loss: 0.1280 (Forecasting Loss:0.0973 + XiCon Loss:3.0770 x Lambda(0.01)), Vali MSE Loss: 0.1792 Test MSE Loss: 0.1381
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1216951
	speed: 0.0549s/iter; left time: 1363.1027s
	iters: 200, epoch: 7 | loss: 0.1301357
	speed: 0.0528s/iter; left time: 1305.6427s
Epoch: 7 cost time: 14.195274114608765
Epoch: 7, Steps: 265 Train Loss: 0.1266 (Forecasting Loss:0.0959 + XiCon Loss:3.0743 x Lambda(0.01)), Vali MSE Loss: 0.1785 Test MSE Loss: 0.1371
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1304903
	speed: 0.0541s/iter; left time: 1327.4539s
	iters: 200, epoch: 8 | loss: 0.1247114
	speed: 0.0523s/iter; left time: 1277.5799s
Epoch: 8 cost time: 14.054790019989014
Epoch: 8, Steps: 265 Train Loss: 0.1260 (Forecasting Loss:0.0953 + XiCon Loss:3.0711 x Lambda(0.01)), Vali MSE Loss: 0.1796 Test MSE Loss: 0.1368
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1206946
	speed: 0.0544s/iter; left time: 1321.2065s
	iters: 200, epoch: 9 | loss: 0.1208596
	speed: 0.0536s/iter; left time: 1295.6013s
Epoch: 9 cost time: 14.299388647079468
Epoch: 9, Steps: 265 Train Loss: 0.1257 (Forecasting Loss:0.0950 + XiCon Loss:3.0699 x Lambda(0.01)), Vali MSE Loss: 0.1799 Test MSE Loss: 0.1370
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1218336
	speed: 0.0563s/iter; left time: 1352.0364s
	iters: 200, epoch: 10 | loss: 0.1298127
	speed: 0.0541s/iter; left time: 1293.4468s
Epoch: 10 cost time: 14.392675399780273
Epoch: 10, Steps: 265 Train Loss: 0.1255 (Forecasting Loss:0.0948 + XiCon Loss:3.0677 x Lambda(0.01)), Vali MSE Loss: 0.1800 Test MSE Loss: 0.1367
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1246577
	speed: 0.0540s/iter; left time: 1281.5497s
	iters: 200, epoch: 11 | loss: 0.1236173
	speed: 0.0520s/iter; left time: 1229.5499s
Epoch: 11 cost time: 14.019787788391113
Epoch: 11, Steps: 265 Train Loss: 0.1254 (Forecasting Loss:0.0947 + XiCon Loss:3.0672 x Lambda(0.01)), Vali MSE Loss: 0.1801 Test MSE Loss: 0.1371
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04102865979075432, mae:0.15572217106819153, mape:0.1251196265220642, mspe:0.029178941622376442 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.2842
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2388180
	speed: 0.0503s/iter; left time: 1326.8972s
	iters: 200, epoch: 1 | loss: 0.2277519
	speed: 0.0466s/iter; left time: 1226.6877s
Epoch: 1 cost time: 12.681288003921509
Epoch: 1, Steps: 265 Train Loss: 0.2372 (Forecasting Loss:0.2046 + XiCon Loss:3.2659 x Lambda(0.01)), Vali MSE Loss: 0.1474 Test MSE Loss: 0.1000
Validation loss decreased (inf --> 0.147386).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2093418
	speed: 0.0496s/iter; left time: 1296.8844s
	iters: 200, epoch: 2 | loss: 0.1855737
	speed: 0.0477s/iter; left time: 1242.2680s
Epoch: 2 cost time: 12.934055089950562
Epoch: 2, Steps: 265 Train Loss: 0.2132 (Forecasting Loss:0.1814 + XiCon Loss:3.1814 x Lambda(0.01)), Vali MSE Loss: 0.1569 Test MSE Loss: 0.1188
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1569487
	speed: 0.0519s/iter; left time: 1342.9505s
	iters: 200, epoch: 3 | loss: 0.1500713
	speed: 0.0506s/iter; left time: 1304.0983s
Epoch: 3 cost time: 13.401883125305176
Epoch: 3, Steps: 265 Train Loss: 0.1559 (Forecasting Loss:0.1246 + XiCon Loss:3.1322 x Lambda(0.01)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1266
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1359034
	speed: 0.0953s/iter; left time: 2440.6045s
	iters: 200, epoch: 4 | loss: 0.1303557
	speed: 0.1024s/iter; left time: 2611.0383s
Epoch: 4 cost time: 26.147990703582764
Epoch: 4, Steps: 265 Train Loss: 0.1348 (Forecasting Loss:0.1037 + XiCon Loss:3.1085 x Lambda(0.01)), Vali MSE Loss: 0.1663 Test MSE Loss: 0.1260
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1272811
	speed: 0.1149s/iter; left time: 2911.8469s
	iters: 200, epoch: 5 | loss: 0.1253915
	speed: 0.1037s/iter; left time: 2618.0779s
Epoch: 5 cost time: 28.747424125671387
Epoch: 5, Steps: 265 Train Loss: 0.1301 (Forecasting Loss:0.0990 + XiCon Loss:3.1043 x Lambda(0.01)), Vali MSE Loss: 0.1660 Test MSE Loss: 0.1265
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1289521
	speed: 0.0913s/iter; left time: 2289.2054s
	iters: 200, epoch: 6 | loss: 0.1214648
	speed: 0.0775s/iter; left time: 1936.3255s
Epoch: 6 cost time: 20.344260692596436
Epoch: 6, Steps: 265 Train Loss: 0.1285 (Forecasting Loss:0.0974 + XiCon Loss:3.1101 x Lambda(0.01)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1267
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1282107
	speed: 0.0486s/iter; left time: 1206.8859s
	iters: 200, epoch: 7 | loss: 0.1274085
	speed: 0.0467s/iter; left time: 1153.3599s
Epoch: 7 cost time: 12.664786577224731
Epoch: 7, Steps: 265 Train Loss: 0.1275 (Forecasting Loss:0.0963 + XiCon Loss:3.1201 x Lambda(0.01)), Vali MSE Loss: 0.1674 Test MSE Loss: 0.1275
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1284977
	speed: 0.0504s/iter; left time: 1237.2734s
	iters: 200, epoch: 8 | loss: 0.1220660
	speed: 0.0474s/iter; left time: 1159.5980s
Epoch: 8 cost time: 12.895832538604736
Epoch: 8, Steps: 265 Train Loss: 0.1268 (Forecasting Loss:0.0956 + XiCon Loss:3.1209 x Lambda(0.01)), Vali MSE Loss: 0.1661 Test MSE Loss: 0.1266
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1266063
	speed: 0.0500s/iter; left time: 1212.8386s
	iters: 200, epoch: 9 | loss: 0.1246345
	speed: 0.0471s/iter; left time: 1139.3839s
Epoch: 9 cost time: 12.827431201934814
Epoch: 9, Steps: 265 Train Loss: 0.1265 (Forecasting Loss:0.0953 + XiCon Loss:3.1232 x Lambda(0.01)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1278
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1284450
	speed: 0.0512s/iter; left time: 1228.4732s
	iters: 200, epoch: 10 | loss: 0.1236107
	speed: 0.0482s/iter; left time: 1152.2399s
Epoch: 10 cost time: 13.159343957901001
Epoch: 10, Steps: 265 Train Loss: 0.1263 (Forecasting Loss:0.0951 + XiCon Loss:3.1236 x Lambda(0.01)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1276
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1249338
	speed: 0.0529s/iter; left time: 1256.8152s
	iters: 200, epoch: 11 | loss: 0.1255746
	speed: 0.0513s/iter; left time: 1212.7688s
Epoch: 11 cost time: 13.744957685470581
Epoch: 11, Steps: 265 Train Loss: 0.1262 (Forecasting Loss:0.0949 + XiCon Loss:3.1259 x Lambda(0.01)), Vali MSE Loss: 0.1669 Test MSE Loss: 0.1276
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.042342688888311386, mae:0.1575595736503601, mape:0.1251869946718216, mspe:0.028752455487847328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.7060
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2346442
	speed: 0.0493s/iter; left time: 1302.0313s
	iters: 200, epoch: 1 | loss: 0.2215876
	speed: 0.0482s/iter; left time: 1268.8934s
Epoch: 1 cost time: 12.874358892440796
Epoch: 1, Steps: 265 Train Loss: 0.2414 (Forecasting Loss:0.2088 + XiCon Loss:3.2578 x Lambda(0.01)), Vali MSE Loss: 0.1471 Test MSE Loss: 0.0989
Validation loss decreased (inf --> 0.147120).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2097820
	speed: 0.0537s/iter; left time: 1403.9600s
	iters: 200, epoch: 2 | loss: 0.2044111
	speed: 0.0533s/iter; left time: 1387.0723s
Epoch: 2 cost time: 14.117044448852539
Epoch: 2, Steps: 265 Train Loss: 0.2206 (Forecasting Loss:0.1889 + XiCon Loss:3.1686 x Lambda(0.01)), Vali MSE Loss: 0.1517 Test MSE Loss: 0.1064
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1744553
	speed: 0.0552s/iter; left time: 1427.6607s
	iters: 200, epoch: 3 | loss: 0.1722448
	speed: 0.0528s/iter; left time: 1360.4730s
Epoch: 3 cost time: 14.249366998672485
Epoch: 3, Steps: 265 Train Loss: 0.1844 (Forecasting Loss:0.1535 + XiCon Loss:3.0958 x Lambda(0.01)), Vali MSE Loss: 0.1607 Test MSE Loss: 0.1268
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1593595
	speed: 0.0549s/iter; left time: 1405.8809s
	iters: 200, epoch: 4 | loss: 0.1508583
	speed: 0.0537s/iter; left time: 1368.4197s
Epoch: 4 cost time: 14.361809968948364
Epoch: 4, Steps: 265 Train Loss: 0.1574 (Forecasting Loss:0.1267 + XiCon Loss:3.0755 x Lambda(0.01)), Vali MSE Loss: 0.1650 Test MSE Loss: 0.1339
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1416238
	speed: 0.0548s/iter; left time: 1388.7753s
	iters: 200, epoch: 5 | loss: 0.1434632
	speed: 0.0524s/iter; left time: 1323.8464s
Epoch: 5 cost time: 14.165416717529297
Epoch: 5, Steps: 265 Train Loss: 0.1449 (Forecasting Loss:0.1143 + XiCon Loss:3.0636 x Lambda(0.01)), Vali MSE Loss: 0.1657 Test MSE Loss: 0.1379
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1405010
	speed: 0.0532s/iter; left time: 1332.9163s
	iters: 200, epoch: 6 | loss: 0.1379153
	speed: 0.0530s/iter; left time: 1324.2753s
Epoch: 6 cost time: 14.002237558364868
Epoch: 6, Steps: 265 Train Loss: 0.1397 (Forecasting Loss:0.1091 + XiCon Loss:3.0608 x Lambda(0.01)), Vali MSE Loss: 0.1685 Test MSE Loss: 0.1379
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1385235
	speed: 0.0548s/iter; left time: 1359.1842s
	iters: 200, epoch: 7 | loss: 0.1317355
	speed: 0.0532s/iter; left time: 1313.9359s
Epoch: 7 cost time: 14.287536144256592
Epoch: 7, Steps: 265 Train Loss: 0.1374 (Forecasting Loss:0.1068 + XiCon Loss:3.0591 x Lambda(0.01)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1362181
	speed: 0.0555s/iter; left time: 1361.1330s
	iters: 200, epoch: 8 | loss: 0.1473788
	speed: 0.0537s/iter; left time: 1312.2254s
Epoch: 8 cost time: 14.367074251174927
Epoch: 8, Steps: 265 Train Loss: 0.1363 (Forecasting Loss:0.1057 + XiCon Loss:3.0573 x Lambda(0.01)), Vali MSE Loss: 0.1686 Test MSE Loss: 0.1394
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1432562
	speed: 0.0560s/iter; left time: 1360.7995s
	iters: 200, epoch: 9 | loss: 0.1281024
	speed: 0.0531s/iter; left time: 1283.3752s
Epoch: 9 cost time: 14.506370544433594
Epoch: 9, Steps: 265 Train Loss: 0.1359 (Forecasting Loss:0.1053 + XiCon Loss:3.0574 x Lambda(0.01)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1392
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1418365
	speed: 0.0552s/iter; left time: 1326.3414s
	iters: 200, epoch: 10 | loss: 0.1371345
	speed: 0.0549s/iter; left time: 1311.9703s
Epoch: 10 cost time: 14.523378849029541
Epoch: 10, Steps: 265 Train Loss: 0.1355 (Forecasting Loss:0.1050 + XiCon Loss:3.0571 x Lambda(0.01)), Vali MSE Loss: 0.1687 Test MSE Loss: 0.1393
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1307103
	speed: 0.0549s/iter; left time: 1304.0409s
	iters: 200, epoch: 11 | loss: 0.1332233
	speed: 0.0524s/iter; left time: 1240.1992s
Epoch: 11 cost time: 14.286489248275757
Epoch: 11, Steps: 265 Train Loss: 0.1354 (Forecasting Loss:0.1048 + XiCon Loss:3.0571 x Lambda(0.01)), Vali MSE Loss: 0.1689 Test MSE Loss: 0.1394
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04163888096809387, mae:0.15612469613552094, mape:0.12366325408220291, mspe:0.02774355746805668 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4465
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2068650
	speed: 0.0476s/iter; left time: 1257.0865s
	iters: 200, epoch: 1 | loss: 0.2154354
	speed: 0.0429s/iter; left time: 1127.5420s
Epoch: 1 cost time: 11.983185052871704
Epoch: 1, Steps: 265 Train Loss: 0.2382 (Forecasting Loss:0.2056 + XiCon Loss:3.2641 x Lambda(0.01)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.0984
Validation loss decreased (inf --> 0.147511).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2130996
	speed: 0.0540s/iter; left time: 1411.0614s
	iters: 200, epoch: 2 | loss: 0.2133634
	speed: 0.0529s/iter; left time: 1376.2406s
Epoch: 2 cost time: 14.15330719947815
Epoch: 2, Steps: 265 Train Loss: 0.2212 (Forecasting Loss:0.1890 + XiCon Loss:3.2158 x Lambda(0.01)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.1087
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1798346
	speed: 0.0547s/iter; left time: 1415.9303s
	iters: 200, epoch: 3 | loss: 0.1818193
	speed: 0.0534s/iter; left time: 1374.8896s
Epoch: 3 cost time: 14.21183967590332
Epoch: 3, Steps: 265 Train Loss: 0.1777 (Forecasting Loss:0.1465 + XiCon Loss:3.1229 x Lambda(0.01)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1145
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1452896
	speed: 0.0556s/iter; left time: 1424.4555s
	iters: 200, epoch: 4 | loss: 0.1337492
	speed: 0.0536s/iter; left time: 1368.1042s
Epoch: 4 cost time: 14.456750392913818
Epoch: 4, Steps: 265 Train Loss: 0.1450 (Forecasting Loss:0.1141 + XiCon Loss:3.0896 x Lambda(0.01)), Vali MSE Loss: 0.1808 Test MSE Loss: 0.1196
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1345926
	speed: 0.0557s/iter; left time: 1410.3944s
	iters: 200, epoch: 5 | loss: 0.1317985
	speed: 0.0542s/iter; left time: 1369.1855s
Epoch: 5 cost time: 14.496219873428345
Epoch: 5, Steps: 265 Train Loss: 0.1360 (Forecasting Loss:0.1053 + XiCon Loss:3.0657 x Lambda(0.01)), Vali MSE Loss: 0.1810 Test MSE Loss: 0.1211
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1316359
	speed: 0.0556s/iter; left time: 1393.3372s
	iters: 200, epoch: 6 | loss: 0.1231816
	speed: 0.0536s/iter; left time: 1337.8126s
Epoch: 6 cost time: 14.502308368682861
Epoch: 6, Steps: 265 Train Loss: 0.1325 (Forecasting Loss:0.1019 + XiCon Loss:3.0529 x Lambda(0.01)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1222
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1305312
	speed: 0.0562s/iter; left time: 1394.8200s
	iters: 200, epoch: 7 | loss: 0.1314580
	speed: 0.0550s/iter; left time: 1357.8925s
Epoch: 7 cost time: 14.601603269577026
Epoch: 7, Steps: 265 Train Loss: 0.1310 (Forecasting Loss:0.1005 + XiCon Loss:3.0463 x Lambda(0.01)), Vali MSE Loss: 0.1821 Test MSE Loss: 0.1221
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1274723
	speed: 0.0560s/iter; left time: 1374.3163s
	iters: 200, epoch: 8 | loss: 0.1276499
	speed: 0.0541s/iter; left time: 1323.2875s
Epoch: 8 cost time: 14.463365077972412
Epoch: 8, Steps: 265 Train Loss: 0.1302 (Forecasting Loss:0.0998 + XiCon Loss:3.0432 x Lambda(0.01)), Vali MSE Loss: 0.1813 Test MSE Loss: 0.1219
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1254379
	speed: 0.0537s/iter; left time: 1304.2590s
	iters: 200, epoch: 9 | loss: 0.1292547
	speed: 0.0530s/iter; left time: 1281.8747s
Epoch: 9 cost time: 14.211937427520752
Epoch: 9, Steps: 265 Train Loss: 0.1299 (Forecasting Loss:0.0994 + XiCon Loss:3.0433 x Lambda(0.01)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1220
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1285156
	speed: 0.0548s/iter; left time: 1314.9211s
	iters: 200, epoch: 10 | loss: 0.1328359
	speed: 0.0534s/iter; left time: 1277.1088s
Epoch: 10 cost time: 14.245489358901978
Epoch: 10, Steps: 265 Train Loss: 0.1296 (Forecasting Loss:0.0992 + XiCon Loss:3.0404 x Lambda(0.01)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1225
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1360103
	speed: 0.0556s/iter; left time: 1319.5712s
	iters: 200, epoch: 11 | loss: 0.1327587
	speed: 0.0535s/iter; left time: 1265.4008s
Epoch: 11 cost time: 14.366233110427856
Epoch: 11, Steps: 265 Train Loss: 0.1295 (Forecasting Loss:0.0991 + XiCon Loss:3.0434 x Lambda(0.01)), Vali MSE Loss: 0.1818 Test MSE Loss: 0.1225
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.041274406015872955, mae:0.15543949604034424, mape:0.12371866405010223, mspe:0.028118174523115158 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5640
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.2543442
	speed: 0.0497s/iter; left time: 1312.9208s
	iters: 200, epoch: 1 | loss: 0.2346775
	speed: 0.0469s/iter; left time: 1232.8740s
Epoch: 1 cost time: 12.695403099060059
Epoch: 1, Steps: 265 Train Loss: 0.2378 (Forecasting Loss:0.2050 + XiCon Loss:3.2735 x Lambda(0.01)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.0997
Validation loss decreased (inf --> 0.147013).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2377660
	speed: 0.0518s/iter; left time: 1354.0379s
	iters: 200, epoch: 2 | loss: 0.2193739
	speed: 0.0511s/iter; left time: 1330.4885s
Epoch: 2 cost time: 13.729166269302368
Epoch: 2, Steps: 265 Train Loss: 0.2295 (Forecasting Loss:0.1969 + XiCon Loss:3.2579 x Lambda(0.01)), Vali MSE Loss: 0.1525 Test MSE Loss: 0.1045
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2102881
	speed: 0.0541s/iter; left time: 1398.5860s
	iters: 200, epoch: 3 | loss: 0.2075177
	speed: 0.0532s/iter; left time: 1369.8715s
Epoch: 3 cost time: 14.209930896759033
Epoch: 3, Steps: 265 Train Loss: 0.2070 (Forecasting Loss:0.1759 + XiCon Loss:3.1132 x Lambda(0.01)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1661612
	speed: 0.0525s/iter; left time: 1344.0321s
	iters: 200, epoch: 4 | loss: 0.1530244
	speed: 0.0507s/iter; left time: 1292.0823s
Epoch: 4 cost time: 13.672687768936157
Epoch: 4, Steps: 265 Train Loss: 0.1676 (Forecasting Loss:0.1368 + XiCon Loss:3.0801 x Lambda(0.01)), Vali MSE Loss: 0.1921 Test MSE Loss: 0.1324
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1412461
	speed: 0.0555s/iter; left time: 1407.0091s
	iters: 200, epoch: 5 | loss: 0.1433602
	speed: 0.0530s/iter; left time: 1338.3596s
Epoch: 5 cost time: 14.321027755737305
Epoch: 5, Steps: 265 Train Loss: 0.1439 (Forecasting Loss:0.1132 + XiCon Loss:3.0646 x Lambda(0.01)), Vali MSE Loss: 0.1978 Test MSE Loss: 0.1387
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1416208
	speed: 0.0546s/iter; left time: 1368.9631s
	iters: 200, epoch: 6 | loss: 0.1307223
	speed: 0.0539s/iter; left time: 1347.1232s
Epoch: 6 cost time: 14.407186269760132
Epoch: 6, Steps: 265 Train Loss: 0.1364 (Forecasting Loss:0.1057 + XiCon Loss:3.0617 x Lambda(0.01)), Vali MSE Loss: 0.1939 Test MSE Loss: 0.1424
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1319406
	speed: 0.0565s/iter; left time: 1400.8767s
	iters: 200, epoch: 7 | loss: 0.1323033
	speed: 0.0528s/iter; left time: 1303.7215s
Epoch: 7 cost time: 14.393857955932617
Epoch: 7, Steps: 265 Train Loss: 0.1335 (Forecasting Loss:0.1030 + XiCon Loss:3.0576 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.1419
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1281361
	speed: 0.0553s/iter; left time: 1357.8945s
	iters: 200, epoch: 8 | loss: 0.1322954
	speed: 0.0532s/iter; left time: 1300.8414s
Epoch: 8 cost time: 14.377601385116577
Epoch: 8, Steps: 265 Train Loss: 0.1322 (Forecasting Loss:0.1017 + XiCon Loss:3.0555 x Lambda(0.01)), Vali MSE Loss: 0.1949 Test MSE Loss: 0.1428
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1209288
	speed: 0.0552s/iter; left time: 1341.1033s
	iters: 200, epoch: 9 | loss: 0.1365627
	speed: 0.0533s/iter; left time: 1289.5800s
Epoch: 9 cost time: 14.335417985916138
Epoch: 9, Steps: 265 Train Loss: 0.1316 (Forecasting Loss:0.1011 + XiCon Loss:3.0534 x Lambda(0.01)), Vali MSE Loss: 0.1942 Test MSE Loss: 0.1436
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1279426
	speed: 0.0557s/iter; left time: 1338.6783s
	iters: 200, epoch: 10 | loss: 0.1282251
	speed: 0.0523s/iter; left time: 1250.4223s
Epoch: 10 cost time: 14.324706077575684
Epoch: 10, Steps: 265 Train Loss: 0.1313 (Forecasting Loss:0.1007 + XiCon Loss:3.0542 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1434
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1298853
	speed: 0.0554s/iter; left time: 1315.7293s
	iters: 200, epoch: 11 | loss: 0.1284573
	speed: 0.0533s/iter; left time: 1261.2767s
Epoch: 11 cost time: 14.255887985229492
Epoch: 11, Steps: 265 Train Loss: 0.1310 (Forecasting Loss:0.1005 + XiCon Loss:3.0519 x Lambda(0.01)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1433
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.04214083403348923, mae:0.15733374655246735, mape:0.1268399953842163, mspe:0.030611826106905937 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0417+-0.00069, MAE:0.1564+-0.00119, MAPE:0.1249+-0.00162, MSPE:0.0289+-0.00138, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3834
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2710746
	speed: 0.0420s/iter; left time: 1105.9168s
	iters: 200, epoch: 1 | loss: 0.2980378
	speed: 0.0372s/iter; left time: 975.5465s
Epoch: 1 cost time: 10.33070969581604
Epoch: 1, Steps: 264 Train Loss: 0.2676 (Forecasting Loss:0.2358 + XiCon Loss:3.1731 x Lambda(0.01)), Vali MSE Loss: 0.1736 Test MSE Loss: 0.1158
Validation loss decreased (inf --> 0.173622).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2816873
	speed: 0.0418s/iter; left time: 1087.2688s
	iters: 200, epoch: 2 | loss: 0.2653358
	speed: 0.0454s/iter; left time: 1178.4186s
Epoch: 2 cost time: 11.694851875305176
Epoch: 2, Steps: 264 Train Loss: 0.2581 (Forecasting Loss:0.2271 + XiCon Loss:3.0980 x Lambda(0.01)), Vali MSE Loss: 0.1913 Test MSE Loss: 0.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2172568
	speed: 0.0464s/iter; left time: 1194.8420s
	iters: 200, epoch: 3 | loss: 0.1965402
	speed: 0.0443s/iter; left time: 1138.4880s
Epoch: 3 cost time: 11.97251582145691
Epoch: 3, Steps: 264 Train Loss: 0.2136 (Forecasting Loss:0.1831 + XiCon Loss:3.0504 x Lambda(0.01)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1608
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1898379
	speed: 0.0464s/iter; left time: 1184.8829s
	iters: 200, epoch: 4 | loss: 0.1896984
	speed: 0.0439s/iter; left time: 1115.1201s
Epoch: 4 cost time: 11.906002521514893
Epoch: 4, Steps: 264 Train Loss: 0.1895 (Forecasting Loss:0.1590 + XiCon Loss:3.0516 x Lambda(0.01)), Vali MSE Loss: 0.2192 Test MSE Loss: 0.1576
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1825988
	speed: 0.0457s/iter; left time: 1152.8388s
	iters: 200, epoch: 5 | loss: 0.1700183
	speed: 0.0437s/iter; left time: 1099.5968s
Epoch: 5 cost time: 11.767780065536499
Epoch: 5, Steps: 264 Train Loss: 0.1792 (Forecasting Loss:0.1486 + XiCon Loss:3.0573 x Lambda(0.01)), Vali MSE Loss: 0.2147 Test MSE Loss: 0.1612
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1745689
	speed: 0.0456s/iter; left time: 1138.5064s
	iters: 200, epoch: 6 | loss: 0.1679225
	speed: 0.0440s/iter; left time: 1095.8982s
Epoch: 6 cost time: 11.74962592124939
Epoch: 6, Steps: 264 Train Loss: 0.1748 (Forecasting Loss:0.1442 + XiCon Loss:3.0657 x Lambda(0.01)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1645
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1753014
	speed: 0.0474s/iter; left time: 1170.7927s
	iters: 200, epoch: 7 | loss: 0.1667123
	speed: 0.0437s/iter; left time: 1075.5062s
Epoch: 7 cost time: 11.937243223190308
Epoch: 7, Steps: 264 Train Loss: 0.1726 (Forecasting Loss:0.1419 + XiCon Loss:3.0697 x Lambda(0.01)), Vali MSE Loss: 0.2179 Test MSE Loss: 0.1661
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1765786
	speed: 0.0459s/iter; left time: 1122.4429s
	iters: 200, epoch: 8 | loss: 0.1788314
	speed: 0.0435s/iter; left time: 1058.3434s
Epoch: 8 cost time: 11.703526258468628
Epoch: 8, Steps: 264 Train Loss: 0.1715 (Forecasting Loss:0.1408 + XiCon Loss:3.0665 x Lambda(0.01)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.1649
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1705916
	speed: 0.0454s/iter; left time: 1097.7973s
	iters: 200, epoch: 9 | loss: 0.1719863
	speed: 0.0440s/iter; left time: 1058.9516s
Epoch: 9 cost time: 11.766912937164307
Epoch: 9, Steps: 264 Train Loss: 0.1712 (Forecasting Loss:0.1405 + XiCon Loss:3.0666 x Lambda(0.01)), Vali MSE Loss: 0.2176 Test MSE Loss: 0.1655
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1745798
	speed: 0.0457s/iter; left time: 1093.3176s
	iters: 200, epoch: 10 | loss: 0.1793030
	speed: 0.0458s/iter; left time: 1090.4931s
Epoch: 10 cost time: 11.945865154266357
Epoch: 10, Steps: 264 Train Loss: 0.1708 (Forecasting Loss:0.1401 + XiCon Loss:3.0670 x Lambda(0.01)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.1663
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1682707
	speed: 0.0462s/iter; left time: 1092.3653s
	iters: 200, epoch: 11 | loss: 0.1729025
	speed: 0.0439s/iter; left time: 1035.4522s
Epoch: 11 cost time: 11.809481382369995
Epoch: 11, Steps: 264 Train Loss: 0.1708 (Forecasting Loss:0.1401 + XiCon Loss:3.0657 x Lambda(0.01)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1663
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05456022545695305, mae:0.17700262367725372, mape:0.13777515292167664, mspe:0.033321790397167206 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.5561
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2474887
	speed: 0.0402s/iter; left time: 1058.4176s
	iters: 200, epoch: 1 | loss: 0.2418415
	speed: 0.0370s/iter; left time: 968.5948s
Epoch: 1 cost time: 10.08254361152649
Epoch: 1, Steps: 264 Train Loss: 0.2669 (Forecasting Loss:0.2353 + XiCon Loss:3.1616 x Lambda(0.01)), Vali MSE Loss: 0.1780 Test MSE Loss: 0.1182
Validation loss decreased (inf --> 0.177993).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2463559
	speed: 0.0458s/iter; left time: 1192.2018s
	iters: 200, epoch: 2 | loss: 0.2708331
	speed: 0.0464s/iter; left time: 1204.5282s
Epoch: 2 cost time: 12.138740062713623
Epoch: 2, Steps: 264 Train Loss: 0.2671 (Forecasting Loss:0.2363 + XiCon Loss:3.0859 x Lambda(0.01)), Vali MSE Loss: 0.1901 Test MSE Loss: 0.1317
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2371869
	speed: 0.0460s/iter; left time: 1186.0158s
	iters: 200, epoch: 3 | loss: 0.2271541
	speed: 0.0451s/iter; left time: 1157.6103s
Epoch: 3 cost time: 11.869411706924438
Epoch: 3, Steps: 264 Train Loss: 0.2398 (Forecasting Loss:0.2094 + XiCon Loss:3.0366 x Lambda(0.01)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1502
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2117577
	speed: 0.0462s/iter; left time: 1179.5689s
	iters: 200, epoch: 4 | loss: 0.2282598
	speed: 0.0448s/iter; left time: 1138.9494s
Epoch: 4 cost time: 12.059086561203003
Epoch: 4, Steps: 264 Train Loss: 0.2156 (Forecasting Loss:0.1842 + XiCon Loss:3.1466 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1581
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1963365
	speed: 0.0446s/iter; left time: 1125.3886s
	iters: 200, epoch: 5 | loss: 0.2113874
	speed: 0.0438s/iter; left time: 1101.5034s
Epoch: 5 cost time: 11.746774911880493
Epoch: 5, Steps: 264 Train Loss: 0.1992 (Forecasting Loss:0.1672 + XiCon Loss:3.1944 x Lambda(0.01)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1664
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1838700
	speed: 0.0467s/iter; left time: 1165.4302s
	iters: 200, epoch: 6 | loss: 0.2015325
	speed: 0.0445s/iter; left time: 1106.7483s
Epoch: 6 cost time: 12.074082374572754
Epoch: 6, Steps: 264 Train Loss: 0.1912 (Forecasting Loss:0.1591 + XiCon Loss:3.2091 x Lambda(0.01)), Vali MSE Loss: 0.2129 Test MSE Loss: 0.1706
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1809553
	speed: 0.0467s/iter; left time: 1155.3447s
	iters: 200, epoch: 7 | loss: 0.1769802
	speed: 0.0452s/iter; left time: 1111.6779s
Epoch: 7 cost time: 12.080783605575562
Epoch: 7, Steps: 264 Train Loss: 0.1875 (Forecasting Loss:0.1554 + XiCon Loss:3.2135 x Lambda(0.01)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1736
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1869729
	speed: 0.0476s/iter; left time: 1163.8385s
	iters: 200, epoch: 8 | loss: 0.1821685
	speed: 0.0452s/iter; left time: 1101.4189s
Epoch: 8 cost time: 12.157637357711792
Epoch: 8, Steps: 264 Train Loss: 0.1856 (Forecasting Loss:0.1535 + XiCon Loss:3.2134 x Lambda(0.01)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1748
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1875872
	speed: 0.0453s/iter; left time: 1095.6237s
	iters: 200, epoch: 9 | loss: 0.1901759
	speed: 0.0444s/iter; left time: 1069.1651s
Epoch: 9 cost time: 11.800655126571655
Epoch: 9, Steps: 264 Train Loss: 0.1847 (Forecasting Loss:0.1525 + XiCon Loss:3.2185 x Lambda(0.01)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1747
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1806278
	speed: 0.0462s/iter; left time: 1104.5400s
	iters: 200, epoch: 10 | loss: 0.1918888
	speed: 0.0452s/iter; left time: 1075.8256s
Epoch: 10 cost time: 12.024250507354736
Epoch: 10, Steps: 264 Train Loss: 0.1842 (Forecasting Loss:0.1520 + XiCon Loss:3.2177 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1730
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1942348
	speed: 0.0469s/iter; left time: 1109.3418s
	iters: 200, epoch: 11 | loss: 0.1854610
	speed: 0.0465s/iter; left time: 1094.8307s
Epoch: 11 cost time: 12.175691843032837
Epoch: 11, Steps: 264 Train Loss: 0.1838 (Forecasting Loss:0.1517 + XiCon Loss:3.2155 x Lambda(0.01)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1732
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05614257976412773, mae:0.18031488358974457, mape:0.14059285819530487, mspe:0.034437939524650574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.4259
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2744717
	speed: 0.0389s/iter; left time: 1023.5822s
	iters: 200, epoch: 1 | loss: 0.2471648
	speed: 0.0373s/iter; left time: 978.1240s
Epoch: 1 cost time: 10.029118776321411
Epoch: 1, Steps: 264 Train Loss: 0.2652 (Forecasting Loss:0.2334 + XiCon Loss:3.1763 x Lambda(0.01)), Vali MSE Loss: 0.1783 Test MSE Loss: 0.1207
Validation loss decreased (inf --> 0.178278).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2499894
	speed: 0.0393s/iter; left time: 1022.9557s
	iters: 200, epoch: 2 | loss: 0.2382491
	speed: 0.0374s/iter; left time: 969.6501s
Epoch: 2 cost time: 10.096802949905396
Epoch: 2, Steps: 264 Train Loss: 0.2618 (Forecasting Loss:0.2306 + XiCon Loss:3.1235 x Lambda(0.01)), Vali MSE Loss: 0.1823 Test MSE Loss: 0.1303
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2280415
	speed: 0.0390s/iter; left time: 1004.2645s
	iters: 200, epoch: 3 | loss: 0.2175809
	speed: 0.0376s/iter; left time: 964.4377s
Epoch: 3 cost time: 10.02501106262207
Epoch: 3, Steps: 264 Train Loss: 0.2269 (Forecasting Loss:0.1958 + XiCon Loss:3.1094 x Lambda(0.01)), Vali MSE Loss: 0.1719 Test MSE Loss: 0.1419
Validation loss decreased (0.178278 --> 0.171930).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.1923220
	speed: 0.0388s/iter; left time: 990.2493s
	iters: 200, epoch: 4 | loss: 0.2013896
	speed: 0.0369s/iter; left time: 937.8959s
Epoch: 4 cost time: 9.970791101455688
Epoch: 4, Steps: 264 Train Loss: 0.2026 (Forecasting Loss:0.1714 + XiCon Loss:3.1238 x Lambda(0.01)), Vali MSE Loss: 0.1874 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1743980
	speed: 0.0399s/iter; left time: 1007.4725s
	iters: 200, epoch: 5 | loss: 0.1867325
	speed: 0.0373s/iter; left time: 938.5704s
Epoch: 5 cost time: 10.126168727874756
Epoch: 5, Steps: 264 Train Loss: 0.1887 (Forecasting Loss:0.1573 + XiCon Loss:3.1345 x Lambda(0.01)), Vali MSE Loss: 0.1926 Test MSE Loss: 0.1673
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1839301
	speed: 0.0394s/iter; left time: 985.3072s
	iters: 200, epoch: 6 | loss: 0.1813053
	speed: 0.0371s/iter; left time: 924.1321s
Epoch: 6 cost time: 10.031591653823853
Epoch: 6, Steps: 264 Train Loss: 0.1820 (Forecasting Loss:0.1506 + XiCon Loss:3.1460 x Lambda(0.01)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1716
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1809617
	speed: 0.0399s/iter; left time: 987.3132s
	iters: 200, epoch: 7 | loss: 0.1776592
	speed: 0.0368s/iter; left time: 905.2962s
Epoch: 7 cost time: 10.038527727127075
Epoch: 7, Steps: 264 Train Loss: 0.1790 (Forecasting Loss:0.1474 + XiCon Loss:3.1523 x Lambda(0.01)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1726
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1806628
	speed: 0.0397s/iter; left time: 969.7436s
	iters: 200, epoch: 8 | loss: 0.1740171
	speed: 0.0373s/iter; left time: 907.2711s
Epoch: 8 cost time: 10.061102390289307
Epoch: 8, Steps: 264 Train Loss: 0.1773 (Forecasting Loss:0.1458 + XiCon Loss:3.1501 x Lambda(0.01)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1716
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1821788
	speed: 0.0396s/iter; left time: 958.4050s
	iters: 200, epoch: 9 | loss: 0.1741429
	speed: 0.0370s/iter; left time: 890.3090s
Epoch: 9 cost time: 10.112976312637329
Epoch: 9, Steps: 264 Train Loss: 0.1764 (Forecasting Loss:0.1449 + XiCon Loss:3.1494 x Lambda(0.01)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.1705
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1603088
	speed: 0.0393s/iter; left time: 940.6515s
	iters: 200, epoch: 10 | loss: 0.1709606
	speed: 0.0378s/iter; left time: 901.5326s
Epoch: 10 cost time: 10.10758638381958
Epoch: 10, Steps: 264 Train Loss: 0.1760 (Forecasting Loss:0.1445 + XiCon Loss:3.1495 x Lambda(0.01)), Vali MSE Loss: 0.1936 Test MSE Loss: 0.1716
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1682536
	speed: 0.0392s/iter; left time: 928.6579s
	iters: 200, epoch: 11 | loss: 0.1756554
	speed: 0.0384s/iter; left time: 905.0930s
Epoch: 11 cost time: 10.16984748840332
Epoch: 11, Steps: 264 Train Loss: 0.1757 (Forecasting Loss:0.1442 + XiCon Loss:3.1496 x Lambda(0.01)), Vali MSE Loss: 0.1953 Test MSE Loss: 0.1726
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.1816009
	speed: 0.0393s/iter; left time: 918.8657s
	iters: 200, epoch: 12 | loss: 0.1798155
	speed: 0.0375s/iter; left time: 873.7426s
Epoch: 12 cost time: 10.079941749572754
Epoch: 12, Steps: 264 Train Loss: 0.1757 (Forecasting Loss:0.1442 + XiCon Loss:3.1497 x Lambda(0.01)), Vali MSE Loss: 0.1954 Test MSE Loss: 0.1724
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.1798528
	speed: 0.0399s/iter; left time: 923.8665s
	iters: 200, epoch: 13 | loss: 0.1810641
	speed: 0.0368s/iter; left time: 847.3225s
Epoch: 13 cost time: 10.08491063117981
Epoch: 13, Steps: 264 Train Loss: 0.1757 (Forecasting Loss:0.1442 + XiCon Loss:3.1499 x Lambda(0.01)), Vali MSE Loss: 0.1951 Test MSE Loss: 0.1722
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.07553832978010178, mae:0.20835430920124054, mape:0.17188851535320282, mspe:0.06404510885477066 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8286
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2898157
	speed: 0.0399s/iter; left time: 1050.4226s
	iters: 200, epoch: 1 | loss: 0.2885045
	speed: 0.0372s/iter; left time: 975.8375s
Epoch: 1 cost time: 10.100318431854248
Epoch: 1, Steps: 264 Train Loss: 0.2688 (Forecasting Loss:0.2369 + XiCon Loss:3.1986 x Lambda(0.01)), Vali MSE Loss: 0.1754 Test MSE Loss: 0.1157
Validation loss decreased (inf --> 0.175381).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2727682
	speed: 0.0416s/iter; left time: 1082.9383s
	iters: 200, epoch: 2 | loss: 0.2749474
	speed: 0.0427s/iter; left time: 1107.8026s
Epoch: 2 cost time: 11.238138914108276
Epoch: 2, Steps: 264 Train Loss: 0.2646 (Forecasting Loss:0.2330 + XiCon Loss:3.1657 x Lambda(0.01)), Vali MSE Loss: 0.1880 Test MSE Loss: 0.1283
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2409558
	speed: 0.0464s/iter; left time: 1196.9820s
	iters: 200, epoch: 3 | loss: 0.2330630
	speed: 0.0436s/iter; left time: 1118.6144s
Epoch: 3 cost time: 11.857484102249146
Epoch: 3, Steps: 264 Train Loss: 0.2345 (Forecasting Loss:0.2029 + XiCon Loss:3.1560 x Lambda(0.01)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1438
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2141157
	speed: 0.0458s/iter; left time: 1167.2076s
	iters: 200, epoch: 4 | loss: 0.1990039
	speed: 0.0443s/iter; left time: 1126.0845s
Epoch: 4 cost time: 11.820420026779175
Epoch: 4, Steps: 264 Train Loss: 0.2103 (Forecasting Loss:0.1789 + XiCon Loss:3.1406 x Lambda(0.01)), Vali MSE Loss: 0.1875 Test MSE Loss: 0.1560
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1985237
	speed: 0.0464s/iter; left time: 1170.5207s
	iters: 200, epoch: 5 | loss: 0.2001778
	speed: 0.0439s/iter; left time: 1102.9162s
Epoch: 5 cost time: 11.843439102172852
Epoch: 5, Steps: 264 Train Loss: 0.1985 (Forecasting Loss:0.1671 + XiCon Loss:3.1402 x Lambda(0.01)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1604
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1924963
	speed: 0.0466s/iter; left time: 1163.5056s
	iters: 200, epoch: 6 | loss: 0.1842699
	speed: 0.0429s/iter; left time: 1067.8001s
Epoch: 6 cost time: 11.735711336135864
Epoch: 6, Steps: 264 Train Loss: 0.1929 (Forecasting Loss:0.1616 + XiCon Loss:3.1362 x Lambda(0.01)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1622
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1729261
	speed: 0.0455s/iter; left time: 1125.0892s
	iters: 200, epoch: 7 | loss: 0.1815020
	speed: 0.0438s/iter; left time: 1079.1094s
Epoch: 7 cost time: 11.737345218658447
Epoch: 7, Steps: 264 Train Loss: 0.1905 (Forecasting Loss:0.1592 + XiCon Loss:3.1287 x Lambda(0.01)), Vali MSE Loss: 0.1895 Test MSE Loss: 0.1629
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1875987
	speed: 0.0465s/iter; left time: 1137.9416s
	iters: 200, epoch: 8 | loss: 0.1772315
	speed: 0.0450s/iter; left time: 1095.7286s
Epoch: 8 cost time: 11.88440465927124
Epoch: 8, Steps: 264 Train Loss: 0.1891 (Forecasting Loss:0.1578 + XiCon Loss:3.1359 x Lambda(0.01)), Vali MSE Loss: 0.1897 Test MSE Loss: 0.1632
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1891353
	speed: 0.0458s/iter; left time: 1107.6490s
	iters: 200, epoch: 9 | loss: 0.1883319
	speed: 0.0445s/iter; left time: 1072.9914s
Epoch: 9 cost time: 11.839245557785034
Epoch: 9, Steps: 264 Train Loss: 0.1886 (Forecasting Loss:0.1572 + XiCon Loss:3.1337 x Lambda(0.01)), Vali MSE Loss: 0.1907 Test MSE Loss: 0.1647
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1952350
	speed: 0.0468s/iter; left time: 1120.7054s
	iters: 200, epoch: 10 | loss: 0.1824609
	speed: 0.0442s/iter; left time: 1053.0643s
Epoch: 10 cost time: 11.949492931365967
Epoch: 10, Steps: 264 Train Loss: 0.1880 (Forecasting Loss:0.1566 + XiCon Loss:3.1357 x Lambda(0.01)), Vali MSE Loss: 0.1902 Test MSE Loss: 0.1640
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1877067
	speed: 0.0457s/iter; left time: 1082.0032s
	iters: 200, epoch: 11 | loss: 0.1925412
	speed: 0.0444s/iter; left time: 1045.2672s
Epoch: 11 cost time: 11.879658699035645
Epoch: 11, Steps: 264 Train Loss: 0.1881 (Forecasting Loss:0.1567 + XiCon Loss:3.1343 x Lambda(0.01)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1645
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05458837375044823, mae:0.17684480547904968, mape:0.13828398287296295, mspe:0.03413628041744232 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.3636
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.2569137
	speed: 0.0409s/iter; left time: 1075.1722s
	iters: 200, epoch: 1 | loss: 0.2411815
	speed: 0.0366s/iter; left time: 958.9458s
Epoch: 1 cost time: 10.088599920272827
Epoch: 1, Steps: 264 Train Loss: 0.2658 (Forecasting Loss:0.2337 + XiCon Loss:3.2099 x Lambda(0.01)), Vali MSE Loss: 0.1740 Test MSE Loss: 0.1174
Validation loss decreased (inf --> 0.173998).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.2401436
	speed: 0.0393s/iter; left time: 1024.0666s
	iters: 200, epoch: 2 | loss: 0.2642328
	speed: 0.0358s/iter; left time: 927.9685s
Epoch: 2 cost time: 9.887225151062012
Epoch: 2, Steps: 264 Train Loss: 0.2589 (Forecasting Loss:0.2277 + XiCon Loss:3.1176 x Lambda(0.01)), Vali MSE Loss: 0.1848 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.2193665
	speed: 0.0388s/iter; left time: 999.9628s
	iters: 200, epoch: 3 | loss: 0.2135690
	speed: 0.0368s/iter; left time: 946.0065s
Epoch: 3 cost time: 9.907537698745728
Epoch: 3, Steps: 264 Train Loss: 0.2177 (Forecasting Loss:0.1868 + XiCon Loss:3.0889 x Lambda(0.01)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1614
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.2017482
	speed: 0.0393s/iter; left time: 1002.5603s
	iters: 200, epoch: 4 | loss: 0.1778356
	speed: 0.0376s/iter; left time: 955.3954s
Epoch: 4 cost time: 10.08842921257019
Epoch: 4, Steps: 264 Train Loss: 0.1896 (Forecasting Loss:0.1587 + XiCon Loss:3.0977 x Lambda(0.01)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.1461
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.1833702
	speed: 0.0392s/iter; left time: 990.2009s
	iters: 200, epoch: 5 | loss: 0.1702228
	speed: 0.0378s/iter; left time: 951.2009s
Epoch: 5 cost time: 10.082964897155762
Epoch: 5, Steps: 264 Train Loss: 0.1783 (Forecasting Loss:0.1473 + XiCon Loss:3.1014 x Lambda(0.01)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1554
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.1716908
	speed: 0.0397s/iter; left time: 991.5668s
	iters: 200, epoch: 6 | loss: 0.1642176
	speed: 0.0366s/iter; left time: 910.4744s
Epoch: 6 cost time: 10.0909583568573
Epoch: 6, Steps: 264 Train Loss: 0.1736 (Forecasting Loss:0.1425 + XiCon Loss:3.1036 x Lambda(0.01)), Vali MSE Loss: 0.2000 Test MSE Loss: 0.1571
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.1833444
	speed: 0.0384s/iter; left time: 949.0830s
	iters: 200, epoch: 7 | loss: 0.1774909
	speed: 0.0369s/iter; left time: 907.2261s
Epoch: 7 cost time: 9.93588376045227
Epoch: 7, Steps: 264 Train Loss: 0.1710 (Forecasting Loss:0.1400 + XiCon Loss:3.1036 x Lambda(0.01)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1610
EarlyStopping counter: 6 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.1548688
	speed: 0.0392s/iter; left time: 958.4415s
	iters: 200, epoch: 8 | loss: 0.1708626
	speed: 0.0372s/iter; left time: 906.6909s
Epoch: 8 cost time: 10.07171893119812
Epoch: 8, Steps: 264 Train Loss: 0.1699 (Forecasting Loss:0.1389 + XiCon Loss:3.1035 x Lambda(0.01)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1601
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.1739792
	speed: 0.0395s/iter; left time: 955.4781s
	iters: 200, epoch: 9 | loss: 0.1642009
	speed: 0.0372s/iter; left time: 897.2023s
Epoch: 9 cost time: 10.059197187423706
Epoch: 9, Steps: 264 Train Loss: 0.1694 (Forecasting Loss:0.1384 + XiCon Loss:3.1017 x Lambda(0.01)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1615
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.1685387
	speed: 0.0396s/iter; left time: 946.5777s
	iters: 200, epoch: 10 | loss: 0.1767338
	speed: 0.0369s/iter; left time: 879.2540s
Epoch: 10 cost time: 9.979690790176392
Epoch: 10, Steps: 264 Train Loss: 0.1690 (Forecasting Loss:0.1379 + XiCon Loss:3.1040 x Lambda(0.01)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1614
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.1731596
	speed: 0.0396s/iter; left time: 936.5597s
	iters: 200, epoch: 11 | loss: 0.1686756
	speed: 0.0374s/iter; left time: 880.1208s
Epoch: 11 cost time: 10.05109977722168
Epoch: 11, Steps: 264 Train Loss: 0.1689 (Forecasting Loss:0.1379 + XiCon Loss:3.1010 x Lambda(0.01)), Vali MSE Loss: 0.1955 Test MSE Loss: 0.1608
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05492062866687775, mae:0.1799251139163971, mape:0.14298945665359497, mspe:0.0366494357585907 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0592+-0.01140, MAE:0.1845+-0.01669, MAPE:0.1463+-0.01794, MSPE:0.0405+-0.01640, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.7519
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3121155
	speed: 0.0434s/iter; left time: 1129.1263s
	iters: 200, epoch: 1 | loss: 0.3384745
	speed: 0.0368s/iter; left time: 952.1538s
Epoch: 1 cost time: 10.31526803970337
Epoch: 1, Steps: 261 Train Loss: 0.3110 (Forecasting Loss:0.2770 + XiCon Loss:3.3979 x Lambda(0.01)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1415
Validation loss decreased (inf --> 0.199431).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2980270
	speed: 0.0396s/iter; left time: 1018.6032s
	iters: 200, epoch: 2 | loss: 0.2979890
	speed: 0.0374s/iter; left time: 957.6744s
Epoch: 2 cost time: 9.980548858642578
Epoch: 2, Steps: 261 Train Loss: 0.2971 (Forecasting Loss:0.2637 + XiCon Loss:3.3334 x Lambda(0.01)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1427
Validation loss decreased (0.199431 --> 0.194082).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2879760
	speed: 0.0399s/iter; left time: 1015.6032s
	iters: 200, epoch: 3 | loss: 0.2750746
	speed: 0.0382s/iter; left time: 969.9286s
Epoch: 3 cost time: 10.101333618164062
Epoch: 3, Steps: 261 Train Loss: 0.2783 (Forecasting Loss:0.2455 + XiCon Loss:3.2879 x Lambda(0.01)), Vali MSE Loss: 0.1987 Test MSE Loss: 0.1455
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2872753
	speed: 0.0398s/iter; left time: 1004.8396s
	iters: 200, epoch: 4 | loss: 0.2665363
	speed: 0.0374s/iter; left time: 939.2416s
Epoch: 4 cost time: 10.035664558410645
Epoch: 4, Steps: 261 Train Loss: 0.2681 (Forecasting Loss:0.2353 + XiCon Loss:3.2849 x Lambda(0.01)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1483
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2611147
	speed: 0.0403s/iter; left time: 1006.8896s
	iters: 200, epoch: 5 | loss: 0.2772092
	speed: 0.0373s/iter; left time: 926.5553s
Epoch: 5 cost time: 10.074141025543213
Epoch: 5, Steps: 261 Train Loss: 0.2631 (Forecasting Loss:0.2303 + XiCon Loss:3.2797 x Lambda(0.01)), Vali MSE Loss: 0.2022 Test MSE Loss: 0.1490
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2723553
	speed: 0.0398s/iter; left time: 983.7556s
	iters: 200, epoch: 6 | loss: 0.2477095
	speed: 0.0377s/iter; left time: 928.2328s
Epoch: 6 cost time: 10.03731894493103
Epoch: 6, Steps: 261 Train Loss: 0.2606 (Forecasting Loss:0.2278 + XiCon Loss:3.2783 x Lambda(0.01)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1505
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2518351
	speed: 0.0397s/iter; left time: 969.7525s
	iters: 200, epoch: 7 | loss: 0.2508705
	speed: 0.0379s/iter; left time: 921.8257s
Epoch: 7 cost time: 10.195586681365967
Epoch: 7, Steps: 261 Train Loss: 0.2590 (Forecasting Loss:0.2263 + XiCon Loss:3.2738 x Lambda(0.01)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1495
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2652232
	speed: 0.0407s/iter; left time: 983.6541s
	iters: 200, epoch: 8 | loss: 0.2582347
	speed: 0.0368s/iter; left time: 885.8019s
Epoch: 8 cost time: 10.032129049301147
Epoch: 8, Steps: 261 Train Loss: 0.2585 (Forecasting Loss:0.2258 + XiCon Loss:3.2773 x Lambda(0.01)), Vali MSE Loss: 0.2037 Test MSE Loss: 0.1495
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2582142
	speed: 0.0402s/iter; left time: 960.8491s
	iters: 200, epoch: 9 | loss: 0.2686726
	speed: 0.0382s/iter; left time: 909.6702s
Epoch: 9 cost time: 10.1114022731781
Epoch: 9, Steps: 261 Train Loss: 0.2581 (Forecasting Loss:0.2253 + XiCon Loss:3.2778 x Lambda(0.01)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1498
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2442332
	speed: 0.0403s/iter; left time: 953.7608s
	iters: 200, epoch: 10 | loss: 0.2723117
	speed: 0.0381s/iter; left time: 897.3678s
Epoch: 10 cost time: 10.086309909820557
Epoch: 10, Steps: 261 Train Loss: 0.2580 (Forecasting Loss:0.2252 + XiCon Loss:3.2739 x Lambda(0.01)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1504
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2650597
	speed: 0.0394s/iter; left time: 920.7955s
	iters: 200, epoch: 11 | loss: 0.2584634
	speed: 0.0383s/iter; left time: 890.9095s
Epoch: 11 cost time: 10.024977922439575
Epoch: 11, Steps: 261 Train Loss: 0.2579 (Forecasting Loss:0.2251 + XiCon Loss:3.2758 x Lambda(0.01)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1499
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2757794
	speed: 0.0404s/iter; left time: 934.6383s
	iters: 200, epoch: 12 | loss: 0.2537203
	speed: 0.0392s/iter; left time: 901.8174s
Epoch: 12 cost time: 10.257210493087769
Epoch: 12, Steps: 261 Train Loss: 0.2580 (Forecasting Loss:0.2252 + XiCon Loss:3.2766 x Lambda(0.01)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1500
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07502274215221405, mae:0.21038037538528442, mape:0.16290044784545898, mspe:0.045625075697898865 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.6242
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3022309
	speed: 0.0376s/iter; left time: 976.5050s
	iters: 200, epoch: 1 | loss: 0.2849053
	speed: 0.0350s/iter; left time: 905.2760s
Epoch: 1 cost time: 9.393749952316284
Epoch: 1, Steps: 261 Train Loss: 0.3091 (Forecasting Loss:0.2751 + XiCon Loss:3.4013 x Lambda(0.01)), Vali MSE Loss: 0.1996 Test MSE Loss: 0.1409
Validation loss decreased (inf --> 0.199552).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3117858
	speed: 0.0384s/iter; left time: 987.2858s
	iters: 200, epoch: 2 | loss: 0.2780010
	speed: 0.0344s/iter; left time: 882.3091s
Epoch: 2 cost time: 9.385555028915405
Epoch: 2, Steps: 261 Train Loss: 0.2958 (Forecasting Loss:0.2635 + XiCon Loss:3.2352 x Lambda(0.01)), Vali MSE Loss: 0.2058 Test MSE Loss: 0.1496
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2962028
	speed: 0.0382s/iter; left time: 972.7681s
	iters: 200, epoch: 3 | loss: 0.2775677
	speed: 0.0373s/iter; left time: 946.5872s
Epoch: 3 cost time: 9.78420114517212
Epoch: 3, Steps: 261 Train Loss: 0.2679 (Forecasting Loss:0.2358 + XiCon Loss:3.2151 x Lambda(0.01)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1499
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2498433
	speed: 0.0391s/iter; left time: 985.4398s
	iters: 200, epoch: 4 | loss: 0.2545376
	speed: 0.0382s/iter; left time: 960.0739s
Epoch: 4 cost time: 10.074201583862305
Epoch: 4, Steps: 261 Train Loss: 0.2524 (Forecasting Loss:0.2202 + XiCon Loss:3.2218 x Lambda(0.01)), Vali MSE Loss: 0.2209 Test MSE Loss: 0.1496
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2503483
	speed: 0.0417s/iter; left time: 1041.0618s
	iters: 200, epoch: 5 | loss: 0.2793559
	speed: 0.0380s/iter; left time: 944.0464s
Epoch: 5 cost time: 10.21667742729187
Epoch: 5, Steps: 261 Train Loss: 0.2464 (Forecasting Loss:0.2141 + XiCon Loss:3.2235 x Lambda(0.01)), Vali MSE Loss: 0.2266 Test MSE Loss: 0.1520
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2542697
	speed: 0.0405s/iter; left time: 999.4280s
	iters: 200, epoch: 6 | loss: 0.2300633
	speed: 0.0388s/iter; left time: 953.2970s
Epoch: 6 cost time: 10.198335409164429
Epoch: 6, Steps: 261 Train Loss: 0.2431 (Forecasting Loss:0.2109 + XiCon Loss:3.2214 x Lambda(0.01)), Vali MSE Loss: 0.2276 Test MSE Loss: 0.1546
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2383762
	speed: 0.0417s/iter; left time: 1017.8285s
	iters: 200, epoch: 7 | loss: 0.2374772
	speed: 0.0391s/iter; left time: 950.7081s
Epoch: 7 cost time: 10.512097835540771
Epoch: 7, Steps: 261 Train Loss: 0.2414 (Forecasting Loss:0.2092 + XiCon Loss:3.2219 x Lambda(0.01)), Vali MSE Loss: 0.2319 Test MSE Loss: 0.1558
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2374396
	speed: 0.0403s/iter; left time: 974.1927s
	iters: 200, epoch: 8 | loss: 0.2484756
	speed: 0.0384s/iter; left time: 923.6303s
Epoch: 8 cost time: 10.242172956466675
Epoch: 8, Steps: 261 Train Loss: 0.2406 (Forecasting Loss:0.2084 + XiCon Loss:3.2201 x Lambda(0.01)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1551
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2266581
	speed: 0.0417s/iter; left time: 996.2431s
	iters: 200, epoch: 9 | loss: 0.2321460
	speed: 0.0370s/iter; left time: 880.5599s
Epoch: 9 cost time: 10.121809482574463
Epoch: 9, Steps: 261 Train Loss: 0.2404 (Forecasting Loss:0.2082 + XiCon Loss:3.2199 x Lambda(0.01)), Vali MSE Loss: 0.2303 Test MSE Loss: 0.1554
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2432150
	speed: 0.0427s/iter; left time: 1008.8760s
	iters: 200, epoch: 10 | loss: 0.2395561
	speed: 0.0398s/iter; left time: 938.3010s
Epoch: 10 cost time: 10.642656326293945
Epoch: 10, Steps: 261 Train Loss: 0.2403 (Forecasting Loss:0.2081 + XiCon Loss:3.2214 x Lambda(0.01)), Vali MSE Loss: 0.2309 Test MSE Loss: 0.1552
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2211557
	speed: 0.0408s/iter; left time: 954.4441s
	iters: 200, epoch: 11 | loss: 0.2256762
	speed: 0.0383s/iter; left time: 891.5431s
Epoch: 11 cost time: 10.251512050628662
Epoch: 11, Steps: 261 Train Loss: 0.2401 (Forecasting Loss:0.2079 + XiCon Loss:3.2202 x Lambda(0.01)), Vali MSE Loss: 0.2305 Test MSE Loss: 0.1552
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07418714463710785, mae:0.20758788287639618, mape:0.15635675191879272, mspe:0.04046321287751198 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.2898
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3050063
	speed: 0.0348s/iter; left time: 906.1235s
	iters: 200, epoch: 1 | loss: 0.3194211
	speed: 0.0306s/iter; left time: 793.6077s
Epoch: 1 cost time: 8.475854873657227
Epoch: 1, Steps: 261 Train Loss: 0.3100 (Forecasting Loss:0.2761 + XiCon Loss:3.3854 x Lambda(0.01)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1410
Validation loss decreased (inf --> 0.199813).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2949690
	speed: 0.0344s/iter; left time: 885.9696s
	iters: 200, epoch: 2 | loss: 0.2874397
	speed: 0.0318s/iter; left time: 815.4018s
Epoch: 2 cost time: 8.517724514007568
Epoch: 2, Steps: 261 Train Loss: 0.2955 (Forecasting Loss:0.2621 + XiCon Loss:3.3399 x Lambda(0.01)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1430
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2828159
	speed: 0.0349s/iter; left time: 889.4933s
	iters: 200, epoch: 3 | loss: 0.2727090
	speed: 0.0332s/iter; left time: 842.0889s
Epoch: 3 cost time: 8.840885639190674
Epoch: 3, Steps: 261 Train Loss: 0.2662 (Forecasting Loss:0.2331 + XiCon Loss:3.3167 x Lambda(0.01)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1540
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2333808
	speed: 0.0380s/iter; left time: 958.5025s
	iters: 200, epoch: 4 | loss: 0.2509853
	speed: 0.0341s/iter; left time: 855.9661s
Epoch: 4 cost time: 9.272355079650879
Epoch: 4, Steps: 261 Train Loss: 0.2506 (Forecasting Loss:0.2174 + XiCon Loss:3.3173 x Lambda(0.01)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.1580
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2408819
	speed: 0.0372s/iter; left time: 927.3992s
	iters: 200, epoch: 5 | loss: 0.2305459
	speed: 0.0339s/iter; left time: 843.8080s
Epoch: 5 cost time: 9.148144483566284
Epoch: 5, Steps: 261 Train Loss: 0.2434 (Forecasting Loss:0.2102 + XiCon Loss:3.3168 x Lambda(0.01)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1588
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2357165
	speed: 0.0357s/iter; left time: 881.7410s
	iters: 200, epoch: 6 | loss: 0.2409523
	speed: 0.0336s/iter; left time: 825.6149s
Epoch: 6 cost time: 8.997812986373901
Epoch: 6, Steps: 261 Train Loss: 0.2406 (Forecasting Loss:0.2074 + XiCon Loss:3.3175 x Lambda(0.01)), Vali MSE Loss: 0.2189 Test MSE Loss: 0.1574
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2332066
	speed: 0.0380s/iter; left time: 928.4182s
	iters: 200, epoch: 7 | loss: 0.2364816
	speed: 0.0327s/iter; left time: 795.6038s
Epoch: 7 cost time: 9.099254131317139
Epoch: 7, Steps: 261 Train Loss: 0.2390 (Forecasting Loss:0.2059 + XiCon Loss:3.3164 x Lambda(0.01)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1569
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2306560
	speed: 0.0366s/iter; left time: 885.0943s
	iters: 200, epoch: 8 | loss: 0.2340780
	speed: 0.0344s/iter; left time: 827.0963s
Epoch: 8 cost time: 9.200999975204468
Epoch: 8, Steps: 261 Train Loss: 0.2386 (Forecasting Loss:0.2054 + XiCon Loss:3.3174 x Lambda(0.01)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.1562
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2465662
	speed: 0.0372s/iter; left time: 889.7089s
	iters: 200, epoch: 9 | loss: 0.2481140
	speed: 0.0334s/iter; left time: 796.5310s
Epoch: 9 cost time: 9.095669507980347
Epoch: 9, Steps: 261 Train Loss: 0.2380 (Forecasting Loss:0.2048 + XiCon Loss:3.3170 x Lambda(0.01)), Vali MSE Loss: 0.2190 Test MSE Loss: 0.1563
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2430895
	speed: 0.0375s/iter; left time: 887.4395s
	iters: 200, epoch: 10 | loss: 0.2295730
	speed: 0.0338s/iter; left time: 795.5555s
Epoch: 10 cost time: 9.168138980865479
Epoch: 10, Steps: 261 Train Loss: 0.2379 (Forecasting Loss:0.2047 + XiCon Loss:3.3177 x Lambda(0.01)), Vali MSE Loss: 0.2180 Test MSE Loss: 0.1563
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2321179
	speed: 0.0380s/iter; left time: 889.6647s
	iters: 200, epoch: 11 | loss: 0.2434160
	speed: 0.0340s/iter; left time: 790.7713s
Epoch: 11 cost time: 9.285194635391235
Epoch: 11, Steps: 261 Train Loss: 0.2377 (Forecasting Loss:0.2045 + XiCon Loss:3.3166 x Lambda(0.01)), Vali MSE Loss: 0.2182 Test MSE Loss: 0.1564
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07418964803218842, mae:0.2077149599790573, mape:0.1565868854522705, mspe:0.04078896716237068 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.8221
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.3151723
	speed: 0.0384s/iter; left time: 999.6223s
	iters: 200, epoch: 1 | loss: 0.3166878
	speed: 0.0359s/iter; left time: 929.6727s
Epoch: 1 cost time: 9.56520676612854
Epoch: 1, Steps: 261 Train Loss: 0.3103 (Forecasting Loss:0.2765 + XiCon Loss:3.3812 x Lambda(0.01)), Vali MSE Loss: 0.1988 Test MSE Loss: 0.1426
Validation loss decreased (inf --> 0.198832).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.3009596
	speed: 0.0383s/iter; left time: 985.9755s
	iters: 200, epoch: 2 | loss: 0.3101657
	speed: 0.0347s/iter; left time: 890.1982s
Epoch: 2 cost time: 9.42990756034851
Epoch: 2, Steps: 261 Train Loss: 0.2926 (Forecasting Loss:0.2595 + XiCon Loss:3.3049 x Lambda(0.01)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1441
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2684565
	speed: 0.0374s/iter; left time: 954.0117s
	iters: 200, epoch: 3 | loss: 0.2765452
	speed: 0.0355s/iter; left time: 901.2604s
Epoch: 3 cost time: 9.449259519577026
Epoch: 3, Steps: 261 Train Loss: 0.2646 (Forecasting Loss:0.2317 + XiCon Loss:3.2937 x Lambda(0.01)), Vali MSE Loss: 0.2259 Test MSE Loss: 0.1584
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2481703
	speed: 0.0372s/iter; left time: 937.6563s
	iters: 200, epoch: 4 | loss: 0.2490143
	speed: 0.0351s/iter; left time: 880.9776s
Epoch: 4 cost time: 9.339583158493042
Epoch: 4, Steps: 261 Train Loss: 0.2484 (Forecasting Loss:0.2154 + XiCon Loss:3.2991 x Lambda(0.01)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1509
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2307040
	speed: 0.0387s/iter; left time: 965.2738s
	iters: 200, epoch: 5 | loss: 0.2568986
	speed: 0.0348s/iter; left time: 864.0424s
Epoch: 5 cost time: 9.44320297241211
Epoch: 5, Steps: 261 Train Loss: 0.2407 (Forecasting Loss:0.2077 + XiCon Loss:3.2977 x Lambda(0.01)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1540
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2347048
	speed: 0.0378s/iter; left time: 932.8631s
	iters: 200, epoch: 6 | loss: 0.2261170
	speed: 0.0358s/iter; left time: 879.4336s
Epoch: 6 cost time: 9.412238597869873
Epoch: 6, Steps: 261 Train Loss: 0.2373 (Forecasting Loss:0.2044 + XiCon Loss:3.2946 x Lambda(0.01)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.1552
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2508512
	speed: 0.0375s/iter; left time: 915.6294s
	iters: 200, epoch: 7 | loss: 0.2418795
	speed: 0.0364s/iter; left time: 885.2849s
Epoch: 7 cost time: 9.481307744979858
Epoch: 7, Steps: 261 Train Loss: 0.2356 (Forecasting Loss:0.2026 + XiCon Loss:3.2934 x Lambda(0.01)), Vali MSE Loss: 0.2181 Test MSE Loss: 0.1543
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2415604
	speed: 0.0372s/iter; left time: 900.3671s
	iters: 200, epoch: 8 | loss: 0.2497333
	speed: 0.0346s/iter; left time: 833.3842s
Epoch: 8 cost time: 9.28495478630066
Epoch: 8, Steps: 261 Train Loss: 0.2345 (Forecasting Loss:0.2016 + XiCon Loss:3.2923 x Lambda(0.01)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1543
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2372831
	speed: 0.0387s/iter; left time: 925.5494s
	iters: 200, epoch: 9 | loss: 0.2229825
	speed: 0.0340s/iter; left time: 808.7102s
Epoch: 9 cost time: 9.393787860870361
Epoch: 9, Steps: 261 Train Loss: 0.2341 (Forecasting Loss:0.2012 + XiCon Loss:3.2924 x Lambda(0.01)), Vali MSE Loss: 0.2183 Test MSE Loss: 0.1549
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2404478
	speed: 0.0376s/iter; left time: 888.9961s
	iters: 200, epoch: 10 | loss: 0.2195269
	speed: 0.0348s/iter; left time: 819.7459s
Epoch: 10 cost time: 9.335376024246216
Epoch: 10, Steps: 261 Train Loss: 0.2338 (Forecasting Loss:0.2009 + XiCon Loss:3.2934 x Lambda(0.01)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1549
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2417246
	speed: 0.0372s/iter; left time: 869.3994s
	iters: 200, epoch: 11 | loss: 0.2248412
	speed: 0.0351s/iter; left time: 818.2885s
Epoch: 11 cost time: 9.362109661102295
Epoch: 11, Steps: 261 Train Loss: 0.2338 (Forecasting Loss:0.2009 + XiCon Loss:3.2933 x Lambda(0.01)), Vali MSE Loss: 0.2188 Test MSE Loss: 0.1551
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07553399354219437, mae:0.2096613347530365, mape:0.15725919604301453, mspe:0.04062735661864281 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 18.0669
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.2973543
	speed: 0.0382s/iter; left time: 992.5569s
	iters: 200, epoch: 1 | loss: 0.2941899
	speed: 0.0350s/iter; left time: 905.5254s
Epoch: 1 cost time: 9.470846176147461
Epoch: 1, Steps: 261 Train Loss: 0.3113 (Forecasting Loss:0.2773 + XiCon Loss:3.4006 x Lambda(0.01)), Vali MSE Loss: 0.1974 Test MSE Loss: 0.1404
Validation loss decreased (inf --> 0.197371).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2987628
	speed: 0.0368s/iter; left time: 947.5562s
	iters: 200, epoch: 2 | loss: 0.2877939
	speed: 0.0342s/iter; left time: 877.7862s
Epoch: 2 cost time: 9.212972164154053
Epoch: 2, Steps: 261 Train Loss: 0.3021 (Forecasting Loss:0.2698 + XiCon Loss:3.2306 x Lambda(0.01)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1395
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2486567
	speed: 0.0388s/iter; left time: 988.4143s
	iters: 200, epoch: 3 | loss: 0.2644862
	speed: 0.0354s/iter; left time: 898.5489s
Epoch: 3 cost time: 9.527967929840088
Epoch: 3, Steps: 261 Train Loss: 0.2825 (Forecasting Loss:0.2509 + XiCon Loss:3.1690 x Lambda(0.01)), Vali MSE Loss: 0.1944 Test MSE Loss: 0.1438
Validation loss decreased (0.197371 --> 0.194353).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2781212
	speed: 0.0380s/iter; left time: 957.3313s
	iters: 200, epoch: 4 | loss: 0.2803207
	speed: 0.0355s/iter; left time: 892.1438s
Epoch: 4 cost time: 9.455453395843506
Epoch: 4, Steps: 261 Train Loss: 0.2730 (Forecasting Loss:0.2413 + XiCon Loss:3.1675 x Lambda(0.01)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1519
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2671346
	speed: 0.0380s/iter; left time: 948.0262s
	iters: 200, epoch: 5 | loss: 0.2570933
	speed: 0.0344s/iter; left time: 854.8688s
Epoch: 5 cost time: 9.334614276885986
Epoch: 5, Steps: 261 Train Loss: 0.2683 (Forecasting Loss:0.2366 + XiCon Loss:3.1736 x Lambda(0.01)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1509
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2634606
	speed: 0.0370s/iter; left time: 913.6519s
	iters: 200, epoch: 6 | loss: 0.2526560
	speed: 0.0341s/iter; left time: 837.7116s
Epoch: 6 cost time: 9.166140794754028
Epoch: 6, Steps: 261 Train Loss: 0.2660 (Forecasting Loss:0.2342 + XiCon Loss:3.1749 x Lambda(0.01)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1524
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2512753
	speed: 0.0372s/iter; left time: 909.3643s
	iters: 200, epoch: 7 | loss: 0.2714094
	speed: 0.0346s/iter; left time: 841.3225s
Epoch: 7 cost time: 9.226417064666748
Epoch: 7, Steps: 261 Train Loss: 0.2648 (Forecasting Loss:0.2330 + XiCon Loss:3.1787 x Lambda(0.01)), Vali MSE Loss: 0.2038 Test MSE Loss: 0.1531
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2669537
	speed: 0.0375s/iter; left time: 907.6868s
	iters: 200, epoch: 8 | loss: 0.2506845
	speed: 0.0341s/iter; left time: 821.6747s
Epoch: 8 cost time: 9.210123538970947
Epoch: 8, Steps: 261 Train Loss: 0.2641 (Forecasting Loss:0.2323 + XiCon Loss:3.1796 x Lambda(0.01)), Vali MSE Loss: 0.2036 Test MSE Loss: 0.1532
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2652781
	speed: 0.0374s/iter; left time: 894.0032s
	iters: 200, epoch: 9 | loss: 0.2669084
	speed: 0.0347s/iter; left time: 827.3960s
Epoch: 9 cost time: 9.280631303787231
Epoch: 9, Steps: 261 Train Loss: 0.2640 (Forecasting Loss:0.2322 + XiCon Loss:3.1799 x Lambda(0.01)), Vali MSE Loss: 0.2043 Test MSE Loss: 0.1531
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2772261
	speed: 0.0372s/iter; left time: 879.0154s
	iters: 200, epoch: 10 | loss: 0.2601641
	speed: 0.0357s/iter; left time: 841.7783s
Epoch: 10 cost time: 9.507446765899658
Epoch: 10, Steps: 261 Train Loss: 0.2638 (Forecasting Loss:0.2320 + XiCon Loss:3.1793 x Lambda(0.01)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1533
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2791480
	speed: 0.0380s/iter; left time: 889.5227s
	iters: 200, epoch: 11 | loss: 0.2566006
	speed: 0.0348s/iter; left time: 810.7023s
Epoch: 11 cost time: 9.365447759628296
Epoch: 11, Steps: 261 Train Loss: 0.2635 (Forecasting Loss:0.2316 + XiCon Loss:3.1807 x Lambda(0.01)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1533
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2758753
	speed: 0.0375s/iter; left time: 867.6415s
	iters: 200, epoch: 12 | loss: 0.2523448
	speed: 0.0341s/iter; left time: 785.2597s
Epoch: 12 cost time: 9.279688358306885
Epoch: 12, Steps: 261 Train Loss: 0.2635 (Forecasting Loss:0.2316 + XiCon Loss:3.1812 x Lambda(0.01)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1533
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.3058658
	speed: 0.0370s/iter; left time: 847.0739s
	iters: 200, epoch: 13 | loss: 0.2571254
	speed: 0.0338s/iter; left time: 768.5781s
Epoch: 13 cost time: 9.138028621673584
Epoch: 13, Steps: 261 Train Loss: 0.2635 (Forecasting Loss:0.2317 + XiCon Loss:3.1818 x Lambda(0.01)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1533
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07631605118513107, mae:0.2113059163093567, mape:0.16306161880493164, mspe:0.04679487645626068 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0750+-0.00113, MAE:0.2093+-0.00204, MAPE:0.1592+-0.00427, MSPE:0.0429+-0.00383, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6936
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1988994
	speed: 0.0375s/iter; left time: 995.0071s
	iters: 200, epoch: 1 | loss: 0.2118890
	speed: 0.0322s/iter; left time: 849.7894s
Epoch: 1 cost time: 9.067830324172974
Epoch: 1, Steps: 266 Train Loss: 0.2177 (Forecasting Loss:0.1841 + XiCon Loss:3.3596 x Lambda(0.01)), Vali MSE Loss: 0.1542 Test MSE Loss: 0.1361
Validation loss decreased (inf --> 0.154219).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1901098
	speed: 0.0338s/iter; left time: 886.9177s
	iters: 200, epoch: 2 | loss: 0.1922926
	speed: 0.0306s/iter; left time: 800.5230s
Epoch: 2 cost time: 8.472882509231567
Epoch: 2, Steps: 266 Train Loss: 0.1862 (Forecasting Loss:0.1540 + XiCon Loss:3.2245 x Lambda(0.01)), Vali MSE Loss: 0.1497 Test MSE Loss: 0.1356
Validation loss decreased (0.154219 --> 0.149742).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1701628
	speed: 0.0326s/iter; left time: 847.6660s
	iters: 200, epoch: 3 | loss: 0.1567376
	speed: 0.0314s/iter; left time: 811.1821s
Epoch: 3 cost time: 8.464476823806763
Epoch: 3, Steps: 266 Train Loss: 0.1708 (Forecasting Loss:0.1386 + XiCon Loss:3.2210 x Lambda(0.01)), Vali MSE Loss: 0.1551 Test MSE Loss: 0.1425
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1438054
	speed: 0.0326s/iter; left time: 838.0951s
	iters: 200, epoch: 4 | loss: 0.1545695
	speed: 0.0303s/iter; left time: 776.4632s
Epoch: 4 cost time: 8.291438579559326
Epoch: 4, Steps: 266 Train Loss: 0.1555 (Forecasting Loss:0.1231 + XiCon Loss:3.2409 x Lambda(0.01)), Vali MSE Loss: 0.1580 Test MSE Loss: 0.1450
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1499530
	speed: 0.0325s/iter; left time: 826.6878s
	iters: 200, epoch: 5 | loss: 0.1468362
	speed: 0.0315s/iter; left time: 799.3236s
Epoch: 5 cost time: 8.628415822982788
Epoch: 5, Steps: 266 Train Loss: 0.1443 (Forecasting Loss:0.1119 + XiCon Loss:3.2411 x Lambda(0.01)), Vali MSE Loss: 0.1552 Test MSE Loss: 0.1480
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1394406
	speed: 0.0328s/iter; left time: 825.7280s
	iters: 200, epoch: 6 | loss: 0.1314149
	speed: 0.0306s/iter; left time: 768.1589s
Epoch: 6 cost time: 8.438998937606812
Epoch: 6, Steps: 266 Train Loss: 0.1398 (Forecasting Loss:0.1073 + XiCon Loss:3.2453 x Lambda(0.01)), Vali MSE Loss: 0.1522 Test MSE Loss: 0.1491
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1384531
	speed: 0.0334s/iter; left time: 831.2030s
	iters: 200, epoch: 7 | loss: 0.1430870
	speed: 0.0311s/iter; left time: 772.5549s
Epoch: 7 cost time: 8.488725900650024
Epoch: 7, Steps: 266 Train Loss: 0.1375 (Forecasting Loss:0.1051 + XiCon Loss:3.2470 x Lambda(0.01)), Vali MSE Loss: 0.1531 Test MSE Loss: 0.1491
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1379472
	speed: 0.0332s/iter; left time: 817.6021s
	iters: 200, epoch: 8 | loss: 0.1401684
	speed: 0.0312s/iter; left time: 765.0596s
Epoch: 8 cost time: 8.493274688720703
Epoch: 8, Steps: 266 Train Loss: 0.1368 (Forecasting Loss:0.1043 + XiCon Loss:3.2473 x Lambda(0.01)), Vali MSE Loss: 0.1543 Test MSE Loss: 0.1498
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1409455
	speed: 0.0325s/iter; left time: 791.2370s
	iters: 200, epoch: 9 | loss: 0.1284955
	speed: 0.0305s/iter; left time: 740.1444s
Epoch: 9 cost time: 8.325339794158936
Epoch: 9, Steps: 266 Train Loss: 0.1361 (Forecasting Loss:0.1036 + XiCon Loss:3.2493 x Lambda(0.01)), Vali MSE Loss: 0.1541 Test MSE Loss: 0.1495
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1457183
	speed: 0.0330s/iter; left time: 795.4218s
	iters: 200, epoch: 10 | loss: 0.1308946
	speed: 0.0310s/iter; left time: 744.4474s
Epoch: 10 cost time: 8.465792894363403
Epoch: 10, Steps: 266 Train Loss: 0.1359 (Forecasting Loss:0.1034 + XiCon Loss:3.2503 x Lambda(0.01)), Vali MSE Loss: 0.1546 Test MSE Loss: 0.1506
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1334319
	speed: 0.0330s/iter; left time: 786.8913s
	iters: 200, epoch: 11 | loss: 0.1471846
	speed: 0.0310s/iter; left time: 735.6111s
Epoch: 11 cost time: 8.429957628250122
Epoch: 11, Steps: 266 Train Loss: 0.1358 (Forecasting Loss:0.1033 + XiCon Loss:3.2488 x Lambda(0.01)), Vali MSE Loss: 0.1542 Test MSE Loss: 0.1502
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1416999
	speed: 0.0323s/iter; left time: 760.4467s
	iters: 200, epoch: 12 | loss: 0.1319562
	speed: 0.0307s/iter; left time: 719.8609s
Epoch: 12 cost time: 8.33407974243164
Epoch: 12, Steps: 266 Train Loss: 0.1356 (Forecasting Loss:0.1031 + XiCon Loss:3.2499 x Lambda(0.01)), Vali MSE Loss: 0.1541 Test MSE Loss: 0.1504
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07257296144962311, mae:0.19864186644554138, mape:0.5067909955978394, mspe:10.50756549835205 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7835
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2115167
	speed: 0.0333s/iter; left time: 882.4216s
	iters: 200, epoch: 1 | loss: 0.1648791
	speed: 0.0320s/iter; left time: 845.2045s
Epoch: 1 cost time: 8.640337944030762
Epoch: 1, Steps: 266 Train Loss: 0.2195 (Forecasting Loss:0.1859 + XiCon Loss:3.3651 x Lambda(0.01)), Vali MSE Loss: 0.1582 Test MSE Loss: 0.1354
Validation loss decreased (inf --> 0.158249).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1814859
	speed: 0.0337s/iter; left time: 884.8783s
	iters: 200, epoch: 2 | loss: 0.1667697
	speed: 0.0309s/iter; left time: 808.3246s
Epoch: 2 cost time: 8.477832078933716
Epoch: 2, Steps: 266 Train Loss: 0.1826 (Forecasting Loss:0.1497 + XiCon Loss:3.2887 x Lambda(0.01)), Vali MSE Loss: 0.1566 Test MSE Loss: 0.1394
Validation loss decreased (0.158249 --> 0.156581).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1736950
	speed: 0.0328s/iter; left time: 851.7904s
	iters: 200, epoch: 3 | loss: 0.1555590
	speed: 0.0313s/iter; left time: 809.8599s
Epoch: 3 cost time: 8.411973476409912
Epoch: 3, Steps: 266 Train Loss: 0.1649 (Forecasting Loss:0.1325 + XiCon Loss:3.2353 x Lambda(0.01)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1498
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1576569
	speed: 0.0339s/iter; left time: 871.5134s
	iters: 200, epoch: 4 | loss: 0.1509520
	speed: 0.0317s/iter; left time: 811.7536s
Epoch: 4 cost time: 8.599669218063354
Epoch: 4, Steps: 266 Train Loss: 0.1500 (Forecasting Loss:0.1178 + XiCon Loss:3.2189 x Lambda(0.01)), Vali MSE Loss: 0.1762 Test MSE Loss: 0.1561
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1316891
	speed: 0.0335s/iter; left time: 852.9456s
	iters: 200, epoch: 5 | loss: 0.1340571
	speed: 0.0305s/iter; left time: 773.4452s
Epoch: 5 cost time: 8.47861099243164
Epoch: 5, Steps: 266 Train Loss: 0.1411 (Forecasting Loss:0.1090 + XiCon Loss:3.2088 x Lambda(0.01)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1600
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1321628
	speed: 0.0339s/iter; left time: 853.0054s
	iters: 200, epoch: 6 | loss: 0.1456356
	speed: 0.0315s/iter; left time: 790.8370s
Epoch: 6 cost time: 8.619295120239258
Epoch: 6, Steps: 266 Train Loss: 0.1368 (Forecasting Loss:0.1047 + XiCon Loss:3.2104 x Lambda(0.01)), Vali MSE Loss: 0.1766 Test MSE Loss: 0.1583
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1414729
	speed: 0.0334s/iter; left time: 830.7468s
	iters: 200, epoch: 7 | loss: 0.1297354
	speed: 0.0310s/iter; left time: 767.8208s
Epoch: 7 cost time: 8.448819398880005
Epoch: 7, Steps: 266 Train Loss: 0.1347 (Forecasting Loss:0.1026 + XiCon Loss:3.2061 x Lambda(0.01)), Vali MSE Loss: 0.1779 Test MSE Loss: 0.1621
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1309400
	speed: 0.0332s/iter; left time: 817.3770s
	iters: 200, epoch: 8 | loss: 0.1321341
	speed: 0.0308s/iter; left time: 756.4803s
Epoch: 8 cost time: 8.421183109283447
Epoch: 8, Steps: 266 Train Loss: 0.1334 (Forecasting Loss:0.1014 + XiCon Loss:3.2062 x Lambda(0.01)), Vali MSE Loss: 0.1788 Test MSE Loss: 0.1624
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1263200
	speed: 0.0326s/iter; left time: 794.5508s
	iters: 200, epoch: 9 | loss: 0.1216185
	speed: 0.0307s/iter; left time: 745.8934s
Epoch: 9 cost time: 8.337599515914917
Epoch: 9, Steps: 266 Train Loss: 0.1332 (Forecasting Loss:0.1011 + XiCon Loss:3.2069 x Lambda(0.01)), Vali MSE Loss: 0.1792 Test MSE Loss: 0.1624
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1267766
	speed: 0.0327s/iter; left time: 789.1033s
	iters: 200, epoch: 10 | loss: 0.1242995
	speed: 0.0314s/iter; left time: 753.2243s
Epoch: 10 cost time: 8.53317928314209
Epoch: 10, Steps: 266 Train Loss: 0.1331 (Forecasting Loss:0.1010 + XiCon Loss:3.2081 x Lambda(0.01)), Vali MSE Loss: 0.1792 Test MSE Loss: 0.1624
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1243488
	speed: 0.0339s/iter; left time: 808.7668s
	iters: 200, epoch: 11 | loss: 0.1316402
	speed: 0.0320s/iter; left time: 759.6834s
Epoch: 11 cost time: 8.615943431854248
Epoch: 11, Steps: 266 Train Loss: 0.1327 (Forecasting Loss:0.1006 + XiCon Loss:3.2066 x Lambda(0.01)), Vali MSE Loss: 0.1797 Test MSE Loss: 0.1628
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1164218
	speed: 0.0334s/iter; left time: 786.8512s
	iters: 200, epoch: 12 | loss: 0.1368859
	speed: 0.0306s/iter; left time: 717.6235s
Epoch: 12 cost time: 8.415897369384766
Epoch: 12, Steps: 266 Train Loss: 0.1328 (Forecasting Loss:0.1008 + XiCon Loss:3.2061 x Lambda(0.01)), Vali MSE Loss: 0.1797 Test MSE Loss: 0.1628
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07524597644805908, mae:0.20355026423931122, mape:0.5127484202384949, mspe:10.451611518859863 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7839
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.1949421
	speed: 0.0329s/iter; left time: 871.2375s
	iters: 200, epoch: 1 | loss: 0.1959212
	speed: 0.0327s/iter; left time: 864.2290s
Epoch: 1 cost time: 8.680562734603882
Epoch: 1, Steps: 266 Train Loss: 0.2127 (Forecasting Loss:0.1791 + XiCon Loss:3.3618 x Lambda(0.01)), Vali MSE Loss: 0.1565 Test MSE Loss: 0.1356
Validation loss decreased (inf --> 0.156516).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1715444
	speed: 0.0327s/iter; left time: 857.6729s
	iters: 200, epoch: 2 | loss: 0.2150942
	speed: 0.0310s/iter; left time: 811.1982s
Epoch: 2 cost time: 8.413355588912964
Epoch: 2, Steps: 266 Train Loss: 0.1849 (Forecasting Loss:0.1524 + XiCon Loss:3.2454 x Lambda(0.01)), Vali MSE Loss: 0.1519 Test MSE Loss: 0.1405
Validation loss decreased (0.156516 --> 0.151888).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1706758
	speed: 0.0329s/iter; left time: 854.5549s
	iters: 200, epoch: 3 | loss: 0.1518496
	speed: 0.0306s/iter; left time: 791.0874s
Epoch: 3 cost time: 8.360856294631958
Epoch: 3, Steps: 266 Train Loss: 0.1644 (Forecasting Loss:0.1325 + XiCon Loss:3.1867 x Lambda(0.01)), Vali MSE Loss: 0.1545 Test MSE Loss: 0.1551
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1478136
	speed: 0.0329s/iter; left time: 845.9817s
	iters: 200, epoch: 4 | loss: 0.1560835
	speed: 0.0310s/iter; left time: 793.4545s
Epoch: 4 cost time: 8.398632287979126
Epoch: 4, Steps: 266 Train Loss: 0.1474 (Forecasting Loss:0.1156 + XiCon Loss:3.1810 x Lambda(0.01)), Vali MSE Loss: 0.1601 Test MSE Loss: 0.1630
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1337319
	speed: 0.0333s/iter; left time: 846.2246s
	iters: 200, epoch: 5 | loss: 0.1343849
	speed: 0.0303s/iter; left time: 766.5055s
Epoch: 5 cost time: 8.367883682250977
Epoch: 5, Steps: 266 Train Loss: 0.1359 (Forecasting Loss:0.1041 + XiCon Loss:3.1786 x Lambda(0.01)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1742
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1314031
	speed: 0.0335s/iter; left time: 843.0411s
	iters: 200, epoch: 6 | loss: 0.1288256
	speed: 0.0307s/iter; left time: 768.8836s
Epoch: 6 cost time: 8.488398790359497
Epoch: 6, Steps: 266 Train Loss: 0.1311 (Forecasting Loss:0.0993 + XiCon Loss:3.1800 x Lambda(0.01)), Vali MSE Loss: 0.1649 Test MSE Loss: 0.1685
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1235299
	speed: 0.0322s/iter; left time: 800.9509s
	iters: 200, epoch: 7 | loss: 0.1220919
	speed: 0.0297s/iter; left time: 737.3565s
Epoch: 7 cost time: 8.219924449920654
Epoch: 7, Steps: 266 Train Loss: 0.1288 (Forecasting Loss:0.0970 + XiCon Loss:3.1809 x Lambda(0.01)), Vali MSE Loss: 0.1674 Test MSE Loss: 0.1725
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1299468
	speed: 0.0327s/iter; left time: 804.5232s
	iters: 200, epoch: 8 | loss: 0.1192435
	speed: 0.0308s/iter; left time: 754.9065s
Epoch: 8 cost time: 8.38788890838623
Epoch: 8, Steps: 266 Train Loss: 0.1276 (Forecasting Loss:0.0958 + XiCon Loss:3.1813 x Lambda(0.01)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1733
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1329482
	speed: 0.0332s/iter; left time: 809.0395s
	iters: 200, epoch: 9 | loss: 0.1300514
	speed: 0.0313s/iter; left time: 760.2673s
Epoch: 9 cost time: 8.501021146774292
Epoch: 9, Steps: 266 Train Loss: 0.1273 (Forecasting Loss:0.0955 + XiCon Loss:3.1824 x Lambda(0.01)), Vali MSE Loss: 0.1682 Test MSE Loss: 0.1721
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1250568
	speed: 0.0328s/iter; left time: 789.8514s
	iters: 200, epoch: 10 | loss: 0.1203515
	speed: 0.0315s/iter; left time: 756.9608s
Epoch: 10 cost time: 8.53324580192566
Epoch: 10, Steps: 266 Train Loss: 0.1271 (Forecasting Loss:0.0953 + XiCon Loss:3.1804 x Lambda(0.01)), Vali MSE Loss: 0.1684 Test MSE Loss: 0.1729
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1254608
	speed: 0.0336s/iter; left time: 800.0759s
	iters: 200, epoch: 11 | loss: 0.1391139
	speed: 0.0310s/iter; left time: 734.8600s
Epoch: 11 cost time: 8.449151515960693
Epoch: 11, Steps: 266 Train Loss: 0.1270 (Forecasting Loss:0.0952 + XiCon Loss:3.1818 x Lambda(0.01)), Vali MSE Loss: 0.1682 Test MSE Loss: 0.1730
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1444544
	speed: 0.0341s/iter; left time: 803.0784s
	iters: 200, epoch: 12 | loss: 0.1347295
	speed: 0.0320s/iter; left time: 751.4077s
Epoch: 12 cost time: 8.651285648345947
Epoch: 12, Steps: 266 Train Loss: 0.1269 (Forecasting Loss:0.0951 + XiCon Loss:3.1819 x Lambda(0.01)), Vali MSE Loss: 0.1685 Test MSE Loss: 0.1733
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07656300812959671, mae:0.2044467031955719, mape:0.5062364339828491, mspe:9.758996963500977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7380
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2270229
	speed: 0.0340s/iter; left time: 901.7587s
	iters: 200, epoch: 1 | loss: 0.1966751
	speed: 0.0325s/iter; left time: 857.9765s
Epoch: 1 cost time: 8.815595149993896
Epoch: 1, Steps: 266 Train Loss: 0.2182 (Forecasting Loss:0.1845 + XiCon Loss:3.3705 x Lambda(0.01)), Vali MSE Loss: 0.1578 Test MSE Loss: 0.1358
Validation loss decreased (inf --> 0.157801).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2018181
	speed: 0.0338s/iter; left time: 887.9801s
	iters: 200, epoch: 2 | loss: 0.1707050
	speed: 0.0316s/iter; left time: 826.1948s
Epoch: 2 cost time: 8.569868087768555
Epoch: 2, Steps: 266 Train Loss: 0.1836 (Forecasting Loss:0.1510 + XiCon Loss:3.2620 x Lambda(0.01)), Vali MSE Loss: 0.1588 Test MSE Loss: 0.1441
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1591454
	speed: 0.0339s/iter; left time: 880.7553s
	iters: 200, epoch: 3 | loss: 0.1612598
	speed: 0.0314s/iter; left time: 813.1668s
Epoch: 3 cost time: 8.633638381958008
Epoch: 3, Steps: 266 Train Loss: 0.1614 (Forecasting Loss:0.1293 + XiCon Loss:3.2066 x Lambda(0.01)), Vali MSE Loss: 0.1687 Test MSE Loss: 0.1502
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1528831
	speed: 0.0331s/iter; left time: 851.5178s
	iters: 200, epoch: 4 | loss: 0.1366235
	speed: 0.0322s/iter; left time: 824.7828s
Epoch: 4 cost time: 8.57713770866394
Epoch: 4, Steps: 266 Train Loss: 0.1471 (Forecasting Loss:0.1152 + XiCon Loss:3.1947 x Lambda(0.01)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1618
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1429516
	speed: 0.0321s/iter; left time: 815.4417s
	iters: 200, epoch: 5 | loss: 0.1374147
	speed: 0.0305s/iter; left time: 773.5324s
Epoch: 5 cost time: 8.355895280838013
Epoch: 5, Steps: 266 Train Loss: 0.1390 (Forecasting Loss:0.1070 + XiCon Loss:3.1962 x Lambda(0.01)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1620
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1312026
	speed: 0.0331s/iter; left time: 833.1270s
	iters: 200, epoch: 6 | loss: 0.1297582
	speed: 0.0313s/iter; left time: 784.9779s
Epoch: 6 cost time: 8.463919639587402
Epoch: 6, Steps: 266 Train Loss: 0.1348 (Forecasting Loss:0.1029 + XiCon Loss:3.1956 x Lambda(0.01)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1629
EarlyStopping counter: 5 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1375652
	speed: 0.0334s/iter; left time: 831.9982s
	iters: 200, epoch: 7 | loss: 0.1377948
	speed: 0.0307s/iter; left time: 760.3516s
Epoch: 7 cost time: 8.463969707489014
Epoch: 7, Steps: 266 Train Loss: 0.1328 (Forecasting Loss:0.1008 + XiCon Loss:3.1960 x Lambda(0.01)), Vali MSE Loss: 0.1894 Test MSE Loss: 0.1656
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1333315
	speed: 0.0321s/iter; left time: 791.9356s
	iters: 200, epoch: 8 | loss: 0.1299659
	speed: 0.0307s/iter; left time: 752.9021s
Epoch: 8 cost time: 8.325101137161255
Epoch: 8, Steps: 266 Train Loss: 0.1319 (Forecasting Loss:0.0999 + XiCon Loss:3.1962 x Lambda(0.01)), Vali MSE Loss: 0.1876 Test MSE Loss: 0.1650
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1290822
	speed: 0.0334s/iter; left time: 814.9041s
	iters: 200, epoch: 9 | loss: 0.1255331
	speed: 0.0304s/iter; left time: 738.4023s
Epoch: 9 cost time: 8.455162763595581
Epoch: 9, Steps: 266 Train Loss: 0.1315 (Forecasting Loss:0.0995 + XiCon Loss:3.1961 x Lambda(0.01)), Vali MSE Loss: 0.1876 Test MSE Loss: 0.1649
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1313850
	speed: 0.0333s/iter; left time: 802.8618s
	iters: 200, epoch: 10 | loss: 0.1351704
	speed: 0.0332s/iter; left time: 797.3520s
Epoch: 10 cost time: 8.816842079162598
Epoch: 10, Steps: 266 Train Loss: 0.1311 (Forecasting Loss:0.0991 + XiCon Loss:3.1958 x Lambda(0.01)), Vali MSE Loss: 0.1879 Test MSE Loss: 0.1650
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1286854
	speed: 0.0343s/iter; left time: 818.4882s
	iters: 200, epoch: 11 | loss: 0.1333418
	speed: 0.0323s/iter; left time: 767.5343s
Epoch: 11 cost time: 8.798539400100708
Epoch: 11, Steps: 266 Train Loss: 0.1310 (Forecasting Loss:0.0991 + XiCon Loss:3.1976 x Lambda(0.01)), Vali MSE Loss: 0.1881 Test MSE Loss: 0.1651
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07137239724397659, mae:0.200180321931839, mape:0.48795709013938904, mspe:9.14760971069336 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7515
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 0.2206573
	speed: 0.0334s/iter; left time: 884.1182s
	iters: 200, epoch: 1 | loss: 0.1826443
	speed: 0.0308s/iter; left time: 812.4013s
Epoch: 1 cost time: 8.41930079460144
Epoch: 1, Steps: 266 Train Loss: 0.2200 (Forecasting Loss:0.1864 + XiCon Loss:3.3552 x Lambda(0.01)), Vali MSE Loss: 0.1565 Test MSE Loss: 0.1361
Validation loss decreased (inf --> 0.156546).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.1808065
	speed: 0.0334s/iter; left time: 876.5980s
	iters: 200, epoch: 2 | loss: 0.1691398
	speed: 0.0322s/iter; left time: 840.3560s
Epoch: 2 cost time: 8.682469129562378
Epoch: 2, Steps: 266 Train Loss: 0.1852 (Forecasting Loss:0.1529 + XiCon Loss:3.2292 x Lambda(0.01)), Vali MSE Loss: 0.1474 Test MSE Loss: 0.1365
Validation loss decreased (0.156546 --> 0.147389).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.1715584
	speed: 0.0345s/iter; left time: 895.0333s
	iters: 200, epoch: 3 | loss: 0.1685768
	speed: 0.0310s/iter; left time: 802.8276s
Epoch: 3 cost time: 8.576701641082764
Epoch: 3, Steps: 266 Train Loss: 0.1639 (Forecasting Loss:0.1316 + XiCon Loss:3.2338 x Lambda(0.01)), Vali MSE Loss: 0.1596 Test MSE Loss: 0.1444
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.1498093
	speed: 0.0331s/iter; left time: 851.3753s
	iters: 200, epoch: 4 | loss: 0.1608944
	speed: 0.0313s/iter; left time: 800.3877s
Epoch: 4 cost time: 8.41727900505066
Epoch: 4, Steps: 266 Train Loss: 0.1479 (Forecasting Loss:0.1152 + XiCon Loss:3.2724 x Lambda(0.01)), Vali MSE Loss: 0.1677 Test MSE Loss: 0.1518
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.1446064
	speed: 0.0312s/iter; left time: 794.0015s
	iters: 200, epoch: 5 | loss: 0.1445079
	speed: 0.0296s/iter; left time: 749.8445s
Epoch: 5 cost time: 8.01139211654663
Epoch: 5, Steps: 266 Train Loss: 0.1402 (Forecasting Loss:0.1073 + XiCon Loss:3.2911 x Lambda(0.01)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1562
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.1373905
	speed: 0.0332s/iter; left time: 836.9233s
	iters: 200, epoch: 6 | loss: 0.1459317
	speed: 0.0315s/iter; left time: 789.2014s
Epoch: 6 cost time: 8.499309778213501
Epoch: 6, Steps: 266 Train Loss: 0.1363 (Forecasting Loss:0.1033 + XiCon Loss:3.2991 x Lambda(0.01)), Vali MSE Loss: 0.1692 Test MSE Loss: 0.1607
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.1387802
	speed: 0.0338s/iter; left time: 840.9244s
	iters: 200, epoch: 7 | loss: 0.1264586
	speed: 0.0314s/iter; left time: 779.2979s
Epoch: 7 cost time: 8.613012552261353
Epoch: 7, Steps: 266 Train Loss: 0.1348 (Forecasting Loss:0.1018 + XiCon Loss:3.3002 x Lambda(0.01)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1582
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.1346797
	speed: 0.0335s/iter; left time: 825.7691s
	iters: 200, epoch: 8 | loss: 0.1321466
	speed: 0.0311s/iter; left time: 762.8044s
Epoch: 8 cost time: 8.511007070541382
Epoch: 8, Steps: 266 Train Loss: 0.1338 (Forecasting Loss:0.1007 + XiCon Loss:3.3055 x Lambda(0.01)), Vali MSE Loss: 0.1716 Test MSE Loss: 0.1584
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.1285080
	speed: 0.0326s/iter; left time: 795.3243s
	iters: 200, epoch: 9 | loss: 0.1272810
	speed: 0.0308s/iter; left time: 746.8746s
Epoch: 9 cost time: 8.348442554473877
Epoch: 9, Steps: 266 Train Loss: 0.1334 (Forecasting Loss:0.1003 + XiCon Loss:3.3041 x Lambda(0.01)), Vali MSE Loss: 0.1709 Test MSE Loss: 0.1590
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.1486070
	speed: 0.0322s/iter; left time: 776.7371s
	iters: 200, epoch: 10 | loss: 0.1247412
	speed: 0.0311s/iter; left time: 747.3568s
Epoch: 10 cost time: 8.39757490158081
Epoch: 10, Steps: 266 Train Loss: 0.1333 (Forecasting Loss:0.1002 + XiCon Loss:3.3040 x Lambda(0.01)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1601
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.1355242
	speed: 0.0331s/iter; left time: 789.0330s
	iters: 200, epoch: 11 | loss: 0.1293550
	speed: 0.0320s/iter; left time: 759.8291s
Epoch: 11 cost time: 8.623324155807495
Epoch: 11, Steps: 266 Train Loss: 0.1330 (Forecasting Loss:0.1000 + XiCon Loss:3.3085 x Lambda(0.01)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1600
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.1374356
	speed: 0.0326s/iter; left time: 768.7651s
	iters: 200, epoch: 12 | loss: 0.1351681
	speed: 0.0311s/iter; left time: 728.9913s
Epoch: 12 cost time: 8.47629690170288
Epoch: 12, Steps: 266 Train Loss: 0.1331 (Forecasting Loss:0.1001 + XiCon Loss:3.3077 x Lambda(0.01)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1599
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.07287154346704483, mae:0.20018447935581207, mape:0.50858074426651, mspe:10.545160293579102 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0737+-0.00263, MAE:0.2014+-0.00307, MAPE:0.5045+-0.01189, MSPE:10.0822+-0.76280, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6630
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3989191
	speed: 0.0372s/iter; left time: 982.5250s
	iters: 200, epoch: 1 | loss: 0.3866965
	speed: 0.0321s/iter; left time: 844.1607s
Epoch: 1 cost time: 8.989328384399414
Epoch: 1, Steps: 265 Train Loss: 0.3853 (Forecasting Loss:0.3530 + XiCon Loss:3.2312 x Lambda(0.01)), Vali MSE Loss: 0.3360 Test MSE Loss: 0.2773
Validation loss decreased (inf --> 0.336014).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2480514
	speed: 0.0346s/iter; left time: 904.4633s
	iters: 200, epoch: 2 | loss: 0.2754827
	speed: 0.0317s/iter; left time: 826.0465s
Epoch: 2 cost time: 8.70975112915039
Epoch: 2, Steps: 265 Train Loss: 0.2691 (Forecasting Loss:0.2368 + XiCon Loss:3.2240 x Lambda(0.01)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1728
Validation loss decreased (0.336014 --> 0.213095).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2241938
	speed: 0.0326s/iter; left time: 842.1426s
	iters: 200, epoch: 3 | loss: 0.2384542
	speed: 0.0310s/iter; left time: 797.8112s
Epoch: 3 cost time: 8.345946311950684
Epoch: 3, Steps: 265 Train Loss: 0.2425 (Forecasting Loss:0.2103 + XiCon Loss:3.2170 x Lambda(0.01)), Vali MSE Loss: 0.2096 Test MSE Loss: 0.1697
Validation loss decreased (0.213095 --> 0.209607).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2162144
	speed: 0.0336s/iter; left time: 861.3569s
	iters: 200, epoch: 4 | loss: 0.2382360
	speed: 0.0317s/iter; left time: 809.7805s
Epoch: 4 cost time: 8.585600137710571
Epoch: 4, Steps: 265 Train Loss: 0.2393 (Forecasting Loss:0.2072 + XiCon Loss:3.2150 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1685
Validation loss decreased (0.209607 --> 0.208378).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2443007
	speed: 0.0343s/iter; left time: 869.6482s
	iters: 200, epoch: 5 | loss: 0.2356951
	speed: 0.0320s/iter; left time: 807.3929s
Epoch: 5 cost time: 8.720885038375854
Epoch: 5, Steps: 265 Train Loss: 0.2380 (Forecasting Loss:0.2059 + XiCon Loss:3.2115 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1683
Validation loss decreased (0.208378 --> 0.208308).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2644373
	speed: 0.0337s/iter; left time: 844.6594s
	iters: 200, epoch: 6 | loss: 0.2256430
	speed: 0.0317s/iter; left time: 792.9529s
Epoch: 6 cost time: 8.674660205841064
Epoch: 6, Steps: 265 Train Loss: 0.2376 (Forecasting Loss:0.2055 + XiCon Loss:3.2135 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1681
Validation loss decreased (0.208308 --> 0.208264).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2282464
	speed: 0.0344s/iter; left time: 853.3179s
	iters: 200, epoch: 7 | loss: 0.2686535
	speed: 0.0314s/iter; left time: 774.7259s
Epoch: 7 cost time: 8.675281286239624
Epoch: 7, Steps: 265 Train Loss: 0.2376 (Forecasting Loss:0.2055 + XiCon Loss:3.2136 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1681
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2498462
	speed: 0.0332s/iter; left time: 815.0671s
	iters: 200, epoch: 8 | loss: 0.2735811
	speed: 0.0317s/iter; left time: 773.7590s
Epoch: 8 cost time: 8.551399230957031
Epoch: 8, Steps: 265 Train Loss: 0.2372 (Forecasting Loss:0.2051 + XiCon Loss:3.2128 x Lambda(0.01)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1681
Validation loss decreased (0.208264 --> 0.208219).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2407754
	speed: 0.0334s/iter; left time: 811.4259s
	iters: 200, epoch: 9 | loss: 0.2126920
	speed: 0.0313s/iter; left time: 756.2417s
Epoch: 9 cost time: 8.486768960952759
Epoch: 9, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2140 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1681
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2527833
	speed: 0.0344s/iter; left time: 826.2005s
	iters: 200, epoch: 10 | loss: 0.2252179
	speed: 0.0311s/iter; left time: 742.9068s
Epoch: 10 cost time: 8.581807613372803
Epoch: 10, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2106 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1680
Validation loss decreased (0.208219 --> 0.208087).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2403900
	speed: 0.0331s/iter; left time: 785.6563s
	iters: 200, epoch: 11 | loss: 0.2104808
	speed: 0.0322s/iter; left time: 761.6140s
Epoch: 11 cost time: 8.7394278049469
Epoch: 11, Steps: 265 Train Loss: 0.2372 (Forecasting Loss:0.2051 + XiCon Loss:3.2142 x Lambda(0.01)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1680
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2486046
	speed: 0.0337s/iter; left time: 791.0534s
	iters: 200, epoch: 12 | loss: 0.2264897
	speed: 0.0315s/iter; left time: 736.8066s
Epoch: 12 cost time: 8.571970462799072
Epoch: 12, Steps: 265 Train Loss: 0.2373 (Forecasting Loss:0.2051 + XiCon Loss:3.2131 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2513362
	speed: 0.0334s/iter; left time: 776.0869s
	iters: 200, epoch: 13 | loss: 0.2064801
	speed: 0.0310s/iter; left time: 717.4015s
Epoch: 13 cost time: 8.50575590133667
Epoch: 13, Steps: 265 Train Loss: 0.2370 (Forecasting Loss:0.2049 + XiCon Loss:3.2120 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2328821
	speed: 0.0329s/iter; left time: 755.2356s
	iters: 200, epoch: 14 | loss: 0.2296070
	speed: 0.0310s/iter; left time: 709.0975s
Epoch: 14 cost time: 8.462433099746704
Epoch: 14, Steps: 265 Train Loss: 0.2370 (Forecasting Loss:0.2049 + XiCon Loss:3.2119 x Lambda(0.01)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1680
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2685191
	speed: 0.0330s/iter; left time: 749.1562s
	iters: 200, epoch: 15 | loss: 0.2130882
	speed: 0.0305s/iter; left time: 688.9978s
Epoch: 15 cost time: 8.332724809646606
Epoch: 15, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2124 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1680
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2495809
	speed: 0.0318s/iter; left time: 712.9737s
	iters: 200, epoch: 16 | loss: 0.2433295
	speed: 0.0770s/iter; left time: 1719.9000s
Epoch: 16 cost time: 16.179194688796997
Epoch: 16, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2145 x Lambda(0.01)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1680
Validation loss decreased (0.208087 --> 0.208013).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2546394
	speed: 0.0980s/iter; left time: 2172.4192s
	iters: 200, epoch: 17 | loss: 0.2595232
	speed: 0.1005s/iter; left time: 2218.0120s
Epoch: 17 cost time: 25.957431316375732
Epoch: 17, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2049 + XiCon Loss:3.2124 x Lambda(0.01)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1680
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2258730
	speed: 0.0756s/iter; left time: 1655.2573s
	iters: 200, epoch: 18 | loss: 0.2586896
	speed: 0.0723s/iter; left time: 1575.0303s
Epoch: 18 cost time: 19.17885112762451
Epoch: 18, Steps: 265 Train Loss: 0.2369 (Forecasting Loss:0.2048 + XiCon Loss:3.2111 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1680
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2276240
	speed: 0.0618s/iter; left time: 1336.7252s
	iters: 200, epoch: 19 | loss: 0.2347453
	speed: 0.0393s/iter; left time: 845.9314s
Epoch: 19 cost time: 12.598249912261963
Epoch: 19, Steps: 265 Train Loss: 0.2370 (Forecasting Loss:0.2049 + XiCon Loss:3.2118 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.2096294
	speed: 0.0337s/iter; left time: 719.0044s
	iters: 200, epoch: 20 | loss: 0.2381922
	speed: 0.0319s/iter; left time: 678.6303s
Epoch: 20 cost time: 8.685981273651123
Epoch: 20, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2112 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.2221834
	speed: 0.0336s/iter; left time: 708.9498s
	iters: 200, epoch: 21 | loss: 0.2162915
	speed: 0.0309s/iter; left time: 649.3866s
Epoch: 21 cost time: 8.440001010894775
Epoch: 21, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2122 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1680
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.2382660
	speed: 0.0322s/iter; left time: 671.5494s
	iters: 200, epoch: 22 | loss: 0.2337889
	speed: 0.0303s/iter; left time: 629.1015s
Epoch: 22 cost time: 8.230643510818481
Epoch: 22, Steps: 265 Train Loss: 0.2369 (Forecasting Loss:0.2048 + XiCon Loss:3.2118 x Lambda(0.01)), Vali MSE Loss: 0.2082 Test MSE Loss: 0.1680
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.2443800
	speed: 0.0318s/iter; left time: 654.8352s
	iters: 200, epoch: 23 | loss: 0.2217902
	speed: 0.0299s/iter; left time: 611.9206s
Epoch: 23 cost time: 8.172211170196533
Epoch: 23, Steps: 265 Train Loss: 0.2372 (Forecasting Loss:0.2050 + XiCon Loss:3.2118 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2470767
	speed: 0.0314s/iter; left time: 637.4404s
	iters: 200, epoch: 24 | loss: 0.2388538
	speed: 0.0294s/iter; left time: 595.0633s
Epoch: 24 cost time: 7.932166814804077
Epoch: 24, Steps: 265 Train Loss: 0.2372 (Forecasting Loss:0.2051 + XiCon Loss:3.2109 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2427868
	speed: 0.0312s/iter; left time: 624.6786s
	iters: 200, epoch: 25 | loss: 0.2309733
	speed: 0.0285s/iter; left time: 567.6263s
Epoch: 25 cost time: 7.883262395858765
Epoch: 25, Steps: 265 Train Loss: 0.2371 (Forecasting Loss:0.2050 + XiCon Loss:3.2149 x Lambda(0.01)), Vali MSE Loss: 0.2083 Test MSE Loss: 0.1680
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.2514852
	speed: 0.0330s/iter; left time: 652.9910s
	iters: 200, epoch: 26 | loss: 0.2393265
	speed: 0.0308s/iter; left time: 605.3019s
Epoch: 26 cost time: 8.48317837715149
Epoch: 26, Steps: 265 Train Loss: 0.2370 (Forecasting Loss:0.2049 + XiCon Loss:3.2132 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09812799841165543, mae:0.23792116343975067, mape:0.5673724412918091, mspe:11.722583770751953 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6557
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3583966
	speed: 0.0360s/iter; left time: 950.5156s
	iters: 200, epoch: 1 | loss: 0.4024628
	speed: 0.0330s/iter; left time: 868.1879s
Epoch: 1 cost time: 9.126381635665894
Epoch: 1, Steps: 265 Train Loss: 0.3930 (Forecasting Loss:0.3606 + XiCon Loss:3.2453 x Lambda(0.01)), Vali MSE Loss: 0.3354 Test MSE Loss: 0.2827
Validation loss decreased (inf --> 0.335378).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2566154
	speed: 0.0350s/iter; left time: 914.8219s
	iters: 200, epoch: 2 | loss: 0.2672175
	speed: 0.0327s/iter; left time: 851.1367s
Epoch: 2 cost time: 8.842335224151611
Epoch: 2, Steps: 265 Train Loss: 0.2698 (Forecasting Loss:0.2374 + XiCon Loss:3.2368 x Lambda(0.01)), Vali MSE Loss: 0.2144 Test MSE Loss: 0.1713
Validation loss decreased (0.335378 --> 0.214433).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2418721
	speed: 0.0335s/iter; left time: 866.8789s
	iters: 200, epoch: 3 | loss: 0.2232340
	speed: 0.0312s/iter; left time: 803.3070s
Epoch: 3 cost time: 8.5105562210083
Epoch: 3, Steps: 265 Train Loss: 0.2417 (Forecasting Loss:0.2095 + XiCon Loss:3.2258 x Lambda(0.01)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1675
Validation loss decreased (0.214433 --> 0.210245).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2302684
	speed: 0.0344s/iter; left time: 880.3338s
	iters: 200, epoch: 4 | loss: 0.2346407
	speed: 0.0302s/iter; left time: 771.1171s
Epoch: 4 cost time: 8.454435348510742
Epoch: 4, Steps: 265 Train Loss: 0.2383 (Forecasting Loss:0.2061 + XiCon Loss:3.2237 x Lambda(0.01)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1667
Validation loss decreased (0.210245 --> 0.208997).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2327519
	speed: 0.0342s/iter; left time: 865.9843s
	iters: 200, epoch: 5 | loss: 0.2414334
	speed: 0.0314s/iter; left time: 792.7236s
Epoch: 5 cost time: 8.720415830612183
Epoch: 5, Steps: 265 Train Loss: 0.2370 (Forecasting Loss:0.2048 + XiCon Loss:3.2205 x Lambda(0.01)), Vali MSE Loss: 0.2081 Test MSE Loss: 0.1663
Validation loss decreased (0.208997 --> 0.208093).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2560393
	speed: 0.0349s/iter; left time: 875.4254s
	iters: 200, epoch: 6 | loss: 0.2280455
	speed: 0.0321s/iter; left time: 801.1834s
Epoch: 6 cost time: 8.79464864730835
Epoch: 6, Steps: 265 Train Loss: 0.2365 (Forecasting Loss:0.2043 + XiCon Loss:3.2198 x Lambda(0.01)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1661
Validation loss decreased (0.208093 --> 0.207801).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2308884
	speed: 0.0350s/iter; left time: 869.1678s
	iters: 200, epoch: 7 | loss: 0.2380736
	speed: 0.0319s/iter; left time: 787.5491s
Epoch: 7 cost time: 8.758147716522217
Epoch: 7, Steps: 265 Train Loss: 0.2362 (Forecasting Loss:0.2040 + XiCon Loss:3.2197 x Lambda(0.01)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1660
Validation loss decreased (0.207801 --> 0.207497).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2621736
	speed: 0.0334s/iter; left time: 818.7022s
	iters: 200, epoch: 8 | loss: 0.2459154
	speed: 0.0308s/iter; left time: 753.4282s
Epoch: 8 cost time: 8.435079336166382
Epoch: 8, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2038 + XiCon Loss:3.2185 x Lambda(0.01)), Vali MSE Loss: 0.2077 Test MSE Loss: 0.1660
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2377232
	speed: 0.0336s/iter; left time: 814.7938s
	iters: 200, epoch: 9 | loss: 0.2312453
	speed: 0.0309s/iter; left time: 746.5961s
Epoch: 9 cost time: 8.426346063613892
Epoch: 9, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2038 + XiCon Loss:3.2194 x Lambda(0.01)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1659
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2353207
	speed: 0.0332s/iter; left time: 797.3819s
	iters: 200, epoch: 10 | loss: 0.2269255
	speed: 0.0318s/iter; left time: 761.6522s
Epoch: 10 cost time: 8.630694389343262
Epoch: 10, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2188 x Lambda(0.01)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1659
Validation loss decreased (0.207497 --> 0.207302).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2066146
	speed: 0.0338s/iter; left time: 802.3473s
	iters: 200, epoch: 11 | loss: 0.2182360
	speed: 0.0313s/iter; left time: 740.7787s
Epoch: 11 cost time: 8.564303398132324
Epoch: 11, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2196 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2257262
	speed: 0.0340s/iter; left time: 797.9034s
	iters: 200, epoch: 12 | loss: 0.2206489
	speed: 0.0317s/iter; left time: 741.2727s
Epoch: 12 cost time: 8.689580917358398
Epoch: 12, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2179 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1659
Validation loss decreased (0.207302 --> 0.207218).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2448011
	speed: 0.0337s/iter; left time: 783.2778s
	iters: 200, epoch: 13 | loss: 0.2443698
	speed: 0.0317s/iter; left time: 732.8201s
Epoch: 13 cost time: 8.64121699333191
Epoch: 13, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2191 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2325719
	speed: 0.0344s/iter; left time: 790.0944s
	iters: 200, epoch: 14 | loss: 0.2301011
	speed: 0.0338s/iter; left time: 772.8929s
Epoch: 14 cost time: 9.060529708862305
Epoch: 14, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2202 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2525660
	speed: 0.0338s/iter; left time: 767.2992s
	iters: 200, epoch: 15 | loss: 0.2352010
	speed: 0.0327s/iter; left time: 739.7851s
Epoch: 15 cost time: 8.72194528579712
Epoch: 15, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2190 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2228055
	speed: 0.0347s/iter; left time: 777.2510s
	iters: 200, epoch: 16 | loss: 0.2316846
	speed: 0.0309s/iter; left time: 689.6233s
Epoch: 16 cost time: 8.621025085449219
Epoch: 16, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2178 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1659
Validation loss decreased (0.207218 --> 0.207217).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2230317
	speed: 0.0343s/iter; left time: 759.5448s
	iters: 200, epoch: 17 | loss: 0.2466263
	speed: 0.0318s/iter; left time: 701.3090s
Epoch: 17 cost time: 8.678972244262695
Epoch: 17, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2038 + XiCon Loss:3.2200 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2469180
	speed: 0.0335s/iter; left time: 732.4549s
	iters: 200, epoch: 18 | loss: 0.2231954
	speed: 0.0314s/iter; left time: 684.6241s
Epoch: 18 cost time: 8.528712272644043
Epoch: 18, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2172 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2294937
	speed: 0.0331s/iter; left time: 715.1374s
	iters: 200, epoch: 19 | loss: 0.2316906
	speed: 0.0330s/iter; left time: 710.8496s
Epoch: 19 cost time: 8.784617900848389
Epoch: 19, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2186 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.2600926
	speed: 0.0337s/iter; left time: 720.9449s
	iters: 200, epoch: 20 | loss: 0.2115507
	speed: 0.0323s/iter; left time: 687.9066s
Epoch: 20 cost time: 8.672238111495972
Epoch: 20, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2193 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1659
Validation loss decreased (0.207217 --> 0.207164).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.2235917
	speed: 0.0330s/iter; left time: 695.5714s
	iters: 200, epoch: 21 | loss: 0.2317894
	speed: 0.0303s/iter; left time: 636.8827s
Epoch: 21 cost time: 8.351255416870117
Epoch: 21, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2038 + XiCon Loss:3.2187 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.2710735
	speed: 0.0340s/iter; left time: 709.0464s
	iters: 200, epoch: 22 | loss: 0.2372617
	speed: 0.0316s/iter; left time: 654.8233s
Epoch: 22 cost time: 8.559184789657593
Epoch: 22, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2191 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.2528771
	speed: 0.0332s/iter; left time: 683.6106s
	iters: 200, epoch: 23 | loss: 0.2504509
	speed: 0.0319s/iter; left time: 652.6569s
Epoch: 23 cost time: 8.554601907730103
Epoch: 23, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2170 x Lambda(0.01)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1659
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2505986
	speed: 0.0339s/iter; left time: 688.0453s
	iters: 200, epoch: 24 | loss: 0.2262741
	speed: 0.0317s/iter; left time: 641.0960s
Epoch: 24 cost time: 8.621183633804321
Epoch: 24, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2202 x Lambda(0.01)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1659
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2559103
	speed: 0.0334s/iter; left time: 669.8971s
	iters: 200, epoch: 25 | loss: 0.2489884
	speed: 0.0322s/iter; left time: 642.6239s
Epoch: 25 cost time: 8.623712062835693
Epoch: 25, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2188 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.2295986
	speed: 0.0327s/iter; left time: 647.5134s
	iters: 200, epoch: 26 | loss: 0.2223383
	speed: 0.0320s/iter; left time: 629.6786s
Epoch: 26 cost time: 8.566386461257935
Epoch: 26, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2038 + XiCon Loss:3.2201 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1659
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.2436809
	speed: 0.0339s/iter; left time: 661.0072s
	iters: 200, epoch: 27 | loss: 0.2198019
	speed: 0.0315s/iter; left time: 611.8370s
Epoch: 27 cost time: 8.55070424079895
Epoch: 27, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2201 x Lambda(0.01)), Vali MSE Loss: 0.2074 Test MSE Loss: 0.1659
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.2409484
	speed: 0.0339s/iter; left time: 652.7097s
	iters: 200, epoch: 28 | loss: 0.2386353
	speed: 0.0319s/iter; left time: 610.0286s
Epoch: 28 cost time: 8.784477233886719
Epoch: 28, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2038 + XiCon Loss:3.2177 x Lambda(0.01)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1659
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.2190580
	speed: 0.0339s/iter; left time: 643.0305s
	iters: 200, epoch: 29 | loss: 0.2387639
	speed: 0.0310s/iter; left time: 584.8233s
Epoch: 29 cost time: 8.539507865905762
Epoch: 29, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2165 x Lambda(0.01)), Vali MSE Loss: 0.2072 Test MSE Loss: 0.1659
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.2213480
	speed: 0.0338s/iter; left time: 632.2984s
	iters: 200, epoch: 30 | loss: 0.2340825
	speed: 0.0316s/iter; left time: 587.7630s
Epoch: 30 cost time: 8.628097534179688
Epoch: 30, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2034 + XiCon Loss:3.2197 x Lambda(0.01)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1659
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09606645256280899, mae:0.23572522401809692, mape:0.5672762989997864, mspe:11.82652759552002 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0589
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3543690
	speed: 0.0345s/iter; left time: 909.5937s
	iters: 200, epoch: 1 | loss: 0.3308436
	speed: 0.0318s/iter; left time: 837.1471s
Epoch: 1 cost time: 8.78318166732788
Epoch: 1, Steps: 265 Train Loss: 0.3789 (Forecasting Loss:0.3466 + XiCon Loss:3.2283 x Lambda(0.01)), Vali MSE Loss: 0.3247 Test MSE Loss: 0.2711
Validation loss decreased (inf --> 0.324683).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2353143
	speed: 0.0338s/iter; left time: 883.9586s
	iters: 200, epoch: 2 | loss: 0.2381534
	speed: 0.0329s/iter; left time: 855.4259s
Epoch: 2 cost time: 8.707231998443604
Epoch: 2, Steps: 265 Train Loss: 0.2665 (Forecasting Loss:0.2342 + XiCon Loss:3.2323 x Lambda(0.01)), Vali MSE Loss: 0.2138 Test MSE Loss: 0.1723
Validation loss decreased (0.324683 --> 0.213798).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2550260
	speed: 0.0339s/iter; left time: 877.6746s
	iters: 200, epoch: 3 | loss: 0.2340398
	speed: 0.0321s/iter; left time: 826.7770s
Epoch: 3 cost time: 8.688450574874878
Epoch: 3, Steps: 265 Train Loss: 0.2388 (Forecasting Loss:0.2066 + XiCon Loss:3.2176 x Lambda(0.01)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1727
Validation loss decreased (0.213798 --> 0.211527).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2322040
	speed: 0.0339s/iter; left time: 868.5349s
	iters: 200, epoch: 4 | loss: 0.2307760
	speed: 0.0316s/iter; left time: 805.5463s
Epoch: 4 cost time: 8.634047508239746
Epoch: 4, Steps: 265 Train Loss: 0.2350 (Forecasting Loss:0.2029 + XiCon Loss:3.2117 x Lambda(0.01)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1722
Validation loss decreased (0.211527 --> 0.209194).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2216715
	speed: 0.0332s/iter; left time: 840.1223s
	iters: 200, epoch: 5 | loss: 0.2334082
	speed: 0.0308s/iter; left time: 776.1681s
Epoch: 5 cost time: 8.47423529624939
Epoch: 5, Steps: 265 Train Loss: 0.2337 (Forecasting Loss:0.2017 + XiCon Loss:3.2075 x Lambda(0.01)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1722
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2602486
	speed: 0.0341s/iter; left time: 855.4711s
	iters: 200, epoch: 6 | loss: 0.2475655
	speed: 0.0335s/iter; left time: 837.0366s
Epoch: 6 cost time: 8.896755695343018
Epoch: 6, Steps: 265 Train Loss: 0.2329 (Forecasting Loss:0.2009 + XiCon Loss:3.2038 x Lambda(0.01)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1721
Validation loss decreased (0.209194 --> 0.208809).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2498314
	speed: 0.0339s/iter; left time: 840.8337s
	iters: 200, epoch: 7 | loss: 0.2302425
	speed: 0.0313s/iter; left time: 773.3722s
Epoch: 7 cost time: 8.593737125396729
Epoch: 7, Steps: 265 Train Loss: 0.2328 (Forecasting Loss:0.2007 + XiCon Loss:3.2043 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1721
Validation loss decreased (0.208809 --> 0.208588).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2318626
	speed: 0.0339s/iter; left time: 831.2135s
	iters: 200, epoch: 8 | loss: 0.2357395
	speed: 0.0311s/iter; left time: 759.9678s
Epoch: 8 cost time: 8.557979583740234
Epoch: 8, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2036 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1721
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2429207
	speed: 0.0340s/iter; left time: 826.2426s
	iters: 200, epoch: 9 | loss: 0.2346508
	speed: 0.0318s/iter; left time: 767.8028s
Epoch: 9 cost time: 8.647840023040771
Epoch: 9, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2035 x Lambda(0.01)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1721
Validation loss decreased (0.208588 --> 0.208503).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2175557
	speed: 0.0332s/iter; left time: 798.4242s
	iters: 200, epoch: 10 | loss: 0.2214909
	speed: 0.0316s/iter; left time: 756.2532s
Epoch: 10 cost time: 8.496269941329956
Epoch: 10, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2024 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1720
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2419720
	speed: 0.0334s/iter; left time: 792.6449s
	iters: 200, epoch: 11 | loss: 0.2380209
	speed: 0.0325s/iter; left time: 769.6374s
Epoch: 11 cost time: 8.74003005027771
Epoch: 11, Steps: 265 Train Loss: 0.2324 (Forecasting Loss:0.2004 + XiCon Loss:3.2024 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1720
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2258848
	speed: 0.0358s/iter; left time: 841.1857s
	iters: 200, epoch: 12 | loss: 0.2320888
	speed: 0.0337s/iter; left time: 789.0788s
Epoch: 12 cost time: 9.09336543083191
Epoch: 12, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2018 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
Validation loss decreased (0.208503 --> 0.208362).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2240243
	speed: 0.0334s/iter; left time: 776.2650s
	iters: 200, epoch: 13 | loss: 0.2260850
	speed: 0.0309s/iter; left time: 714.2957s
Epoch: 13 cost time: 8.437519311904907
Epoch: 13, Steps: 265 Train Loss: 0.2324 (Forecasting Loss:0.2004 + XiCon Loss:3.2026 x Lambda(0.01)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1720
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2047827
	speed: 0.0333s/iter; left time: 764.3883s
	iters: 200, epoch: 14 | loss: 0.2146885
	speed: 0.0313s/iter; left time: 715.7428s
Epoch: 14 cost time: 8.435506820678711
Epoch: 14, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2023 x Lambda(0.01)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2357003
	speed: 0.0349s/iter; left time: 792.4520s
	iters: 200, epoch: 15 | loss: 0.2167753
	speed: 0.0314s/iter; left time: 708.2892s
Epoch: 15 cost time: 8.684173583984375
Epoch: 15, Steps: 265 Train Loss: 0.2324 (Forecasting Loss:0.2003 + XiCon Loss:3.2044 x Lambda(0.01)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1720
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2373578
	speed: 0.0345s/iter; left time: 774.2492s
	iters: 200, epoch: 16 | loss: 0.2199797
	speed: 0.0324s/iter; left time: 722.3255s
Epoch: 16 cost time: 8.829395055770874
Epoch: 16, Steps: 265 Train Loss: 0.2323 (Forecasting Loss:0.2003 + XiCon Loss:3.2030 x Lambda(0.01)), Vali MSE Loss: 0.2080 Test MSE Loss: 0.1720
Validation loss decreased (0.208362 --> 0.208040).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2283732
	speed: 0.0338s/iter; left time: 750.1379s
	iters: 200, epoch: 17 | loss: 0.2227285
	speed: 0.0321s/iter; left time: 707.2057s
Epoch: 17 cost time: 8.567187070846558
Epoch: 17, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2004 + XiCon Loss:3.2037 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2170500
	speed: 0.0343s/iter; left time: 751.1934s
	iters: 200, epoch: 18 | loss: 0.2235399
	speed: 0.0316s/iter; left time: 688.2567s
Epoch: 18 cost time: 8.64806842803955
Epoch: 18, Steps: 265 Train Loss: 0.2324 (Forecasting Loss:0.2003 + XiCon Loss:3.2024 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2474372
	speed: 0.0343s/iter; left time: 741.2156s
	iters: 200, epoch: 19 | loss: 0.2463707
	speed: 0.0313s/iter; left time: 673.0703s
Epoch: 19 cost time: 8.599721431732178
Epoch: 19, Steps: 265 Train Loss: 0.2323 (Forecasting Loss:0.2003 + XiCon Loss:3.2058 x Lambda(0.01)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1720
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.2214880
	speed: 0.0338s/iter; left time: 723.1005s
	iters: 200, epoch: 20 | loss: 0.2245420
	speed: 0.0316s/iter; left time: 672.0059s
Epoch: 20 cost time: 8.624444484710693
Epoch: 20, Steps: 265 Train Loss: 0.2323 (Forecasting Loss:0.2003 + XiCon Loss:3.2030 x Lambda(0.01)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1720
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.2376399
	speed: 0.0341s/iter; left time: 718.8926s
	iters: 200, epoch: 21 | loss: 0.2402124
	speed: 0.0325s/iter; left time: 682.3965s
Epoch: 21 cost time: 8.723896265029907
Epoch: 21, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2004 + XiCon Loss:3.2031 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.2236852
	speed: 0.0335s/iter; left time: 698.0432s
	iters: 200, epoch: 22 | loss: 0.2305696
	speed: 0.0310s/iter; left time: 642.9212s
Epoch: 22 cost time: 8.51328444480896
Epoch: 22, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2004 + XiCon Loss:3.2037 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.2172121
	speed: 0.0333s/iter; left time: 684.9815s
	iters: 200, epoch: 23 | loss: 0.2017792
	speed: 0.0317s/iter; left time: 648.7275s
Epoch: 23 cost time: 8.55048942565918
Epoch: 23, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2031 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2220927
	speed: 0.0336s/iter; left time: 682.4188s
	iters: 200, epoch: 24 | loss: 0.2207218
	speed: 0.0317s/iter; left time: 640.7484s
Epoch: 24 cost time: 8.60218071937561
Epoch: 24, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2046 x Lambda(0.01)), Vali MSE Loss: 0.2084 Test MSE Loss: 0.1720
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2287303
	speed: 0.0328s/iter; left time: 656.6238s
	iters: 200, epoch: 25 | loss: 0.2456905
	speed: 0.0317s/iter; left time: 633.0913s
Epoch: 25 cost time: 8.551404476165771
Epoch: 25, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2029 x Lambda(0.01)), Vali MSE Loss: 0.2085 Test MSE Loss: 0.1720
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.2166408
	speed: 0.0344s/iter; left time: 679.5860s
	iters: 200, epoch: 26 | loss: 0.2129550
	speed: 0.0320s/iter; left time: 630.0054s
Epoch: 26 cost time: 8.70742130279541
Epoch: 26, Steps: 265 Train Loss: 0.2325 (Forecasting Loss:0.2005 + XiCon Loss:3.2032 x Lambda(0.01)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.10134036839008331, mae:0.24273565411567688, mape:0.5844893455505371, mspe:12.300239562988281 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.9286
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.3882573
	speed: 0.0325s/iter; left time: 858.1239s
	iters: 200, epoch: 1 | loss: 0.3724475
	speed: 0.0308s/iter; left time: 811.0757s
Epoch: 1 cost time: 8.451141119003296
Epoch: 1, Steps: 265 Train Loss: 0.3934 (Forecasting Loss:0.3610 + XiCon Loss:3.2395 x Lambda(0.01)), Vali MSE Loss: 0.3314 Test MSE Loss: 0.2836
Validation loss decreased (inf --> 0.331423).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2515378
	speed: 0.0339s/iter; left time: 885.3588s
	iters: 200, epoch: 2 | loss: 0.2272623
	speed: 0.0312s/iter; left time: 811.5317s
Epoch: 2 cost time: 8.550409317016602
Epoch: 2, Steps: 265 Train Loss: 0.2666 (Forecasting Loss:0.2344 + XiCon Loss:3.2298 x Lambda(0.01)), Vali MSE Loss: 0.2177 Test MSE Loss: 0.1751
Validation loss decreased (0.331423 --> 0.217687).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2259156
	speed: 0.0330s/iter; left time: 852.5889s
	iters: 200, epoch: 3 | loss: 0.2504861
	speed: 0.0315s/iter; left time: 811.0469s
Epoch: 3 cost time: 8.495270729064941
Epoch: 3, Steps: 265 Train Loss: 0.2402 (Forecasting Loss:0.2080 + XiCon Loss:3.2230 x Lambda(0.01)), Vali MSE Loss: 0.2139 Test MSE Loss: 0.1714
Validation loss decreased (0.217687 --> 0.213891).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2395758
	speed: 0.0336s/iter; left time: 861.1722s
	iters: 200, epoch: 4 | loss: 0.2157180
	speed: 0.0317s/iter; left time: 807.5746s
Epoch: 4 cost time: 8.591350078582764
Epoch: 4, Steps: 265 Train Loss: 0.2379 (Forecasting Loss:0.2058 + XiCon Loss:3.2163 x Lambda(0.01)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1709
Validation loss decreased (0.213891 --> 0.213246).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2447360
	speed: 0.0338s/iter; left time: 855.8632s
	iters: 200, epoch: 5 | loss: 0.2445871
	speed: 0.0310s/iter; left time: 783.3395s
Epoch: 5 cost time: 8.521684408187866
Epoch: 5, Steps: 265 Train Loss: 0.2368 (Forecasting Loss:0.2046 + XiCon Loss:3.2156 x Lambda(0.01)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1704
Validation loss decreased (0.213246 --> 0.212374).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2375879
	speed: 0.0331s/iter; left time: 831.2232s
	iters: 200, epoch: 6 | loss: 0.2363940
	speed: 0.0323s/iter; left time: 807.2204s
Epoch: 6 cost time: 8.653667688369751
Epoch: 6, Steps: 265 Train Loss: 0.2363 (Forecasting Loss:0.2041 + XiCon Loss:3.2139 x Lambda(0.01)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1703
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2407297
	speed: 0.0332s/iter; left time: 824.7491s
	iters: 200, epoch: 7 | loss: 0.2319578
	speed: 0.0308s/iter; left time: 761.1017s
Epoch: 7 cost time: 8.482134103775024
Epoch: 7, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2137 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
Validation loss decreased (0.212374 --> 0.212119).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2239337
	speed: 0.0344s/iter; left time: 844.7212s
	iters: 200, epoch: 8 | loss: 0.2526439
	speed: 0.0313s/iter; left time: 766.0383s
Epoch: 8 cost time: 8.637390851974487
Epoch: 8, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2039 + XiCon Loss:3.2131 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2239121
	speed: 0.0331s/iter; left time: 803.2345s
	iters: 200, epoch: 9 | loss: 0.2376466
	speed: 0.0304s/iter; left time: 735.7998s
Epoch: 9 cost time: 8.295661926269531
Epoch: 9, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2137 x Lambda(0.01)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1701
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2603025
	speed: 0.0328s/iter; left time: 788.4913s
	iters: 200, epoch: 10 | loss: 0.2081939
	speed: 0.0317s/iter; left time: 758.5109s
Epoch: 10 cost time: 8.499567985534668
Epoch: 10, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2141 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2381555
	speed: 0.0342s/iter; left time: 811.4311s
	iters: 200, epoch: 11 | loss: 0.2346226
	speed: 0.0312s/iter; left time: 737.5362s
Epoch: 11 cost time: 8.600796937942505
Epoch: 11, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2131 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2393714
	speed: 0.0330s/iter; left time: 775.4759s
	iters: 200, epoch: 12 | loss: 0.2550825
	speed: 0.0317s/iter; left time: 741.0654s
Epoch: 12 cost time: 8.552422523498535
Epoch: 12, Steps: 265 Train Loss: 0.2360 (Forecasting Loss:0.2039 + XiCon Loss:3.2152 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2436270
	speed: 0.0335s/iter; left time: 776.7910s
	iters: 200, epoch: 13 | loss: 0.2483849
	speed: 0.0312s/iter; left time: 721.4873s
Epoch: 13 cost time: 8.543049573898315
Epoch: 13, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2119 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2294730
	speed: 0.0335s/iter; left time: 769.3107s
	iters: 200, epoch: 14 | loss: 0.2127960
	speed: 0.0308s/iter; left time: 702.8572s
Epoch: 14 cost time: 8.465951442718506
Epoch: 14, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2035 + XiCon Loss:3.2123 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2487970
	speed: 0.0340s/iter; left time: 771.4046s
	iters: 200, epoch: 15 | loss: 0.2159185
	speed: 0.0319s/iter; left time: 719.8071s
Epoch: 15 cost time: 8.734869241714478
Epoch: 15, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2110 x Lambda(0.01)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1701
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2527152
	speed: 0.0327s/iter; left time: 733.2633s
	iters: 200, epoch: 16 | loss: 0.2248812
	speed: 0.0318s/iter; left time: 710.4961s
Epoch: 16 cost time: 8.550263166427612
Epoch: 16, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2034 + XiCon Loss:3.2139 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2593451
	speed: 0.0347s/iter; left time: 769.3912s
	iters: 200, epoch: 17 | loss: 0.2130580
	speed: 0.0312s/iter; left time: 687.7299s
Epoch: 17 cost time: 8.584410905838013
Epoch: 17, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2103 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
Validation loss decreased (0.212119 --> 0.212090).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2392994
	speed: 0.0343s/iter; left time: 750.4117s
	iters: 200, epoch: 18 | loss: 0.2467779
	speed: 0.0316s/iter; left time: 688.6932s
Epoch: 18 cost time: 8.684672832489014
Epoch: 18, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2037 + XiCon Loss:3.2129 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2357171
	speed: 0.0336s/iter; left time: 726.7771s
	iters: 200, epoch: 19 | loss: 0.2348989
	speed: 0.0312s/iter; left time: 671.7549s
Epoch: 19 cost time: 8.587389707565308
Epoch: 19, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2115 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.2067485
	speed: 0.0334s/iter; left time: 713.3244s
	iters: 200, epoch: 20 | loss: 0.2530099
	speed: 0.0330s/iter; left time: 701.7731s
Epoch: 20 cost time: 8.825681209564209
Epoch: 20, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2134 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.2465900
	speed: 0.0348s/iter; left time: 733.2996s
	iters: 200, epoch: 21 | loss: 0.2352771
	speed: 0.0304s/iter; left time: 639.2888s
Epoch: 21 cost time: 8.50883436203003
Epoch: 21, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2037 + XiCon Loss:3.2130 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.2148996
	speed: 0.0327s/iter; left time: 680.8577s
	iters: 200, epoch: 22 | loss: 0.2166982
	speed: 0.0312s/iter; left time: 646.5569s
Epoch: 22 cost time: 8.467981338500977
Epoch: 22, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2138 x Lambda(0.01)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1701
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.2254211
	speed: 0.0336s/iter; left time: 690.6425s
	iters: 200, epoch: 23 | loss: 0.2587090
	speed: 0.0324s/iter; left time: 662.2737s
Epoch: 23 cost time: 8.635488510131836
Epoch: 23, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2037 + XiCon Loss:3.2126 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
Validation loss decreased (0.212090 --> 0.212070).  Saving model ...
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.2333820
	speed: 0.0340s/iter; left time: 690.3887s
	iters: 200, epoch: 24 | loss: 0.2473052
	speed: 0.0317s/iter; left time: 641.1195s
Epoch: 24 cost time: 8.620786428451538
Epoch: 24, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2037 + XiCon Loss:3.2138 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.2632164
	speed: 0.0339s/iter; left time: 678.5915s
	iters: 200, epoch: 25 | loss: 0.2549312
	speed: 0.0325s/iter; left time: 648.7709s
Epoch: 25 cost time: 8.8029146194458
Epoch: 25, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2153 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.2150998
	speed: 0.0338s/iter; left time: 668.2036s
	iters: 200, epoch: 26 | loss: 0.2348461
	speed: 0.0314s/iter; left time: 617.3259s
Epoch: 26 cost time: 8.57926082611084
Epoch: 26, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2136 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.2282252
	speed: 0.0330s/iter; left time: 642.9141s
	iters: 200, epoch: 27 | loss: 0.2693372
	speed: 0.0315s/iter; left time: 611.0089s
Epoch: 27 cost time: 8.534244060516357
Epoch: 27, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2142 x Lambda(0.01)), Vali MSE Loss: 0.2124 Test MSE Loss: 0.1701
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.2220041
	speed: 0.0337s/iter; left time: 647.8253s
	iters: 200, epoch: 28 | loss: 0.2460650
	speed: 0.0313s/iter; left time: 598.6935s
Epoch: 28 cost time: 8.54555368423462
Epoch: 28, Steps: 265 Train Loss: 0.2359 (Forecasting Loss:0.2038 + XiCon Loss:3.2129 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.2137867
	speed: 0.0341s/iter; left time: 647.5720s
	iters: 200, epoch: 29 | loss: 0.2391632
	speed: 0.0317s/iter; left time: 598.2967s
Epoch: 29 cost time: 8.671841144561768
Epoch: 29, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2131 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.2365167
	speed: 0.0344s/iter; left time: 643.1787s
	iters: 200, epoch: 30 | loss: 0.2442157
	speed: 0.0339s/iter; left time: 631.9624s
Epoch: 30 cost time: 8.994689226150513
Epoch: 30, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2150 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.2453835
	speed: 0.0337s/iter; left time: 622.1761s
	iters: 200, epoch: 31 | loss: 0.2665080
	speed: 0.0321s/iter; left time: 589.9610s
Epoch: 31 cost time: 8.622881412506104
Epoch: 31, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2131 x Lambda(0.01)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1701
Validation loss decreased (0.212070 --> 0.211967).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.2439415
	speed: 0.0347s/iter; left time: 630.4576s
	iters: 200, epoch: 32 | loss: 0.2181129
	speed: 0.0312s/iter; left time: 564.3381s
Epoch: 32 cost time: 8.627482414245605
Epoch: 32, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2114 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.2438582
	speed: 0.0328s/iter; left time: 588.6199s
	iters: 200, epoch: 33 | loss: 0.2425214
	speed: 0.0292s/iter; left time: 520.6554s
Epoch: 33 cost time: 8.244886636734009
Epoch: 33, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2125 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.2722320
	speed: 0.0330s/iter; left time: 583.3787s
	iters: 200, epoch: 34 | loss: 0.2490053
	speed: 0.0316s/iter; left time: 554.4529s
Epoch: 34 cost time: 8.525426864624023
Epoch: 34, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2136 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.2545813
	speed: 0.0335s/iter; left time: 581.8163s
	iters: 200, epoch: 35 | loss: 0.2814271
	speed: 0.0334s/iter; left time: 577.2777s
Epoch: 35 cost time: 8.903585433959961
Epoch: 35, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2037 + XiCon Loss:3.2146 x Lambda(0.01)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1701
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.2032162
	speed: 0.0342s/iter; left time: 585.2208s
	iters: 200, epoch: 36 | loss: 0.2468896
	speed: 0.0313s/iter; left time: 532.9581s
Epoch: 36 cost time: 8.671838521957397
Epoch: 36, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2037 + XiCon Loss:3.2122 x Lambda(0.01)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1701
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.2353444
	speed: 0.0335s/iter; left time: 565.0340s
	iters: 200, epoch: 37 | loss: 0.2281750
	speed: 0.0316s/iter; left time: 529.7332s
Epoch: 37 cost time: 8.547299146652222
Epoch: 37, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2035 + XiCon Loss:3.2113 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.2169266
	speed: 0.0329s/iter; left time: 546.8094s
	iters: 200, epoch: 38 | loss: 0.2576467
	speed: 0.0318s/iter; left time: 523.8158s
Epoch: 38 cost time: 8.46758770942688
Epoch: 38, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2036 + XiCon Loss:3.2115 x Lambda(0.01)), Vali MSE Loss: 0.2121 Test MSE Loss: 0.1701
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.2349002
	speed: 0.0341s/iter; left time: 557.6163s
	iters: 200, epoch: 39 | loss: 0.2082876
	speed: 0.0312s/iter; left time: 506.8324s
Epoch: 39 cost time: 8.611060619354248
Epoch: 39, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2135 x Lambda(0.01)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1701
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.2448204
	speed: 0.0341s/iter; left time: 547.8770s
	iters: 200, epoch: 40 | loss: 0.2240656
	speed: 0.0329s/iter; left time: 525.5744s
Epoch: 40 cost time: 8.86404800415039
Epoch: 40, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2037 + XiCon Loss:3.2139 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.2208527
	speed: 0.0332s/iter; left time: 524.6200s
	iters: 200, epoch: 41 | loss: 0.2527435
	speed: 0.0311s/iter; left time: 487.6471s
Epoch: 41 cost time: 8.458596229553223
Epoch: 41, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2036 + XiCon Loss:3.2128 x Lambda(0.01)), Vali MSE Loss: 0.2122 Test MSE Loss: 0.1701
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.099842369556427, mae:0.2403353601694107, mape:0.588520348072052, mspe:12.850205421447754 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7037
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 0.4188066
	speed: 0.0338s/iter; left time: 891.8869s
	iters: 200, epoch: 1 | loss: 0.3409142
	speed: 0.0318s/iter; left time: 835.9983s
Epoch: 1 cost time: 8.59413743019104
Epoch: 1, Steps: 265 Train Loss: 0.3792 (Forecasting Loss:0.3468 + XiCon Loss:3.2410 x Lambda(0.01)), Vali MSE Loss: 0.3277 Test MSE Loss: 0.2724
Validation loss decreased (inf --> 0.327725).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.2836183
	speed: 0.0336s/iter; left time: 878.9935s
	iters: 200, epoch: 2 | loss: 0.2340461
	speed: 0.0335s/iter; left time: 872.1700s
Epoch: 2 cost time: 8.903919219970703
Epoch: 2, Steps: 265 Train Loss: 0.2684 (Forecasting Loss:0.2360 + XiCon Loss:3.2427 x Lambda(0.01)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1727
Validation loss decreased (0.327725 --> 0.214057).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.2390858
	speed: 0.0330s/iter; left time: 853.2766s
	iters: 200, epoch: 3 | loss: 0.2421837
	speed: 0.0323s/iter; left time: 833.3248s
Epoch: 3 cost time: 8.609698057174683
Epoch: 3, Steps: 265 Train Loss: 0.2412 (Forecasting Loss:0.2087 + XiCon Loss:3.2449 x Lambda(0.01)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1696
Validation loss decreased (0.214057 --> 0.211496).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.2368975
	speed: 0.0336s/iter; left time: 859.6322s
	iters: 200, epoch: 4 | loss: 0.2535367
	speed: 0.0308s/iter; left time: 785.4459s
Epoch: 4 cost time: 8.475237846374512
Epoch: 4, Steps: 265 Train Loss: 0.2377 (Forecasting Loss:0.2053 + XiCon Loss:3.2399 x Lambda(0.01)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1689
Validation loss decreased (0.211496 --> 0.210108).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.2382867
	speed: 0.0334s/iter; left time: 846.8566s
	iters: 200, epoch: 5 | loss: 0.2431701
	speed: 0.0311s/iter; left time: 785.0199s
Epoch: 5 cost time: 8.490487575531006
Epoch: 5, Steps: 265 Train Loss: 0.2366 (Forecasting Loss:0.2042 + XiCon Loss:3.2404 x Lambda(0.01)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1690
Validation loss decreased (0.210108 --> 0.209962).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.2223895
	speed: 0.0336s/iter; left time: 842.9510s
	iters: 200, epoch: 6 | loss: 0.2462777
	speed: 0.0312s/iter; left time: 778.7081s
Epoch: 6 cost time: 8.548242807388306
Epoch: 6, Steps: 265 Train Loss: 0.2362 (Forecasting Loss:0.2038 + XiCon Loss:3.2395 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1690
Validation loss decreased (0.209962 --> 0.209873).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.2286332
	speed: 0.0344s/iter; left time: 853.0323s
	iters: 200, epoch: 7 | loss: 0.2072010
	speed: 0.0340s/iter; left time: 839.6246s
Epoch: 7 cost time: 9.089601755142212
Epoch: 7, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2034 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1690
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.2583087
	speed: 0.0338s/iter; left time: 829.3989s
	iters: 200, epoch: 8 | loss: 0.2385553
	speed: 0.0332s/iter; left time: 810.4482s
Epoch: 8 cost time: 8.79016661643982
Epoch: 8, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2399 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1689
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.2318404
	speed: 0.0336s/iter; left time: 815.9987s
	iters: 200, epoch: 9 | loss: 0.2197282
	speed: 0.0325s/iter; left time: 785.0996s
Epoch: 9 cost time: 8.704521894454956
Epoch: 9, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2402 x Lambda(0.01)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1689
Validation loss decreased (0.209873 --> 0.209845).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.2486910
	speed: 0.0338s/iter; left time: 810.5800s
	iters: 200, epoch: 10 | loss: 0.2482023
	speed: 0.0313s/iter; left time: 747.5871s
Epoch: 10 cost time: 8.594404935836792
Epoch: 10, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2408 x Lambda(0.01)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1689
Validation loss decreased (0.209845 --> 0.209782).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.2436352
	speed: 0.0340s/iter; left time: 807.7251s
	iters: 200, epoch: 11 | loss: 0.2365378
	speed: 0.0311s/iter; left time: 735.3452s
Epoch: 11 cost time: 8.646759510040283
Epoch: 11, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2032 + XiCon Loss:3.2390 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1689
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.2320952
	speed: 0.0335s/iter; left time: 785.7777s
	iters: 200, epoch: 12 | loss: 0.2390788
	speed: 0.0324s/iter; left time: 757.8501s
Epoch: 12 cost time: 8.700680255889893
Epoch: 12, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2421 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1689
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.2406214
	speed: 0.0342s/iter; left time: 793.7474s
	iters: 200, epoch: 13 | loss: 0.2169056
	speed: 0.0319s/iter; left time: 738.6971s
Epoch: 13 cost time: 8.678296566009521
Epoch: 13, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2032 + XiCon Loss:3.2408 x Lambda(0.01)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1689
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.2349518
	speed: 0.0336s/iter; left time: 770.8455s
	iters: 200, epoch: 14 | loss: 0.2274168
	speed: 0.0299s/iter; left time: 683.9633s
Epoch: 14 cost time: 8.326767444610596
Epoch: 14, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2394 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1689
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.2477619
	speed: 0.0334s/iter; left time: 757.2737s
	iters: 200, epoch: 15 | loss: 0.2452585
	speed: 0.0311s/iter; left time: 702.1755s
Epoch: 15 cost time: 8.419428825378418
Epoch: 15, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2033 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1689
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.2260224
	speed: 0.0339s/iter; left time: 760.0208s
	iters: 200, epoch: 16 | loss: 0.2233078
	speed: 0.0312s/iter; left time: 696.9772s
Epoch: 16 cost time: 8.59484338760376
Epoch: 16, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2406 x Lambda(0.01)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1689
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.2653081
	speed: 0.0342s/iter; left time: 757.1437s
	iters: 200, epoch: 17 | loss: 0.2400326
	speed: 0.0310s/iter; left time: 684.2314s
Epoch: 17 cost time: 8.500841617584229
Epoch: 17, Steps: 265 Train Loss: 0.2355 (Forecasting Loss:0.2031 + XiCon Loss:3.2392 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1689
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.2785369
	speed: 0.0338s/iter; left time: 739.2792s
	iters: 200, epoch: 18 | loss: 0.2084084
	speed: 0.0319s/iter; left time: 695.6918s
Epoch: 18 cost time: 8.651474475860596
Epoch: 18, Steps: 265 Train Loss: 0.2356 (Forecasting Loss:0.2032 + XiCon Loss:3.2388 x Lambda(0.01)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1689
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.2129693
	speed: 0.0335s/iter; left time: 724.0733s
	iters: 200, epoch: 19 | loss: 0.2669395
	speed: 0.0317s/iter; left time: 681.6614s
Epoch: 19 cost time: 8.607814073562622
Epoch: 19, Steps: 265 Train Loss: 0.2357 (Forecasting Loss:0.2033 + XiCon Loss:3.2414 x Lambda(0.01)), Vali MSE Loss: 0.2098 Test MSE Loss: 0.1689
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.1954917
	speed: 0.0335s/iter; left time: 716.4481s
	iters: 200, epoch: 20 | loss: 0.2245142
	speed: 0.0315s/iter; left time: 669.7053s
Epoch: 20 cost time: 8.590293169021606
Epoch: 20, Steps: 265 Train Loss: 0.2358 (Forecasting Loss:0.2034 + XiCon Loss:3.2387 x Lambda(0.01)), Vali MSE Loss: 0.2099 Test MSE Loss: 0.1689
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09903836250305176, mae:0.23872825503349304, mape:0.585536003112793, mspe:12.806732177734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0989+-0.00244, MAE:0.2391+-0.00327, MAPE:0.5786+-0.01296, MSPE:12.3013+-0.65617, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.8488
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3872238
	speed: 0.0423s/iter; left time: 1112.6167s
	iters: 200, epoch: 1 | loss: 0.3309920
	speed: 0.0361s/iter; left time: 946.6907s
Epoch: 1 cost time: 10.101942539215088
Epoch: 1, Steps: 264 Train Loss: 0.3677 (Forecasting Loss:0.3354 + XiCon Loss:3.2277 x Lambda(0.01)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.2325
Validation loss decreased (inf --> 0.294833).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2808264
	speed: 0.0368s/iter; left time: 957.1001s
	iters: 200, epoch: 2 | loss: 0.2836897
	speed: 0.0352s/iter; left time: 913.9503s
Epoch: 2 cost time: 9.348212957382202
Epoch: 2, Steps: 264 Train Loss: 0.2828 (Forecasting Loss:0.2512 + XiCon Loss:3.1574 x Lambda(0.01)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.1962
Validation loss decreased (0.294833 --> 0.251846).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2627325
	speed: 0.0367s/iter; left time: 946.8476s
	iters: 200, epoch: 3 | loss: 0.2384268
	speed: 0.0338s/iter; left time: 866.6520s
Epoch: 3 cost time: 9.300962448120117
Epoch: 3, Steps: 264 Train Loss: 0.2675 (Forecasting Loss:0.2366 + XiCon Loss:3.0925 x Lambda(0.01)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.2041
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2304181
	speed: 0.0363s/iter; left time: 926.3824s
	iters: 200, epoch: 4 | loss: 0.2707274
	speed: 0.0338s/iter; left time: 857.9845s
Epoch: 4 cost time: 9.136603593826294
Epoch: 4, Steps: 264 Train Loss: 0.2600 (Forecasting Loss:0.2291 + XiCon Loss:3.0916 x Lambda(0.01)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.2022
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2267018
	speed: 0.0367s/iter; left time: 927.2575s
	iters: 200, epoch: 5 | loss: 0.2416393
	speed: 0.0348s/iter; left time: 873.9354s
Epoch: 5 cost time: 9.324766159057617
Epoch: 5, Steps: 264 Train Loss: 0.2570 (Forecasting Loss:0.2261 + XiCon Loss:3.0939 x Lambda(0.01)), Vali MSE Loss: 0.2650 Test MSE Loss: 0.2046
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2550868
	speed: 0.0364s/iter; left time: 909.5470s
	iters: 200, epoch: 6 | loss: 0.2439674
	speed: 0.0343s/iter; left time: 853.2354s
Epoch: 6 cost time: 9.253229141235352
Epoch: 6, Steps: 264 Train Loss: 0.2558 (Forecasting Loss:0.2249 + XiCon Loss:3.0912 x Lambda(0.01)), Vali MSE Loss: 0.2674 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2279540
	speed: 0.0360s/iter; left time: 890.1717s
	iters: 200, epoch: 7 | loss: 0.2673976
	speed: 0.0341s/iter; left time: 840.4878s
Epoch: 7 cost time: 9.173427104949951
Epoch: 7, Steps: 264 Train Loss: 0.2551 (Forecasting Loss:0.2242 + XiCon Loss:3.0899 x Lambda(0.01)), Vali MSE Loss: 0.2660 Test MSE Loss: 0.2048
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2601962
	speed: 0.0364s/iter; left time: 890.6219s
	iters: 200, epoch: 8 | loss: 0.2563879
	speed: 0.0345s/iter; left time: 840.1117s
Epoch: 8 cost time: 9.273965120315552
Epoch: 8, Steps: 264 Train Loss: 0.2548 (Forecasting Loss:0.2239 + XiCon Loss:3.0921 x Lambda(0.01)), Vali MSE Loss: 0.2665 Test MSE Loss: 0.2051
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2472799
	speed: 0.0368s/iter; left time: 891.3402s
	iters: 200, epoch: 9 | loss: 0.2617364
	speed: 0.0335s/iter; left time: 807.9824s
Epoch: 9 cost time: 9.256066083908081
Epoch: 9, Steps: 264 Train Loss: 0.2548 (Forecasting Loss:0.2238 + XiCon Loss:3.0931 x Lambda(0.01)), Vali MSE Loss: 0.2669 Test MSE Loss: 0.2054
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2820477
	speed: 0.0363s/iter; left time: 868.8432s
	iters: 200, epoch: 10 | loss: 0.2325148
	speed: 0.0334s/iter; left time: 795.8742s
Epoch: 10 cost time: 9.241934537887573
Epoch: 10, Steps: 264 Train Loss: 0.2549 (Forecasting Loss:0.2239 + XiCon Loss:3.0929 x Lambda(0.01)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.2055
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2387851
	speed: 0.0371s/iter; left time: 876.7767s
	iters: 200, epoch: 11 | loss: 0.2709276
	speed: 0.0352s/iter; left time: 828.3996s
Epoch: 11 cost time: 9.413445472717285
Epoch: 11, Steps: 264 Train Loss: 0.2548 (Forecasting Loss:0.2238 + XiCon Loss:3.0940 x Lambda(0.01)), Vali MSE Loss: 0.2674 Test MSE Loss: 0.2055
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2659787
	speed: 0.0368s/iter; left time: 859.8656s
	iters: 200, epoch: 12 | loss: 0.2225643
	speed: 0.0344s/iter; left time: 802.1309s
Epoch: 12 cost time: 9.278898000717163
Epoch: 12, Steps: 264 Train Loss: 0.2545 (Forecasting Loss:0.2235 + XiCon Loss:3.0925 x Lambda(0.01)), Vali MSE Loss: 0.2673 Test MSE Loss: 0.2056
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12342808395624161, mae:0.2690097987651825, mape:0.6570669412612915, mspe:15.13288402557373 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2616
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3831489
	speed: 0.0382s/iter; left time: 1005.2999s
	iters: 200, epoch: 1 | loss: 0.3205074
	speed: 0.0356s/iter; left time: 932.0524s
Epoch: 1 cost time: 9.628418445587158
Epoch: 1, Steps: 264 Train Loss: 0.3633 (Forecasting Loss:0.3309 + XiCon Loss:3.2359 x Lambda(0.01)), Vali MSE Loss: 0.2925 Test MSE Loss: 0.2294
Validation loss decreased (inf --> 0.292452).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2764884
	speed: 0.0361s/iter; left time: 940.6725s
	iters: 200, epoch: 2 | loss: 0.2461414
	speed: 0.0346s/iter; left time: 897.9367s
Epoch: 2 cost time: 9.333956003189087
Epoch: 2, Steps: 264 Train Loss: 0.2779 (Forecasting Loss:0.2459 + XiCon Loss:3.1994 x Lambda(0.01)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.2033
Validation loss decreased (0.292452 --> 0.258354).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2651498
	speed: 0.0370s/iter; left time: 953.1674s
	iters: 200, epoch: 3 | loss: 0.2668257
	speed: 0.0340s/iter; left time: 873.7035s
Epoch: 3 cost time: 9.251018524169922
Epoch: 3, Steps: 264 Train Loss: 0.2624 (Forecasting Loss:0.2309 + XiCon Loss:3.1589 x Lambda(0.01)), Vali MSE Loss: 0.2670 Test MSE Loss: 0.2090
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2408296
	speed: 0.0363s/iter; left time: 926.3851s
	iters: 200, epoch: 4 | loss: 0.2544659
	speed: 0.0339s/iter; left time: 860.7408s
Epoch: 4 cost time: 9.197299718856812
Epoch: 4, Steps: 264 Train Loss: 0.2557 (Forecasting Loss:0.2242 + XiCon Loss:3.1460 x Lambda(0.01)), Vali MSE Loss: 0.2719 Test MSE Loss: 0.2134
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2648368
	speed: 0.0369s/iter; left time: 931.9020s
	iters: 200, epoch: 5 | loss: 0.2502433
	speed: 0.0342s/iter; left time: 860.9608s
Epoch: 5 cost time: 9.33179259300232
Epoch: 5, Steps: 264 Train Loss: 0.2518 (Forecasting Loss:0.2204 + XiCon Loss:3.1424 x Lambda(0.01)), Vali MSE Loss: 0.2762 Test MSE Loss: 0.2169
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2842234
	speed: 0.0375s/iter; left time: 937.7566s
	iters: 200, epoch: 6 | loss: 0.2508382
	speed: 0.0344s/iter; left time: 856.7671s
Epoch: 6 cost time: 9.445649862289429
Epoch: 6, Steps: 264 Train Loss: 0.2503 (Forecasting Loss:0.2188 + XiCon Loss:3.1420 x Lambda(0.01)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.2169
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2638480
	speed: 0.0376s/iter; left time: 928.2777s
	iters: 200, epoch: 7 | loss: 0.2332456
	speed: 0.0346s/iter; left time: 850.8046s
Epoch: 7 cost time: 9.424575805664062
Epoch: 7, Steps: 264 Train Loss: 0.2490 (Forecasting Loss:0.2176 + XiCon Loss:3.1403 x Lambda(0.01)), Vali MSE Loss: 0.2777 Test MSE Loss: 0.2189
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2458883
	speed: 0.0378s/iter; left time: 923.8558s
	iters: 200, epoch: 8 | loss: 0.2423439
	speed: 0.0352s/iter; left time: 857.1690s
Epoch: 8 cost time: 9.508996963500977
Epoch: 8, Steps: 264 Train Loss: 0.2487 (Forecasting Loss:0.2173 + XiCon Loss:3.1411 x Lambda(0.01)), Vali MSE Loss: 0.2782 Test MSE Loss: 0.2191
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2497784
	speed: 0.0367s/iter; left time: 886.6220s
	iters: 200, epoch: 9 | loss: 0.2558842
	speed: 0.0342s/iter; left time: 823.8458s
Epoch: 9 cost time: 9.337665319442749
Epoch: 9, Steps: 264 Train Loss: 0.2486 (Forecasting Loss:0.2172 + XiCon Loss:3.1411 x Lambda(0.01)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2194
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2565036
	speed: 0.0366s/iter; left time: 876.7584s
	iters: 200, epoch: 10 | loss: 0.2383663
	speed: 0.0344s/iter; left time: 820.2663s
Epoch: 10 cost time: 9.399585008621216
Epoch: 10, Steps: 264 Train Loss: 0.2484 (Forecasting Loss:0.2170 + XiCon Loss:3.1405 x Lambda(0.01)), Vali MSE Loss: 0.2790 Test MSE Loss: 0.2196
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2535910
	speed: 0.0365s/iter; left time: 863.2320s
	iters: 200, epoch: 11 | loss: 0.2511635
	speed: 0.0350s/iter; left time: 824.0152s
Epoch: 11 cost time: 9.375174760818481
Epoch: 11, Steps: 264 Train Loss: 0.2484 (Forecasting Loss:0.2170 + XiCon Loss:3.1409 x Lambda(0.01)), Vali MSE Loss: 0.2789 Test MSE Loss: 0.2196
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2515187
	speed: 0.0371s/iter; left time: 868.4802s
	iters: 200, epoch: 12 | loss: 0.2679165
	speed: 0.0338s/iter; left time: 787.4250s
Epoch: 12 cost time: 9.343788862228394
Epoch: 12, Steps: 264 Train Loss: 0.2482 (Forecasting Loss:0.2168 + XiCon Loss:3.1429 x Lambda(0.01)), Vali MSE Loss: 0.2787 Test MSE Loss: 0.2196
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12941814959049225, mae:0.27724021673202515, mape:0.665799617767334, mspe:15.786608695983887 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.0597
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3619221
	speed: 0.0398s/iter; left time: 1046.1218s
	iters: 200, epoch: 1 | loss: 0.3828864
	speed: 0.0354s/iter; left time: 928.3906s
Epoch: 1 cost time: 9.863749742507935
Epoch: 1, Steps: 264 Train Loss: 0.3671 (Forecasting Loss:0.3347 + XiCon Loss:3.2469 x Lambda(0.01)), Vali MSE Loss: 0.2959 Test MSE Loss: 0.2324
Validation loss decreased (inf --> 0.295896).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3169780
	speed: 0.0376s/iter; left time: 977.9012s
	iters: 200, epoch: 2 | loss: 0.2645980
	speed: 0.0345s/iter; left time: 893.8045s
Epoch: 2 cost time: 9.364426851272583
Epoch: 2, Steps: 264 Train Loss: 0.2771 (Forecasting Loss:0.2456 + XiCon Loss:3.1474 x Lambda(0.01)), Vali MSE Loss: 0.2593 Test MSE Loss: 0.2053
Validation loss decreased (0.295896 --> 0.259344).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2660685
	speed: 0.0366s/iter; left time: 944.0890s
	iters: 200, epoch: 3 | loss: 0.2724495
	speed: 0.0344s/iter; left time: 884.3214s
Epoch: 3 cost time: 9.313631772994995
Epoch: 3, Steps: 264 Train Loss: 0.2592 (Forecasting Loss:0.2283 + XiCon Loss:3.0912 x Lambda(0.01)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.2153
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2662241
	speed: 0.0369s/iter; left time: 941.8076s
	iters: 200, epoch: 4 | loss: 0.2614665
	speed: 0.0353s/iter; left time: 896.2650s
Epoch: 4 cost time: 9.440716028213501
Epoch: 4, Steps: 264 Train Loss: 0.2530 (Forecasting Loss:0.2222 + XiCon Loss:3.0819 x Lambda(0.01)), Vali MSE Loss: 0.2615 Test MSE Loss: 0.2210
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2480395
	speed: 0.0363s/iter; left time: 917.5343s
	iters: 200, epoch: 5 | loss: 0.2371868
	speed: 0.0346s/iter; left time: 870.9281s
Epoch: 5 cost time: 9.3174467086792
Epoch: 5, Steps: 264 Train Loss: 0.2502 (Forecasting Loss:0.2194 + XiCon Loss:3.0768 x Lambda(0.01)), Vali MSE Loss: 0.2572 Test MSE Loss: 0.2199
Validation loss decreased (0.259344 --> 0.257246).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2464708
	speed: 0.0375s/iter; left time: 935.9082s
	iters: 200, epoch: 6 | loss: 0.2771779
	speed: 0.0343s/iter; left time: 853.6862s
Epoch: 6 cost time: 9.36121654510498
Epoch: 6, Steps: 264 Train Loss: 0.2488 (Forecasting Loss:0.2181 + XiCon Loss:3.0728 x Lambda(0.01)), Vali MSE Loss: 0.2595 Test MSE Loss: 0.2222
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2668292
	speed: 0.0359s/iter; left time: 887.2657s
	iters: 200, epoch: 7 | loss: 0.2602273
	speed: 0.0348s/iter; left time: 857.0933s
Epoch: 7 cost time: 9.298720359802246
Epoch: 7, Steps: 264 Train Loss: 0.2479 (Forecasting Loss:0.2172 + XiCon Loss:3.0709 x Lambda(0.01)), Vali MSE Loss: 0.2594 Test MSE Loss: 0.2232
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2498402
	speed: 0.0364s/iter; left time: 891.1954s
	iters: 200, epoch: 8 | loss: 0.2212919
	speed: 0.0345s/iter; left time: 840.0086s
Epoch: 8 cost time: 9.312280416488647
Epoch: 8, Steps: 264 Train Loss: 0.2478 (Forecasting Loss:0.2170 + XiCon Loss:3.0722 x Lambda(0.01)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.2241
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2360830
	speed: 0.0363s/iter; left time: 878.1902s
	iters: 200, epoch: 9 | loss: 0.2403775
	speed: 0.0343s/iter; left time: 825.9159s
Epoch: 9 cost time: 9.220459938049316
Epoch: 9, Steps: 264 Train Loss: 0.2476 (Forecasting Loss:0.2169 + XiCon Loss:3.0706 x Lambda(0.01)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.2239
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2338175
	speed: 0.0361s/iter; left time: 862.7446s
	iters: 200, epoch: 10 | loss: 0.2705853
	speed: 0.0343s/iter; left time: 816.1144s
Epoch: 10 cost time: 9.229572772979736
Epoch: 10, Steps: 264 Train Loss: 0.2474 (Forecasting Loss:0.2167 + XiCon Loss:3.0725 x Lambda(0.01)), Vali MSE Loss: 0.2600 Test MSE Loss: 0.2238
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2322027
	speed: 0.0383s/iter; left time: 906.6379s
	iters: 200, epoch: 11 | loss: 0.2395258
	speed: 0.0351s/iter; left time: 826.7578s
Epoch: 11 cost time: 9.47987151145935
Epoch: 11, Steps: 264 Train Loss: 0.2475 (Forecasting Loss:0.2168 + XiCon Loss:3.0705 x Lambda(0.01)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.2238
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2562857
	speed: 0.0365s/iter; left time: 854.2646s
	iters: 200, epoch: 12 | loss: 0.2452683
	speed: 0.0347s/iter; left time: 808.8167s
Epoch: 12 cost time: 9.36101770401001
Epoch: 12, Steps: 264 Train Loss: 0.2472 (Forecasting Loss:0.2165 + XiCon Loss:3.0717 x Lambda(0.01)), Vali MSE Loss: 0.2598 Test MSE Loss: 0.2238
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.2512483
	speed: 0.0364s/iter; left time: 842.4210s
	iters: 200, epoch: 13 | loss: 0.2352580
	speed: 0.0341s/iter; left time: 784.7901s
Epoch: 13 cost time: 9.20514988899231
Epoch: 13, Steps: 264 Train Loss: 0.2473 (Forecasting Loss:0.2166 + XiCon Loss:3.0705 x Lambda(0.01)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.2238
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 0.2503399
	speed: 0.0370s/iter; left time: 845.0163s
	iters: 200, epoch: 14 | loss: 0.2472019
	speed: 0.0352s/iter; left time: 800.9228s
Epoch: 14 cost time: 9.407159090042114
Epoch: 14, Steps: 264 Train Loss: 0.2473 (Forecasting Loss:0.2166 + XiCon Loss:3.0707 x Lambda(0.01)), Vali MSE Loss: 0.2599 Test MSE Loss: 0.2238
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 0.2463526
	speed: 0.0362s/iter; left time: 818.4333s
	iters: 200, epoch: 15 | loss: 0.2380825
	speed: 0.0347s/iter; left time: 781.2711s
Epoch: 15 cost time: 9.360549688339233
Epoch: 15, Steps: 264 Train Loss: 0.2471 (Forecasting Loss:0.2164 + XiCon Loss:3.0709 x Lambda(0.01)), Vali MSE Loss: 0.2596 Test MSE Loss: 0.2238
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.144700825214386, mae:0.2951637804508209, mape:0.7432105541229248, mspe:20.254915237426758 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6348
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3827473
	speed: 0.0377s/iter; left time: 992.0426s
	iters: 200, epoch: 1 | loss: 0.3187649
	speed: 0.0351s/iter; left time: 919.7158s
Epoch: 1 cost time: 9.551470518112183
Epoch: 1, Steps: 264 Train Loss: 0.3654 (Forecasting Loss:0.3332 + XiCon Loss:3.2174 x Lambda(0.01)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2310
Validation loss decreased (inf --> 0.294713).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2851184
	speed: 0.0375s/iter; left time: 977.5244s
	iters: 200, epoch: 2 | loss: 0.2871534
	speed: 0.0342s/iter; left time: 888.0552s
Epoch: 2 cost time: 9.409377336502075
Epoch: 2, Steps: 264 Train Loss: 0.2804 (Forecasting Loss:0.2483 + XiCon Loss:3.2116 x Lambda(0.01)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.2082
Validation loss decreased (0.294713 --> 0.263516).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2690514
	speed: 0.0369s/iter; left time: 951.2661s
	iters: 200, epoch: 3 | loss: 0.2691426
	speed: 0.0346s/iter; left time: 889.5520s
Epoch: 3 cost time: 9.344146490097046
Epoch: 3, Steps: 264 Train Loss: 0.2682 (Forecasting Loss:0.2362 + XiCon Loss:3.1956 x Lambda(0.01)), Vali MSE Loss: 0.2588 Test MSE Loss: 0.2048
Validation loss decreased (0.263516 --> 0.258841).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2927225
	speed: 0.0359s/iter; left time: 916.3332s
	iters: 200, epoch: 4 | loss: 0.2722708
	speed: 0.0345s/iter; left time: 876.8872s
Epoch: 4 cost time: 9.163499116897583
Epoch: 4, Steps: 264 Train Loss: 0.2649 (Forecasting Loss:0.2330 + XiCon Loss:3.1926 x Lambda(0.01)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.2064
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2690441
	speed: 0.0367s/iter; left time: 927.2949s
	iters: 200, epoch: 5 | loss: 0.2781622
	speed: 0.0345s/iter; left time: 867.1496s
Epoch: 5 cost time: 9.256294965744019
Epoch: 5, Steps: 264 Train Loss: 0.2630 (Forecasting Loss:0.2311 + XiCon Loss:3.1874 x Lambda(0.01)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.2063
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2666398
	speed: 0.0363s/iter; left time: 906.9163s
	iters: 200, epoch: 6 | loss: 0.2845036
	speed: 0.0345s/iter; left time: 857.5344s
Epoch: 6 cost time: 9.223803520202637
Epoch: 6, Steps: 264 Train Loss: 0.2618 (Forecasting Loss:0.2299 + XiCon Loss:3.1870 x Lambda(0.01)), Vali MSE Loss: 0.2663 Test MSE Loss: 0.2063
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2974854
	speed: 0.0368s/iter; left time: 908.4355s
	iters: 200, epoch: 7 | loss: 0.2552810
	speed: 0.0333s/iter; left time: 818.8618s
Epoch: 7 cost time: 9.14200496673584
Epoch: 7, Steps: 264 Train Loss: 0.2613 (Forecasting Loss:0.2294 + XiCon Loss:3.1850 x Lambda(0.01)), Vali MSE Loss: 0.2665 Test MSE Loss: 0.2066
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2612261
	speed: 0.0370s/iter; left time: 903.6956s
	iters: 200, epoch: 8 | loss: 0.2692303
	speed: 0.0344s/iter; left time: 837.7025s
Epoch: 8 cost time: 9.356036901473999
Epoch: 8, Steps: 264 Train Loss: 0.2611 (Forecasting Loss:0.2292 + XiCon Loss:3.1845 x Lambda(0.01)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.2066
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2649953
	speed: 0.0368s/iter; left time: 889.5883s
	iters: 200, epoch: 9 | loss: 0.2635734
	speed: 0.0352s/iter; left time: 848.1514s
Epoch: 9 cost time: 9.446977376937866
Epoch: 9, Steps: 264 Train Loss: 0.2609 (Forecasting Loss:0.2291 + XiCon Loss:3.1870 x Lambda(0.01)), Vali MSE Loss: 0.2665 Test MSE Loss: 0.2066
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2560884
	speed: 0.0373s/iter; left time: 891.3297s
	iters: 200, epoch: 10 | loss: 0.2811884
	speed: 0.0339s/iter; left time: 807.2623s
Epoch: 10 cost time: 9.269152402877808
Epoch: 10, Steps: 264 Train Loss: 0.2607 (Forecasting Loss:0.2289 + XiCon Loss:3.1852 x Lambda(0.01)), Vali MSE Loss: 0.2665 Test MSE Loss: 0.2067
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2636340
	speed: 0.0377s/iter; left time: 891.8732s
	iters: 200, epoch: 11 | loss: 0.2668390
	speed: 0.0341s/iter; left time: 803.7809s
Epoch: 11 cost time: 9.382498025894165
Epoch: 11, Steps: 264 Train Loss: 0.2607 (Forecasting Loss:0.2288 + XiCon Loss:3.1863 x Lambda(0.01)), Vali MSE Loss: 0.2667 Test MSE Loss: 0.2067
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2432938
	speed: 0.0373s/iter; left time: 872.8281s
	iters: 200, epoch: 12 | loss: 0.2551793
	speed: 0.0348s/iter; left time: 810.0073s
Epoch: 12 cost time: 9.485111713409424
Epoch: 12, Steps: 264 Train Loss: 0.2605 (Forecasting Loss:0.2287 + XiCon Loss:3.1853 x Lambda(0.01)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.2067
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.2476618
	speed: 0.0375s/iter; left time: 867.2820s
	iters: 200, epoch: 13 | loss: 0.2535287
	speed: 0.0346s/iter; left time: 796.3803s
Epoch: 13 cost time: 9.397465229034424
Epoch: 13, Steps: 264 Train Loss: 0.2607 (Forecasting Loss:0.2288 + XiCon Loss:3.1879 x Lambda(0.01)), Vali MSE Loss: 0.2666 Test MSE Loss: 0.2067
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.13077566027641296, mae:0.27877652645111084, mape:0.7029566764831543, mspe:18.026418685913086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7714
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.3939738
	speed: 0.0381s/iter; left time: 1001.8471s
	iters: 200, epoch: 1 | loss: 0.3328252
	speed: 0.0367s/iter; left time: 961.2792s
Epoch: 1 cost time: 9.746511936187744
Epoch: 1, Steps: 264 Train Loss: 0.3689 (Forecasting Loss:0.3366 + XiCon Loss:3.2332 x Lambda(0.01)), Vali MSE Loss: 0.2988 Test MSE Loss: 0.2342
Validation loss decreased (inf --> 0.298838).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3039439
	speed: 0.0372s/iter; left time: 968.0105s
	iters: 200, epoch: 2 | loss: 0.2524931
	speed: 0.0341s/iter; left time: 885.3852s
Epoch: 2 cost time: 9.330493211746216
Epoch: 2, Steps: 264 Train Loss: 0.2777 (Forecasting Loss:0.2460 + XiCon Loss:3.1625 x Lambda(0.01)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2012
Validation loss decreased (0.298838 --> 0.249802).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.2686015
	speed: 0.0367s/iter; left time: 946.8604s
	iters: 200, epoch: 3 | loss: 0.2951679
	speed: 0.0351s/iter; left time: 900.8721s
Epoch: 3 cost time: 9.401360034942627
Epoch: 3, Steps: 264 Train Loss: 0.2618 (Forecasting Loss:0.2306 + XiCon Loss:3.1213 x Lambda(0.01)), Vali MSE Loss: 0.2552 Test MSE Loss: 0.2047
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2481942
	speed: 0.0371s/iter; left time: 946.1614s
	iters: 200, epoch: 4 | loss: 0.2439704
	speed: 0.0341s/iter; left time: 866.4305s
Epoch: 4 cost time: 9.334299802780151
Epoch: 4, Steps: 264 Train Loss: 0.2571 (Forecasting Loss:0.2259 + XiCon Loss:3.1135 x Lambda(0.01)), Vali MSE Loss: 0.2565 Test MSE Loss: 0.2070
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2524596
	speed: 0.0368s/iter; left time: 929.8795s
	iters: 200, epoch: 5 | loss: 0.2821133
	speed: 0.0340s/iter; left time: 855.2781s
Epoch: 5 cost time: 9.315908670425415
Epoch: 5, Steps: 264 Train Loss: 0.2547 (Forecasting Loss:0.2237 + XiCon Loss:3.1082 x Lambda(0.01)), Vali MSE Loss: 0.2591 Test MSE Loss: 0.2097
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2345996
	speed: 0.0369s/iter; left time: 922.6098s
	iters: 200, epoch: 6 | loss: 0.2224705
	speed: 0.0349s/iter; left time: 869.4511s
Epoch: 6 cost time: 9.427765130996704
Epoch: 6, Steps: 264 Train Loss: 0.2535 (Forecasting Loss:0.2224 + XiCon Loss:3.1053 x Lambda(0.01)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.2086
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2802730
	speed: 0.0365s/iter; left time: 902.0305s
	iters: 200, epoch: 7 | loss: 0.2293052
	speed: 0.0358s/iter; left time: 880.8633s
Epoch: 7 cost time: 9.545321464538574
Epoch: 7, Steps: 264 Train Loss: 0.2530 (Forecasting Loss:0.2220 + XiCon Loss:3.1019 x Lambda(0.01)), Vali MSE Loss: 0.2607 Test MSE Loss: 0.2091
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2408569
	speed: 0.0364s/iter; left time: 889.7772s
	iters: 200, epoch: 8 | loss: 0.2653898
	speed: 0.0344s/iter; left time: 836.6400s
Epoch: 8 cost time: 9.286360740661621
Epoch: 8, Steps: 264 Train Loss: 0.2526 (Forecasting Loss:0.2216 + XiCon Loss:3.1031 x Lambda(0.01)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.2094
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2672257
	speed: 0.0363s/iter; left time: 876.8849s
	iters: 200, epoch: 9 | loss: 0.2167344
	speed: 0.0347s/iter; left time: 836.0100s
Epoch: 9 cost time: 9.339089155197144
Epoch: 9, Steps: 264 Train Loss: 0.2523 (Forecasting Loss:0.2213 + XiCon Loss:3.1031 x Lambda(0.01)), Vali MSE Loss: 0.2606 Test MSE Loss: 0.2096
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2677711
	speed: 0.0365s/iter; left time: 873.8439s
	iters: 200, epoch: 10 | loss: 0.2417347
	speed: 0.0344s/iter; left time: 818.8771s
Epoch: 10 cost time: 9.278434038162231
Epoch: 10, Steps: 264 Train Loss: 0.2524 (Forecasting Loss:0.2214 + XiCon Loss:3.1017 x Lambda(0.01)), Vali MSE Loss: 0.2603 Test MSE Loss: 0.2095
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2692750
	speed: 0.0366s/iter; left time: 866.0530s
	iters: 200, epoch: 11 | loss: 0.2387306
	speed: 0.0333s/iter; left time: 784.0511s
Epoch: 11 cost time: 9.179163455963135
Epoch: 11, Steps: 264 Train Loss: 0.2523 (Forecasting Loss:0.2213 + XiCon Loss:3.1021 x Lambda(0.01)), Vali MSE Loss: 0.2605 Test MSE Loss: 0.2096
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2681577
	speed: 0.0370s/iter; left time: 865.5692s
	iters: 200, epoch: 12 | loss: 0.3014832
	speed: 0.0358s/iter; left time: 835.1174s
Epoch: 12 cost time: 9.619913816452026
Epoch: 12, Steps: 264 Train Loss: 0.2523 (Forecasting Loss:0.2212 + XiCon Loss:3.1012 x Lambda(0.01)), Vali MSE Loss: 0.2602 Test MSE Loss: 0.2096
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12697279453277588, mae:0.27533769607543945, mape:0.6652430891990662, mspe:15.873932838439941 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1311+-0.01008, MAE:0.2791+-0.01206, MAPE:0.6869+-0.04491, MSPE:17.0150+-2.62468, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.01, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2461
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4146582
	speed: 0.0528s/iter; left time: 1372.6301s
	iters: 200, epoch: 1 | loss: 0.3542994
	speed: 0.0477s/iter; left time: 1234.7661s
Epoch: 1 cost time: 12.972593784332275
Epoch: 1, Steps: 261 Train Loss: 0.4039 (Forecasting Loss:0.3716 + XiCon Loss:3.2341 x Lambda(0.01)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2788
Validation loss decreased (inf --> 0.321241).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3074108
	speed: 0.0510s/iter; left time: 1311.7519s
	iters: 200, epoch: 2 | loss: 0.2931291
	speed: 0.0487s/iter; left time: 1247.5310s
Epoch: 2 cost time: 12.98313045501709
Epoch: 2, Steps: 261 Train Loss: 0.3238 (Forecasting Loss:0.2918 + XiCon Loss:3.1919 x Lambda(0.01)), Vali MSE Loss: 0.3060 Test MSE Loss: 0.2526
Validation loss decreased (0.321241 --> 0.305999).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3021751
	speed: 0.0499s/iter; left time: 1272.1090s
	iters: 200, epoch: 3 | loss: 0.3240824
	speed: 0.0480s/iter; left time: 1217.0310s
Epoch: 3 cost time: 12.838942050933838
Epoch: 3, Steps: 261 Train Loss: 0.3074 (Forecasting Loss:0.2756 + XiCon Loss:3.1716 x Lambda(0.01)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2592
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2877762
	speed: 0.0506s/iter; left time: 1276.7018s
	iters: 200, epoch: 4 | loss: 0.2998416
	speed: 0.0497s/iter; left time: 1247.7342s
Epoch: 4 cost time: 13.03371262550354
Epoch: 4, Steps: 261 Train Loss: 0.3006 (Forecasting Loss:0.2689 + XiCon Loss:3.1639 x Lambda(0.01)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2632
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3044417
	speed: 0.0511s/iter; left time: 1275.0329s
	iters: 200, epoch: 5 | loss: 0.2934837
	speed: 0.0504s/iter; left time: 1253.7343s
Epoch: 5 cost time: 13.145100116729736
Epoch: 5, Steps: 261 Train Loss: 0.2979 (Forecasting Loss:0.2663 + XiCon Loss:3.1571 x Lambda(0.01)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2624
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3261190
	speed: 0.0523s/iter; left time: 1291.3249s
	iters: 200, epoch: 6 | loss: 0.3092983
	speed: 0.0444s/iter; left time: 1092.3164s
Epoch: 6 cost time: 12.398317098617554
Epoch: 6, Steps: 261 Train Loss: 0.2961 (Forecasting Loss:0.2646 + XiCon Loss:3.1558 x Lambda(0.01)), Vali MSE Loss: 0.3245 Test MSE Loss: 0.2631
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2786933
	speed: 0.0507s/iter; left time: 1238.8078s
	iters: 200, epoch: 7 | loss: 0.2802842
	speed: 0.0496s/iter; left time: 1208.1099s
Epoch: 7 cost time: 13.136582374572754
Epoch: 7, Steps: 261 Train Loss: 0.2956 (Forecasting Loss:0.2641 + XiCon Loss:3.1534 x Lambda(0.01)), Vali MSE Loss: 0.3244 Test MSE Loss: 0.2650
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2926033
	speed: 0.0504s/iter; left time: 1218.1571s
	iters: 200, epoch: 8 | loss: 0.2992374
	speed: 0.0497s/iter; left time: 1197.5779s
Epoch: 8 cost time: 13.088754415512085
Epoch: 8, Steps: 261 Train Loss: 0.2954 (Forecasting Loss:0.2639 + XiCon Loss:3.1541 x Lambda(0.01)), Vali MSE Loss: 0.3266 Test MSE Loss: 0.2648
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2894404
	speed: 0.0516s/iter; left time: 1235.0592s
	iters: 200, epoch: 9 | loss: 0.2821270
	speed: 0.0490s/iter; left time: 1166.8123s
Epoch: 9 cost time: 13.077820062637329
Epoch: 9, Steps: 261 Train Loss: 0.2952 (Forecasting Loss:0.2636 + XiCon Loss:3.1544 x Lambda(0.01)), Vali MSE Loss: 0.3269 Test MSE Loss: 0.2647
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3173334
	speed: 0.0513s/iter; left time: 1213.4593s
	iters: 200, epoch: 10 | loss: 0.2793787
	speed: 0.0494s/iter; left time: 1162.8123s
Epoch: 10 cost time: 13.015190362930298
Epoch: 10, Steps: 261 Train Loss: 0.2949 (Forecasting Loss:0.2634 + XiCon Loss:3.1527 x Lambda(0.01)), Vali MSE Loss: 0.3269 Test MSE Loss: 0.2648
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2973604
	speed: 0.0506s/iter; left time: 1183.6853s
	iters: 200, epoch: 11 | loss: 0.2828278
	speed: 0.0490s/iter; left time: 1140.3964s
Epoch: 11 cost time: 12.946383237838745
Epoch: 11, Steps: 261 Train Loss: 0.2950 (Forecasting Loss:0.2635 + XiCon Loss:3.1520 x Lambda(0.01)), Vali MSE Loss: 0.3268 Test MSE Loss: 0.2648
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2722155
	speed: 0.0505s/iter; left time: 1168.3467s
	iters: 200, epoch: 12 | loss: 0.3140105
	speed: 0.0494s/iter; left time: 1137.6012s
Epoch: 12 cost time: 12.971361637115479
Epoch: 12, Steps: 261 Train Loss: 0.2950 (Forecasting Loss:0.2635 + XiCon Loss:3.1547 x Lambda(0.01)), Vali MSE Loss: 0.3270 Test MSE Loss: 0.2648
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17810723185539246, mae:0.3270374834537506, mape:0.7023678421974182, mspe:17.846162796020508 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.6798
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4264663
	speed: 0.0461s/iter; left time: 1197.9052s
	iters: 200, epoch: 1 | loss: 0.3703299
	speed: 0.0437s/iter; left time: 1133.0879s
Epoch: 1 cost time: 11.724995136260986
Epoch: 1, Steps: 261 Train Loss: 0.4053 (Forecasting Loss:0.3729 + XiCon Loss:3.2381 x Lambda(0.01)), Vali MSE Loss: 0.3320 Test MSE Loss: 0.2851
Validation loss decreased (inf --> 0.332017).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3428921
	speed: 0.0465s/iter; left time: 1196.1598s
	iters: 200, epoch: 2 | loss: 0.3224458
	speed: 0.0440s/iter; left time: 1128.0346s
Epoch: 2 cost time: 11.72336745262146
Epoch: 2, Steps: 261 Train Loss: 0.3277 (Forecasting Loss:0.2959 + XiCon Loss:3.1742 x Lambda(0.01)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2525
Validation loss decreased (0.332017 --> 0.289993).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3157279
	speed: 0.0474s/iter; left time: 1208.4069s
	iters: 200, epoch: 3 | loss: 0.3146455
	speed: 0.0453s/iter; left time: 1149.8927s
Epoch: 3 cost time: 11.961556434631348
Epoch: 3, Steps: 261 Train Loss: 0.3126 (Forecasting Loss:0.2811 + XiCon Loss:3.1434 x Lambda(0.01)), Vali MSE Loss: 0.2930 Test MSE Loss: 0.2568
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2971999
	speed: 0.0474s/iter; left time: 1195.2859s
	iters: 200, epoch: 4 | loss: 0.3291810
	speed: 0.0446s/iter; left time: 1119.4623s
Epoch: 4 cost time: 11.921633005142212
Epoch: 4, Steps: 261 Train Loss: 0.3078 (Forecasting Loss:0.2765 + XiCon Loss:3.1354 x Lambda(0.01)), Vali MSE Loss: 0.2980 Test MSE Loss: 0.2614
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3264510
	speed: 0.0490s/iter; left time: 1222.8085s
	iters: 200, epoch: 5 | loss: 0.2995491
	speed: 0.0455s/iter; left time: 1130.7255s
Epoch: 5 cost time: 12.24735426902771
Epoch: 5, Steps: 261 Train Loss: 0.3060 (Forecasting Loss:0.2747 + XiCon Loss:3.1316 x Lambda(0.01)), Vali MSE Loss: 0.2993 Test MSE Loss: 0.2631
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3064606
	speed: 0.0478s/iter; left time: 1180.3242s
	iters: 200, epoch: 6 | loss: 0.2968265
	speed: 0.0450s/iter; left time: 1106.8385s
Epoch: 6 cost time: 12.011223554611206
Epoch: 6, Steps: 261 Train Loss: 0.3050 (Forecasting Loss:0.2736 + XiCon Loss:3.1322 x Lambda(0.01)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.2624
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.2946590
	speed: 0.0474s/iter; left time: 1157.4410s
	iters: 200, epoch: 7 | loss: 0.2768184
	speed: 0.0448s/iter; left time: 1089.6291s
Epoch: 7 cost time: 11.881408452987671
Epoch: 7, Steps: 261 Train Loss: 0.3044 (Forecasting Loss:0.2731 + XiCon Loss:3.1301 x Lambda(0.01)), Vali MSE Loss: 0.2982 Test MSE Loss: 0.2623
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2976453
	speed: 0.0479s/iter; left time: 1158.1175s
	iters: 200, epoch: 8 | loss: 0.3127199
	speed: 0.0446s/iter; left time: 1073.9796s
Epoch: 8 cost time: 12.03320860862732
Epoch: 8, Steps: 261 Train Loss: 0.3041 (Forecasting Loss:0.2728 + XiCon Loss:3.1316 x Lambda(0.01)), Vali MSE Loss: 0.2983 Test MSE Loss: 0.2627
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2766888
	speed: 0.0496s/iter; left time: 1186.7881s
	iters: 200, epoch: 9 | loss: 0.3166568
	speed: 0.0449s/iter; left time: 1069.3537s
Epoch: 9 cost time: 12.154191732406616
Epoch: 9, Steps: 261 Train Loss: 0.3039 (Forecasting Loss:0.2727 + XiCon Loss:3.1275 x Lambda(0.01)), Vali MSE Loss: 0.2987 Test MSE Loss: 0.2625
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3336957
	speed: 0.0496s/iter; left time: 1173.8152s
	iters: 200, epoch: 10 | loss: 0.3076350
	speed: 0.0448s/iter; left time: 1056.1097s
Epoch: 10 cost time: 12.226508617401123
Epoch: 10, Steps: 261 Train Loss: 0.3042 (Forecasting Loss:0.2729 + XiCon Loss:3.1287 x Lambda(0.01)), Vali MSE Loss: 0.2982 Test MSE Loss: 0.2629
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2921647
	speed: 0.0479s/iter; left time: 1119.7543s
	iters: 200, epoch: 11 | loss: 0.2995057
	speed: 0.0444s/iter; left time: 1034.5275s
Epoch: 11 cost time: 12.001530170440674
Epoch: 11, Steps: 261 Train Loss: 0.3041 (Forecasting Loss:0.2728 + XiCon Loss:3.1309 x Lambda(0.01)), Vali MSE Loss: 0.2984 Test MSE Loss: 0.2627
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3118598
	speed: 0.0493s/iter; left time: 1141.0802s
	iters: 200, epoch: 12 | loss: 0.3297792
	speed: 0.0441s/iter; left time: 1015.6492s
Epoch: 12 cost time: 12.014519453048706
Epoch: 12, Steps: 261 Train Loss: 0.3039 (Forecasting Loss:0.2726 + XiCon Loss:3.1289 x Lambda(0.01)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.2627
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17623762786388397, mae:0.32874777913093567, mape:0.7346077561378479, mspe:20.449113845825195 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.5647
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4106679
	speed: 0.0465s/iter; left time: 1210.0146s
	iters: 200, epoch: 1 | loss: 0.3738213
	speed: 0.0432s/iter; left time: 1119.7231s
Epoch: 1 cost time: 11.614846229553223
Epoch: 1, Steps: 261 Train Loss: 0.4042 (Forecasting Loss:0.3718 + XiCon Loss:3.2372 x Lambda(0.01)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2833
Validation loss decreased (inf --> 0.328808).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3185487
	speed: 0.0455s/iter; left time: 1170.7786s
	iters: 200, epoch: 2 | loss: 0.3175757
	speed: 0.0441s/iter; left time: 1131.3181s
Epoch: 2 cost time: 11.620674133300781
Epoch: 2, Steps: 261 Train Loss: 0.3287 (Forecasting Loss:0.2974 + XiCon Loss:3.1342 x Lambda(0.01)), Vali MSE Loss: 0.2872 Test MSE Loss: 0.2468
Validation loss decreased (0.328808 --> 0.287249).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3289448
	speed: 0.0459s/iter; left time: 1169.9916s
	iters: 200, epoch: 3 | loss: 0.3138571
	speed: 0.0453s/iter; left time: 1149.5989s
Epoch: 3 cost time: 11.905980825424194
Epoch: 3, Steps: 261 Train Loss: 0.3136 (Forecasting Loss:0.2830 + XiCon Loss:3.0615 x Lambda(0.01)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2512
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3181509
	speed: 0.0458s/iter; left time: 1153.9059s
	iters: 200, epoch: 4 | loss: 0.2844748
	speed: 0.0462s/iter; left time: 1160.8893s
Epoch: 4 cost time: 12.033681392669678
Epoch: 4, Steps: 261 Train Loss: 0.3087 (Forecasting Loss:0.2783 + XiCon Loss:3.0472 x Lambda(0.01)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2588
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.2995557
	speed: 0.0458s/iter; left time: 1144.0055s
	iters: 200, epoch: 5 | loss: 0.3394221
	speed: 0.0445s/iter; left time: 1106.3753s
Epoch: 5 cost time: 11.75171947479248
Epoch: 5, Steps: 261 Train Loss: 0.3058 (Forecasting Loss:0.2754 + XiCon Loss:3.0412 x Lambda(0.01)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2626
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3036914
	speed: 0.0458s/iter; left time: 1130.8508s
	iters: 200, epoch: 6 | loss: 0.3110038
	speed: 0.0443s/iter; left time: 1089.3744s
Epoch: 6 cost time: 11.765036821365356
Epoch: 6, Steps: 261 Train Loss: 0.3039 (Forecasting Loss:0.2735 + XiCon Loss:3.0394 x Lambda(0.01)), Vali MSE Loss: 0.2948 Test MSE Loss: 0.2634
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3121099
	speed: 0.0469s/iter; left time: 1146.8599s
	iters: 200, epoch: 7 | loss: 0.3044156
	speed: 0.0442s/iter; left time: 1075.5853s
Epoch: 7 cost time: 11.768831729888916
Epoch: 7, Steps: 261 Train Loss: 0.3029 (Forecasting Loss:0.2726 + XiCon Loss:3.0369 x Lambda(0.01)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.2638
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3126789
	speed: 0.0471s/iter; left time: 1137.6882s
	iters: 200, epoch: 8 | loss: 0.2931754
	speed: 0.0438s/iter; left time: 1054.7533s
Epoch: 8 cost time: 11.967031478881836
Epoch: 8, Steps: 261 Train Loss: 0.3025 (Forecasting Loss:0.2721 + XiCon Loss:3.0382 x Lambda(0.01)), Vali MSE Loss: 0.2951 Test MSE Loss: 0.2642
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2954216
	speed: 0.0479s/iter; left time: 1145.4147s
	iters: 200, epoch: 9 | loss: 0.2816081
	speed: 0.0443s/iter; left time: 1054.1571s
Epoch: 9 cost time: 11.955303430557251
Epoch: 9, Steps: 261 Train Loss: 0.3025 (Forecasting Loss:0.2721 + XiCon Loss:3.0384 x Lambda(0.01)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.2649
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3014629
	speed: 0.0472s/iter; left time: 1116.2284s
	iters: 200, epoch: 10 | loss: 0.2787274
	speed: 0.0444s/iter; left time: 1045.0225s
Epoch: 10 cost time: 11.934501886367798
Epoch: 10, Steps: 261 Train Loss: 0.3023 (Forecasting Loss:0.2719 + XiCon Loss:3.0379 x Lambda(0.01)), Vali MSE Loss: 0.2943 Test MSE Loss: 0.2650
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2906291
	speed: 0.0462s/iter; left time: 1079.6698s
	iters: 200, epoch: 11 | loss: 0.3366705
	speed: 0.0456s/iter; left time: 1061.3862s
Epoch: 11 cost time: 11.954968452453613
Epoch: 11, Steps: 261 Train Loss: 0.3022 (Forecasting Loss:0.2718 + XiCon Loss:3.0401 x Lambda(0.01)), Vali MSE Loss: 0.2946 Test MSE Loss: 0.2650
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2984344
	speed: 0.0482s/iter; left time: 1115.4335s
	iters: 200, epoch: 12 | loss: 0.2946122
	speed: 0.0446s/iter; left time: 1027.8490s
Epoch: 12 cost time: 11.958876132965088
Epoch: 12, Steps: 261 Train Loss: 0.3021 (Forecasting Loss:0.2717 + XiCon Loss:3.0377 x Lambda(0.01)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2650
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17090632021427155, mae:0.3227525055408478, mape:0.714972734451294, mspe:18.941967010498047 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 19.2338
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4074018
	speed: 0.0479s/iter; left time: 1246.3678s
	iters: 200, epoch: 1 | loss: 0.4044875
	speed: 0.0449s/iter; left time: 1162.0812s
Epoch: 1 cost time: 12.013785123825073
Epoch: 1, Steps: 261 Train Loss: 0.4041 (Forecasting Loss:0.3718 + XiCon Loss:3.2377 x Lambda(0.01)), Vali MSE Loss: 0.3253 Test MSE Loss: 0.2809
Validation loss decreased (inf --> 0.325316).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.2953703
	speed: 0.0475s/iter; left time: 1222.3566s
	iters: 200, epoch: 2 | loss: 0.3210012
	speed: 0.0431s/iter; left time: 1104.3678s
Epoch: 2 cost time: 11.735896110534668
Epoch: 2, Steps: 261 Train Loss: 0.3237 (Forecasting Loss:0.2921 + XiCon Loss:3.1636 x Lambda(0.01)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.2499
Validation loss decreased (0.325316 --> 0.288418).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3096319
	speed: 0.0465s/iter; left time: 1185.8387s
	iters: 200, epoch: 3 | loss: 0.2880542
	speed: 0.0443s/iter; left time: 1124.3242s
Epoch: 3 cost time: 11.869655132293701
Epoch: 3, Steps: 261 Train Loss: 0.3106 (Forecasting Loss:0.2794 + XiCon Loss:3.1175 x Lambda(0.01)), Vali MSE Loss: 0.2866 Test MSE Loss: 0.2535
Validation loss decreased (0.288418 --> 0.286558).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.3086380
	speed: 0.0474s/iter; left time: 1195.9441s
	iters: 200, epoch: 4 | loss: 0.2876108
	speed: 0.0443s/iter; left time: 1113.3489s
Epoch: 4 cost time: 11.927617311477661
Epoch: 4, Steps: 261 Train Loss: 0.3065 (Forecasting Loss:0.2754 + XiCon Loss:3.1037 x Lambda(0.01)), Vali MSE Loss: 0.2926 Test MSE Loss: 0.2555
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3176572
	speed: 0.0486s/iter; left time: 1212.3736s
	iters: 200, epoch: 5 | loss: 0.2979809
	speed: 0.0439s/iter; left time: 1091.9653s
Epoch: 5 cost time: 12.001413583755493
Epoch: 5, Steps: 261 Train Loss: 0.3037 (Forecasting Loss:0.2727 + XiCon Loss:3.1007 x Lambda(0.01)), Vali MSE Loss: 0.2950 Test MSE Loss: 0.2571
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.3235866
	speed: 0.0486s/iter; left time: 1200.5262s
	iters: 200, epoch: 6 | loss: 0.3216011
	speed: 0.0451s/iter; left time: 1109.5518s
Epoch: 6 cost time: 12.240889549255371
Epoch: 6, Steps: 261 Train Loss: 0.3025 (Forecasting Loss:0.2715 + XiCon Loss:3.0994 x Lambda(0.01)), Vali MSE Loss: 0.2947 Test MSE Loss: 0.2579
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3166277
	speed: 0.0480s/iter; left time: 1173.6184s
	iters: 200, epoch: 7 | loss: 0.2648515
	speed: 0.0444s/iter; left time: 1080.5323s
Epoch: 7 cost time: 11.931230306625366
Epoch: 7, Steps: 261 Train Loss: 0.3017 (Forecasting Loss:0.2707 + XiCon Loss:3.0993 x Lambda(0.01)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2581
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.2788618
	speed: 0.0492s/iter; left time: 1189.9177s
	iters: 200, epoch: 8 | loss: 0.2881106
	speed: 0.0441s/iter; left time: 1061.7551s
Epoch: 8 cost time: 12.001699209213257
Epoch: 8, Steps: 261 Train Loss: 0.3015 (Forecasting Loss:0.2705 + XiCon Loss:3.0963 x Lambda(0.01)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2586
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.2862635
	speed: 0.0468s/iter; left time: 1118.5590s
	iters: 200, epoch: 9 | loss: 0.2888804
	speed: 0.0440s/iter; left time: 1048.4916s
Epoch: 9 cost time: 11.732124328613281
Epoch: 9, Steps: 261 Train Loss: 0.3012 (Forecasting Loss:0.2702 + XiCon Loss:3.0986 x Lambda(0.01)), Vali MSE Loss: 0.2940 Test MSE Loss: 0.2584
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.2914675
	speed: 0.0493s/iter; left time: 1167.1351s
	iters: 200, epoch: 10 | loss: 0.2911889
	speed: 0.0457s/iter; left time: 1076.1261s
Epoch: 10 cost time: 12.166678190231323
Epoch: 10, Steps: 261 Train Loss: 0.3011 (Forecasting Loss:0.2701 + XiCon Loss:3.0981 x Lambda(0.01)), Vali MSE Loss: 0.2939 Test MSE Loss: 0.2585
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2954290
	speed: 0.0474s/iter; left time: 1108.8509s
	iters: 200, epoch: 11 | loss: 0.3157615
	speed: 0.0454s/iter; left time: 1058.0760s
Epoch: 11 cost time: 11.96340823173523
Epoch: 11, Steps: 261 Train Loss: 0.3010 (Forecasting Loss:0.2700 + XiCon Loss:3.0980 x Lambda(0.01)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2585
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.3054770
	speed: 0.0488s/iter; left time: 1128.3696s
	iters: 200, epoch: 12 | loss: 0.3292401
	speed: 0.0456s/iter; left time: 1049.9726s
Epoch: 12 cost time: 12.104848861694336
Epoch: 12, Steps: 261 Train Loss: 0.3012 (Forecasting Loss:0.2702 + XiCon Loss:3.0982 x Lambda(0.01)), Vali MSE Loss: 0.2940 Test MSE Loss: 0.2585
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 0.3023937
	speed: 0.0472s/iter; left time: 1079.8962s
	iters: 200, epoch: 13 | loss: 0.3132097
	speed: 0.0453s/iter; left time: 1031.3441s
Epoch: 13 cost time: 12.020740747451782
Epoch: 13, Steps: 261 Train Loss: 0.3009 (Forecasting Loss:0.2699 + XiCon Loss:3.0975 x Lambda(0.01)), Vali MSE Loss: 0.2941 Test MSE Loss: 0.2585
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.1767258197069168, mae:0.3302655816078186, mape:0.738512396812439, mspe:19.82215690612793 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.7003
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 0.4607489
	speed: 0.0512s/iter; left time: 1331.4949s
	iters: 200, epoch: 1 | loss: 0.3986835
	speed: 0.0483s/iter; left time: 1250.3659s
Epoch: 1 cost time: 12.864732503890991
Epoch: 1, Steps: 261 Train Loss: 0.4016 (Forecasting Loss:0.3693 + XiCon Loss:3.2326 x Lambda(0.01)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2799
Validation loss decreased (inf --> 0.323342).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 0.3049792
	speed: 0.0499s/iter; left time: 1284.8948s
	iters: 200, epoch: 2 | loss: 0.2880578
	speed: 0.0474s/iter; left time: 1215.8136s
Epoch: 2 cost time: 12.501057147979736
Epoch: 2, Steps: 261 Train Loss: 0.3273 (Forecasting Loss:0.2955 + XiCon Loss:3.1740 x Lambda(0.01)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.2481
Validation loss decreased (0.323342 --> 0.291441).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 0.3278810
	speed: 0.0478s/iter; left time: 1216.8060s
	iters: 200, epoch: 3 | loss: 0.3230293
	speed: 0.0485s/iter; left time: 1231.7003s
Epoch: 3 cost time: 12.589985609054565
Epoch: 3, Steps: 261 Train Loss: 0.3126 (Forecasting Loss:0.2813 + XiCon Loss:3.1311 x Lambda(0.01)), Vali MSE Loss: 0.2927 Test MSE Loss: 0.2547
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 0.2986485
	speed: 0.0506s/iter; left time: 1276.5662s
	iters: 200, epoch: 4 | loss: 0.3133473
	speed: 0.0491s/iter; left time: 1233.1501s
Epoch: 4 cost time: 12.947813987731934
Epoch: 4, Steps: 261 Train Loss: 0.3077 (Forecasting Loss:0.2765 + XiCon Loss:3.1174 x Lambda(0.01)), Vali MSE Loss: 0.2969 Test MSE Loss: 0.2592
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 0.3169295
	speed: 0.0513s/iter; left time: 1280.1146s
	iters: 200, epoch: 5 | loss: 0.3246341
	speed: 0.0495s/iter; left time: 1230.4058s
Epoch: 5 cost time: 13.161253690719604
Epoch: 5, Steps: 261 Train Loss: 0.3047 (Forecasting Loss:0.2736 + XiCon Loss:3.1136 x Lambda(0.01)), Vali MSE Loss: 0.2985 Test MSE Loss: 0.2625
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 0.2968112
	speed: 0.0525s/iter; left time: 1296.2290s
	iters: 200, epoch: 6 | loss: 0.3313899
	speed: 0.0496s/iter; left time: 1220.4696s
Epoch: 6 cost time: 13.310157537460327
Epoch: 6, Steps: 261 Train Loss: 0.3038 (Forecasting Loss:0.2727 + XiCon Loss:3.1116 x Lambda(0.01)), Vali MSE Loss: 0.2989 Test MSE Loss: 0.2621
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 0.3005787
	speed: 0.0506s/iter; left time: 1236.6483s
	iters: 200, epoch: 7 | loss: 0.3274523
	speed: 0.0492s/iter; left time: 1198.4292s
Epoch: 7 cost time: 13.052029848098755
Epoch: 7, Steps: 261 Train Loss: 0.3030 (Forecasting Loss:0.2719 + XiCon Loss:3.1109 x Lambda(0.01)), Vali MSE Loss: 0.2994 Test MSE Loss: 0.2618
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 0.3092780
	speed: 0.0510s/iter; left time: 1233.1347s
	iters: 200, epoch: 8 | loss: 0.3040959
	speed: 0.0486s/iter; left time: 1169.7615s
Epoch: 8 cost time: 12.881879568099976
Epoch: 8, Steps: 261 Train Loss: 0.3029 (Forecasting Loss:0.2718 + XiCon Loss:3.1097 x Lambda(0.01)), Vali MSE Loss: 0.2997 Test MSE Loss: 0.2619
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 0.3016978
	speed: 0.0519s/iter; left time: 1242.0631s
	iters: 200, epoch: 9 | loss: 0.3049273
	speed: 0.0488s/iter; left time: 1161.5819s
Epoch: 9 cost time: 13.046504020690918
Epoch: 9, Steps: 261 Train Loss: 0.3027 (Forecasting Loss:0.2716 + XiCon Loss:3.1112 x Lambda(0.01)), Vali MSE Loss: 0.2997 Test MSE Loss: 0.2623
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 0.3000089
	speed: 0.0509s/iter; left time: 1204.0304s
	iters: 200, epoch: 10 | loss: 0.3143841
	speed: 0.0465s/iter; left time: 1096.2909s
Epoch: 10 cost time: 12.570289850234985
Epoch: 10, Steps: 261 Train Loss: 0.3029 (Forecasting Loss:0.2718 + XiCon Loss:3.1100 x Lambda(0.01)), Vali MSE Loss: 0.3000 Test MSE Loss: 0.2624
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 0.2834297
	speed: 0.0512s/iter; left time: 1196.8136s
	iters: 200, epoch: 11 | loss: 0.2783950
	speed: 0.0496s/iter; left time: 1154.1594s
Epoch: 11 cost time: 13.028138875961304
Epoch: 11, Steps: 261 Train Loss: 0.3027 (Forecasting Loss:0.2716 + XiCon Loss:3.1104 x Lambda(0.01)), Vali MSE Loss: 0.3001 Test MSE Loss: 0.2623
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 0.2941560
	speed: 0.0517s/iter; left time: 1195.4619s
	iters: 200, epoch: 12 | loss: 0.3055946
	speed: 0.0484s/iter; left time: 1114.7732s
Epoch: 12 cost time: 12.95080852508545
Epoch: 12, Steps: 261 Train Loss: 0.3026 (Forecasting Loss:0.2715 + XiCon Loss:3.1108 x Lambda(0.01)), Vali MSE Loss: 0.3001 Test MSE Loss: 0.2623
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17270316183567047, mae:0.3235442042350769, mape:0.7291606664657593, mspe:19.719533920288086 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1749+-0.00373, MAE:0.3265+-0.00404, MAPE:0.7239+-0.01862, MSPE:19.3558+-1.24095, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
