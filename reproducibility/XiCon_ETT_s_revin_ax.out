Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.4572
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2510026
	speed: 0.0159s/iter; left time: 201.9043s
Epoch: 1 cost time: 1.9006664752960205
Epoch: 1, Steps: 128 Train Loss: 3.2796 (Forecasting Loss:0.2444 + XiCon Loss:3.0353 x Lambda(1.0)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1229
Validation loss decreased (inf --> 0.173759).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0828340
	speed: 0.0143s/iter; left time: 179.2370s
Epoch: 2 cost time: 1.800849437713623
Epoch: 2, Steps: 128 Train Loss: 3.0790 (Forecasting Loss:0.2456 + XiCon Loss:2.8334 x Lambda(1.0)), Vali MSE Loss: 0.1757 Test MSE Loss: 0.1332
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 2.9071755
	speed: 0.0125s/iter; left time: 155.3541s
Epoch: 3 cost time: 1.5663814544677734
Epoch: 3, Steps: 128 Train Loss: 3.0431 (Forecasting Loss:0.2317 + XiCon Loss:2.8114 x Lambda(1.0)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1223
Validation loss decreased (0.173759 --> 0.168029).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0910246
	speed: 0.0121s/iter; left time: 148.6248s
Epoch: 4 cost time: 1.560521125793457
Epoch: 4, Steps: 128 Train Loss: 3.0956 (Forecasting Loss:0.2214 + XiCon Loss:2.8742 x Lambda(1.0)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1158
Validation loss decreased (0.168029 --> 0.167087).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2923937
	speed: 0.0121s/iter; left time: 147.3137s
Epoch: 5 cost time: 1.5158054828643799
Epoch: 5, Steps: 128 Train Loss: 3.2006 (Forecasting Loss:0.2143 + XiCon Loss:2.9863 x Lambda(1.0)), Vali MSE Loss: 0.1651 Test MSE Loss: 0.1148
Validation loss decreased (0.167087 --> 0.165085).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2069545
	speed: 0.0127s/iter; left time: 152.7218s
Epoch: 6 cost time: 1.591036081314087
Epoch: 6, Steps: 128 Train Loss: 3.1791 (Forecasting Loss:0.2103 + XiCon Loss:2.9688 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1144
Validation loss decreased (0.165085 --> 0.164738).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2388556
	speed: 0.0122s/iter; left time: 145.2729s
Epoch: 7 cost time: 1.5233285427093506
Epoch: 7, Steps: 128 Train Loss: 3.1818 (Forecasting Loss:0.2085 + XiCon Loss:2.9733 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1151
Validation loss decreased (0.164738 --> 0.163515).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1650333
	speed: 0.0125s/iter; left time: 147.4879s
Epoch: 8 cost time: 1.5726869106292725
Epoch: 8, Steps: 128 Train Loss: 3.1612 (Forecasting Loss:0.2075 + XiCon Loss:2.9537 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0963459
	speed: 0.0122s/iter; left time: 141.8819s
Epoch: 9 cost time: 1.5200169086456299
Epoch: 9, Steps: 128 Train Loss: 3.1640 (Forecasting Loss:0.2066 + XiCon Loss:2.9574 x Lambda(1.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1148
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.0513299
	speed: 0.0121s/iter; left time: 139.2786s
Epoch: 10 cost time: 1.5099949836730957
Epoch: 10, Steps: 128 Train Loss: 3.1453 (Forecasting Loss:0.2062 + XiCon Loss:2.9390 x Lambda(1.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1148
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1882565
	speed: 0.0126s/iter; left time: 143.4340s
Epoch: 11 cost time: 1.5948927402496338
Epoch: 11, Steps: 128 Train Loss: 3.1552 (Forecasting Loss:0.2060 + XiCon Loss:2.9492 x Lambda(1.0)), Vali MSE Loss: 0.1648 Test MSE Loss: 0.1147
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.1267238
	speed: 0.0120s/iter; left time: 135.0226s
Epoch: 12 cost time: 1.4986867904663086
Epoch: 12, Steps: 128 Train Loss: 3.1521 (Forecasting Loss:0.2059 + XiCon Loss:2.9462 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1146
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.2296762
	speed: 0.0120s/iter; left time: 133.9206s
Epoch: 13 cost time: 1.5047590732574463
Epoch: 13, Steps: 128 Train Loss: 3.1643 (Forecasting Loss:0.2061 + XiCon Loss:2.9582 x Lambda(1.0)), Vali MSE Loss: 0.1646 Test MSE Loss: 0.1147
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.3827884
	speed: 0.0119s/iter; left time: 130.9388s
Epoch: 14 cost time: 1.4850726127624512
Epoch: 14, Steps: 128 Train Loss: 3.1652 (Forecasting Loss:0.2061 + XiCon Loss:2.9591 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1147
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1002917
	speed: 0.0121s/iter; left time: 132.0227s
Epoch: 15 cost time: 1.5172970294952393
Epoch: 15, Steps: 128 Train Loss: 3.1595 (Forecasting Loss:0.2065 + XiCon Loss:2.9530 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1147
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.0595508
	speed: 0.0126s/iter; left time: 135.9263s
Epoch: 16 cost time: 1.5832843780517578
Epoch: 16, Steps: 128 Train Loss: 3.1683 (Forecasting Loss:0.2061 + XiCon Loss:2.9621 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1147
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.1220827
	speed: 0.0119s/iter; left time: 127.1157s
Epoch: 17 cost time: 1.4952483177185059
Epoch: 17, Steps: 128 Train Loss: 3.1603 (Forecasting Loss:0.2062 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.1644 Test MSE Loss: 0.1147
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05397489294409752, mae:0.17619596421718597, mape:0.1414296180009842, mspe:0.03953569754958153 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2677
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2012334
	speed: 0.0128s/iter; left time: 162.5260s
Epoch: 1 cost time: 1.607630968093872
Epoch: 1, Steps: 128 Train Loss: 3.2542 (Forecasting Loss:0.2418 + XiCon Loss:3.0124 x Lambda(1.0)), Vali MSE Loss: 0.1742 Test MSE Loss: 0.1218
Validation loss decreased (inf --> 0.174172).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1155291
	speed: 0.0137s/iter; left time: 171.9302s
Epoch: 2 cost time: 1.7150421142578125
Epoch: 2, Steps: 128 Train Loss: 3.0846 (Forecasting Loss:0.2454 + XiCon Loss:2.8392 x Lambda(1.0)), Vali MSE Loss: 0.1790 Test MSE Loss: 0.1219
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.4212625
	speed: 0.0126s/iter; left time: 156.2871s
Epoch: 3 cost time: 1.6029512882232666
Epoch: 3, Steps: 128 Train Loss: 3.2775 (Forecasting Loss:0.2322 + XiCon Loss:3.0453 x Lambda(1.0)), Vali MSE Loss: 0.1683 Test MSE Loss: 0.1212
Validation loss decreased (0.174172 --> 0.168254).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1101604
	speed: 0.0130s/iter; left time: 160.7310s
Epoch: 4 cost time: 1.6011388301849365
Epoch: 4, Steps: 128 Train Loss: 3.2711 (Forecasting Loss:0.2229 + XiCon Loss:3.0482 x Lambda(1.0)), Vali MSE Loss: 0.1668 Test MSE Loss: 0.1197
Validation loss decreased (0.168254 --> 0.166804).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2847168
	speed: 0.0119s/iter; left time: 144.5378s
Epoch: 5 cost time: 1.4856488704681396
Epoch: 5, Steps: 128 Train Loss: 3.2136 (Forecasting Loss:0.2181 + XiCon Loss:2.9955 x Lambda(1.0)), Vali MSE Loss: 0.1647 Test MSE Loss: 0.1170
Validation loss decreased (0.166804 --> 0.164668).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2259626
	speed: 0.0117s/iter; left time: 140.9896s
Epoch: 6 cost time: 1.4678082466125488
Epoch: 6, Steps: 128 Train Loss: 3.2096 (Forecasting Loss:0.2159 + XiCon Loss:2.9937 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1177
Validation loss decreased (0.164668 --> 0.164246).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.1190219
	speed: 0.0117s/iter; left time: 140.1237s
Epoch: 7 cost time: 1.4705677032470703
Epoch: 7, Steps: 128 Train Loss: 3.1876 (Forecasting Loss:0.2144 + XiCon Loss:2.9732 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1158
Validation loss decreased (0.164246 --> 0.163633).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.4374928
	speed: 0.0117s/iter; left time: 137.6830s
Epoch: 8 cost time: 1.4631028175354004
Epoch: 8, Steps: 128 Train Loss: 3.2016 (Forecasting Loss:0.2135 + XiCon Loss:2.9881 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1164
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.0574865
	speed: 0.0117s/iter; left time: 136.6832s
Epoch: 9 cost time: 1.4692940711975098
Epoch: 9, Steps: 128 Train Loss: 3.1824 (Forecasting Loss:0.2133 + XiCon Loss:2.9691 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1161
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2863865
	speed: 0.0117s/iter; left time: 135.5231s
Epoch: 10 cost time: 1.4743752479553223
Epoch: 10, Steps: 128 Train Loss: 3.1934 (Forecasting Loss:0.2132 + XiCon Loss:2.9803 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1162
Validation loss decreased (0.163633 --> 0.163532).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2342436
	speed: 0.0117s/iter; left time: 133.2632s
Epoch: 11 cost time: 1.4605648517608643
Epoch: 11, Steps: 128 Train Loss: 3.1750 (Forecasting Loss:0.2130 + XiCon Loss:2.9620 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.2551889
	speed: 0.0116s/iter; left time: 131.3114s
Epoch: 12 cost time: 1.4568116664886475
Epoch: 12, Steps: 128 Train Loss: 3.1960 (Forecasting Loss:0.2130 + XiCon Loss:2.9831 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1161
Validation loss decreased (0.163532 --> 0.163428).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0905025
	speed: 0.0118s/iter; left time: 131.4144s
Epoch: 13 cost time: 1.473323106765747
Epoch: 13, Steps: 128 Train Loss: 3.1785 (Forecasting Loss:0.2131 + XiCon Loss:2.9655 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0869105
	speed: 0.0117s/iter; left time: 129.2172s
Epoch: 14 cost time: 1.4666497707366943
Epoch: 14, Steps: 128 Train Loss: 3.1795 (Forecasting Loss:0.2130 + XiCon Loss:2.9665 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.1449170
	speed: 0.0124s/iter; left time: 135.2170s
Epoch: 15 cost time: 1.534538984298706
Epoch: 15, Steps: 128 Train Loss: 3.1999 (Forecasting Loss:0.2129 + XiCon Loss:2.9870 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1744268
	speed: 0.0123s/iter; left time: 132.4944s
Epoch: 16 cost time: 1.5439395904541016
Epoch: 16, Steps: 128 Train Loss: 3.1861 (Forecasting Loss:0.2130 + XiCon Loss:2.9731 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1161
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.0902050
	speed: 0.0116s/iter; left time: 124.0854s
Epoch: 17 cost time: 1.4738271236419678
Epoch: 17, Steps: 128 Train Loss: 3.1997 (Forecasting Loss:0.2130 + XiCon Loss:2.9867 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1161
Validation loss decreased (0.163428 --> 0.163264).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.1725330
	speed: 0.0124s/iter; left time: 130.1779s
Epoch: 18 cost time: 1.5364959239959717
Epoch: 18, Steps: 128 Train Loss: 3.1780 (Forecasting Loss:0.2128 + XiCon Loss:2.9652 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2674389
	speed: 0.0117s/iter; left time: 121.2957s
Epoch: 19 cost time: 1.457554578781128
Epoch: 19, Steps: 128 Train Loss: 3.1854 (Forecasting Loss:0.2130 + XiCon Loss:2.9724 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1161
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.1935239
	speed: 0.0116s/iter; left time: 119.3177s
Epoch: 20 cost time: 1.4582929611206055
Epoch: 20, Steps: 128 Train Loss: 3.1830 (Forecasting Loss:0.2129 + XiCon Loss:2.9700 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1161
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.1170907
	speed: 0.0116s/iter; left time: 117.6488s
Epoch: 21 cost time: 1.4520957469940186
Epoch: 21, Steps: 128 Train Loss: 3.2083 (Forecasting Loss:0.2130 + XiCon Loss:2.9953 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.0651951
	speed: 0.0118s/iter; left time: 118.2920s
Epoch: 22 cost time: 1.4760513305664062
Epoch: 22, Steps: 128 Train Loss: 3.1908 (Forecasting Loss:0.2130 + XiCon Loss:2.9778 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1161
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.0906787
	speed: 0.0119s/iter; left time: 117.5595s
Epoch: 23 cost time: 1.4968831539154053
Epoch: 23, Steps: 128 Train Loss: 3.1896 (Forecasting Loss:0.2130 + XiCon Loss:2.9766 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1161
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.1327221
	speed: 0.0122s/iter; left time: 118.8101s
Epoch: 24 cost time: 1.5090293884277344
Epoch: 24, Steps: 128 Train Loss: 3.1943 (Forecasting Loss:0.2130 + XiCon Loss:2.9813 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1161
Validation loss decreased (0.163264 --> 0.163258).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.3213804
	speed: 0.0118s/iter; left time: 113.4270s
Epoch: 25 cost time: 1.47664213180542
Epoch: 25, Steps: 128 Train Loss: 3.2021 (Forecasting Loss:0.2130 + XiCon Loss:2.9891 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1161
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2311809
	speed: 0.0117s/iter; left time: 110.6925s
Epoch: 26 cost time: 1.4600396156311035
Epoch: 26, Steps: 128 Train Loss: 3.1868 (Forecasting Loss:0.2130 + XiCon Loss:2.9738 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1161
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.1340885
	speed: 0.0116s/iter; left time: 109.1528s
Epoch: 27 cost time: 1.4586989879608154
Epoch: 27, Steps: 128 Train Loss: 3.1919 (Forecasting Loss:0.2130 + XiCon Loss:2.9789 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1161
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.1544137
	speed: 0.0121s/iter; left time: 112.2994s
Epoch: 28 cost time: 1.5109376907348633
Epoch: 28, Steps: 128 Train Loss: 3.1794 (Forecasting Loss:0.2130 + XiCon Loss:2.9664 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.4336696
	speed: 0.0128s/iter; left time: 116.4127s
Epoch: 29 cost time: 1.6220943927764893
Epoch: 29, Steps: 128 Train Loss: 3.1896 (Forecasting Loss:0.2130 + XiCon Loss:2.9766 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1161
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.0071077
	speed: 0.0116s/iter; left time: 104.5385s
Epoch: 30 cost time: 1.4553484916687012
Epoch: 30, Steps: 128 Train Loss: 3.1685 (Forecasting Loss:0.2129 + XiCon Loss:2.9556 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1161
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.2990084
	speed: 0.0116s/iter; left time: 103.0668s
Epoch: 31 cost time: 1.4561779499053955
Epoch: 31, Steps: 128 Train Loss: 3.1987 (Forecasting Loss:0.2131 + XiCon Loss:2.9856 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1161
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.1230590
	speed: 0.0115s/iter; left time: 100.6501s
Epoch: 32 cost time: 1.4460866451263428
Epoch: 32, Steps: 128 Train Loss: 3.1903 (Forecasting Loss:0.2129 + XiCon Loss:2.9774 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1161
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.5332561
	speed: 0.0116s/iter; left time: 99.5380s
Epoch: 33 cost time: 1.4511125087738037
Epoch: 33, Steps: 128 Train Loss: 3.2067 (Forecasting Loss:0.2130 + XiCon Loss:2.9937 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1161
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.2314708
	speed: 0.0116s/iter; left time: 97.9429s
Epoch: 34 cost time: 1.4478144645690918
Epoch: 34, Steps: 128 Train Loss: 3.1720 (Forecasting Loss:0.2130 + XiCon Loss:2.9590 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1161
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05440378934144974, mae:0.17782177031040192, mape:0.14146281778812408, mspe:0.03733791410923004 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2288
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.1804066
	speed: 0.0121s/iter; left time: 153.1151s
Epoch: 1 cost time: 1.5028324127197266
Epoch: 1, Steps: 128 Train Loss: 3.2364 (Forecasting Loss:0.2447 + XiCon Loss:2.9918 x Lambda(1.0)), Vali MSE Loss: 0.1733 Test MSE Loss: 0.1204
Validation loss decreased (inf --> 0.173306).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0838349
	speed: 0.0120s/iter; left time: 150.7823s
Epoch: 2 cost time: 1.501122236251831
Epoch: 2, Steps: 128 Train Loss: 3.0842 (Forecasting Loss:0.2453 + XiCon Loss:2.8390 x Lambda(1.0)), Vali MSE Loss: 0.1783 Test MSE Loss: 0.1273
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0498724
	speed: 0.0120s/iter; left time: 149.4252s
Epoch: 3 cost time: 1.5003998279571533
Epoch: 3, Steps: 128 Train Loss: 3.0490 (Forecasting Loss:0.2283 + XiCon Loss:2.8207 x Lambda(1.0)), Vali MSE Loss: 0.1688 Test MSE Loss: 0.1202
Validation loss decreased (0.173306 --> 0.168784).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.1698339
	speed: 0.0118s/iter; left time: 145.6915s
Epoch: 4 cost time: 1.483670711517334
Epoch: 4, Steps: 128 Train Loss: 3.1685 (Forecasting Loss:0.2212 + XiCon Loss:2.9473 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1170
Validation loss decreased (0.168784 --> 0.165500).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.2641344
	speed: 0.0118s/iter; left time: 143.4233s
Epoch: 5 cost time: 1.4726269245147705
Epoch: 5, Steps: 128 Train Loss: 3.1981 (Forecasting Loss:0.2165 + XiCon Loss:2.9815 x Lambda(1.0)), Vali MSE Loss: 0.1652 Test MSE Loss: 0.1165
Validation loss decreased (0.165500 --> 0.165223).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.1195469
	speed: 0.0124s/iter; left time: 149.4402s
Epoch: 6 cost time: 1.5477073192596436
Epoch: 6, Steps: 128 Train Loss: 3.1524 (Forecasting Loss:0.2148 + XiCon Loss:2.9375 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1176
Validation loss decreased (0.165223 --> 0.163470).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2843471
	speed: 0.0119s/iter; left time: 141.6454s
Epoch: 7 cost time: 1.487095594406128
Epoch: 7, Steps: 128 Train Loss: 3.1428 (Forecasting Loss:0.2139 + XiCon Loss:2.9290 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1173
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2631087
	speed: 0.0130s/iter; left time: 152.9519s
Epoch: 8 cost time: 1.6071200370788574
Epoch: 8, Steps: 128 Train Loss: 3.1336 (Forecasting Loss:0.2128 + XiCon Loss:2.9207 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1172
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.2052822
	speed: 0.0119s/iter; left time: 139.4134s
Epoch: 9 cost time: 1.4864234924316406
Epoch: 9, Steps: 128 Train Loss: 3.1471 (Forecasting Loss:0.2124 + XiCon Loss:2.9347 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1174
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2302225
	speed: 0.0118s/iter; left time: 136.1553s
Epoch: 10 cost time: 1.4877777099609375
Epoch: 10, Steps: 128 Train Loss: 3.1355 (Forecasting Loss:0.2120 + XiCon Loss:2.9235 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1178
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1162593
	speed: 0.0128s/iter; left time: 145.9778s
Epoch: 11 cost time: 1.5793838500976562
Epoch: 11, Steps: 128 Train Loss: 3.1401 (Forecasting Loss:0.2119 + XiCon Loss:2.9282 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1184
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.0671122
	speed: 0.0128s/iter; left time: 144.0019s
Epoch: 12 cost time: 1.6076977252960205
Epoch: 12, Steps: 128 Train Loss: 3.1494 (Forecasting Loss:0.2117 + XiCon Loss:2.9378 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1182
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.0623329
	speed: 0.0121s/iter; left time: 135.5785s
Epoch: 13 cost time: 1.5149962902069092
Epoch: 13, Steps: 128 Train Loss: 3.1336 (Forecasting Loss:0.2119 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1181
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.0718360
	speed: 0.0119s/iter; left time: 131.4470s
Epoch: 14 cost time: 1.4981048107147217
Epoch: 14, Steps: 128 Train Loss: 3.1317 (Forecasting Loss:0.2119 + XiCon Loss:2.9198 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1181
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.0760074
	speed: 0.0118s/iter; left time: 128.5199s
Epoch: 15 cost time: 1.4842865467071533
Epoch: 15, Steps: 128 Train Loss: 3.1583 (Forecasting Loss:0.2121 + XiCon Loss:2.9463 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1181
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.1755943
	speed: 0.0126s/iter; left time: 136.1468s
Epoch: 16 cost time: 1.6017017364501953
Epoch: 16, Steps: 128 Train Loss: 3.1397 (Forecasting Loss:0.2120 + XiCon Loss:2.9277 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1181
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05534800514578819, mae:0.17982050776481628, mape:0.14465032517910004, mspe:0.04086384177207947 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2351
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2109601
	speed: 0.0124s/iter; left time: 157.4834s
Epoch: 1 cost time: 1.5470457077026367
Epoch: 1, Steps: 128 Train Loss: 3.2568 (Forecasting Loss:0.2453 + XiCon Loss:3.0114 x Lambda(1.0)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.1224
Validation loss decreased (inf --> 0.172271).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.1160965
	speed: 0.0121s/iter; left time: 152.3881s
Epoch: 2 cost time: 1.546025276184082
Epoch: 2, Steps: 128 Train Loss: 3.1010 (Forecasting Loss:0.2440 + XiCon Loss:2.8570 x Lambda(1.0)), Vali MSE Loss: 0.1745 Test MSE Loss: 0.1264
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0509655
	speed: 0.0121s/iter; left time: 150.5536s
Epoch: 3 cost time: 1.508413314819336
Epoch: 3, Steps: 128 Train Loss: 3.0450 (Forecasting Loss:0.2310 + XiCon Loss:2.8141 x Lambda(1.0)), Vali MSE Loss: 0.1679 Test MSE Loss: 0.1188
Validation loss decreased (0.172271 --> 0.167917).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0406349
	speed: 0.0123s/iter; left time: 151.3848s
Epoch: 4 cost time: 1.5351452827453613
Epoch: 4, Steps: 128 Train Loss: 3.0129 (Forecasting Loss:0.2218 + XiCon Loss:2.7911 x Lambda(1.0)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1184
Validation loss decreased (0.167917 --> 0.166987).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0441499
	speed: 0.0129s/iter; left time: 156.7838s
Epoch: 5 cost time: 1.5923686027526855
Epoch: 5, Steps: 128 Train Loss: 3.0177 (Forecasting Loss:0.2177 + XiCon Loss:2.8001 x Lambda(1.0)), Vali MSE Loss: 0.1666 Test MSE Loss: 0.1230
Validation loss decreased (0.166987 --> 0.166582).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.3904414
	speed: 0.0122s/iter; left time: 146.9006s
Epoch: 6 cost time: 1.5274877548217773
Epoch: 6, Steps: 128 Train Loss: 3.1906 (Forecasting Loss:0.2159 + XiCon Loss:2.9747 x Lambda(1.0)), Vali MSE Loss: 0.1667 Test MSE Loss: 0.1167
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.3747027
	speed: 0.0127s/iter; left time: 151.4362s
Epoch: 7 cost time: 1.5736768245697021
Epoch: 7, Steps: 128 Train Loss: 3.2822 (Forecasting Loss:0.2145 + XiCon Loss:3.0677 x Lambda(1.0)), Vali MSE Loss: 0.1645 Test MSE Loss: 0.1166
Validation loss decreased (0.166582 --> 0.164487).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.1802197
	speed: 0.0119s/iter; left time: 141.0395s
Epoch: 8 cost time: 1.5255582332611084
Epoch: 8, Steps: 128 Train Loss: 3.3095 (Forecasting Loss:0.2142 + XiCon Loss:3.0953 x Lambda(1.0)), Vali MSE Loss: 0.1643 Test MSE Loss: 0.1169
Validation loss decreased (0.164487 --> 0.164312).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.3293455
	speed: 0.0127s/iter; left time: 148.0948s
Epoch: 9 cost time: 1.5698583126068115
Epoch: 9, Steps: 128 Train Loss: 3.3081 (Forecasting Loss:0.2137 + XiCon Loss:3.0944 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1165
Validation loss decreased (0.164312 --> 0.163988).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.2090461
	speed: 0.0119s/iter; left time: 137.7577s
Epoch: 10 cost time: 1.5033347606658936
Epoch: 10, Steps: 128 Train Loss: 3.2962 (Forecasting Loss:0.2136 + XiCon Loss:3.0826 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.1693461
	speed: 0.0118s/iter; left time: 135.0954s
Epoch: 11 cost time: 1.4827311038970947
Epoch: 11, Steps: 128 Train Loss: 3.3025 (Forecasting Loss:0.2134 + XiCon Loss:3.0890 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1169
Validation loss decreased (0.163988 --> 0.163695).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.3231757
	speed: 0.0119s/iter; left time: 134.6378s
Epoch: 12 cost time: 1.4935858249664307
Epoch: 12, Steps: 128 Train Loss: 3.2967 (Forecasting Loss:0.2134 + XiCon Loss:3.0834 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1168
Validation loss decreased (0.163695 --> 0.163686).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.3122036
	speed: 0.0119s/iter; left time: 133.2805s
Epoch: 13 cost time: 1.511408805847168
Epoch: 13, Steps: 128 Train Loss: 3.3144 (Forecasting Loss:0.2133 + XiCon Loss:3.1011 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.1992612
	speed: 0.0119s/iter; left time: 131.3769s
Epoch: 14 cost time: 1.4905052185058594
Epoch: 14, Steps: 128 Train Loss: 3.2830 (Forecasting Loss:0.2131 + XiCon Loss:3.0698 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.4911602
	speed: 0.0124s/iter; left time: 135.5888s
Epoch: 15 cost time: 1.5427258014678955
Epoch: 15, Steps: 128 Train Loss: 3.3128 (Forecasting Loss:0.2133 + XiCon Loss:3.0995 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2736714
	speed: 0.0118s/iter; left time: 127.6141s
Epoch: 16 cost time: 1.4839105606079102
Epoch: 16, Steps: 128 Train Loss: 3.3133 (Forecasting Loss:0.2134 + XiCon Loss:3.0999 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1168
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.4618797
	speed: 0.0120s/iter; left time: 127.3406s
Epoch: 17 cost time: 1.4888794422149658
Epoch: 17, Steps: 128 Train Loss: 3.2906 (Forecasting Loss:0.2133 + XiCon Loss:3.0772 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.3087597
	speed: 0.0125s/iter; left time: 131.3867s
Epoch: 18 cost time: 1.5721542835235596
Epoch: 18, Steps: 128 Train Loss: 3.3180 (Forecasting Loss:0.2134 + XiCon Loss:3.1046 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1168
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.1930101
	speed: 0.0121s/iter; left time: 125.3846s
Epoch: 19 cost time: 1.504807949066162
Epoch: 19, Steps: 128 Train Loss: 3.2945 (Forecasting Loss:0.2132 + XiCon Loss:3.0813 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1168
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.5322721
	speed: 0.0122s/iter; left time: 124.8670s
Epoch: 20 cost time: 1.5155367851257324
Epoch: 20, Steps: 128 Train Loss: 3.3095 (Forecasting Loss:0.2133 + XiCon Loss:3.0961 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1168
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.3118129
	speed: 0.0121s/iter; left time: 122.6510s
Epoch: 21 cost time: 1.5112719535827637
Epoch: 21, Steps: 128 Train Loss: 3.3253 (Forecasting Loss:0.2134 + XiCon Loss:3.1119 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.2487438
	speed: 0.0119s/iter; left time: 118.9286s
Epoch: 22 cost time: 1.491105318069458
Epoch: 22, Steps: 128 Train Loss: 3.3000 (Forecasting Loss:0.2135 + XiCon Loss:3.0866 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1168
Validation loss decreased (0.163686 --> 0.163644).  Saving model ...
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2826848
	speed: 0.0125s/iter; left time: 123.3461s
Epoch: 23 cost time: 1.580585241317749
Epoch: 23, Steps: 128 Train Loss: 3.3053 (Forecasting Loss:0.2134 + XiCon Loss:3.0919 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.2010009
	speed: 0.0118s/iter; left time: 115.2572s
Epoch: 24 cost time: 1.4803428649902344
Epoch: 24, Steps: 128 Train Loss: 3.3219 (Forecasting Loss:0.2132 + XiCon Loss:3.1087 x Lambda(1.0)), Vali MSE Loss: 0.1641 Test MSE Loss: 0.1168
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.3052197
	speed: 0.0120s/iter; left time: 115.7954s
Epoch: 25 cost time: 1.5090816020965576
Epoch: 25, Steps: 128 Train Loss: 3.3095 (Forecasting Loss:0.2134 + XiCon Loss:3.0961 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2645149
	speed: 0.0118s/iter; left time: 112.4989s
Epoch: 26 cost time: 1.479705810546875
Epoch: 26, Steps: 128 Train Loss: 3.3008 (Forecasting Loss:0.2133 + XiCon Loss:3.0875 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.2769532
	speed: 0.0119s/iter; left time: 111.9948s
Epoch: 27 cost time: 1.5010745525360107
Epoch: 27, Steps: 128 Train Loss: 3.3076 (Forecasting Loss:0.2135 + XiCon Loss:3.0941 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1168
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.2071857
	speed: 0.0119s/iter; left time: 110.4089s
Epoch: 28 cost time: 1.494502067565918
Epoch: 28, Steps: 128 Train Loss: 3.3048 (Forecasting Loss:0.2134 + XiCon Loss:3.0914 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1168
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.4623005
	speed: 0.0119s/iter; left time: 108.4065s
Epoch: 29 cost time: 1.4867701530456543
Epoch: 29, Steps: 128 Train Loss: 3.3015 (Forecasting Loss:0.2135 + XiCon Loss:3.0880 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.3555026
	speed: 0.0121s/iter; left time: 109.1543s
Epoch: 30 cost time: 1.5449917316436768
Epoch: 30, Steps: 128 Train Loss: 3.3083 (Forecasting Loss:0.2133 + XiCon Loss:3.0950 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1168
Validation loss decreased (0.163644 --> 0.163450).  Saving model ...
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.4302690
	speed: 0.0121s/iter; left time: 107.6025s
Epoch: 31 cost time: 1.5111818313598633
Epoch: 31, Steps: 128 Train Loss: 3.2990 (Forecasting Loss:0.2133 + XiCon Loss:3.0858 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.2604909
	speed: 0.0119s/iter; left time: 103.7494s
Epoch: 32 cost time: 1.486654281616211
Epoch: 32, Steps: 128 Train Loss: 3.3031 (Forecasting Loss:0.2135 + XiCon Loss:3.0897 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.2574923
	speed: 0.0119s/iter; left time: 102.7824s
Epoch: 33 cost time: 1.504075288772583
Epoch: 33, Steps: 128 Train Loss: 3.3142 (Forecasting Loss:0.2133 + XiCon Loss:3.1009 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.4082348
	speed: 0.0125s/iter; left time: 105.9056s
Epoch: 34 cost time: 1.5484838485717773
Epoch: 34, Steps: 128 Train Loss: 3.3030 (Forecasting Loss:0.2134 + XiCon Loss:3.0896 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1168
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 35 | loss: 3.3233533
	speed: 0.0119s/iter; left time: 99.1741s
Epoch: 35 cost time: 1.4848933219909668
Epoch: 35, Steps: 128 Train Loss: 3.3168 (Forecasting Loss:0.2131 + XiCon Loss:3.1037 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1168
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 36 | loss: 3.2798531
	speed: 0.0120s/iter; left time: 98.7274s
Epoch: 36 cost time: 1.5077245235443115
Epoch: 36, Steps: 128 Train Loss: 3.2983 (Forecasting Loss:0.2134 + XiCon Loss:3.0848 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1168
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 37 | loss: 3.3310976
	speed: 0.0124s/iter; left time: 100.3334s
Epoch: 37 cost time: 1.5346348285675049
Epoch: 37, Steps: 128 Train Loss: 3.3135 (Forecasting Loss:0.2133 + XiCon Loss:3.1002 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 38 | loss: 3.3882666
	speed: 0.0122s/iter; left time: 96.8113s
Epoch: 38 cost time: 1.5285329818725586
Epoch: 38, Steps: 128 Train Loss: 3.3019 (Forecasting Loss:0.2134 + XiCon Loss:3.0884 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 39 | loss: 3.2951336
	speed: 0.0124s/iter; left time: 96.8545s
Epoch: 39 cost time: 1.577265739440918
Epoch: 39, Steps: 128 Train Loss: 3.3153 (Forecasting Loss:0.2132 + XiCon Loss:3.1021 x Lambda(1.0)), Vali MSE Loss: 0.1640 Test MSE Loss: 0.1168
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 40 | loss: 3.4573891
	speed: 0.0125s/iter; left time: 96.6827s
Epoch: 40 cost time: 1.5826640129089355
Epoch: 40, Steps: 128 Train Loss: 3.2905 (Forecasting Loss:0.2133 + XiCon Loss:3.0773 x Lambda(1.0)), Vali MSE Loss: 0.1639 Test MSE Loss: 0.1168
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05488244816660881, mae:0.17864283919334412, mape:0.14176276326179504, mspe:0.037344809621572495 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:70081
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2425
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2666295
	speed: 0.0127s/iter; left time: 161.9298s
Epoch: 1 cost time: 1.5921308994293213
Epoch: 1, Steps: 128 Train Loss: 3.2703 (Forecasting Loss:0.2452 + XiCon Loss:3.0251 x Lambda(1.0)), Vali MSE Loss: 0.1755 Test MSE Loss: 0.1240
Validation loss decreased (inf --> 0.175515).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 3.0990944
	speed: 0.0119s/iter; left time: 149.6114s
Epoch: 2 cost time: 1.4930245876312256
Epoch: 2, Steps: 128 Train Loss: 3.1192 (Forecasting Loss:0.2507 + XiCon Loss:2.8686 x Lambda(1.0)), Vali MSE Loss: 0.1766 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 3.0352256
	speed: 0.0127s/iter; left time: 157.5783s
Epoch: 3 cost time: 1.60202956199646
Epoch: 3, Steps: 128 Train Loss: 3.0498 (Forecasting Loss:0.2293 + XiCon Loss:2.8205 x Lambda(1.0)), Vali MSE Loss: 0.1680 Test MSE Loss: 0.1206
Validation loss decreased (0.175515 --> 0.167999).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 3.0559518
	speed: 0.0120s/iter; left time: 147.9988s
Epoch: 4 cost time: 1.5036613941192627
Epoch: 4, Steps: 128 Train Loss: 3.0326 (Forecasting Loss:0.2213 + XiCon Loss:2.8113 x Lambda(1.0)), Vali MSE Loss: 0.1678 Test MSE Loss: 0.1179
Validation loss decreased (0.167999 --> 0.167785).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 3.0868630
	speed: 0.0120s/iter; left time: 146.5482s
Epoch: 5 cost time: 1.507101058959961
Epoch: 5, Steps: 128 Train Loss: 3.0462 (Forecasting Loss:0.2178 + XiCon Loss:2.8284 x Lambda(1.0)), Vali MSE Loss: 0.1655 Test MSE Loss: 0.1190
Validation loss decreased (0.167785 --> 0.165511).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 3.2019112
	speed: 0.0120s/iter; left time: 144.9284s
Epoch: 6 cost time: 1.515892505645752
Epoch: 6, Steps: 128 Train Loss: 3.1589 (Forecasting Loss:0.2153 + XiCon Loss:2.9436 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1159
Validation loss decreased (0.165511 --> 0.163414).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 3.2836773
	speed: 0.0131s/iter; left time: 155.9178s
Epoch: 7 cost time: 1.6309077739715576
Epoch: 7, Steps: 128 Train Loss: 3.2545 (Forecasting Loss:0.2143 + XiCon Loss:3.0402 x Lambda(1.0)), Vali MSE Loss: 0.1642 Test MSE Loss: 0.1166
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 3.2836006
	speed: 0.0124s/iter; left time: 146.1046s
Epoch: 8 cost time: 1.5729238986968994
Epoch: 8, Steps: 128 Train Loss: 3.2998 (Forecasting Loss:0.2134 + XiCon Loss:3.0864 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1160
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 3.4546561
	speed: 0.0126s/iter; left time: 146.7066s
Epoch: 9 cost time: 1.5886528491973877
Epoch: 9, Steps: 128 Train Loss: 3.3015 (Forecasting Loss:0.2132 + XiCon Loss:3.0883 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1158
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 3.3712645
	speed: 0.0125s/iter; left time: 144.1040s
Epoch: 10 cost time: 1.5838017463684082
Epoch: 10, Steps: 128 Train Loss: 3.2870 (Forecasting Loss:0.2131 + XiCon Loss:3.0739 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1158
Validation loss decreased (0.163414 --> 0.163361).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 3.2628198
	speed: 0.0122s/iter; left time: 139.2946s
Epoch: 11 cost time: 1.5295464992523193
Epoch: 11, Steps: 128 Train Loss: 3.2761 (Forecasting Loss:0.2131 + XiCon Loss:3.0630 x Lambda(1.0)), Vali MSE Loss: 0.1637 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 3.3047261
	speed: 0.0120s/iter; left time: 135.9468s
Epoch: 12 cost time: 1.5059621334075928
Epoch: 12, Steps: 128 Train Loss: 3.3085 (Forecasting Loss:0.2127 + XiCon Loss:3.0959 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 3.4297786
	speed: 0.0122s/iter; left time: 135.7632s
Epoch: 13 cost time: 1.5153050422668457
Epoch: 13, Steps: 128 Train Loss: 3.3000 (Forecasting Loss:0.2127 + XiCon Loss:3.0873 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 3.3966777
	speed: 0.0123s/iter; left time: 135.6143s
Epoch: 14 cost time: 1.5344409942626953
Epoch: 14, Steps: 128 Train Loss: 3.2990 (Forecasting Loss:0.2128 + XiCon Loss:3.0861 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1157
Validation loss decreased (0.163361 --> 0.163226).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 3.3214626
	speed: 0.0130s/iter; left time: 141.4072s
Epoch: 15 cost time: 1.629162073135376
Epoch: 15, Steps: 128 Train Loss: 3.3170 (Forecasting Loss:0.2126 + XiCon Loss:3.1044 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 3.2569809
	speed: 0.0119s/iter; left time: 127.8179s
Epoch: 16 cost time: 1.481433629989624
Epoch: 16, Steps: 128 Train Loss: 3.3224 (Forecasting Loss:0.2127 + XiCon Loss:3.1096 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1157
Validation loss decreased (0.163226 --> 0.163133).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 3.3246512
	speed: 0.0119s/iter; left time: 126.8844s
Epoch: 17 cost time: 1.4913268089294434
Epoch: 17, Steps: 128 Train Loss: 3.3045 (Forecasting Loss:0.2127 + XiCon Loss:3.0918 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 3.3597231
	speed: 0.0124s/iter; left time: 130.9657s
Epoch: 18 cost time: 1.5482122898101807
Epoch: 18, Steps: 128 Train Loss: 3.3064 (Forecasting Loss:0.2129 + XiCon Loss:3.0935 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 3.2092803
	speed: 0.0118s/iter; left time: 122.9416s
Epoch: 19 cost time: 1.4816009998321533
Epoch: 19, Steps: 128 Train Loss: 3.3048 (Forecasting Loss:0.2125 + XiCon Loss:3.0923 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 3.2718518
	speed: 0.0117s/iter; left time: 120.4554s
Epoch: 20 cost time: 1.4764695167541504
Epoch: 20, Steps: 128 Train Loss: 3.3083 (Forecasting Loss:0.2126 + XiCon Loss:3.0957 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 3.3434598
	speed: 0.0127s/iter; left time: 129.0739s
Epoch: 21 cost time: 1.6000871658325195
Epoch: 21, Steps: 128 Train Loss: 3.2959 (Forecasting Loss:0.2126 + XiCon Loss:3.0833 x Lambda(1.0)), Vali MSE Loss: 0.1632 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 22 | loss: 3.3064370
	speed: 0.0119s/iter; left time: 118.7643s
Epoch: 22 cost time: 1.4893195629119873
Epoch: 22, Steps: 128 Train Loss: 3.2948 (Forecasting Loss:0.2129 + XiCon Loss:3.0819 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 23 | loss: 3.2620239
	speed: 0.0120s/iter; left time: 118.6075s
Epoch: 23 cost time: 1.4985439777374268
Epoch: 23, Steps: 128 Train Loss: 3.3078 (Forecasting Loss:0.2126 + XiCon Loss:3.0952 x Lambda(1.0)), Vali MSE Loss: 0.1633 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 24 | loss: 3.2118354
	speed: 0.0123s/iter; left time: 119.6573s
Epoch: 24 cost time: 1.56661057472229
Epoch: 24, Steps: 128 Train Loss: 3.3111 (Forecasting Loss:0.2126 + XiCon Loss:3.0984 x Lambda(1.0)), Vali MSE Loss: 0.1630 Test MSE Loss: 0.1157
Validation loss decreased (0.163133 --> 0.163011).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 25 | loss: 3.3928804
	speed: 0.0121s/iter; left time: 116.5712s
Epoch: 25 cost time: 1.5106148719787598
Epoch: 25, Steps: 128 Train Loss: 3.2995 (Forecasting Loss:0.2127 + XiCon Loss:3.0868 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1157
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 26 | loss: 3.2335255
	speed: 0.0119s/iter; left time: 112.6356s
Epoch: 26 cost time: 1.4864501953125
Epoch: 26, Steps: 128 Train Loss: 3.2936 (Forecasting Loss:0.2127 + XiCon Loss:3.0809 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 27 | loss: 3.3417802
	speed: 0.0123s/iter; left time: 115.0131s
Epoch: 27 cost time: 1.538769006729126
Epoch: 27, Steps: 128 Train Loss: 3.3301 (Forecasting Loss:0.2127 + XiCon Loss:3.1175 x Lambda(1.0)), Vali MSE Loss: 0.1631 Test MSE Loss: 0.1157
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 28 | loss: 3.4861970
	speed: 0.0120s/iter; left time: 110.7890s
Epoch: 28 cost time: 1.4978947639465332
Epoch: 28, Steps: 128 Train Loss: 3.3349 (Forecasting Loss:0.2125 + XiCon Loss:3.1223 x Lambda(1.0)), Vali MSE Loss: 0.1636 Test MSE Loss: 0.1157
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 29 | loss: 3.3197849
	speed: 0.0128s/iter; left time: 116.6590s
Epoch: 29 cost time: 1.6206417083740234
Epoch: 29, Steps: 128 Train Loss: 3.3060 (Forecasting Loss:0.2124 + XiCon Loss:3.0936 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 30 | loss: 3.1354403
	speed: 0.0120s/iter; left time: 107.7082s
Epoch: 30 cost time: 1.5020020008087158
Epoch: 30, Steps: 128 Train Loss: 3.3031 (Forecasting Loss:0.2126 + XiCon Loss:3.0905 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 31 | loss: 3.2009852
	speed: 0.0121s/iter; left time: 107.5957s
Epoch: 31 cost time: 1.5126631259918213
Epoch: 31, Steps: 128 Train Loss: 3.3255 (Forecasting Loss:0.2127 + XiCon Loss:3.1128 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 32 | loss: 3.2296724
	speed: 0.0117s/iter; left time: 102.4494s
Epoch: 32 cost time: 1.4691886901855469
Epoch: 32, Steps: 128 Train Loss: 3.3057 (Forecasting Loss:0.2127 + XiCon Loss:3.0930 x Lambda(1.0)), Vali MSE Loss: 0.1634 Test MSE Loss: 0.1157
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 33 | loss: 3.3113317
	speed: 0.0117s/iter; left time: 100.9571s
Epoch: 33 cost time: 1.4731202125549316
Epoch: 33, Steps: 128 Train Loss: 3.2874 (Forecasting Loss:0.2128 + XiCon Loss:3.0746 x Lambda(1.0)), Vali MSE Loss: 0.1638 Test MSE Loss: 0.1157
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 34 | loss: 3.1953530
	speed: 0.0119s/iter; left time: 100.6377s
Epoch: 34 cost time: 1.4940528869628906
Epoch: 34, Steps: 128 Train Loss: 3.3020 (Forecasting Loss:0.2126 + XiCon Loss:3.0894 x Lambda(1.0)), Vali MSE Loss: 0.1635 Test MSE Loss: 0.1157
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl96_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.05449799820780754, mae:0.17691896855831146, mape:0.14020633697509766, mspe:0.03712638095021248 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0546+-0.00064, MAE:0.1779+-0.00177, MAPE:0.1419+-0.00205, MSPE:0.0384+-0.00208, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=2, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2752
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.6196442
	speed: 0.0159s/iter; left time: 199.1601s
Epoch: 1 cost time: 1.9024672508239746
Epoch: 1, Steps: 126 Train Loss: 30.8154 (Forecasting Loss:0.2773 + XiCon Loss:3.0538 x Lambda(10.0)), Vali MSE Loss: 0.1977 Test MSE Loss: 0.1441
Validation loss decreased (inf --> 0.197738).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.4173641
	speed: 0.0145s/iter; left time: 178.8810s
Epoch: 2 cost time: 1.8221638202667236
Epoch: 2, Steps: 126 Train Loss: 28.7917 (Forecasting Loss:0.2614 + XiCon Loss:2.8530 x Lambda(10.0)), Vali MSE Loss: 0.1934 Test MSE Loss: 0.1421
Validation loss decreased (0.197738 --> 0.193405).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.3237267
	speed: 0.0152s/iter; left time: 186.6024s
Epoch: 3 cost time: 1.8923580646514893
Epoch: 3, Steps: 126 Train Loss: 29.0316 (Forecasting Loss:0.2529 + XiCon Loss:2.8779 x Lambda(10.0)), Vali MSE Loss: 0.1877 Test MSE Loss: 0.1410
Validation loss decreased (0.193405 --> 0.187666).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.5716476
	speed: 0.0147s/iter; left time: 178.6112s
Epoch: 4 cost time: 1.824127435684204
Epoch: 4, Steps: 126 Train Loss: 29.9871 (Forecasting Loss:0.2463 + XiCon Loss:2.9741 x Lambda(10.0)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1394
Validation loss decreased (0.187666 --> 0.185890).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.4797764
	speed: 0.0151s/iter; left time: 180.8615s
Epoch: 5 cost time: 1.854567050933838
Epoch: 5, Steps: 126 Train Loss: 29.6047 (Forecasting Loss:0.2430 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.1840 Test MSE Loss: 0.1356
Validation loss decreased (0.185890 --> 0.184014).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5306301
	speed: 0.0145s/iter; left time: 171.6944s
Epoch: 6 cost time: 1.805605173110962
Epoch: 6, Steps: 126 Train Loss: 29.7289 (Forecasting Loss:0.2412 + XiCon Loss:2.9488 x Lambda(10.0)), Vali MSE Loss: 0.1845 Test MSE Loss: 0.1366
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.4220619
	speed: 0.0146s/iter; left time: 170.9144s
Epoch: 7 cost time: 1.8011674880981445
Epoch: 7, Steps: 126 Train Loss: 29.5571 (Forecasting Loss:0.2396 + XiCon Loss:2.9318 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1372
Validation loss decreased (0.184014 --> 0.183719).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.4704590
	speed: 0.0147s/iter; left time: 171.1960s
Epoch: 8 cost time: 1.8319921493530273
Epoch: 8, Steps: 126 Train Loss: 29.3996 (Forecasting Loss:0.2391 + XiCon Loss:2.9161 x Lambda(10.0)), Vali MSE Loss: 0.1839 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.4169903
	speed: 0.0148s/iter; left time: 169.5930s
Epoch: 9 cost time: 1.8289580345153809
Epoch: 9, Steps: 126 Train Loss: 29.3913 (Forecasting Loss:0.2389 + XiCon Loss:2.9152 x Lambda(10.0)), Vali MSE Loss: 0.1838 Test MSE Loss: 0.1366
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.3875694
	speed: 0.0150s/iter; left time: 170.3537s
Epoch: 10 cost time: 1.8764643669128418
Epoch: 10, Steps: 126 Train Loss: 29.6582 (Forecasting Loss:0.2387 + XiCon Loss:2.9419 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1371
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5748405
	speed: 0.0150s/iter; left time: 168.6201s
Epoch: 11 cost time: 1.8519580364227295
Epoch: 11, Steps: 126 Train Loss: 29.4805 (Forecasting Loss:0.2386 + XiCon Loss:2.9242 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1371
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.5872345
	speed: 0.0147s/iter; left time: 163.2121s
Epoch: 12 cost time: 1.8281829357147217
Epoch: 12, Steps: 126 Train Loss: 29.4669 (Forecasting Loss:0.2385 + XiCon Loss:2.9228 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
Validation loss decreased (0.183719 --> 0.183713).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.7192154
	speed: 0.0148s/iter; left time: 162.3344s
Epoch: 13 cost time: 1.8475854396820068
Epoch: 13, Steps: 126 Train Loss: 29.4362 (Forecasting Loss:0.2383 + XiCon Loss:2.9198 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.4746780
	speed: 0.0146s/iter; left time: 158.8216s
Epoch: 14 cost time: 1.8194711208343506
Epoch: 14, Steps: 126 Train Loss: 29.4821 (Forecasting Loss:0.2386 + XiCon Loss:2.9243 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 27.8971844
	speed: 0.0148s/iter; left time: 158.6700s
Epoch: 15 cost time: 1.8379547595977783
Epoch: 15, Steps: 126 Train Loss: 29.5196 (Forecasting Loss:0.2386 + XiCon Loss:2.9281 x Lambda(10.0)), Vali MSE Loss: 0.1836 Test MSE Loss: 0.1370
Validation loss decreased (0.183713 --> 0.183643).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.2454185
	speed: 0.0148s/iter; left time: 157.0467s
Epoch: 16 cost time: 1.8360881805419922
Epoch: 16, Steps: 126 Train Loss: 29.4526 (Forecasting Loss:0.2382 + XiCon Loss:2.9214 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.4039211
	speed: 0.0150s/iter; left time: 156.9260s
Epoch: 17 cost time: 1.849912166595459
Epoch: 17, Steps: 126 Train Loss: 29.4479 (Forecasting Loss:0.2385 + XiCon Loss:2.9209 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.4272346
	speed: 0.0149s/iter; left time: 153.8618s
Epoch: 18 cost time: 1.8435521125793457
Epoch: 18, Steps: 126 Train Loss: 29.4434 (Forecasting Loss:0.2384 + XiCon Loss:2.9205 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.0112133
	speed: 0.0146s/iter; left time: 149.3178s
Epoch: 19 cost time: 1.815065860748291
Epoch: 19, Steps: 126 Train Loss: 29.5508 (Forecasting Loss:0.2386 + XiCon Loss:2.9312 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 31.0157070
	speed: 0.0147s/iter; left time: 148.7697s
Epoch: 20 cost time: 1.8285346031188965
Epoch: 20, Steps: 126 Train Loss: 29.5778 (Forecasting Loss:0.2384 + XiCon Loss:2.9339 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.8232956
	speed: 0.0149s/iter; left time: 149.0634s
Epoch: 21 cost time: 1.852128267288208
Epoch: 21, Steps: 126 Train Loss: 29.6130 (Forecasting Loss:0.2387 + XiCon Loss:2.9374 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.6175976
	speed: 0.0148s/iter; left time: 145.4827s
Epoch: 22 cost time: 1.833662509918213
Epoch: 22, Steps: 126 Train Loss: 29.3775 (Forecasting Loss:0.2383 + XiCon Loss:2.9139 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.2966480
	speed: 0.0148s/iter; left time: 143.7399s
Epoch: 23 cost time: 1.8388779163360596
Epoch: 23, Steps: 126 Train Loss: 29.5505 (Forecasting Loss:0.2385 + XiCon Loss:2.9312 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.9345684
	speed: 0.0149s/iter; left time: 142.6624s
Epoch: 24 cost time: 1.8460023403167725
Epoch: 24, Steps: 126 Train Loss: 29.5509 (Forecasting Loss:0.2383 + XiCon Loss:2.9313 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.2785339
	speed: 0.0148s/iter; left time: 139.9043s
Epoch: 25 cost time: 1.8334522247314453
Epoch: 25, Steps: 126 Train Loss: 29.4726 (Forecasting Loss:0.2384 + XiCon Loss:2.9234 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1370
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07018763571977615, mae:0.203831285238266, mape:0.15672677755355835, mspe:0.043370094150304794 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2463
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.5323505
	speed: 0.0139s/iter; left time: 173.6458s
Epoch: 1 cost time: 1.7053937911987305
Epoch: 1, Steps: 126 Train Loss: 30.5605 (Forecasting Loss:0.2765 + XiCon Loss:3.0284 x Lambda(10.0)), Vali MSE Loss: 0.1963 Test MSE Loss: 0.1455
Validation loss decreased (inf --> 0.196332).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.3775654
	speed: 0.0150s/iter; left time: 185.5395s
Epoch: 2 cost time: 1.8494627475738525
Epoch: 2, Steps: 126 Train Loss: 28.7763 (Forecasting Loss:0.2646 + XiCon Loss:2.8512 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1485
Validation loss decreased (0.196332 --> 0.193308).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.2552834
	speed: 0.0147s/iter; left time: 180.2209s
Epoch: 3 cost time: 1.8423113822937012
Epoch: 3, Steps: 126 Train Loss: 28.5671 (Forecasting Loss:0.2520 + XiCon Loss:2.8315 x Lambda(10.0)), Vali MSE Loss: 0.1922 Test MSE Loss: 0.1441
Validation loss decreased (0.193308 --> 0.192168).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.0986958
	speed: 0.0149s/iter; left time: 180.7168s
Epoch: 4 cost time: 1.8593626022338867
Epoch: 4, Steps: 126 Train Loss: 30.4074 (Forecasting Loss:0.2483 + XiCon Loss:3.0159 x Lambda(10.0)), Vali MSE Loss: 0.1893 Test MSE Loss: 0.1382
Validation loss decreased (0.192168 --> 0.189267).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.5346832
	speed: 0.0150s/iter; left time: 180.2891s
Epoch: 5 cost time: 1.8713903427124023
Epoch: 5, Steps: 126 Train Loss: 30.5679 (Forecasting Loss:0.2456 + XiCon Loss:3.0322 x Lambda(10.0)), Vali MSE Loss: 0.1874 Test MSE Loss: 0.1355
Validation loss decreased (0.189267 --> 0.187414).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6198082
	speed: 0.0157s/iter; left time: 186.4522s
Epoch: 6 cost time: 1.9650259017944336
Epoch: 6, Steps: 126 Train Loss: 30.2935 (Forecasting Loss:0.2442 + XiCon Loss:3.0049 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1380
Validation loss decreased (0.187414 --> 0.186274).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.1744995
	speed: 0.0150s/iter; left time: 176.1179s
Epoch: 7 cost time: 1.8604073524475098
Epoch: 7, Steps: 126 Train Loss: 29.9963 (Forecasting Loss:0.2434 + XiCon Loss:2.9753 x Lambda(10.0)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1378
Validation loss decreased (0.186274 --> 0.185883).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.4651852
	speed: 0.0153s/iter; left time: 178.0893s
Epoch: 8 cost time: 1.8964896202087402
Epoch: 8, Steps: 126 Train Loss: 30.1736 (Forecasting Loss:0.2429 + XiCon Loss:2.9931 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1368
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.4823341
	speed: 0.0152s/iter; left time: 174.3306s
Epoch: 9 cost time: 1.8894667625427246
Epoch: 9, Steps: 126 Train Loss: 30.1580 (Forecasting Loss:0.2428 + XiCon Loss:2.9915 x Lambda(10.0)), Vali MSE Loss: 0.1859 Test MSE Loss: 0.1373
Validation loss decreased (0.185883 --> 0.185860).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.2891159
	speed: 0.0150s/iter; left time: 170.8479s
Epoch: 10 cost time: 1.8674876689910889
Epoch: 10, Steps: 126 Train Loss: 30.0541 (Forecasting Loss:0.2429 + XiCon Loss:2.9811 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
Validation loss decreased (0.185860 --> 0.185812).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.2435665
	speed: 0.0157s/iter; left time: 176.1854s
Epoch: 11 cost time: 1.9406883716583252
Epoch: 11, Steps: 126 Train Loss: 30.0240 (Forecasting Loss:0.2427 + XiCon Loss:2.9781 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.4214935
	speed: 0.0151s/iter; left time: 167.3216s
Epoch: 12 cost time: 1.8727161884307861
Epoch: 12, Steps: 126 Train Loss: 30.0344 (Forecasting Loss:0.2427 + XiCon Loss:2.9792 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.5052376
	speed: 0.0150s/iter; left time: 164.8036s
Epoch: 13 cost time: 1.8708224296569824
Epoch: 13, Steps: 126 Train Loss: 29.9719 (Forecasting Loss:0.2426 + XiCon Loss:2.9729 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
Validation loss decreased (0.185812 --> 0.185793).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.5376244
	speed: 0.0150s/iter; left time: 163.2397s
Epoch: 14 cost time: 1.8706068992614746
Epoch: 14, Steps: 126 Train Loss: 29.8822 (Forecasting Loss:0.2426 + XiCon Loss:2.9640 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.4724522
	speed: 0.0154s/iter; left time: 165.0150s
Epoch: 15 cost time: 1.9140937328338623
Epoch: 15, Steps: 126 Train Loss: 30.0561 (Forecasting Loss:0.2427 + XiCon Loss:2.9813 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.6391735
	speed: 0.0152s/iter; left time: 161.5363s
Epoch: 16 cost time: 1.9061346054077148
Epoch: 16, Steps: 126 Train Loss: 30.0379 (Forecasting Loss:0.2426 + XiCon Loss:2.9795 x Lambda(10.0)), Vali MSE Loss: 0.1857 Test MSE Loss: 0.1374
Validation loss decreased (0.185793 --> 0.185724).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3925648
	speed: 0.0150s/iter; left time: 157.7389s
Epoch: 17 cost time: 1.8742048740386963
Epoch: 17, Steps: 126 Train Loss: 29.9741 (Forecasting Loss:0.2426 + XiCon Loss:2.9732 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.9669971
	speed: 0.0152s/iter; left time: 157.3181s
Epoch: 18 cost time: 1.8880724906921387
Epoch: 18, Steps: 126 Train Loss: 30.1332 (Forecasting Loss:0.2428 + XiCon Loss:2.9890 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.8836060
	speed: 0.0151s/iter; left time: 154.3200s
Epoch: 19 cost time: 1.8732085227966309
Epoch: 19, Steps: 126 Train Loss: 29.9740 (Forecasting Loss:0.2425 + XiCon Loss:2.9731 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.7603531
	speed: 0.0153s/iter; left time: 154.6818s
Epoch: 20 cost time: 1.907649040222168
Epoch: 20, Steps: 126 Train Loss: 30.1500 (Forecasting Loss:0.2424 + XiCon Loss:2.9908 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.8506241
	speed: 0.0157s/iter; left time: 156.9216s
Epoch: 21 cost time: 1.9477598667144775
Epoch: 21, Steps: 126 Train Loss: 30.2391 (Forecasting Loss:0.2426 + XiCon Loss:2.9996 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.8191586
	speed: 0.0156s/iter; left time: 153.6029s
Epoch: 22 cost time: 1.925264596939087
Epoch: 22, Steps: 126 Train Loss: 29.9589 (Forecasting Loss:0.2424 + XiCon Loss:2.9716 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 27.8963737
	speed: 0.0152s/iter; left time: 147.8535s
Epoch: 23 cost time: 1.8907153606414795
Epoch: 23, Steps: 126 Train Loss: 29.9435 (Forecasting Loss:0.2422 + XiCon Loss:2.9701 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.8858662
	speed: 0.0151s/iter; left time: 144.9495s
Epoch: 24 cost time: 1.8845953941345215
Epoch: 24, Steps: 126 Train Loss: 30.0179 (Forecasting Loss:0.2427 + XiCon Loss:2.9775 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.9720249
	speed: 0.0153s/iter; left time: 145.1927s
Epoch: 25 cost time: 1.897463321685791
Epoch: 25, Steps: 126 Train Loss: 30.1003 (Forecasting Loss:0.2426 + XiCon Loss:2.9858 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.3275490
	speed: 0.0148s/iter; left time: 137.9732s
Epoch: 26 cost time: 1.8419249057769775
Epoch: 26, Steps: 126 Train Loss: 29.9663 (Forecasting Loss:0.2425 + XiCon Loss:2.9724 x Lambda(10.0)), Vali MSE Loss: 0.1858 Test MSE Loss: 0.1374
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07038962841033936, mae:0.20443901419639587, mape:0.15637007355690002, mspe:0.04207047075033188 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2142
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.4398994
	speed: 0.0135s/iter; left time: 168.9966s
Epoch: 1 cost time: 1.668088674545288
Epoch: 1, Steps: 126 Train Loss: 30.6692 (Forecasting Loss:0.2764 + XiCon Loss:3.0393 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1451
Validation loss decreased (inf --> 0.195954).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.2386780
	speed: 0.0147s/iter; left time: 181.4299s
Epoch: 2 cost time: 1.8502864837646484
Epoch: 2, Steps: 126 Train Loss: 28.8169 (Forecasting Loss:0.2632 + XiCon Loss:2.8554 x Lambda(10.0)), Vali MSE Loss: 0.1929 Test MSE Loss: 0.1455
Validation loss decreased (0.195954 --> 0.192931).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.5747414
	speed: 0.0150s/iter; left time: 184.3098s
Epoch: 3 cost time: 1.8709831237792969
Epoch: 3, Steps: 126 Train Loss: 28.7957 (Forecasting Loss:0.2521 + XiCon Loss:2.8544 x Lambda(10.0)), Vali MSE Loss: 0.1900 Test MSE Loss: 0.1438
Validation loss decreased (0.192931 --> 0.189952).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.8809872
	speed: 0.0151s/iter; left time: 183.2660s
Epoch: 4 cost time: 1.8783586025238037
Epoch: 4, Steps: 126 Train Loss: 30.4433 (Forecasting Loss:0.2474 + XiCon Loss:3.0196 x Lambda(10.0)), Vali MSE Loss: 0.1874 Test MSE Loss: 0.1372
Validation loss decreased (0.189952 --> 0.187424).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.4108601
	speed: 0.0152s/iter; left time: 181.8587s
Epoch: 5 cost time: 1.8724956512451172
Epoch: 5, Steps: 126 Train Loss: 30.2088 (Forecasting Loss:0.2432 + XiCon Loss:2.9966 x Lambda(10.0)), Vali MSE Loss: 0.1851 Test MSE Loss: 0.1346
Validation loss decreased (0.187424 --> 0.185109).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.2166061
	speed: 0.0149s/iter; left time: 176.4680s
Epoch: 6 cost time: 1.858107328414917
Epoch: 6, Steps: 126 Train Loss: 29.9534 (Forecasting Loss:0.2415 + XiCon Loss:2.9712 x Lambda(10.0)), Vali MSE Loss: 0.1850 Test MSE Loss: 0.1363
Validation loss decreased (0.185109 --> 0.185040).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.0905647
	speed: 0.0150s/iter; left time: 175.9392s
Epoch: 7 cost time: 1.8500535488128662
Epoch: 7, Steps: 126 Train Loss: 30.0566 (Forecasting Loss:0.2405 + XiCon Loss:2.9816 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1350
Validation loss decreased (0.185040 --> 0.184409).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.9641190
	speed: 0.0149s/iter; left time: 172.8771s
Epoch: 8 cost time: 1.8430914878845215
Epoch: 8, Steps: 126 Train Loss: 29.8969 (Forecasting Loss:0.2396 + XiCon Loss:2.9657 x Lambda(10.0)), Vali MSE Loss: 0.1839 Test MSE Loss: 0.1354
Validation loss decreased (0.184409 --> 0.183889).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.0276394
	speed: 0.0148s/iter; left time: 170.2199s
Epoch: 9 cost time: 1.8354833126068115
Epoch: 9, Steps: 126 Train Loss: 29.8846 (Forecasting Loss:0.2394 + XiCon Loss:2.9645 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1353
Validation loss decreased (0.183889 --> 0.183723).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 27.5451374
	speed: 0.0151s/iter; left time: 171.3428s
Epoch: 10 cost time: 1.8603692054748535
Epoch: 10, Steps: 126 Train Loss: 29.9118 (Forecasting Loss:0.2393 + XiCon Loss:2.9672 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1352
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.5564938
	speed: 0.0150s/iter; left time: 168.4467s
Epoch: 11 cost time: 1.8546257019042969
Epoch: 11, Steps: 126 Train Loss: 29.8864 (Forecasting Loss:0.2393 + XiCon Loss:2.9647 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.7121048
	speed: 0.0151s/iter; left time: 167.4466s
Epoch: 12 cost time: 1.8684375286102295
Epoch: 12, Steps: 126 Train Loss: 29.8964 (Forecasting Loss:0.2389 + XiCon Loss:2.9658 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3783665
	speed: 0.0149s/iter; left time: 163.2587s
Epoch: 13 cost time: 1.8446786403656006
Epoch: 13, Steps: 126 Train Loss: 29.8092 (Forecasting Loss:0.2391 + XiCon Loss:2.9570 x Lambda(10.0)), Vali MSE Loss: 0.1838 Test MSE Loss: 0.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1401348
	speed: 0.0159s/iter; left time: 172.8925s
Epoch: 14 cost time: 1.9604291915893555
Epoch: 14, Steps: 126 Train Loss: 29.8713 (Forecasting Loss:0.2392 + XiCon Loss:2.9632 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.3789482
	speed: 0.0149s/iter; left time: 160.4679s
Epoch: 15 cost time: 1.855149745941162
Epoch: 15, Steps: 126 Train Loss: 29.8226 (Forecasting Loss:0.2392 + XiCon Loss:2.9583 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.3402157
	speed: 0.0148s/iter; left time: 157.3831s
Epoch: 16 cost time: 1.84139084815979
Epoch: 16, Steps: 126 Train Loss: 29.7540 (Forecasting Loss:0.2392 + XiCon Loss:2.9515 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
Validation loss decreased (0.183723 --> 0.183701).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5596161
	speed: 0.0148s/iter; left time: 155.4928s
Epoch: 17 cost time: 1.8692102432250977
Epoch: 17, Steps: 126 Train Loss: 29.8801 (Forecasting Loss:0.2391 + XiCon Loss:2.9641 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
Validation loss decreased (0.183701 --> 0.183675).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.7745895
	speed: 0.0150s/iter; left time: 155.3080s
Epoch: 18 cost time: 1.8585288524627686
Epoch: 18, Steps: 126 Train Loss: 29.9709 (Forecasting Loss:0.2389 + XiCon Loss:2.9732 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.9394703
	speed: 0.0151s/iter; left time: 154.6777s
Epoch: 19 cost time: 1.8687317371368408
Epoch: 19, Steps: 126 Train Loss: 29.8075 (Forecasting Loss:0.2391 + XiCon Loss:2.9568 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.0302010
	speed: 0.0147s/iter; left time: 149.0019s
Epoch: 20 cost time: 1.8338792324066162
Epoch: 20, Steps: 126 Train Loss: 29.9058 (Forecasting Loss:0.2393 + XiCon Loss:2.9667 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.1015034
	speed: 0.0148s/iter; left time: 147.6220s
Epoch: 21 cost time: 1.836024284362793
Epoch: 21, Steps: 126 Train Loss: 29.9870 (Forecasting Loss:0.2390 + XiCon Loss:2.9748 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.6867428
	speed: 0.0148s/iter; left time: 145.7610s
Epoch: 22 cost time: 1.832951545715332
Epoch: 22, Steps: 126 Train Loss: 29.8154 (Forecasting Loss:0.2390 + XiCon Loss:2.9576 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.6288338
	speed: 0.0151s/iter; left time: 146.9614s
Epoch: 23 cost time: 1.8615434169769287
Epoch: 23, Steps: 126 Train Loss: 29.6993 (Forecasting Loss:0.2390 + XiCon Loss:2.9460 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.0895081
	speed: 0.0149s/iter; left time: 142.8640s
Epoch: 24 cost time: 1.846250295639038
Epoch: 24, Steps: 126 Train Loss: 29.8858 (Forecasting Loss:0.2390 + XiCon Loss:2.9647 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 31.9740982
	speed: 0.0150s/iter; left time: 142.1015s
Epoch: 25 cost time: 1.8597440719604492
Epoch: 25, Steps: 126 Train Loss: 29.7953 (Forecasting Loss:0.2389 + XiCon Loss:2.9556 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.3326054
	speed: 0.0151s/iter; left time: 141.6146s
Epoch: 26 cost time: 1.9039664268493652
Epoch: 26, Steps: 126 Train Loss: 29.8145 (Forecasting Loss:0.2391 + XiCon Loss:2.9575 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.5046577
	speed: 0.0148s/iter; left time: 136.7536s
Epoch: 27 cost time: 1.8440442085266113
Epoch: 27, Steps: 126 Train Loss: 29.7148 (Forecasting Loss:0.2390 + XiCon Loss:2.9476 x Lambda(10.0)), Vali MSE Loss: 0.1837 Test MSE Loss: 0.1351
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06802228838205338, mae:0.2021801769733429, mape:0.15579357743263245, mspe:0.04228507727384567 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2346
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.4728680
	speed: 0.0134s/iter; left time: 166.9661s
Epoch: 1 cost time: 1.6522164344787598
Epoch: 1, Steps: 126 Train Loss: 30.7958 (Forecasting Loss:0.2773 + XiCon Loss:3.0519 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1443
Validation loss decreased (inf --> 0.196037).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.6169147
	speed: 0.0149s/iter; left time: 184.0090s
Epoch: 2 cost time: 1.8598084449768066
Epoch: 2, Steps: 126 Train Loss: 28.9525 (Forecasting Loss:0.2642 + XiCon Loss:2.8688 x Lambda(10.0)), Vali MSE Loss: 0.1946 Test MSE Loss: 0.1414
Validation loss decreased (0.196037 --> 0.194565).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.1314411
	speed: 0.0157s/iter; left time: 191.7344s
Epoch: 3 cost time: 1.9431395530700684
Epoch: 3, Steps: 126 Train Loss: 28.5079 (Forecasting Loss:0.2528 + XiCon Loss:2.8255 x Lambda(10.0)), Vali MSE Loss: 0.1909 Test MSE Loss: 0.1390
Validation loss decreased (0.194565 --> 0.190854).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.8503380
	speed: 0.0155s/iter; left time: 187.8991s
Epoch: 4 cost time: 1.9189860820770264
Epoch: 4, Steps: 126 Train Loss: 30.0842 (Forecasting Loss:0.2477 + XiCon Loss:2.9837 x Lambda(10.0)), Vali MSE Loss: 0.1870 Test MSE Loss: 0.1377
Validation loss decreased (0.190854 --> 0.187016).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.3737164
	speed: 0.0160s/iter; left time: 191.3585s
Epoch: 5 cost time: 1.9703269004821777
Epoch: 5, Steps: 126 Train Loss: 30.3285 (Forecasting Loss:0.2454 + XiCon Loss:3.0083 x Lambda(10.0)), Vali MSE Loss: 0.1877 Test MSE Loss: 0.1369
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.6297531
	speed: 0.0150s/iter; left time: 177.9537s
Epoch: 6 cost time: 1.8669304847717285
Epoch: 6, Steps: 126 Train Loss: 30.0679 (Forecasting Loss:0.2444 + XiCon Loss:2.9824 x Lambda(10.0)), Vali MSE Loss: 0.1869 Test MSE Loss: 0.1385
Validation loss decreased (0.187016 --> 0.186908).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.7675571
	speed: 0.0149s/iter; left time: 174.7730s
Epoch: 7 cost time: 1.8525030612945557
Epoch: 7, Steps: 126 Train Loss: 30.0704 (Forecasting Loss:0.2437 + XiCon Loss:2.9827 x Lambda(10.0)), Vali MSE Loss: 0.1865 Test MSE Loss: 0.1379
Validation loss decreased (0.186908 --> 0.186502).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.8823299
	speed: 0.0150s/iter; left time: 174.7704s
Epoch: 8 cost time: 1.8779075145721436
Epoch: 8, Steps: 126 Train Loss: 29.9940 (Forecasting Loss:0.2431 + XiCon Loss:2.9751 x Lambda(10.0)), Vali MSE Loss: 0.1863 Test MSE Loss: 0.1381
Validation loss decreased (0.186502 --> 0.186281).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8074379
	speed: 0.0149s/iter; left time: 171.7700s
Epoch: 9 cost time: 1.8893752098083496
Epoch: 9, Steps: 126 Train Loss: 30.1232 (Forecasting Loss:0.2426 + XiCon Loss:2.9881 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
Validation loss decreased (0.186281 --> 0.186083).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.5324173
	speed: 0.0149s/iter; left time: 169.0433s
Epoch: 10 cost time: 1.850386142730713
Epoch: 10, Steps: 126 Train Loss: 30.0109 (Forecasting Loss:0.2428 + XiCon Loss:2.9768 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1379
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.7521172
	speed: 0.0151s/iter; left time: 170.0610s
Epoch: 11 cost time: 1.8766019344329834
Epoch: 11, Steps: 126 Train Loss: 29.9959 (Forecasting Loss:0.2428 + XiCon Loss:2.9753 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1381
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.9532280
	speed: 0.0149s/iter; left time: 166.1312s
Epoch: 12 cost time: 1.8558928966522217
Epoch: 12, Steps: 126 Train Loss: 29.9181 (Forecasting Loss:0.2427 + XiCon Loss:2.9675 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
Validation loss decreased (0.186083 --> 0.186064).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.6479664
	speed: 0.0152s/iter; left time: 167.3320s
Epoch: 13 cost time: 1.8836886882781982
Epoch: 13, Steps: 126 Train Loss: 29.8020 (Forecasting Loss:0.2424 + XiCon Loss:2.9560 x Lambda(10.0)), Vali MSE Loss: 0.1862 Test MSE Loss: 0.1380
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4693584
	speed: 0.0152s/iter; left time: 165.5700s
Epoch: 14 cost time: 1.8812792301177979
Epoch: 14, Steps: 126 Train Loss: 30.0627 (Forecasting Loss:0.2427 + XiCon Loss:2.9820 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.2721405
	speed: 0.0150s/iter; left time: 161.5653s
Epoch: 15 cost time: 1.8587825298309326
Epoch: 15, Steps: 126 Train Loss: 30.0996 (Forecasting Loss:0.2426 + XiCon Loss:2.9857 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.0317841
	speed: 0.0151s/iter; left time: 160.3751s
Epoch: 16 cost time: 1.8663382530212402
Epoch: 16, Steps: 126 Train Loss: 30.0784 (Forecasting Loss:0.2428 + XiCon Loss:2.9836 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.1156216
	speed: 0.0150s/iter; left time: 156.9588s
Epoch: 17 cost time: 1.855161428451538
Epoch: 17, Steps: 126 Train Loss: 30.1038 (Forecasting Loss:0.2426 + XiCon Loss:2.9861 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.0607109
	speed: 0.0149s/iter; left time: 154.5647s
Epoch: 18 cost time: 1.8492584228515625
Epoch: 18, Steps: 126 Train Loss: 30.0000 (Forecasting Loss:0.2427 + XiCon Loss:2.9757 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.4606209
	speed: 0.0151s/iter; left time: 154.2077s
Epoch: 19 cost time: 1.8712146282196045
Epoch: 19, Steps: 126 Train Loss: 29.9630 (Forecasting Loss:0.2425 + XiCon Loss:2.9720 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.5389366
	speed: 0.0152s/iter; left time: 153.3556s
Epoch: 20 cost time: 1.8753530979156494
Epoch: 20, Steps: 126 Train Loss: 29.9044 (Forecasting Loss:0.2428 + XiCon Loss:2.9662 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.7243519
	speed: 0.0151s/iter; left time: 150.5100s
Epoch: 21 cost time: 1.8692893981933594
Epoch: 21, Steps: 126 Train Loss: 30.0140 (Forecasting Loss:0.2425 + XiCon Loss:2.9772 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 32.1061478
	speed: 0.0151s/iter; left time: 148.7384s
Epoch: 22 cost time: 1.8651740550994873
Epoch: 22, Steps: 126 Train Loss: 29.9179 (Forecasting Loss:0.2426 + XiCon Loss:2.9675 x Lambda(10.0)), Vali MSE Loss: 0.1861 Test MSE Loss: 0.1380
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.07093625515699387, mae:0.20512501895427704, mape:0.15669769048690796, mspe:0.04209136962890625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:134785
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2283
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 30.3950996
	speed: 0.0136s/iter; left time: 170.3481s
Epoch: 1 cost time: 1.6804101467132568
Epoch: 1, Steps: 126 Train Loss: 30.5075 (Forecasting Loss:0.2780 + XiCon Loss:3.0230 x Lambda(10.0)), Vali MSE Loss: 0.1992 Test MSE Loss: 0.1450
Validation loss decreased (inf --> 0.199191).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.7473202
	speed: 0.0148s/iter; left time: 182.9250s
Epoch: 2 cost time: 1.8259243965148926
Epoch: 2, Steps: 126 Train Loss: 29.0764 (Forecasting Loss:0.2643 + XiCon Loss:2.8812 x Lambda(10.0)), Vali MSE Loss: 0.1937 Test MSE Loss: 0.1414
Validation loss decreased (0.199191 --> 0.193745).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 28.8099651
	speed: 0.0147s/iter; left time: 180.1716s
Epoch: 3 cost time: 1.822692632675171
Epoch: 3, Steps: 126 Train Loss: 28.8489 (Forecasting Loss:0.2528 + XiCon Loss:2.8596 x Lambda(10.0)), Vali MSE Loss: 0.1898 Test MSE Loss: 0.1398
Validation loss decreased (0.193745 --> 0.189769).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7466030
	speed: 0.0148s/iter; left time: 179.0121s
Epoch: 4 cost time: 1.837373971939087
Epoch: 4, Steps: 126 Train Loss: 29.6205 (Forecasting Loss:0.2471 + XiCon Loss:2.9373 x Lambda(10.0)), Vali MSE Loss: 0.1864 Test MSE Loss: 0.1380
Validation loss decreased (0.189769 --> 0.186377).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 32.1163445
	speed: 0.0152s/iter; left time: 182.3150s
Epoch: 5 cost time: 1.8788015842437744
Epoch: 5, Steps: 126 Train Loss: 30.0969 (Forecasting Loss:0.2441 + XiCon Loss:2.9853 x Lambda(10.0)), Vali MSE Loss: 0.1844 Test MSE Loss: 0.1385
Validation loss decreased (0.186377 --> 0.184405).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.4339027
	speed: 0.0151s/iter; left time: 179.7058s
Epoch: 6 cost time: 1.8718349933624268
Epoch: 6, Steps: 126 Train Loss: 30.2401 (Forecasting Loss:0.2424 + XiCon Loss:2.9998 x Lambda(10.0)), Vali MSE Loss: 0.1841 Test MSE Loss: 0.1382
Validation loss decreased (0.184405 --> 0.184106).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.5099087
	speed: 0.0149s/iter; left time: 174.5737s
Epoch: 7 cost time: 1.8468456268310547
Epoch: 7, Steps: 126 Train Loss: 30.2386 (Forecasting Loss:0.2417 + XiCon Loss:2.9997 x Lambda(10.0)), Vali MSE Loss: 0.1836 Test MSE Loss: 0.1363
Validation loss decreased (0.184106 --> 0.183585).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.5724506
	speed: 0.0150s/iter; left time: 173.8206s
Epoch: 8 cost time: 1.8557894229888916
Epoch: 8, Steps: 126 Train Loss: 30.3355 (Forecasting Loss:0.2412 + XiCon Loss:3.0094 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1369
Validation loss decreased (0.183585 --> 0.183335).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.8211479
	speed: 0.0148s/iter; left time: 170.5206s
Epoch: 9 cost time: 1.8420958518981934
Epoch: 9, Steps: 126 Train Loss: 30.2941 (Forecasting Loss:0.2413 + XiCon Loss:3.0053 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1366
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.2468243
	speed: 0.0149s/iter; left time: 169.8897s
Epoch: 10 cost time: 1.858426570892334
Epoch: 10, Steps: 126 Train Loss: 30.2730 (Forecasting Loss:0.2410 + XiCon Loss:3.0032 x Lambda(10.0)), Vali MSE Loss: 0.1835 Test MSE Loss: 0.1366
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.0325756
	speed: 0.0150s/iter; left time: 168.9966s
Epoch: 11 cost time: 1.860093355178833
Epoch: 11, Steps: 126 Train Loss: 30.2885 (Forecasting Loss:0.2408 + XiCon Loss:3.0048 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.3197823
	speed: 0.0149s/iter; left time: 165.5207s
Epoch: 12 cost time: 1.8671228885650635
Epoch: 12, Steps: 126 Train Loss: 30.3494 (Forecasting Loss:0.2409 + XiCon Loss:3.0108 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
Validation loss decreased (0.183335 --> 0.183271).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7309856
	speed: 0.0152s/iter; left time: 167.1012s
Epoch: 13 cost time: 1.8959128856658936
Epoch: 13, Steps: 126 Train Loss: 30.3079 (Forecasting Loss:0.2409 + XiCon Loss:3.0067 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.2303238
	speed: 0.0150s/iter; left time: 162.6075s
Epoch: 14 cost time: 1.8582019805908203
Epoch: 14, Steps: 126 Train Loss: 30.2263 (Forecasting Loss:0.2408 + XiCon Loss:2.9986 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.3141041
	speed: 0.0148s/iter; left time: 158.8871s
Epoch: 15 cost time: 1.8362400531768799
Epoch: 15, Steps: 126 Train Loss: 30.2871 (Forecasting Loss:0.2408 + XiCon Loss:3.0046 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.4291534
	speed: 0.0157s/iter; left time: 166.7834s
Epoch: 16 cost time: 1.9643611907958984
Epoch: 16, Steps: 126 Train Loss: 30.3522 (Forecasting Loss:0.2410 + XiCon Loss:3.0111 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3843040
	speed: 0.0150s/iter; left time: 157.0360s
Epoch: 17 cost time: 1.852708339691162
Epoch: 17, Steps: 126 Train Loss: 30.2165 (Forecasting Loss:0.2410 + XiCon Loss:2.9976 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.5487614
	speed: 0.0148s/iter; left time: 153.6405s
Epoch: 18 cost time: 1.8380868434906006
Epoch: 18, Steps: 126 Train Loss: 30.2857 (Forecasting Loss:0.2410 + XiCon Loss:3.0045 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
Validation loss decreased (0.183271 --> 0.183259).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.7711773
	speed: 0.0148s/iter; left time: 151.8611s
Epoch: 19 cost time: 1.8372671604156494
Epoch: 19, Steps: 126 Train Loss: 30.4236 (Forecasting Loss:0.2407 + XiCon Loss:3.0183 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.8129463
	speed: 0.0147s/iter; left time: 148.5156s
Epoch: 20 cost time: 1.8199455738067627
Epoch: 20, Steps: 126 Train Loss: 30.2657 (Forecasting Loss:0.2409 + XiCon Loss:3.0025 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.5163269
	speed: 0.0148s/iter; left time: 148.2108s
Epoch: 21 cost time: 1.8349432945251465
Epoch: 21, Steps: 126 Train Loss: 30.2897 (Forecasting Loss:0.2409 + XiCon Loss:3.0049 x Lambda(10.0)), Vali MSE Loss: 0.1834 Test MSE Loss: 0.1366
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.8138371
	speed: 0.0151s/iter; left time: 148.5320s
Epoch: 22 cost time: 1.8555808067321777
Epoch: 22, Steps: 126 Train Loss: 30.3382 (Forecasting Loss:0.2409 + XiCon Loss:3.0097 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.6590748
	speed: 0.0147s/iter; left time: 143.2492s
Epoch: 23 cost time: 1.8304784297943115
Epoch: 23, Steps: 126 Train Loss: 30.3510 (Forecasting Loss:0.2410 + XiCon Loss:3.0110 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.5887718
	speed: 0.0149s/iter; left time: 142.8792s
Epoch: 24 cost time: 1.843407392501831
Epoch: 24, Steps: 126 Train Loss: 30.3637 (Forecasting Loss:0.2409 + XiCon Loss:3.0123 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.0875969
	speed: 0.0147s/iter; left time: 138.8471s
Epoch: 25 cost time: 1.8215692043304443
Epoch: 25, Steps: 126 Train Loss: 30.2501 (Forecasting Loss:0.2409 + XiCon Loss:3.0009 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 31.1545696
	speed: 0.0146s/iter; left time: 136.5645s
Epoch: 26 cost time: 1.8176422119140625
Epoch: 26, Steps: 126 Train Loss: 30.2070 (Forecasting Loss:0.2411 + XiCon Loss:2.9966 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.8014851
	speed: 0.0150s/iter; left time: 137.9945s
Epoch: 27 cost time: 1.8521389961242676
Epoch: 27, Steps: 126 Train Loss: 30.1727 (Forecasting Loss:0.2409 + XiCon Loss:2.9932 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 30.7318497
	speed: 0.0147s/iter; left time: 134.1663s
Epoch: 28 cost time: 1.8381595611572266
Epoch: 28, Steps: 126 Train Loss: 30.3365 (Forecasting Loss:0.2409 + XiCon Loss:3.0096 x Lambda(10.0)), Vali MSE Loss: 0.1833 Test MSE Loss: 0.1366
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl192_dm16_nh8_el2_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.06977323442697525, mae:0.20342528820037842, mape:0.15547588467597961, mspe:0.04163433238863945 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0699+-0.00138, MAE:0.2038+-0.00138, MAPE:0.1562+-0.00069, MSPE:0.0423+-0.00081, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3182
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.7425060
	speed: 0.0212s/iter; left time: 260.9718s
Epoch: 1 cost time: 2.511859893798828
Epoch: 1, Steps: 124 Train Loss: 30.7863 (Forecasting Loss:0.2940 + XiCon Loss:3.0492 x Lambda(10.0)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1624
Validation loss decreased (inf --> 0.216352).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8290825
	speed: 0.0174s/iter; left time: 211.7088s
Epoch: 2 cost time: 2.140763282775879
Epoch: 2, Steps: 124 Train Loss: 29.2297 (Forecasting Loss:0.2800 + XiCon Loss:2.8950 x Lambda(10.0)), Vali MSE Loss: 0.2115 Test MSE Loss: 0.1546
Validation loss decreased (0.216352 --> 0.211535).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.2731819
	speed: 0.0178s/iter; left time: 215.0896s
Epoch: 3 cost time: 2.1851680278778076
Epoch: 3, Steps: 124 Train Loss: 30.2867 (Forecasting Loss:0.2606 + XiCon Loss:3.0026 x Lambda(10.0)), Vali MSE Loss: 0.2132 Test MSE Loss: 0.1489
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.4752998
	speed: 0.0178s/iter; left time: 212.0725s
Epoch: 4 cost time: 2.185967445373535
Epoch: 4, Steps: 124 Train Loss: 29.7671 (Forecasting Loss:0.2558 + XiCon Loss:2.9511 x Lambda(10.0)), Vali MSE Loss: 0.2065 Test MSE Loss: 0.1529
Validation loss decreased (0.211535 --> 0.206527).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.6339188
	speed: 0.0189s/iter; left time: 222.7229s
Epoch: 5 cost time: 2.315892457962036
Epoch: 5, Steps: 124 Train Loss: 29.6895 (Forecasting Loss:0.2507 + XiCon Loss:2.9439 x Lambda(10.0)), Vali MSE Loss: 0.2055 Test MSE Loss: 0.1551
Validation loss decreased (0.206527 --> 0.205464).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.4747772
	speed: 0.0185s/iter; left time: 216.6561s
Epoch: 6 cost time: 2.3265292644500732
Epoch: 6, Steps: 124 Train Loss: 29.5610 (Forecasting Loss:0.2486 + XiCon Loss:2.9312 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1523
Validation loss decreased (0.205464 --> 0.202702).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.1859550
	speed: 0.0188s/iter; left time: 217.4081s
Epoch: 7 cost time: 2.2978339195251465
Epoch: 7, Steps: 124 Train Loss: 29.5278 (Forecasting Loss:0.2473 + XiCon Loss:2.9280 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1527
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3523884
	speed: 0.0186s/iter; left time: 212.2419s
Epoch: 8 cost time: 2.2767388820648193
Epoch: 8, Steps: 124 Train Loss: 29.4497 (Forecasting Loss:0.2471 + XiCon Loss:2.9203 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1517
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.7536449
	speed: 0.0190s/iter; left time: 215.2132s
Epoch: 9 cost time: 2.327484369277954
Epoch: 9, Steps: 124 Train Loss: 29.5915 (Forecasting Loss:0.2469 + XiCon Loss:2.9345 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1519
Validation loss decreased (0.202702 --> 0.202329).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.5034332
	speed: 0.0187s/iter; left time: 208.7319s
Epoch: 10 cost time: 2.298889398574829
Epoch: 10, Steps: 124 Train Loss: 29.4228 (Forecasting Loss:0.2467 + XiCon Loss:2.9176 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1522
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.9481640
	speed: 0.0189s/iter; left time: 208.6713s
Epoch: 11 cost time: 2.3276240825653076
Epoch: 11, Steps: 124 Train Loss: 29.4636 (Forecasting Loss:0.2467 + XiCon Loss:2.9217 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1522
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.4266968
	speed: 0.0185s/iter; left time: 202.6713s
Epoch: 12 cost time: 2.287769079208374
Epoch: 12, Steps: 124 Train Loss: 29.5101 (Forecasting Loss:0.2465 + XiCon Loss:2.9264 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1521
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.4917488
	speed: 0.0184s/iter; left time: 199.4830s
Epoch: 13 cost time: 2.2681381702423096
Epoch: 13, Steps: 124 Train Loss: 29.4802 (Forecasting Loss:0.2465 + XiCon Loss:2.9234 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1520
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.9809208
	speed: 0.0186s/iter; left time: 199.1855s
Epoch: 14 cost time: 2.2863898277282715
Epoch: 14, Steps: 124 Train Loss: 29.5367 (Forecasting Loss:0.2465 + XiCon Loss:2.9290 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1520
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5794353
	speed: 0.0182s/iter; left time: 192.7710s
Epoch: 15 cost time: 2.2453174591064453
Epoch: 15, Steps: 124 Train Loss: 29.5573 (Forecasting Loss:0.2465 + XiCon Loss:2.9311 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1520
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.8933487
	speed: 0.0185s/iter; left time: 193.6296s
Epoch: 16 cost time: 2.288947582244873
Epoch: 16, Steps: 124 Train Loss: 29.4727 (Forecasting Loss:0.2468 + XiCon Loss:2.9226 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1520
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.0589771
	speed: 0.0186s/iter; left time: 191.4410s
Epoch: 17 cost time: 2.299631357192993
Epoch: 17, Steps: 124 Train Loss: 29.4431 (Forecasting Loss:0.2469 + XiCon Loss:2.9196 x Lambda(10.0)), Vali MSE Loss: 0.2024 Test MSE Loss: 0.1520
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6349239
	speed: 0.0189s/iter; left time: 192.3873s
Epoch: 18 cost time: 2.3108654022216797
Epoch: 18, Steps: 124 Train Loss: 29.6798 (Forecasting Loss:0.2465 + XiCon Loss:2.9433 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1520
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.7423344
	speed: 0.0188s/iter; left time: 189.6379s
Epoch: 19 cost time: 2.312066078186035
Epoch: 19, Steps: 124 Train Loss: 29.4887 (Forecasting Loss:0.2466 + XiCon Loss:2.9242 x Lambda(10.0)), Vali MSE Loss: 0.2026 Test MSE Loss: 0.1520
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08058442920446396, mae:0.22315368056297302, mape:0.16775012016296387, mspe:0.048128142952919006 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1391
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.8286514
	speed: 0.0178s/iter; left time: 218.6483s
Epoch: 1 cost time: 2.182554244995117
Epoch: 1, Steps: 124 Train Loss: 30.7751 (Forecasting Loss:0.2974 + XiCon Loss:3.0478 x Lambda(10.0)), Vali MSE Loss: 0.2187 Test MSE Loss: 0.1616
Validation loss decreased (inf --> 0.218746).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.5239639
	speed: 0.0190s/iter; left time: 230.9207s
Epoch: 2 cost time: 2.370567560195923
Epoch: 2, Steps: 124 Train Loss: 29.1049 (Forecasting Loss:0.2867 + XiCon Loss:2.8818 x Lambda(10.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1600
Validation loss decreased (0.218746 --> 0.211149).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.1706524
	speed: 0.0190s/iter; left time: 229.4459s
Epoch: 3 cost time: 2.3793561458587646
Epoch: 3, Steps: 124 Train Loss: 30.3214 (Forecasting Loss:0.2717 + XiCon Loss:3.0050 x Lambda(10.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1504
Validation loss decreased (0.211149 --> 0.207827).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.2819481
	speed: 0.0205s/iter; left time: 244.7657s
Epoch: 4 cost time: 2.5421717166900635
Epoch: 4, Steps: 124 Train Loss: 30.3755 (Forecasting Loss:0.2644 + XiCon Loss:3.0111 x Lambda(10.0)), Vali MSE Loss: 0.2060 Test MSE Loss: 0.1581
Validation loss decreased (0.207827 --> 0.205953).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.1877270
	speed: 0.0208s/iter; left time: 245.2924s
Epoch: 5 cost time: 2.552046775817871
Epoch: 5, Steps: 124 Train Loss: 30.2094 (Forecasting Loss:0.2607 + XiCon Loss:2.9949 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1537
Validation loss decreased (0.205953 --> 0.203093).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.6894131
	speed: 0.0207s/iter; left time: 241.3460s
Epoch: 6 cost time: 2.5342354774475098
Epoch: 6, Steps: 124 Train Loss: 30.0473 (Forecasting Loss:0.2589 + XiCon Loss:2.9788 x Lambda(10.0)), Vali MSE Loss: 0.2033 Test MSE Loss: 0.1540
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.2158489
	speed: 0.0207s/iter; left time: 239.1989s
Epoch: 7 cost time: 2.54280686378479
Epoch: 7, Steps: 124 Train Loss: 30.1363 (Forecasting Loss:0.2579 + XiCon Loss:2.9878 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1530
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.3715210
	speed: 0.0204s/iter; left time: 233.7832s
Epoch: 8 cost time: 2.52313494682312
Epoch: 8, Steps: 124 Train Loss: 29.9415 (Forecasting Loss:0.2571 + XiCon Loss:2.9684 x Lambda(10.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1527
Validation loss decreased (0.203093 --> 0.202533).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.2379684
	speed: 0.0208s/iter; left time: 235.4527s
Epoch: 9 cost time: 2.5617194175720215
Epoch: 9, Steps: 124 Train Loss: 30.0559 (Forecasting Loss:0.2568 + XiCon Loss:2.9799 x Lambda(10.0)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1534
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5596886
	speed: 0.0207s/iter; left time: 231.4591s
Epoch: 10 cost time: 2.5462629795074463
Epoch: 10, Steps: 124 Train Loss: 29.9459 (Forecasting Loss:0.2568 + XiCon Loss:2.9689 x Lambda(10.0)), Vali MSE Loss: 0.2025 Test MSE Loss: 0.1531
Validation loss decreased (0.202533 --> 0.202495).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.9471970
	speed: 0.0209s/iter; left time: 230.8597s
Epoch: 11 cost time: 2.5639665126800537
Epoch: 11, Steps: 124 Train Loss: 30.0444 (Forecasting Loss:0.2565 + XiCon Loss:2.9788 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1530
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.4344368
	speed: 0.0206s/iter; left time: 224.9509s
Epoch: 12 cost time: 2.524136781692505
Epoch: 12, Steps: 124 Train Loss: 29.9353 (Forecasting Loss:0.2566 + XiCon Loss:2.9679 x Lambda(10.0)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1530
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.3144112
	speed: 0.0206s/iter; left time: 222.9650s
Epoch: 13 cost time: 2.5463273525238037
Epoch: 13, Steps: 124 Train Loss: 30.0245 (Forecasting Loss:0.2565 + XiCon Loss:2.9768 x Lambda(10.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1530
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.5473251
	speed: 0.0205s/iter; left time: 219.5361s
Epoch: 14 cost time: 2.5348353385925293
Epoch: 14, Steps: 124 Train Loss: 30.1490 (Forecasting Loss:0.2566 + XiCon Loss:2.9892 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1530
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.7914696
	speed: 0.0206s/iter; left time: 217.5214s
Epoch: 15 cost time: 2.5402185916900635
Epoch: 15, Steps: 124 Train Loss: 29.9643 (Forecasting Loss:0.2564 + XiCon Loss:2.9708 x Lambda(10.0)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1530
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.5157375
	speed: 0.0207s/iter; left time: 216.3353s
Epoch: 16 cost time: 2.5548946857452393
Epoch: 16, Steps: 124 Train Loss: 29.9878 (Forecasting Loss:0.2565 + XiCon Loss:2.9731 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1530
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.3406601
	speed: 0.0206s/iter; left time: 212.2944s
Epoch: 17 cost time: 2.528494358062744
Epoch: 17, Steps: 124 Train Loss: 30.0892 (Forecasting Loss:0.2566 + XiCon Loss:2.9833 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1530
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.3750210
	speed: 0.0206s/iter; left time: 209.6496s
Epoch: 18 cost time: 2.5379295349121094
Epoch: 18, Steps: 124 Train Loss: 30.0377 (Forecasting Loss:0.2563 + XiCon Loss:2.9781 x Lambda(10.0)), Vali MSE Loss: 0.2028 Test MSE Loss: 0.1530
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.4079418
	speed: 0.0207s/iter; left time: 208.0077s
Epoch: 19 cost time: 2.5437488555908203
Epoch: 19, Steps: 124 Train Loss: 29.9130 (Forecasting Loss:0.2565 + XiCon Loss:2.9657 x Lambda(10.0)), Vali MSE Loss: 0.2030 Test MSE Loss: 0.1530
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.4776325
	speed: 0.0207s/iter; left time: 205.9307s
Epoch: 20 cost time: 2.5494141578674316
Epoch: 20, Steps: 124 Train Loss: 30.0654 (Forecasting Loss:0.2564 + XiCon Loss:2.9809 x Lambda(10.0)), Vali MSE Loss: 0.2031 Test MSE Loss: 0.1530
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08102644979953766, mae:0.2251424789428711, mape:0.1688898503780365, mspe:0.046898093074560165 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3173
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.8444195
	speed: 0.0179s/iter; left time: 220.1841s
Epoch: 1 cost time: 2.209728479385376
Epoch: 1, Steps: 124 Train Loss: 30.8479 (Forecasting Loss:0.2950 + XiCon Loss:3.0553 x Lambda(10.0)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1618
Validation loss decreased (inf --> 0.216946).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.8455467
	speed: 0.0206s/iter; left time: 250.8444s
Epoch: 2 cost time: 2.598651885986328
Epoch: 2, Steps: 124 Train Loss: 29.2364 (Forecasting Loss:0.2834 + XiCon Loss:2.8953 x Lambda(10.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1601
Validation loss decreased (0.216946 --> 0.212681).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.5150089
	speed: 0.0214s/iter; left time: 258.3134s
Epoch: 3 cost time: 2.633312940597534
Epoch: 3, Steps: 124 Train Loss: 30.5458 (Forecasting Loss:0.2652 + XiCon Loss:3.0281 x Lambda(10.0)), Vali MSE Loss: 0.2220 Test MSE Loss: 0.1495
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1955700
	speed: 0.0213s/iter; left time: 253.5788s
Epoch: 4 cost time: 2.6190102100372314
Epoch: 4, Steps: 124 Train Loss: 30.7546 (Forecasting Loss:0.2534 + XiCon Loss:3.0501 x Lambda(10.0)), Vali MSE Loss: 0.2143 Test MSE Loss: 0.1510
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.2077599
	speed: 0.0211s/iter; left time: 248.8341s
Epoch: 5 cost time: 2.5955734252929688
Epoch: 5, Steps: 124 Train Loss: 30.5512 (Forecasting Loss:0.2475 + XiCon Loss:3.0304 x Lambda(10.0)), Vali MSE Loss: 0.2219 Test MSE Loss: 0.1477
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 32.1364899
	speed: 0.0205s/iter; left time: 239.4469s
Epoch: 6 cost time: 2.522756338119507
Epoch: 6, Steps: 124 Train Loss: 30.4208 (Forecasting Loss:0.2459 + XiCon Loss:3.0175 x Lambda(10.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1482
Validation loss decreased (0.212681 --> 0.212336).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.6702747
	speed: 0.0208s/iter; left time: 240.1691s
Epoch: 7 cost time: 2.550102949142456
Epoch: 7, Steps: 124 Train Loss: 30.3169 (Forecasting Loss:0.2445 + XiCon Loss:3.0072 x Lambda(10.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1508
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2779312
	speed: 0.0204s/iter; left time: 232.8409s
Epoch: 8 cost time: 2.517225503921509
Epoch: 8, Steps: 124 Train Loss: 30.5376 (Forecasting Loss:0.2437 + XiCon Loss:3.0294 x Lambda(10.0)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1500
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.7528458
	speed: 0.0206s/iter; left time: 232.4553s
Epoch: 9 cost time: 2.533796548843384
Epoch: 9, Steps: 124 Train Loss: 30.2031 (Forecasting Loss:0.2434 + XiCon Loss:2.9960 x Lambda(10.0)), Vali MSE Loss: 0.2175 Test MSE Loss: 0.1498
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.6111469
	speed: 0.0206s/iter; left time: 230.8503s
Epoch: 10 cost time: 2.529500722885132
Epoch: 10, Steps: 124 Train Loss: 30.4856 (Forecasting Loss:0.2430 + XiCon Loss:3.0243 x Lambda(10.0)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1498
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.3595295
	speed: 0.0208s/iter; left time: 229.6163s
Epoch: 11 cost time: 2.553013801574707
Epoch: 11, Steps: 124 Train Loss: 30.3870 (Forecasting Loss:0.2434 + XiCon Loss:3.0144 x Lambda(10.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1498
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 31.8908672
	speed: 0.0208s/iter; left time: 227.4945s
Epoch: 12 cost time: 2.5618977546691895
Epoch: 12, Steps: 124 Train Loss: 30.3701 (Forecasting Loss:0.2433 + XiCon Loss:3.0127 x Lambda(10.0)), Vali MSE Loss: 0.2166 Test MSE Loss: 0.1498
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.0634384
	speed: 0.0206s/iter; left time: 222.2456s
Epoch: 13 cost time: 2.53672194480896
Epoch: 13, Steps: 124 Train Loss: 30.2525 (Forecasting Loss:0.2432 + XiCon Loss:3.0009 x Lambda(10.0)), Vali MSE Loss: 0.2169 Test MSE Loss: 0.1498
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.4168625
	speed: 0.0205s/iter; left time: 219.4544s
Epoch: 14 cost time: 2.5152242183685303
Epoch: 14, Steps: 124 Train Loss: 30.3199 (Forecasting Loss:0.2429 + XiCon Loss:3.0077 x Lambda(10.0)), Vali MSE Loss: 0.2173 Test MSE Loss: 0.1498
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.6784534
	speed: 0.0204s/iter; left time: 216.0027s
Epoch: 15 cost time: 2.516322135925293
Epoch: 15, Steps: 124 Train Loss: 30.2869 (Forecasting Loss:0.2429 + XiCon Loss:3.0044 x Lambda(10.0)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1498
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0832634
	speed: 0.0208s/iter; left time: 216.8239s
Epoch: 16 cost time: 2.5563719272613525
Epoch: 16, Steps: 124 Train Loss: 30.1665 (Forecasting Loss:0.2431 + XiCon Loss:2.9923 x Lambda(10.0)), Vali MSE Loss: 0.2170 Test MSE Loss: 0.1498
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07661741971969604, mae:0.21988092362880707, mape:0.16447989642620087, mspe:0.04414425790309906 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1778
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.5707836
	speed: 0.0177s/iter; left time: 218.2946s
Epoch: 1 cost time: 2.1800451278686523
Epoch: 1, Steps: 124 Train Loss: 30.8775 (Forecasting Loss:0.2965 + XiCon Loss:3.0581 x Lambda(10.0)), Vali MSE Loss: 0.2175 Test MSE Loss: 0.1629
Validation loss decreased (inf --> 0.217550).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.3497257
	speed: 0.0229s/iter; left time: 278.5038s
Epoch: 2 cost time: 2.84544038772583
Epoch: 2, Steps: 124 Train Loss: 29.2664 (Forecasting Loss:0.2816 + XiCon Loss:2.8985 x Lambda(10.0)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1571
Validation loss decreased (0.217550 --> 0.215717).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.8925190
	speed: 0.0231s/iter; left time: 278.7743s
Epoch: 3 cost time: 2.8968701362609863
Epoch: 3, Steps: 124 Train Loss: 30.8287 (Forecasting Loss:0.2647 + XiCon Loss:3.0564 x Lambda(10.0)), Vali MSE Loss: 0.2078 Test MSE Loss: 0.1543
Validation loss decreased (0.215717 --> 0.207824).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.3645592
	speed: 0.0240s/iter; left time: 285.7176s
Epoch: 4 cost time: 2.9562220573425293
Epoch: 4, Steps: 124 Train Loss: 30.5788 (Forecasting Loss:0.2577 + XiCon Loss:3.0321 x Lambda(10.0)), Vali MSE Loss: 0.2056 Test MSE Loss: 0.1466
Validation loss decreased (0.207824 --> 0.205616).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.8379021
	speed: 0.0236s/iter; left time: 279.0962s
Epoch: 5 cost time: 2.9115068912506104
Epoch: 5, Steps: 124 Train Loss: 30.3565 (Forecasting Loss:0.2533 + XiCon Loss:3.0103 x Lambda(10.0)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1478
Validation loss decreased (0.205616 --> 0.203528).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.5221825
	speed: 0.0238s/iter; left time: 278.4731s
Epoch: 6 cost time: 2.930063247680664
Epoch: 6, Steps: 124 Train Loss: 30.2224 (Forecasting Loss:0.2510 + XiCon Loss:2.9971 x Lambda(10.0)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1478
Validation loss decreased (0.203528 --> 0.201579).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.4671516
	speed: 0.0238s/iter; left time: 274.7134s
Epoch: 7 cost time: 2.919715404510498
Epoch: 7, Steps: 124 Train Loss: 30.2726 (Forecasting Loss:0.2496 + XiCon Loss:3.0023 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1476
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.5767670
	speed: 0.0239s/iter; left time: 272.8896s
Epoch: 8 cost time: 2.9390954971313477
Epoch: 8, Steps: 124 Train Loss: 29.9086 (Forecasting Loss:0.2500 + XiCon Loss:2.9659 x Lambda(10.0)), Vali MSE Loss: 0.2023 Test MSE Loss: 0.1474
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.6263943
	speed: 0.0238s/iter; left time: 269.3405s
Epoch: 9 cost time: 2.9366531372070312
Epoch: 9, Steps: 124 Train Loss: 30.3028 (Forecasting Loss:0.2492 + XiCon Loss:3.0054 x Lambda(10.0)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1476
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.6684151
	speed: 0.0235s/iter; left time: 263.3832s
Epoch: 10 cost time: 2.9068145751953125
Epoch: 10, Steps: 124 Train Loss: 29.9977 (Forecasting Loss:0.2490 + XiCon Loss:2.9749 x Lambda(10.0)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1475
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.8084335
	speed: 0.0237s/iter; left time: 261.8401s
Epoch: 11 cost time: 2.9187076091766357
Epoch: 11, Steps: 124 Train Loss: 30.2030 (Forecasting Loss:0.2487 + XiCon Loss:2.9954 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1475
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.3108349
	speed: 0.0237s/iter; left time: 259.5364s
Epoch: 12 cost time: 2.932692527770996
Epoch: 12, Steps: 124 Train Loss: 30.0817 (Forecasting Loss:0.2487 + XiCon Loss:2.9833 x Lambda(10.0)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1475
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.2930603
	speed: 0.0236s/iter; left time: 254.9455s
Epoch: 13 cost time: 2.9145233631134033
Epoch: 13, Steps: 124 Train Loss: 30.1619 (Forecasting Loss:0.2488 + XiCon Loss:2.9913 x Lambda(10.0)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1475
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.1484089
	speed: 0.0236s/iter; left time: 252.1532s
Epoch: 14 cost time: 2.9159278869628906
Epoch: 14, Steps: 124 Train Loss: 30.0512 (Forecasting Loss:0.2487 + XiCon Loss:2.9802 x Lambda(10.0)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1475
Validation loss decreased (0.201579 --> 0.201492).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.7886772
	speed: 0.0240s/iter; left time: 253.5682s
Epoch: 15 cost time: 2.9438676834106445
Epoch: 15, Steps: 124 Train Loss: 30.0801 (Forecasting Loss:0.2489 + XiCon Loss:2.9831 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1475
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.9362011
	speed: 0.0239s/iter; left time: 249.8754s
Epoch: 16 cost time: 2.9464266300201416
Epoch: 16, Steps: 124 Train Loss: 30.0885 (Forecasting Loss:0.2489 + XiCon Loss:2.9840 x Lambda(10.0)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1475
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.0891476
	speed: 0.0237s/iter; left time: 244.9111s
Epoch: 17 cost time: 2.94919753074646
Epoch: 17, Steps: 124 Train Loss: 30.2163 (Forecasting Loss:0.2492 + XiCon Loss:2.9967 x Lambda(10.0)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1475
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.6534138
	speed: 0.0237s/iter; left time: 241.8491s
Epoch: 18 cost time: 2.9345288276672363
Epoch: 18, Steps: 124 Train Loss: 30.2391 (Forecasting Loss:0.2491 + XiCon Loss:2.9990 x Lambda(10.0)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1475
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.3383179
	speed: 0.0241s/iter; left time: 242.3634s
Epoch: 19 cost time: 2.953770875930786
Epoch: 19, Steps: 124 Train Loss: 30.2515 (Forecasting Loss:0.2488 + XiCon Loss:3.0003 x Lambda(10.0)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1475
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 32.4905128
	speed: 0.0239s/iter; left time: 237.2753s
Epoch: 20 cost time: 2.9321601390838623
Epoch: 20, Steps: 124 Train Loss: 30.1511 (Forecasting Loss:0.2487 + XiCon Loss:2.9902 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1475
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.7054882
	speed: 0.0241s/iter; left time: 236.7354s
Epoch: 21 cost time: 2.968122720718384
Epoch: 21, Steps: 124 Train Loss: 30.0624 (Forecasting Loss:0.2484 + XiCon Loss:2.9814 x Lambda(10.0)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1475
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.0760365
	speed: 0.0237s/iter; left time: 229.3514s
Epoch: 22 cost time: 2.9174869060516357
Epoch: 22, Steps: 124 Train Loss: 30.2351 (Forecasting Loss:0.2490 + XiCon Loss:2.9986 x Lambda(10.0)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1475
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 30.7210560
	speed: 0.0240s/iter; left time: 229.5781s
Epoch: 23 cost time: 2.9530956745147705
Epoch: 23, Steps: 124 Train Loss: 30.2072 (Forecasting Loss:0.2487 + XiCon Loss:2.9959 x Lambda(10.0)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1475
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.2339115
	speed: 0.0238s/iter; left time: 225.0934s
Epoch: 24 cost time: 2.9362738132476807
Epoch: 24, Steps: 124 Train Loss: 30.1968 (Forecasting Loss:0.2490 + XiCon Loss:2.9948 x Lambda(10.0)), Vali MSE Loss: 0.2017 Test MSE Loss: 0.1475
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.07668090611696243, mae:0.2182340770959854, mape:0.16543570160865784, mspe:0.046666886657476425 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:230273
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1769
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 30.7737541
	speed: 0.0177s/iter; left time: 217.6960s
Epoch: 1 cost time: 2.176097869873047
Epoch: 1, Steps: 124 Train Loss: 30.8071 (Forecasting Loss:0.2950 + XiCon Loss:3.0512 x Lambda(10.0)), Vali MSE Loss: 0.2178 Test MSE Loss: 0.1597
Validation loss decreased (inf --> 0.217804).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 28.3900642
	speed: 0.0207s/iter; left time: 252.6035s
Epoch: 2 cost time: 2.6904280185699463
Epoch: 2, Steps: 124 Train Loss: 29.0605 (Forecasting Loss:0.2827 + XiCon Loss:2.8778 x Lambda(10.0)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1562
Validation loss decreased (0.217804 --> 0.207483).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.2040691
	speed: 0.0225s/iter; left time: 270.5962s
Epoch: 3 cost time: 2.680999517440796
Epoch: 3, Steps: 124 Train Loss: 29.7990 (Forecasting Loss:0.2653 + XiCon Loss:2.9534 x Lambda(10.0)), Vali MSE Loss: 0.2093 Test MSE Loss: 0.1479
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.2550735
	speed: 0.0180s/iter; left time: 215.3179s
Epoch: 4 cost time: 2.204025983810425
Epoch: 4, Steps: 124 Train Loss: 30.5107 (Forecasting Loss:0.2571 + XiCon Loss:3.0254 x Lambda(10.0)), Vali MSE Loss: 0.2032 Test MSE Loss: 0.1612
Validation loss decreased (0.207483 --> 0.203227).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7125492
	speed: 0.0176s/iter; left time: 208.1545s
Epoch: 5 cost time: 2.164914608001709
Epoch: 5, Steps: 124 Train Loss: 30.5246 (Forecasting Loss:0.2539 + XiCon Loss:3.0271 x Lambda(10.0)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1576
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.8589325
	speed: 0.0177s/iter; left time: 206.3987s
Epoch: 6 cost time: 2.175227403640747
Epoch: 6, Steps: 124 Train Loss: 30.5018 (Forecasting Loss:0.2528 + XiCon Loss:3.0249 x Lambda(10.0)), Vali MSE Loss: 0.2019 Test MSE Loss: 0.1582
Validation loss decreased (0.203227 --> 0.201923).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0448303
	speed: 0.0177s/iter; left time: 204.2632s
Epoch: 7 cost time: 2.1719627380371094
Epoch: 7, Steps: 124 Train Loss: 30.3198 (Forecasting Loss:0.2519 + XiCon Loss:3.0068 x Lambda(10.0)), Vali MSE Loss: 0.2010 Test MSE Loss: 0.1575
Validation loss decreased (0.201923 --> 0.201029).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.8189964
	speed: 0.0179s/iter; left time: 204.1067s
Epoch: 8 cost time: 2.190227746963501
Epoch: 8, Steps: 124 Train Loss: 30.4544 (Forecasting Loss:0.2515 + XiCon Loss:3.0203 x Lambda(10.0)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1569
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.2508774
	speed: 0.0174s/iter; left time: 196.9324s
Epoch: 9 cost time: 2.1435532569885254
Epoch: 9, Steps: 124 Train Loss: 30.3302 (Forecasting Loss:0.2512 + XiCon Loss:3.0079 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1582
Validation loss decreased (0.201029 --> 0.200440).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.9387207
	speed: 0.0178s/iter; left time: 199.0233s
Epoch: 10 cost time: 2.1821088790893555
Epoch: 10, Steps: 124 Train Loss: 30.4574 (Forecasting Loss:0.2512 + XiCon Loss:3.0206 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1576
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.7515507
	speed: 0.0177s/iter; left time: 195.5972s
Epoch: 11 cost time: 2.168734550476074
Epoch: 11, Steps: 124 Train Loss: 30.3667 (Forecasting Loss:0.2512 + XiCon Loss:3.0116 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1575
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7595634
	speed: 0.0175s/iter; left time: 191.8882s
Epoch: 12 cost time: 2.146009922027588
Epoch: 12, Steps: 124 Train Loss: 30.3454 (Forecasting Loss:0.2508 + XiCon Loss:3.0095 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1576
Validation loss decreased (0.200440 --> 0.200414).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.7805767
	speed: 0.0177s/iter; left time: 191.1141s
Epoch: 13 cost time: 2.16959547996521
Epoch: 13, Steps: 124 Train Loss: 30.2626 (Forecasting Loss:0.2512 + XiCon Loss:3.0011 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1576
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.6038971
	speed: 0.0175s/iter; left time: 187.5229s
Epoch: 14 cost time: 2.1586215496063232
Epoch: 14, Steps: 124 Train Loss: 30.2935 (Forecasting Loss:0.2510 + XiCon Loss:3.0043 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1576
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.6860752
	speed: 0.0178s/iter; left time: 187.9045s
Epoch: 15 cost time: 2.178337574005127
Epoch: 15, Steps: 124 Train Loss: 30.2540 (Forecasting Loss:0.2510 + XiCon Loss:3.0003 x Lambda(10.0)), Vali MSE Loss: 0.2002 Test MSE Loss: 0.1576
Validation loss decreased (0.200414 --> 0.200163).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 31.9829540
	speed: 0.0175s/iter; left time: 182.3963s
Epoch: 16 cost time: 2.1469104290008545
Epoch: 16, Steps: 124 Train Loss: 30.3702 (Forecasting Loss:0.2510 + XiCon Loss:3.0119 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1576
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.5196972
	speed: 0.0177s/iter; left time: 182.8579s
Epoch: 17 cost time: 2.1826515197753906
Epoch: 17, Steps: 124 Train Loss: 30.4026 (Forecasting Loss:0.2509 + XiCon Loss:3.0152 x Lambda(10.0)), Vali MSE Loss: 0.2003 Test MSE Loss: 0.1576
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.3236332
	speed: 0.0178s/iter; left time: 181.3803s
Epoch: 18 cost time: 2.190509796142578
Epoch: 18, Steps: 124 Train Loss: 30.2944 (Forecasting Loss:0.2511 + XiCon Loss:3.0043 x Lambda(10.0)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1576
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5636616
	speed: 0.0176s/iter; left time: 177.1582s
Epoch: 19 cost time: 2.158601760864258
Epoch: 19, Steps: 124 Train Loss: 30.3202 (Forecasting Loss:0.2511 + XiCon Loss:3.0069 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1576
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.8926010
	speed: 0.0178s/iter; left time: 177.2404s
Epoch: 20 cost time: 2.180002450942993
Epoch: 20, Steps: 124 Train Loss: 30.3488 (Forecasting Loss:0.2510 + XiCon Loss:3.0098 x Lambda(10.0)), Vali MSE Loss: 0.2004 Test MSE Loss: 0.1576
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.3109398
	speed: 0.0174s/iter; left time: 170.7922s
Epoch: 21 cost time: 2.1382973194122314
Epoch: 21, Steps: 124 Train Loss: 30.1962 (Forecasting Loss:0.2512 + XiCon Loss:2.9945 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1576
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 31.0156059
	speed: 0.0175s/iter; left time: 169.9641s
Epoch: 22 cost time: 2.145606279373169
Epoch: 22, Steps: 124 Train Loss: 30.1790 (Forecasting Loss:0.2508 + XiCon Loss:2.9928 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1576
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 28.9053211
	speed: 0.0177s/iter; left time: 169.7803s
Epoch: 23 cost time: 2.1773343086242676
Epoch: 23, Steps: 124 Train Loss: 30.2427 (Forecasting Loss:0.2512 + XiCon Loss:2.9991 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1576
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.7785664
	speed: 0.0176s/iter; left time: 165.8318s
Epoch: 24 cost time: 2.1544578075408936
Epoch: 24, Steps: 124 Train Loss: 30.3898 (Forecasting Loss:0.2509 + XiCon Loss:3.0139 x Lambda(10.0)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1576
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.8631687
	speed: 0.0177s/iter; left time: 164.7997s
Epoch: 25 cost time: 2.1713011264801025
Epoch: 25, Steps: 124 Train Loss: 30.3401 (Forecasting Loss:0.2511 + XiCon Loss:3.0089 x Lambda(10.0)), Vali MSE Loss: 0.2005 Test MSE Loss: 0.1576
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl336_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.08506086468696594, mae:0.23019462823867798, mape:0.17312519252300262, mspe:0.0500418059527874 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0800+-0.00437, MAE:0.2233+-0.00583, MAPE:0.1679+-0.00421, MSPE:0.0472+-0.00268, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[1440], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh1', root_path='./dataset/ETT-small', data_path='ETTh1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.3756
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3704409
	speed: 0.0437s/iter; left time: 511.5409s
Epoch: 1 cost time: 5.1021058559417725
Epoch: 1, Steps: 118 Train Loss: 0.3625 (Forecasting Loss:0.3594 + XiCon Loss:3.0810 x Lambda(0.001)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1691
Validation loss decreased (inf --> 0.258898).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2766785
	speed: 0.0415s/iter; left time: 480.6890s
Epoch: 2 cost time: 5.086408853530884
Epoch: 2, Steps: 118 Train Loss: 0.2995 (Forecasting Loss:0.2964 + XiCon Loss:3.0799 x Lambda(0.001)), Vali MSE Loss: 0.2507 Test MSE Loss: 0.1504
Validation loss decreased (0.258898 --> 0.250723).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2401461
	speed: 0.0539s/iter; left time: 618.3109s
Epoch: 3 cost time: 6.386575222015381
Epoch: 3, Steps: 118 Train Loss: 0.2373 (Forecasting Loss:0.2342 + XiCon Loss:3.0660 x Lambda(0.001)), Vali MSE Loss: 0.2641 Test MSE Loss: 0.1444
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2135905
	speed: 0.0543s/iter; left time: 615.6260s
Epoch: 4 cost time: 6.44650411605835
Epoch: 4, Steps: 118 Train Loss: 0.2225 (Forecasting Loss:0.2194 + XiCon Loss:3.0629 x Lambda(0.001)), Vali MSE Loss: 0.2527 Test MSE Loss: 0.1482
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2089942
	speed: 0.0556s/iter; left time: 624.0832s
Epoch: 5 cost time: 6.602065086364746
Epoch: 5, Steps: 118 Train Loss: 0.2167 (Forecasting Loss:0.2136 + XiCon Loss:3.0610 x Lambda(0.001)), Vali MSE Loss: 0.2545 Test MSE Loss: 0.1469
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2187208
	speed: 0.0608s/iter; left time: 676.0164s
Epoch: 6 cost time: 7.1507062911987305
Epoch: 6, Steps: 118 Train Loss: 0.2141 (Forecasting Loss:0.2110 + XiCon Loss:3.0604 x Lambda(0.001)), Vali MSE Loss: 0.2584 Test MSE Loss: 0.1478
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2125924
	speed: 0.0571s/iter; left time: 628.2077s
Epoch: 7 cost time: 6.791473627090454
Epoch: 7, Steps: 118 Train Loss: 0.2127 (Forecasting Loss:0.2097 + XiCon Loss:3.0566 x Lambda(0.001)), Vali MSE Loss: 0.2567 Test MSE Loss: 0.1491
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2137134
	speed: 0.0583s/iter; left time: 633.7748s
Epoch: 8 cost time: 6.92579197883606
Epoch: 8, Steps: 118 Train Loss: 0.2120 (Forecasting Loss:0.2090 + XiCon Loss:3.0554 x Lambda(0.001)), Vali MSE Loss: 0.2591 Test MSE Loss: 0.1474
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2035452
	speed: 0.0602s/iter; left time: 647.7980s
Epoch: 9 cost time: 7.076961278915405
Epoch: 9, Steps: 118 Train Loss: 0.2113 (Forecasting Loss:0.2082 + XiCon Loss:3.0582 x Lambda(0.001)), Vali MSE Loss: 0.2589 Test MSE Loss: 0.1477
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2215908
	speed: 0.0582s/iter; left time: 619.4071s
Epoch: 10 cost time: 6.906041622161865
Epoch: 10, Steps: 118 Train Loss: 0.2115 (Forecasting Loss:0.2084 + XiCon Loss:3.0558 x Lambda(0.001)), Vali MSE Loss: 0.2586 Test MSE Loss: 0.1480
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2219710
	speed: 0.0589s/iter; left time: 619.1844s
Epoch: 11 cost time: 6.973209381103516
Epoch: 11, Steps: 118 Train Loss: 0.2113 (Forecasting Loss:0.2082 + XiCon Loss:3.0569 x Lambda(0.001)), Vali MSE Loss: 0.2597 Test MSE Loss: 0.1476
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2060558
	speed: 0.0583s/iter; left time: 606.5287s
Epoch: 12 cost time: 6.947578191757202
Epoch: 12, Steps: 118 Train Loss: 0.2111 (Forecasting Loss:0.2081 + XiCon Loss:3.0570 x Lambda(0.001)), Vali MSE Loss: 0.2590 Test MSE Loss: 0.1478
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07802853733301163, mae:0.22269992530345917, mape:0.16780616343021393, mspe:0.04918840527534485 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1981
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3101456
	speed: 0.0429s/iter; left time: 502.3802s
Epoch: 1 cost time: 5.081965923309326
Epoch: 1, Steps: 118 Train Loss: 0.3565 (Forecasting Loss:0.3535 + XiCon Loss:3.0748 x Lambda(0.001)), Vali MSE Loss: 0.2564 Test MSE Loss: 0.1627
Validation loss decreased (inf --> 0.256374).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2835992
	speed: 0.0413s/iter; left time: 478.4210s
Epoch: 2 cost time: 4.90768837928772
Epoch: 2, Steps: 118 Train Loss: 0.3035 (Forecasting Loss:0.3004 + XiCon Loss:3.0672 x Lambda(0.001)), Vali MSE Loss: 0.2185 Test MSE Loss: 0.1479
Validation loss decreased (0.256374 --> 0.218483).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2451678
	speed: 0.0442s/iter; left time: 506.8547s
Epoch: 3 cost time: 5.163248062133789
Epoch: 3, Steps: 118 Train Loss: 0.2587 (Forecasting Loss:0.2556 + XiCon Loss:3.0582 x Lambda(0.001)), Vali MSE Loss: 0.2229 Test MSE Loss: 0.1470
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2381553
	speed: 0.0417s/iter; left time: 473.6710s
Epoch: 4 cost time: 4.961261510848999
Epoch: 4, Steps: 118 Train Loss: 0.2406 (Forecasting Loss:0.2376 + XiCon Loss:3.0586 x Lambda(0.001)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1457
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2278512
	speed: 0.0410s/iter; left time: 460.9148s
Epoch: 5 cost time: 4.901992082595825
Epoch: 5, Steps: 118 Train Loss: 0.2317 (Forecasting Loss:0.2286 + XiCon Loss:3.0585 x Lambda(0.001)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1447
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2347542
	speed: 0.0429s/iter; left time: 476.7935s
Epoch: 6 cost time: 5.075464725494385
Epoch: 6, Steps: 118 Train Loss: 0.2281 (Forecasting Loss:0.2250 + XiCon Loss:3.0593 x Lambda(0.001)), Vali MSE Loss: 0.2409 Test MSE Loss: 0.1450
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2345691
	speed: 0.0415s/iter; left time: 455.9725s
Epoch: 7 cost time: 4.965121030807495
Epoch: 7, Steps: 118 Train Loss: 0.2265 (Forecasting Loss:0.2234 + XiCon Loss:3.0590 x Lambda(0.001)), Vali MSE Loss: 0.2399 Test MSE Loss: 0.1451
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2384651
	speed: 0.0429s/iter; left time: 466.4570s
Epoch: 8 cost time: 5.057119846343994
Epoch: 8, Steps: 118 Train Loss: 0.2253 (Forecasting Loss:0.2222 + XiCon Loss:3.0595 x Lambda(0.001)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1455
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2214168
	speed: 0.0450s/iter; left time: 484.4331s
Epoch: 9 cost time: 5.242521047592163
Epoch: 9, Steps: 118 Train Loss: 0.2249 (Forecasting Loss:0.2218 + XiCon Loss:3.0603 x Lambda(0.001)), Vali MSE Loss: 0.2434 Test MSE Loss: 0.1445
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2340784
	speed: 0.0420s/iter; left time: 447.0503s
Epoch: 10 cost time: 4.978630781173706
Epoch: 10, Steps: 118 Train Loss: 0.2247 (Forecasting Loss:0.2216 + XiCon Loss:3.0576 x Lambda(0.001)), Vali MSE Loss: 0.2420 Test MSE Loss: 0.1450
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2323753
	speed: 0.0419s/iter; left time: 441.1861s
Epoch: 11 cost time: 4.98503303527832
Epoch: 11, Steps: 118 Train Loss: 0.2249 (Forecasting Loss:0.2218 + XiCon Loss:3.0587 x Lambda(0.001)), Vali MSE Loss: 0.2427 Test MSE Loss: 0.1447
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2193862
	speed: 0.0422s/iter; left time: 438.9126s
Epoch: 12 cost time: 4.993003845214844
Epoch: 12, Steps: 118 Train Loss: 0.2248 (Forecasting Loss:0.2218 + XiCon Loss:3.0575 x Lambda(0.001)), Vali MSE Loss: 0.2432 Test MSE Loss: 0.1444
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07548844814300537, mae:0.22025103867053986, mape:0.16617991030216217, mspe:0.04603489860892296 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2543
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3266544
	speed: 0.0408s/iter; left time: 477.7113s
Epoch: 1 cost time: 4.823390483856201
Epoch: 1, Steps: 118 Train Loss: 0.3576 (Forecasting Loss:0.3545 + XiCon Loss:3.0755 x Lambda(0.001)), Vali MSE Loss: 0.2536 Test MSE Loss: 0.1640
Validation loss decreased (inf --> 0.253626).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2741255
	speed: 0.0433s/iter; left time: 501.8745s
Epoch: 2 cost time: 5.166700124740601
Epoch: 2, Steps: 118 Train Loss: 0.3045 (Forecasting Loss:0.3015 + XiCon Loss:3.0586 x Lambda(0.001)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.1444
Validation loss decreased (0.253626 --> 0.252184).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2378853
	speed: 0.0485s/iter; left time: 556.5788s
Epoch: 3 cost time: 5.803968906402588
Epoch: 3, Steps: 118 Train Loss: 0.2410 (Forecasting Loss:0.2379 + XiCon Loss:3.0406 x Lambda(0.001)), Vali MSE Loss: 0.2570 Test MSE Loss: 0.1509
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2133889
	speed: 0.0509s/iter; left time: 577.3836s
Epoch: 4 cost time: 6.057825088500977
Epoch: 4, Steps: 118 Train Loss: 0.2222 (Forecasting Loss:0.2192 + XiCon Loss:3.0384 x Lambda(0.001)), Vali MSE Loss: 0.2616 Test MSE Loss: 0.1463
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2176960
	speed: 0.0557s/iter; left time: 625.9916s
Epoch: 5 cost time: 6.598546028137207
Epoch: 5, Steps: 118 Train Loss: 0.2161 (Forecasting Loss:0.2130 + XiCon Loss:3.0312 x Lambda(0.001)), Vali MSE Loss: 0.2612 Test MSE Loss: 0.1511
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2178375
	speed: 0.0554s/iter; left time: 615.9499s
Epoch: 6 cost time: 6.5586864948272705
Epoch: 6, Steps: 118 Train Loss: 0.2127 (Forecasting Loss:0.2097 + XiCon Loss:3.0356 x Lambda(0.001)), Vali MSE Loss: 0.2635 Test MSE Loss: 0.1494
EarlyStopping counter: 4 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2163425
	speed: 0.0557s/iter; left time: 611.7625s
Epoch: 7 cost time: 6.586297273635864
Epoch: 7, Steps: 118 Train Loss: 0.2112 (Forecasting Loss:0.2082 + XiCon Loss:3.0344 x Lambda(0.001)), Vali MSE Loss: 0.2613 Test MSE Loss: 0.1516
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2061825
	speed: 0.0542s/iter; left time: 589.2635s
Epoch: 8 cost time: 6.461340665817261
Epoch: 8, Steps: 118 Train Loss: 0.2105 (Forecasting Loss:0.2075 + XiCon Loss:3.0335 x Lambda(0.001)), Vali MSE Loss: 0.2609 Test MSE Loss: 0.1509
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2120202
	speed: 0.0581s/iter; left time: 625.1804s
Epoch: 9 cost time: 6.811664819717407
Epoch: 9, Steps: 118 Train Loss: 0.2102 (Forecasting Loss:0.2071 + XiCon Loss:3.0322 x Lambda(0.001)), Vali MSE Loss: 0.2627 Test MSE Loss: 0.1509
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2047822
	speed: 0.0534s/iter; left time: 568.2661s
Epoch: 10 cost time: 6.373950004577637
Epoch: 10, Steps: 118 Train Loss: 0.2100 (Forecasting Loss:0.2069 + XiCon Loss:3.0342 x Lambda(0.001)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1510
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2238827
	speed: 0.0557s/iter; left time: 586.0837s
Epoch: 11 cost time: 6.626042127609253
Epoch: 11, Steps: 118 Train Loss: 0.2098 (Forecasting Loss:0.2068 + XiCon Loss:3.0334 x Lambda(0.001)), Vali MSE Loss: 0.2618 Test MSE Loss: 0.1514
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2152379
	speed: 0.0538s/iter; left time: 560.0254s
Epoch: 12 cost time: 6.381357908248901
Epoch: 12, Steps: 118 Train Loss: 0.2099 (Forecasting Loss:0.2068 + XiCon Loss:3.0354 x Lambda(0.001)), Vali MSE Loss: 0.2621 Test MSE Loss: 0.1511
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07387769222259521, mae:0.21496547758579254, mape:0.16318723559379578, mspe:0.04896806925535202 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.2276
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3241690
	speed: 0.0415s/iter; left time: 485.8341s
Epoch: 1 cost time: 4.911558389663696
Epoch: 1, Steps: 118 Train Loss: 0.3552 (Forecasting Loss:0.3521 + XiCon Loss:3.0760 x Lambda(0.001)), Vali MSE Loss: 0.2555 Test MSE Loss: 0.1590
Validation loss decreased (inf --> 0.255511).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2630388
	speed: 0.0425s/iter; left time: 492.6337s
Epoch: 2 cost time: 5.087830066680908
Epoch: 2, Steps: 118 Train Loss: 0.3165 (Forecasting Loss:0.3134 + XiCon Loss:3.0670 x Lambda(0.001)), Vali MSE Loss: 0.2295 Test MSE Loss: 0.1381
Validation loss decreased (0.255511 --> 0.229545).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2468360
	speed: 0.0455s/iter; left time: 521.1803s
Epoch: 3 cost time: 5.4543023109436035
Epoch: 3, Steps: 118 Train Loss: 0.2466 (Forecasting Loss:0.2435 + XiCon Loss:3.0514 x Lambda(0.001)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1366
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2252147
	speed: 0.0490s/iter; left time: 555.8622s
Epoch: 4 cost time: 5.772825241088867
Epoch: 4, Steps: 118 Train Loss: 0.2280 (Forecasting Loss:0.2250 + XiCon Loss:3.0446 x Lambda(0.001)), Vali MSE Loss: 0.2293 Test MSE Loss: 0.1405
Validation loss decreased (0.229545 --> 0.229251).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2324276
	speed: 0.0513s/iter; left time: 575.7850s
Epoch: 5 cost time: 6.005002498626709
Epoch: 5, Steps: 118 Train Loss: 0.2221 (Forecasting Loss:0.2190 + XiCon Loss:3.0442 x Lambda(0.001)), Vali MSE Loss: 0.2332 Test MSE Loss: 0.1390
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2097956
	speed: 0.0506s/iter; left time: 561.9265s
Epoch: 6 cost time: 5.95567512512207
Epoch: 6, Steps: 118 Train Loss: 0.2188 (Forecasting Loss:0.2158 + XiCon Loss:3.0437 x Lambda(0.001)), Vali MSE Loss: 0.2374 Test MSE Loss: 0.1364
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2153506
	speed: 0.0504s/iter; left time: 554.0900s
Epoch: 7 cost time: 5.955967664718628
Epoch: 7, Steps: 118 Train Loss: 0.2176 (Forecasting Loss:0.2145 + XiCon Loss:3.0480 x Lambda(0.001)), Vali MSE Loss: 0.2395 Test MSE Loss: 0.1370
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2231557
	speed: 0.0499s/iter; left time: 542.7249s
Epoch: 8 cost time: 5.921052694320679
Epoch: 8, Steps: 118 Train Loss: 0.2168 (Forecasting Loss:0.2137 + XiCon Loss:3.0444 x Lambda(0.001)), Vali MSE Loss: 0.2385 Test MSE Loss: 0.1375
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2225371
	speed: 0.0506s/iter; left time: 544.0062s
Epoch: 9 cost time: 6.00571084022522
Epoch: 9, Steps: 118 Train Loss: 0.2165 (Forecasting Loss:0.2134 + XiCon Loss:3.0455 x Lambda(0.001)), Vali MSE Loss: 0.2394 Test MSE Loss: 0.1369
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2218519
	speed: 0.0500s/iter; left time: 532.4096s
Epoch: 10 cost time: 5.919540882110596
Epoch: 10, Steps: 118 Train Loss: 0.2164 (Forecasting Loss:0.2133 + XiCon Loss:3.0449 x Lambda(0.001)), Vali MSE Loss: 0.2404 Test MSE Loss: 0.1367
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2200402
	speed: 0.0491s/iter; left time: 516.6044s
Epoch: 11 cost time: 5.812407732009888
Epoch: 11, Steps: 118 Train Loss: 0.2161 (Forecasting Loss:0.2131 + XiCon Loss:3.0448 x Lambda(0.001)), Vali MSE Loss: 0.2406 Test MSE Loss: 0.1368
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2128103
	speed: 0.0514s/iter; left time: 535.1398s
Epoch: 12 cost time: 6.063030004501343
Epoch: 12, Steps: 118 Train Loss: 0.2159 (Forecasting Loss:0.2129 + XiCon Loss:3.0465 x Lambda(0.001)), Vali MSE Loss: 0.2405 Test MSE Loss: 0.1368
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2262635
	speed: 0.0537s/iter; left time: 551.9768s
Epoch: 13 cost time: 6.279730558395386
Epoch: 13, Steps: 118 Train Loss: 0.2160 (Forecasting Loss:0.2130 + XiCon Loss:3.0464 x Lambda(0.001)), Vali MSE Loss: 0.2410 Test MSE Loss: 0.1368
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2029281
	speed: 0.0505s/iter; left time: 513.9348s
Epoch: 14 cost time: 6.001165390014648
Epoch: 14, Steps: 118 Train Loss: 0.2161 (Forecasting Loss:0.2130 + XiCon Loss:3.0457 x Lambda(0.001)), Vali MSE Loss: 0.2408 Test MSE Loss: 0.1368
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.07016546279191971, mae:0.21087707579135895, mape:0.1574336439371109, mspe:0.04252873361110687 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493265
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99988479] ~ [1.1234797e-04 5.6266367e-05]
Xi-correlation values:[0.99965282 0.99661621] ~ [0. 1.]
Autocorrelation calculation time: 1.1996
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.3340210
	speed: 0.0415s/iter; left time: 485.9767s
Epoch: 1 cost time: 4.924877405166626
Epoch: 1, Steps: 118 Train Loss: 0.3566 (Forecasting Loss:0.3535 + XiCon Loss:3.0753 x Lambda(0.001)), Vali MSE Loss: 0.2554 Test MSE Loss: 0.1621
Validation loss decreased (inf --> 0.255394).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 0.2748199
	speed: 0.0424s/iter; left time: 491.4283s
Epoch: 2 cost time: 5.053062200546265
Epoch: 2, Steps: 118 Train Loss: 0.3057 (Forecasting Loss:0.3026 + XiCon Loss:3.0653 x Lambda(0.001)), Vali MSE Loss: 0.2271 Test MSE Loss: 0.1476
Validation loss decreased (0.255394 --> 0.227130).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 0.2417852
	speed: 0.0419s/iter; left time: 480.7162s
Epoch: 3 cost time: 4.981546878814697
Epoch: 3, Steps: 118 Train Loss: 0.2494 (Forecasting Loss:0.2463 + XiCon Loss:3.0446 x Lambda(0.001)), Vali MSE Loss: 0.2222 Test MSE Loss: 0.1348
Validation loss decreased (0.227130 --> 0.222213).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 0.2246301
	speed: 0.0435s/iter; left time: 493.9043s
Epoch: 4 cost time: 5.118415355682373
Epoch: 4, Steps: 118 Train Loss: 0.2279 (Forecasting Loss:0.2249 + XiCon Loss:3.0275 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1377
Validation loss decreased (0.222213 --> 0.216266).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 0.2108423
	speed: 0.0448s/iter; left time: 502.7002s
Epoch: 5 cost time: 5.286736726760864
Epoch: 5, Steps: 118 Train Loss: 0.2211 (Forecasting Loss:0.2181 + XiCon Loss:3.0261 x Lambda(0.001)), Vali MSE Loss: 0.2165 Test MSE Loss: 0.1371
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 0.2097027
	speed: 0.0443s/iter; left time: 491.7523s
Epoch: 6 cost time: 5.24666690826416
Epoch: 6, Steps: 118 Train Loss: 0.2184 (Forecasting Loss:0.2154 + XiCon Loss:3.0240 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1389
Validation loss decreased (0.216266 --> 0.215651).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 0.2098158
	speed: 0.0432s/iter; left time: 474.5803s
Epoch: 7 cost time: 5.103617191314697
Epoch: 7, Steps: 118 Train Loss: 0.2171 (Forecasting Loss:0.2141 + XiCon Loss:3.0269 x Lambda(0.001)), Vali MSE Loss: 0.2157 Test MSE Loss: 0.1388
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 0.2057379
	speed: 0.0449s/iter; left time: 488.4351s
Epoch: 8 cost time: 5.316566228866577
Epoch: 8, Steps: 118 Train Loss: 0.2160 (Forecasting Loss:0.2130 + XiCon Loss:3.0235 x Lambda(0.001)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1368
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 0.2092601
	speed: 0.0459s/iter; left time: 493.6517s
Epoch: 9 cost time: 5.374333381652832
Epoch: 9, Steps: 118 Train Loss: 0.2159 (Forecasting Loss:0.2129 + XiCon Loss:3.0266 x Lambda(0.001)), Vali MSE Loss: 0.2158 Test MSE Loss: 0.1379
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 0.2004983
	speed: 0.0451s/iter; left time: 479.3083s
Epoch: 10 cost time: 5.285238265991211
Epoch: 10, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2124 + XiCon Loss:3.0236 x Lambda(0.001)), Vali MSE Loss: 0.2164 Test MSE Loss: 0.1382
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 0.2242494
	speed: 0.0452s/iter; left time: 475.0867s
Epoch: 11 cost time: 5.304805040359497
Epoch: 11, Steps: 118 Train Loss: 0.2154 (Forecasting Loss:0.2124 + XiCon Loss:3.0249 x Lambda(0.001)), Vali MSE Loss: 0.2167 Test MSE Loss: 0.1383
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 0.2163943
	speed: 0.0443s/iter; left time: 461.3154s
Epoch: 12 cost time: 5.224519491195679
Epoch: 12, Steps: 118 Train Loss: 0.2156 (Forecasting Loss:0.2126 + XiCon Loss:3.0240 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1384
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 0.2122049
	speed: 0.0442s/iter; left time: 454.6031s
Epoch: 13 cost time: 5.249439239501953
Epoch: 13, Steps: 118 Train Loss: 0.2155 (Forecasting Loss:0.2125 + XiCon Loss:3.0241 x Lambda(0.001)), Vali MSE Loss: 0.2163 Test MSE Loss: 0.1383
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 0.2155632
	speed: 0.0445s/iter; left time: 452.0691s
Epoch: 14 cost time: 5.230056047439575
Epoch: 14, Steps: 118 Train Loss: 0.2151 (Forecasting Loss:0.2120 + XiCon Loss:3.0263 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1383
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 0.2302364
	speed: 0.0483s/iter; left time: 485.8357s
Epoch: 15 cost time: 5.648362874984741
Epoch: 15, Steps: 118 Train Loss: 0.2151 (Forecasting Loss:0.2121 + XiCon Loss:3.0241 x Lambda(0.001)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1384
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 0.2179237
	speed: 0.0433s/iter; left time: 429.8793s
Epoch: 16 cost time: 5.121380567550659
Epoch: 16, Steps: 118 Train Loss: 0.2153 (Forecasting Loss:0.2123 + XiCon Loss:3.0254 x Lambda(0.001)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1384
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh1_ftS_sl336_ll48_pl720_dm16_nh8_el1_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.0681658685207367, mae:0.20969055593013763, mape:0.15847134590148926, mspe:0.0433005653321743 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0731+-0.00495, MAE:0.2157+-0.00707, MAPE:0.1626+-0.00569, MSPE:0.0460+-0.00384, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2983
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2217317
	speed: 0.0161s/iter; left time: 204.0034s
Epoch: 1 cost time: 1.92417311668396
Epoch: 1, Steps: 128 Train Loss: 3.3092 (Forecasting Loss:0.2930 + XiCon Loss:3.0162 x Lambda(1.0)), Vali MSE Loss: 0.2770 Test MSE Loss: 0.2328
Validation loss decreased (inf --> 0.277045).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0535898
	speed: 0.0127s/iter; left time: 159.9045s
Epoch: 2 cost time: 1.592228889465332
Epoch: 2, Steps: 128 Train Loss: 3.0998 (Forecasting Loss:0.2572 + XiCon Loss:2.8426 x Lambda(1.0)), Vali MSE Loss: 0.2575 Test MSE Loss: 0.2207
Validation loss decreased (0.277045 --> 0.257504).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2110381
	speed: 0.0125s/iter; left time: 156.0131s
Epoch: 3 cost time: 1.5738298892974854
Epoch: 3, Steps: 128 Train Loss: 3.0546 (Forecasting Loss:0.2434 + XiCon Loss:2.8112 x Lambda(1.0)), Vali MSE Loss: 0.2539 Test MSE Loss: 0.2211
Validation loss decreased (0.257504 --> 0.253924).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1160295
	speed: 0.0126s/iter; left time: 155.6081s
Epoch: 4 cost time: 1.589432716369629
Epoch: 4, Steps: 128 Train Loss: 3.1279 (Forecasting Loss:0.2375 + XiCon Loss:2.8904 x Lambda(1.0)), Vali MSE Loss: 0.2530 Test MSE Loss: 0.2055
Validation loss decreased (0.253924 --> 0.252985).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0653243
	speed: 0.0127s/iter; left time: 154.7279s
Epoch: 5 cost time: 1.5878283977508545
Epoch: 5, Steps: 128 Train Loss: 3.2189 (Forecasting Loss:0.2347 + XiCon Loss:2.9842 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2086
Validation loss decreased (0.252985 --> 0.251767).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0883553
	speed: 0.0127s/iter; left time: 153.6378s
Epoch: 6 cost time: 1.5874354839324951
Epoch: 6, Steps: 128 Train Loss: 3.2595 (Forecasting Loss:0.2328 + XiCon Loss:3.0267 x Lambda(1.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.2069
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3716447
	speed: 0.0128s/iter; left time: 152.6294s
Epoch: 7 cost time: 1.598625659942627
Epoch: 7, Steps: 128 Train Loss: 3.2622 (Forecasting Loss:0.2315 + XiCon Loss:3.0307 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2074
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2888722
	speed: 0.0126s/iter; left time: 148.8506s
Epoch: 8 cost time: 1.5833702087402344
Epoch: 8, Steps: 128 Train Loss: 3.2697 (Forecasting Loss:0.2311 + XiCon Loss:3.0386 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2069
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3248773
	speed: 0.0131s/iter; left time: 152.9000s
Epoch: 9 cost time: 1.6346759796142578
Epoch: 9, Steps: 128 Train Loss: 3.2605 (Forecasting Loss:0.2310 + XiCon Loss:3.0295 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2061
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3373485
	speed: 0.0130s/iter; left time: 150.0024s
Epoch: 10 cost time: 1.6280243396759033
Epoch: 10, Steps: 128 Train Loss: 3.2778 (Forecasting Loss:0.2310 + XiCon Loss:3.0469 x Lambda(1.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.2063
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2264791
	speed: 0.0133s/iter; left time: 151.9710s
Epoch: 11 cost time: 1.6807169914245605
Epoch: 11, Steps: 128 Train Loss: 3.2558 (Forecasting Loss:0.2309 + XiCon Loss:3.0249 x Lambda(1.0)), Vali MSE Loss: 0.2521 Test MSE Loss: 0.2063
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3635631
	speed: 0.0125s/iter; left time: 141.3494s
Epoch: 12 cost time: 1.565943956375122
Epoch: 12, Steps: 128 Train Loss: 3.2810 (Forecasting Loss:0.2308 + XiCon Loss:3.0502 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2062
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1299086
	speed: 0.0130s/iter; left time: 144.9304s
Epoch: 13 cost time: 1.621598720550537
Epoch: 13, Steps: 128 Train Loss: 3.2749 (Forecasting Loss:0.2308 + XiCon Loss:3.0441 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2062
Validation loss decreased (0.251767 --> 0.251650).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3118992
	speed: 0.0126s/iter; left time: 139.0388s
Epoch: 14 cost time: 1.5824692249298096
Epoch: 14, Steps: 128 Train Loss: 3.2819 (Forecasting Loss:0.2305 + XiCon Loss:3.0514 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2062
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1763468
	speed: 0.0127s/iter; left time: 138.3152s
Epoch: 15 cost time: 1.5891754627227783
Epoch: 15, Steps: 128 Train Loss: 3.2678 (Forecasting Loss:0.2305 + XiCon Loss:3.0373 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2062
Validation loss decreased (0.251650 --> 0.251500).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2853298
	speed: 0.0126s/iter; left time: 135.6420s
Epoch: 16 cost time: 1.5810587406158447
Epoch: 16, Steps: 128 Train Loss: 3.2654 (Forecasting Loss:0.2308 + XiCon Loss:3.0347 x Lambda(1.0)), Vali MSE Loss: 0.2524 Test MSE Loss: 0.2062
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3044367
	speed: 0.0128s/iter; left time: 136.3430s
Epoch: 17 cost time: 1.6012639999389648
Epoch: 17, Steps: 128 Train Loss: 3.2785 (Forecasting Loss:0.2308 + XiCon Loss:3.0477 x Lambda(1.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.2062
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1555429
	speed: 0.0126s/iter; left time: 132.4076s
Epoch: 18 cost time: 1.5855066776275635
Epoch: 18, Steps: 128 Train Loss: 3.2765 (Forecasting Loss:0.2309 + XiCon Loss:3.0456 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2062
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2306643
	speed: 0.0125s/iter; left time: 129.6538s
Epoch: 19 cost time: 1.5672378540039062
Epoch: 19, Steps: 128 Train Loss: 3.2538 (Forecasting Loss:0.2307 + XiCon Loss:3.0231 x Lambda(1.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2062
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.5960674
	speed: 0.0125s/iter; left time: 128.2633s
Epoch: 20 cost time: 1.5640869140625
Epoch: 20, Steps: 128 Train Loss: 3.2815 (Forecasting Loss:0.2307 + XiCon Loss:3.0508 x Lambda(1.0)), Vali MSE Loss: 0.2520 Test MSE Loss: 0.2062
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3760939
	speed: 0.0125s/iter; left time: 126.6610s
Epoch: 21 cost time: 1.5700509548187256
Epoch: 21, Steps: 128 Train Loss: 3.2810 (Forecasting Loss:0.2305 + XiCon Loss:3.0505 x Lambda(1.0)), Vali MSE Loss: 0.2525 Test MSE Loss: 0.2062
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.4555576
	speed: 0.0126s/iter; left time: 126.3584s
Epoch: 22 cost time: 1.617631196975708
Epoch: 22, Steps: 128 Train Loss: 3.2703 (Forecasting Loss:0.2307 + XiCon Loss:3.0395 x Lambda(1.0)), Vali MSE Loss: 0.2519 Test MSE Loss: 0.2062
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.3893609
	speed: 0.0131s/iter; left time: 129.1537s
Epoch: 23 cost time: 1.6307835578918457
Epoch: 23, Steps: 128 Train Loss: 3.2744 (Forecasting Loss:0.2309 + XiCon Loss:3.0435 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2062
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.3496070
	speed: 0.0125s/iter; left time: 121.6472s
Epoch: 24 cost time: 1.5677552223205566
Epoch: 24, Steps: 128 Train Loss: 3.2717 (Forecasting Loss:0.2307 + XiCon Loss:3.0410 x Lambda(1.0)), Vali MSE Loss: 0.2518 Test MSE Loss: 0.2062
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2571959
	speed: 0.0126s/iter; left time: 121.0401s
Epoch: 25 cost time: 1.5779776573181152
Epoch: 25, Steps: 128 Train Loss: 3.2657 (Forecasting Loss:0.2306 + XiCon Loss:3.0351 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2062
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13193172216415405, mae:0.2805503308773041, mape:0.6627088785171509, mspe:19.51763916015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1791
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2272289
	speed: 0.0138s/iter; left time: 175.7436s
Epoch: 1 cost time: 1.736201524734497
Epoch: 1, Steps: 128 Train Loss: 3.3104 (Forecasting Loss:0.2935 + XiCon Loss:3.0169 x Lambda(1.0)), Vali MSE Loss: 0.2747 Test MSE Loss: 0.2273
Validation loss decreased (inf --> 0.274749).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0805416
	speed: 0.0125s/iter; left time: 157.6136s
Epoch: 2 cost time: 1.5827538967132568
Epoch: 2, Steps: 128 Train Loss: 3.1110 (Forecasting Loss:0.2532 + XiCon Loss:2.8578 x Lambda(1.0)), Vali MSE Loss: 0.2759 Test MSE Loss: 0.2257
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3324764
	speed: 0.0137s/iter; left time: 169.9155s
Epoch: 3 cost time: 1.6852037906646729
Epoch: 3, Steps: 128 Train Loss: 3.2401 (Forecasting Loss:0.2400 + XiCon Loss:3.0000 x Lambda(1.0)), Vali MSE Loss: 0.2622 Test MSE Loss: 0.2059
Validation loss decreased (0.274749 --> 0.262233).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1091366
	speed: 0.0127s/iter; left time: 156.2074s
Epoch: 4 cost time: 1.591865062713623
Epoch: 4, Steps: 128 Train Loss: 3.1697 (Forecasting Loss:0.2299 + XiCon Loss:2.9398 x Lambda(1.0)), Vali MSE Loss: 0.2516 Test MSE Loss: 0.2086
Validation loss decreased (0.262233 --> 0.251631).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1030688
	speed: 0.0129s/iter; left time: 156.8602s
Epoch: 5 cost time: 1.6070048809051514
Epoch: 5, Steps: 128 Train Loss: 3.1671 (Forecasting Loss:0.2260 + XiCon Loss:2.9411 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2068
Validation loss decreased (0.251631 --> 0.250025).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1390247
	speed: 0.0125s/iter; left time: 151.1017s
Epoch: 6 cost time: 1.5701298713684082
Epoch: 6, Steps: 128 Train Loss: 3.1571 (Forecasting Loss:0.2221 + XiCon Loss:2.9350 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2096
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0349963
	speed: 0.0127s/iter; left time: 151.5158s
Epoch: 7 cost time: 1.5894083976745605
Epoch: 7, Steps: 128 Train Loss: 3.1547 (Forecasting Loss:0.2203 + XiCon Loss:2.9344 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2092
Validation loss decreased (0.250025 --> 0.249488).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0576596
	speed: 0.0128s/iter; left time: 150.8129s
Epoch: 8 cost time: 1.6272387504577637
Epoch: 8, Steps: 128 Train Loss: 3.1376 (Forecasting Loss:0.2195 + XiCon Loss:2.9182 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2088
Validation loss decreased (0.249488 --> 0.248984).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0800190
	speed: 0.0126s/iter; left time: 147.6849s
Epoch: 9 cost time: 1.5825693607330322
Epoch: 9, Steps: 128 Train Loss: 3.1467 (Forecasting Loss:0.2189 + XiCon Loss:2.9278 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2090
Validation loss decreased (0.248984 --> 0.248733).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0650384
	speed: 0.0129s/iter; left time: 148.9386s
Epoch: 10 cost time: 1.6052656173706055
Epoch: 10, Steps: 128 Train Loss: 3.1499 (Forecasting Loss:0.2188 + XiCon Loss:2.9311 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2091
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2737215
	speed: 0.0133s/iter; left time: 151.9639s
Epoch: 11 cost time: 1.6703715324401855
Epoch: 11, Steps: 128 Train Loss: 3.1448 (Forecasting Loss:0.2187 + XiCon Loss:2.9261 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2093
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2057724
	speed: 0.0130s/iter; left time: 146.5168s
Epoch: 12 cost time: 1.6373322010040283
Epoch: 12, Steps: 128 Train Loss: 3.1453 (Forecasting Loss:0.2182 + XiCon Loss:2.9271 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2093
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2726781
	speed: 0.0127s/iter; left time: 141.7665s
Epoch: 13 cost time: 1.5935921669006348
Epoch: 13, Steps: 128 Train Loss: 3.1470 (Forecasting Loss:0.2185 + XiCon Loss:2.9285 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2092
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1674347
	speed: 0.0127s/iter; left time: 140.4059s
Epoch: 14 cost time: 1.5855295658111572
Epoch: 14, Steps: 128 Train Loss: 3.1585 (Forecasting Loss:0.2186 + XiCon Loss:2.9399 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2093
Validation loss decreased (0.248733 --> 0.248650).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1263494
	speed: 0.0130s/iter; left time: 141.9231s
Epoch: 15 cost time: 1.6178100109100342
Epoch: 15, Steps: 128 Train Loss: 3.1426 (Forecasting Loss:0.2190 + XiCon Loss:2.9236 x Lambda(1.0)), Vali MSE Loss: 0.2489 Test MSE Loss: 0.2093
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1012635
	speed: 0.0127s/iter; left time: 136.6077s
Epoch: 16 cost time: 1.5890231132507324
Epoch: 16, Steps: 128 Train Loss: 3.1398 (Forecasting Loss:0.2181 + XiCon Loss:2.9217 x Lambda(1.0)), Vali MSE Loss: 0.2491 Test MSE Loss: 0.2093
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0419617
	speed: 0.0127s/iter; left time: 135.5061s
Epoch: 17 cost time: 1.5980875492095947
Epoch: 17, Steps: 128 Train Loss: 3.1547 (Forecasting Loss:0.2177 + XiCon Loss:2.9370 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2093
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1461380
	speed: 0.0127s/iter; left time: 133.2101s
Epoch: 18 cost time: 1.5861232280731201
Epoch: 18, Steps: 128 Train Loss: 3.1423 (Forecasting Loss:0.2185 + XiCon Loss:2.9238 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2093
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2112489
	speed: 0.0130s/iter; left time: 135.1461s
Epoch: 19 cost time: 1.6137597560882568
Epoch: 19, Steps: 128 Train Loss: 3.1471 (Forecasting Loss:0.2184 + XiCon Loss:2.9287 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2093
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0644767
	speed: 0.0127s/iter; left time: 130.2484s
Epoch: 20 cost time: 1.588757038116455
Epoch: 20, Steps: 128 Train Loss: 3.1449 (Forecasting Loss:0.2190 + XiCon Loss:2.9259 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2093
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1544216
	speed: 0.0126s/iter; left time: 127.4115s
Epoch: 21 cost time: 1.5965673923492432
Epoch: 21, Steps: 128 Train Loss: 3.1490 (Forecasting Loss:0.2179 + XiCon Loss:2.9311 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2093
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1976814
	speed: 0.0127s/iter; left time: 127.0230s
Epoch: 22 cost time: 1.5914547443389893
Epoch: 22, Steps: 128 Train Loss: 3.1248 (Forecasting Loss:0.2187 + XiCon Loss:2.9061 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2093
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2192726
	speed: 0.0126s/iter; left time: 124.3630s
Epoch: 23 cost time: 1.5842771530151367
Epoch: 23, Steps: 128 Train Loss: 3.1598 (Forecasting Loss:0.2184 + XiCon Loss:2.9414 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2093
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1312182
	speed: 0.0127s/iter; left time: 124.0897s
Epoch: 24 cost time: 1.5987682342529297
Epoch: 24, Steps: 128 Train Loss: 3.1512 (Forecasting Loss:0.2186 + XiCon Loss:2.9326 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2093
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13466762006282806, mae:0.2838977575302124, mape:0.681847095489502, mspe:19.796554565429688 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2426
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.3076155
	speed: 0.0127s/iter; left time: 161.3711s
Epoch: 1 cost time: 1.5924010276794434
Epoch: 1, Steps: 128 Train Loss: 3.3053 (Forecasting Loss:0.2969 + XiCon Loss:3.0084 x Lambda(1.0)), Vali MSE Loss: 0.2757 Test MSE Loss: 0.2286
Validation loss decreased (inf --> 0.275725).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0757101
	speed: 0.0127s/iter; left time: 159.8347s
Epoch: 2 cost time: 1.5971150398254395
Epoch: 2, Steps: 128 Train Loss: 3.0995 (Forecasting Loss:0.2557 + XiCon Loss:2.8438 x Lambda(1.0)), Vali MSE Loss: 0.2662 Test MSE Loss: 0.2155
Validation loss decreased (0.275725 --> 0.266222).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1127002
	speed: 0.0135s/iter; left time: 167.8803s
Epoch: 3 cost time: 1.6996207237243652
Epoch: 3, Steps: 128 Train Loss: 3.0536 (Forecasting Loss:0.2441 + XiCon Loss:2.8095 x Lambda(1.0)), Vali MSE Loss: 0.2585 Test MSE Loss: 0.2044
Validation loss decreased (0.266222 --> 0.258549).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0902791
	speed: 0.0126s/iter; left time: 155.0439s
Epoch: 4 cost time: 1.6174378395080566
Epoch: 4, Steps: 128 Train Loss: 3.1408 (Forecasting Loss:0.2376 + XiCon Loss:2.9032 x Lambda(1.0)), Vali MSE Loss: 0.2512 Test MSE Loss: 0.2065
Validation loss decreased (0.258549 --> 0.251180).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1687760
	speed: 0.0124s/iter; left time: 151.4230s
Epoch: 5 cost time: 1.563366413116455
Epoch: 5, Steps: 128 Train Loss: 3.1407 (Forecasting Loss:0.2338 + XiCon Loss:2.9069 x Lambda(1.0)), Vali MSE Loss: 0.2523 Test MSE Loss: 0.2116
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0298295
	speed: 0.0130s/iter; left time: 157.3014s
Epoch: 6 cost time: 1.6512956619262695
Epoch: 6, Steps: 128 Train Loss: 3.1435 (Forecasting Loss:0.2325 + XiCon Loss:2.9110 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2042
Validation loss decreased (0.251180 --> 0.250253).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0739646
	speed: 0.0126s/iter; left time: 150.1208s
Epoch: 7 cost time: 1.5805981159210205
Epoch: 7, Steps: 128 Train Loss: 3.1426 (Forecasting Loss:0.2318 + XiCon Loss:2.9108 x Lambda(1.0)), Vali MSE Loss: 0.2488 Test MSE Loss: 0.2067
Validation loss decreased (0.250253 --> 0.248831).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1648068
	speed: 0.0137s/iter; left time: 162.0515s
Epoch: 8 cost time: 1.7019176483154297
Epoch: 8, Steps: 128 Train Loss: 3.1675 (Forecasting Loss:0.2313 + XiCon Loss:2.9362 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2047
Validation loss decreased (0.248831 --> 0.248558).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0685301
	speed: 0.0126s/iter; left time: 147.1454s
Epoch: 9 cost time: 1.5898337364196777
Epoch: 9, Steps: 128 Train Loss: 3.1378 (Forecasting Loss:0.2308 + XiCon Loss:2.9070 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
Validation loss decreased (0.248558 --> 0.248349).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2186129
	speed: 0.0132s/iter; left time: 152.3054s
Epoch: 10 cost time: 1.672278881072998
Epoch: 10, Steps: 128 Train Loss: 3.1519 (Forecasting Loss:0.2306 + XiCon Loss:2.9213 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2046
Validation loss decreased (0.248349 --> 0.248131).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0723917
	speed: 0.0128s/iter; left time: 146.0655s
Epoch: 11 cost time: 1.6033484935760498
Epoch: 11, Steps: 128 Train Loss: 3.1452 (Forecasting Loss:0.2306 + XiCon Loss:2.9146 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2046
Validation loss decreased (0.248131 --> 0.248051).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0251882
	speed: 0.0127s/iter; left time: 143.3926s
Epoch: 12 cost time: 1.5921878814697266
Epoch: 12, Steps: 128 Train Loss: 3.1433 (Forecasting Loss:0.2304 + XiCon Loss:2.9129 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2047
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1660712
	speed: 0.0125s/iter; left time: 140.1060s
Epoch: 13 cost time: 1.573089838027954
Epoch: 13, Steps: 128 Train Loss: 3.1545 (Forecasting Loss:0.2307 + XiCon Loss:2.9239 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2047
Validation loss decreased (0.248051 --> 0.247996).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1247637
	speed: 0.0126s/iter; left time: 139.1879s
Epoch: 14 cost time: 1.5815916061401367
Epoch: 14, Steps: 128 Train Loss: 3.1473 (Forecasting Loss:0.2305 + XiCon Loss:2.9167 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1928051
	speed: 0.0128s/iter; left time: 139.5319s
Epoch: 15 cost time: 1.604271650314331
Epoch: 15, Steps: 128 Train Loss: 3.1400 (Forecasting Loss:0.2305 + XiCon Loss:2.9095 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2069702
	speed: 0.0125s/iter; left time: 134.8331s
Epoch: 16 cost time: 1.5721526145935059
Epoch: 16, Steps: 128 Train Loss: 3.1443 (Forecasting Loss:0.2306 + XiCon Loss:2.9138 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.2047
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2932506
	speed: 0.0125s/iter; left time: 133.4471s
Epoch: 17 cost time: 1.5654873847961426
Epoch: 17, Steps: 128 Train Loss: 3.1528 (Forecasting Loss:0.2305 + XiCon Loss:2.9223 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2047
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1817050
	speed: 0.0126s/iter; left time: 132.5384s
Epoch: 18 cost time: 1.5808730125427246
Epoch: 18, Steps: 128 Train Loss: 3.1555 (Forecasting Loss:0.2304 + XiCon Loss:2.9250 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2047
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1112237
	speed: 0.0128s/iter; left time: 132.7766s
Epoch: 19 cost time: 1.602358341217041
Epoch: 19, Steps: 128 Train Loss: 3.1576 (Forecasting Loss:0.2304 + XiCon Loss:2.9272 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0912411
	speed: 0.0136s/iter; left time: 140.0165s
Epoch: 20 cost time: 1.7116270065307617
Epoch: 20, Steps: 128 Train Loss: 3.1633 (Forecasting Loss:0.2305 + XiCon Loss:2.9329 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.1610713
	speed: 0.0132s/iter; left time: 133.9326s
Epoch: 21 cost time: 1.6731829643249512
Epoch: 21, Steps: 128 Train Loss: 3.1460 (Forecasting Loss:0.2307 + XiCon Loss:2.9153 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.2047
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2311020
	speed: 0.0131s/iter; left time: 130.7061s
Epoch: 22 cost time: 1.64042329788208
Epoch: 22, Steps: 128 Train Loss: 3.1612 (Forecasting Loss:0.2303 + XiCon Loss:2.9309 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2047
Validation loss decreased (0.247996 --> 0.247988).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1303635
	speed: 0.0127s/iter; left time: 125.6855s
Epoch: 23 cost time: 1.5857012271881104
Epoch: 23, Steps: 128 Train Loss: 3.1484 (Forecasting Loss:0.2304 + XiCon Loss:2.9180 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.2047
Validation loss decreased (0.247988 --> 0.247444).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1261199
	speed: 0.0127s/iter; left time: 123.5168s
Epoch: 24 cost time: 1.5885205268859863
Epoch: 24, Steps: 128 Train Loss: 3.1610 (Forecasting Loss:0.2303 + XiCon Loss:2.9307 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2047
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.2480507
	speed: 0.0131s/iter; left time: 126.1596s
Epoch: 25 cost time: 1.6333601474761963
Epoch: 25, Steps: 128 Train Loss: 3.1458 (Forecasting Loss:0.2306 + XiCon Loss:2.9151 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2488976
	speed: 0.0125s/iter; left time: 118.6037s
Epoch: 26 cost time: 1.5949196815490723
Epoch: 26, Steps: 128 Train Loss: 3.1516 (Forecasting Loss:0.2304 + XiCon Loss:2.9212 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2047
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3953416
	speed: 0.0130s/iter; left time: 121.5384s
Epoch: 27 cost time: 1.624634027481079
Epoch: 27, Steps: 128 Train Loss: 3.1486 (Forecasting Loss:0.2306 + XiCon Loss:2.9180 x Lambda(1.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.2047
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1615243
	speed: 0.0126s/iter; left time: 116.4879s
Epoch: 28 cost time: 1.590965986251831
Epoch: 28, Steps: 128 Train Loss: 3.1493 (Forecasting Loss:0.2304 + XiCon Loss:2.9189 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.0758660
	speed: 0.0128s/iter; left time: 116.2448s
Epoch: 29 cost time: 1.5995769500732422
Epoch: 29, Steps: 128 Train Loss: 3.1608 (Forecasting Loss:0.2303 + XiCon Loss:2.9304 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2047
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.2329247
	speed: 0.0125s/iter; left time: 112.1033s
Epoch: 30 cost time: 1.5600194931030273
Epoch: 30, Steps: 128 Train Loss: 3.1543 (Forecasting Loss:0.2306 + XiCon Loss:2.9236 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.2047
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.1618280
	speed: 0.0127s/iter; left time: 112.7050s
Epoch: 31 cost time: 1.5905821323394775
Epoch: 31, Steps: 128 Train Loss: 3.1420 (Forecasting Loss:0.2304 + XiCon Loss:2.9115 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2047
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 2.9776971
	speed: 0.0128s/iter; left time: 111.9867s
Epoch: 32 cost time: 1.6104066371917725
Epoch: 32, Steps: 128 Train Loss: 3.1514 (Forecasting Loss:0.2304 + XiCon Loss:2.9210 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2047
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.3987739
	speed: 0.0128s/iter; left time: 110.1003s
Epoch: 33 cost time: 1.6419792175292969
Epoch: 33, Steps: 128 Train Loss: 3.1526 (Forecasting Loss:0.2306 + XiCon Loss:2.9220 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.2047
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13024909794330597, mae:0.2791312038898468, mape:0.6693992614746094, mspe:19.974611282348633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1909
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2533646
	speed: 0.0128s/iter; left time: 162.4316s
Epoch: 1 cost time: 1.5976672172546387
Epoch: 1, Steps: 128 Train Loss: 3.3179 (Forecasting Loss:0.2953 + XiCon Loss:3.0225 x Lambda(1.0)), Vali MSE Loss: 0.2734 Test MSE Loss: 0.2311
Validation loss decreased (inf --> 0.273429).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0651665
	speed: 0.0126s/iter; left time: 158.6928s
Epoch: 2 cost time: 1.5781185626983643
Epoch: 2, Steps: 128 Train Loss: 3.1075 (Forecasting Loss:0.2560 + XiCon Loss:2.8515 x Lambda(1.0)), Vali MSE Loss: 0.2633 Test MSE Loss: 0.2132
Validation loss decreased (0.273429 --> 0.263263).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 2.9173646
	speed: 0.0125s/iter; left time: 156.1048s
Epoch: 3 cost time: 1.572767972946167
Epoch: 3, Steps: 128 Train Loss: 3.0574 (Forecasting Loss:0.2421 + XiCon Loss:2.8153 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.2077
Validation loss decreased (0.263263 --> 0.251527).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1741436
	speed: 0.0129s/iter; left time: 158.9860s
Epoch: 4 cost time: 1.6247987747192383
Epoch: 4, Steps: 128 Train Loss: 3.1100 (Forecasting Loss:0.2365 + XiCon Loss:2.8735 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2116
Validation loss decreased (0.251527 --> 0.248513).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.2432237
	speed: 0.0126s/iter; left time: 154.1670s
Epoch: 5 cost time: 1.585564136505127
Epoch: 5, Steps: 128 Train Loss: 3.1662 (Forecasting Loss:0.2337 + XiCon Loss:2.9325 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.2041
Validation loss decreased (0.248513 --> 0.247429).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3003924
	speed: 0.0127s/iter; left time: 152.6210s
Epoch: 6 cost time: 1.5822193622589111
Epoch: 6, Steps: 128 Train Loss: 3.1846 (Forecasting Loss:0.2320 + XiCon Loss:2.9526 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.2078
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2138515
	speed: 0.0128s/iter; left time: 153.2232s
Epoch: 7 cost time: 1.6048448085784912
Epoch: 7, Steps: 128 Train Loss: 3.1851 (Forecasting Loss:0.2307 + XiCon Loss:2.9544 x Lambda(1.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.2066
Validation loss decreased (0.247429 --> 0.247059).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1643360
	speed: 0.0132s/iter; left time: 156.0027s
Epoch: 8 cost time: 1.6495928764343262
Epoch: 8, Steps: 128 Train Loss: 3.1941 (Forecasting Loss:0.2305 + XiCon Loss:2.9636 x Lambda(1.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.2062
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0436656
	speed: 0.0126s/iter; left time: 146.9759s
Epoch: 9 cost time: 1.5777480602264404
Epoch: 9, Steps: 128 Train Loss: 3.1857 (Forecasting Loss:0.2301 + XiCon Loss:2.9556 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.2065
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2914360
	speed: 0.0126s/iter; left time: 145.8052s
Epoch: 10 cost time: 1.5815162658691406
Epoch: 10, Steps: 128 Train Loss: 3.1776 (Forecasting Loss:0.2301 + XiCon Loss:2.9475 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2064
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1096053
	speed: 0.0126s/iter; left time: 144.1346s
Epoch: 11 cost time: 1.5905685424804688
Epoch: 11, Steps: 128 Train Loss: 3.1956 (Forecasting Loss:0.2300 + XiCon Loss:2.9656 x Lambda(1.0)), Vali MSE Loss: 0.2481 Test MSE Loss: 0.2064
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2046156
	speed: 0.0125s/iter; left time: 141.1318s
Epoch: 12 cost time: 1.5689043998718262
Epoch: 12, Steps: 128 Train Loss: 3.1770 (Forecasting Loss:0.2299 + XiCon Loss:2.9471 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.2064
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1524949
	speed: 0.0130s/iter; left time: 145.5249s
Epoch: 13 cost time: 1.6170783042907715
Epoch: 13, Steps: 128 Train Loss: 3.1887 (Forecasting Loss:0.2299 + XiCon Loss:2.9588 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.2064
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3080642
	speed: 0.0126s/iter; left time: 139.2837s
Epoch: 14 cost time: 1.5793664455413818
Epoch: 14, Steps: 128 Train Loss: 3.1820 (Forecasting Loss:0.2300 + XiCon Loss:2.9520 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.2064
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3925152
	speed: 0.0132s/iter; left time: 143.8253s
Epoch: 15 cost time: 1.6428108215332031
Epoch: 15, Steps: 128 Train Loss: 3.1938 (Forecasting Loss:0.2299 + XiCon Loss:2.9639 x Lambda(1.0)), Vali MSE Loss: 0.2486 Test MSE Loss: 0.2064
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2315812
	speed: 0.0125s/iter; left time: 134.3641s
Epoch: 16 cost time: 1.5652883052825928
Epoch: 16, Steps: 128 Train Loss: 3.1900 (Forecasting Loss:0.2299 + XiCon Loss:2.9601 x Lambda(1.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.2064
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0226438
	speed: 0.0131s/iter; left time: 139.4776s
Epoch: 17 cost time: 1.6251928806304932
Epoch: 17, Steps: 128 Train Loss: 3.1801 (Forecasting Loss:0.2298 + XiCon Loss:2.9503 x Lambda(1.0)), Vali MSE Loss: 0.2479 Test MSE Loss: 0.2064
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13210812211036682, mae:0.28111496567726135, mape:0.6671501994132996, mspe:19.604541778564453 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:71649
train 8209
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2252
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8209
val 2785
test 2785
	iters: 100, epoch: 1 | loss: 3.2590737
	speed: 0.0129s/iter; left time: 164.2567s
Epoch: 1 cost time: 1.6180498600006104
Epoch: 1, Steps: 128 Train Loss: 3.3210 (Forecasting Loss:0.2960 + XiCon Loss:3.0249 x Lambda(1.0)), Vali MSE Loss: 0.2730 Test MSE Loss: 0.2283
Validation loss decreased (inf --> 0.273037).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0786943
	speed: 0.0124s/iter; left time: 156.4114s
Epoch: 2 cost time: 1.5626187324523926
Epoch: 2, Steps: 128 Train Loss: 3.1334 (Forecasting Loss:0.2544 + XiCon Loss:2.8790 x Lambda(1.0)), Vali MSE Loss: 0.2581 Test MSE Loss: 0.2251
Validation loss decreased (0.273037 --> 0.258089).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3077908
	speed: 0.0127s/iter; left time: 158.0090s
Epoch: 3 cost time: 1.5911870002746582
Epoch: 3, Steps: 128 Train Loss: 3.1932 (Forecasting Loss:0.2424 + XiCon Loss:2.9508 x Lambda(1.0)), Vali MSE Loss: 0.2582 Test MSE Loss: 0.2176
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0993469
	speed: 0.0126s/iter; left time: 155.4337s
Epoch: 4 cost time: 1.5864417552947998
Epoch: 4, Steps: 128 Train Loss: 3.2109 (Forecasting Loss:0.2363 + XiCon Loss:2.9746 x Lambda(1.0)), Vali MSE Loss: 0.2509 Test MSE Loss: 0.2044
Validation loss decreased (0.258089 --> 0.250934).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1546879
	speed: 0.0127s/iter; left time: 154.4075s
Epoch: 5 cost time: 1.5850248336791992
Epoch: 5, Steps: 128 Train Loss: 3.2172 (Forecasting Loss:0.2310 + XiCon Loss:2.9862 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2094
Validation loss decreased (0.250934 --> 0.250309).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1251299
	speed: 0.0127s/iter; left time: 152.8693s
Epoch: 6 cost time: 1.584285020828247
Epoch: 6, Steps: 128 Train Loss: 3.2173 (Forecasting Loss:0.2286 + XiCon Loss:2.9887 x Lambda(1.0)), Vali MSE Loss: 0.2503 Test MSE Loss: 0.2080
Validation loss decreased (0.250309 --> 0.250268).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1751575
	speed: 0.0127s/iter; left time: 151.1378s
Epoch: 7 cost time: 1.5888826847076416
Epoch: 7, Steps: 128 Train Loss: 3.1867 (Forecasting Loss:0.2273 + XiCon Loss:2.9594 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2079
Validation loss decreased (0.250268 --> 0.250028).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1117811
	speed: 0.0133s/iter; left time: 156.8128s
Epoch: 8 cost time: 1.6611905097961426
Epoch: 8, Steps: 128 Train Loss: 3.2121 (Forecasting Loss:0.2271 + XiCon Loss:2.9850 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2072
Validation loss decreased (0.250028 --> 0.249752).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3121989
	speed: 0.0131s/iter; left time: 153.5151s
Epoch: 9 cost time: 1.6362535953521729
Epoch: 9, Steps: 128 Train Loss: 3.1935 (Forecasting Loss:0.2265 + XiCon Loss:2.9671 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2070
Validation loss decreased (0.249752 --> 0.249356).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1604807
	speed: 0.0127s/iter; left time: 146.8988s
Epoch: 10 cost time: 1.584686040878296
Epoch: 10, Steps: 128 Train Loss: 3.2069 (Forecasting Loss:0.2265 + XiCon Loss:2.9805 x Lambda(1.0)), Vali MSE Loss: 0.2492 Test MSE Loss: 0.2067
Validation loss decreased (0.249356 --> 0.249216).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1610022
	speed: 0.0128s/iter; left time: 146.2444s
Epoch: 11 cost time: 1.6286821365356445
Epoch: 11, Steps: 128 Train Loss: 3.2084 (Forecasting Loss:0.2262 + XiCon Loss:2.9822 x Lambda(1.0)), Vali MSE Loss: 0.2490 Test MSE Loss: 0.2067
Validation loss decreased (0.249216 --> 0.248974).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1329434
	speed: 0.0125s/iter; left time: 141.4522s
Epoch: 12 cost time: 1.5754876136779785
Epoch: 12, Steps: 128 Train Loss: 3.2122 (Forecasting Loss:0.2266 + XiCon Loss:2.9856 x Lambda(1.0)), Vali MSE Loss: 0.2500 Test MSE Loss: 0.2067
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1189692
	speed: 0.0126s/iter; left time: 140.1293s
Epoch: 13 cost time: 1.5733776092529297
Epoch: 13, Steps: 128 Train Loss: 3.2067 (Forecasting Loss:0.2263 + XiCon Loss:2.9805 x Lambda(1.0)), Vali MSE Loss: 0.2501 Test MSE Loss: 0.2067
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1722159
	speed: 0.0132s/iter; left time: 145.2945s
Epoch: 14 cost time: 1.671966552734375
Epoch: 14, Steps: 128 Train Loss: 3.2108 (Forecasting Loss:0.2264 + XiCon Loss:2.9845 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2067
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1683493
	speed: 0.0126s/iter; left time: 137.9033s
Epoch: 15 cost time: 1.590280294418335
Epoch: 15, Steps: 128 Train Loss: 3.2152 (Forecasting Loss:0.2263 + XiCon Loss:2.9889 x Lambda(1.0)), Vali MSE Loss: 0.2498 Test MSE Loss: 0.2067
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1955936
	speed: 0.0127s/iter; left time: 136.4665s
Epoch: 16 cost time: 1.5883593559265137
Epoch: 16, Steps: 128 Train Loss: 3.1998 (Forecasting Loss:0.2262 + XiCon Loss:2.9736 x Lambda(1.0)), Vali MSE Loss: 0.2495 Test MSE Loss: 0.2067
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.1920397
	speed: 0.0131s/iter; left time: 139.4979s
Epoch: 17 cost time: 1.6255199909210205
Epoch: 17, Steps: 128 Train Loss: 3.2112 (Forecasting Loss:0.2260 + XiCon Loss:2.9852 x Lambda(1.0)), Vali MSE Loss: 0.2496 Test MSE Loss: 0.2067
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2041118
	speed: 0.0126s/iter; left time: 132.8826s
Epoch: 18 cost time: 1.580583095550537
Epoch: 18, Steps: 128 Train Loss: 3.2062 (Forecasting Loss:0.2261 + XiCon Loss:2.9801 x Lambda(1.0)), Vali MSE Loss: 0.2494 Test MSE Loss: 0.2067
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1713643
	speed: 0.0127s/iter; left time: 132.2507s
Epoch: 19 cost time: 1.5979580879211426
Epoch: 19, Steps: 128 Train Loss: 3.2005 (Forecasting Loss:0.2262 + XiCon Loss:2.9743 x Lambda(1.0)), Vali MSE Loss: 0.2499 Test MSE Loss: 0.2067
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1669264
	speed: 0.0131s/iter; left time: 134.2521s
Epoch: 20 cost time: 1.662848949432373
Epoch: 20, Steps: 128 Train Loss: 3.2060 (Forecasting Loss:0.2260 + XiCon Loss:2.9800 x Lambda(1.0)), Vali MSE Loss: 0.2497 Test MSE Loss: 0.2067
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0962095
	speed: 0.0127s/iter; left time: 128.4936s
Epoch: 21 cost time: 1.5883684158325195
Epoch: 21, Steps: 128 Train Loss: 3.1995 (Forecasting Loss:0.2263 + XiCon Loss:2.9732 x Lambda(1.0)), Vali MSE Loss: 0.2493 Test MSE Loss: 0.2067
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl96_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2785
test shape: (43, 64, 96, 1) (43, 64, 96, 1)
test shape: (2752, 96, 1) (2752, 96, 1)
mse:0.13251453638076782, mae:0.28090524673461914, mape:0.6707698702812195, mspe:20.234865188598633 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1323+-0.00197, MAE:0.2811+-0.00215, MAPE:0.6704+-0.00882, MSPE:19.8256+-0.35893, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2772
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3192275
	speed: 0.0170s/iter; left time: 212.8806s
Epoch: 1 cost time: 2.0272412300109863
Epoch: 1, Steps: 126 Train Loss: 3.3384 (Forecasting Loss:0.3208 + XiCon Loss:3.0176 x Lambda(1.0)), Vali MSE Loss: 0.3105 Test MSE Loss: 0.2699
Validation loss decreased (inf --> 0.310503).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1114361
	speed: 0.0151s/iter; left time: 187.3517s
Epoch: 2 cost time: 1.8764517307281494
Epoch: 2, Steps: 126 Train Loss: 3.1420 (Forecasting Loss:0.2934 + XiCon Loss:2.8486 x Lambda(1.0)), Vali MSE Loss: 0.3021 Test MSE Loss: 0.2528
Validation loss decreased (0.310503 --> 0.302106).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1813138
	speed: 0.0157s/iter; left time: 192.1802s
Epoch: 3 cost time: 1.9438362121582031
Epoch: 3, Steps: 126 Train Loss: 3.1281 (Forecasting Loss:0.2793 + XiCon Loss:2.8488 x Lambda(1.0)), Vali MSE Loss: 0.2929 Test MSE Loss: 0.2581
Validation loss decreased (0.302106 --> 0.292884).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0496693
	speed: 0.0153s/iter; left time: 185.1255s
Epoch: 4 cost time: 1.908301591873169
Epoch: 4, Steps: 126 Train Loss: 3.1999 (Forecasting Loss:0.2715 + XiCon Loss:2.9283 x Lambda(1.0)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.2447
Validation loss decreased (0.292884 --> 0.292299).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3030987
	speed: 0.0155s/iter; left time: 186.3266s
Epoch: 5 cost time: 1.9340107440948486
Epoch: 5, Steps: 126 Train Loss: 3.2846 (Forecasting Loss:0.2691 + XiCon Loss:3.0155 x Lambda(1.0)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.2427
Validation loss decreased (0.292299 --> 0.288921).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2866356
	speed: 0.0156s/iter; left time: 185.3622s
Epoch: 6 cost time: 1.9599337577819824
Epoch: 6, Steps: 126 Train Loss: 3.2958 (Forecasting Loss:0.2672 + XiCon Loss:3.0287 x Lambda(1.0)), Vali MSE Loss: 0.2916 Test MSE Loss: 0.2440
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3682964
	speed: 0.0155s/iter; left time: 181.7873s
Epoch: 7 cost time: 1.931105375289917
Epoch: 7, Steps: 126 Train Loss: 3.2969 (Forecasting Loss:0.2662 + XiCon Loss:3.0307 x Lambda(1.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2430
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3351219
	speed: 0.0156s/iter; left time: 181.0838s
Epoch: 8 cost time: 1.9386019706726074
Epoch: 8, Steps: 126 Train Loss: 3.2804 (Forecasting Loss:0.2657 + XiCon Loss:3.0147 x Lambda(1.0)), Vali MSE Loss: 0.2910 Test MSE Loss: 0.2422
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3635244
	speed: 0.0156s/iter; left time: 179.5519s
Epoch: 9 cost time: 1.9512414932250977
Epoch: 9, Steps: 126 Train Loss: 3.2890 (Forecasting Loss:0.2655 + XiCon Loss:3.0236 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2427
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2499728
	speed: 0.0155s/iter; left time: 176.5394s
Epoch: 10 cost time: 1.9350481033325195
Epoch: 10, Steps: 126 Train Loss: 3.2875 (Forecasting Loss:0.2649 + XiCon Loss:3.0225 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2427
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4785976
	speed: 0.0158s/iter; left time: 177.5838s
Epoch: 11 cost time: 1.9747967720031738
Epoch: 11, Steps: 126 Train Loss: 3.2979 (Forecasting Loss:0.2651 + XiCon Loss:3.0328 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2425
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3206413
	speed: 0.0160s/iter; left time: 177.9339s
Epoch: 12 cost time: 1.982370138168335
Epoch: 12, Steps: 126 Train Loss: 3.2930 (Forecasting Loss:0.2649 + XiCon Loss:3.0281 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2425
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2936311
	speed: 0.0158s/iter; left time: 173.1523s
Epoch: 13 cost time: 1.956958293914795
Epoch: 13, Steps: 126 Train Loss: 3.2942 (Forecasting Loss:0.2652 + XiCon Loss:3.0290 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2425
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3781614
	speed: 0.0155s/iter; left time: 168.8660s
Epoch: 14 cost time: 1.9577515125274658
Epoch: 14, Steps: 126 Train Loss: 3.2835 (Forecasting Loss:0.2649 + XiCon Loss:3.0186 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2425
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3037245
	speed: 0.0158s/iter; left time: 169.5354s
Epoch: 15 cost time: 1.959545612335205
Epoch: 15, Steps: 126 Train Loss: 3.2942 (Forecasting Loss:0.2649 + XiCon Loss:3.0293 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2425
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1653098165988922, mae:0.3200238347053528, mape:0.6922218799591064, mspe:20.580751419067383 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2319
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3032362
	speed: 0.0142s/iter; left time: 176.9819s
Epoch: 1 cost time: 1.7425007820129395
Epoch: 1, Steps: 126 Train Loss: 3.3285 (Forecasting Loss:0.3178 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2665
Validation loss decreased (inf --> 0.307865).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1288073
	speed: 0.0156s/iter; left time: 192.7945s
Epoch: 2 cost time: 1.954103708267212
Epoch: 2, Steps: 126 Train Loss: 3.1463 (Forecasting Loss:0.2911 + XiCon Loss:2.8553 x Lambda(1.0)), Vali MSE Loss: 0.2977 Test MSE Loss: 0.2621
Validation loss decreased (0.307865 --> 0.297703).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1056504
	speed: 0.0152s/iter; left time: 185.8869s
Epoch: 3 cost time: 1.885075330734253
Epoch: 3, Steps: 126 Train Loss: 3.1086 (Forecasting Loss:0.2787 + XiCon Loss:2.8299 x Lambda(1.0)), Vali MSE Loss: 0.2884 Test MSE Loss: 0.2595
Validation loss decreased (0.297703 --> 0.288365).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3966656
	speed: 0.0161s/iter; left time: 194.9157s
Epoch: 4 cost time: 2.0065107345581055
Epoch: 4, Steps: 126 Train Loss: 3.1862 (Forecasting Loss:0.2722 + XiCon Loss:2.9140 x Lambda(1.0)), Vali MSE Loss: 0.2932 Test MSE Loss: 0.2425
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4534185
	speed: 0.0160s/iter; left time: 191.4407s
Epoch: 5 cost time: 1.978905439376831
Epoch: 5, Steps: 126 Train Loss: 3.3960 (Forecasting Loss:0.2675 + XiCon Loss:3.1285 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2428
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4196584
	speed: 0.0160s/iter; left time: 190.1719s
Epoch: 6 cost time: 1.983903169631958
Epoch: 6, Steps: 126 Train Loss: 3.4353 (Forecasting Loss:0.2661 + XiCon Loss:3.1692 x Lambda(1.0)), Vali MSE Loss: 0.2905 Test MSE Loss: 0.2413
EarlyStopping counter: 3 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2935531
	speed: 0.0159s/iter; left time: 187.0709s
Epoch: 7 cost time: 1.978003978729248
Epoch: 7, Steps: 126 Train Loss: 3.3986 (Forecasting Loss:0.2647 + XiCon Loss:3.1338 x Lambda(1.0)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.2396
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2707345
	speed: 0.0158s/iter; left time: 183.7778s
Epoch: 8 cost time: 1.9669852256774902
Epoch: 8, Steps: 126 Train Loss: 3.3669 (Forecasting Loss:0.2645 + XiCon Loss:3.1024 x Lambda(1.0)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.2401
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4192317
	speed: 0.0159s/iter; left time: 183.2837s
Epoch: 9 cost time: 1.984990119934082
Epoch: 9, Steps: 126 Train Loss: 3.3656 (Forecasting Loss:0.2640 + XiCon Loss:3.1016 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2404
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4134457
	speed: 0.0159s/iter; left time: 180.6385s
Epoch: 10 cost time: 1.9841456413269043
Epoch: 10, Steps: 126 Train Loss: 3.3671 (Forecasting Loss:0.2637 + XiCon Loss:3.1034 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2403
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3303862
	speed: 0.0162s/iter; left time: 181.6550s
Epoch: 11 cost time: 2.020648956298828
Epoch: 11, Steps: 126 Train Loss: 3.3587 (Forecasting Loss:0.2642 + XiCon Loss:3.0945 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2404
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4795458
	speed: 0.0159s/iter; left time: 176.9482s
Epoch: 12 cost time: 1.9870576858520508
Epoch: 12, Steps: 126 Train Loss: 3.3438 (Forecasting Loss:0.2639 + XiCon Loss:3.0799 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2404
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3461530
	speed: 0.0160s/iter; left time: 175.6114s
Epoch: 13 cost time: 1.9861631393432617
Epoch: 13, Steps: 126 Train Loss: 3.3587 (Forecasting Loss:0.2635 + XiCon Loss:3.0952 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2404
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.18365976214408875, mae:0.3354087769985199, mape:0.7122572064399719, mspe:22.49540901184082 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2383
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2256827
	speed: 0.0142s/iter; left time: 177.4860s
Epoch: 1 cost time: 1.7558660507202148
Epoch: 1, Steps: 126 Train Loss: 3.3200 (Forecasting Loss:0.3163 + XiCon Loss:3.0037 x Lambda(1.0)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2657
Validation loss decreased (inf --> 0.307876).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1693516
	speed: 0.0153s/iter; left time: 188.7889s
Epoch: 2 cost time: 1.8941304683685303
Epoch: 2, Steps: 126 Train Loss: 3.1438 (Forecasting Loss:0.2915 + XiCon Loss:2.8523 x Lambda(1.0)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2732
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3198450
	speed: 0.0158s/iter; left time: 193.2259s
Epoch: 3 cost time: 1.9623725414276123
Epoch: 3, Steps: 126 Train Loss: 3.1907 (Forecasting Loss:0.2795 + XiCon Loss:2.9112 x Lambda(1.0)), Vali MSE Loss: 0.2975 Test MSE Loss: 0.2596
Validation loss decreased (0.307876 --> 0.297534).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2091982
	speed: 0.0158s/iter; left time: 192.0887s
Epoch: 4 cost time: 1.9666731357574463
Epoch: 4, Steps: 126 Train Loss: 3.2594 (Forecasting Loss:0.2729 + XiCon Loss:2.9864 x Lambda(1.0)), Vali MSE Loss: 0.2904 Test MSE Loss: 0.2521
Validation loss decreased (0.297534 --> 0.290367).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.5398059
	speed: 0.0158s/iter; left time: 189.9032s
Epoch: 5 cost time: 1.9626085758209229
Epoch: 5, Steps: 126 Train Loss: 3.2593 (Forecasting Loss:0.2693 + XiCon Loss:2.9899 x Lambda(1.0)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.2467
Validation loss decreased (0.290367 --> 0.289575).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3150468
	speed: 0.0161s/iter; left time: 191.5299s
Epoch: 6 cost time: 1.991858720779419
Epoch: 6, Steps: 126 Train Loss: 3.2903 (Forecasting Loss:0.2681 + XiCon Loss:3.0222 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2472
Validation loss decreased (0.289575 --> 0.289234).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1758921
	speed: 0.0158s/iter; left time: 185.0727s
Epoch: 7 cost time: 1.954967975616455
Epoch: 7, Steps: 126 Train Loss: 3.2610 (Forecasting Loss:0.2669 + XiCon Loss:2.9941 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2462
Validation loss decreased (0.289234 --> 0.289214).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0047774
	speed: 0.0157s/iter; left time: 182.8810s
Epoch: 8 cost time: 1.9669175148010254
Epoch: 8, Steps: 126 Train Loss: 3.2612 (Forecasting Loss:0.2661 + XiCon Loss:2.9951 x Lambda(1.0)), Vali MSE Loss: 0.2897 Test MSE Loss: 0.2464
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2131979
	speed: 0.0159s/iter; left time: 182.6768s
Epoch: 9 cost time: 1.9929752349853516
Epoch: 9, Steps: 126 Train Loss: 3.2723 (Forecasting Loss:0.2660 + XiCon Loss:3.0063 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2467
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2452178
	speed: 0.0157s/iter; left time: 178.8352s
Epoch: 10 cost time: 1.9554719924926758
Epoch: 10, Steps: 126 Train Loss: 3.2556 (Forecasting Loss:0.2656 + XiCon Loss:2.9900 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2467
Validation loss decreased (0.289214 --> 0.289041).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3242342
	speed: 0.0157s/iter; left time: 176.1329s
Epoch: 11 cost time: 1.9524290561676025
Epoch: 11, Steps: 126 Train Loss: 3.2703 (Forecasting Loss:0.2659 + XiCon Loss:3.0044 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3548219
	speed: 0.0160s/iter; left time: 177.8912s
Epoch: 12 cost time: 1.9887945652008057
Epoch: 12, Steps: 126 Train Loss: 3.2683 (Forecasting Loss:0.2660 + XiCon Loss:3.0023 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2466
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2399495
	speed: 0.0158s/iter; left time: 173.9994s
Epoch: 13 cost time: 1.9681251049041748
Epoch: 13, Steps: 126 Train Loss: 3.2728 (Forecasting Loss:0.2653 + XiCon Loss:3.0074 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2883468
	speed: 0.0160s/iter; left time: 173.7322s
Epoch: 14 cost time: 1.9938757419586182
Epoch: 14, Steps: 126 Train Loss: 3.2675 (Forecasting Loss:0.2656 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3360369
	speed: 0.0156s/iter; left time: 167.8360s
Epoch: 15 cost time: 1.9468567371368408
Epoch: 15, Steps: 126 Train Loss: 3.2697 (Forecasting Loss:0.2657 + XiCon Loss:3.0040 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1452932
	speed: 0.0161s/iter; left time: 170.5806s
Epoch: 16 cost time: 1.9942059516906738
Epoch: 16, Steps: 126 Train Loss: 3.2699 (Forecasting Loss:0.2658 + XiCon Loss:3.0040 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4380474
	speed: 0.0158s/iter; left time: 165.6661s
Epoch: 17 cost time: 1.9573092460632324
Epoch: 17, Steps: 126 Train Loss: 3.2698 (Forecasting Loss:0.2657 + XiCon Loss:3.0041 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3226459
	speed: 0.0160s/iter; left time: 166.2009s
Epoch: 18 cost time: 1.996117115020752
Epoch: 18, Steps: 126 Train Loss: 3.2597 (Forecasting Loss:0.2659 + XiCon Loss:2.9938 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2458820
	speed: 0.0157s/iter; left time: 160.9189s
Epoch: 19 cost time: 1.9518649578094482
Epoch: 19, Steps: 126 Train Loss: 3.2669 (Forecasting Loss:0.2658 + XiCon Loss:3.0011 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1540694
	speed: 0.0157s/iter; left time: 158.4529s
Epoch: 20 cost time: 1.9507346153259277
Epoch: 20, Steps: 126 Train Loss: 3.2730 (Forecasting Loss:0.2658 + XiCon Loss:3.0072 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2466
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16910094022750854, mae:0.32431820034980774, mape:0.6752629280090332, mspe:19.823326110839844 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2059
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.3195059
	speed: 0.0145s/iter; left time: 181.0001s
Epoch: 1 cost time: 1.786339282989502
Epoch: 1, Steps: 126 Train Loss: 3.3552 (Forecasting Loss:0.3185 + XiCon Loss:3.0368 x Lambda(1.0)), Vali MSE Loss: 0.3079 Test MSE Loss: 0.2666
Validation loss decreased (inf --> 0.307896).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1487684
	speed: 0.0153s/iter; left time: 189.6794s
Epoch: 2 cost time: 1.8856346607208252
Epoch: 2, Steps: 126 Train Loss: 3.1519 (Forecasting Loss:0.2922 + XiCon Loss:2.8597 x Lambda(1.0)), Vali MSE Loss: 0.3081 Test MSE Loss: 0.2547
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1082585
	speed: 0.0155s/iter; left time: 189.5970s
Epoch: 3 cost time: 1.913205862045288
Epoch: 3, Steps: 126 Train Loss: 3.0928 (Forecasting Loss:0.2778 + XiCon Loss:2.8150 x Lambda(1.0)), Vali MSE Loss: 0.2949 Test MSE Loss: 0.2467
Validation loss decreased (0.307896 --> 0.294852).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1343348
	speed: 0.0160s/iter; left time: 193.8521s
Epoch: 4 cost time: 1.9798240661621094
Epoch: 4, Steps: 126 Train Loss: 3.1655 (Forecasting Loss:0.2744 + XiCon Loss:2.8911 x Lambda(1.0)), Vali MSE Loss: 0.2932 Test MSE Loss: 0.2496
Validation loss decreased (0.294852 --> 0.293228).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1553116
	speed: 0.0154s/iter; left time: 185.1201s
Epoch: 5 cost time: 1.934523582458496
Epoch: 5, Steps: 126 Train Loss: 3.1551 (Forecasting Loss:0.2697 + XiCon Loss:2.8854 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2492
Validation loss decreased (0.293228 --> 0.289909).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2261724
	speed: 0.0158s/iter; left time: 187.0709s
Epoch: 6 cost time: 1.9552483558654785
Epoch: 6, Steps: 126 Train Loss: 3.1607 (Forecasting Loss:0.2679 + XiCon Loss:2.8928 x Lambda(1.0)), Vali MSE Loss: 0.2904 Test MSE Loss: 0.2469
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1074545
	speed: 0.0160s/iter; left time: 187.4130s
Epoch: 7 cost time: 1.9748320579528809
Epoch: 7, Steps: 126 Train Loss: 3.1701 (Forecasting Loss:0.2667 + XiCon Loss:2.9033 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2461
Validation loss decreased (0.289909 --> 0.288800).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2006907
	speed: 0.0161s/iter; left time: 187.4604s
Epoch: 8 cost time: 2.022885799407959
Epoch: 8, Steps: 126 Train Loss: 3.1671 (Forecasting Loss:0.2664 + XiCon Loss:2.9008 x Lambda(1.0)), Vali MSE Loss: 0.2895 Test MSE Loss: 0.2451
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.9674306
	speed: 0.0159s/iter; left time: 182.6997s
Epoch: 9 cost time: 1.9723055362701416
Epoch: 9, Steps: 126 Train Loss: 3.1713 (Forecasting Loss:0.2663 + XiCon Loss:2.9050 x Lambda(1.0)), Vali MSE Loss: 0.2894 Test MSE Loss: 0.2451
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3512206
	speed: 0.0156s/iter; left time: 177.8146s
Epoch: 10 cost time: 1.9504263401031494
Epoch: 10, Steps: 126 Train Loss: 3.1640 (Forecasting Loss:0.2659 + XiCon Loss:2.8981 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2451
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1678786
	speed: 0.0158s/iter; left time: 177.5136s
Epoch: 11 cost time: 1.9653892517089844
Epoch: 11, Steps: 126 Train Loss: 3.1647 (Forecasting Loss:0.2661 + XiCon Loss:2.8986 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2453
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2273180
	speed: 0.0159s/iter; left time: 176.5917s
Epoch: 12 cost time: 1.9717967510223389
Epoch: 12, Steps: 126 Train Loss: 3.1668 (Forecasting Loss:0.2658 + XiCon Loss:2.9011 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2453
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0767601
	speed: 0.0161s/iter; left time: 177.4285s
Epoch: 13 cost time: 2.0098190307617188
Epoch: 13, Steps: 126 Train Loss: 3.1712 (Forecasting Loss:0.2656 + XiCon Loss:2.9056 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2452
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1581979
	speed: 0.0158s/iter; left time: 171.2575s
Epoch: 14 cost time: 1.958420753479004
Epoch: 14, Steps: 126 Train Loss: 3.1690 (Forecasting Loss:0.2661 + XiCon Loss:2.9029 x Lambda(1.0)), Vali MSE Loss: 0.2891 Test MSE Loss: 0.2452
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0736773
	speed: 0.0160s/iter; left time: 172.2013s
Epoch: 15 cost time: 2.0089681148529053
Epoch: 15, Steps: 126 Train Loss: 3.1656 (Forecasting Loss:0.2659 + XiCon Loss:2.8997 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2452
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1160841
	speed: 0.0161s/iter; left time: 171.2531s
Epoch: 16 cost time: 2.0111148357391357
Epoch: 16, Steps: 126 Train Loss: 3.1613 (Forecasting Loss:0.2658 + XiCon Loss:2.8955 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2452
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3298867
	speed: 0.0159s/iter; left time: 166.5617s
Epoch: 17 cost time: 1.9857885837554932
Epoch: 17, Steps: 126 Train Loss: 3.1702 (Forecasting Loss:0.2659 + XiCon Loss:2.9043 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2452
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.1686636060476303, mae:0.32357078790664673, mape:0.6793069243431091, mspe:20.028152465820312 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:136353
train 8113
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1691
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 8113
val 2689
test 2689
	iters: 100, epoch: 1 | loss: 3.2345355
	speed: 0.0141s/iter; left time: 176.0090s
Epoch: 1 cost time: 1.7476074695587158
Epoch: 1, Steps: 126 Train Loss: 3.3398 (Forecasting Loss:0.3186 + XiCon Loss:3.0212 x Lambda(1.0)), Vali MSE Loss: 0.3096 Test MSE Loss: 0.2643
Validation loss decreased (inf --> 0.309566).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0680048
	speed: 0.0150s/iter; left time: 186.0560s
Epoch: 2 cost time: 1.8711607456207275
Epoch: 2, Steps: 126 Train Loss: 3.1380 (Forecasting Loss:0.2904 + XiCon Loss:2.8476 x Lambda(1.0)), Vali MSE Loss: 0.3042 Test MSE Loss: 0.2592
Validation loss decreased (0.309566 --> 0.304222).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2205832
	speed: 0.0158s/iter; left time: 192.9739s
Epoch: 3 cost time: 1.9517500400543213
Epoch: 3, Steps: 126 Train Loss: 3.1539 (Forecasting Loss:0.2771 + XiCon Loss:2.8768 x Lambda(1.0)), Vali MSE Loss: 0.2907 Test MSE Loss: 0.2543
Validation loss decreased (0.304222 --> 0.290662).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2726703
	speed: 0.0160s/iter; left time: 193.8519s
Epoch: 4 cost time: 1.9814631938934326
Epoch: 4, Steps: 126 Train Loss: 3.2925 (Forecasting Loss:0.2711 + XiCon Loss:3.0214 x Lambda(1.0)), Vali MSE Loss: 0.2977 Test MSE Loss: 0.2462
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4334013
	speed: 0.0158s/iter; left time: 189.3756s
Epoch: 5 cost time: 1.9583911895751953
Epoch: 5, Steps: 126 Train Loss: 3.3456 (Forecasting Loss:0.2679 + XiCon Loss:3.0777 x Lambda(1.0)), Vali MSE Loss: 0.2914 Test MSE Loss: 0.2451
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4163718
	speed: 0.0156s/iter; left time: 184.8908s
Epoch: 6 cost time: 1.9649999141693115
Epoch: 6, Steps: 126 Train Loss: 3.3496 (Forecasting Loss:0.2657 + XiCon Loss:3.0839 x Lambda(1.0)), Vali MSE Loss: 0.2893 Test MSE Loss: 0.2448
Validation loss decreased (0.290662 --> 0.289258).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3569219
	speed: 0.0162s/iter; left time: 190.0954s
Epoch: 7 cost time: 1.999356985092163
Epoch: 7, Steps: 126 Train Loss: 3.3673 (Forecasting Loss:0.2650 + XiCon Loss:3.1023 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2450
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4562867
	speed: 0.0154s/iter; left time: 178.6030s
Epoch: 8 cost time: 1.9330449104309082
Epoch: 8, Steps: 126 Train Loss: 3.3835 (Forecasting Loss:0.2641 + XiCon Loss:3.1194 x Lambda(1.0)), Vali MSE Loss: 0.2908 Test MSE Loss: 0.2465
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2738566
	speed: 0.0154s/iter; left time: 176.8105s
Epoch: 9 cost time: 1.9144060611724854
Epoch: 9, Steps: 126 Train Loss: 3.3694 (Forecasting Loss:0.2638 + XiCon Loss:3.1057 x Lambda(1.0)), Vali MSE Loss: 0.2900 Test MSE Loss: 0.2467
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4261110
	speed: 0.0156s/iter; left time: 177.3816s
Epoch: 10 cost time: 1.941772699356079
Epoch: 10, Steps: 126 Train Loss: 3.3658 (Forecasting Loss:0.2638 + XiCon Loss:3.1020 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2464
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4183865
	speed: 0.0156s/iter; left time: 175.1207s
Epoch: 11 cost time: 1.950117588043213
Epoch: 11, Steps: 126 Train Loss: 3.3790 (Forecasting Loss:0.2640 + XiCon Loss:3.1149 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2465
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3536687
	speed: 0.0156s/iter; left time: 173.6816s
Epoch: 12 cost time: 1.944451093673706
Epoch: 12, Steps: 126 Train Loss: 3.3754 (Forecasting Loss:0.2638 + XiCon Loss:3.1116 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2465
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2873683
	speed: 0.0155s/iter; left time: 170.6710s
Epoch: 13 cost time: 1.9295809268951416
Epoch: 13, Steps: 126 Train Loss: 3.3697 (Forecasting Loss:0.2637 + XiCon Loss:3.1060 x Lambda(1.0)), Vali MSE Loss: 0.2901 Test MSE Loss: 0.2465
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2268500
	speed: 0.0159s/iter; left time: 173.1786s
Epoch: 14 cost time: 1.9759995937347412
Epoch: 14, Steps: 126 Train Loss: 3.3713 (Forecasting Loss:0.2637 + XiCon Loss:3.1077 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2465
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3801520
	speed: 0.0154s/iter; left time: 165.1909s
Epoch: 15 cost time: 1.9095065593719482
Epoch: 15, Steps: 126 Train Loss: 3.3721 (Forecasting Loss:0.2637 + XiCon Loss:3.1084 x Lambda(1.0)), Vali MSE Loss: 0.2902 Test MSE Loss: 0.2465
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.4130139
	speed: 0.0159s/iter; left time: 168.6461s
Epoch: 16 cost time: 1.9712891578674316
Epoch: 16, Steps: 126 Train Loss: 3.3674 (Forecasting Loss:0.2636 + XiCon Loss:3.1038 x Lambda(1.0)), Vali MSE Loss: 0.2903 Test MSE Loss: 0.2465
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl192_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2689
test shape: (42, 64, 192, 1) (42, 64, 192, 1)
test shape: (2688, 192, 1) (2688, 192, 1)
mse:0.16725021600723267, mae:0.32233989238739014, mape:0.6848030686378479, mspe:20.08650779724121 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1708+-0.00912, MAE:0.3251+-0.00741, MAPE:0.6888+-0.01811, MSPE:20.6028+-1.35831, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2283
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2900839
	speed: 0.0183s/iter; left time: 225.7202s
Epoch: 1 cost time: 2.175349235534668
Epoch: 1, Steps: 124 Train Loss: 3.3607 (Forecasting Loss:0.3417 + XiCon Loss:3.0190 x Lambda(1.0)), Vali MSE Loss: 0.3465 Test MSE Loss: 0.2927
Validation loss decreased (inf --> 0.346537).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1331596
	speed: 0.0180s/iter; left time: 218.6677s
Epoch: 2 cost time: 2.2251737117767334
Epoch: 2, Steps: 124 Train Loss: 3.1627 (Forecasting Loss:0.3134 + XiCon Loss:2.8493 x Lambda(1.0)), Vali MSE Loss: 0.3400 Test MSE Loss: 0.2887
Validation loss decreased (0.346537 --> 0.340022).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1583259
	speed: 0.0184s/iter; left time: 222.2821s
Epoch: 3 cost time: 2.2750258445739746
Epoch: 3, Steps: 124 Train Loss: 3.1860 (Forecasting Loss:0.3028 + XiCon Loss:2.8832 x Lambda(1.0)), Vali MSE Loss: 0.3309 Test MSE Loss: 0.2746
Validation loss decreased (0.340022 --> 0.330883).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3523798
	speed: 0.0189s/iter; left time: 225.5930s
Epoch: 4 cost time: 2.3357298374176025
Epoch: 4, Steps: 124 Train Loss: 3.2749 (Forecasting Loss:0.2955 + XiCon Loss:2.9794 x Lambda(1.0)), Vali MSE Loss: 0.3265 Test MSE Loss: 0.2762
Validation loss decreased (0.330883 --> 0.326524).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3569880
	speed: 0.0193s/iter; left time: 227.6956s
Epoch: 5 cost time: 2.3802340030670166
Epoch: 5, Steps: 124 Train Loss: 3.3042 (Forecasting Loss:0.2903 + XiCon Loss:3.0139 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2714
Validation loss decreased (0.326524 --> 0.322217).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3469944
	speed: 0.0189s/iter; left time: 220.4332s
Epoch: 6 cost time: 2.326364040374756
Epoch: 6, Steps: 124 Train Loss: 3.3004 (Forecasting Loss:0.2882 + XiCon Loss:3.0123 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2714
Validation loss decreased (0.322217 --> 0.322193).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2031832
	speed: 0.0188s/iter; left time: 217.5108s
Epoch: 7 cost time: 2.320178985595703
Epoch: 7, Steps: 124 Train Loss: 3.2959 (Forecasting Loss:0.2873 + XiCon Loss:3.0086 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2709
Validation loss decreased (0.322193 --> 0.320144).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.4609261
	speed: 0.0193s/iter; left time: 220.4065s
Epoch: 8 cost time: 2.3492863178253174
Epoch: 8, Steps: 124 Train Loss: 3.3161 (Forecasting Loss:0.2866 + XiCon Loss:3.0295 x Lambda(1.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2711
Validation loss decreased (0.320144 --> 0.319855).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3004839
	speed: 0.0193s/iter; left time: 217.9635s
Epoch: 9 cost time: 2.3699822425842285
Epoch: 9, Steps: 124 Train Loss: 3.3111 (Forecasting Loss:0.2865 + XiCon Loss:3.0246 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2711
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.5428545
	speed: 0.0195s/iter; left time: 218.6116s
Epoch: 10 cost time: 2.3944919109344482
Epoch: 10, Steps: 124 Train Loss: 3.3057 (Forecasting Loss:0.2862 + XiCon Loss:3.0195 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2710
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5131814
	speed: 0.0189s/iter; left time: 209.5109s
Epoch: 11 cost time: 2.3390419483184814
Epoch: 11, Steps: 124 Train Loss: 3.2927 (Forecasting Loss:0.2860 + XiCon Loss:3.0067 x Lambda(1.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2711
Validation loss decreased (0.319855 --> 0.319381).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1792712
	speed: 0.0188s/iter; left time: 206.0488s
Epoch: 12 cost time: 2.327300786972046
Epoch: 12, Steps: 124 Train Loss: 3.2938 (Forecasting Loss:0.2862 + XiCon Loss:3.0076 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2711
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.3154407
	speed: 0.0190s/iter; left time: 205.1841s
Epoch: 13 cost time: 2.3279199600219727
Epoch: 13, Steps: 124 Train Loss: 3.2979 (Forecasting Loss:0.2859 + XiCon Loss:3.0120 x Lambda(1.0)), Vali MSE Loss: 0.3202 Test MSE Loss: 0.2711
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3398571
	speed: 0.0191s/iter; left time: 204.1220s
Epoch: 14 cost time: 2.3465006351470947
Epoch: 14, Steps: 124 Train Loss: 3.2988 (Forecasting Loss:0.2859 + XiCon Loss:3.0128 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2711
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2928345
	speed: 0.0193s/iter; left time: 204.1449s
Epoch: 15 cost time: 2.390986204147339
Epoch: 15, Steps: 124 Train Loss: 3.2922 (Forecasting Loss:0.2858 + XiCon Loss:3.0064 x Lambda(1.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2711
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.2722671
	speed: 0.0191s/iter; left time: 199.3385s
Epoch: 16 cost time: 2.342040777206421
Epoch: 16, Steps: 124 Train Loss: 3.3185 (Forecasting Loss:0.2861 + XiCon Loss:3.0324 x Lambda(1.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2711
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2833107
	speed: 0.0186s/iter; left time: 192.1321s
Epoch: 17 cost time: 2.312577486038208
Epoch: 17, Steps: 124 Train Loss: 3.3009 (Forecasting Loss:0.2859 + XiCon Loss:3.0149 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2711
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3315203
	speed: 0.0191s/iter; left time: 194.9787s
Epoch: 18 cost time: 2.347574234008789
Epoch: 18, Steps: 124 Train Loss: 3.3029 (Forecasting Loss:0.2860 + XiCon Loss:3.0169 x Lambda(1.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2711
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4011238
	speed: 0.0190s/iter; left time: 191.0658s
Epoch: 19 cost time: 2.342850685119629
Epoch: 19, Steps: 124 Train Loss: 3.2969 (Forecasting Loss:0.2857 + XiCon Loss:3.0111 x Lambda(1.0)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2711
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.3117020
	speed: 0.0190s/iter; left time: 188.7871s
Epoch: 20 cost time: 2.3518333435058594
Epoch: 20, Steps: 124 Train Loss: 3.3104 (Forecasting Loss:0.2859 + XiCon Loss:3.0245 x Lambda(1.0)), Vali MSE Loss: 0.3200 Test MSE Loss: 0.2711
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2572029
	speed: 0.0193s/iter; left time: 189.9422s
Epoch: 21 cost time: 2.3663597106933594
Epoch: 21, Steps: 124 Train Loss: 3.3137 (Forecasting Loss:0.2860 + XiCon Loss:3.0277 x Lambda(1.0)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2711
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1910315752029419, mae:0.35118845105171204, mape:0.676259458065033, mspe:18.321168899536133 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2010
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2740357
	speed: 0.0154s/iter; left time: 189.8697s
Epoch: 1 cost time: 1.8937692642211914
Epoch: 1, Steps: 124 Train Loss: 3.3498 (Forecasting Loss:0.3370 + XiCon Loss:3.0128 x Lambda(1.0)), Vali MSE Loss: 0.3434 Test MSE Loss: 0.2853
Validation loss decreased (inf --> 0.343448).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2085352
	speed: 0.0181s/iter; left time: 220.7869s
Epoch: 2 cost time: 2.233541488647461
Epoch: 2, Steps: 124 Train Loss: 3.1871 (Forecasting Loss:0.3147 + XiCon Loss:2.8725 x Lambda(1.0)), Vali MSE Loss: 0.3348 Test MSE Loss: 0.2842
Validation loss decreased (0.343448 --> 0.334827).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.3560596
	speed: 0.0179s/iter; left time: 216.1801s
Epoch: 3 cost time: 2.2050788402557373
Epoch: 3, Steps: 124 Train Loss: 3.2989 (Forecasting Loss:0.3021 + XiCon Loss:2.9968 x Lambda(1.0)), Vali MSE Loss: 0.3376 Test MSE Loss: 0.2735
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3194847
	speed: 0.0184s/iter; left time: 219.4224s
Epoch: 4 cost time: 2.262587547302246
Epoch: 4, Steps: 124 Train Loss: 3.3846 (Forecasting Loss:0.2968 + XiCon Loss:3.0878 x Lambda(1.0)), Vali MSE Loss: 0.3305 Test MSE Loss: 0.2745
Validation loss decreased (0.334827 --> 0.330533).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4861174
	speed: 0.0186s/iter; left time: 219.3479s
Epoch: 5 cost time: 2.291973114013672
Epoch: 5, Steps: 124 Train Loss: 3.4217 (Forecasting Loss:0.2924 + XiCon Loss:3.1293 x Lambda(1.0)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2700
Validation loss decreased (0.330533 --> 0.326676).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4993174
	speed: 0.0186s/iter; left time: 217.4335s
Epoch: 6 cost time: 2.2813880443573
Epoch: 6, Steps: 124 Train Loss: 3.4272 (Forecasting Loss:0.2906 + XiCon Loss:3.1366 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2744
Validation loss decreased (0.326676 --> 0.322258).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.7029130
	speed: 0.0187s/iter; left time: 215.9297s
Epoch: 7 cost time: 2.318157911300659
Epoch: 7, Steps: 124 Train Loss: 3.4431 (Forecasting Loss:0.2900 + XiCon Loss:3.1531 x Lambda(1.0)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2731
Validation loss decreased (0.322258 --> 0.322218).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.5970984
	speed: 0.0185s/iter; left time: 211.0048s
Epoch: 8 cost time: 2.291313409805298
Epoch: 8, Steps: 124 Train Loss: 3.4344 (Forecasting Loss:0.2892 + XiCon Loss:3.1452 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2728
Validation loss decreased (0.322218 --> 0.321957).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.4673793
	speed: 0.0186s/iter; left time: 210.6064s
Epoch: 9 cost time: 2.2906880378723145
Epoch: 9, Steps: 124 Train Loss: 3.4427 (Forecasting Loss:0.2892 + XiCon Loss:3.1535 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2725
Validation loss decreased (0.321957 --> 0.321775).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.4563932
	speed: 0.0188s/iter; left time: 210.0217s
Epoch: 10 cost time: 2.3207881450653076
Epoch: 10, Steps: 124 Train Loss: 3.4178 (Forecasting Loss:0.2891 + XiCon Loss:3.1287 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2724
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.3792589
	speed: 0.0190s/iter; left time: 210.2080s
Epoch: 11 cost time: 2.331092596054077
Epoch: 11, Steps: 124 Train Loss: 3.4408 (Forecasting Loss:0.2888 + XiCon Loss:3.1520 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2725
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4795735
	speed: 0.0192s/iter; left time: 209.4779s
Epoch: 12 cost time: 2.3361713886260986
Epoch: 12, Steps: 124 Train Loss: 3.4255 (Forecasting Loss:0.2886 + XiCon Loss:3.1369 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2724
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.4608614
	speed: 0.0188s/iter; left time: 202.8432s
Epoch: 13 cost time: 2.304675340652466
Epoch: 13, Steps: 124 Train Loss: 3.4419 (Forecasting Loss:0.2887 + XiCon Loss:3.1531 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2725
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.7308319
	speed: 0.0186s/iter; left time: 198.3954s
Epoch: 14 cost time: 2.28342342376709
Epoch: 14, Steps: 124 Train Loss: 3.4268 (Forecasting Loss:0.2888 + XiCon Loss:3.1380 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2725
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3256776
	speed: 0.0188s/iter; left time: 198.3401s
Epoch: 15 cost time: 2.315919876098633
Epoch: 15, Steps: 124 Train Loss: 3.4361 (Forecasting Loss:0.2888 + XiCon Loss:3.1473 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2725
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3846331
	speed: 0.0187s/iter; left time: 195.2304s
Epoch: 16 cost time: 2.298840284347534
Epoch: 16, Steps: 124 Train Loss: 3.4315 (Forecasting Loss:0.2889 + XiCon Loss:3.1427 x Lambda(1.0)), Vali MSE Loss: 0.3224 Test MSE Loss: 0.2725
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.5231087
	speed: 0.0188s/iter; left time: 193.9369s
Epoch: 17 cost time: 2.3124618530273438
Epoch: 17, Steps: 124 Train Loss: 3.4407 (Forecasting Loss:0.2889 + XiCon Loss:3.1518 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2725
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.3747196
	speed: 0.0191s/iter; left time: 195.1878s
Epoch: 18 cost time: 2.346597194671631
Epoch: 18, Steps: 124 Train Loss: 3.4477 (Forecasting Loss:0.2888 + XiCon Loss:3.1589 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2725
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.4619133
	speed: 0.0187s/iter; left time: 188.4162s
Epoch: 19 cost time: 2.296841859817505
Epoch: 19, Steps: 124 Train Loss: 3.4355 (Forecasting Loss:0.2889 + XiCon Loss:3.1466 x Lambda(1.0)), Vali MSE Loss: 0.3226 Test MSE Loss: 0.2725
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.1919165551662445, mae:0.35305055975914, mape:0.6678350567817688, mspe:17.7309513092041 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3102
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2846897
	speed: 0.0157s/iter; left time: 193.4782s
Epoch: 1 cost time: 1.9217636585235596
Epoch: 1, Steps: 124 Train Loss: 3.3387 (Forecasting Loss:0.3414 + XiCon Loss:2.9973 x Lambda(1.0)), Vali MSE Loss: 0.3408 Test MSE Loss: 0.2853
Validation loss decreased (inf --> 0.340804).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1063774
	speed: 0.0191s/iter; left time: 232.6087s
Epoch: 2 cost time: 2.32079815864563
Epoch: 2, Steps: 124 Train Loss: 3.1689 (Forecasting Loss:0.3147 + XiCon Loss:2.8542 x Lambda(1.0)), Vali MSE Loss: 0.3367 Test MSE Loss: 0.2845
Validation loss decreased (0.340804 --> 0.336708).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1579309
	speed: 0.0184s/iter; left time: 221.3277s
Epoch: 3 cost time: 2.2692453861236572
Epoch: 3, Steps: 124 Train Loss: 3.1377 (Forecasting Loss:0.3031 + XiCon Loss:2.8346 x Lambda(1.0)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2727
Validation loss decreased (0.336708 --> 0.331539).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2371776
	speed: 0.0180s/iter; left time: 215.1026s
Epoch: 4 cost time: 2.217940092086792
Epoch: 4, Steps: 124 Train Loss: 3.2029 (Forecasting Loss:0.2963 + XiCon Loss:2.9065 x Lambda(1.0)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2783
Validation loss decreased (0.331539 --> 0.326042).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1590822
	speed: 0.0176s/iter; left time: 207.6161s
Epoch: 5 cost time: 2.1656782627105713
Epoch: 5, Steps: 124 Train Loss: 3.2376 (Forecasting Loss:0.2923 + XiCon Loss:2.9453 x Lambda(1.0)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2685
Validation loss decreased (0.326042 --> 0.323908).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2254684
	speed: 0.0176s/iter; left time: 205.6797s
Epoch: 6 cost time: 2.1760823726654053
Epoch: 6, Steps: 124 Train Loss: 3.2766 (Forecasting Loss:0.2899 + XiCon Loss:2.9867 x Lambda(1.0)), Vali MSE Loss: 0.3227 Test MSE Loss: 0.2704
Validation loss decreased (0.323908 --> 0.322706).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3728709
	speed: 0.0181s/iter; left time: 209.6833s
Epoch: 7 cost time: 2.2218334674835205
Epoch: 7, Steps: 124 Train Loss: 3.3091 (Forecasting Loss:0.2880 + XiCon Loss:3.0211 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2704
Validation loss decreased (0.322706 --> 0.321489).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3121800
	speed: 0.0183s/iter; left time: 208.7874s
Epoch: 8 cost time: 2.2480626106262207
Epoch: 8, Steps: 124 Train Loss: 3.3235 (Forecasting Loss:0.2874 + XiCon Loss:3.0361 x Lambda(1.0)), Vali MSE Loss: 0.3223 Test MSE Loss: 0.2679
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1280086
	speed: 0.0184s/iter; left time: 208.3272s
Epoch: 9 cost time: 2.256559133529663
Epoch: 9, Steps: 124 Train Loss: 3.3442 (Forecasting Loss:0.2867 + XiCon Loss:3.0575 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2661753
	speed: 0.0186s/iter; left time: 207.6941s
Epoch: 10 cost time: 2.2887074947357178
Epoch: 10, Steps: 124 Train Loss: 3.3337 (Forecasting Loss:0.2868 + XiCon Loss:3.0469 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2681
Validation loss decreased (0.321489 --> 0.321360).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.4280372
	speed: 0.0184s/iter; left time: 203.7424s
Epoch: 11 cost time: 2.266176223754883
Epoch: 11, Steps: 124 Train Loss: 3.3329 (Forecasting Loss:0.2861 + XiCon Loss:3.0468 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2681
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4991279
	speed: 0.0186s/iter; left time: 203.4051s
Epoch: 12 cost time: 2.2903871536254883
Epoch: 12, Steps: 124 Train Loss: 3.3409 (Forecasting Loss:0.2862 + XiCon Loss:3.0547 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2508543
	speed: 0.0184s/iter; left time: 198.9362s
Epoch: 13 cost time: 2.2598862648010254
Epoch: 13, Steps: 124 Train Loss: 3.3277 (Forecasting Loss:0.2861 + XiCon Loss:3.0415 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2681
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.3304706
	speed: 0.0185s/iter; left time: 197.2674s
Epoch: 14 cost time: 2.2685892581939697
Epoch: 14, Steps: 124 Train Loss: 3.3508 (Forecasting Loss:0.2862 + XiCon Loss:3.0646 x Lambda(1.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2681
Validation loss decreased (0.321360 --> 0.320978).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.4636590
	speed: 0.0183s/iter; left time: 193.2167s
Epoch: 15 cost time: 2.2535104751586914
Epoch: 15, Steps: 124 Train Loss: 3.3334 (Forecasting Loss:0.2863 + XiCon Loss:3.0471 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2681
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3062198
	speed: 0.0186s/iter; left time: 193.8244s
Epoch: 16 cost time: 2.2811684608459473
Epoch: 16, Steps: 124 Train Loss: 3.3369 (Forecasting Loss:0.2862 + XiCon Loss:3.0507 x Lambda(1.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4474611
	speed: 0.0183s/iter; left time: 189.1584s
Epoch: 17 cost time: 2.2599472999572754
Epoch: 17, Steps: 124 Train Loss: 3.3374 (Forecasting Loss:0.2863 + XiCon Loss:3.0511 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2681
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2970436
	speed: 0.0184s/iter; left time: 187.4828s
Epoch: 18 cost time: 2.266249656677246
Epoch: 18, Steps: 124 Train Loss: 3.3307 (Forecasting Loss:0.2863 + XiCon Loss:3.0444 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2681
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2053013
	speed: 0.0185s/iter; left time: 186.0898s
Epoch: 19 cost time: 2.268693208694458
Epoch: 19, Steps: 124 Train Loss: 3.3341 (Forecasting Loss:0.2863 + XiCon Loss:3.0478 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4937134
	speed: 0.0189s/iter; left time: 187.6040s
Epoch: 20 cost time: 2.3207266330718994
Epoch: 20, Steps: 124 Train Loss: 3.3429 (Forecasting Loss:0.2862 + XiCon Loss:3.0567 x Lambda(1.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3770866
	speed: 0.0184s/iter; left time: 180.2954s
Epoch: 21 cost time: 2.2514657974243164
Epoch: 21, Steps: 124 Train Loss: 3.3408 (Forecasting Loss:0.2865 + XiCon Loss:3.0543 x Lambda(1.0)), Vali MSE Loss: 0.3211 Test MSE Loss: 0.2681
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.4278431
	speed: 0.0187s/iter; left time: 180.9235s
Epoch: 22 cost time: 2.2962865829467773
Epoch: 22, Steps: 124 Train Loss: 3.3351 (Forecasting Loss:0.2864 + XiCon Loss:3.0487 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2681
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2782474
	speed: 0.0186s/iter; left time: 178.0357s
Epoch: 23 cost time: 2.2816338539123535
Epoch: 23, Steps: 124 Train Loss: 3.3415 (Forecasting Loss:0.2861 + XiCon Loss:3.0554 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2681
Validation loss decreased (0.320978 --> 0.320816).  Saving model ...
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.4640942
	speed: 0.0189s/iter; left time: 178.8398s
Epoch: 24 cost time: 2.3107876777648926
Epoch: 24, Steps: 124 Train Loss: 3.3386 (Forecasting Loss:0.2864 + XiCon Loss:3.0522 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2681
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.4689682
	speed: 0.0185s/iter; left time: 172.2331s
Epoch: 25 cost time: 2.2743613719940186
Epoch: 25, Steps: 124 Train Loss: 3.3246 (Forecasting Loss:0.2862 + XiCon Loss:3.0383 x Lambda(1.0)), Vali MSE Loss: 0.3217 Test MSE Loss: 0.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2911510
	speed: 0.0188s/iter; left time: 173.1371s
Epoch: 26 cost time: 2.3007116317749023
Epoch: 26, Steps: 124 Train Loss: 3.3321 (Forecasting Loss:0.2864 + XiCon Loss:3.0457 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2681
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.3985920
	speed: 0.0184s/iter; left time: 167.0666s
Epoch: 27 cost time: 2.2783279418945312
Epoch: 27, Steps: 124 Train Loss: 3.3342 (Forecasting Loss:0.2864 + XiCon Loss:3.0478 x Lambda(1.0)), Vali MSE Loss: 0.3221 Test MSE Loss: 0.2681
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.4223995
	speed: 0.0183s/iter; left time: 164.2652s
Epoch: 28 cost time: 2.2594401836395264
Epoch: 28, Steps: 124 Train Loss: 3.3258 (Forecasting Loss:0.2859 + XiCon Loss:3.0398 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.2412798
	speed: 0.0186s/iter; left time: 164.4780s
Epoch: 29 cost time: 2.277101516723633
Epoch: 29, Steps: 124 Train Loss: 3.3319 (Forecasting Loss:0.2862 + XiCon Loss:3.0458 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.4446959
	speed: 0.0183s/iter; left time: 159.1202s
Epoch: 30 cost time: 2.247169256210327
Epoch: 30, Steps: 124 Train Loss: 3.3378 (Forecasting Loss:0.2861 + XiCon Loss:3.0517 x Lambda(1.0)), Vali MSE Loss: 0.3225 Test MSE Loss: 0.2681
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.2734330
	speed: 0.0185s/iter; left time: 158.9397s
Epoch: 31 cost time: 2.264629364013672
Epoch: 31, Steps: 124 Train Loss: 3.3278 (Forecasting Loss:0.2865 + XiCon Loss:3.0413 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2681
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.3769364
	speed: 0.0186s/iter; left time: 157.5711s
Epoch: 32 cost time: 2.2828288078308105
Epoch: 32, Steps: 124 Train Loss: 3.3336 (Forecasting Loss:0.2864 + XiCon Loss:3.0472 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2681
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 3.2001061
	speed: 0.0189s/iter; left time: 157.1710s
Epoch: 33 cost time: 2.304762125015259
Epoch: 33, Steps: 124 Train Loss: 3.3251 (Forecasting Loss:0.2863 + XiCon Loss:3.0388 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2681
Validation loss decreased (0.320816 --> 0.320798).  Saving model ...
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 3.2933412
	speed: 0.0184s/iter; left time: 150.9009s
Epoch: 34 cost time: 2.2525815963745117
Epoch: 34, Steps: 124 Train Loss: 3.3380 (Forecasting Loss:0.2863 + XiCon Loss:3.0517 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2681
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 3.2890248
	speed: 0.0188s/iter; left time: 151.6929s
Epoch: 35 cost time: 2.298968553543091
Epoch: 35, Steps: 124 Train Loss: 3.3168 (Forecasting Loss:0.2863 + XiCon Loss:3.0305 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2681
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 3.3385756
	speed: 0.0187s/iter; left time: 148.5877s
Epoch: 36 cost time: 2.2919013500213623
Epoch: 36, Steps: 124 Train Loss: 3.3336 (Forecasting Loss:0.2862 + XiCon Loss:3.0473 x Lambda(1.0)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2681
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 3.3263814
	speed: 0.0189s/iter; left time: 148.0509s
Epoch: 37 cost time: 2.315924644470215
Epoch: 37, Steps: 124 Train Loss: 3.3295 (Forecasting Loss:0.2861 + XiCon Loss:3.0434 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2681
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 3.3886712
	speed: 0.0183s/iter; left time: 141.2868s
Epoch: 38 cost time: 2.2535696029663086
Epoch: 38, Steps: 124 Train Loss: 3.3214 (Forecasting Loss:0.2861 + XiCon Loss:3.0353 x Lambda(1.0)), Vali MSE Loss: 0.3212 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 3.2565038
	speed: 0.0185s/iter; left time: 140.5643s
Epoch: 39 cost time: 2.2876923084259033
Epoch: 39, Steps: 124 Train Loss: 3.3375 (Forecasting Loss:0.2862 + XiCon Loss:3.0513 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 3.4805744
	speed: 0.0185s/iter; left time: 138.2602s
Epoch: 40 cost time: 2.2854931354522705
Epoch: 40, Steps: 124 Train Loss: 3.3313 (Forecasting Loss:0.2861 + XiCon Loss:3.0452 x Lambda(1.0)), Vali MSE Loss: 0.3219 Test MSE Loss: 0.2681
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.094947017729283e-15
	iters: 100, epoch: 41 | loss: 3.3305271
	speed: 0.0185s/iter; left time: 135.7380s
Epoch: 41 cost time: 2.2744462490081787
Epoch: 41, Steps: 124 Train Loss: 3.3365 (Forecasting Loss:0.2861 + XiCon Loss:3.0504 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2681
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.547473508864641e-15
	iters: 100, epoch: 42 | loss: 3.3859720
	speed: 0.0186s/iter; left time: 134.4049s
Epoch: 42 cost time: 2.2936465740203857
Epoch: 42, Steps: 124 Train Loss: 3.3339 (Forecasting Loss:0.2861 + XiCon Loss:3.0478 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2681
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.2737367544323206e-15
	iters: 100, epoch: 43 | loss: 3.2686796
	speed: 0.0187s/iter; left time: 132.8888s
Epoch: 43 cost time: 2.2968666553497314
Epoch: 43, Steps: 124 Train Loss: 3.3364 (Forecasting Loss:0.2865 + XiCon Loss:3.0500 x Lambda(1.0)), Vali MSE Loss: 0.3214 Test MSE Loss: 0.2681
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.18721388280391693, mae:0.34901759028434753, mape:0.6739846467971802, mspe:18.055255889892578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2190
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.2695246
	speed: 0.0161s/iter; left time: 197.9424s
Epoch: 1 cost time: 1.9605565071105957
Epoch: 1, Steps: 124 Train Loss: 3.3604 (Forecasting Loss:0.3381 + XiCon Loss:3.0223 x Lambda(1.0)), Vali MSE Loss: 0.3405 Test MSE Loss: 0.2844
Validation loss decreased (inf --> 0.340455).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.0962090
	speed: 0.0185s/iter; left time: 225.0547s
Epoch: 2 cost time: 2.2627453804016113
Epoch: 2, Steps: 124 Train Loss: 3.1607 (Forecasting Loss:0.3148 + XiCon Loss:2.8458 x Lambda(1.0)), Vali MSE Loss: 0.3368 Test MSE Loss: 0.2890
Validation loss decreased (0.340455 --> 0.336760).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2407320
	speed: 0.0182s/iter; left time: 219.3360s
Epoch: 3 cost time: 2.2500548362731934
Epoch: 3, Steps: 124 Train Loss: 3.1650 (Forecasting Loss:0.3014 + XiCon Loss:2.8636 x Lambda(1.0)), Vali MSE Loss: 0.3330 Test MSE Loss: 0.2772
Validation loss decreased (0.336760 --> 0.332958).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.3580117
	speed: 0.0181s/iter; left time: 215.8645s
Epoch: 4 cost time: 2.2101235389709473
Epoch: 4, Steps: 124 Train Loss: 3.2442 (Forecasting Loss:0.2963 + XiCon Loss:2.9479 x Lambda(1.0)), Vali MSE Loss: 0.3260 Test MSE Loss: 0.2818
Validation loss decreased (0.332958 --> 0.325992).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3220325
	speed: 0.0181s/iter; left time: 213.3039s
Epoch: 5 cost time: 2.2105345726013184
Epoch: 5, Steps: 124 Train Loss: 3.3014 (Forecasting Loss:0.2916 + XiCon Loss:3.0098 x Lambda(1.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2732
Validation loss decreased (0.325992 --> 0.322905).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4757810
	speed: 0.0182s/iter; left time: 212.1322s
Epoch: 6 cost time: 2.246833324432373
Epoch: 6, Steps: 124 Train Loss: 3.3335 (Forecasting Loss:0.2884 + XiCon Loss:3.0451 x Lambda(1.0)), Vali MSE Loss: 0.3220 Test MSE Loss: 0.2723
Validation loss decreased (0.322905 --> 0.322034).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.3460612
	speed: 0.0179s/iter; left time: 206.5608s
Epoch: 7 cost time: 2.1912689208984375
Epoch: 7, Steps: 124 Train Loss: 3.3393 (Forecasting Loss:0.2873 + XiCon Loss:3.0519 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2737
Validation loss decreased (0.322034 --> 0.321470).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3797376
	speed: 0.0177s/iter; left time: 202.4856s
Epoch: 8 cost time: 2.1782734394073486
Epoch: 8, Steps: 124 Train Loss: 3.3492 (Forecasting Loss:0.2865 + XiCon Loss:3.0627 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2734
Validation loss decreased (0.321470 --> 0.320852).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.3764145
	speed: 0.0180s/iter; left time: 203.4500s
Epoch: 9 cost time: 2.193162202835083
Epoch: 9, Steps: 124 Train Loss: 3.3553 (Forecasting Loss:0.2861 + XiCon Loss:3.0692 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2733
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.3084462
	speed: 0.0178s/iter; left time: 199.4300s
Epoch: 10 cost time: 2.1948935985565186
Epoch: 10, Steps: 124 Train Loss: 3.3392 (Forecasting Loss:0.2859 + XiCon Loss:3.0533 x Lambda(1.0)), Vali MSE Loss: 0.3216 Test MSE Loss: 0.2730
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5343637
	speed: 0.0177s/iter; left time: 195.5392s
Epoch: 11 cost time: 2.2029364109039307
Epoch: 11, Steps: 124 Train Loss: 3.3407 (Forecasting Loss:0.2859 + XiCon Loss:3.0547 x Lambda(1.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2729
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.4051299
	speed: 0.0180s/iter; left time: 197.2932s
Epoch: 12 cost time: 2.2228639125823975
Epoch: 12, Steps: 124 Train Loss: 3.3597 (Forecasting Loss:0.2858 + XiCon Loss:3.0739 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2729
Validation loss decreased (0.320852 --> 0.320787).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.6466117
	speed: 0.0180s/iter; left time: 195.0935s
Epoch: 13 cost time: 2.210543394088745
Epoch: 13, Steps: 124 Train Loss: 3.3491 (Forecasting Loss:0.2857 + XiCon Loss:3.0633 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2729
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.4580667
	speed: 0.0181s/iter; left time: 193.3716s
Epoch: 14 cost time: 2.219968318939209
Epoch: 14, Steps: 124 Train Loss: 3.3504 (Forecasting Loss:0.2859 + XiCon Loss:3.0645 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2729
Validation loss decreased (0.320787 --> 0.320260).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.3607099
	speed: 0.0179s/iter; left time: 188.9727s
Epoch: 15 cost time: 2.1935760974884033
Epoch: 15, Steps: 124 Train Loss: 3.3485 (Forecasting Loss:0.2857 + XiCon Loss:3.0628 x Lambda(1.0)), Vali MSE Loss: 0.3215 Test MSE Loss: 0.2729
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3585227
	speed: 0.0181s/iter; left time: 188.9377s
Epoch: 16 cost time: 2.2137863636016846
Epoch: 16, Steps: 124 Train Loss: 3.3502 (Forecasting Loss:0.2860 + XiCon Loss:3.0641 x Lambda(1.0)), Vali MSE Loss: 0.3213 Test MSE Loss: 0.2729
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3873649
	speed: 0.0180s/iter; left time: 185.2606s
Epoch: 17 cost time: 2.2014565467834473
Epoch: 17, Steps: 124 Train Loss: 3.3544 (Forecasting Loss:0.2857 + XiCon Loss:3.0687 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2730
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.4833474
	speed: 0.0177s/iter; left time: 180.8594s
Epoch: 18 cost time: 2.1762280464172363
Epoch: 18, Steps: 124 Train Loss: 3.3532 (Forecasting Loss:0.2858 + XiCon Loss:3.0674 x Lambda(1.0)), Vali MSE Loss: 0.3210 Test MSE Loss: 0.2730
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2618666
	speed: 0.0179s/iter; left time: 180.7164s
Epoch: 19 cost time: 2.2248144149780273
Epoch: 19, Steps: 124 Train Loss: 3.3530 (Forecasting Loss:0.2856 + XiCon Loss:3.0674 x Lambda(1.0)), Vali MSE Loss: 0.3204 Test MSE Loss: 0.2729
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4019568
	speed: 0.0181s/iter; left time: 179.5760s
Epoch: 20 cost time: 2.2302134037017822
Epoch: 20, Steps: 124 Train Loss: 3.3538 (Forecasting Loss:0.2856 + XiCon Loss:3.0682 x Lambda(1.0)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2730
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.3793957
	speed: 0.0183s/iter; left time: 179.7237s
Epoch: 21 cost time: 2.2339930534362793
Epoch: 21, Steps: 124 Train Loss: 3.3476 (Forecasting Loss:0.2857 + XiCon Loss:3.0619 x Lambda(1.0)), Vali MSE Loss: 0.3209 Test MSE Loss: 0.2730
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2566557
	speed: 0.0181s/iter; left time: 175.3940s
Epoch: 22 cost time: 2.222562551498413
Epoch: 22, Steps: 124 Train Loss: 3.3454 (Forecasting Loss:0.2857 + XiCon Loss:3.0597 x Lambda(1.0)), Vali MSE Loss: 0.3208 Test MSE Loss: 0.2730
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2361445
	speed: 0.0177s/iter; left time: 169.6785s
Epoch: 23 cost time: 2.1803934574127197
Epoch: 23, Steps: 124 Train Loss: 3.3486 (Forecasting Loss:0.2857 + XiCon Loss:3.0629 x Lambda(1.0)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2730
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1637225
	speed: 0.0182s/iter; left time: 172.0218s
Epoch: 24 cost time: 2.2430310249328613
Epoch: 24, Steps: 124 Train Loss: 3.3556 (Forecasting Loss:0.2856 + XiCon Loss:3.0699 x Lambda(1.0)), Vali MSE Loss: 0.3205 Test MSE Loss: 0.2730
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19233615696430206, mae:0.3535348176956177, mape:0.6794325709342957, mspe:18.302942276000977 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 7969
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2319
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7969
val 2545
test 2545
	iters: 100, epoch: 1 | loss: 3.3132949
	speed: 0.0159s/iter; left time: 196.0111s
Epoch: 1 cost time: 1.9474828243255615
Epoch: 1, Steps: 124 Train Loss: 3.3185 (Forecasting Loss:0.3342 + XiCon Loss:2.9843 x Lambda(1.0)), Vali MSE Loss: 0.3408 Test MSE Loss: 0.2828
Validation loss decreased (inf --> 0.340783).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1338770
	speed: 0.0180s/iter; left time: 219.7071s
Epoch: 2 cost time: 2.211658477783203
Epoch: 2, Steps: 124 Train Loss: 3.1968 (Forecasting Loss:0.3155 + XiCon Loss:2.8814 x Lambda(1.0)), Vali MSE Loss: 0.3501 Test MSE Loss: 0.2942
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1528068
	speed: 0.0180s/iter; left time: 216.8965s
Epoch: 3 cost time: 2.2054970264434814
Epoch: 3, Steps: 124 Train Loss: 3.2497 (Forecasting Loss:0.3034 + XiCon Loss:2.9462 x Lambda(1.0)), Vali MSE Loss: 0.3288 Test MSE Loss: 0.2827
Validation loss decreased (0.340783 --> 0.328776).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.2202280
	speed: 0.0183s/iter; left time: 218.0242s
Epoch: 4 cost time: 2.242194175720215
Epoch: 4, Steps: 124 Train Loss: 3.2664 (Forecasting Loss:0.2964 + XiCon Loss:2.9699 x Lambda(1.0)), Vali MSE Loss: 0.3249 Test MSE Loss: 0.2774
Validation loss decreased (0.328776 --> 0.324857).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.4014721
	speed: 0.0182s/iter; left time: 214.8727s
Epoch: 5 cost time: 2.2261526584625244
Epoch: 5, Steps: 124 Train Loss: 3.3383 (Forecasting Loss:0.2933 + XiCon Loss:3.0450 x Lambda(1.0)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2751
Validation loss decreased (0.324857 --> 0.324043).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.4633830
	speed: 0.0184s/iter; left time: 214.6843s
Epoch: 6 cost time: 2.248011827468872
Epoch: 6, Steps: 124 Train Loss: 3.3407 (Forecasting Loss:0.2914 + XiCon Loss:3.0493 x Lambda(1.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2753
Validation loss decreased (0.324043 --> 0.323437).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.5082777
	speed: 0.0179s/iter; left time: 206.7722s
Epoch: 7 cost time: 2.2003724575042725
Epoch: 7, Steps: 124 Train Loss: 3.3612 (Forecasting Loss:0.2905 + XiCon Loss:3.0707 x Lambda(1.0)), Vali MSE Loss: 0.3231 Test MSE Loss: 0.2729
Validation loss decreased (0.323437 --> 0.323116).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.3275800
	speed: 0.0183s/iter; left time: 209.5141s
Epoch: 8 cost time: 2.247553825378418
Epoch: 8, Steps: 124 Train Loss: 3.3652 (Forecasting Loss:0.2897 + XiCon Loss:3.0755 x Lambda(1.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2739
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2193146
	speed: 0.0185s/iter; left time: 209.6526s
Epoch: 9 cost time: 2.2789478302001953
Epoch: 9, Steps: 124 Train Loss: 3.3478 (Forecasting Loss:0.2896 + XiCon Loss:3.0582 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2738
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.2928760
	speed: 0.0187s/iter; left time: 208.6320s
Epoch: 10 cost time: 2.2915401458740234
Epoch: 10, Steps: 124 Train Loss: 3.3441 (Forecasting Loss:0.2894 + XiCon Loss:3.0547 x Lambda(1.0)), Vali MSE Loss: 0.3229 Test MSE Loss: 0.2735
Validation loss decreased (0.323116 --> 0.322910).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.5413873
	speed: 0.0182s/iter; left time: 201.3374s
Epoch: 11 cost time: 2.2356326580047607
Epoch: 11, Steps: 124 Train Loss: 3.3513 (Forecasting Loss:0.2892 + XiCon Loss:3.0621 x Lambda(1.0)), Vali MSE Loss: 0.3228 Test MSE Loss: 0.2736
Validation loss decreased (0.322910 --> 0.322771).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.3723207
	speed: 0.0184s/iter; left time: 200.9998s
Epoch: 12 cost time: 2.2502920627593994
Epoch: 12, Steps: 124 Train Loss: 3.3506 (Forecasting Loss:0.2891 + XiCon Loss:3.0615 x Lambda(1.0)), Vali MSE Loss: 0.3240 Test MSE Loss: 0.2736
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.2040293
	speed: 0.0184s/iter; left time: 199.0918s
Epoch: 13 cost time: 2.2598838806152344
Epoch: 13, Steps: 124 Train Loss: 3.3368 (Forecasting Loss:0.2894 + XiCon Loss:3.0474 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2736
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2705781
	speed: 0.0183s/iter; left time: 196.0383s
Epoch: 14 cost time: 2.256523370742798
Epoch: 14, Steps: 124 Train Loss: 3.3391 (Forecasting Loss:0.2892 + XiCon Loss:3.0499 x Lambda(1.0)), Vali MSE Loss: 0.3233 Test MSE Loss: 0.2736
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2421575
	speed: 0.0188s/iter; left time: 199.1261s
Epoch: 15 cost time: 2.3000431060791016
Epoch: 15, Steps: 124 Train Loss: 3.3433 (Forecasting Loss:0.2892 + XiCon Loss:3.0541 x Lambda(1.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2736
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.3537881
	speed: 0.0182s/iter; left time: 190.1347s
Epoch: 16 cost time: 2.2328174114227295
Epoch: 16, Steps: 124 Train Loss: 3.3383 (Forecasting Loss:0.2890 + XiCon Loss:3.0493 x Lambda(1.0)), Vali MSE Loss: 0.3243 Test MSE Loss: 0.2736
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.4082167
	speed: 0.0185s/iter; left time: 190.4055s
Epoch: 17 cost time: 2.279947280883789
Epoch: 17, Steps: 124 Train Loss: 3.3458 (Forecasting Loss:0.2890 + XiCon Loss:3.0568 x Lambda(1.0)), Vali MSE Loss: 0.3235 Test MSE Loss: 0.2736
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.5830724
	speed: 0.0187s/iter; left time: 190.6746s
Epoch: 18 cost time: 2.299473524093628
Epoch: 18, Steps: 124 Train Loss: 3.3465 (Forecasting Loss:0.2893 + XiCon Loss:3.0572 x Lambda(1.0)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2736
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3281920
	speed: 0.0184s/iter; left time: 185.4979s
Epoch: 19 cost time: 2.252751350402832
Epoch: 19, Steps: 124 Train Loss: 3.3540 (Forecasting Loss:0.2893 + XiCon Loss:3.0648 x Lambda(1.0)), Vali MSE Loss: 0.3232 Test MSE Loss: 0.2736
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.4506810
	speed: 0.0182s/iter; left time: 181.2117s
Epoch: 20 cost time: 2.2403829097747803
Epoch: 20, Steps: 124 Train Loss: 3.3408 (Forecasting Loss:0.2893 + XiCon Loss:3.0515 x Lambda(1.0)), Vali MSE Loss: 0.3234 Test MSE Loss: 0.2736
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.4506931
	speed: 0.0184s/iter; left time: 180.2951s
Epoch: 21 cost time: 2.2513375282287598
Epoch: 21, Steps: 124 Train Loss: 3.3393 (Forecasting Loss:0.2892 + XiCon Loss:3.0501 x Lambda(1.0)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2736
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2545
test shape: (39, 64, 336, 1) (39, 64, 336, 1)
test shape: (2496, 336, 1) (2496, 336, 1)
mse:0.19268004596233368, mae:0.3544246554374695, mape:0.6736693382263184, mspe:17.842388153076172 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1910+-0.00276, MAE:0.3522+-0.00268, MAPE:0.6742+-0.00528, MSPE:18.0505+-0.32994, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.001, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTh2', root_path='./dataset/ETT-small', data_path='ETTh2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=7, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.3037
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4553461
	speed: 0.0198s/iter; left time: 231.4216s
Epoch: 1 cost time: 2.2710587978363037
Epoch: 1, Steps: 118 Train Loss: 0.4767 (Forecasting Loss:0.4736 + XiCon Loss:3.0892 x Lambda(0.001)), Vali MSE Loss: 0.4757 Test MSE Loss: 0.3612
Validation loss decreased (inf --> 0.475686).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3711855
	speed: 0.0164s/iter; left time: 189.4846s
Epoch: 2 cost time: 1.9210057258605957
Epoch: 2, Steps: 118 Train Loss: 0.3497 (Forecasting Loss:0.3466 + XiCon Loss:3.0891 x Lambda(0.001)), Vali MSE Loss: 0.3780 Test MSE Loss: 0.2872
Validation loss decreased (0.475686 --> 0.377951).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.3063914
	speed: 0.0159s/iter; left time: 182.3491s
Epoch: 3 cost time: 1.8671462535858154
Epoch: 3, Steps: 118 Train Loss: 0.3135 (Forecasting Loss:0.3104 + XiCon Loss:3.0876 x Lambda(0.001)), Vali MSE Loss: 0.3737 Test MSE Loss: 0.2778
Validation loss decreased (0.377951 --> 0.373673).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.3192182
	speed: 0.0161s/iter; left time: 183.2036s
Epoch: 4 cost time: 1.8968701362609863
Epoch: 4, Steps: 118 Train Loss: 0.3086 (Forecasting Loss:0.3056 + XiCon Loss:3.0830 x Lambda(0.001)), Vali MSE Loss: 0.3752 Test MSE Loss: 0.2798
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.3112355
	speed: 0.0162s/iter; left time: 181.6965s
Epoch: 5 cost time: 1.8978421688079834
Epoch: 5, Steps: 118 Train Loss: 0.3065 (Forecasting Loss:0.3034 + XiCon Loss:3.0829 x Lambda(0.001)), Vali MSE Loss: 0.3832 Test MSE Loss: 0.2812
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2906520
	speed: 0.0163s/iter; left time: 181.3024s
Epoch: 6 cost time: 1.909644603729248
Epoch: 6, Steps: 118 Train Loss: 0.3054 (Forecasting Loss:0.3023 + XiCon Loss:3.0850 x Lambda(0.001)), Vali MSE Loss: 0.3788 Test MSE Loss: 0.2802
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.3088054
	speed: 0.0160s/iter; left time: 176.1199s
Epoch: 7 cost time: 1.879991054534912
Epoch: 7, Steps: 118 Train Loss: 0.3055 (Forecasting Loss:0.3025 + XiCon Loss:3.0823 x Lambda(0.001)), Vali MSE Loss: 0.3760 Test MSE Loss: 0.2805
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2894976
	speed: 0.0160s/iter; left time: 174.2692s
Epoch: 8 cost time: 1.8782727718353271
Epoch: 8, Steps: 118 Train Loss: 0.3045 (Forecasting Loss:0.3015 + XiCon Loss:3.0839 x Lambda(0.001)), Vali MSE Loss: 0.3755 Test MSE Loss: 0.2808
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.3027896
	speed: 0.0161s/iter; left time: 172.9176s
Epoch: 9 cost time: 1.8801074028015137
Epoch: 9, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3017 + XiCon Loss:3.0840 x Lambda(0.001)), Vali MSE Loss: 0.3771 Test MSE Loss: 0.2808
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.3063556
	speed: 0.0158s/iter; left time: 168.5943s
Epoch: 10 cost time: 1.861069917678833
Epoch: 10, Steps: 118 Train Loss: 0.3047 (Forecasting Loss:0.3016 + XiCon Loss:3.0847 x Lambda(0.001)), Vali MSE Loss: 0.3773 Test MSE Loss: 0.2808
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2957335
	speed: 0.0160s/iter; left time: 167.8999s
Epoch: 11 cost time: 1.8701002597808838
Epoch: 11, Steps: 118 Train Loss: 0.3048 (Forecasting Loss:0.3017 + XiCon Loss:3.0852 x Lambda(0.001)), Vali MSE Loss: 0.3765 Test MSE Loss: 0.2808
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.3164310
	speed: 0.0159s/iter; left time: 165.0804s
Epoch: 12 cost time: 1.8620715141296387
Epoch: 12, Steps: 118 Train Loss: 0.3047 (Forecasting Loss:0.3016 + XiCon Loss:3.0861 x Lambda(0.001)), Vali MSE Loss: 0.3770 Test MSE Loss: 0.2808
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2932218
	speed: 0.0161s/iter; left time: 165.7368s
Epoch: 13 cost time: 1.8874318599700928
Epoch: 13, Steps: 118 Train Loss: 0.3045 (Forecasting Loss:0.3014 + XiCon Loss:3.0819 x Lambda(0.001)), Vali MSE Loss: 0.3768 Test MSE Loss: 0.2808
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.19793325662612915, mae:0.3575948178768158, mape:0.6931772232055664, mspe:23.375370025634766 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1754
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4365259
	speed: 0.0161s/iter; left time: 188.4147s
Epoch: 1 cost time: 1.9005753993988037
Epoch: 1, Steps: 118 Train Loss: 0.4716 (Forecasting Loss:0.4685 + XiCon Loss:3.0983 x Lambda(0.001)), Vali MSE Loss: 0.4889 Test MSE Loss: 0.3764
Validation loss decreased (inf --> 0.488925).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3000395
	speed: 0.0163s/iter; left time: 188.5472s
Epoch: 2 cost time: 1.9070544242858887
Epoch: 2, Steps: 118 Train Loss: 0.3484 (Forecasting Loss:0.3453 + XiCon Loss:3.1047 x Lambda(0.001)), Vali MSE Loss: 0.3577 Test MSE Loss: 0.2694
Validation loss decreased (0.488925 --> 0.357698).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2867369
	speed: 0.0164s/iter; left time: 187.5803s
Epoch: 3 cost time: 1.9271323680877686
Epoch: 3, Steps: 118 Train Loss: 0.2813 (Forecasting Loss:0.2781 + XiCon Loss:3.1141 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2673
Validation loss decreased (0.357698 --> 0.315699).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2612010
	speed: 0.0168s/iter; left time: 190.9570s
Epoch: 4 cost time: 1.9828414916992188
Epoch: 4, Steps: 118 Train Loss: 0.2714 (Forecasting Loss:0.2683 + XiCon Loss:3.1104 x Lambda(0.001)), Vali MSE Loss: 0.3120 Test MSE Loss: 0.2658
Validation loss decreased (0.315699 --> 0.311975).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2669691
	speed: 0.0169s/iter; left time: 189.3743s
Epoch: 5 cost time: 1.983072280883789
Epoch: 5, Steps: 118 Train Loss: 0.2683 (Forecasting Loss:0.2652 + XiCon Loss:3.1059 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2663
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2559334
	speed: 0.0170s/iter; left time: 188.5322s
Epoch: 6 cost time: 1.991441011428833
Epoch: 6, Steps: 118 Train Loss: 0.2668 (Forecasting Loss:0.2637 + XiCon Loss:3.1030 x Lambda(0.001)), Vali MSE Loss: 0.3113 Test MSE Loss: 0.2678
Validation loss decreased (0.311975 --> 0.311274).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2711596
	speed: 0.0169s/iter; left time: 185.9876s
Epoch: 7 cost time: 1.9923856258392334
Epoch: 7, Steps: 118 Train Loss: 0.2660 (Forecasting Loss:0.2629 + XiCon Loss:3.1044 x Lambda(0.001)), Vali MSE Loss: 0.3129 Test MSE Loss: 0.2679
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2566593
	speed: 0.0170s/iter; left time: 185.0824s
Epoch: 8 cost time: 1.9977741241455078
Epoch: 8, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2627 + XiCon Loss:3.1032 x Lambda(0.001)), Vali MSE Loss: 0.3117 Test MSE Loss: 0.2684
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2516386
	speed: 0.0171s/iter; left time: 183.6195s
Epoch: 9 cost time: 2.0031797885894775
Epoch: 9, Steps: 118 Train Loss: 0.2657 (Forecasting Loss:0.2626 + XiCon Loss:3.1023 x Lambda(0.001)), Vali MSE Loss: 0.3142 Test MSE Loss: 0.2676
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2709511
	speed: 0.0168s/iter; left time: 178.7508s
Epoch: 10 cost time: 1.9784314632415771
Epoch: 10, Steps: 118 Train Loss: 0.2658 (Forecasting Loss:0.2627 + XiCon Loss:3.1020 x Lambda(0.001)), Vali MSE Loss: 0.3131 Test MSE Loss: 0.2682
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2758023
	speed: 0.0170s/iter; left time: 179.0027s
Epoch: 11 cost time: 1.9932820796966553
Epoch: 11, Steps: 118 Train Loss: 0.2654 (Forecasting Loss:0.2623 + XiCon Loss:3.1032 x Lambda(0.001)), Vali MSE Loss: 0.3137 Test MSE Loss: 0.2681
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2580596
	speed: 0.0169s/iter; left time: 175.6581s
Epoch: 12 cost time: 1.9763832092285156
Epoch: 12, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1050 x Lambda(0.001)), Vali MSE Loss: 0.3136 Test MSE Loss: 0.2681
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2824108
	speed: 0.0171s/iter; left time: 175.7768s
Epoch: 13 cost time: 1.9995300769805908
Epoch: 13, Steps: 118 Train Loss: 0.2653 (Forecasting Loss:0.2622 + XiCon Loss:3.1035 x Lambda(0.001)), Vali MSE Loss: 0.3134 Test MSE Loss: 0.2680
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2550620
	speed: 0.0170s/iter; left time: 172.3602s
Epoch: 14 cost time: 1.9898676872253418
Epoch: 14, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1018 x Lambda(0.001)), Vali MSE Loss: 0.3128 Test MSE Loss: 0.2680
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2687141
	speed: 0.0169s/iter; left time: 169.5946s
Epoch: 15 cost time: 1.9805779457092285
Epoch: 15, Steps: 118 Train Loss: 0.2655 (Forecasting Loss:0.2624 + XiCon Loss:3.1054 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2680
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2608499
	speed: 0.0168s/iter; left time: 166.8288s
Epoch: 16 cost time: 1.9749689102172852
Epoch: 16, Steps: 118 Train Loss: 0.2652 (Forecasting Loss:0.2621 + XiCon Loss:3.1027 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2680
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.18608886003494263, mae:0.34956374764442444, mape:0.6738387942314148, mspe:18.211875915527344 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2033
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4507197
	speed: 0.0163s/iter; left time: 190.2627s
Epoch: 1 cost time: 1.9103026390075684
Epoch: 1, Steps: 118 Train Loss: 0.4724 (Forecasting Loss:0.4693 + XiCon Loss:3.0845 x Lambda(0.001)), Vali MSE Loss: 0.4768 Test MSE Loss: 0.3596
Validation loss decreased (inf --> 0.476793).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.2846698
	speed: 0.0163s/iter; left time: 188.2403s
Epoch: 2 cost time: 1.9372012615203857
Epoch: 2, Steps: 118 Train Loss: 0.3435 (Forecasting Loss:0.3404 + XiCon Loss:3.0663 x Lambda(0.001)), Vali MSE Loss: 0.3616 Test MSE Loss: 0.2609
Validation loss decreased (0.476793 --> 0.361580).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2800289
	speed: 0.0178s/iter; left time: 203.5096s
Epoch: 3 cost time: 2.0902953147888184
Epoch: 3, Steps: 118 Train Loss: 0.2830 (Forecasting Loss:0.2799 + XiCon Loss:3.0512 x Lambda(0.001)), Vali MSE Loss: 0.3386 Test MSE Loss: 0.2589
Validation loss decreased (0.361580 --> 0.338561).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2749145
	speed: 0.0178s/iter; left time: 202.3401s
Epoch: 4 cost time: 2.094679832458496
Epoch: 4, Steps: 118 Train Loss: 0.2753 (Forecasting Loss:0.2722 + XiCon Loss:3.0527 x Lambda(0.001)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2584
Validation loss decreased (0.338561 --> 0.318051).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2665961
	speed: 0.0180s/iter; left time: 201.8403s
Epoch: 5 cost time: 2.1103711128234863
Epoch: 5, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2687 + XiCon Loss:3.0494 x Lambda(0.001)), Vali MSE Loss: 0.3148 Test MSE Loss: 0.2577
Validation loss decreased (0.318051 --> 0.314842).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2838434
	speed: 0.0183s/iter; left time: 202.8223s
Epoch: 6 cost time: 2.1451590061187744
Epoch: 6, Steps: 118 Train Loss: 0.2704 (Forecasting Loss:0.2673 + XiCon Loss:3.0479 x Lambda(0.001)), Vali MSE Loss: 0.3132 Test MSE Loss: 0.2592
Validation loss decreased (0.314842 --> 0.313247).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2654099
	speed: 0.0183s/iter; left time: 200.7743s
Epoch: 7 cost time: 2.1392626762390137
Epoch: 7, Steps: 118 Train Loss: 0.2696 (Forecasting Loss:0.2665 + XiCon Loss:3.0496 x Lambda(0.001)), Vali MSE Loss: 0.3218 Test MSE Loss: 0.2586
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2600400
	speed: 0.0179s/iter; left time: 194.1453s
Epoch: 8 cost time: 2.105747938156128
Epoch: 8, Steps: 118 Train Loss: 0.2692 (Forecasting Loss:0.2661 + XiCon Loss:3.0467 x Lambda(0.001)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.2593
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2758695
	speed: 0.0181s/iter; left time: 194.2412s
Epoch: 9 cost time: 2.132612466812134
Epoch: 9, Steps: 118 Train Loss: 0.2693 (Forecasting Loss:0.2662 + XiCon Loss:3.0495 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2591
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2676582
	speed: 0.0184s/iter; left time: 195.5017s
Epoch: 10 cost time: 2.168877124786377
Epoch: 10, Steps: 118 Train Loss: 0.2688 (Forecasting Loss:0.2658 + XiCon Loss:3.0473 x Lambda(0.001)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.2593
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2745420
	speed: 0.0186s/iter; left time: 195.4329s
Epoch: 11 cost time: 2.1716182231903076
Epoch: 11, Steps: 118 Train Loss: 0.2691 (Forecasting Loss:0.2661 + XiCon Loss:3.0468 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2593
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2781161
	speed: 0.0182s/iter; left time: 189.2186s
Epoch: 12 cost time: 2.1260011196136475
Epoch: 12, Steps: 118 Train Loss: 0.2687 (Forecasting Loss:0.2657 + XiCon Loss:3.0477 x Lambda(0.001)), Vali MSE Loss: 0.3175 Test MSE Loss: 0.2593
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.3101295
	speed: 0.0181s/iter; left time: 186.4971s
Epoch: 13 cost time: 2.131411075592041
Epoch: 13, Steps: 118 Train Loss: 0.2689 (Forecasting Loss:0.2659 + XiCon Loss:3.0478 x Lambda(0.001)), Vali MSE Loss: 0.3180 Test MSE Loss: 0.2593
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2489912
	speed: 0.0180s/iter; left time: 182.7786s
Epoch: 14 cost time: 2.122105836868286
Epoch: 14, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0507 x Lambda(0.001)), Vali MSE Loss: 0.3182 Test MSE Loss: 0.2593
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2732463
	speed: 0.0182s/iter; left time: 182.7081s
Epoch: 15 cost time: 2.1375491619110107
Epoch: 15, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2660 + XiCon Loss:3.0479 x Lambda(0.001)), Vali MSE Loss: 0.3177 Test MSE Loss: 0.2593
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2891743
	speed: 0.0183s/iter; left time: 181.8120s
Epoch: 16 cost time: 2.1424002647399902
Epoch: 16, Steps: 118 Train Loss: 0.2690 (Forecasting Loss:0.2659 + XiCon Loss:3.0484 x Lambda(0.001)), Vali MSE Loss: 0.3183 Test MSE Loss: 0.2593
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1763322353363037, mae:0.34200820326805115, mape:0.6958960294723511, mspe:21.353939056396484 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.1717
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4674284
	speed: 0.0169s/iter; left time: 197.5262s
Epoch: 1 cost time: 1.9725184440612793
Epoch: 1, Steps: 118 Train Loss: 0.4995 (Forecasting Loss:0.4964 + XiCon Loss:3.0884 x Lambda(0.001)), Vali MSE Loss: 0.5423 Test MSE Loss: 0.4452
Validation loss decreased (inf --> 0.542251).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3095543
	speed: 0.0162s/iter; left time: 187.8126s
Epoch: 2 cost time: 1.900972604751587
Epoch: 2, Steps: 118 Train Loss: 0.3702 (Forecasting Loss:0.3671 + XiCon Loss:3.0897 x Lambda(0.001)), Vali MSE Loss: 0.3589 Test MSE Loss: 0.2744
Validation loss decreased (0.542251 --> 0.358858).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2780117
	speed: 0.0170s/iter; left time: 194.8849s
Epoch: 3 cost time: 2.0027453899383545
Epoch: 3, Steps: 118 Train Loss: 0.2913 (Forecasting Loss:0.2882 + XiCon Loss:3.1038 x Lambda(0.001)), Vali MSE Loss: 0.3267 Test MSE Loss: 0.2682
Validation loss decreased (0.358858 --> 0.326719).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2772445
	speed: 0.0179s/iter; left time: 202.9794s
Epoch: 4 cost time: 2.097503185272217
Epoch: 4, Steps: 118 Train Loss: 0.2759 (Forecasting Loss:0.2728 + XiCon Loss:3.1098 x Lambda(0.001)), Vali MSE Loss: 0.3222 Test MSE Loss: 0.2660
Validation loss decreased (0.326719 --> 0.322199).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2733909
	speed: 0.0175s/iter; left time: 196.5464s
Epoch: 5 cost time: 2.052924633026123
Epoch: 5, Steps: 118 Train Loss: 0.2714 (Forecasting Loss:0.2683 + XiCon Loss:3.1054 x Lambda(0.001)), Vali MSE Loss: 0.3173 Test MSE Loss: 0.2655
Validation loss decreased (0.322199 --> 0.317346).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2610882
	speed: 0.0177s/iter; left time: 197.1047s
Epoch: 6 cost time: 2.0825512409210205
Epoch: 6, Steps: 118 Train Loss: 0.2698 (Forecasting Loss:0.2667 + XiCon Loss:3.1046 x Lambda(0.001)), Vali MSE Loss: 0.3238 Test MSE Loss: 0.2652
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2835780
	speed: 0.0179s/iter; left time: 196.4323s
Epoch: 7 cost time: 2.101030111312866
Epoch: 7, Steps: 118 Train Loss: 0.2686 (Forecasting Loss:0.2655 + XiCon Loss:3.1069 x Lambda(0.001)), Vali MSE Loss: 0.3236 Test MSE Loss: 0.2651
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2594388
	speed: 0.0177s/iter; left time: 192.0921s
Epoch: 8 cost time: 2.072718858718872
Epoch: 8, Steps: 118 Train Loss: 0.2682 (Forecasting Loss:0.2651 + XiCon Loss:3.1060 x Lambda(0.001)), Vali MSE Loss: 0.3181 Test MSE Loss: 0.2658
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2582060
	speed: 0.0178s/iter; left time: 191.8216s
Epoch: 9 cost time: 2.090115547180176
Epoch: 9, Steps: 118 Train Loss: 0.2679 (Forecasting Loss:0.2648 + XiCon Loss:3.1046 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2658
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2525407
	speed: 0.0177s/iter; left time: 188.3644s
Epoch: 10 cost time: 2.0749335289001465
Epoch: 10, Steps: 118 Train Loss: 0.2677 (Forecasting Loss:0.2646 + XiCon Loss:3.1063 x Lambda(0.001)), Vali MSE Loss: 0.3187 Test MSE Loss: 0.2658
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2806640
	speed: 0.0181s/iter; left time: 190.1356s
Epoch: 11 cost time: 2.1247222423553467
Epoch: 11, Steps: 118 Train Loss: 0.2676 (Forecasting Loss:0.2645 + XiCon Loss:3.1036 x Lambda(0.001)), Vali MSE Loss: 0.3193 Test MSE Loss: 0.2658
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2637171
	speed: 0.0179s/iter; left time: 186.7033s
Epoch: 12 cost time: 2.122483015060425
Epoch: 12, Steps: 118 Train Loss: 0.2680 (Forecasting Loss:0.2649 + XiCon Loss:3.1046 x Lambda(0.001)), Vali MSE Loss: 0.3201 Test MSE Loss: 0.2658
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2651913
	speed: 0.0178s/iter; left time: 183.3551s
Epoch: 13 cost time: 2.094430923461914
Epoch: 13, Steps: 118 Train Loss: 0.2678 (Forecasting Loss:0.2647 + XiCon Loss:3.1046 x Lambda(0.001)), Vali MSE Loss: 0.3203 Test MSE Loss: 0.2658
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2664356
	speed: 0.0179s/iter; left time: 181.7650s
Epoch: 14 cost time: 2.0983965396881104
Epoch: 14, Steps: 118 Train Loss: 0.2681 (Forecasting Loss:0.2650 + XiCon Loss:3.1036 x Lambda(0.001)), Vali MSE Loss: 0.3199 Test MSE Loss: 0.2658
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2560788
	speed: 0.0178s/iter; left time: 178.7305s
Epoch: 15 cost time: 2.0861520767211914
Epoch: 15, Steps: 118 Train Loss: 0.2679 (Forecasting Loss:0.2648 + XiCon Loss:3.1059 x Lambda(0.001)), Vali MSE Loss: 0.3206 Test MSE Loss: 0.2658
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1828918606042862, mae:0.34817227721214294, mape:0.711731493473053, mspe:20.311973571777344 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 7585
number of available CPU:  16
Auto-correlation values(abs):[1.        0.9999075] ~ [1.77736511e-04 8.89139511e-05]
Xi-correlation values:[0.99965282 0.99685559] ~ [0. 1.]
Autocorrelation calculation time: 1.2055
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 7585
val 2161
test 2161
	iters: 100, epoch: 1 | loss: 0.4437440
	speed: 0.0163s/iter; left time: 190.8916s
Epoch: 1 cost time: 1.9125866889953613
Epoch: 1, Steps: 118 Train Loss: 0.4779 (Forecasting Loss:0.4748 + XiCon Loss:3.1192 x Lambda(0.001)), Vali MSE Loss: 0.5074 Test MSE Loss: 0.4006
Validation loss decreased (inf --> 0.507353).  Saving model ...
Updating learning rate to 0.001
	iters: 100, epoch: 2 | loss: 0.3168635
	speed: 0.0163s/iter; left time: 188.5118s
Epoch: 2 cost time: 1.9132592678070068
Epoch: 2, Steps: 118 Train Loss: 0.3506 (Forecasting Loss:0.3475 + XiCon Loss:3.1068 x Lambda(0.001)), Vali MSE Loss: 0.3516 Test MSE Loss: 0.2701
Validation loss decreased (0.507353 --> 0.351560).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 3 | loss: 0.2703624
	speed: 0.0163s/iter; left time: 186.4944s
Epoch: 3 cost time: 1.9127190113067627
Epoch: 3, Steps: 118 Train Loss: 0.2853 (Forecasting Loss:0.2823 + XiCon Loss:3.0723 x Lambda(0.001)), Vali MSE Loss: 0.3276 Test MSE Loss: 0.2722
Validation loss decreased (0.351560 --> 0.327571).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 4 | loss: 0.2671579
	speed: 0.0161s/iter; left time: 182.4009s
Epoch: 4 cost time: 1.8917739391326904
Epoch: 4, Steps: 118 Train Loss: 0.2774 (Forecasting Loss:0.2743 + XiCon Loss:3.0706 x Lambda(0.001)), Vali MSE Loss: 0.3195 Test MSE Loss: 0.2662
Validation loss decreased (0.327571 --> 0.319464).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 5 | loss: 0.2878785
	speed: 0.0161s/iter; left time: 180.3108s
Epoch: 5 cost time: 1.8866961002349854
Epoch: 5, Steps: 118 Train Loss: 0.2744 (Forecasting Loss:0.2713 + XiCon Loss:3.0698 x Lambda(0.001)), Vali MSE Loss: 0.3176 Test MSE Loss: 0.2610
Validation loss decreased (0.319464 --> 0.317551).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 6 | loss: 0.2724240
	speed: 0.0161s/iter; left time: 179.0938s
Epoch: 6 cost time: 1.8910880088806152
Epoch: 6, Steps: 118 Train Loss: 0.2733 (Forecasting Loss:0.2703 + XiCon Loss:3.0697 x Lambda(0.001)), Vali MSE Loss: 0.3169 Test MSE Loss: 0.2617
Validation loss decreased (0.317551 --> 0.316889).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 7 | loss: 0.2806687
	speed: 0.0160s/iter; left time: 176.3172s
Epoch: 7 cost time: 1.8848302364349365
Epoch: 7, Steps: 118 Train Loss: 0.2725 (Forecasting Loss:0.2694 + XiCon Loss:3.0681 x Lambda(0.001)), Vali MSE Loss: 0.3167 Test MSE Loss: 0.2604
Validation loss decreased (0.316889 --> 0.316685).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 8 | loss: 0.2457983
	speed: 0.0164s/iter; left time: 178.0397s
Epoch: 8 cost time: 1.916783094406128
Epoch: 8, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2690 + XiCon Loss:3.0686 x Lambda(0.001)), Vali MSE Loss: 0.3152 Test MSE Loss: 0.2596
Validation loss decreased (0.316685 --> 0.315240).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 9 | loss: 0.2666395
	speed: 0.0162s/iter; left time: 174.2766s
Epoch: 9 cost time: 1.906421184539795
Epoch: 9, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2690 + XiCon Loss:3.0686 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2598
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 10 | loss: 0.2874259
	speed: 0.0165s/iter; left time: 175.5880s
Epoch: 10 cost time: 1.9311037063598633
Epoch: 10, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2691 + XiCon Loss:3.0694 x Lambda(0.001)), Vali MSE Loss: 0.3160 Test MSE Loss: 0.2598
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 11 | loss: 0.2521653
	speed: 0.0160s/iter; left time: 168.8117s
Epoch: 11 cost time: 1.8853192329406738
Epoch: 11, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2690 + XiCon Loss:3.0706 x Lambda(0.001)), Vali MSE Loss: 0.3153 Test MSE Loss: 0.2598
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 12 | loss: 0.2675182
	speed: 0.0160s/iter; left time: 166.1913s
Epoch: 12 cost time: 1.8795099258422852
Epoch: 12, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2688 + XiCon Loss:3.0702 x Lambda(0.001)), Vali MSE Loss: 0.3161 Test MSE Loss: 0.2598
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 13 | loss: 0.2423511
	speed: 0.0162s/iter; left time: 166.2537s
Epoch: 13 cost time: 1.898895502090454
Epoch: 13, Steps: 118 Train Loss: 0.2718 (Forecasting Loss:0.2687 + XiCon Loss:3.0672 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2598
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 14 | loss: 0.2774164
	speed: 0.0162s/iter; left time: 164.7278s
Epoch: 14 cost time: 1.904219627380371
Epoch: 14, Steps: 118 Train Loss: 0.2719 (Forecasting Loss:0.2688 + XiCon Loss:3.0683 x Lambda(0.001)), Vali MSE Loss: 0.3157 Test MSE Loss: 0.2597
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 15 | loss: 0.2705439
	speed: 0.0163s/iter; left time: 163.5795s
Epoch: 15 cost time: 1.9165761470794678
Epoch: 15, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2690 + XiCon Loss:3.0709 x Lambda(0.001)), Vali MSE Loss: 0.3171 Test MSE Loss: 0.2597
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 16 | loss: 0.2599585
	speed: 0.0161s/iter; left time: 160.3141s
Epoch: 16 cost time: 1.8976025581359863
Epoch: 16, Steps: 118 Train Loss: 0.2720 (Forecasting Loss:0.2690 + XiCon Loss:3.0690 x Lambda(0.001)), Vali MSE Loss: 0.3158 Test MSE Loss: 0.2597
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 17 | loss: 0.2623233
	speed: 0.0162s/iter; left time: 158.7831s
Epoch: 17 cost time: 1.9005067348480225
Epoch: 17, Steps: 118 Train Loss: 0.2722 (Forecasting Loss:0.2691 + XiCon Loss:3.0719 x Lambda(0.001)), Vali MSE Loss: 0.3159 Test MSE Loss: 0.2597
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 18 | loss: 0.2893138
	speed: 0.0161s/iter; left time: 155.7722s
Epoch: 18 cost time: 1.8904931545257568
Epoch: 18, Steps: 118 Train Loss: 0.2721 (Forecasting Loss:0.2691 + XiCon Loss:3.0678 x Lambda(0.001)), Vali MSE Loss: 0.3163 Test MSE Loss: 0.2597
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTh2_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 2161
test shape: (33, 64, 720, 1) (33, 64, 720, 1)
test shape: (2112, 720, 1) (2112, 720, 1)
mse:0.1769924759864807, mae:0.34220853447914124, mape:0.7653405070304871, mspe:23.931926727294922 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1840+-0.01089, MAE:0.3479+-0.00795, MAPE:0.7080+-0.04317, MSPE:21.4370+-2.88910, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=3, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.4354
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.1877480
	speed: 0.0412s/iter; left time: 1091.3867s
	iters: 200, epoch: 1 | loss: 3.1337979
	speed: 0.0344s/iter; left time: 908.0974s
Epoch: 1 cost time: 9.854146003723145
Epoch: 1, Steps: 266 Train Loss: 3.2073 (Forecasting Loss:0.1678 + XiCon Loss:3.0395 x Lambda(1.0)), Vali MSE Loss: 0.1152 Test MSE Loss: 0.0788
Validation loss decreased (inf --> 0.115224).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.1434522
	speed: 0.0367s/iter; left time: 963.6204s
	iters: 200, epoch: 2 | loss: 3.1150086
	speed: 0.0360s/iter; left time: 941.1237s
Epoch: 2 cost time: 9.628257036209106
Epoch: 2, Steps: 266 Train Loss: 3.1769 (Forecasting Loss:0.1503 + XiCon Loss:3.0266 x Lambda(1.0)), Vali MSE Loss: 0.1117 Test MSE Loss: 0.0760
Validation loss decreased (0.115224 --> 0.111695).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1642950
	speed: 0.0369s/iter; left time: 958.9932s
	iters: 200, epoch: 3 | loss: 3.0912783
	speed: 0.0351s/iter; left time: 906.7117s
Epoch: 3 cost time: 9.5963613986969
Epoch: 3, Steps: 266 Train Loss: 3.1300 (Forecasting Loss:0.1451 + XiCon Loss:2.9849 x Lambda(1.0)), Vali MSE Loss: 0.1096 Test MSE Loss: 0.0758
Validation loss decreased (0.111695 --> 0.109610).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 2.9852149
	speed: 0.0378s/iter; left time: 972.7173s
	iters: 200, epoch: 4 | loss: 3.0753455
	speed: 0.0354s/iter; left time: 906.6949s
Epoch: 4 cost time: 9.670199632644653
Epoch: 4, Steps: 266 Train Loss: 3.1029 (Forecasting Loss:0.1431 + XiCon Loss:2.9599 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0760
Validation loss decreased (0.109610 --> 0.108631).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0546372
	speed: 0.0371s/iter; left time: 942.8262s
	iters: 200, epoch: 5 | loss: 3.0058877
	speed: 0.0348s/iter; left time: 882.8211s
Epoch: 5 cost time: 9.507794857025146
Epoch: 5, Steps: 266 Train Loss: 3.1035 (Forecasting Loss:0.1421 + XiCon Loss:2.9614 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0750
Validation loss decreased (0.108631 --> 0.107753).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1021073
	speed: 0.0376s/iter; left time: 947.4461s
	iters: 200, epoch: 6 | loss: 3.0157845
	speed: 0.0347s/iter; left time: 869.5023s
Epoch: 6 cost time: 9.598859786987305
Epoch: 6, Steps: 266 Train Loss: 3.0898 (Forecasting Loss:0.1417 + XiCon Loss:2.9481 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0752
Validation loss decreased (0.107753 --> 0.107655).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 2.9429741
	speed: 0.0373s/iter; left time: 928.2979s
	iters: 200, epoch: 7 | loss: 2.9927254
	speed: 0.0359s/iter; left time: 890.8404s
Epoch: 7 cost time: 9.673490524291992
Epoch: 7, Steps: 266 Train Loss: 3.0876 (Forecasting Loss:0.1414 + XiCon Loss:2.9462 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0751
Validation loss decreased (0.107655 --> 0.107409).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.0797639
	speed: 0.0377s/iter; left time: 929.3631s
	iters: 200, epoch: 8 | loss: 3.1247449
	speed: 0.0362s/iter; left time: 887.1791s
Epoch: 8 cost time: 9.77753233909607
Epoch: 8, Steps: 266 Train Loss: 3.0886 (Forecasting Loss:0.1413 + XiCon Loss:2.9473 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0753
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0806797
	speed: 0.0372s/iter; left time: 906.7140s
	iters: 200, epoch: 9 | loss: 3.0803175
	speed: 0.0352s/iter; left time: 853.5743s
Epoch: 9 cost time: 9.560797691345215
Epoch: 9, Steps: 266 Train Loss: 3.0883 (Forecasting Loss:0.1412 + XiCon Loss:2.9471 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0754
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1787429
	speed: 0.0370s/iter; left time: 891.4455s
	iters: 200, epoch: 10 | loss: 3.0066426
	speed: 0.0352s/iter; left time: 845.6528s
Epoch: 10 cost time: 9.509002208709717
Epoch: 10, Steps: 266 Train Loss: 3.0963 (Forecasting Loss:0.1412 + XiCon Loss:2.9551 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.1365919
	speed: 0.0375s/iter; left time: 894.8288s
	iters: 200, epoch: 11 | loss: 3.1104255
	speed: 0.0373s/iter; left time: 886.0057s
Epoch: 11 cost time: 9.822168827056885
Epoch: 11, Steps: 266 Train Loss: 3.0858 (Forecasting Loss:0.1411 + XiCon Loss:2.9446 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.0580513
	speed: 0.0365s/iter; left time: 860.9073s
	iters: 200, epoch: 12 | loss: 3.0481565
	speed: 0.0353s/iter; left time: 828.5727s
Epoch: 12 cost time: 9.57977294921875
Epoch: 12, Steps: 266 Train Loss: 3.0847 (Forecasting Loss:0.1412 + XiCon Loss:2.9436 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
Validation loss decreased (0.107409 --> 0.107404).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.0289378
	speed: 0.0383s/iter; left time: 892.0951s
	iters: 200, epoch: 13 | loss: 3.1111519
	speed: 0.0351s/iter; left time: 814.8025s
Epoch: 13 cost time: 9.69476842880249
Epoch: 13, Steps: 266 Train Loss: 3.0948 (Forecasting Loss:0.1412 + XiCon Loss:2.9536 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1305554
	speed: 0.0403s/iter; left time: 928.3755s
	iters: 200, epoch: 14 | loss: 3.0548007
	speed: 0.0346s/iter; left time: 792.9793s
Epoch: 14 cost time: 9.838597774505615
Epoch: 14, Steps: 266 Train Loss: 3.0855 (Forecasting Loss:0.1412 + XiCon Loss:2.9443 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0752
Validation loss decreased (0.107404 --> 0.107347).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1287365
	speed: 0.0381s/iter; left time: 867.0254s
	iters: 200, epoch: 15 | loss: 3.1140366
	speed: 0.0368s/iter; left time: 834.5472s
Epoch: 15 cost time: 9.889456033706665
Epoch: 15, Steps: 266 Train Loss: 3.0819 (Forecasting Loss:0.1412 + XiCon Loss:2.9407 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0752
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1778121
	speed: 0.0375s/iter; left time: 843.0842s
	iters: 200, epoch: 16 | loss: 3.1047695
	speed: 0.0359s/iter; left time: 804.8109s
Epoch: 16 cost time: 9.6618971824646
Epoch: 16, Steps: 266 Train Loss: 3.0920 (Forecasting Loss:0.1411 + XiCon Loss:2.9509 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.0936260
	speed: 0.0375s/iter; left time: 833.8120s
	iters: 200, epoch: 17 | loss: 3.0596874
	speed: 0.0362s/iter; left time: 801.4501s
Epoch: 17 cost time: 9.723164319992065
Epoch: 17, Steps: 266 Train Loss: 3.0849 (Forecasting Loss:0.1411 + XiCon Loss:2.9437 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1376309
	speed: 0.0374s/iter; left time: 821.3365s
	iters: 200, epoch: 18 | loss: 2.9869606
	speed: 0.0355s/iter; left time: 775.6730s
Epoch: 18 cost time: 9.635682821273804
Epoch: 18, Steps: 266 Train Loss: 3.0827 (Forecasting Loss:0.1412 + XiCon Loss:2.9415 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1276050
	speed: 0.0372s/iter; left time: 807.1173s
	iters: 200, epoch: 19 | loss: 2.9615271
	speed: 0.0360s/iter; left time: 777.3540s
Epoch: 19 cost time: 9.614047288894653
Epoch: 19, Steps: 266 Train Loss: 3.0793 (Forecasting Loss:0.1411 + XiCon Loss:2.9382 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0870752
	speed: 0.0374s/iter; left time: 803.0112s
	iters: 200, epoch: 20 | loss: 3.0665064
	speed: 0.0353s/iter; left time: 753.4688s
Epoch: 20 cost time: 9.61135196685791
Epoch: 20, Steps: 266 Train Loss: 3.0915 (Forecasting Loss:0.1411 + XiCon Loss:2.9504 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0752
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 2.9864368
	speed: 0.0375s/iter; left time: 794.5683s
	iters: 200, epoch: 21 | loss: 3.2273121
	speed: 0.0355s/iter; left time: 747.5449s
Epoch: 21 cost time: 9.633255958557129
Epoch: 21, Steps: 266 Train Loss: 3.0783 (Forecasting Loss:0.1411 + XiCon Loss:2.9372 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.1525185
	speed: 0.0375s/iter; left time: 783.8888s
	iters: 200, epoch: 22 | loss: 3.1143394
	speed: 0.0355s/iter; left time: 739.2691s
Epoch: 22 cost time: 9.64890456199646
Epoch: 22, Steps: 266 Train Loss: 3.0953 (Forecasting Loss:0.1411 + XiCon Loss:2.9542 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0752
Validation loss decreased (0.107347 --> 0.107329).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 2.9639001
	speed: 0.0369s/iter; left time: 761.4046s
	iters: 200, epoch: 23 | loss: 3.2718379
	speed: 0.0353s/iter; left time: 725.2448s
Epoch: 23 cost time: 9.522300958633423
Epoch: 23, Steps: 266 Train Loss: 3.0911 (Forecasting Loss:0.1412 + XiCon Loss:2.9499 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1601222
	speed: 0.0378s/iter; left time: 770.5053s
	iters: 200, epoch: 24 | loss: 3.0909340
	speed: 0.0350s/iter; left time: 710.3698s
Epoch: 24 cost time: 9.639061450958252
Epoch: 24, Steps: 266 Train Loss: 3.0933 (Forecasting Loss:0.1411 + XiCon Loss:2.9522 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1493917
	speed: 0.0370s/iter; left time: 744.1068s
	iters: 200, epoch: 25 | loss: 3.1856108
	speed: 0.0355s/iter; left time: 710.0557s
Epoch: 25 cost time: 9.536626100540161
Epoch: 25, Steps: 266 Train Loss: 3.0994 (Forecasting Loss:0.1411 + XiCon Loss:2.9583 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0752
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.1740489
	speed: 0.0374s/iter; left time: 741.9205s
	iters: 200, epoch: 26 | loss: 2.9970708
	speed: 0.0352s/iter; left time: 695.2894s
Epoch: 26 cost time: 9.69227409362793
Epoch: 26, Steps: 266 Train Loss: 3.0878 (Forecasting Loss:0.1411 + XiCon Loss:2.9466 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1701524
	speed: 0.0376s/iter; left time: 737.0987s
	iters: 200, epoch: 27 | loss: 2.9664416
	speed: 0.0356s/iter; left time: 694.2160s
Epoch: 27 cost time: 9.677350521087646
Epoch: 27, Steps: 266 Train Loss: 3.0896 (Forecasting Loss:0.1411 + XiCon Loss:2.9485 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.0396581
	speed: 0.0376s/iter; left time: 726.2962s
	iters: 200, epoch: 28 | loss: 3.1735189
	speed: 0.0355s/iter; left time: 681.5756s
Epoch: 28 cost time: 9.667179107666016
Epoch: 28, Steps: 266 Train Loss: 3.0946 (Forecasting Loss:0.1412 + XiCon Loss:2.9534 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0752
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1997271
	speed: 0.0373s/iter; left time: 711.6199s
	iters: 200, epoch: 29 | loss: 3.3419096
	speed: 0.0352s/iter; left time: 666.4702s
Epoch: 29 cost time: 9.607912063598633
Epoch: 29, Steps: 266 Train Loss: 3.0841 (Forecasting Loss:0.1412 + XiCon Loss:2.9429 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.0443754
	speed: 0.0369s/iter; left time: 693.2460s
	iters: 200, epoch: 30 | loss: 2.9909475
	speed: 0.0359s/iter; left time: 670.7409s
Epoch: 30 cost time: 9.67959451675415
Epoch: 30, Steps: 266 Train Loss: 3.0849 (Forecasting Loss:0.1411 + XiCon Loss:2.9438 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 3.1454370
	speed: 0.0368s/iter; left time: 682.0220s
	iters: 200, epoch: 31 | loss: 2.9916363
	speed: 0.0363s/iter; left time: 668.3531s
Epoch: 31 cost time: 9.633382320404053
Epoch: 31, Steps: 266 Train Loss: 3.0896 (Forecasting Loss:0.1411 + XiCon Loss:2.9485 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 3.1014540
	speed: 0.0367s/iter; left time: 670.3393s
	iters: 200, epoch: 32 | loss: 3.3073983
	speed: 0.0353s/iter; left time: 640.0515s
Epoch: 32 cost time: 9.576019763946533
Epoch: 32, Steps: 266 Train Loss: 3.0855 (Forecasting Loss:0.1411 + XiCon Loss:2.9443 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0752
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.027068743482232094, mae:0.12330104410648346, mape:0.10041164606809616, mspe:0.02063978835940361 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.3999
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.1748412
	speed: 0.0377s/iter; left time: 998.7935s
	iters: 200, epoch: 1 | loss: 3.1628041
	speed: 0.0341s/iter; left time: 899.8929s
Epoch: 1 cost time: 9.425654411315918
Epoch: 1, Steps: 266 Train Loss: 3.2162 (Forecasting Loss:0.1669 + XiCon Loss:3.0494 x Lambda(1.0)), Vali MSE Loss: 0.1153 Test MSE Loss: 0.0777
Validation loss decreased (inf --> 0.115304).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.4364920
	speed: 0.0388s/iter; left time: 1017.1192s
	iters: 200, epoch: 2 | loss: 3.1576834
	speed: 0.0348s/iter; left time: 908.2775s
Epoch: 2 cost time: 9.702129602432251
Epoch: 2, Steps: 266 Train Loss: 3.2495 (Forecasting Loss:0.1505 + XiCon Loss:3.0990 x Lambda(1.0)), Vali MSE Loss: 0.1109 Test MSE Loss: 0.0761
Validation loss decreased (0.115304 --> 0.110912).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2086098
	speed: 0.0378s/iter; left time: 981.1936s
	iters: 200, epoch: 3 | loss: 3.0796895
	speed: 0.0354s/iter; left time: 916.9106s
Epoch: 3 cost time: 9.666752815246582
Epoch: 3, Steps: 266 Train Loss: 3.1309 (Forecasting Loss:0.1454 + XiCon Loss:2.9856 x Lambda(1.0)), Vali MSE Loss: 0.1088 Test MSE Loss: 0.0752
Validation loss decreased (0.110912 --> 0.108847).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1259537
	speed: 0.0371s/iter; left time: 953.2452s
	iters: 200, epoch: 4 | loss: 3.1432853
	speed: 0.0358s/iter; left time: 917.4042s
Epoch: 4 cost time: 9.67129111289978
Epoch: 4, Steps: 266 Train Loss: 3.1201 (Forecasting Loss:0.1433 + XiCon Loss:2.9768 x Lambda(1.0)), Vali MSE Loss: 0.1084 Test MSE Loss: 0.0748
Validation loss decreased (0.108847 --> 0.108369).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0964935
	speed: 0.0373s/iter; left time: 950.0710s
	iters: 200, epoch: 5 | loss: 3.1228669
	speed: 0.0350s/iter; left time: 887.5319s
Epoch: 5 cost time: 9.576467514038086
Epoch: 5, Steps: 266 Train Loss: 3.1167 (Forecasting Loss:0.1425 + XiCon Loss:2.9741 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0747
Validation loss decreased (0.108369 --> 0.108008).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.0854051
	speed: 0.0372s/iter; left time: 937.2764s
	iters: 200, epoch: 6 | loss: 3.3659747
	speed: 0.0356s/iter; left time: 892.8557s
Epoch: 6 cost time: 9.648341417312622
Epoch: 6, Steps: 266 Train Loss: 3.1096 (Forecasting Loss:0.1421 + XiCon Loss:2.9675 x Lambda(1.0)), Vali MSE Loss: 0.1078 Test MSE Loss: 0.0742
Validation loss decreased (0.108008 --> 0.107807).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0933657
	speed: 0.0370s/iter; left time: 922.0826s
	iters: 200, epoch: 7 | loss: 3.1321738
	speed: 0.0358s/iter; left time: 886.9537s
Epoch: 7 cost time: 9.710966110229492
Epoch: 7, Steps: 266 Train Loss: 3.1045 (Forecasting Loss:0.1418 + XiCon Loss:2.9627 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107807 --> 0.107518).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1057432
	speed: 0.0370s/iter; left time: 911.5678s
	iters: 200, epoch: 8 | loss: 3.1656635
	speed: 0.0352s/iter; left time: 864.7176s
Epoch: 8 cost time: 9.598042964935303
Epoch: 8, Steps: 266 Train Loss: 3.1028 (Forecasting Loss:0.1417 + XiCon Loss:2.9611 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107518 --> 0.107502).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 2.9769609
	speed: 0.0382s/iter; left time: 930.7916s
	iters: 200, epoch: 9 | loss: 3.2416549
	speed: 0.0347s/iter; left time: 843.4036s
Epoch: 9 cost time: 9.59612774848938
Epoch: 9, Steps: 266 Train Loss: 3.1060 (Forecasting Loss:0.1416 + XiCon Loss:2.9644 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1944621
	speed: 0.0370s/iter; left time: 892.7579s
	iters: 200, epoch: 10 | loss: 3.1314471
	speed: 0.0348s/iter; left time: 835.9376s
Epoch: 10 cost time: 9.49330449104309
Epoch: 10, Steps: 266 Train Loss: 3.1100 (Forecasting Loss:0.1416 + XiCon Loss:2.9683 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107502 --> 0.107492).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0110211
	speed: 0.0377s/iter; left time: 897.9260s
	iters: 200, epoch: 11 | loss: 3.0121100
	speed: 0.0358s/iter; left time: 850.3666s
Epoch: 11 cost time: 9.682880878448486
Epoch: 11, Steps: 266 Train Loss: 3.1015 (Forecasting Loss:0.1416 + XiCon Loss:2.9600 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107492 --> 0.107453).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1937473
	speed: 0.0369s/iter; left time: 870.4337s
	iters: 200, epoch: 12 | loss: 3.1018987
	speed: 0.0347s/iter; left time: 813.8569s
Epoch: 12 cost time: 9.498128652572632
Epoch: 12, Steps: 266 Train Loss: 3.1066 (Forecasting Loss:0.1415 + XiCon Loss:2.9651 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107453 --> 0.107448).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 2.9705443
	speed: 0.0375s/iter; left time: 874.5929s
	iters: 200, epoch: 13 | loss: 3.1016197
	speed: 0.0346s/iter; left time: 802.3021s
Epoch: 13 cost time: 9.484169721603394
Epoch: 13, Steps: 266 Train Loss: 3.1102 (Forecasting Loss:0.1415 + XiCon Loss:2.9687 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107448 --> 0.107440).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 2.9942904
	speed: 0.0369s/iter; left time: 849.1804s
	iters: 200, epoch: 14 | loss: 3.1991534
	speed: 0.0347s/iter; left time: 797.2170s
Epoch: 14 cost time: 9.439091920852661
Epoch: 14, Steps: 266 Train Loss: 3.0995 (Forecasting Loss:0.1415 + XiCon Loss:2.9580 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 2.9733441
	speed: 0.0370s/iter; left time: 842.6763s
	iters: 200, epoch: 15 | loss: 3.0578470
	speed: 0.0356s/iter; left time: 806.5650s
Epoch: 15 cost time: 9.559791803359985
Epoch: 15, Steps: 266 Train Loss: 3.1073 (Forecasting Loss:0.1416 + XiCon Loss:2.9658 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0379753
	speed: 0.0372s/iter; left time: 837.2833s
	iters: 200, epoch: 16 | loss: 3.0215542
	speed: 0.0369s/iter; left time: 827.5308s
Epoch: 16 cost time: 9.848226547241211
Epoch: 16, Steps: 266 Train Loss: 3.1095 (Forecasting Loss:0.1415 + XiCon Loss:2.9680 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2472754
	speed: 0.0371s/iter; left time: 825.7632s
	iters: 200, epoch: 17 | loss: 3.0891786
	speed: 0.0348s/iter; left time: 771.6411s
Epoch: 17 cost time: 9.517040729522705
Epoch: 17, Steps: 266 Train Loss: 3.1092 (Forecasting Loss:0.1415 + XiCon Loss:2.9677 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107440 --> 0.107427).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.2606516
	speed: 0.0380s/iter; left time: 835.1138s
	iters: 200, epoch: 18 | loss: 3.0602882
	speed: 0.0350s/iter; left time: 765.3231s
Epoch: 18 cost time: 9.636468410491943
Epoch: 18, Steps: 266 Train Loss: 3.1004 (Forecasting Loss:0.1416 + XiCon Loss:2.9588 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107427 --> 0.107369).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.0844121
	speed: 0.0368s/iter; left time: 798.1786s
	iters: 200, epoch: 19 | loss: 2.9730961
	speed: 0.0353s/iter; left time: 764.0066s
Epoch: 19 cost time: 9.53444504737854
Epoch: 19, Steps: 266 Train Loss: 3.1015 (Forecasting Loss:0.1414 + XiCon Loss:2.9601 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1310306
	speed: 0.0378s/iter; left time: 811.0911s
	iters: 200, epoch: 20 | loss: 3.3390574
	speed: 0.0346s/iter; left time: 738.1839s
Epoch: 20 cost time: 9.565982818603516
Epoch: 20, Steps: 266 Train Loss: 3.1096 (Forecasting Loss:0.1415 + XiCon Loss:2.9681 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107369 --> 0.107359).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0744207
	speed: 0.0373s/iter; left time: 789.5518s
	iters: 200, epoch: 21 | loss: 3.0226514
	speed: 0.0356s/iter; left time: 749.6017s
Epoch: 21 cost time: 9.625877380371094
Epoch: 21, Steps: 266 Train Loss: 3.1047 (Forecasting Loss:0.1416 + XiCon Loss:2.9631 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.0657482
	speed: 0.0376s/iter; left time: 786.5499s
	iters: 200, epoch: 22 | loss: 3.1666896
	speed: 0.0350s/iter; left time: 728.1360s
Epoch: 22 cost time: 9.550495624542236
Epoch: 22, Steps: 266 Train Loss: 3.1004 (Forecasting Loss:0.1415 + XiCon Loss:2.9589 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1182380
	speed: 0.0375s/iter; left time: 773.8402s
	iters: 200, epoch: 23 | loss: 3.1571829
	speed: 0.0351s/iter; left time: 721.2118s
Epoch: 23 cost time: 9.620971918106079
Epoch: 23, Steps: 266 Train Loss: 3.1028 (Forecasting Loss:0.1415 + XiCon Loss:2.9613 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.0169814
	speed: 0.0377s/iter; left time: 769.0901s
	iters: 200, epoch: 24 | loss: 3.2164996
	speed: 0.0353s/iter; left time: 715.0249s
Epoch: 24 cost time: 9.668050527572632
Epoch: 24, Steps: 266 Train Loss: 3.1048 (Forecasting Loss:0.1415 + XiCon Loss:2.9633 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.0834928
	speed: 0.0375s/iter; left time: 754.7240s
	iters: 200, epoch: 25 | loss: 3.3440900
	speed: 0.0352s/iter; left time: 704.3212s
Epoch: 25 cost time: 9.62288522720337
Epoch: 25, Steps: 266 Train Loss: 3.1002 (Forecasting Loss:0.1416 + XiCon Loss:2.9586 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.2103562
	speed: 0.0369s/iter; left time: 732.5790s
	iters: 200, epoch: 26 | loss: 3.1923494
	speed: 0.0342s/iter; left time: 675.8914s
Epoch: 26 cost time: 9.474400281906128
Epoch: 26, Steps: 266 Train Loss: 3.1083 (Forecasting Loss:0.1415 + XiCon Loss:2.9668 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 2.9684601
	speed: 0.0370s/iter; left time: 725.1194s
	iters: 200, epoch: 27 | loss: 3.3708580
	speed: 0.0349s/iter; left time: 679.3163s
Epoch: 27 cost time: 9.4852294921875
Epoch: 27, Steps: 266 Train Loss: 3.1052 (Forecasting Loss:0.1415 + XiCon Loss:2.9637 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.0605218
	speed: 0.0373s/iter; left time: 720.6304s
	iters: 200, epoch: 28 | loss: 3.1146357
	speed: 0.0354s/iter; left time: 680.5246s
Epoch: 28 cost time: 9.6531982421875
Epoch: 28, Steps: 266 Train Loss: 3.1065 (Forecasting Loss:0.1415 + XiCon Loss:2.9650 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1874535
	speed: 0.0371s/iter; left time: 706.7028s
	iters: 200, epoch: 29 | loss: 3.0996046
	speed: 0.0356s/iter; left time: 674.0613s
Epoch: 29 cost time: 9.656110525131226
Epoch: 29, Steps: 266 Train Loss: 3.1000 (Forecasting Loss:0.1415 + XiCon Loss:2.9584 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 3.0320988
	speed: 0.0383s/iter; left time: 718.6321s
	iters: 200, epoch: 30 | loss: 3.1559269
	speed: 0.0352s/iter; left time: 657.4782s
Epoch: 30 cost time: 9.605172157287598
Epoch: 30, Steps: 266 Train Loss: 3.1023 (Forecasting Loss:0.1416 + XiCon Loss:2.9608 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026328613981604576, mae:0.12173487991094589, mape:0.09840168803930283, mspe:0.019566774368286133 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.3113
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.1647680
	speed: 0.0375s/iter; left time: 993.7253s
	iters: 200, epoch: 1 | loss: 3.1376367
	speed: 0.0344s/iter; left time: 908.6059s
Epoch: 1 cost time: 9.487720251083374
Epoch: 1, Steps: 266 Train Loss: 3.1864 (Forecasting Loss:0.1686 + XiCon Loss:3.0178 x Lambda(1.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.0793
Validation loss decreased (inf --> 0.114901).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.2093270
	speed: 0.0374s/iter; left time: 981.7882s
	iters: 200, epoch: 2 | loss: 3.3123665
	speed: 0.0350s/iter; left time: 914.0160s
Epoch: 2 cost time: 9.591490745544434
Epoch: 2, Steps: 266 Train Loss: 3.3034 (Forecasting Loss:0.1510 + XiCon Loss:3.1524 x Lambda(1.0)), Vali MSE Loss: 0.1137 Test MSE Loss: 0.0785
Validation loss decreased (0.114901 --> 0.113699).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.0104549
	speed: 0.0374s/iter; left time: 972.1937s
	iters: 200, epoch: 3 | loss: 3.2760026
	speed: 0.0353s/iter; left time: 912.8934s
Epoch: 3 cost time: 9.591647386550903
Epoch: 3, Steps: 266 Train Loss: 3.2536 (Forecasting Loss:0.1455 + XiCon Loss:3.1081 x Lambda(1.0)), Vali MSE Loss: 0.1097 Test MSE Loss: 0.0754
Validation loss decreased (0.113699 --> 0.109721).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1789377
	speed: 0.0372s/iter; left time: 956.0091s
	iters: 200, epoch: 4 | loss: 3.1291094
	speed: 0.0361s/iter; left time: 925.0684s
Epoch: 4 cost time: 9.703155994415283
Epoch: 4, Steps: 266 Train Loss: 3.2315 (Forecasting Loss:0.1436 + XiCon Loss:3.0879 x Lambda(1.0)), Vali MSE Loss: 0.1086 Test MSE Loss: 0.0750
Validation loss decreased (0.109721 --> 0.108571).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.3631015
	speed: 0.0378s/iter; left time: 961.3591s
	iters: 200, epoch: 5 | loss: 3.3092823
	speed: 0.0351s/iter; left time: 888.5699s
Epoch: 5 cost time: 9.642521142959595
Epoch: 5, Steps: 266 Train Loss: 3.2035 (Forecasting Loss:0.1425 + XiCon Loss:3.0610 x Lambda(1.0)), Vali MSE Loss: 0.1081 Test MSE Loss: 0.0744
Validation loss decreased (0.108571 --> 0.108123).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.2996686
	speed: 0.0374s/iter; left time: 941.5847s
	iters: 200, epoch: 6 | loss: 3.1822948
	speed: 0.0348s/iter; left time: 872.0503s
Epoch: 6 cost time: 9.488885164260864
Epoch: 6, Steps: 266 Train Loss: 3.2087 (Forecasting Loss:0.1420 + XiCon Loss:3.0666 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0744
Validation loss decreased (0.108123 --> 0.107638).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.2303736
	speed: 0.0374s/iter; left time: 930.4040s
	iters: 200, epoch: 7 | loss: 3.3610501
	speed: 0.0348s/iter; left time: 863.4805s
Epoch: 7 cost time: 9.564853191375732
Epoch: 7, Steps: 266 Train Loss: 3.1934 (Forecasting Loss:0.1417 + XiCon Loss:3.0517 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0741
Validation loss decreased (0.107638 --> 0.107609).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1399350
	speed: 0.0374s/iter; left time: 922.6043s
	iters: 200, epoch: 8 | loss: 3.2589304
	speed: 0.0343s/iter; left time: 842.4657s
Epoch: 8 cost time: 9.495940923690796
Epoch: 8, Steps: 266 Train Loss: 3.1988 (Forecasting Loss:0.1416 + XiCon Loss:3.0572 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107609 --> 0.107458).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.1074629
	speed: 0.0376s/iter; left time: 915.6780s
	iters: 200, epoch: 9 | loss: 3.0186412
	speed: 0.0352s/iter; left time: 854.1143s
Epoch: 9 cost time: 9.621248722076416
Epoch: 9, Steps: 266 Train Loss: 3.1967 (Forecasting Loss:0.1416 + XiCon Loss:3.0551 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1828034
	speed: 0.0377s/iter; left time: 908.2840s
	iters: 200, epoch: 10 | loss: 3.1858022
	speed: 0.0354s/iter; left time: 850.0702s
Epoch: 10 cost time: 9.68601393699646
Epoch: 10, Steps: 266 Train Loss: 3.1989 (Forecasting Loss:0.1415 + XiCon Loss:3.0573 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107458 --> 0.107442).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2669208
	speed: 0.0372s/iter; left time: 886.9511s
	iters: 200, epoch: 11 | loss: 3.2109158
	speed: 0.0349s/iter; left time: 829.3254s
Epoch: 11 cost time: 9.490939855575562
Epoch: 11, Steps: 266 Train Loss: 3.1800 (Forecasting Loss:0.1415 + XiCon Loss:3.0384 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1423526
	speed: 0.0370s/iter; left time: 871.6614s
	iters: 200, epoch: 12 | loss: 3.2325666
	speed: 0.0347s/iter; left time: 815.1877s
Epoch: 12 cost time: 9.512497663497925
Epoch: 12, Steps: 266 Train Loss: 3.1917 (Forecasting Loss:0.1415 + XiCon Loss:3.0502 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1229022
	speed: 0.0384s/iter; left time: 894.6276s
	iters: 200, epoch: 13 | loss: 3.1925087
	speed: 0.0354s/iter; left time: 821.9517s
Epoch: 13 cost time: 9.766139030456543
Epoch: 13, Steps: 266 Train Loss: 3.1906 (Forecasting Loss:0.1415 + XiCon Loss:3.0491 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.2486818
	speed: 0.0372s/iter; left time: 856.4441s
	iters: 200, epoch: 14 | loss: 3.1765089
	speed: 0.0345s/iter; left time: 791.8759s
Epoch: 14 cost time: 9.580861806869507
Epoch: 14, Steps: 266 Train Loss: 3.1888 (Forecasting Loss:0.1416 + XiCon Loss:3.0473 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.2085786
	speed: 0.0376s/iter; left time: 855.7443s
	iters: 200, epoch: 15 | loss: 3.3574467
	speed: 0.0345s/iter; left time: 782.4348s
Epoch: 15 cost time: 9.599154949188232
Epoch: 15, Steps: 266 Train Loss: 3.1951 (Forecasting Loss:0.1415 + XiCon Loss:3.0537 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1742337
	speed: 0.0372s/iter; left time: 838.1271s
	iters: 200, epoch: 16 | loss: 3.1018579
	speed: 0.0354s/iter; left time: 793.4602s
Epoch: 16 cost time: 9.636188745498657
Epoch: 16, Steps: 266 Train Loss: 3.1968 (Forecasting Loss:0.1415 + XiCon Loss:3.0553 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.3093278
	speed: 0.0375s/iter; left time: 834.1759s
	iters: 200, epoch: 17 | loss: 3.3524976
	speed: 0.0363s/iter; left time: 804.4996s
Epoch: 17 cost time: 9.694261312484741
Epoch: 17, Steps: 266 Train Loss: 3.2059 (Forecasting Loss:0.1415 + XiCon Loss:3.0644 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
Validation loss decreased (0.107442 --> 0.107427).  Saving model ...
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1522532
	speed: 0.0371s/iter; left time: 814.7989s
	iters: 200, epoch: 18 | loss: 3.3133755
	speed: 0.0351s/iter; left time: 768.4355s
Epoch: 18 cost time: 9.559330224990845
Epoch: 18, Steps: 266 Train Loss: 3.2053 (Forecasting Loss:0.1414 + XiCon Loss:3.0638 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.2350585
	speed: 0.0374s/iter; left time: 811.5702s
	iters: 200, epoch: 19 | loss: 3.2637136
	speed: 0.0347s/iter; left time: 749.1125s
Epoch: 19 cost time: 9.543701171875
Epoch: 19, Steps: 266 Train Loss: 3.1996 (Forecasting Loss:0.1415 + XiCon Loss:3.0581 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.2557621
	speed: 0.0370s/iter; left time: 793.3160s
	iters: 200, epoch: 20 | loss: 3.2857759
	speed: 0.0349s/iter; left time: 744.5460s
Epoch: 20 cost time: 9.531314134597778
Epoch: 20, Steps: 266 Train Loss: 3.1967 (Forecasting Loss:0.1415 + XiCon Loss:3.0552 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0742
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.2434366
	speed: 0.0371s/iter; left time: 785.9243s
	iters: 200, epoch: 21 | loss: 3.1351771
	speed: 0.0356s/iter; left time: 750.7614s
Epoch: 21 cost time: 9.634701251983643
Epoch: 21, Steps: 266 Train Loss: 3.1957 (Forecasting Loss:0.1415 + XiCon Loss:3.0542 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0742
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.2118413
	speed: 0.0369s/iter; left time: 771.2172s
	iters: 200, epoch: 22 | loss: 3.1836786
	speed: 0.0352s/iter; left time: 732.8121s
Epoch: 22 cost time: 9.62143611907959
Epoch: 22, Steps: 266 Train Loss: 3.1891 (Forecasting Loss:0.1415 + XiCon Loss:3.0477 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.2904580
	speed: 0.0367s/iter; left time: 757.6030s
	iters: 200, epoch: 23 | loss: 3.1354947
	speed: 0.0354s/iter; left time: 727.5885s
Epoch: 23 cost time: 9.526626825332642
Epoch: 23, Steps: 266 Train Loss: 3.1861 (Forecasting Loss:0.1415 + XiCon Loss:3.0446 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.1865442
	speed: 0.0364s/iter; left time: 741.6750s
	iters: 200, epoch: 24 | loss: 3.1865354
	speed: 0.0348s/iter; left time: 705.3511s
Epoch: 24 cost time: 9.436328887939453
Epoch: 24, Steps: 266 Train Loss: 3.1883 (Forecasting Loss:0.1415 + XiCon Loss:3.0468 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.1512241
	speed: 0.0368s/iter; left time: 740.0515s
	iters: 200, epoch: 25 | loss: 3.3036003
	speed: 0.0349s/iter; left time: 699.4537s
Epoch: 25 cost time: 9.544634103775024
Epoch: 25, Steps: 266 Train Loss: 3.1891 (Forecasting Loss:0.1415 + XiCon Loss:3.0476 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.3412471
	speed: 0.0377s/iter; left time: 748.1903s
	iters: 200, epoch: 26 | loss: 3.0812752
	speed: 0.0354s/iter; left time: 699.3384s
Epoch: 26 cost time: 9.623743772506714
Epoch: 26, Steps: 266 Train Loss: 3.1938 (Forecasting Loss:0.1415 + XiCon Loss:3.0523 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1544583
	speed: 0.0375s/iter; left time: 733.7915s
	iters: 200, epoch: 27 | loss: 3.3140006
	speed: 0.0351s/iter; left time: 684.0653s
Epoch: 27 cost time: 9.607145309448242
Epoch: 27, Steps: 266 Train Loss: 3.1879 (Forecasting Loss:0.1415 + XiCon Loss:3.0464 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0742
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026395566761493683, mae:0.12194295227527618, mape:0.09855937957763672, mspe:0.019575785845518112 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.5656
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.2700460
	speed: 0.0376s/iter; left time: 996.6740s
	iters: 200, epoch: 1 | loss: 3.1068401
	speed: 0.0344s/iter; left time: 908.4029s
Epoch: 1 cost time: 9.574202060699463
Epoch: 1, Steps: 266 Train Loss: 3.2177 (Forecasting Loss:0.1668 + XiCon Loss:3.0510 x Lambda(1.0)), Vali MSE Loss: 0.1140 Test MSE Loss: 0.0782
Validation loss decreased (inf --> 0.113980).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.5447299
	speed: 0.0371s/iter; left time: 973.2510s
	iters: 200, epoch: 2 | loss: 3.1640825
	speed: 0.0355s/iter; left time: 928.4061s
Epoch: 2 cost time: 9.557782411575317
Epoch: 2, Steps: 266 Train Loss: 3.2791 (Forecasting Loss:0.1510 + XiCon Loss:3.1282 x Lambda(1.0)), Vali MSE Loss: 0.1105 Test MSE Loss: 0.0766
Validation loss decreased (0.113980 --> 0.110516).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.2199526
	speed: 0.0368s/iter; left time: 956.1469s
	iters: 200, epoch: 3 | loss: 3.1069424
	speed: 0.0346s/iter; left time: 894.1424s
Epoch: 3 cost time: 9.47262167930603
Epoch: 3, Steps: 266 Train Loss: 3.1775 (Forecasting Loss:0.1451 + XiCon Loss:3.0324 x Lambda(1.0)), Vali MSE Loss: 0.1090 Test MSE Loss: 0.0752
Validation loss decreased (0.110516 --> 0.109042).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.1020186
	speed: 0.0372s/iter; left time: 956.0211s
	iters: 200, epoch: 4 | loss: 3.2194047
	speed: 0.0351s/iter; left time: 897.6718s
Epoch: 4 cost time: 9.584183931350708
Epoch: 4, Steps: 266 Train Loss: 3.1649 (Forecasting Loss:0.1435 + XiCon Loss:3.0214 x Lambda(1.0)), Vali MSE Loss: 0.1080 Test MSE Loss: 0.0746
Validation loss decreased (0.109042 --> 0.108005).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.1017580
	speed: 0.0370s/iter; left time: 941.7062s
	iters: 200, epoch: 5 | loss: 3.3817186
	speed: 0.0357s/iter; left time: 904.2940s
Epoch: 5 cost time: 9.662552833557129
Epoch: 5, Steps: 266 Train Loss: 3.1536 (Forecasting Loss:0.1423 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0741
Validation loss decreased (0.108005 --> 0.107736).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.3062484
	speed: 0.0373s/iter; left time: 939.6243s
	iters: 200, epoch: 6 | loss: 3.0289690
	speed: 0.0352s/iter; left time: 882.9546s
Epoch: 6 cost time: 9.6291983127594
Epoch: 6, Steps: 266 Train Loss: 3.1574 (Forecasting Loss:0.1420 + XiCon Loss:3.0154 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
Validation loss decreased (0.107736 --> 0.107544).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.1772740
	speed: 0.0372s/iter; left time: 927.2355s
	iters: 200, epoch: 7 | loss: 3.1198318
	speed: 0.0352s/iter; left time: 872.4866s
Epoch: 7 cost time: 9.584589958190918
Epoch: 7, Steps: 266 Train Loss: 3.1460 (Forecasting Loss:0.1417 + XiCon Loss:3.0043 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
Validation loss decreased (0.107544 --> 0.107409).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.1574919
	speed: 0.0375s/iter; left time: 924.3583s
	iters: 200, epoch: 8 | loss: 3.1632805
	speed: 0.0345s/iter; left time: 847.5865s
Epoch: 8 cost time: 9.520156621932983
Epoch: 8, Steps: 266 Train Loss: 3.1502 (Forecasting Loss:0.1416 + XiCon Loss:3.0086 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.0380549
	speed: 0.0377s/iter; left time: 918.5389s
	iters: 200, epoch: 9 | loss: 3.0996487
	speed: 0.0352s/iter; left time: 854.6512s
Epoch: 9 cost time: 9.576139688491821
Epoch: 9, Steps: 266 Train Loss: 3.1458 (Forecasting Loss:0.1415 + XiCon Loss:3.0044 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.1010735
	speed: 0.0370s/iter; left time: 891.6855s
	iters: 200, epoch: 10 | loss: 3.1106462
	speed: 0.0351s/iter; left time: 843.0726s
Epoch: 10 cost time: 9.546567916870117
Epoch: 10, Steps: 266 Train Loss: 3.1567 (Forecasting Loss:0.1415 + XiCon Loss:3.0152 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107409 --> 0.107404).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.0810237
	speed: 0.0378s/iter; left time: 900.0705s
	iters: 200, epoch: 11 | loss: 3.5298092
	speed: 0.0349s/iter; left time: 828.6251s
Epoch: 11 cost time: 9.592910289764404
Epoch: 11, Steps: 266 Train Loss: 3.1499 (Forecasting Loss:0.1414 + XiCon Loss:3.0085 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
Validation loss decreased (0.107404 --> 0.107317).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.1591620
	speed: 0.0373s/iter; left time: 879.2257s
	iters: 200, epoch: 12 | loss: 3.0916266
	speed: 0.0356s/iter; left time: 836.5135s
Epoch: 12 cost time: 9.668846845626831
Epoch: 12, Steps: 266 Train Loss: 3.1518 (Forecasting Loss:0.1414 + XiCon Loss:3.0104 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1821582
	speed: 0.0373s/iter; left time: 870.4775s
	iters: 200, epoch: 13 | loss: 3.0407462
	speed: 0.0346s/iter; left time: 802.5208s
Epoch: 13 cost time: 9.48790168762207
Epoch: 13, Steps: 266 Train Loss: 3.1468 (Forecasting Loss:0.1414 + XiCon Loss:3.0054 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1777496
	speed: 0.0378s/iter; left time: 872.0629s
	iters: 200, epoch: 14 | loss: 3.1095395
	speed: 0.0356s/iter; left time: 815.9268s
Epoch: 14 cost time: 9.645187616348267
Epoch: 14, Steps: 266 Train Loss: 3.1520 (Forecasting Loss:0.1414 + XiCon Loss:3.0106 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.0990529
	speed: 0.0367s/iter; left time: 835.9233s
	iters: 200, epoch: 15 | loss: 3.3762732
	speed: 0.0346s/iter; left time: 783.6332s
Epoch: 15 cost time: 9.480335474014282
Epoch: 15, Steps: 266 Train Loss: 3.1610 (Forecasting Loss:0.1414 + XiCon Loss:3.0196 x Lambda(1.0)), Vali MSE Loss: 0.1073 Test MSE Loss: 0.0741
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.0699134
	speed: 0.0364s/iter; left time: 819.8670s
	iters: 200, epoch: 16 | loss: 3.0723317
	speed: 0.0349s/iter; left time: 781.3983s
Epoch: 16 cost time: 9.445517778396606
Epoch: 16, Steps: 266 Train Loss: 3.1557 (Forecasting Loss:0.1414 + XiCon Loss:3.0143 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2148142
	speed: 0.0366s/iter; left time: 814.8282s
	iters: 200, epoch: 17 | loss: 2.9805095
	speed: 0.0351s/iter; left time: 776.9424s
Epoch: 17 cost time: 9.504409313201904
Epoch: 17, Steps: 266 Train Loss: 3.1448 (Forecasting Loss:0.1414 + XiCon Loss:3.0034 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1799207
	speed: 0.0375s/iter; left time: 825.1718s
	iters: 200, epoch: 18 | loss: 3.0714247
	speed: 0.0354s/iter; left time: 774.3718s
Epoch: 18 cost time: 9.671252250671387
Epoch: 18, Steps: 266 Train Loss: 3.1475 (Forecasting Loss:0.1414 + XiCon Loss:3.0061 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.3145826
	speed: 0.0367s/iter; left time: 796.7984s
	iters: 200, epoch: 19 | loss: 3.0695035
	speed: 0.0335s/iter; left time: 723.6353s
Epoch: 19 cost time: 9.315060377120972
Epoch: 19, Steps: 266 Train Loss: 3.1525 (Forecasting Loss:0.1414 + XiCon Loss:3.0111 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.1788948
	speed: 0.0368s/iter; left time: 789.5986s
	iters: 200, epoch: 20 | loss: 3.1849046
	speed: 0.0345s/iter; left time: 735.6861s
Epoch: 20 cost time: 9.45087742805481
Epoch: 20, Steps: 266 Train Loss: 3.1532 (Forecasting Loss:0.1414 + XiCon Loss:3.0118 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0435283
	speed: 0.0366s/iter; left time: 774.9125s
	iters: 200, epoch: 21 | loss: 3.1802464
	speed: 0.0343s/iter; left time: 722.9498s
Epoch: 21 cost time: 9.411555767059326
Epoch: 21, Steps: 266 Train Loss: 3.1493 (Forecasting Loss:0.1414 + XiCon Loss:3.0078 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0741
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026340916752815247, mae:0.12179196625947952, mape:0.0984293520450592, mspe:0.019576216116547585 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:91905
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6109
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 3.2030563
	speed: 0.0372s/iter; left time: 986.1608s
	iters: 200, epoch: 1 | loss: 3.1035392
	speed: 0.0342s/iter; left time: 902.7773s
Epoch: 1 cost time: 9.44225287437439
Epoch: 1, Steps: 266 Train Loss: 3.2174 (Forecasting Loss:0.1690 + XiCon Loss:3.0484 x Lambda(1.0)), Vali MSE Loss: 0.1149 Test MSE Loss: 0.0798
Validation loss decreased (inf --> 0.114887).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 3.3791811
	speed: 0.0379s/iter; left time: 993.6408s
	iters: 200, epoch: 2 | loss: 3.2348926
	speed: 0.0359s/iter; left time: 939.4454s
Epoch: 2 cost time: 9.732111692428589
Epoch: 2, Steps: 266 Train Loss: 3.3645 (Forecasting Loss:0.1505 + XiCon Loss:3.2140 x Lambda(1.0)), Vali MSE Loss: 0.1114 Test MSE Loss: 0.0761
Validation loss decreased (0.114887 --> 0.111385).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 3.1050320
	speed: 0.0377s/iter; left time: 977.7368s
	iters: 200, epoch: 3 | loss: 3.0609639
	speed: 0.0356s/iter; left time: 920.1128s
Epoch: 3 cost time: 9.701812982559204
Epoch: 3, Steps: 266 Train Loss: 3.2008 (Forecasting Loss:0.1452 + XiCon Loss:3.0557 x Lambda(1.0)), Vali MSE Loss: 0.1099 Test MSE Loss: 0.0756
Validation loss decreased (0.111385 --> 0.109879).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 3.0774245
	speed: 0.0377s/iter; left time: 970.1448s
	iters: 200, epoch: 4 | loss: 3.2930059
	speed: 0.0355s/iter; left time: 907.9813s
Epoch: 4 cost time: 9.652441024780273
Epoch: 4, Steps: 266 Train Loss: 3.1225 (Forecasting Loss:0.1434 + XiCon Loss:2.9790 x Lambda(1.0)), Vali MSE Loss: 0.1082 Test MSE Loss: 0.0747
Validation loss decreased (0.109879 --> 0.108246).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 3.0350604
	speed: 0.0377s/iter; left time: 958.6722s
	iters: 200, epoch: 5 | loss: 3.1232700
	speed: 0.0356s/iter; left time: 901.1132s
Epoch: 5 cost time: 9.645349025726318
Epoch: 5, Steps: 266 Train Loss: 3.1214 (Forecasting Loss:0.1426 + XiCon Loss:2.9788 x Lambda(1.0)), Vali MSE Loss: 0.1079 Test MSE Loss: 0.0741
Validation loss decreased (0.108246 --> 0.107949).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 3.1398163
	speed: 0.0374s/iter; left time: 941.1702s
	iters: 200, epoch: 6 | loss: 3.1759813
	speed: 0.0351s/iter; left time: 879.1366s
Epoch: 6 cost time: 9.659521102905273
Epoch: 6, Steps: 266 Train Loss: 3.1204 (Forecasting Loss:0.1420 + XiCon Loss:2.9784 x Lambda(1.0)), Vali MSE Loss: 0.1077 Test MSE Loss: 0.0742
Validation loss decreased (0.107949 --> 0.107702).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 3.0391407
	speed: 0.0378s/iter; left time: 941.0017s
	iters: 200, epoch: 7 | loss: 3.0804629
	speed: 0.0358s/iter; left time: 888.8601s
Epoch: 7 cost time: 9.706386804580688
Epoch: 7, Steps: 266 Train Loss: 3.1156 (Forecasting Loss:0.1418 + XiCon Loss:2.9738 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0741
Validation loss decreased (0.107702 --> 0.107541).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 3.2151327
	speed: 0.0376s/iter; left time: 925.5701s
	iters: 200, epoch: 8 | loss: 3.0726860
	speed: 0.0351s/iter; left time: 860.1298s
Epoch: 8 cost time: 9.607080459594727
Epoch: 8, Steps: 266 Train Loss: 3.1171 (Forecasting Loss:0.1416 + XiCon Loss:2.9755 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 3.2626591
	speed: 0.0380s/iter; left time: 925.3384s
	iters: 200, epoch: 9 | loss: 3.0646710
	speed: 0.0349s/iter; left time: 847.7898s
Epoch: 9 cost time: 9.634009599685669
Epoch: 9, Steps: 266 Train Loss: 3.1142 (Forecasting Loss:0.1416 + XiCon Loss:2.9726 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0739
Validation loss decreased (0.107541 --> 0.107480).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 3.0883951
	speed: 0.0384s/iter; left time: 924.6565s
	iters: 200, epoch: 10 | loss: 3.0824070
	speed: 0.0346s/iter; left time: 831.3833s
Epoch: 10 cost time: 9.662622451782227
Epoch: 10, Steps: 266 Train Loss: 3.1028 (Forecasting Loss:0.1415 + XiCon Loss:2.9613 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107480 --> 0.107446).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 3.2491333
	speed: 0.0383s/iter; left time: 912.9722s
	iters: 200, epoch: 11 | loss: 3.2620325
	speed: 0.0352s/iter; left time: 835.4941s
Epoch: 11 cost time: 9.727999210357666
Epoch: 11, Steps: 266 Train Loss: 3.1069 (Forecasting Loss:0.1415 + XiCon Loss:2.9654 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107446 --> 0.107440).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 3.2966850
	speed: 0.0369s/iter; left time: 870.2684s
	iters: 200, epoch: 12 | loss: 3.0901587
	speed: 0.0354s/iter; left time: 830.1600s
Epoch: 12 cost time: 9.53889536857605
Epoch: 12, Steps: 266 Train Loss: 3.1121 (Forecasting Loss:0.1415 + XiCon Loss:2.9706 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107440 --> 0.107419).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 3.1966696
	speed: 0.0378s/iter; left time: 880.5751s
	iters: 200, epoch: 13 | loss: 3.1032479
	speed: 0.0354s/iter; left time: 822.3945s
Epoch: 13 cost time: 9.709028720855713
Epoch: 13, Steps: 266 Train Loss: 3.1068 (Forecasting Loss:0.1415 + XiCon Loss:2.9653 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107419 --> 0.107407).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 3.1437457
	speed: 0.0386s/iter; left time: 889.1882s
	iters: 200, epoch: 14 | loss: 3.2467728
	speed: 0.0351s/iter; left time: 805.2222s
Epoch: 14 cost time: 9.642074346542358
Epoch: 14, Steps: 266 Train Loss: 3.1066 (Forecasting Loss:0.1415 + XiCon Loss:2.9651 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 3.1343157
	speed: 0.0372s/iter; left time: 846.9307s
	iters: 200, epoch: 15 | loss: 3.1281142
	speed: 0.0363s/iter; left time: 822.9199s
Epoch: 15 cost time: 9.753613471984863
Epoch: 15, Steps: 266 Train Loss: 3.1100 (Forecasting Loss:0.1415 + XiCon Loss:2.9684 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 3.1647933
	speed: 0.0370s/iter; left time: 834.0005s
	iters: 200, epoch: 16 | loss: 3.0063300
	speed: 0.0347s/iter; left time: 777.9224s
Epoch: 16 cost time: 9.486225366592407
Epoch: 16, Steps: 266 Train Loss: 3.1051 (Forecasting Loss:0.1415 + XiCon Loss:2.9636 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 3.2052026
	speed: 0.0375s/iter; left time: 834.4151s
	iters: 200, epoch: 17 | loss: 3.0616541
	speed: 0.0351s/iter; left time: 777.9262s
Epoch: 17 cost time: 9.609977960586548
Epoch: 17, Steps: 266 Train Loss: 3.1063 (Forecasting Loss:0.1416 + XiCon Loss:2.9647 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 3.1389916
	speed: 0.0375s/iter; left time: 823.8904s
	iters: 200, epoch: 18 | loss: 3.0882668
	speed: 0.0357s/iter; left time: 781.6588s
Epoch: 18 cost time: 9.685960054397583
Epoch: 18, Steps: 266 Train Loss: 3.1091 (Forecasting Loss:0.1416 + XiCon Loss:2.9675 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 3.1267452
	speed: 0.0372s/iter; left time: 806.9136s
	iters: 200, epoch: 19 | loss: 3.0328543
	speed: 0.0356s/iter; left time: 768.8786s
Epoch: 19 cost time: 9.615763902664185
Epoch: 19, Steps: 266 Train Loss: 3.1058 (Forecasting Loss:0.1416 + XiCon Loss:2.9642 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
Validation loss decreased (0.107407 --> 0.107375).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 3.0978725
	speed: 0.0382s/iter; left time: 819.4697s
	iters: 200, epoch: 20 | loss: 3.1506889
	speed: 0.0357s/iter; left time: 761.7794s
Epoch: 20 cost time: 9.733558893203735
Epoch: 20, Steps: 266 Train Loss: 3.1154 (Forecasting Loss:0.1415 + XiCon Loss:2.9739 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 3.0221450
	speed: 0.0379s/iter; left time: 803.2849s
	iters: 200, epoch: 21 | loss: 2.9823966
	speed: 0.0362s/iter; left time: 762.5344s
Epoch: 21 cost time: 9.794471025466919
Epoch: 21, Steps: 266 Train Loss: 3.1130 (Forecasting Loss:0.1416 + XiCon Loss:2.9715 x Lambda(1.0)), Vali MSE Loss: 0.1074 Test MSE Loss: 0.0740
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 3.0778944
	speed: 0.0376s/iter; left time: 786.7349s
	iters: 200, epoch: 22 | loss: 2.9734044
	speed: 0.0354s/iter; left time: 735.9160s
Epoch: 22 cost time: 9.725500583648682
Epoch: 22, Steps: 266 Train Loss: 3.1071 (Forecasting Loss:0.1415 + XiCon Loss:2.9655 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 3.1340039
	speed: 0.0371s/iter; left time: 766.5400s
	iters: 200, epoch: 23 | loss: 3.0199196
	speed: 0.0357s/iter; left time: 732.8943s
Epoch: 23 cost time: 9.63070011138916
Epoch: 23, Steps: 266 Train Loss: 3.1003 (Forecasting Loss:0.1416 + XiCon Loss:2.9587 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 3.0825047
	speed: 0.0369s/iter; left time: 752.3420s
	iters: 200, epoch: 24 | loss: 3.1242108
	speed: 0.0351s/iter; left time: 712.2796s
Epoch: 24 cost time: 9.549540519714355
Epoch: 24, Steps: 266 Train Loss: 3.1081 (Forecasting Loss:0.1415 + XiCon Loss:2.9666 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 3.0275819
	speed: 0.0371s/iter; left time: 745.6412s
	iters: 200, epoch: 25 | loss: 3.0076239
	speed: 0.0364s/iter; left time: 728.6897s
Epoch: 25 cost time: 9.736519575119019
Epoch: 25, Steps: 266 Train Loss: 3.1084 (Forecasting Loss:0.1416 + XiCon Loss:2.9669 x Lambda(1.0)), Vali MSE Loss: 0.1076 Test MSE Loss: 0.0740
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 3.0990827
	speed: 0.0375s/iter; left time: 743.7429s
	iters: 200, epoch: 26 | loss: 3.0265458
	speed: 0.0349s/iter; left time: 688.4502s
Epoch: 26 cost time: 9.609979629516602
Epoch: 26, Steps: 266 Train Loss: 3.1127 (Forecasting Loss:0.1416 + XiCon Loss:2.9711 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 3.1119208
	speed: 0.0380s/iter; left time: 744.1737s
	iters: 200, epoch: 27 | loss: 3.0762208
	speed: 0.0356s/iter; left time: 694.4418s
Epoch: 27 cost time: 9.690609455108643
Epoch: 27, Steps: 266 Train Loss: 3.1113 (Forecasting Loss:0.1416 + XiCon Loss:2.9697 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 3.1263077
	speed: 0.0378s/iter; left time: 731.1795s
	iters: 200, epoch: 28 | loss: 3.1751111
	speed: 0.0351s/iter; left time: 674.7590s
Epoch: 28 cost time: 9.695796012878418
Epoch: 28, Steps: 266 Train Loss: 3.1133 (Forecasting Loss:0.1415 + XiCon Loss:2.9718 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 3.1047885
	speed: 0.0372s/iter; left time: 708.2921s
	iters: 200, epoch: 29 | loss: 3.2948928
	speed: 0.0365s/iter; left time: 691.5033s
Epoch: 29 cost time: 9.690088272094727
Epoch: 29, Steps: 266 Train Loss: 3.1074 (Forecasting Loss:0.1415 + XiCon Loss:2.9659 x Lambda(1.0)), Vali MSE Loss: 0.1075 Test MSE Loss: 0.0740
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl96_dm32_nh8_el3_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.026291854679584503, mae:0.12168052792549133, mape:0.0983908399939537, mspe:0.01956416293978691 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0265+-0.00041, MAE:0.1221+-0.00085, MAPE:0.0988+-0.00110, MSPE:0.0198+-0.00059, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=32, n_heads=8, e_layers=5, d_layers=1, d_ff=32, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.1400
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.5692158
	speed: 0.0498s/iter; left time: 1315.5504s
	iters: 200, epoch: 1 | loss: 29.4778233
	speed: 0.0443s/iter; left time: 1164.8045s
Epoch: 1 cost time: 12.332838535308838
Epoch: 1, Steps: 265 Train Loss: 30.4582 (Forecasting Loss:0.2098 + XiCon Loss:3.0248 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.0983
Validation loss decreased (inf --> 0.148612).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 35.4539146
	speed: 0.0507s/iter; left time: 1325.3243s
	iters: 200, epoch: 2 | loss: 34.5255165
	speed: 0.0470s/iter; left time: 1224.8201s
Epoch: 2 cost time: 12.85381555557251
Epoch: 2, Steps: 265 Train Loss: 34.3749 (Forecasting Loss:0.1984 + XiCon Loss:3.4176 x Lambda(10.0)), Vali MSE Loss: 0.1457 Test MSE Loss: 0.0961
Validation loss decreased (0.148612 --> 0.145696).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.7882004
	speed: 0.0479s/iter; left time: 1238.2550s
	iters: 200, epoch: 3 | loss: 31.5274010
	speed: 0.0452s/iter; left time: 1164.2975s
Epoch: 3 cost time: 12.422090768814087
Epoch: 3, Steps: 265 Train Loss: 33.7164 (Forecasting Loss:0.1922 + XiCon Loss:3.3524 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0955
Validation loss decreased (0.145696 --> 0.143802).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 32.1493340
	speed: 0.0489s/iter; left time: 1251.2265s
	iters: 200, epoch: 4 | loss: 31.5431862
	speed: 0.0459s/iter; left time: 1171.0871s
Epoch: 4 cost time: 12.506452322006226
Epoch: 4, Steps: 265 Train Loss: 32.9806 (Forecasting Loss:0.1902 + XiCon Loss:3.2790 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.0958
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.0985641
	speed: 0.0490s/iter; left time: 1242.0466s
	iters: 200, epoch: 5 | loss: 30.1157475
	speed: 0.0470s/iter; left time: 1186.7119s
Epoch: 5 cost time: 12.640907049179077
Epoch: 5, Steps: 265 Train Loss: 30.9955 (Forecasting Loss:0.1904 + XiCon Loss:3.0805 x Lambda(10.0)), Vali MSE Loss: 0.1432 Test MSE Loss: 0.0952
Validation loss decreased (0.143802 --> 0.143165).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.8449936
	speed: 0.0496s/iter; left time: 1244.9558s
	iters: 200, epoch: 6 | loss: 32.2868767
	speed: 0.0477s/iter; left time: 1190.7504s
Epoch: 6 cost time: 12.813571214675903
Epoch: 6, Steps: 265 Train Loss: 32.3254 (Forecasting Loss:0.1891 + XiCon Loss:3.2136 x Lambda(10.0)), Vali MSE Loss: 0.1429 Test MSE Loss: 0.0947
Validation loss decreased (0.143165 --> 0.142917).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.5894794
	speed: 0.0485s/iter; left time: 1202.8704s
	iters: 200, epoch: 7 | loss: 33.0037651
	speed: 0.0461s/iter; left time: 1140.1311s
Epoch: 7 cost time: 12.55681562423706
Epoch: 7, Steps: 265 Train Loss: 32.7818 (Forecasting Loss:0.1887 + XiCon Loss:3.2593 x Lambda(10.0)), Vali MSE Loss: 0.1427 Test MSE Loss: 0.0947
Validation loss decreased (0.142917 --> 0.142724).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.5037308
	speed: 0.0489s/iter; left time: 1199.4684s
	iters: 200, epoch: 8 | loss: 30.9201260
	speed: 0.0478s/iter; left time: 1167.5354s
Epoch: 8 cost time: 12.831117153167725
Epoch: 8, Steps: 265 Train Loss: 32.6995 (Forecasting Loss:0.1887 + XiCon Loss:3.2511 x Lambda(10.0)), Vali MSE Loss: 0.1426 Test MSE Loss: 0.0947
Validation loss decreased (0.142724 --> 0.142614).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 34.2907600
	speed: 0.0485s/iter; left time: 1177.1247s
	iters: 200, epoch: 9 | loss: 30.3045254
	speed: 0.0466s/iter; left time: 1126.4720s
Epoch: 9 cost time: 12.588639974594116
Epoch: 9, Steps: 265 Train Loss: 32.6940 (Forecasting Loss:0.1885 + XiCon Loss:3.2506 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0947
Validation loss decreased (0.142614 --> 0.142507).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.3458748
	speed: 0.0484s/iter; left time: 1162.6628s
	iters: 200, epoch: 10 | loss: 32.3448906
	speed: 0.0465s/iter; left time: 1111.2959s
Epoch: 10 cost time: 12.552608251571655
Epoch: 10, Steps: 265 Train Loss: 32.6851 (Forecasting Loss:0.1885 + XiCon Loss:3.2497 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0947
Validation loss decreased (0.142507 --> 0.142422).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 33.3066788
	speed: 0.0491s/iter; left time: 1165.3102s
	iters: 200, epoch: 11 | loss: 31.2076550
	speed: 0.0468s/iter; left time: 1105.9988s
Epoch: 11 cost time: 12.602543354034424
Epoch: 11, Steps: 265 Train Loss: 32.7813 (Forecasting Loss:0.1885 + XiCon Loss:3.2593 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 34.0097427
	speed: 0.0487s/iter; left time: 1142.7263s
	iters: 200, epoch: 12 | loss: 33.5143547
	speed: 0.0473s/iter; left time: 1105.7445s
Epoch: 12 cost time: 12.740712404251099
Epoch: 12, Steps: 265 Train Loss: 32.6807 (Forecasting Loss:0.1884 + XiCon Loss:3.2492 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
Validation loss decreased (0.142422 --> 0.142365).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 33.1370163
	speed: 0.0517s/iter; left time: 1199.8811s
	iters: 200, epoch: 13 | loss: 31.7374401
	speed: 0.0469s/iter; left time: 1084.1443s
Epoch: 13 cost time: 12.939609289169312
Epoch: 13, Steps: 265 Train Loss: 32.7993 (Forecasting Loss:0.1884 + XiCon Loss:3.2611 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 33.1707764
	speed: 0.0486s/iter; left time: 1114.7188s
	iters: 200, epoch: 14 | loss: 30.2826824
	speed: 0.0468s/iter; left time: 1069.6913s
Epoch: 14 cost time: 12.630470991134644
Epoch: 14, Steps: 265 Train Loss: 32.6993 (Forecasting Loss:0.1885 + XiCon Loss:3.2511 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.7965870
	speed: 0.0483s/iter; left time: 1095.1902s
	iters: 200, epoch: 15 | loss: 32.5439377
	speed: 0.0472s/iter; left time: 1065.8638s
Epoch: 15 cost time: 12.589215993881226
Epoch: 15, Steps: 265 Train Loss: 32.7194 (Forecasting Loss:0.1884 + XiCon Loss:3.2531 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.7608585
	speed: 0.0491s/iter; left time: 1100.4168s
	iters: 200, epoch: 16 | loss: 32.9307938
	speed: 0.0467s/iter; left time: 1042.8263s
Epoch: 16 cost time: 12.703468561172485
Epoch: 16, Steps: 265 Train Loss: 32.7646 (Forecasting Loss:0.1884 + XiCon Loss:3.2576 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0946
Validation loss decreased (0.142365 --> 0.142315).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.4115067
	speed: 0.0484s/iter; left time: 1072.1966s
	iters: 200, epoch: 17 | loss: 31.7737255
	speed: 0.0480s/iter; left time: 1058.3782s
Epoch: 17 cost time: 12.74425458908081
Epoch: 17, Steps: 265 Train Loss: 32.6685 (Forecasting Loss:0.1884 + XiCon Loss:3.2480 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0946
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 34.0461006
	speed: 0.0482s/iter; left time: 1054.5695s
	iters: 200, epoch: 18 | loss: 33.6427879
	speed: 0.0466s/iter; left time: 1014.7580s
Epoch: 18 cost time: 12.523679256439209
Epoch: 18, Steps: 265 Train Loss: 32.7062 (Forecasting Loss:0.1883 + XiCon Loss:3.2518 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 32.6483650
	speed: 0.0496s/iter; left time: 1072.4273s
	iters: 200, epoch: 19 | loss: 31.3344097
	speed: 0.0468s/iter; left time: 1008.6213s
Epoch: 19 cost time: 12.766487836837769
Epoch: 19, Steps: 265 Train Loss: 32.7828 (Forecasting Loss:0.1884 + XiCon Loss:3.2594 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.1370201
	speed: 0.0496s/iter; left time: 1059.3360s
	iters: 200, epoch: 20 | loss: 35.1436272
	speed: 0.0465s/iter; left time: 989.1479s
Epoch: 20 cost time: 12.721050262451172
Epoch: 20, Steps: 265 Train Loss: 32.8232 (Forecasting Loss:0.1883 + XiCon Loss:3.2635 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0946
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 30.3376865
	speed: 0.0491s/iter; left time: 1036.1359s
	iters: 200, epoch: 21 | loss: 32.1268005
	speed: 0.0467s/iter; left time: 980.3785s
Epoch: 21 cost time: 12.63781189918518
Epoch: 21, Steps: 265 Train Loss: 32.6380 (Forecasting Loss:0.1884 + XiCon Loss:3.2450 x Lambda(10.0)), Vali MSE Loss: 0.1425 Test MSE Loss: 0.0946
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.8633270
	speed: 0.0497s/iter; left time: 1035.0317s
	iters: 200, epoch: 22 | loss: 34.4363251
	speed: 0.0467s/iter; left time: 968.5061s
Epoch: 22 cost time: 12.727348327636719
Epoch: 22, Steps: 265 Train Loss: 32.6744 (Forecasting Loss:0.1883 + XiCon Loss:3.2486 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 34.3062744
	speed: 0.0494s/iter; left time: 1015.9236s
	iters: 200, epoch: 23 | loss: 33.3772469
	speed: 0.0472s/iter; left time: 966.4658s
Epoch: 23 cost time: 12.753600120544434
Epoch: 23, Steps: 265 Train Loss: 32.7245 (Forecasting Loss:0.1884 + XiCon Loss:3.2536 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 32.3578529
	speed: 0.0486s/iter; left time: 986.6143s
	iters: 200, epoch: 24 | loss: 32.4168663
	speed: 0.0467s/iter; left time: 944.0185s
Epoch: 24 cost time: 12.584953308105469
Epoch: 24, Steps: 265 Train Loss: 32.7305 (Forecasting Loss:0.1885 + XiCon Loss:3.2542 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 34.5054779
	speed: 0.0488s/iter; left time: 978.2059s
	iters: 200, epoch: 25 | loss: 33.6150665
	speed: 0.0478s/iter; left time: 953.7947s
Epoch: 25 cost time: 12.741679668426514
Epoch: 25, Steps: 265 Train Loss: 32.6908 (Forecasting Loss:0.1884 + XiCon Loss:3.2502 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 33.2405739
	speed: 0.0492s/iter; left time: 972.9509s
	iters: 200, epoch: 26 | loss: 31.1648331
	speed: 0.0480s/iter; left time: 944.3268s
Epoch: 26 cost time: 12.883138418197632
Epoch: 26, Steps: 265 Train Loss: 32.7498 (Forecasting Loss:0.1884 + XiCon Loss:3.2561 x Lambda(10.0)), Vali MSE Loss: 0.1424 Test MSE Loss: 0.0946
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03940049558877945, mae:0.14988718926906586, mape:0.11925208568572998, mspe:0.0268320944160223 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.0231
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 29.9404545
	speed: 0.0477s/iter; left time: 1259.0237s
	iters: 200, epoch: 1 | loss: 29.3449364
	speed: 0.0448s/iter; left time: 1177.7131s
Epoch: 1 cost time: 12.136641502380371
Epoch: 1, Steps: 265 Train Loss: 30.3027 (Forecasting Loss:0.2121 + XiCon Loss:3.0091 x Lambda(10.0)), Vali MSE Loss: 0.1470 Test MSE Loss: 0.0987
Validation loss decreased (inf --> 0.147025).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 30.7566452
	speed: 0.0488s/iter; left time: 1275.3890s
	iters: 200, epoch: 2 | loss: 31.1820431
	speed: 0.0461s/iter; left time: 1200.3169s
Epoch: 2 cost time: 12.543700695037842
Epoch: 2, Steps: 265 Train Loss: 31.3340 (Forecasting Loss:0.1984 + XiCon Loss:3.1136 x Lambda(10.0)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.0974
Validation loss decreased (0.147025 --> 0.146282).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.1717300
	speed: 0.0489s/iter; left time: 1264.1711s
	iters: 200, epoch: 3 | loss: 31.8334942
	speed: 0.0472s/iter; left time: 1217.1903s
Epoch: 3 cost time: 12.70220136642456
Epoch: 3, Steps: 265 Train Loss: 30.8737 (Forecasting Loss:0.1928 + XiCon Loss:3.0681 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.0956
Validation loss decreased (0.146282 --> 0.143754).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6327000
	speed: 0.0494s/iter; left time: 1265.4957s
	iters: 200, epoch: 4 | loss: 30.2580204
	speed: 0.0471s/iter; left time: 1200.4796s
Epoch: 4 cost time: 12.657609939575195
Epoch: 4, Steps: 265 Train Loss: 30.7946 (Forecasting Loss:0.1914 + XiCon Loss:3.0603 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0951
Validation loss decreased (0.143754 --> 0.142189).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.7609081
	speed: 0.0487s/iter; left time: 1234.8896s
	iters: 200, epoch: 5 | loss: 30.9157124
	speed: 0.0467s/iter; left time: 1178.3241s
Epoch: 5 cost time: 12.631344079971313
Epoch: 5, Steps: 265 Train Loss: 30.8435 (Forecasting Loss:0.1902 + XiCon Loss:3.0653 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
Validation loss decreased (0.142189 --> 0.141738).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.5837173
	speed: 0.0498s/iter; left time: 1249.9831s
	iters: 200, epoch: 6 | loss: 29.2876530
	speed: 0.0466s/iter; left time: 1163.2608s
Epoch: 6 cost time: 12.776869297027588
Epoch: 6, Steps: 265 Train Loss: 30.4410 (Forecasting Loss:0.1898 + XiCon Loss:3.0251 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.4674644
	speed: 0.0483s/iter; left time: 1197.4096s
	iters: 200, epoch: 7 | loss: 30.4774723
	speed: 0.0478s/iter; left time: 1181.3817s
Epoch: 7 cost time: 12.667186737060547
Epoch: 7, Steps: 265 Train Loss: 30.6782 (Forecasting Loss:0.1895 + XiCon Loss:3.0489 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0950
Validation loss decreased (0.141738 --> 0.141545).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.3364277
	speed: 0.0486s/iter; left time: 1193.2616s
	iters: 200, epoch: 8 | loss: 29.4090118
	speed: 0.0472s/iter; left time: 1154.1743s
Epoch: 8 cost time: 12.728883504867554
Epoch: 8, Steps: 265 Train Loss: 30.4229 (Forecasting Loss:0.1892 + XiCon Loss:3.0234 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0951
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.1767464
	speed: 0.0500s/iter; left time: 1213.0111s
	iters: 200, epoch: 9 | loss: 31.6907902
	speed: 0.0476s/iter; left time: 1151.8374s
Epoch: 9 cost time: 12.930519342422485
Epoch: 9, Steps: 265 Train Loss: 30.3661 (Forecasting Loss:0.1891 + XiCon Loss:3.0177 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.1463394
	speed: 0.0488s/iter; left time: 1171.9567s
	iters: 200, epoch: 10 | loss: 30.2311802
	speed: 0.0471s/iter; left time: 1126.4420s
Epoch: 10 cost time: 12.70317816734314
Epoch: 10, Steps: 265 Train Loss: 30.3668 (Forecasting Loss:0.1890 + XiCon Loss:3.0178 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0950
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.6272144
	speed: 0.0495s/iter; left time: 1176.8021s
	iters: 200, epoch: 11 | loss: 32.0852547
	speed: 0.0468s/iter; left time: 1106.6530s
Epoch: 11 cost time: 12.744937658309937
Epoch: 11, Steps: 265 Train Loss: 30.3811 (Forecasting Loss:0.1891 + XiCon Loss:3.0192 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0950
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.7261047
	speed: 0.0495s/iter; left time: 1162.1023s
	iters: 200, epoch: 12 | loss: 29.8483143
	speed: 0.0467s/iter; left time: 1092.8839s
Epoch: 12 cost time: 12.756946086883545
Epoch: 12, Steps: 265 Train Loss: 30.3724 (Forecasting Loss:0.1890 + XiCon Loss:3.0183 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0950
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.9650230
	speed: 0.0487s/iter; left time: 1131.8384s
	iters: 200, epoch: 13 | loss: 30.5187950
	speed: 0.0465s/iter; left time: 1075.8453s
Epoch: 13 cost time: 12.706889390945435
Epoch: 13, Steps: 265 Train Loss: 30.4681 (Forecasting Loss:0.1890 + XiCon Loss:3.0279 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0950
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.1421928
	speed: 0.0492s/iter; left time: 1130.3448s
	iters: 200, epoch: 14 | loss: 29.8595085
	speed: 0.0473s/iter; left time: 1080.1475s
Epoch: 14 cost time: 12.76006531715393
Epoch: 14, Steps: 265 Train Loss: 30.3956 (Forecasting Loss:0.1891 + XiCon Loss:3.0207 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0950
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.3372879
	speed: 0.0494s/iter; left time: 1120.2997s
	iters: 200, epoch: 15 | loss: 29.6349525
	speed: 0.0473s/iter; left time: 1068.6640s
Epoch: 15 cost time: 12.80310869216919
Epoch: 15, Steps: 265 Train Loss: 30.3947 (Forecasting Loss:0.1890 + XiCon Loss:3.0206 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0950
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.5685425
	speed: 0.0493s/iter; left time: 1105.2311s
	iters: 200, epoch: 16 | loss: 29.8805523
	speed: 0.0481s/iter; left time: 1073.0965s
Epoch: 16 cost time: 12.855502367019653
Epoch: 16, Steps: 265 Train Loss: 30.2492 (Forecasting Loss:0.1889 + XiCon Loss:3.0060 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0950
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.7031593
	speed: 0.0487s/iter; left time: 1078.3567s
	iters: 200, epoch: 17 | loss: 31.2662849
	speed: 0.0470s/iter; left time: 1037.9511s
Epoch: 17 cost time: 12.697192192077637
Epoch: 17, Steps: 265 Train Loss: 30.3776 (Forecasting Loss:0.1889 + XiCon Loss:3.0189 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039673347026109695, mae:0.1502428948879242, mape:0.11944404989480972, mspe:0.026678230613470078 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.4000
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.6096592
	speed: 0.0477s/iter; left time: 1259.5627s
	iters: 200, epoch: 1 | loss: 30.0649300
	speed: 0.0443s/iter; left time: 1164.6514s
Epoch: 1 cost time: 12.114340543746948
Epoch: 1, Steps: 265 Train Loss: 30.3376 (Forecasting Loss:0.2115 + XiCon Loss:3.0126 x Lambda(10.0)), Vali MSE Loss: 0.1477 Test MSE Loss: 0.0985
Validation loss decreased (inf --> 0.147703).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.4980850
	speed: 0.0502s/iter; left time: 1312.4608s
	iters: 200, epoch: 2 | loss: 36.3909225
	speed: 0.0462s/iter; left time: 1201.6100s
Epoch: 2 cost time: 12.707683801651001
Epoch: 2, Steps: 265 Train Loss: 35.1231 (Forecasting Loss:0.2106 + XiCon Loss:3.4912 x Lambda(10.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0977
Validation loss decreased (0.147703 --> 0.146416).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 36.9233437
	speed: 0.0483s/iter; left time: 1248.6999s
	iters: 200, epoch: 3 | loss: 35.8998680
	speed: 0.0463s/iter; left time: 1193.0787s
Epoch: 3 cost time: 12.496496438980103
Epoch: 3, Steps: 265 Train Loss: 36.9480 (Forecasting Loss:0.2949 + XiCon Loss:3.6653 x Lambda(10.0)), Vali MSE Loss: 0.1434 Test MSE Loss: 0.0956
Validation loss decreased (0.146416 --> 0.143409).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 36.2044029
	speed: 0.0501s/iter; left time: 1284.1168s
	iters: 200, epoch: 4 | loss: 37.5963516
	speed: 0.0467s/iter; left time: 1192.1475s
Epoch: 4 cost time: 12.824275970458984
Epoch: 4, Steps: 265 Train Loss: 35.6351 (Forecasting Loss:0.2042 + XiCon Loss:3.5431 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0954
Validation loss decreased (0.143409 --> 0.141859).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 35.7722855
	speed: 0.0492s/iter; left time: 1247.6290s
	iters: 200, epoch: 5 | loss: 38.8020172
	speed: 0.0477s/iter; left time: 1204.8541s
Epoch: 5 cost time: 12.70012640953064
Epoch: 5, Steps: 265 Train Loss: 35.5279 (Forecasting Loss:0.1899 + XiCon Loss:3.5338 x Lambda(10.0)), Vali MSE Loss: 0.1422 Test MSE Loss: 0.0951
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 36.8466072
	speed: 0.0497s/iter; left time: 1246.0020s
	iters: 200, epoch: 6 | loss: 34.6403732
	speed: 0.0471s/iter; left time: 1176.1140s
Epoch: 6 cost time: 12.71885347366333
Epoch: 6, Steps: 265 Train Loss: 35.3480 (Forecasting Loss:0.1894 + XiCon Loss:3.5159 x Lambda(10.0)), Vali MSE Loss: 0.1419 Test MSE Loss: 0.0949
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 33.7953873
	speed: 0.0488s/iter; left time: 1210.8930s
	iters: 200, epoch: 7 | loss: 36.2659302
	speed: 0.0464s/iter; left time: 1145.5018s
Epoch: 7 cost time: 12.618062019348145
Epoch: 7, Steps: 265 Train Loss: 35.1875 (Forecasting Loss:0.1891 + XiCon Loss:3.4998 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
Validation loss decreased (0.141859 --> 0.141569).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 32.9266815
	speed: 0.0491s/iter; left time: 1205.8561s
	iters: 200, epoch: 8 | loss: 33.5035172
	speed: 0.0470s/iter; left time: 1148.4314s
Epoch: 8 cost time: 12.73246169090271
Epoch: 8, Steps: 265 Train Loss: 35.1250 (Forecasting Loss:0.1890 + XiCon Loss:3.4936 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0949
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 38.2507362
	speed: 0.0490s/iter; left time: 1189.9998s
	iters: 200, epoch: 9 | loss: 33.9566002
	speed: 0.0474s/iter; left time: 1146.7847s
Epoch: 9 cost time: 12.689810514450073
Epoch: 9, Steps: 265 Train Loss: 34.9369 (Forecasting Loss:0.1888 + XiCon Loss:3.4748 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0950
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 35.9571533
	speed: 0.0490s/iter; left time: 1176.3537s
	iters: 200, epoch: 10 | loss: 37.7758675
	speed: 0.0480s/iter; left time: 1147.2007s
Epoch: 10 cost time: 12.759382486343384
Epoch: 10, Steps: 265 Train Loss: 34.7298 (Forecasting Loss:0.1888 + XiCon Loss:3.4541 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
Validation loss decreased (0.141569 --> 0.141488).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.2839737
	speed: 0.0483s/iter; left time: 1146.0511s
	iters: 200, epoch: 11 | loss: 32.8494225
	speed: 0.0467s/iter; left time: 1105.1066s
Epoch: 11 cost time: 12.55968451499939
Epoch: 11, Steps: 265 Train Loss: 35.0205 (Forecasting Loss:0.1888 + XiCon Loss:3.4832 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 37.0210457
	speed: 0.0486s/iter; left time: 1141.7573s
	iters: 200, epoch: 12 | loss: 35.1140823
	speed: 0.0471s/iter; left time: 1101.6010s
Epoch: 12 cost time: 12.654788970947266
Epoch: 12, Steps: 265 Train Loss: 35.0151 (Forecasting Loss:0.1887 + XiCon Loss:3.4826 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 34.1208801
	speed: 0.0488s/iter; left time: 1132.6013s
	iters: 200, epoch: 13 | loss: 37.0688515
	speed: 0.0472s/iter; left time: 1092.1923s
Epoch: 13 cost time: 12.721581935882568
Epoch: 13, Steps: 265 Train Loss: 35.1153 (Forecasting Loss:0.1888 + XiCon Loss:3.4927 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 34.4666481
	speed: 0.0485s/iter; left time: 1113.4062s
	iters: 200, epoch: 14 | loss: 36.1049843
	speed: 0.0468s/iter; left time: 1070.6915s
Epoch: 14 cost time: 12.62825322151184
Epoch: 14, Steps: 265 Train Loss: 34.9257 (Forecasting Loss:0.1888 + XiCon Loss:3.4737 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 35.4075127
	speed: 0.0498s/iter; left time: 1130.1777s
	iters: 200, epoch: 15 | loss: 36.1323929
	speed: 0.0471s/iter; left time: 1063.7809s
Epoch: 15 cost time: 12.773669004440308
Epoch: 15, Steps: 265 Train Loss: 34.9337 (Forecasting Loss:0.1887 + XiCon Loss:3.4745 x Lambda(10.0)), Vali MSE Loss: 0.1414 Test MSE Loss: 0.0948
Validation loss decreased (0.141488 --> 0.141440).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 36.5488243
	speed: 0.0494s/iter; left time: 1107.3382s
	iters: 200, epoch: 16 | loss: 37.0318260
	speed: 0.0475s/iter; left time: 1060.4498s
Epoch: 16 cost time: 12.810694932937622
Epoch: 16, Steps: 265 Train Loss: 34.9453 (Forecasting Loss:0.1888 + XiCon Loss:3.4757 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.7995052
	speed: 0.0493s/iter; left time: 1091.7067s
	iters: 200, epoch: 17 | loss: 36.7001457
	speed: 0.0475s/iter; left time: 1047.6345s
Epoch: 17 cost time: 12.772493839263916
Epoch: 17, Steps: 265 Train Loss: 34.9321 (Forecasting Loss:0.1888 + XiCon Loss:3.4743 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 34.8760719
	speed: 0.0496s/iter; left time: 1086.1271s
	iters: 200, epoch: 18 | loss: 33.9168472
	speed: 0.0471s/iter; left time: 1025.5239s
Epoch: 18 cost time: 12.796838998794556
Epoch: 18, Steps: 265 Train Loss: 35.0981 (Forecasting Loss:0.1889 + XiCon Loss:3.4909 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 36.2911491
	speed: 0.0484s/iter; left time: 1046.5288s
	iters: 200, epoch: 19 | loss: 35.7557945
	speed: 0.0467s/iter; left time: 1006.2785s
Epoch: 19 cost time: 12.66307282447815
Epoch: 19, Steps: 265 Train Loss: 34.9821 (Forecasting Loss:0.1887 + XiCon Loss:3.4793 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 34.7856712
	speed: 0.0489s/iter; left time: 1045.4632s
	iters: 200, epoch: 20 | loss: 35.4103165
	speed: 0.0471s/iter; left time: 1002.4615s
Epoch: 20 cost time: 12.711412906646729
Epoch: 20, Steps: 265 Train Loss: 35.0438 (Forecasting Loss:0.1888 + XiCon Loss:3.4855 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 34.1825180
	speed: 0.0486s/iter; left time: 1025.5781s
	iters: 200, epoch: 21 | loss: 32.6119041
	speed: 0.0470s/iter; left time: 986.4816s
Epoch: 21 cost time: 12.607552766799927
Epoch: 21, Steps: 265 Train Loss: 34.9236 (Forecasting Loss:0.1887 + XiCon Loss:3.4735 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 36.5752907
	speed: 0.0486s/iter; left time: 1013.0215s
	iters: 200, epoch: 22 | loss: 36.2654724
	speed: 0.0479s/iter; left time: 993.9251s
Epoch: 22 cost time: 12.767695665359497
Epoch: 22, Steps: 265 Train Loss: 35.1069 (Forecasting Loss:0.1887 + XiCon Loss:3.4918 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 34.6198082
	speed: 0.0485s/iter; left time: 998.5468s
	iters: 200, epoch: 23 | loss: 33.9417839
	speed: 0.0469s/iter; left time: 960.4095s
Epoch: 23 cost time: 12.612558841705322
Epoch: 23, Steps: 265 Train Loss: 35.0027 (Forecasting Loss:0.1887 + XiCon Loss:3.4814 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 34.8166695
	speed: 0.0485s/iter; left time: 984.2618s
	iters: 200, epoch: 24 | loss: 32.5041847
	speed: 0.0473s/iter; left time: 956.2796s
Epoch: 24 cost time: 12.702218294143677
Epoch: 24, Steps: 265 Train Loss: 35.2227 (Forecasting Loss:0.1887 + XiCon Loss:3.5034 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0948
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 33.2152901
	speed: 0.0482s/iter; left time: 965.3122s
	iters: 200, epoch: 25 | loss: 37.4734535
	speed: 0.0473s/iter; left time: 944.1920s
Epoch: 25 cost time: 12.581845045089722
Epoch: 25, Steps: 265 Train Loss: 34.9266 (Forecasting Loss:0.1888 + XiCon Loss:3.4738 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0948
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039551980793476105, mae:0.1501004993915558, mape:0.11931725591421127, mspe:0.026769012212753296 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.5077
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.0953598
	speed: 0.0481s/iter; left time: 1270.3260s
	iters: 200, epoch: 1 | loss: 29.7320251
	speed: 0.0448s/iter; left time: 1179.1752s
Epoch: 1 cost time: 12.252512693405151
Epoch: 1, Steps: 265 Train Loss: 30.2355 (Forecasting Loss:0.2095 + XiCon Loss:3.0026 x Lambda(10.0)), Vali MSE Loss: 0.1475 Test MSE Loss: 0.1005
Validation loss decreased (inf --> 0.147467).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 36.0104599
	speed: 0.0506s/iter; left time: 1322.4646s
	iters: 200, epoch: 2 | loss: 36.1309242
	speed: 0.0462s/iter; left time: 1203.4950s
Epoch: 2 cost time: 12.784819841384888
Epoch: 2, Steps: 265 Train Loss: 35.0871 (Forecasting Loss:0.1969 + XiCon Loss:3.4890 x Lambda(10.0)), Vali MSE Loss: 0.1463 Test MSE Loss: 0.0967
Validation loss decreased (0.147467 --> 0.146338).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.9101505
	speed: 0.0486s/iter; left time: 1257.5328s
	iters: 200, epoch: 3 | loss: 34.1286964
	speed: 0.0468s/iter; left time: 1205.1490s
Epoch: 3 cost time: 12.634811162948608
Epoch: 3, Steps: 265 Train Loss: 33.4829 (Forecasting Loss:0.1934 + XiCon Loss:3.3290 x Lambda(10.0)), Vali MSE Loss: 0.1459 Test MSE Loss: 0.0972
Validation loss decreased (0.146338 --> 0.145866).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 34.0782623
	speed: 0.0487s/iter; left time: 1247.9603s
	iters: 200, epoch: 4 | loss: 30.4134045
	speed: 0.0464s/iter; left time: 1184.4138s
Epoch: 4 cost time: 12.547518491744995
Epoch: 4, Steps: 265 Train Loss: 32.1816 (Forecasting Loss:0.1915 + XiCon Loss:3.1990 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0951
Validation loss decreased (0.145866 --> 0.142279).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.7459641
	speed: 0.0476s/iter; left time: 1205.4336s
	iters: 200, epoch: 5 | loss: 32.2623978
	speed: 0.0467s/iter; left time: 1178.2683s
Epoch: 5 cost time: 12.458097696304321
Epoch: 5, Steps: 265 Train Loss: 32.1004 (Forecasting Loss:0.1902 + XiCon Loss:3.1910 x Lambda(10.0)), Vali MSE Loss: 0.1423 Test MSE Loss: 0.0953
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 33.5535240
	speed: 0.0486s/iter; left time: 1217.6633s
	iters: 200, epoch: 6 | loss: 33.2044983
	speed: 0.0462s/iter; left time: 1154.7836s
Epoch: 6 cost time: 12.56380009651184
Epoch: 6, Steps: 265 Train Loss: 32.1754 (Forecasting Loss:0.1894 + XiCon Loss:3.1986 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0947
Validation loss decreased (0.142279 --> 0.141733).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 32.3464317
	speed: 0.0490s/iter; left time: 1215.9372s
	iters: 200, epoch: 7 | loss: 30.7276001
	speed: 0.0470s/iter; left time: 1162.2827s
Epoch: 7 cost time: 12.719602823257446
Epoch: 7, Steps: 265 Train Loss: 32.0038 (Forecasting Loss:0.1892 + XiCon Loss:3.1815 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0947
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 31.8309307
	speed: 0.0490s/iter; left time: 1203.6555s
	iters: 200, epoch: 8 | loss: 32.6040154
	speed: 0.0479s/iter; left time: 1170.0947s
Epoch: 8 cost time: 12.799525737762451
Epoch: 8, Steps: 265 Train Loss: 32.0068 (Forecasting Loss:0.1891 + XiCon Loss:3.1818 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0946
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 32.1422729
	speed: 0.0490s/iter; left time: 1190.9369s
	iters: 200, epoch: 9 | loss: 32.0552711
	speed: 0.0469s/iter; left time: 1134.6253s
Epoch: 9 cost time: 12.660470962524414
Epoch: 9, Steps: 265 Train Loss: 32.0717 (Forecasting Loss:0.1889 + XiCon Loss:3.1883 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141733 --> 0.141655).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 33.6717262
	speed: 0.0496s/iter; left time: 1191.5538s
	iters: 200, epoch: 10 | loss: 33.3336296
	speed: 0.0468s/iter; left time: 1118.1167s
Epoch: 10 cost time: 12.76724910736084
Epoch: 10, Steps: 265 Train Loss: 32.0605 (Forecasting Loss:0.1889 + XiCon Loss:3.1872 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0945
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.5565205
	speed: 0.0490s/iter; left time: 1164.1971s
	iters: 200, epoch: 11 | loss: 31.7060661
	speed: 0.0466s/iter; left time: 1103.1641s
Epoch: 11 cost time: 12.733439207077026
Epoch: 11, Steps: 265 Train Loss: 32.0088 (Forecasting Loss:0.1889 + XiCon Loss:3.1820 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5213280
	speed: 0.0494s/iter; left time: 1161.1280s
	iters: 200, epoch: 12 | loss: 32.0418777
	speed: 0.0469s/iter; left time: 1097.9607s
Epoch: 12 cost time: 12.746147394180298
Epoch: 12, Steps: 265 Train Loss: 31.8418 (Forecasting Loss:0.1888 + XiCon Loss:3.1653 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141655 --> 0.141626).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.3940563
	speed: 0.0482s/iter; left time: 1118.3406s
	iters: 200, epoch: 13 | loss: 30.5271492
	speed: 0.0469s/iter; left time: 1085.1518s
Epoch: 13 cost time: 12.608275175094604
Epoch: 13, Steps: 265 Train Loss: 31.8611 (Forecasting Loss:0.1888 + XiCon Loss:3.1672 x Lambda(10.0)), Vali MSE Loss: 0.1415 Test MSE Loss: 0.0944
Validation loss decreased (0.141626 --> 0.141492).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 34.0209045
	speed: 0.0489s/iter; left time: 1123.1662s
	iters: 200, epoch: 14 | loss: 33.8329620
	speed: 0.0477s/iter; left time: 1090.8434s
Epoch: 14 cost time: 12.80476188659668
Epoch: 14, Steps: 265 Train Loss: 31.9276 (Forecasting Loss:0.1890 + XiCon Loss:3.1739 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 33.6439285
	speed: 0.0487s/iter; left time: 1104.1658s
	iters: 200, epoch: 15 | loss: 32.1504402
	speed: 0.0479s/iter; left time: 1083.1193s
Epoch: 15 cost time: 12.751515626907349
Epoch: 15, Steps: 265 Train Loss: 31.9503 (Forecasting Loss:0.1889 + XiCon Loss:3.1761 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 32.0809593
	speed: 0.0492s/iter; left time: 1103.2142s
	iters: 200, epoch: 16 | loss: 31.3503361
	speed: 0.0481s/iter; left time: 1074.1909s
Epoch: 16 cost time: 12.78440260887146
Epoch: 16, Steps: 265 Train Loss: 31.8792 (Forecasting Loss:0.1890 + XiCon Loss:3.1690 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 32.2545853
	speed: 0.0496s/iter; left time: 1100.1256s
	iters: 200, epoch: 17 | loss: 31.5704899
	speed: 0.0476s/iter; left time: 1051.0683s
Epoch: 17 cost time: 12.915186405181885
Epoch: 17, Steps: 265 Train Loss: 31.8841 (Forecasting Loss:0.1890 + XiCon Loss:3.1695 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.3038425
	speed: 0.0493s/iter; left time: 1078.6419s
	iters: 200, epoch: 18 | loss: 33.9160423
	speed: 0.0474s/iter; left time: 1034.1375s
Epoch: 18 cost time: 12.737730503082275
Epoch: 18, Steps: 265 Train Loss: 31.8306 (Forecasting Loss:0.1889 + XiCon Loss:3.1642 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 31.6810703
	speed: 0.0491s/iter; left time: 1062.0175s
	iters: 200, epoch: 19 | loss: 31.5300426
	speed: 0.0473s/iter; left time: 1018.6146s
Epoch: 19 cost time: 12.778128623962402
Epoch: 19, Steps: 265 Train Loss: 31.9816 (Forecasting Loss:0.1889 + XiCon Loss:3.1793 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 33.3497696
	speed: 0.0490s/iter; left time: 1046.2159s
	iters: 200, epoch: 20 | loss: 32.4484673
	speed: 0.0471s/iter; left time: 1002.4434s
Epoch: 20 cost time: 12.707207679748535
Epoch: 20, Steps: 265 Train Loss: 31.9457 (Forecasting Loss:0.1888 + XiCon Loss:3.1757 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.3370037
	speed: 0.0483s/iter; left time: 1018.4444s
	iters: 200, epoch: 21 | loss: 32.3894386
	speed: 0.0468s/iter; left time: 982.4689s
Epoch: 21 cost time: 12.70592212677002
Epoch: 21, Steps: 265 Train Loss: 31.8942 (Forecasting Loss:0.1889 + XiCon Loss:3.1705 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 33.5768204
	speed: 0.0487s/iter; left time: 1014.9389s
	iters: 200, epoch: 22 | loss: 30.9571896
	speed: 0.0471s/iter; left time: 975.9890s
Epoch: 22 cost time: 12.67981767654419
Epoch: 22, Steps: 265 Train Loss: 31.9324 (Forecasting Loss:0.1890 + XiCon Loss:3.1743 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 31.3808212
	speed: 0.0494s/iter; left time: 1016.0678s
	iters: 200, epoch: 23 | loss: 32.2230797
	speed: 0.0475s/iter; left time: 971.8191s
Epoch: 23 cost time: 12.813788890838623
Epoch: 23, Steps: 265 Train Loss: 31.9783 (Forecasting Loss:0.1889 + XiCon Loss:3.1789 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.03929436579346657, mae:0.1495998352766037, mape:0.11867892742156982, mspe:0.026344675570726395 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:169025
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.1034
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 30.0516796
	speed: 0.0476s/iter; left time: 1255.6909s
	iters: 200, epoch: 1 | loss: 30.1449299
	speed: 0.0444s/iter; left time: 1166.4836s
Epoch: 1 cost time: 12.148319721221924
Epoch: 1, Steps: 265 Train Loss: 30.3962 (Forecasting Loss:0.2124 + XiCon Loss:3.0184 x Lambda(10.0)), Vali MSE Loss: 0.1481 Test MSE Loss: 0.0982
Validation loss decreased (inf --> 0.148094).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 33.6508141
	speed: 0.0491s/iter; left time: 1282.3400s
	iters: 200, epoch: 2 | loss: 37.0588150
	speed: 0.0456s/iter; left time: 1186.2130s
Epoch: 2 cost time: 12.558983087539673
Epoch: 2, Steps: 265 Train Loss: 32.0933 (Forecasting Loss:0.1988 + XiCon Loss:3.1895 x Lambda(10.0)), Vali MSE Loss: 0.1464 Test MSE Loss: 0.0964
Validation loss decreased (0.148094 --> 0.146368).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 32.2792816
	speed: 0.0485s/iter; left time: 1253.6721s
	iters: 200, epoch: 3 | loss: 30.1461678
	speed: 0.0466s/iter; left time: 1202.1164s
Epoch: 3 cost time: 12.5698983669281
Epoch: 3, Steps: 265 Train Loss: 31.2583 (Forecasting Loss:0.1932 + XiCon Loss:3.1065 x Lambda(10.0)), Vali MSE Loss: 0.1431 Test MSE Loss: 0.0954
Validation loss decreased (0.146368 --> 0.143122).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.8905144
	speed: 0.0486s/iter; left time: 1243.9149s
	iters: 200, epoch: 4 | loss: 30.4718533
	speed: 0.0468s/iter; left time: 1193.8722s
Epoch: 4 cost time: 12.62036657333374
Epoch: 4, Steps: 265 Train Loss: 30.4289 (Forecasting Loss:0.1914 + XiCon Loss:3.0237 x Lambda(10.0)), Vali MSE Loss: 0.1428 Test MSE Loss: 0.0950
Validation loss decreased (0.143122 --> 0.142839).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 31.8494720
	speed: 0.0480s/iter; left time: 1216.3992s
	iters: 200, epoch: 5 | loss: 33.1569061
	speed: 0.0467s/iter; left time: 1177.5631s
Epoch: 5 cost time: 12.484445810317993
Epoch: 5, Steps: 265 Train Loss: 31.2182 (Forecasting Loss:0.1901 + XiCon Loss:3.1028 x Lambda(10.0)), Vali MSE Loss: 0.1435 Test MSE Loss: 0.0953
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4603767
	speed: 0.0486s/iter; left time: 1217.7619s
	iters: 200, epoch: 6 | loss: 30.5263042
	speed: 0.0470s/iter; left time: 1174.2933s
Epoch: 6 cost time: 12.61837649345398
Epoch: 6, Steps: 265 Train Loss: 30.6389 (Forecasting Loss:0.1900 + XiCon Loss:3.0449 x Lambda(10.0)), Vali MSE Loss: 0.1421 Test MSE Loss: 0.0945
Validation loss decreased (0.142839 --> 0.142115).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.8710117
	speed: 0.0486s/iter; left time: 1206.1037s
	iters: 200, epoch: 7 | loss: 32.2656631
	speed: 0.0470s/iter; left time: 1161.2456s
Epoch: 7 cost time: 12.677953958511353
Epoch: 7, Steps: 265 Train Loss: 30.7199 (Forecasting Loss:0.1896 + XiCon Loss:3.0530 x Lambda(10.0)), Vali MSE Loss: 0.1420 Test MSE Loss: 0.0946
Validation loss decreased (0.142115 --> 0.141977).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.2965126
	speed: 0.0493s/iter; left time: 1210.6340s
	iters: 200, epoch: 8 | loss: 31.8148518
	speed: 0.0468s/iter; left time: 1142.9552s
Epoch: 8 cost time: 12.636482238769531
Epoch: 8, Steps: 265 Train Loss: 30.6433 (Forecasting Loss:0.1894 + XiCon Loss:3.0454 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
Validation loss decreased (0.141977 --> 0.141717).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 31.6020451
	speed: 0.0493s/iter; left time: 1196.3888s
	iters: 200, epoch: 9 | loss: 30.8626823
	speed: 0.0485s/iter; left time: 1173.4058s
Epoch: 9 cost time: 12.87203049659729
Epoch: 9, Steps: 265 Train Loss: 30.4995 (Forecasting Loss:0.1893 + XiCon Loss:3.0310 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
Validation loss decreased (0.141717 --> 0.141554).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.4382858
	speed: 0.0501s/iter; left time: 1203.2663s
	iters: 200, epoch: 10 | loss: 30.4798889
	speed: 0.0473s/iter; left time: 1131.6355s
Epoch: 10 cost time: 12.888852834701538
Epoch: 10, Steps: 265 Train Loss: 30.6374 (Forecasting Loss:0.1893 + XiCon Loss:3.0448 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 32.0220413
	speed: 0.0497s/iter; left time: 1179.3634s
	iters: 200, epoch: 11 | loss: 29.7479248
	speed: 0.0464s/iter; left time: 1097.3877s
Epoch: 11 cost time: 12.674469232559204
Epoch: 11, Steps: 265 Train Loss: 30.6407 (Forecasting Loss:0.1893 + XiCon Loss:3.0451 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.0192833
	speed: 0.0485s/iter; left time: 1138.9917s
	iters: 200, epoch: 12 | loss: 30.7582989
	speed: 0.0468s/iter; left time: 1093.9169s
Epoch: 12 cost time: 12.666284799575806
Epoch: 12, Steps: 265 Train Loss: 30.6827 (Forecasting Loss:0.1893 + XiCon Loss:3.0493 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3210030
	speed: 0.0488s/iter; left time: 1133.8215s
	iters: 200, epoch: 13 | loss: 32.0883789
	speed: 0.0474s/iter; left time: 1096.7895s
Epoch: 13 cost time: 12.663609266281128
Epoch: 13, Steps: 265 Train Loss: 30.6418 (Forecasting Loss:0.1893 + XiCon Loss:3.0453 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 31.3454571
	speed: 0.0493s/iter; left time: 1132.5826s
	iters: 200, epoch: 14 | loss: 30.3570652
	speed: 0.0473s/iter; left time: 1081.2305s
Epoch: 14 cost time: 12.749024391174316
Epoch: 14, Steps: 265 Train Loss: 30.6064 (Forecasting Loss:0.1892 + XiCon Loss:3.0417 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.9719543
	speed: 0.0488s/iter; left time: 1106.5316s
	iters: 200, epoch: 15 | loss: 29.7088337
	speed: 0.0463s/iter; left time: 1045.8474s
Epoch: 15 cost time: 12.593947172164917
Epoch: 15, Steps: 265 Train Loss: 30.5176 (Forecasting Loss:0.1892 + XiCon Loss:3.0328 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4650822
	speed: 0.0485s/iter; left time: 1087.5099s
	iters: 200, epoch: 16 | loss: 30.5673981
	speed: 0.0468s/iter; left time: 1044.8497s
Epoch: 16 cost time: 12.639689207077026
Epoch: 16, Steps: 265 Train Loss: 30.6329 (Forecasting Loss:0.1892 + XiCon Loss:3.0444 x Lambda(10.0)), Vali MSE Loss: 0.1418 Test MSE Loss: 0.0944
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.8599205
	speed: 0.0483s/iter; left time: 1069.9666s
	iters: 200, epoch: 17 | loss: 30.2561684
	speed: 0.0472s/iter; left time: 1041.5417s
Epoch: 17 cost time: 12.629618644714355
Epoch: 17, Steps: 265 Train Loss: 30.6576 (Forecasting Loss:0.1893 + XiCon Loss:3.0468 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.2441998
	speed: 0.0483s/iter; left time: 1057.8072s
	iters: 200, epoch: 18 | loss: 29.9011841
	speed: 0.0469s/iter; left time: 1021.8532s
Epoch: 18 cost time: 12.653091669082642
Epoch: 18, Steps: 265 Train Loss: 30.5945 (Forecasting Loss:0.1892 + XiCon Loss:3.0405 x Lambda(10.0)), Vali MSE Loss: 0.1417 Test MSE Loss: 0.0944
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.0077076
	speed: 0.0488s/iter; left time: 1055.0303s
	iters: 200, epoch: 19 | loss: 32.4230461
	speed: 0.0468s/iter; left time: 1006.7913s
Epoch: 19 cost time: 12.656914949417114
Epoch: 19, Steps: 265 Train Loss: 30.6189 (Forecasting Loss:0.1893 + XiCon Loss:3.0430 x Lambda(10.0)), Vali MSE Loss: 0.1416 Test MSE Loss: 0.0944
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl192_dm32_nh8_el5_dl1_df32_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.039345987141132355, mae:0.149453267455101, mape:0.11863620579242706, mspe:0.026337934657931328 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0395+-0.00019, MAE:0.1499+-0.00041, MAPE:0.1191+-0.00047, MSPE:0.0266+-0.00029, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=3, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.01, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6452
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5505209
	speed: 0.0393s/iter; left time: 1034.2437s
	iters: 200, epoch: 1 | loss: 0.5688828
	speed: 0.0339s/iter; left time: 887.2439s
Epoch: 1 cost time: 9.50885558128357
Epoch: 1, Steps: 264 Train Loss: 0.5431 (Forecasting Loss:0.2364 + XiCon Loss:3.0663 x Lambda(0.1)), Vali MSE Loss: 0.1727 Test MSE Loss: 0.1154
Validation loss decreased (inf --> 0.172732).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5548749
	speed: 0.0437s/iter; left time: 1138.6276s
	iters: 200, epoch: 2 | loss: 0.5669781
	speed: 0.0399s/iter; left time: 1035.9284s
Epoch: 2 cost time: 10.78863000869751
Epoch: 2, Steps: 264 Train Loss: 0.5414 (Forecasting Loss:0.2437 + XiCon Loss:2.9765 x Lambda(0.1)), Vali MSE Loss: 0.1785 Test MSE Loss: 0.1178
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5188975
	speed: 0.0395s/iter; left time: 1019.1811s
	iters: 200, epoch: 3 | loss: 0.4917571
	speed: 0.0380s/iter; left time: 975.2693s
Epoch: 3 cost time: 10.16259241104126
Epoch: 3, Steps: 264 Train Loss: 0.5278 (Forecasting Loss:0.2340 + XiCon Loss:2.9377 x Lambda(0.1)), Vali MSE Loss: 0.1724 Test MSE Loss: 0.1138
Validation loss decreased (0.172732 --> 0.172413).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5006778
	speed: 0.0396s/iter; left time: 1010.9869s
	iters: 200, epoch: 4 | loss: 0.5416974
	speed: 0.0373s/iter; left time: 946.5168s
Epoch: 4 cost time: 10.19803762435913
Epoch: 4, Steps: 264 Train Loss: 0.5200 (Forecasting Loss:0.2297 + XiCon Loss:2.9032 x Lambda(0.1)), Vali MSE Loss: 0.1717 Test MSE Loss: 0.1137
Validation loss decreased (0.172413 --> 0.171687).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5150855
	speed: 0.0388s/iter; left time: 980.1868s
	iters: 200, epoch: 5 | loss: 0.4923191
	speed: 0.0376s/iter; left time: 944.2738s
Epoch: 5 cost time: 10.033950805664062
Epoch: 5, Steps: 264 Train Loss: 0.5156 (Forecasting Loss:0.2280 + XiCon Loss:2.8758 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1125
Validation loss decreased (0.171687 --> 0.170765).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5109625
	speed: 0.0400s/iter; left time: 999.9062s
	iters: 200, epoch: 6 | loss: 0.5057945
	speed: 0.0369s/iter; left time: 918.3818s
Epoch: 6 cost time: 10.047635316848755
Epoch: 6, Steps: 264 Train Loss: 0.5149 (Forecasting Loss:0.2275 + XiCon Loss:2.8745 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1126
Validation loss decreased (0.170765 --> 0.170298).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5270862
	speed: 0.0396s/iter; left time: 978.0741s
	iters: 200, epoch: 7 | loss: 0.5042046
	speed: 0.0373s/iter; left time: 918.6663s
Epoch: 7 cost time: 10.113489389419556
Epoch: 7, Steps: 264 Train Loss: 0.5143 (Forecasting Loss:0.2268 + XiCon Loss:2.8756 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1130
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5071463
	speed: 0.0388s/iter; left time: 948.8167s
	iters: 200, epoch: 8 | loss: 0.5200802
	speed: 0.0372s/iter; left time: 906.9255s
Epoch: 8 cost time: 10.016539335250854
Epoch: 8, Steps: 264 Train Loss: 0.5141 (Forecasting Loss:0.2265 + XiCon Loss:2.8758 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
Validation loss decreased (0.170298 --> 0.170094).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.4910516
	speed: 0.0396s/iter; left time: 957.6423s
	iters: 200, epoch: 9 | loss: 0.5036517
	speed: 0.0376s/iter; left time: 904.6233s
Epoch: 9 cost time: 10.195945024490356
Epoch: 9, Steps: 264 Train Loss: 0.5129 (Forecasting Loss:0.2261 + XiCon Loss:2.8683 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5342017
	speed: 0.0400s/iter; left time: 957.6787s
	iters: 200, epoch: 10 | loss: 0.5272282
	speed: 0.0375s/iter; left time: 893.6621s
Epoch: 10 cost time: 10.134211540222168
Epoch: 10, Steps: 264 Train Loss: 0.5129 (Forecasting Loss:0.2259 + XiCon Loss:2.8706 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1127
Validation loss decreased (0.170094 --> 0.169948).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4996164
	speed: 0.0396s/iter; left time: 936.2670s
	iters: 200, epoch: 11 | loss: 0.5008756
	speed: 0.0377s/iter; left time: 887.3487s
Epoch: 11 cost time: 10.218382358551025
Epoch: 11, Steps: 264 Train Loss: 0.5126 (Forecasting Loss:0.2257 + XiCon Loss:2.8694 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5351996
	speed: 0.0393s/iter; left time: 918.6998s
	iters: 200, epoch: 12 | loss: 0.5045375
	speed: 0.0373s/iter; left time: 868.8344s
Epoch: 12 cost time: 10.021784543991089
Epoch: 12, Steps: 264 Train Loss: 0.5131 (Forecasting Loss:0.2258 + XiCon Loss:2.8733 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1127
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4962402
	speed: 0.0396s/iter; left time: 916.0283s
	iters: 200, epoch: 13 | loss: 0.4931180
	speed: 0.0371s/iter; left time: 855.6411s
Epoch: 13 cost time: 10.114778757095337
Epoch: 13, Steps: 264 Train Loss: 0.5124 (Forecasting Loss:0.2258 + XiCon Loss:2.8661 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1127
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5264060
	speed: 0.0396s/iter; left time: 905.7716s
	iters: 200, epoch: 14 | loss: 0.5090927
	speed: 0.0376s/iter; left time: 856.2597s
Epoch: 14 cost time: 10.135433435440063
Epoch: 14, Steps: 264 Train Loss: 0.5124 (Forecasting Loss:0.2257 + XiCon Loss:2.8675 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5143033
	speed: 0.0396s/iter; left time: 896.1818s
	iters: 200, epoch: 15 | loss: 0.5259962
	speed: 0.0374s/iter; left time: 842.5363s
Epoch: 15 cost time: 10.110113620758057
Epoch: 15, Steps: 264 Train Loss: 0.5129 (Forecasting Loss:0.2256 + XiCon Loss:2.8732 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1127
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.4974246
	speed: 0.0397s/iter; left time: 885.8383s
	iters: 200, epoch: 16 | loss: 0.5088179
	speed: 0.0375s/iter; left time: 834.2702s
Epoch: 16 cost time: 10.147889137268066
Epoch: 16, Steps: 264 Train Loss: 0.5122 (Forecasting Loss:0.2257 + XiCon Loss:2.8649 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5116652
	speed: 0.0398s/iter; left time: 878.3112s
	iters: 200, epoch: 17 | loss: 0.5012594
	speed: 0.0379s/iter; left time: 833.8663s
Epoch: 17 cost time: 10.17922830581665
Epoch: 17, Steps: 264 Train Loss: 0.5127 (Forecasting Loss:0.2257 + XiCon Loss:2.8703 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5203303
	speed: 0.0392s/iter; left time: 854.5405s
	iters: 200, epoch: 18 | loss: 0.5072218
	speed: 0.0382s/iter; left time: 828.5509s
Epoch: 18 cost time: 10.135877847671509
Epoch: 18, Steps: 264 Train Loss: 0.5125 (Forecasting Loss:0.2258 + XiCon Loss:2.8672 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5036801
	speed: 0.0397s/iter; left time: 856.5224s
	iters: 200, epoch: 19 | loss: 0.5419906
	speed: 0.0377s/iter; left time: 808.8394s
Epoch: 19 cost time: 10.128801822662354
Epoch: 19, Steps: 264 Train Loss: 0.5126 (Forecasting Loss:0.2256 + XiCon Loss:2.8696 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1127
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5183727
	speed: 0.0399s/iter; left time: 848.4648s
	iters: 200, epoch: 20 | loss: 0.5073564
	speed: 0.0372s/iter; left time: 788.8360s
Epoch: 20 cost time: 10.165385723114014
Epoch: 20, Steps: 264 Train Loss: 0.5125 (Forecasting Loss:0.2257 + XiCon Loss:2.8684 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05263396352529526, mae:0.17268039286136627, mape:0.1347089260816574, mspe:0.032283637672662735 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.5346
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5397030
	speed: 0.0369s/iter; left time: 971.6476s
	iters: 200, epoch: 1 | loss: 0.5343851
	speed: 0.0346s/iter; left time: 907.4873s
Epoch: 1 cost time: 9.260875701904297
Epoch: 1, Steps: 264 Train Loss: 0.5466 (Forecasting Loss:0.2380 + XiCon Loss:3.0869 x Lambda(0.1)), Vali MSE Loss: 0.1723 Test MSE Loss: 0.1146
Validation loss decreased (inf --> 0.172306).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5495600
	speed: 0.0419s/iter; left time: 1091.1349s
	iters: 200, epoch: 2 | loss: 0.5111342
	speed: 0.0374s/iter; left time: 970.1701s
Epoch: 2 cost time: 10.329537391662598
Epoch: 2, Steps: 264 Train Loss: 0.5410 (Forecasting Loss:0.2418 + XiCon Loss:2.9916 x Lambda(0.1)), Vali MSE Loss: 0.1779 Test MSE Loss: 0.1171
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5011009
	speed: 0.0389s/iter; left time: 1001.9675s
	iters: 200, epoch: 3 | loss: 0.5457146
	speed: 0.0371s/iter; left time: 951.3508s
Epoch: 3 cost time: 9.915632247924805
Epoch: 3, Steps: 264 Train Loss: 0.5294 (Forecasting Loss:0.2341 + XiCon Loss:2.9526 x Lambda(0.1)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1156
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5163260
	speed: 0.0397s/iter; left time: 1013.2327s
	iters: 200, epoch: 4 | loss: 0.5477391
	speed: 0.0367s/iter; left time: 933.2344s
Epoch: 4 cost time: 10.063037157058716
Epoch: 4, Steps: 264 Train Loss: 0.5233 (Forecasting Loss:0.2310 + XiCon Loss:2.9233 x Lambda(0.1)), Vali MSE Loss: 0.1711 Test MSE Loss: 0.1131
Validation loss decreased (0.172306 --> 0.171055).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5298246
	speed: 0.0393s/iter; left time: 992.3747s
	iters: 200, epoch: 5 | loss: 0.5396938
	speed: 0.0377s/iter; left time: 946.8435s
Epoch: 5 cost time: 10.163438558578491
Epoch: 5, Steps: 264 Train Loss: 0.5204 (Forecasting Loss:0.2284 + XiCon Loss:2.9203 x Lambda(0.1)), Vali MSE Loss: 0.1710 Test MSE Loss: 0.1136
Validation loss decreased (0.171055 --> 0.170952).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5241596
	speed: 0.0400s/iter; left time: 999.6130s
	iters: 200, epoch: 6 | loss: 0.5153735
	speed: 0.0367s/iter; left time: 912.9797s
Epoch: 6 cost time: 10.099364757537842
Epoch: 6, Steps: 264 Train Loss: 0.5189 (Forecasting Loss:0.2274 + XiCon Loss:2.9156 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
Validation loss decreased (0.170952 --> 0.170240).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5100400
	speed: 0.0403s/iter; left time: 996.2398s
	iters: 200, epoch: 7 | loss: 0.5283929
	speed: 0.0374s/iter; left time: 921.0001s
Epoch: 7 cost time: 10.207126140594482
Epoch: 7, Steps: 264 Train Loss: 0.5181 (Forecasting Loss:0.2268 + XiCon Loss:2.9133 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
Validation loss decreased (0.170240 --> 0.169978).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5087429
	speed: 0.0399s/iter; left time: 976.4061s
	iters: 200, epoch: 8 | loss: 0.5210881
	speed: 0.0378s/iter; left time: 921.2148s
Epoch: 8 cost time: 10.183528661727905
Epoch: 8, Steps: 264 Train Loss: 0.5178 (Forecasting Loss:0.2264 + XiCon Loss:2.9144 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5171403
	speed: 0.0387s/iter; left time: 935.9075s
	iters: 200, epoch: 9 | loss: 0.4873217
	speed: 0.0377s/iter; left time: 908.1428s
Epoch: 9 cost time: 10.027454853057861
Epoch: 9, Steps: 264 Train Loss: 0.5177 (Forecasting Loss:0.2265 + XiCon Loss:2.9115 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5166283
	speed: 0.0398s/iter; left time: 952.5223s
	iters: 200, epoch: 10 | loss: 0.5360402
	speed: 0.0369s/iter; left time: 879.0419s
Epoch: 10 cost time: 10.059597492218018
Epoch: 10, Steps: 264 Train Loss: 0.5175 (Forecasting Loss:0.2265 + XiCon Loss:2.9108 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5229676
	speed: 0.0391s/iter; left time: 924.3506s
	iters: 200, epoch: 11 | loss: 0.5079958
	speed: 0.0369s/iter; left time: 869.4442s
Epoch: 11 cost time: 10.004292011260986
Epoch: 11, Steps: 264 Train Loss: 0.5176 (Forecasting Loss:0.2264 + XiCon Loss:2.9128 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5349545
	speed: 0.0386s/iter; left time: 903.3934s
	iters: 200, epoch: 12 | loss: 0.4964272
	speed: 0.0366s/iter; left time: 853.2954s
Epoch: 12 cost time: 9.948331594467163
Epoch: 12, Steps: 264 Train Loss: 0.5173 (Forecasting Loss:0.2263 + XiCon Loss:2.9095 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1124
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5078291
	speed: 0.0390s/iter; left time: 902.5775s
	iters: 200, epoch: 13 | loss: 0.5095146
	speed: 0.0372s/iter; left time: 856.0049s
Epoch: 13 cost time: 10.044594764709473
Epoch: 13, Steps: 264 Train Loss: 0.5170 (Forecasting Loss:0.2263 + XiCon Loss:2.9078 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1124
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5075634
	speed: 0.0397s/iter; left time: 907.5670s
	iters: 200, epoch: 14 | loss: 0.5181822
	speed: 0.0374s/iter; left time: 851.8452s
Epoch: 14 cost time: 10.11702847480774
Epoch: 14, Steps: 264 Train Loss: 0.5176 (Forecasting Loss:0.2262 + XiCon Loss:2.9137 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1123
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5350606
	speed: 0.0401s/iter; left time: 907.2483s
	iters: 200, epoch: 15 | loss: 0.5186496
	speed: 0.0373s/iter; left time: 838.6485s
Epoch: 15 cost time: 10.177931547164917
Epoch: 15, Steps: 264 Train Loss: 0.5176 (Forecasting Loss:0.2263 + XiCon Loss:2.9128 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5139334
	speed: 0.0395s/iter; left time: 881.9452s
	iters: 200, epoch: 16 | loss: 0.5045487
	speed: 0.0380s/iter; left time: 845.3407s
Epoch: 16 cost time: 10.175464153289795
Epoch: 16, Steps: 264 Train Loss: 0.5178 (Forecasting Loss:0.2262 + XiCon Loss:2.9151 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5010764
	speed: 0.0398s/iter; left time: 879.0947s
	iters: 200, epoch: 17 | loss: 0.5425878
	speed: 0.0377s/iter; left time: 828.4922s
Epoch: 17 cost time: 10.179480075836182
Epoch: 17, Steps: 264 Train Loss: 0.5172 (Forecasting Loss:0.2262 + XiCon Loss:2.9101 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1123
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05247368663549423, mae:0.17239464819431305, mape:0.13471949100494385, mspe:0.03241635486483574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.0180
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5690889
	speed: 0.0375s/iter; left time: 987.3960s
	iters: 200, epoch: 1 | loss: 0.5479076
	speed: 0.0347s/iter; left time: 910.3975s
Epoch: 1 cost time: 9.408611059188843
Epoch: 1, Steps: 264 Train Loss: 0.5423 (Forecasting Loss:0.2364 + XiCon Loss:3.0589 x Lambda(0.1)), Vali MSE Loss: 0.1773 Test MSE Loss: 0.1173
Validation loss decreased (inf --> 0.177293).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5321701
	speed: 0.0416s/iter; left time: 1083.7288s
	iters: 200, epoch: 2 | loss: 0.5309078
	speed: 0.0378s/iter; left time: 979.8309s
Epoch: 2 cost time: 10.36800742149353
Epoch: 2, Steps: 264 Train Loss: 0.5435 (Forecasting Loss:0.2418 + XiCon Loss:3.0173 x Lambda(0.1)), Vali MSE Loss: 0.1777 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5359846
	speed: 0.0399s/iter; left time: 1029.3102s
	iters: 200, epoch: 3 | loss: 0.5480482
	speed: 0.0370s/iter; left time: 950.6331s
Epoch: 3 cost time: 10.069225072860718
Epoch: 3, Steps: 264 Train Loss: 0.5283 (Forecasting Loss:0.2336 + XiCon Loss:2.9469 x Lambda(0.1)), Vali MSE Loss: 0.1762 Test MSE Loss: 0.1169
Validation loss decreased (0.177293 --> 0.176156).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5252984
	speed: 0.0388s/iter; left time: 988.6457s
	iters: 200, epoch: 4 | loss: 0.5205353
	speed: 0.0364s/iter; left time: 925.8582s
Epoch: 4 cost time: 9.930606603622437
Epoch: 4, Steps: 264 Train Loss: 0.5219 (Forecasting Loss:0.2301 + XiCon Loss:2.9178 x Lambda(0.1)), Vali MSE Loss: 0.1715 Test MSE Loss: 0.1133
Validation loss decreased (0.176156 --> 0.171479).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5193553
	speed: 0.0393s/iter; left time: 992.3404s
	iters: 200, epoch: 5 | loss: 0.5026133
	speed: 0.0376s/iter; left time: 945.2970s
Epoch: 5 cost time: 10.156831741333008
Epoch: 5, Steps: 264 Train Loss: 0.5195 (Forecasting Loss:0.2283 + XiCon Loss:2.9120 x Lambda(0.1)), Vali MSE Loss: 0.1706 Test MSE Loss: 0.1126
Validation loss decreased (0.171479 --> 0.170606).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5111256
	speed: 0.0397s/iter; left time: 992.8825s
	iters: 200, epoch: 6 | loss: 0.5228205
	speed: 0.0369s/iter; left time: 918.3868s
Epoch: 6 cost time: 10.05818223953247
Epoch: 6, Steps: 264 Train Loss: 0.5181 (Forecasting Loss:0.2274 + XiCon Loss:2.9068 x Lambda(0.1)), Vali MSE Loss: 0.1708 Test MSE Loss: 0.1130
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5381498
	speed: 0.0395s/iter; left time: 976.4455s
	iters: 200, epoch: 7 | loss: 0.5124542
	speed: 0.0383s/iter; left time: 942.8557s
Epoch: 7 cost time: 10.145426750183105
Epoch: 7, Steps: 264 Train Loss: 0.5175 (Forecasting Loss:0.2269 + XiCon Loss:2.9058 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1129
Validation loss decreased (0.170606 --> 0.170404).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5062302
	speed: 0.0386s/iter; left time: 944.5481s
	iters: 200, epoch: 8 | loss: 0.5090997
	speed: 0.0370s/iter; left time: 902.0602s
Epoch: 8 cost time: 9.952555418014526
Epoch: 8, Steps: 264 Train Loss: 0.5176 (Forecasting Loss:0.2265 + XiCon Loss:2.9112 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
Validation loss decreased (0.170404 --> 0.170077).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5389656
	speed: 0.0395s/iter; left time: 955.9396s
	iters: 200, epoch: 9 | loss: 0.5269489
	speed: 0.0369s/iter; left time: 888.0276s
Epoch: 9 cost time: 9.981444358825684
Epoch: 9, Steps: 264 Train Loss: 0.5163 (Forecasting Loss:0.2263 + XiCon Loss:2.9004 x Lambda(0.1)), Vali MSE Loss: 0.1703 Test MSE Loss: 0.1127
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5005630
	speed: 0.0397s/iter; left time: 950.7137s
	iters: 200, epoch: 10 | loss: 0.5209655
	speed: 0.0371s/iter; left time: 885.0231s
Epoch: 10 cost time: 10.093381881713867
Epoch: 10, Steps: 264 Train Loss: 0.5163 (Forecasting Loss:0.2263 + XiCon Loss:2.8999 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1125
Validation loss decreased (0.170077 --> 0.169956).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.5203875
	speed: 0.0394s/iter; left time: 932.7494s
	iters: 200, epoch: 11 | loss: 0.5112438
	speed: 0.0374s/iter; left time: 880.6488s
Epoch: 11 cost time: 10.097657203674316
Epoch: 11, Steps: 264 Train Loss: 0.5168 (Forecasting Loss:0.2261 + XiCon Loss:2.9068 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1126
Validation loss decreased (0.169956 --> 0.169941).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5245222
	speed: 0.0392s/iter; left time: 916.5503s
	iters: 200, epoch: 12 | loss: 0.5317362
	speed: 0.0367s/iter; left time: 854.8218s
Epoch: 12 cost time: 10.002577543258667
Epoch: 12, Steps: 264 Train Loss: 0.5165 (Forecasting Loss:0.2262 + XiCon Loss:2.9031 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5182763
	speed: 0.0389s/iter; left time: 899.2405s
	iters: 200, epoch: 13 | loss: 0.5006166
	speed: 0.0370s/iter; left time: 851.3532s
Epoch: 13 cost time: 9.965009689331055
Epoch: 13, Steps: 264 Train Loss: 0.5169 (Forecasting Loss:0.2262 + XiCon Loss:2.9071 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5108945
	speed: 0.0395s/iter; left time: 904.1593s
	iters: 200, epoch: 14 | loss: 0.5183846
	speed: 0.0377s/iter; left time: 857.2976s
Epoch: 14 cost time: 10.147310733795166
Epoch: 14, Steps: 264 Train Loss: 0.5167 (Forecasting Loss:0.2262 + XiCon Loss:2.9057 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.4751791
	speed: 0.0391s/iter; left time: 884.4572s
	iters: 200, epoch: 15 | loss: 0.5108294
	speed: 0.0374s/iter; left time: 842.2667s
Epoch: 15 cost time: 10.070507287979126
Epoch: 15, Steps: 264 Train Loss: 0.5173 (Forecasting Loss:0.2262 + XiCon Loss:2.9119 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5227703
	speed: 0.0394s/iter; left time: 880.4303s
	iters: 200, epoch: 16 | loss: 0.5138302
	speed: 0.0366s/iter; left time: 814.3895s
Epoch: 16 cost time: 10.039879322052002
Epoch: 16, Steps: 264 Train Loss: 0.5166 (Forecasting Loss:0.2261 + XiCon Loss:2.9052 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5013055
	speed: 0.0396s/iter; left time: 874.5753s
	iters: 200, epoch: 17 | loss: 0.5018724
	speed: 0.0375s/iter; left time: 823.7783s
Epoch: 17 cost time: 10.110713005065918
Epoch: 17, Steps: 264 Train Loss: 0.5171 (Forecasting Loss:0.2262 + XiCon Loss:2.9094 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5026838
	speed: 0.0399s/iter; left time: 869.5461s
	iters: 200, epoch: 18 | loss: 0.5167524
	speed: 0.0372s/iter; left time: 807.0279s
Epoch: 18 cost time: 10.126564264297485
Epoch: 18, Steps: 264 Train Loss: 0.5165 (Forecasting Loss:0.2262 + XiCon Loss:2.9033 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1126
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5316877
	speed: 0.0402s/iter; left time: 866.5950s
	iters: 200, epoch: 19 | loss: 0.5174066
	speed: 0.0373s/iter; left time: 800.3719s
Epoch: 19 cost time: 10.177109479904175
Epoch: 19, Steps: 264 Train Loss: 0.5163 (Forecasting Loss:0.2261 + XiCon Loss:2.9019 x Lambda(0.1)), Vali MSE Loss: 0.1702 Test MSE Loss: 0.1126
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5441095
	speed: 0.0391s/iter; left time: 831.3160s
	iters: 200, epoch: 20 | loss: 0.5250668
	speed: 0.0375s/iter; left time: 795.1110s
Epoch: 20 cost time: 10.092450857162476
Epoch: 20, Steps: 264 Train Loss: 0.5170 (Forecasting Loss:0.2261 + XiCon Loss:2.9081 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5258757
	speed: 0.0393s/iter; left time: 825.1061s
	iters: 200, epoch: 21 | loss: 0.5178202
	speed: 0.0374s/iter; left time: 782.8155s
Epoch: 21 cost time: 10.138081550598145
Epoch: 21, Steps: 264 Train Loss: 0.5169 (Forecasting Loss:0.2262 + XiCon Loss:2.9067 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1126
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05258025601506233, mae:0.17257538437843323, mape:0.13466693460941315, mspe:0.03227023780345917 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.2633
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5538668
	speed: 0.0374s/iter; left time: 982.6674s
	iters: 200, epoch: 1 | loss: 0.5363885
	speed: 0.0340s/iter; left time: 890.7181s
Epoch: 1 cost time: 9.329127311706543
Epoch: 1, Steps: 264 Train Loss: 0.5468 (Forecasting Loss:0.2382 + XiCon Loss:3.0861 x Lambda(0.1)), Vali MSE Loss: 0.1731 Test MSE Loss: 0.1136
Validation loss decreased (inf --> 0.173141).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5740149
	speed: 0.0427s/iter; left time: 1111.2160s
	iters: 200, epoch: 2 | loss: 0.5367007
	speed: 0.0381s/iter; left time: 987.0215s
Epoch: 2 cost time: 10.501648426055908
Epoch: 2, Steps: 264 Train Loss: 0.5451 (Forecasting Loss:0.2424 + XiCon Loss:3.0276 x Lambda(0.1)), Vali MSE Loss: 0.1749 Test MSE Loss: 0.1171
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5350765
	speed: 0.0404s/iter; left time: 1041.6527s
	iters: 200, epoch: 3 | loss: 0.5024678
	speed: 0.0383s/iter; left time: 983.9280s
Epoch: 3 cost time: 10.310212135314941
Epoch: 3, Steps: 264 Train Loss: 0.5321 (Forecasting Loss:0.2332 + XiCon Loss:2.9891 x Lambda(0.1)), Vali MSE Loss: 0.1725 Test MSE Loss: 0.1140
Validation loss decreased (0.173141 --> 0.172464).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5324285
	speed: 0.0394s/iter; left time: 1005.7107s
	iters: 200, epoch: 4 | loss: 0.5546407
	speed: 0.0373s/iter; left time: 948.9193s
Epoch: 4 cost time: 10.117575883865356
Epoch: 4, Steps: 264 Train Loss: 0.5271 (Forecasting Loss:0.2299 + XiCon Loss:2.9713 x Lambda(0.1)), Vali MSE Loss: 0.1726 Test MSE Loss: 0.1158
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5100811
	speed: 0.0415s/iter; left time: 1047.2588s
	iters: 200, epoch: 5 | loss: 0.5014311
	speed: 0.0388s/iter; left time: 976.4989s
Epoch: 5 cost time: 10.53688907623291
Epoch: 5, Steps: 264 Train Loss: 0.5225 (Forecasting Loss:0.2267 + XiCon Loss:2.9577 x Lambda(0.1)), Vali MSE Loss: 0.1675 Test MSE Loss: 0.1139
Validation loss decreased (0.172464 --> 0.167504).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5080660
	speed: 0.0408s/iter; left time: 1019.1914s
	iters: 200, epoch: 6 | loss: 0.5331797
	speed: 0.0374s/iter; left time: 929.4690s
Epoch: 6 cost time: 10.300767660140991
Epoch: 6, Steps: 264 Train Loss: 0.5196 (Forecasting Loss:0.2246 + XiCon Loss:2.9508 x Lambda(0.1)), Vali MSE Loss: 0.1676 Test MSE Loss: 0.1144
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5218375
	speed: 0.0403s/iter; left time: 995.2044s
	iters: 200, epoch: 7 | loss: 0.5022368
	speed: 0.0381s/iter; left time: 938.2500s
Epoch: 7 cost time: 10.263919591903687
Epoch: 7, Steps: 264 Train Loss: 0.5179 (Forecasting Loss:0.2233 + XiCon Loss:2.9460 x Lambda(0.1)), Vali MSE Loss: 0.1672 Test MSE Loss: 0.1143
Validation loss decreased (0.167504 --> 0.167181).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5101019
	speed: 0.0408s/iter; left time: 998.4017s
	iters: 200, epoch: 8 | loss: 0.5229270
	speed: 0.0389s/iter; left time: 946.4748s
Epoch: 8 cost time: 10.565493822097778
Epoch: 8, Steps: 264 Train Loss: 0.5165 (Forecasting Loss:0.2223 + XiCon Loss:2.9423 x Lambda(0.1)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1147
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5056988
	speed: 0.0405s/iter; left time: 980.5127s
	iters: 200, epoch: 9 | loss: 0.5066649
	speed: 0.0390s/iter; left time: 938.9710s
Epoch: 9 cost time: 10.46703577041626
Epoch: 9, Steps: 264 Train Loss: 0.5162 (Forecasting Loss:0.2218 + XiCon Loss:2.9441 x Lambda(0.1)), Vali MSE Loss: 0.1670 Test MSE Loss: 0.1149
Validation loss decreased (0.167181 --> 0.167046).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.4898546
	speed: 0.0413s/iter; left time: 988.5460s
	iters: 200, epoch: 10 | loss: 0.5292943
	speed: 0.0381s/iter; left time: 908.5025s
Epoch: 10 cost time: 10.384597301483154
Epoch: 10, Steps: 264 Train Loss: 0.5155 (Forecasting Loss:0.2214 + XiCon Loss:2.9410 x Lambda(0.1)), Vali MSE Loss: 0.1672 Test MSE Loss: 0.1150
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4992175
	speed: 0.0410s/iter; left time: 969.5259s
	iters: 200, epoch: 11 | loss: 0.4884656
	speed: 0.0385s/iter; left time: 908.1477s
Epoch: 11 cost time: 10.459771156311035
Epoch: 11, Steps: 264 Train Loss: 0.5158 (Forecasting Loss:0.2213 + XiCon Loss:2.9454 x Lambda(0.1)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1150
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.5022431
	speed: 0.0403s/iter; left time: 941.7896s
	iters: 200, epoch: 12 | loss: 0.5084468
	speed: 0.0384s/iter; left time: 895.6267s
Epoch: 12 cost time: 10.376586675643921
Epoch: 12, Steps: 264 Train Loss: 0.5160 (Forecasting Loss:0.2213 + XiCon Loss:2.9473 x Lambda(0.1)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1150
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.5363569
	speed: 0.0400s/iter; left time: 925.7219s
	iters: 200, epoch: 13 | loss: 0.5226593
	speed: 0.0380s/iter; left time: 874.6462s
Epoch: 13 cost time: 10.234040021896362
Epoch: 13, Steps: 264 Train Loss: 0.5157 (Forecasting Loss:0.2211 + XiCon Loss:2.9457 x Lambda(0.1)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1150
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5113211
	speed: 0.0400s/iter; left time: 915.8662s
	iters: 200, epoch: 14 | loss: 0.5202991
	speed: 0.0383s/iter; left time: 871.9779s
Epoch: 14 cost time: 10.287790775299072
Epoch: 14, Steps: 264 Train Loss: 0.5155 (Forecasting Loss:0.2212 + XiCon Loss:2.9435 x Lambda(0.1)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1150
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5189290
	speed: 0.0412s/iter; left time: 930.2176s
	iters: 200, epoch: 15 | loss: 0.5200076
	speed: 0.0379s/iter; left time: 852.4970s
Epoch: 15 cost time: 10.421361923217773
Epoch: 15, Steps: 264 Train Loss: 0.5162 (Forecasting Loss:0.2213 + XiCon Loss:2.9492 x Lambda(0.1)), Vali MSE Loss: 0.1671 Test MSE Loss: 0.1150
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5202978
	speed: 0.0402s/iter; left time: 897.3298s
	iters: 200, epoch: 16 | loss: 0.5261059
	speed: 0.0383s/iter; left time: 851.0958s
Epoch: 16 cost time: 10.292963981628418
Epoch: 16, Steps: 264 Train Loss: 0.5153 (Forecasting Loss:0.2213 + XiCon Loss:2.9408 x Lambda(0.1)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1150
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5167679
	speed: 0.0409s/iter; left time: 903.9183s
	iters: 200, epoch: 17 | loss: 0.5090274
	speed: 0.0382s/iter; left time: 840.3138s
Epoch: 17 cost time: 10.37907338142395
Epoch: 17, Steps: 264 Train Loss: 0.5157 (Forecasting Loss:0.2213 + XiCon Loss:2.9442 x Lambda(0.1)), Vali MSE Loss: 0.1672 Test MSE Loss: 0.1150
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5413923
	speed: 0.0406s/iter; left time: 886.4045s
	iters: 200, epoch: 18 | loss: 0.5327723
	speed: 0.0379s/iter; left time: 821.9425s
Epoch: 18 cost time: 10.374105215072632
Epoch: 18, Steps: 264 Train Loss: 0.5158 (Forecasting Loss:0.2213 + XiCon Loss:2.9454 x Lambda(0.1)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1150
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5322546
	speed: 0.0411s/iter; left time: 885.8801s
	iters: 200, epoch: 19 | loss: 0.4963223
	speed: 0.0384s/iter; left time: 823.3997s
Epoch: 19 cost time: 10.429548263549805
Epoch: 19, Steps: 264 Train Loss: 0.5162 (Forecasting Loss:0.2211 + XiCon Loss:2.9502 x Lambda(0.1)), Vali MSE Loss: 0.1673 Test MSE Loss: 0.1150
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05372173339128494, mae:0.175984188914299, mape:0.13767842948436737, mspe:0.033558525145053864 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:233409
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.8218
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 0.5169303
	speed: 0.0373s/iter; left time: 981.2587s
	iters: 200, epoch: 1 | loss: 0.5380441
	speed: 0.0338s/iter; left time: 886.2492s
Epoch: 1 cost time: 9.294902086257935
Epoch: 1, Steps: 264 Train Loss: 0.5443 (Forecasting Loss:0.2364 + XiCon Loss:3.0789 x Lambda(0.1)), Vali MSE Loss: 0.1738 Test MSE Loss: 0.1156
Validation loss decreased (inf --> 0.173781).  Saving model ...
Updating learning rate to 0.01
	iters: 100, epoch: 2 | loss: 0.5782506
	speed: 0.0427s/iter; left time: 1111.7571s
	iters: 200, epoch: 2 | loss: 0.5385340
	speed: 0.0386s/iter; left time: 1001.7610s
Epoch: 2 cost time: 10.547966718673706
Epoch: 2, Steps: 264 Train Loss: 0.5442 (Forecasting Loss:0.2436 + XiCon Loss:3.0058 x Lambda(0.1)), Vali MSE Loss: 0.1816 Test MSE Loss: 0.1227
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.005
	iters: 100, epoch: 3 | loss: 0.5204935
	speed: 0.0392s/iter; left time: 1010.2761s
	iters: 200, epoch: 3 | loss: 0.4915848
	speed: 0.0379s/iter; left time: 972.2752s
Epoch: 3 cost time: 10.13223385810852
Epoch: 3, Steps: 264 Train Loss: 0.5270 (Forecasting Loss:0.2332 + XiCon Loss:2.9386 x Lambda(0.1)), Vali MSE Loss: 0.1734 Test MSE Loss: 0.1159
Validation loss decreased (0.173781 --> 0.173415).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 4 | loss: 0.5324980
	speed: 0.0403s/iter; left time: 1028.6271s
	iters: 200, epoch: 4 | loss: 0.5251091
	speed: 0.0382s/iter; left time: 971.3181s
Epoch: 4 cost time: 10.290719985961914
Epoch: 4, Steps: 264 Train Loss: 0.5214 (Forecasting Loss:0.2302 + XiCon Loss:2.9124 x Lambda(0.1)), Vali MSE Loss: 0.1718 Test MSE Loss: 0.1141
Validation loss decreased (0.173415 --> 0.171795).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 5 | loss: 0.5128506
	speed: 0.0402s/iter; left time: 1014.9785s
	iters: 200, epoch: 5 | loss: 0.5095451
	speed: 0.0377s/iter; left time: 946.9441s
Epoch: 5 cost time: 10.209358930587769
Epoch: 5, Steps: 264 Train Loss: 0.5176 (Forecasting Loss:0.2280 + XiCon Loss:2.8955 x Lambda(0.1)), Vali MSE Loss: 0.1714 Test MSE Loss: 0.1137
Validation loss decreased (0.171795 --> 0.171370).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 6 | loss: 0.5313299
	speed: 0.0398s/iter; left time: 994.0926s
	iters: 200, epoch: 6 | loss: 0.5120139
	speed: 0.0387s/iter; left time: 962.4171s
Epoch: 6 cost time: 10.342904567718506
Epoch: 6, Steps: 264 Train Loss: 0.5161 (Forecasting Loss:0.2271 + XiCon Loss:2.8906 x Lambda(0.1)), Vali MSE Loss: 0.1704 Test MSE Loss: 0.1127
Validation loss decreased (0.171370 --> 0.170351).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 7 | loss: 0.5378505
	speed: 0.0394s/iter; left time: 974.7034s
	iters: 200, epoch: 7 | loss: 0.5164739
	speed: 0.0379s/iter; left time: 933.0588s
Epoch: 7 cost time: 10.150619983673096
Epoch: 7, Steps: 264 Train Loss: 0.5145 (Forecasting Loss:0.2266 + XiCon Loss:2.8790 x Lambda(0.1)), Vali MSE Loss: 0.1701 Test MSE Loss: 0.1127
Validation loss decreased (0.170351 --> 0.170089).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 8 | loss: 0.5307089
	speed: 0.0399s/iter; left time: 974.7130s
	iters: 200, epoch: 8 | loss: 0.5153669
	speed: 0.0378s/iter; left time: 919.3335s
Epoch: 8 cost time: 10.198702812194824
Epoch: 8, Steps: 264 Train Loss: 0.5137 (Forecasting Loss:0.2259 + XiCon Loss:2.8779 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
Validation loss decreased (0.170089 --> 0.169802).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 9 | loss: 0.5040525
	speed: 0.0397s/iter; left time: 961.2589s
	iters: 200, epoch: 9 | loss: 0.5145915
	speed: 0.0380s/iter; left time: 914.6610s
Epoch: 9 cost time: 10.176961183547974
Epoch: 9, Steps: 264 Train Loss: 0.5132 (Forecasting Loss:0.2259 + XiCon Loss:2.8729 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1126
Validation loss decreased (0.169802 --> 0.169773).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 10 | loss: 0.5499692
	speed: 0.0398s/iter; left time: 953.1796s
	iters: 200, epoch: 10 | loss: 0.5272840
	speed: 0.0373s/iter; left time: 889.4594s
Epoch: 10 cost time: 10.185014247894287
Epoch: 10, Steps: 264 Train Loss: 0.5135 (Forecasting Loss:0.2259 + XiCon Loss:2.8757 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 11 | loss: 0.4909747
	speed: 0.0399s/iter; left time: 944.9784s
	iters: 200, epoch: 11 | loss: 0.5250502
	speed: 0.0380s/iter; left time: 894.2207s
Epoch: 11 cost time: 10.251517295837402
Epoch: 11, Steps: 264 Train Loss: 0.5127 (Forecasting Loss:0.2256 + XiCon Loss:2.8708 x Lambda(0.1)), Vali MSE Loss: 0.1697 Test MSE Loss: 0.1128
Validation loss decreased (0.169773 --> 0.169715).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 12 | loss: 0.4976345
	speed: 0.0396s/iter; left time: 925.5376s
	iters: 200, epoch: 12 | loss: 0.5331494
	speed: 0.0385s/iter; left time: 896.4998s
Epoch: 12 cost time: 10.280963659286499
Epoch: 12, Steps: 264 Train Loss: 0.5131 (Forecasting Loss:0.2257 + XiCon Loss:2.8739 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 13 | loss: 0.4909125
	speed: 0.0401s/iter; left time: 928.2267s
	iters: 200, epoch: 13 | loss: 0.4959167
	speed: 0.0381s/iter; left time: 876.6953s
Epoch: 13 cost time: 10.27327275276184
Epoch: 13, Steps: 264 Train Loss: 0.5130 (Forecasting Loss:0.2255 + XiCon Loss:2.8748 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 14 | loss: 0.5113112
	speed: 0.0395s/iter; left time: 903.9165s
	iters: 200, epoch: 14 | loss: 0.5119380
	speed: 0.0374s/iter; left time: 851.8643s
Epoch: 14 cost time: 10.152954816818237
Epoch: 14, Steps: 264 Train Loss: 0.5127 (Forecasting Loss:0.2255 + XiCon Loss:2.8718 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 15 | loss: 0.5489556
	speed: 0.0409s/iter; left time: 924.5920s
	iters: 200, epoch: 15 | loss: 0.5469476
	speed: 0.0379s/iter; left time: 852.2831s
Epoch: 15 cost time: 10.385414600372314
Epoch: 15, Steps: 264 Train Loss: 0.5131 (Forecasting Loss:0.2255 + XiCon Loss:2.8761 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 16 | loss: 0.5220417
	speed: 0.0397s/iter; left time: 887.3781s
	iters: 200, epoch: 16 | loss: 0.5178084
	speed: 0.0382s/iter; left time: 850.1282s
Epoch: 16 cost time: 10.234107255935669
Epoch: 16, Steps: 264 Train Loss: 0.5126 (Forecasting Loss:0.2256 + XiCon Loss:2.8701 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 17 | loss: 0.5197458
	speed: 0.0390s/iter; left time: 861.8298s
	iters: 200, epoch: 17 | loss: 0.4853135
	speed: 0.0374s/iter; left time: 821.9432s
Epoch: 17 cost time: 10.122785806655884
Epoch: 17, Steps: 264 Train Loss: 0.5127 (Forecasting Loss:0.2254 + XiCon Loss:2.8732 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1128
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 18 | loss: 0.5023711
	speed: 0.0406s/iter; left time: 885.0426s
	iters: 200, epoch: 18 | loss: 0.5363067
	speed: 0.0387s/iter; left time: 839.8664s
Epoch: 18 cost time: 10.409295320510864
Epoch: 18, Steps: 264 Train Loss: 0.5128 (Forecasting Loss:0.2255 + XiCon Loss:2.8731 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 19 | loss: 0.5369714
	speed: 0.0407s/iter; left time: 876.3078s
	iters: 200, epoch: 19 | loss: 0.5138201
	speed: 0.0379s/iter; left time: 812.4685s
Epoch: 19 cost time: 10.265404224395752
Epoch: 19, Steps: 264 Train Loss: 0.5132 (Forecasting Loss:0.2256 + XiCon Loss:2.8767 x Lambda(0.1)), Vali MSE Loss: 0.1699 Test MSE Loss: 0.1128
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 20 | loss: 0.5102253
	speed: 0.0397s/iter; left time: 845.1377s
	iters: 200, epoch: 20 | loss: 0.5001832
	speed: 0.0379s/iter; left time: 803.8056s
Epoch: 20 cost time: 10.181325674057007
Epoch: 20, Steps: 264 Train Loss: 0.5127 (Forecasting Loss:0.2254 + XiCon Loss:2.8728 x Lambda(0.1)), Vali MSE Loss: 0.1698 Test MSE Loss: 0.1128
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 21 | loss: 0.5306962
	speed: 0.0401s/iter; left time: 842.0934s
	iters: 200, epoch: 21 | loss: 0.5228422
	speed: 0.0382s/iter; left time: 799.4292s
Epoch: 21 cost time: 10.287372589111328
Epoch: 21, Steps: 264 Train Loss: 0.5129 (Forecasting Loss:0.2257 + XiCon Loss:2.8723 x Lambda(0.1)), Vali MSE Loss: 0.1700 Test MSE Loss: 0.1128
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl336_dm16_nh8_el3_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.05269519239664078, mae:0.17297570407390594, mape:0.1350840926170349, mspe:0.03244265168905258 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0528+-0.00063, MAE:0.1733+-0.00187, MAPE:0.1354+-0.00161, MSPE:0.0326+-0.00068, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm1', root_path='./dataset/ETT-small', data_path='ETTm1.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=3, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.3786
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.4414330
	speed: 0.0387s/iter; left time: 1007.1568s
	iters: 200, epoch: 1 | loss: 32.1652946
	speed: 0.0338s/iter; left time: 874.2248s
Epoch: 1 cost time: 9.345497131347656
Epoch: 1, Steps: 261 Train Loss: 32.2413 (Forecasting Loss:0.2771 + XiCon Loss:3.1964 x Lambda(10.0)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1417
Validation loss decreased (inf --> 0.200676).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6666756
	speed: 0.0416s/iter; left time: 1069.9595s
	iters: 200, epoch: 2 | loss: 29.5564251
	speed: 0.0406s/iter; left time: 1040.1227s
Epoch: 2 cost time: 10.726701498031616
Epoch: 2, Steps: 261 Train Loss: 29.7779 (Forecasting Loss:0.2749 + XiCon Loss:2.9503 x Lambda(10.0)), Vali MSE Loss: 0.1994 Test MSE Loss: 0.1417
Validation loss decreased (0.200676 --> 0.199437).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.3994026
	speed: 0.0415s/iter; left time: 1057.2564s
	iters: 200, epoch: 3 | loss: 29.5217934
	speed: 0.0395s/iter; left time: 1001.6400s
Epoch: 3 cost time: 10.54496955871582
Epoch: 3, Steps: 261 Train Loss: 29.0817 (Forecasting Loss:0.2686 + XiCon Loss:2.8813 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1406
Validation loss decreased (0.199437 --> 0.197605).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.8345261
	speed: 0.0417s/iter; left time: 1051.0444s
	iters: 200, epoch: 4 | loss: 29.0650539
	speed: 0.0393s/iter; left time: 988.2339s
Epoch: 4 cost time: 10.473246335983276
Epoch: 4, Steps: 261 Train Loss: 28.8587 (Forecasting Loss:0.2650 + XiCon Loss:2.8594 x Lambda(10.0)), Vali MSE Loss: 0.1941 Test MSE Loss: 0.1419
Validation loss decreased (0.197605 --> 0.194096).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.6843185
	speed: 0.0409s/iter; left time: 1021.9734s
	iters: 200, epoch: 5 | loss: 28.8340549
	speed: 0.0398s/iter; left time: 990.0167s
Epoch: 5 cost time: 10.521900653839111
Epoch: 5, Steps: 261 Train Loss: 28.7553 (Forecasting Loss:0.2631 + XiCon Loss:2.8492 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.1409
Validation loss decreased (0.194096 --> 0.193092).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.6634731
	speed: 0.0414s/iter; left time: 1023.0808s
	iters: 200, epoch: 6 | loss: 28.8780861
	speed: 0.0399s/iter; left time: 981.6507s
Epoch: 6 cost time: 10.60774302482605
Epoch: 6, Steps: 261 Train Loss: 28.7487 (Forecasting Loss:0.2616 + XiCon Loss:2.8487 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.8244934
	speed: 0.0418s/iter; left time: 1022.2571s
	iters: 200, epoch: 7 | loss: 28.8313847
	speed: 0.0393s/iter; left time: 955.4811s
Epoch: 7 cost time: 10.563832759857178
Epoch: 7, Steps: 261 Train Loss: 28.7154 (Forecasting Loss:0.2614 + XiCon Loss:2.8454 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1408
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.7896633
	speed: 0.0415s/iter; left time: 1003.4162s
	iters: 200, epoch: 8 | loss: 28.3057804
	speed: 0.0399s/iter; left time: 961.1435s
Epoch: 8 cost time: 10.598007678985596
Epoch: 8, Steps: 261 Train Loss: 28.7337 (Forecasting Loss:0.2610 + XiCon Loss:2.8473 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1406
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1694145
	speed: 0.0423s/iter; left time: 1012.2696s
	iters: 200, epoch: 9 | loss: 28.9042034
	speed: 0.0399s/iter; left time: 950.2780s
Epoch: 9 cost time: 10.650978326797485
Epoch: 9, Steps: 261 Train Loss: 28.7230 (Forecasting Loss:0.2608 + XiCon Loss:2.8462 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.5984154
	speed: 0.0416s/iter; left time: 985.0559s
	iters: 200, epoch: 10 | loss: 28.9460926
	speed: 0.0397s/iter; left time: 933.9142s
Epoch: 10 cost time: 10.513341188430786
Epoch: 10, Steps: 261 Train Loss: 28.6949 (Forecasting Loss:0.2608 + XiCon Loss:2.8434 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.1408
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.7669849
	speed: 0.0423s/iter; left time: 988.7695s
	iters: 200, epoch: 11 | loss: 28.7775021
	speed: 0.0399s/iter; left time: 929.1044s
Epoch: 11 cost time: 10.64230990409851
Epoch: 11, Steps: 261 Train Loss: 28.7331 (Forecasting Loss:0.2606 + XiCon Loss:2.8472 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.2504215
	speed: 0.0422s/iter; left time: 976.6139s
	iters: 200, epoch: 12 | loss: 29.1790886
	speed: 0.0403s/iter; left time: 928.4959s
Epoch: 12 cost time: 10.708263158798218
Epoch: 12, Steps: 261 Train Loss: 28.7267 (Forecasting Loss:0.2606 + XiCon Loss:2.8466 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.7915459
	speed: 0.0420s/iter; left time: 961.3157s
	iters: 200, epoch: 13 | loss: 28.2741451
	speed: 0.0402s/iter; left time: 914.7510s
Epoch: 13 cost time: 10.675345420837402
Epoch: 13, Steps: 261 Train Loss: 28.7105 (Forecasting Loss:0.2606 + XiCon Loss:2.8450 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.1407
Validation loss decreased (0.193092 --> 0.193073).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.9419899
	speed: 0.0415s/iter; left time: 938.9449s
	iters: 200, epoch: 14 | loss: 28.6796246
	speed: 0.0401s/iter; left time: 901.5787s
Epoch: 14 cost time: 10.618613243103027
Epoch: 14, Steps: 261 Train Loss: 28.7042 (Forecasting Loss:0.2607 + XiCon Loss:2.8443 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 28.6501656
	speed: 0.0417s/iter; left time: 931.0705s
	iters: 200, epoch: 15 | loss: 28.0902176
	speed: 0.0400s/iter; left time: 889.0360s
Epoch: 15 cost time: 10.640151739120483
Epoch: 15, Steps: 261 Train Loss: 28.7040 (Forecasting Loss:0.2606 + XiCon Loss:2.8443 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.2896690
	speed: 0.0421s/iter; left time: 930.3975s
	iters: 200, epoch: 16 | loss: 28.6868973
	speed: 0.0399s/iter; left time: 878.2358s
Epoch: 16 cost time: 10.602200746536255
Epoch: 16, Steps: 261 Train Loss: 28.6997 (Forecasting Loss:0.2606 + XiCon Loss:2.8439 x Lambda(10.0)), Vali MSE Loss: 0.1931 Test MSE Loss: 0.1407
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.8952465
	speed: 0.0421s/iter; left time: 918.9179s
	iters: 200, epoch: 17 | loss: 28.7575455
	speed: 0.0402s/iter; left time: 872.9448s
Epoch: 17 cost time: 10.697403192520142
Epoch: 17, Steps: 261 Train Loss: 28.7405 (Forecasting Loss:0.2607 + XiCon Loss:2.8480 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.1900997
	speed: 0.0409s/iter; left time: 881.3940s
	iters: 200, epoch: 18 | loss: 28.8837299
	speed: 0.0396s/iter; left time: 849.1108s
Epoch: 18 cost time: 10.450531244277954
Epoch: 18, Steps: 261 Train Loss: 28.7397 (Forecasting Loss:0.2606 + XiCon Loss:2.8479 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1407
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.8411903
	speed: 0.0415s/iter; left time: 883.8133s
	iters: 200, epoch: 19 | loss: 29.3526268
	speed: 0.0393s/iter; left time: 833.0917s
Epoch: 19 cost time: 10.487355947494507
Epoch: 19, Steps: 261 Train Loss: 28.7195 (Forecasting Loss:0.2607 + XiCon Loss:2.8459 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.7491455
	speed: 0.0410s/iter; left time: 863.7669s
	iters: 200, epoch: 20 | loss: 28.5347939
	speed: 0.0398s/iter; left time: 833.8260s
Epoch: 20 cost time: 10.55019736289978
Epoch: 20, Steps: 261 Train Loss: 28.7348 (Forecasting Loss:0.2607 + XiCon Loss:2.8474 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1407
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 28.7011089
	speed: 0.0414s/iter; left time: 860.1773s
	iters: 200, epoch: 21 | loss: 28.3313084
	speed: 0.0399s/iter; left time: 826.1472s
Epoch: 21 cost time: 10.560594320297241
Epoch: 21, Steps: 261 Train Loss: 28.7228 (Forecasting Loss:0.2607 + XiCon Loss:2.8462 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 28.5674191
	speed: 0.0417s/iter; left time: 855.6440s
	iters: 200, epoch: 22 | loss: 29.5192223
	speed: 0.0395s/iter; left time: 805.9827s
Epoch: 22 cost time: 10.565646409988403
Epoch: 22, Steps: 261 Train Loss: 28.7013 (Forecasting Loss:0.2606 + XiCon Loss:2.8441 x Lambda(10.0)), Vali MSE Loss: 0.1933 Test MSE Loss: 0.1407
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.0209885
	speed: 0.0413s/iter; left time: 837.1870s
	iters: 200, epoch: 23 | loss: 28.8020248
	speed: 0.0395s/iter; left time: 796.7037s
Epoch: 23 cost time: 10.588239431381226
Epoch: 23, Steps: 261 Train Loss: 28.7479 (Forecasting Loss:0.2606 + XiCon Loss:2.8487 x Lambda(10.0)), Vali MSE Loss: 0.1932 Test MSE Loss: 0.1407
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07490158826112747, mae:0.20644716918468475, mape:0.15536387264728546, mspe:0.040425438433885574 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.6832
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 31.9129677
	speed: 0.0378s/iter; left time: 982.5695s
	iters: 200, epoch: 1 | loss: 31.8347359
	speed: 0.0347s/iter; left time: 899.9404s
Epoch: 1 cost time: 9.38023328781128
Epoch: 1, Steps: 261 Train Loss: 32.0535 (Forecasting Loss:0.2759 + XiCon Loss:3.1778 x Lambda(10.0)), Vali MSE Loss: 0.1976 Test MSE Loss: 0.1411
Validation loss decreased (inf --> 0.197582).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.9683971
	speed: 0.0407s/iter; left time: 1047.1723s
	iters: 200, epoch: 2 | loss: 29.8798943
	speed: 0.0381s/iter; left time: 977.2175s
Epoch: 2 cost time: 10.23763132095337
Epoch: 2, Steps: 261 Train Loss: 29.8760 (Forecasting Loss:0.2746 + XiCon Loss:2.9601 x Lambda(10.0)), Vali MSE Loss: 0.1998 Test MSE Loss: 0.1419
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.7488155
	speed: 0.0413s/iter; left time: 1051.9647s
	iters: 200, epoch: 3 | loss: 29.7885475
	speed: 0.0386s/iter; left time: 979.6755s
Epoch: 3 cost time: 10.369847536087036
Epoch: 3, Steps: 261 Train Loss: 29.6689 (Forecasting Loss:0.2695 + XiCon Loss:2.9399 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1407
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.9859543
	speed: 0.0410s/iter; left time: 1034.1778s
	iters: 200, epoch: 4 | loss: 29.7924538
	speed: 0.0389s/iter; left time: 978.1984s
Epoch: 4 cost time: 10.373414039611816
Epoch: 4, Steps: 261 Train Loss: 29.6665 (Forecasting Loss:0.2672 + XiCon Loss:2.9399 x Lambda(10.0)), Vali MSE Loss: 0.1964 Test MSE Loss: 0.1397
Validation loss decreased (0.197582 --> 0.196373).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.4926949
	speed: 0.0414s/iter; left time: 1032.3637s
	iters: 200, epoch: 5 | loss: 29.5702534
	speed: 0.0392s/iter; left time: 975.4838s
Epoch: 5 cost time: 10.505764722824097
Epoch: 5, Steps: 261 Train Loss: 29.6243 (Forecasting Loss:0.2662 + XiCon Loss:2.9358 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1402
Validation loss decreased (0.196373 --> 0.196238).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.7725410
	speed: 0.0411s/iter; left time: 1015.3736s
	iters: 200, epoch: 6 | loss: 30.3835125
	speed: 0.0388s/iter; left time: 954.4270s
Epoch: 6 cost time: 10.393766403198242
Epoch: 6, Steps: 261 Train Loss: 29.6384 (Forecasting Loss:0.2655 + XiCon Loss:2.9373 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1398
Validation loss decreased (0.196238 --> 0.196194).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.5420723
	speed: 0.0407s/iter; left time: 993.3685s
	iters: 200, epoch: 7 | loss: 29.9201584
	speed: 0.0390s/iter; left time: 947.9533s
Epoch: 7 cost time: 10.349055290222168
Epoch: 7, Steps: 261 Train Loss: 29.6130 (Forecasting Loss:0.2651 + XiCon Loss:2.9348 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1405
Validation loss decreased (0.196194 --> 0.196014).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.8651390
	speed: 0.0413s/iter; left time: 997.4343s
	iters: 200, epoch: 8 | loss: 29.7638226
	speed: 0.0383s/iter; left time: 921.2352s
Epoch: 8 cost time: 10.322702646255493
Epoch: 8, Steps: 261 Train Loss: 29.6270 (Forecasting Loss:0.2649 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1399
Validation loss decreased (0.196014 --> 0.195791).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3067951
	speed: 0.0410s/iter; left time: 981.5700s
	iters: 200, epoch: 9 | loss: 29.7134056
	speed: 0.0397s/iter; left time: 944.7917s
Epoch: 9 cost time: 10.494570016860962
Epoch: 9, Steps: 261 Train Loss: 29.6232 (Forecasting Loss:0.2649 + XiCon Loss:2.9358 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.4586086
	speed: 0.0407s/iter; left time: 963.3568s
	iters: 200, epoch: 10 | loss: 29.7934303
	speed: 0.0391s/iter; left time: 921.1693s
Epoch: 10 cost time: 10.397233247756958
Epoch: 10, Steps: 261 Train Loss: 29.6345 (Forecasting Loss:0.2649 + XiCon Loss:2.9370 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1400
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.8390617
	speed: 0.0410s/iter; left time: 958.1107s
	iters: 200, epoch: 11 | loss: 29.9968948
	speed: 0.0396s/iter; left time: 923.3065s
Epoch: 11 cost time: 10.434464693069458
Epoch: 11, Steps: 261 Train Loss: 29.6342 (Forecasting Loss:0.2647 + XiCon Loss:2.9369 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.6479053
	speed: 0.0406s/iter; left time: 940.2189s
	iters: 200, epoch: 12 | loss: 29.8404446
	speed: 0.0386s/iter; left time: 888.8795s
Epoch: 12 cost time: 10.300692558288574
Epoch: 12, Steps: 261 Train Loss: 29.6286 (Forecasting Loss:0.2648 + XiCon Loss:2.9364 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.3821545
	speed: 0.0410s/iter; left time: 938.5765s
	iters: 200, epoch: 13 | loss: 29.7827377
	speed: 0.0397s/iter; left time: 903.3588s
Epoch: 13 cost time: 10.50827670097351
Epoch: 13, Steps: 261 Train Loss: 29.6380 (Forecasting Loss:0.2649 + XiCon Loss:2.9373 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
Validation loss decreased (0.195791 --> 0.195753).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.7634506
	speed: 0.0409s/iter; left time: 924.8973s
	iters: 200, epoch: 14 | loss: 29.6792717
	speed: 0.0388s/iter; left time: 872.9659s
Epoch: 14 cost time: 10.356756210327148
Epoch: 14, Steps: 261 Train Loss: 29.6393 (Forecasting Loss:0.2648 + XiCon Loss:2.9374 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.2530251
	speed: 0.0412s/iter; left time: 919.7833s
	iters: 200, epoch: 15 | loss: 29.0824814
	speed: 0.0388s/iter; left time: 862.7762s
Epoch: 15 cost time: 10.384113788604736
Epoch: 15, Steps: 261 Train Loss: 29.6266 (Forecasting Loss:0.2648 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195753 --> 0.195749).  Saving model ...
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.0964355
	speed: 0.0412s/iter; left time: 909.5496s
	iters: 200, epoch: 16 | loss: 29.3942966
	speed: 0.0390s/iter; left time: 857.4887s
Epoch: 16 cost time: 10.448759078979492
Epoch: 16, Steps: 261 Train Loss: 29.6381 (Forecasting Loss:0.2648 + XiCon Loss:2.9373 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.6879959
	speed: 0.0407s/iter; left time: 887.6024s
	iters: 200, epoch: 17 | loss: 29.5967712
	speed: 0.0395s/iter; left time: 859.0633s
Epoch: 17 cost time: 10.476658582687378
Epoch: 17, Steps: 261 Train Loss: 29.6450 (Forecasting Loss:0.2648 + XiCon Loss:2.9380 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.6194572
	speed: 0.0409s/iter; left time: 882.9149s
	iters: 200, epoch: 18 | loss: 29.2289257
	speed: 0.0388s/iter; left time: 832.1441s
Epoch: 18 cost time: 10.398165225982666
Epoch: 18, Steps: 261 Train Loss: 29.6295 (Forecasting Loss:0.2648 + XiCon Loss:2.9365 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8360844
	speed: 0.0405s/iter; left time: 863.6957s
	iters: 200, epoch: 19 | loss: 29.7239151
	speed: 0.0390s/iter; left time: 826.5459s
Epoch: 19 cost time: 10.335304498672485
Epoch: 19, Steps: 261 Train Loss: 29.6341 (Forecasting Loss:0.2648 + XiCon Loss:2.9369 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.7860203
	speed: 0.0414s/iter; left time: 871.6067s
	iters: 200, epoch: 20 | loss: 29.9304085
	speed: 0.0391s/iter; left time: 819.7197s
Epoch: 20 cost time: 10.463420391082764
Epoch: 20, Steps: 261 Train Loss: 29.6440 (Forecasting Loss:0.2648 + XiCon Loss:2.9379 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.6130829
	speed: 0.0408s/iter; left time: 846.8297s
	iters: 200, epoch: 21 | loss: 29.5867043
	speed: 0.0391s/iter; left time: 808.6122s
Epoch: 21 cost time: 10.403796672821045
Epoch: 21, Steps: 261 Train Loss: 29.6281 (Forecasting Loss:0.2647 + XiCon Loss:2.9363 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.4885159
	speed: 0.0415s/iter; left time: 850.8405s
	iters: 200, epoch: 22 | loss: 29.5635948
	speed: 0.0389s/iter; left time: 794.8601s
Epoch: 22 cost time: 10.40022611618042
Epoch: 22, Steps: 261 Train Loss: 29.6404 (Forecasting Loss:0.2648 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195749 --> 0.195743).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.5735645
	speed: 0.0414s/iter; left time: 839.5034s
	iters: 200, epoch: 23 | loss: 29.5624046
	speed: 0.0395s/iter; left time: 796.4436s
Epoch: 23 cost time: 10.434518337249756
Epoch: 23, Steps: 261 Train Loss: 29.6209 (Forecasting Loss:0.2648 + XiCon Loss:2.9356 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 30.0047798
	speed: 0.0409s/iter; left time: 817.3988s
	iters: 200, epoch: 24 | loss: 29.9877205
	speed: 0.0388s/iter; left time: 771.3239s
Epoch: 24 cost time: 10.386252403259277
Epoch: 24, Steps: 261 Train Loss: 29.6432 (Forecasting Loss:0.2647 + XiCon Loss:2.9379 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.3367672
	speed: 0.0412s/iter; left time: 812.6612s
	iters: 200, epoch: 25 | loss: 30.0279427
	speed: 0.0400s/iter; left time: 785.5751s
Epoch: 25 cost time: 10.494295835494995
Epoch: 25, Steps: 261 Train Loss: 29.6122 (Forecasting Loss:0.2648 + XiCon Loss:2.9347 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195743 --> 0.195726).  Saving model ...
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 30.0651112
	speed: 0.0417s/iter; left time: 811.5019s
	iters: 200, epoch: 26 | loss: 29.1782722
	speed: 0.0397s/iter; left time: 769.5091s
Epoch: 26 cost time: 10.545411825180054
Epoch: 26, Steps: 261 Train Loss: 29.6409 (Forecasting Loss:0.2648 + XiCon Loss:2.9376 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.8949451
	speed: 0.0416s/iter; left time: 799.0543s
	iters: 200, epoch: 27 | loss: 29.1756706
	speed: 0.0394s/iter; left time: 752.8261s
Epoch: 27 cost time: 10.466313123703003
Epoch: 27, Steps: 261 Train Loss: 29.6328 (Forecasting Loss:0.2648 + XiCon Loss:2.9368 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.3667507
	speed: 0.0416s/iter; left time: 788.5370s
	iters: 200, epoch: 28 | loss: 29.3608761
	speed: 0.0387s/iter; left time: 729.7575s
Epoch: 28 cost time: 10.378346920013428
Epoch: 28, Steps: 261 Train Loss: 29.6222 (Forecasting Loss:0.2648 + XiCon Loss:2.9357 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 29.6700840
	speed: 0.0420s/iter; left time: 784.6375s
	iters: 200, epoch: 29 | loss: 29.7318172
	speed: 0.0390s/iter; left time: 725.9306s
Epoch: 29 cost time: 10.45659875869751
Epoch: 29, Steps: 261 Train Loss: 29.6201 (Forecasting Loss:0.2648 + XiCon Loss:2.9355 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 29.6785259
	speed: 0.0417s/iter; left time: 769.1969s
	iters: 200, epoch: 30 | loss: 29.7037678
	speed: 0.0396s/iter; left time: 726.2567s
Epoch: 30 cost time: 10.569246530532837
Epoch: 30, Steps: 261 Train Loss: 29.6339 (Forecasting Loss:0.2648 + XiCon Loss:2.9369 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 29.8747139
	speed: 0.0414s/iter; left time: 752.7132s
	iters: 200, epoch: 31 | loss: 29.9900360
	speed: 0.0401s/iter; left time: 725.3731s
Epoch: 31 cost time: 10.670145988464355
Epoch: 31, Steps: 261 Train Loss: 29.6454 (Forecasting Loss:0.2647 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 29.2875748
	speed: 0.0420s/iter; left time: 751.9290s
	iters: 200, epoch: 32 | loss: 29.8908863
	speed: 0.0402s/iter; left time: 715.3493s
Epoch: 32 cost time: 10.663238048553467
Epoch: 32, Steps: 261 Train Loss: 29.6287 (Forecasting Loss:0.2647 + XiCon Loss:2.9364 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195726 --> 0.195706).  Saving model ...
Updating learning rate to 2.3283064365386963e-12
	iters: 100, epoch: 33 | loss: 29.6785145
	speed: 0.0424s/iter; left time: 749.1707s
	iters: 200, epoch: 33 | loss: 29.3222256
	speed: 0.0394s/iter; left time: 692.1707s
Epoch: 33 cost time: 10.659101963043213
Epoch: 33, Steps: 261 Train Loss: 29.6380 (Forecasting Loss:0.2649 + XiCon Loss:2.9373 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-12
	iters: 100, epoch: 34 | loss: 30.0474052
	speed: 0.0421s/iter; left time: 732.4547s
	iters: 200, epoch: 34 | loss: 29.6088409
	speed: 0.0408s/iter; left time: 705.0923s
Epoch: 34 cost time: 10.753535032272339
Epoch: 34, Steps: 261 Train Loss: 29.6428 (Forecasting Loss:0.2647 + XiCon Loss:2.9378 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
Validation loss decreased (0.195706 --> 0.195669).  Saving model ...
Updating learning rate to 5.820766091346741e-13
	iters: 100, epoch: 35 | loss: 29.6178112
	speed: 0.0418s/iter; left time: 715.3816s
	iters: 200, epoch: 35 | loss: 29.8557186
	speed: 0.0404s/iter; left time: 687.6520s
Epoch: 35 cost time: 10.772087812423706
Epoch: 35, Steps: 261 Train Loss: 29.6135 (Forecasting Loss:0.2648 + XiCon Loss:2.9349 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-13
	iters: 100, epoch: 36 | loss: 29.1891403
	speed: 0.0423s/iter; left time: 713.4883s
	iters: 200, epoch: 36 | loss: 30.0277824
	speed: 0.0401s/iter; left time: 673.1339s
Epoch: 36 cost time: 10.710094451904297
Epoch: 36, Steps: 261 Train Loss: 29.6418 (Forecasting Loss:0.2648 + XiCon Loss:2.9377 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4551915228366852e-13
	iters: 100, epoch: 37 | loss: 29.9303303
	speed: 0.0421s/iter; left time: 699.6970s
	iters: 200, epoch: 37 | loss: 29.6833458
	speed: 0.0395s/iter; left time: 651.8562s
Epoch: 37 cost time: 10.591847896575928
Epoch: 37, Steps: 261 Train Loss: 29.6462 (Forecasting Loss:0.2648 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.275957614183426e-14
	iters: 100, epoch: 38 | loss: 30.1222515
	speed: 0.0425s/iter; left time: 694.1827s
	iters: 200, epoch: 38 | loss: 29.4162025
	speed: 0.0400s/iter; left time: 649.8428s
Epoch: 38 cost time: 10.698751211166382
Epoch: 38, Steps: 261 Train Loss: 29.6671 (Forecasting Loss:0.2648 + XiCon Loss:2.9402 x Lambda(10.0)), Vali MSE Loss: 0.1956 Test MSE Loss: 0.1401
Validation loss decreased (0.195669 --> 0.195650).  Saving model ...
Updating learning rate to 3.637978807091713e-14
	iters: 100, epoch: 39 | loss: 29.5835800
	speed: 0.0420s/iter; left time: 676.1378s
	iters: 200, epoch: 39 | loss: 29.7527504
	speed: 0.0399s/iter; left time: 638.4449s
Epoch: 39 cost time: 10.644036054611206
Epoch: 39, Steps: 261 Train Loss: 29.6397 (Forecasting Loss:0.2648 + XiCon Loss:2.9375 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-14
	iters: 100, epoch: 40 | loss: 29.4330902
	speed: 0.0423s/iter; left time: 668.9629s
	iters: 200, epoch: 40 | loss: 29.5929508
	speed: 0.0403s/iter; left time: 633.4437s
Epoch: 40 cost time: 10.760862350463867
Epoch: 40, Steps: 261 Train Loss: 29.6371 (Forecasting Loss:0.2648 + XiCon Loss:2.9372 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-15
	iters: 100, epoch: 41 | loss: 29.7818737
	speed: 0.0426s/iter; left time: 662.8492s
	iters: 200, epoch: 41 | loss: 29.8433590
	speed: 0.0398s/iter; left time: 615.1063s
Epoch: 41 cost time: 10.687561988830566
Epoch: 41, Steps: 261 Train Loss: 29.6268 (Forecasting Loss:0.2648 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.547473508864641e-15
	iters: 100, epoch: 42 | loss: 29.8251514
	speed: 0.0423s/iter; left time: 647.2708s
	iters: 200, epoch: 42 | loss: 29.8041286
	speed: 0.0400s/iter; left time: 608.5140s
Epoch: 42 cost time: 10.737594366073608
Epoch: 42, Steps: 261 Train Loss: 29.6326 (Forecasting Loss:0.2648 + XiCon Loss:2.9368 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323206e-15
	iters: 100, epoch: 43 | loss: 29.5817966
	speed: 0.0420s/iter; left time: 631.8047s
	iters: 200, epoch: 43 | loss: 29.6264305
	speed: 0.0396s/iter; left time: 591.6765s
Epoch: 43 cost time: 10.633110284805298
Epoch: 43, Steps: 261 Train Loss: 29.6439 (Forecasting Loss:0.2648 + XiCon Loss:2.9379 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161603e-15
	iters: 100, epoch: 44 | loss: 29.7788563
	speed: 0.0421s/iter; left time: 622.1092s
	iters: 200, epoch: 44 | loss: 29.7611675
	speed: 0.0399s/iter; left time: 586.3453s
Epoch: 44 cost time: 10.634313583374023
Epoch: 44, Steps: 261 Train Loss: 29.6361 (Forecasting Loss:0.2648 + XiCon Loss:2.9371 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-16
	iters: 100, epoch: 45 | loss: 29.5414124
	speed: 0.0420s/iter; left time: 609.2178s
	iters: 200, epoch: 45 | loss: 29.4140205
	speed: 0.0399s/iter; left time: 574.9884s
Epoch: 45 cost time: 10.659063816070557
Epoch: 45, Steps: 261 Train Loss: 29.6162 (Forecasting Loss:0.2648 + XiCon Loss:2.9351 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-16
	iters: 100, epoch: 46 | loss: 30.2304077
	speed: 0.0422s/iter; left time: 601.4352s
	iters: 200, epoch: 46 | loss: 29.7738552
	speed: 0.0399s/iter; left time: 564.2207s
Epoch: 46 cost time: 10.641149759292603
Epoch: 46, Steps: 261 Train Loss: 29.6461 (Forecasting Loss:0.2648 + XiCon Loss:2.9381 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-16
	iters: 100, epoch: 47 | loss: 29.6092815
	speed: 0.0424s/iter; left time: 594.0658s
	iters: 200, epoch: 47 | loss: 29.9482460
	speed: 0.0403s/iter; left time: 559.4413s
Epoch: 47 cost time: 10.669519424438477
Epoch: 47, Steps: 261 Train Loss: 29.6353 (Forecasting Loss:0.2649 + XiCon Loss:2.9370 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-17
	iters: 100, epoch: 48 | loss: 30.0713539
	speed: 0.0424s/iter; left time: 581.7073s
	iters: 200, epoch: 48 | loss: 29.1880550
	speed: 0.0394s/iter; left time: 537.3127s
Epoch: 48 cost time: 10.638676643371582
Epoch: 48, Steps: 261 Train Loss: 29.6393 (Forecasting Loss:0.2648 + XiCon Loss:2.9375 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1401
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07387252897024155, mae:0.20637767016887665, mape:0.15484869480133057, mspe:0.0396527498960495 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.0083
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.2458534
	speed: 0.0338s/iter; left time: 879.4040s
	iters: 200, epoch: 1 | loss: 31.4581470
	speed: 0.0302s/iter; left time: 782.9680s
Epoch: 1 cost time: 8.294727325439453
Epoch: 1, Steps: 261 Train Loss: 31.9125 (Forecasting Loss:0.2805 + XiCon Loss:3.1632 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1417
Validation loss decreased (inf --> 0.198936).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.3414841
	speed: 0.0378s/iter; left time: 971.8137s
	iters: 200, epoch: 2 | loss: 29.6924915
	speed: 0.0361s/iter; left time: 926.3515s
Epoch: 2 cost time: 9.538858652114868
Epoch: 2, Steps: 261 Train Loss: 29.6585 (Forecasting Loss:0.2756 + XiCon Loss:2.9383 x Lambda(10.0)), Vali MSE Loss: 0.2018 Test MSE Loss: 0.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.0707150
	speed: 0.0368s/iter; left time: 938.5664s
	iters: 200, epoch: 3 | loss: 29.1327019
	speed: 0.0341s/iter; left time: 865.1267s
Epoch: 3 cost time: 9.193676710128784
Epoch: 3, Steps: 261 Train Loss: 29.3629 (Forecasting Loss:0.2697 + XiCon Loss:2.9093 x Lambda(10.0)), Vali MSE Loss: 0.1997 Test MSE Loss: 0.1436
EarlyStopping counter: 2 out of 10
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.2281303
	speed: 0.0365s/iter; left time: 919.7103s
	iters: 200, epoch: 4 | loss: 28.4756851
	speed: 0.0336s/iter; left time: 845.0179s
Epoch: 4 cost time: 9.126367568969727
Epoch: 4, Steps: 261 Train Loss: 29.1317 (Forecasting Loss:0.2671 + XiCon Loss:2.8865 x Lambda(10.0)), Vali MSE Loss: 0.1969 Test MSE Loss: 0.1401
Validation loss decreased (0.198936 --> 0.196937).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.1261864
	speed: 0.0370s/iter; left time: 924.5759s
	iters: 200, epoch: 5 | loss: 29.7950974
	speed: 0.0337s/iter; left time: 837.0118s
Epoch: 5 cost time: 9.134890079498291
Epoch: 5, Steps: 261 Train Loss: 29.1357 (Forecasting Loss:0.2659 + XiCon Loss:2.8870 x Lambda(10.0)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1401
Validation loss decreased (0.196937 --> 0.196483).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.1565418
	speed: 0.0364s/iter; left time: 898.4955s
	iters: 200, epoch: 6 | loss: 29.4192944
	speed: 0.0336s/iter; left time: 825.2736s
Epoch: 6 cost time: 9.060213088989258
Epoch: 6, Steps: 261 Train Loss: 29.0875 (Forecasting Loss:0.2651 + XiCon Loss:2.8822 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1403
Validation loss decreased (0.196483 --> 0.196079).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 28.6628056
	speed: 0.0370s/iter; left time: 904.3845s
	iters: 200, epoch: 7 | loss: 28.8338013
	speed: 0.0339s/iter; left time: 826.1373s
Epoch: 7 cost time: 9.191434621810913
Epoch: 7, Steps: 261 Train Loss: 29.0889 (Forecasting Loss:0.2647 + XiCon Loss:2.8824 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1403
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.7243137
	speed: 0.0356s/iter; left time: 861.1382s
	iters: 200, epoch: 8 | loss: 28.7749729
	speed: 0.0330s/iter; left time: 794.5720s
Epoch: 8 cost time: 8.919244527816772
Epoch: 8, Steps: 261 Train Loss: 29.0761 (Forecasting Loss:0.2644 + XiCon Loss:2.8812 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
Validation loss decreased (0.196079 --> 0.195893).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 28.9053593
	speed: 0.0367s/iter; left time: 878.5598s
	iters: 200, epoch: 9 | loss: 29.5856457
	speed: 0.0334s/iter; left time: 794.7064s
Epoch: 9 cost time: 9.090498447418213
Epoch: 9, Steps: 261 Train Loss: 29.0728 (Forecasting Loss:0.2643 + XiCon Loss:2.8808 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.2734489
	speed: 0.0371s/iter; left time: 877.6512s
	iters: 200, epoch: 10 | loss: 29.3910275
	speed: 0.0343s/iter; left time: 807.2752s
Epoch: 10 cost time: 9.23255968093872
Epoch: 10, Steps: 261 Train Loss: 29.1183 (Forecasting Loss:0.2640 + XiCon Loss:2.8854 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1398
Validation loss decreased (0.195893 --> 0.195885).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 28.7675667
	speed: 0.0364s/iter; left time: 852.2714s
	iters: 200, epoch: 11 | loss: 28.4007053
	speed: 0.0338s/iter; left time: 787.8711s
Epoch: 11 cost time: 9.103950262069702
Epoch: 11, Steps: 261 Train Loss: 29.0788 (Forecasting Loss:0.2642 + XiCon Loss:2.8815 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1398
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.2922783
	speed: 0.0366s/iter; left time: 845.6983s
	iters: 200, epoch: 12 | loss: 29.0533791
	speed: 0.0335s/iter; left time: 772.2188s
Epoch: 12 cost time: 9.086556673049927
Epoch: 12, Steps: 261 Train Loss: 29.0824 (Forecasting Loss:0.2643 + XiCon Loss:2.8818 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1399
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.0812225
	speed: 0.0369s/iter; left time: 844.0108s
	iters: 200, epoch: 13 | loss: 29.3808289
	speed: 0.0339s/iter; left time: 772.4675s
Epoch: 13 cost time: 9.14525842666626
Epoch: 13, Steps: 261 Train Loss: 29.1077 (Forecasting Loss:0.2641 + XiCon Loss:2.8844 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.2129021
	speed: 0.0364s/iter; left time: 822.7349s
	iters: 200, epoch: 14 | loss: 29.1847153
	speed: 0.0334s/iter; left time: 751.7178s
Epoch: 14 cost time: 9.042235612869263
Epoch: 14, Steps: 261 Train Loss: 29.0648 (Forecasting Loss:0.2642 + XiCon Loss:2.8801 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.2542286
	speed: 0.0369s/iter; left time: 824.5436s
	iters: 200, epoch: 15 | loss: 29.1628857
	speed: 0.0336s/iter; left time: 746.7429s
Epoch: 15 cost time: 9.110470533370972
Epoch: 15, Steps: 261 Train Loss: 29.0932 (Forecasting Loss:0.2641 + XiCon Loss:2.8829 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1399
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 28.9894352
	speed: 0.0366s/iter; left time: 807.7118s
	iters: 200, epoch: 16 | loss: 29.3346462
	speed: 0.0337s/iter; left time: 740.9854s
Epoch: 16 cost time: 9.104932069778442
Epoch: 16, Steps: 261 Train Loss: 29.0730 (Forecasting Loss:0.2641 + XiCon Loss:2.8809 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.3368530
	speed: 0.0362s/iter; left time: 789.7752s
	iters: 200, epoch: 17 | loss: 29.1719475
	speed: 0.0335s/iter; left time: 727.0927s
Epoch: 17 cost time: 9.040582180023193
Epoch: 17, Steps: 261 Train Loss: 29.0945 (Forecasting Loss:0.2641 + XiCon Loss:2.8830 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1399
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.3588409
	speed: 0.0367s/iter; left time: 791.0488s
	iters: 200, epoch: 18 | loss: 28.8246326
	speed: 0.0336s/iter; left time: 721.3688s
Epoch: 18 cost time: 9.100165605545044
Epoch: 18, Steps: 261 Train Loss: 29.0904 (Forecasting Loss:0.2641 + XiCon Loss:2.8826 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.5277119
	speed: 0.0362s/iter; left time: 771.3209s
	iters: 200, epoch: 19 | loss: 29.1648140
	speed: 0.0332s/iter; left time: 703.6727s
Epoch: 19 cost time: 9.03493618965149
Epoch: 19, Steps: 261 Train Loss: 29.0912 (Forecasting Loss:0.2641 + XiCon Loss:2.8827 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.1890259
	speed: 0.0364s/iter; left time: 766.6132s
	iters: 200, epoch: 20 | loss: 28.8814793
	speed: 0.0336s/iter; left time: 703.5175s
Epoch: 20 cost time: 9.097960472106934
Epoch: 20, Steps: 261 Train Loss: 29.1029 (Forecasting Loss:0.2641 + XiCon Loss:2.8839 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1399
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.0736665427684784, mae:0.20594003796577454, mape:0.15471620857715607, mspe:0.03984295576810837 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 17.2720
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 31.6445274
	speed: 0.0390s/iter; left time: 1013.1798s
	iters: 200, epoch: 1 | loss: 31.7875080
	speed: 0.0357s/iter; left time: 924.3522s
Epoch: 1 cost time: 9.651589155197144
Epoch: 1, Steps: 261 Train Loss: 32.1488 (Forecasting Loss:0.2766 + XiCon Loss:3.1872 x Lambda(10.0)), Vali MSE Loss: 0.1991 Test MSE Loss: 0.1413
Validation loss decreased (inf --> 0.199056).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8157349
	speed: 0.0409s/iter; left time: 1053.1110s
	iters: 200, epoch: 2 | loss: 30.0408649
	speed: 0.0398s/iter; left time: 1019.5543s
Epoch: 2 cost time: 10.569767475128174
Epoch: 2, Steps: 261 Train Loss: 29.8579 (Forecasting Loss:0.2751 + XiCon Loss:2.9583 x Lambda(10.0)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1421
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.5642395
	speed: 0.0421s/iter; left time: 1071.6185s
	iters: 200, epoch: 3 | loss: 29.8938904
	speed: 0.0399s/iter; left time: 1012.6522s
Epoch: 3 cost time: 10.59354019165039
Epoch: 3, Steps: 261 Train Loss: 29.6427 (Forecasting Loss:0.2692 + XiCon Loss:2.9374 x Lambda(10.0)), Vali MSE Loss: 0.1984 Test MSE Loss: 0.1426
Validation loss decreased (0.199056 --> 0.198425).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1518841
	speed: 0.0419s/iter; left time: 1057.0029s
	iters: 200, epoch: 4 | loss: 29.8782368
	speed: 0.0400s/iter; left time: 1005.3211s
Epoch: 4 cost time: 10.649478673934937
Epoch: 4, Steps: 261 Train Loss: 29.6325 (Forecasting Loss:0.2676 + XiCon Loss:2.9365 x Lambda(10.0)), Vali MSE Loss: 0.1968 Test MSE Loss: 0.1411
Validation loss decreased (0.198425 --> 0.196758).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9237804
	speed: 0.0423s/iter; left time: 1055.5279s
	iters: 200, epoch: 5 | loss: 29.8239250
	speed: 0.0399s/iter; left time: 991.3750s
Epoch: 5 cost time: 10.710667848587036
Epoch: 5, Steps: 261 Train Loss: 29.6266 (Forecasting Loss:0.2660 + XiCon Loss:2.9361 x Lambda(10.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1411
Validation loss decreased (0.196758 --> 0.196644).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.4449406
	speed: 0.0419s/iter; left time: 1034.7950s
	iters: 200, epoch: 6 | loss: 29.5281563
	speed: 0.0402s/iter; left time: 988.6946s
Epoch: 6 cost time: 10.661886930465698
Epoch: 6, Steps: 261 Train Loss: 29.6260 (Forecasting Loss:0.2654 + XiCon Loss:2.9361 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1406
Validation loss decreased (0.196644 --> 0.196114).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.0200500
	speed: 0.0424s/iter; left time: 1034.8418s
	iters: 200, epoch: 7 | loss: 29.7296581
	speed: 0.0402s/iter; left time: 977.6608s
Epoch: 7 cost time: 10.719562292098999
Epoch: 7, Steps: 261 Train Loss: 29.6014 (Forecasting Loss:0.2652 + XiCon Loss:2.9336 x Lambda(10.0)), Vali MSE Loss: 0.1961 Test MSE Loss: 0.1407
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.5965633
	speed: 0.0420s/iter; left time: 1015.1473s
	iters: 200, epoch: 8 | loss: 29.4649868
	speed: 0.0400s/iter; left time: 962.7552s
Epoch: 8 cost time: 10.608724355697632
Epoch: 8, Steps: 261 Train Loss: 29.5973 (Forecasting Loss:0.2650 + XiCon Loss:2.9332 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1404
Validation loss decreased (0.196114 --> 0.196013).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9004879
	speed: 0.0421s/iter; left time: 1006.6892s
	iters: 200, epoch: 9 | loss: 29.1095448
	speed: 0.0401s/iter; left time: 955.5329s
Epoch: 9 cost time: 10.708801031112671
Epoch: 9, Steps: 261 Train Loss: 29.5906 (Forecasting Loss:0.2649 + XiCon Loss:2.9326 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
Validation loss decreased (0.196013 --> 0.195935).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8326168
	speed: 0.0417s/iter; left time: 986.8908s
	iters: 200, epoch: 10 | loss: 29.5080643
	speed: 0.0397s/iter; left time: 934.1617s
Epoch: 10 cost time: 10.596205234527588
Epoch: 10, Steps: 261 Train Loss: 29.6217 (Forecasting Loss:0.2649 + XiCon Loss:2.9357 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
Validation loss decreased (0.195935 --> 0.195815).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.4477119
	speed: 0.0426s/iter; left time: 996.3867s
	iters: 200, epoch: 11 | loss: 29.5563297
	speed: 0.0403s/iter; left time: 938.3156s
Epoch: 11 cost time: 10.754916429519653
Epoch: 11, Steps: 261 Train Loss: 29.5916 (Forecasting Loss:0.2648 + XiCon Loss:2.9327 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1402
Validation loss decreased (0.195815 --> 0.195773).  Saving model ...
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.5649509
	speed: 0.0423s/iter; left time: 977.6050s
	iters: 200, epoch: 12 | loss: 29.5076485
	speed: 0.0404s/iter; left time: 929.4454s
Epoch: 12 cost time: 10.684086799621582
Epoch: 12, Steps: 261 Train Loss: 29.6485 (Forecasting Loss:0.2648 + XiCon Loss:2.9384 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.6854286
	speed: 0.0421s/iter; left time: 963.2422s
	iters: 200, epoch: 13 | loss: 29.8046265
	speed: 0.0399s/iter; left time: 908.8752s
Epoch: 13 cost time: 10.701745986938477
Epoch: 13, Steps: 261 Train Loss: 29.5922 (Forecasting Loss:0.2648 + XiCon Loss:2.9327 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.4623604
	speed: 0.0419s/iter; left time: 948.3532s
	iters: 200, epoch: 14 | loss: 29.6154099
	speed: 0.0401s/iter; left time: 901.9474s
Epoch: 14 cost time: 10.692503929138184
Epoch: 14, Steps: 261 Train Loss: 29.6214 (Forecasting Loss:0.2648 + XiCon Loss:2.9357 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.4881325
	speed: 0.0425s/iter; left time: 949.4157s
	iters: 200, epoch: 15 | loss: 29.7399712
	speed: 0.0400s/iter; left time: 889.5759s
Epoch: 15 cost time: 10.721983909606934
Epoch: 15, Steps: 261 Train Loss: 29.5964 (Forecasting Loss:0.2648 + XiCon Loss:2.9332 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.7067604
	speed: 0.0420s/iter; left time: 927.0016s
	iters: 200, epoch: 16 | loss: 29.8231335
	speed: 0.0402s/iter; left time: 883.2562s
Epoch: 16 cost time: 10.704038619995117
Epoch: 16, Steps: 261 Train Loss: 29.6266 (Forecasting Loss:0.2648 + XiCon Loss:2.9362 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5645313
	speed: 0.0423s/iter; left time: 922.2114s
	iters: 200, epoch: 17 | loss: 29.6615448
	speed: 0.0398s/iter; left time: 863.6261s
Epoch: 17 cost time: 10.602233171463013
Epoch: 17, Steps: 261 Train Loss: 29.6076 (Forecasting Loss:0.2648 + XiCon Loss:2.9343 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.3821564
	speed: 0.0426s/iter; left time: 918.6024s
	iters: 200, epoch: 18 | loss: 29.7935257
	speed: 0.0403s/iter; left time: 865.3350s
Epoch: 18 cost time: 10.773659467697144
Epoch: 18, Steps: 261 Train Loss: 29.6233 (Forecasting Loss:0.2648 + XiCon Loss:2.9359 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.2920132
	speed: 0.0419s/iter; left time: 893.1845s
	iters: 200, epoch: 19 | loss: 29.6807022
	speed: 0.0393s/iter; left time: 832.6002s
Epoch: 19 cost time: 10.573929071426392
Epoch: 19, Steps: 261 Train Loss: 29.5885 (Forecasting Loss:0.2647 + XiCon Loss:2.9324 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1401
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.2923794
	speed: 0.0425s/iter; left time: 894.8566s
	iters: 200, epoch: 20 | loss: 29.4146004
	speed: 0.0396s/iter; left time: 829.5251s
Epoch: 20 cost time: 10.653990268707275
Epoch: 20, Steps: 261 Train Loss: 29.6066 (Forecasting Loss:0.2648 + XiCon Loss:2.9342 x Lambda(10.0)), Vali MSE Loss: 0.1960 Test MSE Loss: 0.1401
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.5856094
	speed: 0.0419s/iter; left time: 870.1771s
	iters: 200, epoch: 21 | loss: 28.9225006
	speed: 0.0395s/iter; left time: 816.0580s
Epoch: 21 cost time: 10.529033184051514
Epoch: 21, Steps: 261 Train Loss: 29.5795 (Forecasting Loss:0.2648 + XiCon Loss:2.9315 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1401
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07392081618309021, mae:0.2064400166273117, mape:0.15486620366573334, mspe:0.03965108469128609 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:487089
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99998168] ~ [2.48563476e-05 1.24460244e-05]
Xi-correlation values:[0.9999132  0.99767593] ~ [0. 1.]
Autocorrelation calculation time: 16.7029
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 32.3485718
	speed: 0.0329s/iter; left time: 856.2290s
	iters: 200, epoch: 1 | loss: 32.0385094
	speed: 0.0298s/iter; left time: 772.3890s
Epoch: 1 cost time: 8.115797519683838
Epoch: 1, Steps: 261 Train Loss: 32.3402 (Forecasting Loss:0.2745 + XiCon Loss:3.2066 x Lambda(10.0)), Vali MSE Loss: 0.1975 Test MSE Loss: 0.1412
Validation loss decreased (inf --> 0.197462).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.8217163
	speed: 0.0357s/iter; left time: 918.1904s
	iters: 200, epoch: 2 | loss: 30.7121334
	speed: 0.0340s/iter; left time: 872.5158s
Epoch: 2 cost time: 9.119324445724487
Epoch: 2, Steps: 261 Train Loss: 29.8821 (Forecasting Loss:0.2743 + XiCon Loss:2.9608 x Lambda(10.0)), Vali MSE Loss: 0.1989 Test MSE Loss: 0.1432
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.1563816
	speed: 0.0367s/iter; left time: 934.9476s
	iters: 200, epoch: 3 | loss: 29.4489956
	speed: 0.0337s/iter; left time: 854.7750s
Epoch: 3 cost time: 9.1560800075531
Epoch: 3, Steps: 261 Train Loss: 29.2686 (Forecasting Loss:0.2694 + XiCon Loss:2.8999 x Lambda(10.0)), Vali MSE Loss: 0.1966 Test MSE Loss: 0.1422
Validation loss decreased (0.197462 --> 0.196565).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 28.6691780
	speed: 0.0365s/iter; left time: 920.2631s
	iters: 200, epoch: 4 | loss: 28.6990528
	speed: 0.0342s/iter; left time: 859.3577s
Epoch: 4 cost time: 9.184926509857178
Epoch: 4, Steps: 261 Train Loss: 29.0936 (Forecasting Loss:0.2670 + XiCon Loss:2.8827 x Lambda(10.0)), Vali MSE Loss: 0.1965 Test MSE Loss: 0.1407
Validation loss decreased (0.196565 --> 0.196538).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 28.8461323
	speed: 0.0363s/iter; left time: 904.7495s
	iters: 200, epoch: 5 | loss: 28.4804077
	speed: 0.0340s/iter; left time: 845.9218s
Epoch: 5 cost time: 9.119520664215088
Epoch: 5, Steps: 261 Train Loss: 29.0328 (Forecasting Loss:0.2659 + XiCon Loss:2.8767 x Lambda(10.0)), Vali MSE Loss: 0.1962 Test MSE Loss: 0.1401
Validation loss decreased (0.196538 --> 0.196201).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 28.6270790
	speed: 0.0368s/iter; left time: 908.1310s
	iters: 200, epoch: 6 | loss: 28.9245510
	speed: 0.0339s/iter; left time: 833.5142s
Epoch: 6 cost time: 9.18830919265747
Epoch: 6, Steps: 261 Train Loss: 29.0043 (Forecasting Loss:0.2651 + XiCon Loss:2.8739 x Lambda(10.0)), Vali MSE Loss: 0.1959 Test MSE Loss: 0.1410
Validation loss decreased (0.196201 --> 0.195881).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.5357323
	speed: 0.0367s/iter; left time: 895.6226s
	iters: 200, epoch: 7 | loss: 28.7700691
	speed: 0.0344s/iter; left time: 837.1234s
Epoch: 7 cost time: 9.191767692565918
Epoch: 7, Steps: 261 Train Loss: 28.9851 (Forecasting Loss:0.2648 + XiCon Loss:2.8720 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
Validation loss decreased (0.195881 --> 0.195829).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 28.8393631
	speed: 0.0367s/iter; left time: 885.9925s
	iters: 200, epoch: 8 | loss: 29.0776272
	speed: 0.0343s/iter; left time: 825.3220s
Epoch: 8 cost time: 9.197109699249268
Epoch: 8, Steps: 261 Train Loss: 28.9339 (Forecasting Loss:0.2647 + XiCon Loss:2.8669 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1402
Validation loss decreased (0.195829 --> 0.195769).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.1859379
	speed: 0.0376s/iter; left time: 898.4778s
	iters: 200, epoch: 9 | loss: 28.9900608
	speed: 0.0342s/iter; left time: 814.4428s
Epoch: 9 cost time: 9.26242971420288
Epoch: 9, Steps: 261 Train Loss: 28.9601 (Forecasting Loss:0.2647 + XiCon Loss:2.8695 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1402
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 28.9900169
	speed: 0.0370s/iter; left time: 876.0278s
	iters: 200, epoch: 10 | loss: 28.8371391
	speed: 0.0346s/iter; left time: 814.7971s
Epoch: 10 cost time: 9.268677473068237
Epoch: 10, Steps: 261 Train Loss: 28.9565 (Forecasting Loss:0.2646 + XiCon Loss:2.8692 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5031281
	speed: 0.0368s/iter; left time: 860.7628s
	iters: 200, epoch: 11 | loss: 28.8325481
	speed: 0.0340s/iter; left time: 790.8692s
Epoch: 11 cost time: 9.181034326553345
Epoch: 11, Steps: 261 Train Loss: 28.9751 (Forecasting Loss:0.2645 + XiCon Loss:2.8711 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1404
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 28.7906227
	speed: 0.0372s/iter; left time: 859.6625s
	iters: 200, epoch: 12 | loss: 28.7349949
	speed: 0.0344s/iter; left time: 791.9851s
Epoch: 12 cost time: 9.267533540725708
Epoch: 12, Steps: 261 Train Loss: 28.9399 (Forecasting Loss:0.2645 + XiCon Loss:2.8675 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1404
Validation loss decreased (0.195769 --> 0.195765).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 28.5478344
	speed: 0.0366s/iter; left time: 837.6597s
	iters: 200, epoch: 13 | loss: 29.2014332
	speed: 0.0344s/iter; left time: 783.1651s
Epoch: 13 cost time: 9.215108871459961
Epoch: 13, Steps: 261 Train Loss: 28.9517 (Forecasting Loss:0.2645 + XiCon Loss:2.8687 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1404
Validation loss decreased (0.195765 --> 0.195722).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.0816593
	speed: 0.0368s/iter; left time: 832.7138s
	iters: 200, epoch: 14 | loss: 29.6525497
	speed: 0.0343s/iter; left time: 771.2450s
Epoch: 14 cost time: 9.216519355773926
Epoch: 14, Steps: 261 Train Loss: 28.9293 (Forecasting Loss:0.2645 + XiCon Loss:2.8665 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1403
Validation loss decreased (0.195722 --> 0.195702).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.1791363
	speed: 0.0366s/iter; left time: 818.5185s
	iters: 200, epoch: 15 | loss: 29.0660038
	speed: 0.0344s/iter; left time: 764.4296s
Epoch: 15 cost time: 9.240666151046753
Epoch: 15, Steps: 261 Train Loss: 28.9360 (Forecasting Loss:0.2645 + XiCon Loss:2.8672 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.2678356
	speed: 0.0367s/iter; left time: 809.5122s
	iters: 200, epoch: 16 | loss: 28.6658211
	speed: 0.0340s/iter; left time: 746.9427s
Epoch: 16 cost time: 9.209500074386597
Epoch: 16, Steps: 261 Train Loss: 28.9508 (Forecasting Loss:0.2645 + XiCon Loss:2.8686 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1403
Validation loss decreased (0.195702 --> 0.195667).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 28.8682289
	speed: 0.0366s/iter; left time: 799.7324s
	iters: 200, epoch: 17 | loss: 28.8017406
	speed: 0.0342s/iter; left time: 743.4375s
Epoch: 17 cost time: 9.203471422195435
Epoch: 17, Steps: 261 Train Loss: 28.9533 (Forecasting Loss:0.2645 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 28.8063755
	speed: 0.0366s/iter; left time: 789.8687s
	iters: 200, epoch: 18 | loss: 28.9891510
	speed: 0.0344s/iter; left time: 738.3373s
Epoch: 18 cost time: 9.207610368728638
Epoch: 18, Steps: 261 Train Loss: 28.9416 (Forecasting Loss:0.2644 + XiCon Loss:2.8677 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 28.7413044
	speed: 0.0371s/iter; left time: 789.5353s
	iters: 200, epoch: 19 | loss: 29.0554790
	speed: 0.0342s/iter; left time: 725.7508s
Epoch: 19 cost time: 9.296583890914917
Epoch: 19, Steps: 261 Train Loss: 28.9771 (Forecasting Loss:0.2645 + XiCon Loss:2.8713 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 28.7860928
	speed: 0.0368s/iter; left time: 774.7959s
	iters: 200, epoch: 20 | loss: 28.8055382
	speed: 0.0346s/iter; left time: 724.5482s
Epoch: 20 cost time: 9.265266180038452
Epoch: 20, Steps: 261 Train Loss: 28.9874 (Forecasting Loss:0.2645 + XiCon Loss:2.8723 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1403
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.1840649
	speed: 0.0367s/iter; left time: 762.8925s
	iters: 200, epoch: 21 | loss: 28.8603439
	speed: 0.0346s/iter; left time: 714.7891s
Epoch: 21 cost time: 9.230528593063354
Epoch: 21, Steps: 261 Train Loss: 28.9539 (Forecasting Loss:0.2646 + XiCon Loss:2.8689 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.1213703
	speed: 0.0371s/iter; left time: 761.2721s
	iters: 200, epoch: 22 | loss: 29.5350895
	speed: 0.0342s/iter; left time: 698.2483s
Epoch: 22 cost time: 9.279328346252441
Epoch: 22, Steps: 261 Train Loss: 28.9268 (Forecasting Loss:0.2645 + XiCon Loss:2.8662 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1403
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.0425816
	speed: 0.0374s/iter; left time: 758.3601s
	iters: 200, epoch: 23 | loss: 29.7434559
	speed: 0.0343s/iter; left time: 691.6511s
Epoch: 23 cost time: 9.3108229637146
Epoch: 23, Steps: 261 Train Loss: 28.9569 (Forecasting Loss:0.2645 + XiCon Loss:2.8692 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.1375561
	speed: 0.0374s/iter; left time: 747.6388s
	iters: 200, epoch: 24 | loss: 29.0973244
	speed: 0.0342s/iter; left time: 681.2332s
Epoch: 24 cost time: 9.287111520767212
Epoch: 24, Steps: 261 Train Loss: 28.9737 (Forecasting Loss:0.2645 + XiCon Loss:2.8709 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 28.4437752
	speed: 0.0373s/iter; left time: 736.8133s
	iters: 200, epoch: 25 | loss: 29.5593510
	speed: 0.0344s/iter; left time: 676.3174s
Epoch: 25 cost time: 9.314701080322266
Epoch: 25, Steps: 261 Train Loss: 29.0065 (Forecasting Loss:0.2646 + XiCon Loss:2.8742 x Lambda(10.0)), Vali MSE Loss: 0.1958 Test MSE Loss: 0.1403
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 28.9353218
	speed: 0.0370s/iter; left time: 721.3868s
	iters: 200, epoch: 26 | loss: 28.5815563
	speed: 0.0341s/iter; left time: 660.6908s
Epoch: 26 cost time: 9.238901615142822
Epoch: 26, Steps: 261 Train Loss: 28.9669 (Forecasting Loss:0.2645 + XiCon Loss:2.8702 x Lambda(10.0)), Vali MSE Loss: 0.1957 Test MSE Loss: 0.1403
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm1_ftS_sl336_ll48_pl720_dm8_nh8_el3_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.07397899031639099, mae:0.20670722424983978, mape:0.15513727068901062, mspe:0.03977511078119278 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0741+-0.00060, MAE:0.2064+-0.00034, MAPE:0.1550+-0.00032, MSPE:0.0399+-0.00040, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=10.0, multiscales=[96], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.3563
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 31.6034088
	speed: 0.0353s/iter; left time: 934.8111s
	iters: 200, epoch: 1 | loss: 30.8270760
	speed: 0.0294s/iter; left time: 776.1720s
Epoch: 1 cost time: 8.564730882644653
Epoch: 1, Steps: 266 Train Loss: 31.3151 (Forecasting Loss:0.1870 + XiCon Loss:3.1128 x Lambda(10.0)), Vali MSE Loss: 0.1576 Test MSE Loss: 0.1382
Validation loss decreased (inf --> 0.157565).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.1119823
	speed: 0.0308s/iter; left time: 807.1553s
	iters: 200, epoch: 2 | loss: 30.9790802
	speed: 0.0282s/iter; left time: 737.5308s
Epoch: 2 cost time: 7.816401958465576
Epoch: 2, Steps: 266 Train Loss: 30.5543 (Forecasting Loss:0.1587 + XiCon Loss:3.0396 x Lambda(10.0)), Vali MSE Loss: 0.1566 Test MSE Loss: 0.1328
Validation loss decreased (0.157565 --> 0.156570).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.4917641
	speed: 0.0313s/iter; left time: 812.8327s
	iters: 200, epoch: 3 | loss: 29.2628994
	speed: 0.0280s/iter; left time: 723.1568s
Epoch: 3 cost time: 7.824617147445679
Epoch: 3, Steps: 266 Train Loss: 30.3123 (Forecasting Loss:0.1521 + XiCon Loss:3.0160 x Lambda(10.0)), Vali MSE Loss: 0.1483 Test MSE Loss: 0.1295
Validation loss decreased (0.156570 --> 0.148289).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 29.7846241
	speed: 0.0305s/iter; left time: 783.8975s
	iters: 200, epoch: 4 | loss: 30.9507866
	speed: 0.0279s/iter; left time: 715.3877s
Epoch: 4 cost time: 7.774836778640747
Epoch: 4, Steps: 266 Train Loss: 30.1597 (Forecasting Loss:0.1497 + XiCon Loss:3.0010 x Lambda(10.0)), Vali MSE Loss: 0.1460 Test MSE Loss: 0.1277
Validation loss decreased (0.148289 --> 0.145955).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1509991
	speed: 0.0304s/iter; left time: 773.2245s
	iters: 200, epoch: 5 | loss: 29.5071888
	speed: 0.0292s/iter; left time: 738.9793s
Epoch: 5 cost time: 7.880456447601318
Epoch: 5, Steps: 266 Train Loss: 30.0743 (Forecasting Loss:0.1480 + XiCon Loss:2.9926 x Lambda(10.0)), Vali MSE Loss: 0.1461 Test MSE Loss: 0.1259
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.8740101
	speed: 0.0305s/iter; left time: 767.3718s
	iters: 200, epoch: 6 | loss: 31.2145863
	speed: 0.0288s/iter; left time: 721.8737s
Epoch: 6 cost time: 7.835065841674805
Epoch: 6, Steps: 266 Train Loss: 30.0828 (Forecasting Loss:0.1474 + XiCon Loss:2.9935 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1246
Validation loss decreased (0.145955 --> 0.144548).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8170776
	speed: 0.0309s/iter; left time: 768.3523s
	iters: 200, epoch: 7 | loss: 29.7925472
	speed: 0.0286s/iter; left time: 708.4645s
Epoch: 7 cost time: 7.881726264953613
Epoch: 7, Steps: 266 Train Loss: 30.0051 (Forecasting Loss:0.1472 + XiCon Loss:2.9858 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
Validation loss decreased (0.144548 --> 0.144390).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.7287922
	speed: 0.0308s/iter; left time: 758.0854s
	iters: 200, epoch: 8 | loss: 29.8137245
	speed: 0.0285s/iter; left time: 698.4190s
Epoch: 8 cost time: 7.802371025085449
Epoch: 8, Steps: 266 Train Loss: 30.0080 (Forecasting Loss:0.1470 + XiCon Loss:2.9861 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1247
Validation loss decreased (0.144390 --> 0.144147).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.9893494
	speed: 0.0315s/iter; left time: 768.7700s
	iters: 200, epoch: 9 | loss: 31.0025482
	speed: 0.0286s/iter; left time: 695.3204s
Epoch: 9 cost time: 7.90902042388916
Epoch: 9, Steps: 266 Train Loss: 30.0783 (Forecasting Loss:0.1469 + XiCon Loss:2.9931 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1246
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 29.8607540
	speed: 0.0309s/iter; left time: 745.9153s
	iters: 200, epoch: 10 | loss: 29.6937313
	speed: 0.0281s/iter; left time: 673.6887s
Epoch: 10 cost time: 7.810105800628662
Epoch: 10, Steps: 266 Train Loss: 30.0071 (Forecasting Loss:0.1469 + XiCon Loss:2.9860 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 31.2854252
	speed: 0.0309s/iter; left time: 736.7605s
	iters: 200, epoch: 11 | loss: 30.2705688
	speed: 0.0290s/iter; left time: 688.6410s
Epoch: 11 cost time: 7.862006425857544
Epoch: 11, Steps: 266 Train Loss: 29.9727 (Forecasting Loss:0.1469 + XiCon Loss:2.9826 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.5803146
	speed: 0.0306s/iter; left time: 721.8107s
	iters: 200, epoch: 12 | loss: 29.7956161
	speed: 0.0292s/iter; left time: 684.3892s
Epoch: 12 cost time: 7.8720502853393555
Epoch: 12, Steps: 266 Train Loss: 29.9758 (Forecasting Loss:0.1468 + XiCon Loss:2.9829 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.4755173
	speed: 0.0307s/iter; left time: 716.7428s
	iters: 200, epoch: 13 | loss: 30.0938129
	speed: 0.0292s/iter; left time: 677.3120s
Epoch: 13 cost time: 7.87596583366394
Epoch: 13, Steps: 266 Train Loss: 29.9784 (Forecasting Loss:0.1468 + XiCon Loss:2.9832 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1244
Validation loss decreased (0.144147 --> 0.143974).  Saving model ...
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 30.5949440
	speed: 0.0306s/iter; left time: 704.1664s
	iters: 200, epoch: 14 | loss: 29.5503368
	speed: 0.0290s/iter; left time: 665.1246s
Epoch: 14 cost time: 7.936928987503052
Epoch: 14, Steps: 266 Train Loss: 30.0624 (Forecasting Loss:0.1468 + XiCon Loss:2.9916 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 31.8699532
	speed: 0.0300s/iter; left time: 683.9744s
	iters: 200, epoch: 15 | loss: 30.0054359
	speed: 0.0289s/iter; left time: 655.6640s
Epoch: 15 cost time: 7.821985721588135
Epoch: 15, Steps: 266 Train Loss: 29.9713 (Forecasting Loss:0.1467 + XiCon Loss:2.9825 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.7269783
	speed: 0.0310s/iter; left time: 697.0071s
	iters: 200, epoch: 16 | loss: 30.8599033
	speed: 0.0285s/iter; left time: 639.0761s
Epoch: 16 cost time: 7.855098485946655
Epoch: 16, Steps: 266 Train Loss: 30.0255 (Forecasting Loss:0.1468 + XiCon Loss:2.9879 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 31.4258862
	speed: 0.0308s/iter; left time: 685.6569s
	iters: 200, epoch: 17 | loss: 28.5934048
	speed: 0.0284s/iter; left time: 628.5523s
Epoch: 17 cost time: 7.860247850418091
Epoch: 17, Steps: 266 Train Loss: 29.9993 (Forecasting Loss:0.1467 + XiCon Loss:2.9853 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.5301971
	speed: 0.0317s/iter; left time: 696.2473s
	iters: 200, epoch: 18 | loss: 30.4083824
	speed: 0.0284s/iter; left time: 622.4023s
Epoch: 18 cost time: 7.920500993728638
Epoch: 18, Steps: 266 Train Loss: 29.9801 (Forecasting Loss:0.1468 + XiCon Loss:2.9833 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.3561916
	speed: 0.0312s/iter; left time: 677.7002s
	iters: 200, epoch: 19 | loss: 29.5826797
	speed: 0.0290s/iter; left time: 627.0797s
Epoch: 19 cost time: 7.946516752243042
Epoch: 19, Steps: 266 Train Loss: 29.9653 (Forecasting Loss:0.1468 + XiCon Loss:2.9819 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.2160645
	speed: 0.0298s/iter; left time: 638.3803s
	iters: 200, epoch: 20 | loss: 30.6543922
	speed: 0.0288s/iter; left time: 614.6573s
Epoch: 20 cost time: 7.760584354400635
Epoch: 20, Steps: 266 Train Loss: 29.9838 (Forecasting Loss:0.1467 + XiCon Loss:2.9837 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 32.1404495
	speed: 0.0314s/iter; left time: 664.4326s
	iters: 200, epoch: 21 | loss: 28.7761993
	speed: 0.0297s/iter; left time: 626.0100s
Epoch: 21 cost time: 8.136021375656128
Epoch: 21, Steps: 266 Train Loss: 30.0104 (Forecasting Loss:0.1467 + XiCon Loss:2.9864 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 30.9447536
	speed: 0.0298s/iter; left time: 623.9602s
	iters: 200, epoch: 22 | loss: 29.8370132
	speed: 0.0282s/iter; left time: 586.3215s
Epoch: 22 cost time: 7.689128160476685
Epoch: 22, Steps: 266 Train Loss: 30.0437 (Forecasting Loss:0.1468 + XiCon Loss:2.9897 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.7352295
	speed: 0.0300s/iter; left time: 619.6106s
	iters: 200, epoch: 23 | loss: 29.4515572
	speed: 0.0274s/iter; left time: 562.5400s
Epoch: 23 cost time: 7.642350912094116
Epoch: 23, Steps: 266 Train Loss: 29.9986 (Forecasting Loss:0.1467 + XiCon Loss:2.9852 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06460455060005188, mae:0.18427297472953796, mape:0.44861605763435364, mspe:8.136788368225098 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.6898
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 31.6520672
	speed: 0.0330s/iter; left time: 874.6947s
	iters: 200, epoch: 1 | loss: 30.6395149
	speed: 0.0302s/iter; left time: 798.3587s
Epoch: 1 cost time: 8.306267499923706
Epoch: 1, Steps: 266 Train Loss: 31.4087 (Forecasting Loss:0.1857 + XiCon Loss:3.1223 x Lambda(10.0)), Vali MSE Loss: 0.1586 Test MSE Loss: 0.1358
Validation loss decreased (inf --> 0.158606).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 32.1748009
	speed: 0.0311s/iter; left time: 816.9467s
	iters: 200, epoch: 2 | loss: 31.0870724
	speed: 0.0298s/iter; left time: 778.7650s
Epoch: 2 cost time: 8.086891412734985
Epoch: 2, Steps: 266 Train Loss: 30.5969 (Forecasting Loss:0.1590 + XiCon Loss:3.0438 x Lambda(10.0)), Vali MSE Loss: 0.1527 Test MSE Loss: 0.1320
Validation loss decreased (0.158606 --> 0.152748).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8902340
	speed: 0.0307s/iter; left time: 796.5966s
	iters: 200, epoch: 3 | loss: 31.3451691
	speed: 0.0289s/iter; left time: 748.5177s
Epoch: 3 cost time: 7.8910813331604
Epoch: 3, Steps: 266 Train Loss: 30.5701 (Forecasting Loss:0.1517 + XiCon Loss:3.0418 x Lambda(10.0)), Vali MSE Loss: 0.1486 Test MSE Loss: 0.1279
Validation loss decreased (0.152748 --> 0.148617).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 31.9158936
	speed: 0.0303s/iter; left time: 777.8363s
	iters: 200, epoch: 4 | loss: 30.6753139
	speed: 0.0291s/iter; left time: 745.4816s
Epoch: 4 cost time: 7.866972923278809
Epoch: 4, Steps: 266 Train Loss: 30.3184 (Forecasting Loss:0.1496 + XiCon Loss:3.0169 x Lambda(10.0)), Vali MSE Loss: 0.1471 Test MSE Loss: 0.1256
Validation loss decreased (0.148617 --> 0.147099).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9175949
	speed: 0.0307s/iter; left time: 780.4787s
	iters: 200, epoch: 5 | loss: 29.6693840
	speed: 0.0294s/iter; left time: 744.0665s
Epoch: 5 cost time: 7.970117092132568
Epoch: 5, Steps: 266 Train Loss: 30.1441 (Forecasting Loss:0.1481 + XiCon Loss:2.9996 x Lambda(10.0)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.1254
Validation loss decreased (0.147099 --> 0.145089).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 31.0037651
	speed: 0.0306s/iter; left time: 770.6667s
	iters: 200, epoch: 6 | loss: 29.3956623
	speed: 0.0290s/iter; left time: 727.2969s
Epoch: 6 cost time: 7.848541498184204
Epoch: 6, Steps: 266 Train Loss: 30.1869 (Forecasting Loss:0.1475 + XiCon Loss:3.0039 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1246
Validation loss decreased (0.145089 --> 0.144738).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 29.8943806
	speed: 0.0303s/iter; left time: 754.2627s
	iters: 200, epoch: 7 | loss: 29.5042114
	speed: 0.0283s/iter; left time: 702.9073s
Epoch: 7 cost time: 7.843528509140015
Epoch: 7, Steps: 266 Train Loss: 30.1614 (Forecasting Loss:0.1472 + XiCon Loss:3.0014 x Lambda(10.0)), Vali MSE Loss: 0.1450 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.5076294
	speed: 0.0304s/iter; left time: 750.1324s
	iters: 200, epoch: 8 | loss: 29.4698181
	speed: 0.0281s/iter; left time: 689.3236s
Epoch: 8 cost time: 7.7697975635528564
Epoch: 8, Steps: 266 Train Loss: 30.0773 (Forecasting Loss:0.1470 + XiCon Loss:2.9930 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1246
Validation loss decreased (0.144738 --> 0.144543).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.8010502
	speed: 0.0304s/iter; left time: 741.8270s
	iters: 200, epoch: 9 | loss: 30.6927948
	speed: 0.0285s/iter; left time: 691.3251s
Epoch: 9 cost time: 7.843493461608887
Epoch: 9, Steps: 266 Train Loss: 30.1444 (Forecasting Loss:0.1470 + XiCon Loss:2.9997 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1244
Validation loss decreased (0.144543 --> 0.144376).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5129299
	speed: 0.0299s/iter; left time: 720.8733s
	iters: 200, epoch: 10 | loss: 30.6711903
	speed: 0.0290s/iter; left time: 697.0587s
Epoch: 10 cost time: 7.82178807258606
Epoch: 10, Steps: 266 Train Loss: 30.0970 (Forecasting Loss:0.1469 + XiCon Loss:2.9950 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1244
Validation loss decreased (0.144376 --> 0.144347).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5596771
	speed: 0.0312s/iter; left time: 744.1279s
	iters: 200, epoch: 11 | loss: 30.8721428
	speed: 0.0289s/iter; left time: 685.2628s
Epoch: 11 cost time: 7.9231858253479
Epoch: 11, Steps: 266 Train Loss: 30.1660 (Forecasting Loss:0.1469 + XiCon Loss:3.0019 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.8113899
	speed: 0.0312s/iter; left time: 735.2386s
	iters: 200, epoch: 12 | loss: 29.2537174
	speed: 0.0289s/iter; left time: 677.5528s
Epoch: 12 cost time: 7.880573272705078
Epoch: 12, Steps: 266 Train Loss: 30.1038 (Forecasting Loss:0.1469 + XiCon Loss:2.9957 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1243
Validation loss decreased (0.144347 --> 0.144226).  Saving model ...
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.0454235
	speed: 0.0314s/iter; left time: 731.1635s
	iters: 200, epoch: 13 | loss: 29.7405910
	speed: 0.0288s/iter; left time: 668.8407s
Epoch: 13 cost time: 7.890872240066528
Epoch: 13, Steps: 266 Train Loss: 30.1764 (Forecasting Loss:0.1468 + XiCon Loss:3.0030 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.8196831
	speed: 0.0308s/iter; left time: 710.5238s
	iters: 200, epoch: 14 | loss: 30.7108517
	speed: 0.0290s/iter; left time: 666.1458s
Epoch: 14 cost time: 7.960606336593628
Epoch: 14, Steps: 266 Train Loss: 30.1861 (Forecasting Loss:0.1469 + XiCon Loss:3.0039 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1243
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.5288849
	speed: 0.0307s/iter; left time: 700.0820s
	iters: 200, epoch: 15 | loss: 29.6939411
	speed: 0.0285s/iter; left time: 645.5332s
Epoch: 15 cost time: 7.798354148864746
Epoch: 15, Steps: 266 Train Loss: 30.1062 (Forecasting Loss:0.1469 + XiCon Loss:2.9959 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.3836060
	speed: 0.0311s/iter; left time: 700.1614s
	iters: 200, epoch: 16 | loss: 30.5003262
	speed: 0.0291s/iter; left time: 651.8748s
Epoch: 16 cost time: 7.9120025634765625
Epoch: 16, Steps: 266 Train Loss: 30.1701 (Forecasting Loss:0.1468 + XiCon Loss:3.0023 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1243
Validation loss decreased (0.144226 --> 0.144189).  Saving model ...
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 30.1789055
	speed: 0.0314s/iter; left time: 698.7541s
	iters: 200, epoch: 17 | loss: 29.3092995
	speed: 0.0283s/iter; left time: 627.6078s
Epoch: 17 cost time: 7.935453176498413
Epoch: 17, Steps: 266 Train Loss: 30.1432 (Forecasting Loss:0.1469 + XiCon Loss:2.9996 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 29.2576447
	speed: 0.0300s/iter; left time: 658.8315s
	iters: 200, epoch: 18 | loss: 30.6059189
	speed: 0.0287s/iter; left time: 626.9830s
Epoch: 18 cost time: 7.796566486358643
Epoch: 18, Steps: 266 Train Loss: 30.1614 (Forecasting Loss:0.1468 + XiCon Loss:3.0015 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1243
Validation loss decreased (0.144189 --> 0.144132).  Saving model ...
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.8810692
	speed: 0.0310s/iter; left time: 673.4846s
	iters: 200, epoch: 19 | loss: 30.6092033
	speed: 0.0299s/iter; left time: 645.7117s
Epoch: 19 cost time: 8.078671216964722
Epoch: 19, Steps: 266 Train Loss: 30.1465 (Forecasting Loss:0.1468 + XiCon Loss:3.0000 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 29.2321701
	speed: 0.0302s/iter; left time: 647.8756s
	iters: 200, epoch: 20 | loss: 29.1471939
	speed: 0.0281s/iter; left time: 600.8049s
Epoch: 20 cost time: 7.735944509506226
Epoch: 20, Steps: 266 Train Loss: 30.1043 (Forecasting Loss:0.1469 + XiCon Loss:2.9957 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1243
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 29.6211758
	speed: 0.0312s/iter; left time: 660.4652s
	iters: 200, epoch: 21 | loss: 29.4559002
	speed: 0.0289s/iter; left time: 609.3743s
Epoch: 21 cost time: 7.876060724258423
Epoch: 21, Steps: 266 Train Loss: 30.1366 (Forecasting Loss:0.1468 + XiCon Loss:2.9990 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.1030598
	speed: 0.0310s/iter; left time: 648.9626s
	iters: 200, epoch: 22 | loss: 30.6899414
	speed: 0.0287s/iter; left time: 597.1225s
Epoch: 22 cost time: 7.822773456573486
Epoch: 22, Steps: 266 Train Loss: 30.0833 (Forecasting Loss:0.1468 + XiCon Loss:2.9936 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1243
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.8958435
	speed: 0.0305s/iter; left time: 629.9164s
	iters: 200, epoch: 23 | loss: 30.3409634
	speed: 0.0293s/iter; left time: 602.4364s
Epoch: 23 cost time: 7.93889045715332
Epoch: 23, Steps: 266 Train Loss: 30.1265 (Forecasting Loss:0.1469 + XiCon Loss:2.9980 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.5072632
	speed: 0.0310s/iter; left time: 631.6485s
	iters: 200, epoch: 24 | loss: 29.7794476
	speed: 0.0296s/iter; left time: 600.0701s
Epoch: 24 cost time: 7.959878206253052
Epoch: 24, Steps: 266 Train Loss: 30.1829 (Forecasting Loss:0.1469 + XiCon Loss:3.0036 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1243
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 30.5396843
	speed: 0.0304s/iter; left time: 611.4746s
	iters: 200, epoch: 25 | loss: 30.5642128
	speed: 0.0282s/iter; left time: 563.8062s
Epoch: 25 cost time: 7.799636363983154
Epoch: 25, Steps: 266 Train Loss: 30.1360 (Forecasting Loss:0.1468 + XiCon Loss:2.9989 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 29.8130455
	speed: 0.0314s/iter; left time: 622.7093s
	iters: 200, epoch: 26 | loss: 30.0424423
	speed: 0.0292s/iter; left time: 577.0788s
Epoch: 26 cost time: 7.949559211730957
Epoch: 26, Steps: 266 Train Loss: 30.0701 (Forecasting Loss:0.1469 + XiCon Loss:2.9923 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.4623489
	speed: 0.0308s/iter; left time: 602.7285s
	iters: 200, epoch: 27 | loss: 30.7223225
	speed: 0.0291s/iter; left time: 567.3310s
Epoch: 27 cost time: 7.925502300262451
Epoch: 27, Steps: 266 Train Loss: 30.1406 (Forecasting Loss:0.1469 + XiCon Loss:2.9994 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1243
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.4749374
	speed: 0.0302s/iter; left time: 582.5640s
	iters: 200, epoch: 28 | loss: 30.2611008
	speed: 0.0289s/iter; left time: 555.1794s
Epoch: 28 cost time: 7.821196794509888
Epoch: 28, Steps: 266 Train Loss: 30.1285 (Forecasting Loss:0.1468 + XiCon Loss:2.9982 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1243
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06452608108520508, mae:0.18413691222667694, mape:0.4474749267101288, mspe:8.083902359008789 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9880
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 31.3136387
	speed: 0.0332s/iter; left time: 878.8898s
	iters: 200, epoch: 1 | loss: 30.7125816
	speed: 0.0303s/iter; left time: 799.9376s
Epoch: 1 cost time: 8.420308113098145
Epoch: 1, Steps: 266 Train Loss: 31.2533 (Forecasting Loss:0.1832 + XiCon Loss:3.1070 x Lambda(10.0)), Vali MSE Loss: 0.1579 Test MSE Loss: 0.1364
Validation loss decreased (inf --> 0.157933).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 31.7135258
	speed: 0.0320s/iter; left time: 840.1495s
	iters: 200, epoch: 2 | loss: 30.9798794
	speed: 0.0277s/iter; left time: 724.8684s
Epoch: 2 cost time: 7.927850246429443
Epoch: 2, Steps: 266 Train Loss: 30.5466 (Forecasting Loss:0.1606 + XiCon Loss:3.0386 x Lambda(10.0)), Vali MSE Loss: 0.1503 Test MSE Loss: 0.1303
Validation loss decreased (0.157933 --> 0.150279).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 29.6917515
	speed: 0.0302s/iter; left time: 785.2838s
	iters: 200, epoch: 3 | loss: 30.4133263
	speed: 0.0286s/iter; left time: 739.6729s
Epoch: 3 cost time: 7.813326358795166
Epoch: 3, Steps: 266 Train Loss: 30.2046 (Forecasting Loss:0.1510 + XiCon Loss:3.0054 x Lambda(10.0)), Vali MSE Loss: 0.1485 Test MSE Loss: 0.1303
Validation loss decreased (0.150279 --> 0.148549).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.2578735
	speed: 0.0303s/iter; left time: 779.5950s
	iters: 200, epoch: 4 | loss: 29.6167126
	speed: 0.0295s/iter; left time: 756.1659s
Epoch: 4 cost time: 7.872846841812134
Epoch: 4, Steps: 266 Train Loss: 30.3734 (Forecasting Loss:0.1493 + XiCon Loss:3.0224 x Lambda(10.0)), Vali MSE Loss: 0.1451 Test MSE Loss: 0.1260
Validation loss decreased (0.148549 --> 0.145090).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.1952229
	speed: 0.0299s/iter; left time: 760.6681s
	iters: 200, epoch: 5 | loss: 30.4609089
	speed: 0.0287s/iter; left time: 727.0297s
Epoch: 5 cost time: 7.7739691734313965
Epoch: 5, Steps: 266 Train Loss: 30.3573 (Forecasting Loss:0.1480 + XiCon Loss:3.0209 x Lambda(10.0)), Vali MSE Loss: 0.1456 Test MSE Loss: 0.1255
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.4398346
	speed: 0.0313s/iter; left time: 787.8365s
	iters: 200, epoch: 6 | loss: 30.0872059
	speed: 0.0282s/iter; left time: 707.3138s
Epoch: 6 cost time: 7.815642595291138
Epoch: 6, Steps: 266 Train Loss: 30.3437 (Forecasting Loss:0.1473 + XiCon Loss:3.0196 x Lambda(10.0)), Vali MSE Loss: 0.1447 Test MSE Loss: 0.1248
Validation loss decreased (0.145090 --> 0.144698).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.4592686
	speed: 0.0312s/iter; left time: 776.0505s
	iters: 200, epoch: 7 | loss: 31.0762520
	speed: 0.0293s/iter; left time: 727.3636s
Epoch: 7 cost time: 8.004005908966064
Epoch: 7, Steps: 266 Train Loss: 30.2070 (Forecasting Loss:0.1470 + XiCon Loss:3.0060 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1246
Validation loss decreased (0.144698 --> 0.143938).  Saving model ...
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.6849861
	speed: 0.0304s/iter; left time: 749.9244s
	iters: 200, epoch: 8 | loss: 30.1790791
	speed: 0.0286s/iter; left time: 701.8898s
Epoch: 8 cost time: 7.900442361831665
Epoch: 8, Steps: 266 Train Loss: 30.2537 (Forecasting Loss:0.1468 + XiCon Loss:3.0107 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.6594124
	speed: 0.0310s/iter; left time: 754.4047s
	iters: 200, epoch: 9 | loss: 31.7431297
	speed: 0.0277s/iter; left time: 671.3992s
Epoch: 9 cost time: 7.788583517074585
Epoch: 9, Steps: 266 Train Loss: 30.2776 (Forecasting Loss:0.1467 + XiCon Loss:3.0131 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 31.2272110
	speed: 0.0308s/iter; left time: 742.8151s
	iters: 200, epoch: 10 | loss: 29.6470909
	speed: 0.0290s/iter; left time: 695.0767s
Epoch: 10 cost time: 7.854679346084595
Epoch: 10, Steps: 266 Train Loss: 30.2572 (Forecasting Loss:0.1467 + XiCon Loss:3.0111 x Lambda(10.0)), Vali MSE Loss: 0.1437 Test MSE Loss: 0.1244
Validation loss decreased (0.143938 --> 0.143729).  Saving model ...
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 30.1974392
	speed: 0.0304s/iter; left time: 724.4965s
	iters: 200, epoch: 11 | loss: 30.6979351
	speed: 0.0281s/iter; left time: 667.1192s
Epoch: 11 cost time: 7.737585067749023
Epoch: 11, Steps: 266 Train Loss: 30.2712 (Forecasting Loss:0.1467 + XiCon Loss:3.0124 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1244
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9215736
	speed: 0.0314s/iter; left time: 741.1185s
	iters: 200, epoch: 12 | loss: 30.7911282
	speed: 0.0282s/iter; left time: 661.8104s
Epoch: 12 cost time: 7.863262176513672
Epoch: 12, Steps: 266 Train Loss: 30.2543 (Forecasting Loss:0.1466 + XiCon Loss:3.0108 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1244
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 29.2298355
	speed: 0.0307s/iter; left time: 716.3766s
	iters: 200, epoch: 13 | loss: 29.4367161
	speed: 0.0296s/iter; left time: 685.9566s
Epoch: 13 cost time: 7.9156575202941895
Epoch: 13, Steps: 266 Train Loss: 30.1943 (Forecasting Loss:0.1466 + XiCon Loss:3.0048 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1244
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 28.8026733
	speed: 0.0307s/iter; left time: 706.7065s
	iters: 200, epoch: 14 | loss: 30.2874851
	speed: 0.0286s/iter; left time: 655.7599s
Epoch: 14 cost time: 7.86290431022644
Epoch: 14, Steps: 266 Train Loss: 30.1985 (Forecasting Loss:0.1467 + XiCon Loss:3.0052 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1244
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 32.0759010
	speed: 0.0305s/iter; left time: 693.7148s
	iters: 200, epoch: 15 | loss: 29.9450264
	speed: 0.0292s/iter; left time: 663.0272s
Epoch: 15 cost time: 7.934644937515259
Epoch: 15, Steps: 266 Train Loss: 30.2626 (Forecasting Loss:0.1466 + XiCon Loss:3.0116 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1244
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 29.5300694
	speed: 0.0308s/iter; left time: 693.6454s
	iters: 200, epoch: 16 | loss: 30.6778679
	speed: 0.0282s/iter; left time: 632.9649s
Epoch: 16 cost time: 7.777289390563965
Epoch: 16, Steps: 266 Train Loss: 30.3023 (Forecasting Loss:0.1465 + XiCon Loss:3.0156 x Lambda(10.0)), Vali MSE Loss: 0.1438 Test MSE Loss: 0.1244
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.7486153
	speed: 0.0316s/iter; left time: 702.2776s
	iters: 200, epoch: 17 | loss: 30.3031807
	speed: 0.0306s/iter; left time: 677.3232s
Epoch: 17 cost time: 8.05819821357727
Epoch: 17, Steps: 266 Train Loss: 30.2921 (Forecasting Loss:0.1466 + XiCon Loss:3.0145 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1244
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 31.0350914
	speed: 0.0307s/iter; left time: 675.2711s
	iters: 200, epoch: 18 | loss: 30.7198219
	speed: 0.0297s/iter; left time: 648.8112s
Epoch: 18 cost time: 7.938108682632446
Epoch: 18, Steps: 266 Train Loss: 30.2633 (Forecasting Loss:0.1466 + XiCon Loss:3.0117 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1244
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 30.5564442
	speed: 0.0316s/iter; left time: 687.1780s
	iters: 200, epoch: 19 | loss: 29.4152241
	speed: 0.0289s/iter; left time: 623.6620s
Epoch: 19 cost time: 7.951712369918823
Epoch: 19, Steps: 266 Train Loss: 30.2720 (Forecasting Loss:0.1466 + XiCon Loss:3.0125 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1244
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.9555511
	speed: 0.0310s/iter; left time: 664.4171s
	iters: 200, epoch: 20 | loss: 30.5175018
	speed: 0.0286s/iter; left time: 610.6467s
Epoch: 20 cost time: 7.8519203662872314
Epoch: 20, Steps: 266 Train Loss: 30.2960 (Forecasting Loss:0.1465 + XiCon Loss:3.0149 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1244
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06436487287282944, mae:0.18438437581062317, mape:0.45001018047332764, mspe:8.186738014221191 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.0334
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 31.3175812
	speed: 0.0312s/iter; left time: 827.6383s
	iters: 200, epoch: 1 | loss: 30.5805187
	speed: 0.0281s/iter; left time: 741.0046s
Epoch: 1 cost time: 7.815706968307495
Epoch: 1, Steps: 266 Train Loss: 31.2111 (Forecasting Loss:0.1866 + XiCon Loss:3.1024 x Lambda(10.0)), Vali MSE Loss: 0.1565 Test MSE Loss: 0.1367
Validation loss decreased (inf --> 0.156490).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.6998501
	speed: 0.0316s/iter; left time: 828.1131s
	iters: 200, epoch: 2 | loss: 31.4902248
	speed: 0.0289s/iter; left time: 754.2583s
Epoch: 2 cost time: 7.938710451126099
Epoch: 2, Steps: 266 Train Loss: 30.5573 (Forecasting Loss:0.1597 + XiCon Loss:3.0398 x Lambda(10.0)), Vali MSE Loss: 0.1613 Test MSE Loss: 0.1381
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 30.8162041
	speed: 0.0309s/iter; left time: 802.8055s
	iters: 200, epoch: 3 | loss: 29.1420021
	speed: 0.0290s/iter; left time: 751.0753s
Epoch: 3 cost time: 7.942721605300903
Epoch: 3, Steps: 266 Train Loss: 30.1939 (Forecasting Loss:0.1523 + XiCon Loss:3.0042 x Lambda(10.0)), Vali MSE Loss: 0.1485 Test MSE Loss: 0.1278
Validation loss decreased (0.156490 --> 0.148512).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.6857090
	speed: 0.0306s/iter; left time: 786.1618s
	iters: 200, epoch: 4 | loss: 28.5375099
	speed: 0.0288s/iter; left time: 738.5704s
Epoch: 4 cost time: 7.827341794967651
Epoch: 4, Steps: 266 Train Loss: 30.0538 (Forecasting Loss:0.1496 + XiCon Loss:2.9904 x Lambda(10.0)), Vali MSE Loss: 0.1474 Test MSE Loss: 0.1272
Validation loss decreased (0.148512 --> 0.147394).  Saving model ...
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 30.3920383
	speed: 0.0310s/iter; left time: 788.0944s
	iters: 200, epoch: 5 | loss: 31.3835087
	speed: 0.0284s/iter; left time: 718.5781s
Epoch: 5 cost time: 7.8233561515808105
Epoch: 5, Steps: 266 Train Loss: 29.9599 (Forecasting Loss:0.1481 + XiCon Loss:2.9812 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1251
Validation loss decreased (0.147394 --> 0.144190).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 30.6274681
	speed: 0.0318s/iter; left time: 799.7848s
	iters: 200, epoch: 6 | loss: 30.0769501
	speed: 0.0290s/iter; left time: 725.9768s
Epoch: 6 cost time: 7.9739086627960205
Epoch: 6, Steps: 266 Train Loss: 29.8658 (Forecasting Loss:0.1475 + XiCon Loss:2.9718 x Lambda(10.0)), Vali MSE Loss: 0.1446 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 30.9864216
	speed: 0.0304s/iter; left time: 757.3069s
	iters: 200, epoch: 7 | loss: 29.2214489
	speed: 0.0292s/iter; left time: 723.8517s
Epoch: 7 cost time: 7.863547325134277
Epoch: 7, Steps: 266 Train Loss: 29.9492 (Forecasting Loss:0.1471 + XiCon Loss:2.9802 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1248
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 30.1939297
	speed: 0.0309s/iter; left time: 762.3993s
	iters: 200, epoch: 8 | loss: 30.8791904
	speed: 0.0286s/iter; left time: 700.6870s
Epoch: 8 cost time: 7.951350688934326
Epoch: 8, Steps: 266 Train Loss: 29.9205 (Forecasting Loss:0.1470 + XiCon Loss:2.9774 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
Validation loss decreased (0.144190 --> 0.144168).  Saving model ...
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 30.7883816
	speed: 0.0297s/iter; left time: 724.9050s
	iters: 200, epoch: 9 | loss: 29.5083046
	speed: 0.0286s/iter; left time: 693.5724s
Epoch: 9 cost time: 7.685012578964233
Epoch: 9, Steps: 266 Train Loss: 29.9365 (Forecasting Loss:0.1470 + XiCon Loss:2.9790 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
Validation loss decreased (0.144168 --> 0.143984).  Saving model ...
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.4079971
	speed: 0.0312s/iter; left time: 753.1645s
	iters: 200, epoch: 10 | loss: 28.8725853
	speed: 0.0292s/iter; left time: 700.0318s
Epoch: 10 cost time: 7.937248229980469
Epoch: 10, Steps: 266 Train Loss: 29.8526 (Forecasting Loss:0.1468 + XiCon Loss:2.9706 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.9425716
	speed: 0.0315s/iter; left time: 752.1806s
	iters: 200, epoch: 11 | loss: 30.1242065
	speed: 0.0281s/iter; left time: 668.2444s
Epoch: 11 cost time: 7.84451699256897
Epoch: 11, Steps: 266 Train Loss: 29.9221 (Forecasting Loss:0.1468 + XiCon Loss:2.9775 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 30.4308643
	speed: 0.0306s/iter; left time: 721.4969s
	iters: 200, epoch: 12 | loss: 30.6815205
	speed: 0.0286s/iter; left time: 671.3935s
Epoch: 12 cost time: 7.791248798370361
Epoch: 12, Steps: 266 Train Loss: 29.9364 (Forecasting Loss:0.1468 + XiCon Loss:2.9790 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 30.7030945
	speed: 0.0310s/iter; left time: 722.0342s
	iters: 200, epoch: 13 | loss: 30.3630371
	speed: 0.0284s/iter; left time: 659.2096s
Epoch: 13 cost time: 7.9665350914001465
Epoch: 13, Steps: 266 Train Loss: 29.9207 (Forecasting Loss:0.1467 + XiCon Loss:2.9774 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.5273972
	speed: 0.0311s/iter; left time: 716.1906s
	iters: 200, epoch: 14 | loss: 30.6531525
	speed: 0.0287s/iter; left time: 659.2956s
Epoch: 14 cost time: 7.872176885604858
Epoch: 14, Steps: 266 Train Loss: 29.8980 (Forecasting Loss:0.1468 + XiCon Loss:2.9751 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1245
Validation loss decreased (0.143984 --> 0.143946).  Saving model ...
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 30.1361046
	speed: 0.0310s/iter; left time: 705.1675s
	iters: 200, epoch: 15 | loss: 30.0372124
	speed: 0.0286s/iter; left time: 647.4620s
Epoch: 15 cost time: 7.934382677078247
Epoch: 15, Steps: 266 Train Loss: 29.8936 (Forecasting Loss:0.1468 + XiCon Loss:2.9747 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.2433262
	speed: 0.0309s/iter; left time: 695.1132s
	iters: 200, epoch: 16 | loss: 29.7840042
	speed: 0.0282s/iter; left time: 632.4515s
Epoch: 16 cost time: 7.8078083992004395
Epoch: 16, Steps: 266 Train Loss: 29.9439 (Forecasting Loss:0.1467 + XiCon Loss:2.9797 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-07
	iters: 100, epoch: 17 | loss: 29.5915318
	speed: 0.0307s/iter; left time: 682.4108s
	iters: 200, epoch: 17 | loss: 30.0096283
	speed: 0.0286s/iter; left time: 632.8787s
Epoch: 17 cost time: 7.793558359146118
Epoch: 17, Steps: 266 Train Loss: 29.8957 (Forecasting Loss:0.1468 + XiCon Loss:2.9749 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-08
	iters: 100, epoch: 18 | loss: 30.8902702
	speed: 0.0306s/iter; left time: 672.0205s
	iters: 200, epoch: 18 | loss: 29.1100216
	speed: 0.0289s/iter; left time: 633.1808s
Epoch: 18 cost time: 7.823943376541138
Epoch: 18, Steps: 266 Train Loss: 29.9576 (Forecasting Loss:0.1468 + XiCon Loss:2.9811 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-08
	iters: 100, epoch: 19 | loss: 29.7194500
	speed: 0.0307s/iter; left time: 666.0410s
	iters: 200, epoch: 19 | loss: 29.9519196
	speed: 0.0295s/iter; left time: 638.3658s
Epoch: 19 cost time: 7.928727388381958
Epoch: 19, Steps: 266 Train Loss: 29.9056 (Forecasting Loss:0.1468 + XiCon Loss:2.9759 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1245
Validation loss decreased (0.143946 --> 0.143918).  Saving model ...
Updating learning rate to 1.9073486328125e-08
	iters: 100, epoch: 20 | loss: 30.4235382
	speed: 0.0307s/iter; left time: 657.9795s
	iters: 200, epoch: 20 | loss: 29.3238487
	speed: 0.0291s/iter; left time: 620.2784s
Epoch: 20 cost time: 7.855830192565918
Epoch: 20, Steps: 266 Train Loss: 29.9663 (Forecasting Loss:0.1467 + XiCon Loss:2.9820 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1245
Validation loss decreased (0.143918 --> 0.143884).  Saving model ...
Updating learning rate to 9.5367431640625e-09
	iters: 100, epoch: 21 | loss: 31.5169678
	speed: 0.0316s/iter; left time: 669.4489s
	iters: 200, epoch: 21 | loss: 31.3149815
	speed: 0.0293s/iter; left time: 617.4799s
Epoch: 21 cost time: 8.02805757522583
Epoch: 21, Steps: 266 Train Loss: 29.8996 (Forecasting Loss:0.1468 + XiCon Loss:2.9753 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-09
	iters: 100, epoch: 22 | loss: 29.5686111
	speed: 0.0311s/iter; left time: 650.9049s
	iters: 200, epoch: 22 | loss: 29.9366360
	speed: 0.0292s/iter; left time: 608.7304s
Epoch: 22 cost time: 7.914302587509155
Epoch: 22, Steps: 266 Train Loss: 29.8900 (Forecasting Loss:0.1468 + XiCon Loss:2.9743 x Lambda(10.0)), Vali MSE Loss: 0.1439 Test MSE Loss: 0.1245
Validation loss decreased (0.143884 --> 0.143869).  Saving model ...
Updating learning rate to 2.384185791015625e-09
	iters: 100, epoch: 23 | loss: 29.8859386
	speed: 0.0310s/iter; left time: 640.4580s
	iters: 200, epoch: 23 | loss: 29.9305191
	speed: 0.0285s/iter; left time: 585.3015s
Epoch: 23 cost time: 7.8585875034332275
Epoch: 23, Steps: 266 Train Loss: 29.9216 (Forecasting Loss:0.1467 + XiCon Loss:2.9775 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1920928955078125e-09
	iters: 100, epoch: 24 | loss: 29.8767147
	speed: 0.0303s/iter; left time: 618.0281s
	iters: 200, epoch: 24 | loss: 30.5275154
	speed: 0.0288s/iter; left time: 583.8203s
Epoch: 24 cost time: 7.834139823913574
Epoch: 24, Steps: 266 Train Loss: 29.8959 (Forecasting Loss:0.1468 + XiCon Loss:2.9749 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.960464477539063e-10
	iters: 100, epoch: 25 | loss: 29.7721481
	speed: 0.0304s/iter; left time: 610.7676s
	iters: 200, epoch: 25 | loss: 29.2707710
	speed: 0.0289s/iter; left time: 578.5607s
Epoch: 25 cost time: 7.804088830947876
Epoch: 25, Steps: 266 Train Loss: 29.8800 (Forecasting Loss:0.1468 + XiCon Loss:2.9733 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.9802322387695313e-10
	iters: 100, epoch: 26 | loss: 28.9680367
	speed: 0.0314s/iter; left time: 623.8518s
	iters: 200, epoch: 26 | loss: 29.9613457
	speed: 0.0286s/iter; left time: 565.2203s
Epoch: 26 cost time: 7.915132284164429
Epoch: 26, Steps: 266 Train Loss: 29.8612 (Forecasting Loss:0.1467 + XiCon Loss:2.9714 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.4901161193847657e-10
	iters: 100, epoch: 27 | loss: 29.4135151
	speed: 0.0308s/iter; left time: 603.0800s
	iters: 200, epoch: 27 | loss: 31.3886452
	speed: 0.0280s/iter; left time: 545.7176s
Epoch: 27 cost time: 7.751964569091797
Epoch: 27, Steps: 266 Train Loss: 29.9437 (Forecasting Loss:0.1467 + XiCon Loss:2.9797 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.450580596923828e-11
	iters: 100, epoch: 28 | loss: 29.6004219
	speed: 0.0300s/iter; left time: 579.5638s
	iters: 200, epoch: 28 | loss: 30.5203362
	speed: 0.0286s/iter; left time: 549.4023s
Epoch: 28 cost time: 7.753022909164429
Epoch: 28, Steps: 266 Train Loss: 29.9786 (Forecasting Loss:0.1467 + XiCon Loss:2.9832 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.725290298461914e-11
	iters: 100, epoch: 29 | loss: 30.3940277
	speed: 0.0306s/iter; left time: 582.2987s
	iters: 200, epoch: 29 | loss: 29.1598854
	speed: 0.0288s/iter; left time: 545.7636s
Epoch: 29 cost time: 7.7928924560546875
Epoch: 29, Steps: 266 Train Loss: 29.9637 (Forecasting Loss:0.1467 + XiCon Loss:2.9817 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.862645149230957e-11
	iters: 100, epoch: 30 | loss: 29.7129345
	speed: 0.0309s/iter; left time: 580.4214s
	iters: 200, epoch: 30 | loss: 29.9242649
	speed: 0.0283s/iter; left time: 528.8142s
Epoch: 30 cost time: 7.843682050704956
Epoch: 30, Steps: 266 Train Loss: 29.9181 (Forecasting Loss:0.1469 + XiCon Loss:2.9771 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.313225746154785e-12
	iters: 100, epoch: 31 | loss: 29.8026886
	speed: 0.0311s/iter; left time: 575.5303s
	iters: 200, epoch: 31 | loss: 28.6669941
	speed: 0.0291s/iter; left time: 536.7816s
Epoch: 31 cost time: 7.894887447357178
Epoch: 31, Steps: 266 Train Loss: 29.9343 (Forecasting Loss:0.1467 + XiCon Loss:2.9788 x Lambda(10.0)), Vali MSE Loss: 0.1441 Test MSE Loss: 0.1245
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.656612873077393e-12
	iters: 100, epoch: 32 | loss: 30.9882565
	speed: 0.0299s/iter; left time: 546.2263s
	iters: 200, epoch: 32 | loss: 30.5479679
	speed: 0.0291s/iter; left time: 529.1750s
Epoch: 32 cost time: 7.7667601108551025
Epoch: 32, Steps: 266 Train Loss: 29.9738 (Forecasting Loss:0.1468 + XiCon Loss:2.9827 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1245
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06453566998243332, mae:0.18437975645065308, mape:0.4492807984352112, mspe:8.110602378845215 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:73217
train 34129
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.4414
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34129
val 11425
test 11425
	iters: 100, epoch: 1 | loss: 31.9122810
	speed: 0.0328s/iter; left time: 868.7683s
	iters: 200, epoch: 1 | loss: 31.1794701
	speed: 0.0304s/iter; left time: 801.8396s
Epoch: 1 cost time: 8.359320163726807
Epoch: 1, Steps: 266 Train Loss: 31.4646 (Forecasting Loss:0.1900 + XiCon Loss:3.1275 x Lambda(10.0)), Vali MSE Loss: 0.1609 Test MSE Loss: 0.1375
Validation loss decreased (inf --> 0.160892).  Saving model ...
Updating learning rate to 0.005
	iters: 100, epoch: 2 | loss: 29.4940357
	speed: 0.0314s/iter; left time: 824.2252s
	iters: 200, epoch: 2 | loss: 32.0739708
	speed: 0.0281s/iter; left time: 734.7262s
Epoch: 2 cost time: 7.880133152008057
Epoch: 2, Steps: 266 Train Loss: 30.5597 (Forecasting Loss:0.1586 + XiCon Loss:3.0401 x Lambda(10.0)), Vali MSE Loss: 0.1500 Test MSE Loss: 0.1314
Validation loss decreased (0.160892 --> 0.149981).  Saving model ...
Updating learning rate to 0.0025
	iters: 100, epoch: 3 | loss: 31.1188469
	speed: 0.0308s/iter; left time: 798.7404s
	iters: 200, epoch: 3 | loss: 31.3041630
	speed: 0.0285s/iter; left time: 738.4750s
Epoch: 3 cost time: 7.84799599647522
Epoch: 3, Steps: 266 Train Loss: 30.8289 (Forecasting Loss:0.1522 + XiCon Loss:3.0677 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.1266
Validation loss decreased (0.149981 --> 0.147857).  Saving model ...
Updating learning rate to 0.00125
	iters: 100, epoch: 4 | loss: 30.1826248
	speed: 0.0315s/iter; left time: 808.7340s
	iters: 200, epoch: 4 | loss: 30.2177753
	speed: 0.0289s/iter; left time: 739.8729s
Epoch: 4 cost time: 7.970168352127075
Epoch: 4, Steps: 266 Train Loss: 30.4656 (Forecasting Loss:0.1495 + XiCon Loss:3.0316 x Lambda(10.0)), Vali MSE Loss: 0.1479 Test MSE Loss: 0.1268
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000625
	iters: 100, epoch: 5 | loss: 29.9859619
	speed: 0.0299s/iter; left time: 760.6615s
	iters: 200, epoch: 5 | loss: 30.6541252
	speed: 0.0287s/iter; left time: 726.3592s
Epoch: 5 cost time: 7.804908514022827
Epoch: 5, Steps: 266 Train Loss: 30.3683 (Forecasting Loss:0.1480 + XiCon Loss:3.0220 x Lambda(10.0)), Vali MSE Loss: 0.1465 Test MSE Loss: 0.1252
Validation loss decreased (0.147857 --> 0.146533).  Saving model ...
Updating learning rate to 0.0003125
	iters: 100, epoch: 6 | loss: 29.5930767
	speed: 0.0320s/iter; left time: 804.8888s
	iters: 200, epoch: 6 | loss: 30.2209091
	speed: 0.0282s/iter; left time: 706.3725s
Epoch: 6 cost time: 7.9534525871276855
Epoch: 6, Steps: 266 Train Loss: 30.3236 (Forecasting Loss:0.1476 + XiCon Loss:3.0176 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1253
Validation loss decreased (0.146533 --> 0.143979).  Saving model ...
Updating learning rate to 0.00015625
	iters: 100, epoch: 7 | loss: 31.0255451
	speed: 0.0307s/iter; left time: 763.9876s
	iters: 200, epoch: 7 | loss: 30.4021015
	speed: 0.0285s/iter; left time: 706.1620s
Epoch: 7 cost time: 7.7776477336883545
Epoch: 7, Steps: 266 Train Loss: 30.2659 (Forecasting Loss:0.1472 + XiCon Loss:3.0119 x Lambda(10.0)), Vali MSE Loss: 0.1448 Test MSE Loss: 0.1247
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-05
	iters: 100, epoch: 8 | loss: 29.2383633
	speed: 0.0306s/iter; left time: 754.1076s
	iters: 200, epoch: 8 | loss: 30.5815411
	speed: 0.0282s/iter; left time: 692.4492s
Epoch: 8 cost time: 7.796900272369385
Epoch: 8, Steps: 266 Train Loss: 30.3500 (Forecasting Loss:0.1471 + XiCon Loss:3.0203 x Lambda(10.0)), Vali MSE Loss: 0.1440 Test MSE Loss: 0.1248
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-05
	iters: 100, epoch: 9 | loss: 29.3957996
	speed: 0.0302s/iter; left time: 736.6650s
	iters: 200, epoch: 9 | loss: 30.4123402
	speed: 0.0281s/iter; left time: 681.2111s
Epoch: 9 cost time: 7.721212148666382
Epoch: 9, Steps: 266 Train Loss: 30.3572 (Forecasting Loss:0.1470 + XiCon Loss:3.0210 x Lambda(10.0)), Vali MSE Loss: 0.1445 Test MSE Loss: 0.1247
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-05
	iters: 100, epoch: 10 | loss: 30.5853634
	speed: 0.0302s/iter; left time: 727.1098s
	iters: 200, epoch: 10 | loss: 30.1292553
	speed: 0.0280s/iter; left time: 671.3881s
Epoch: 10 cost time: 7.7412614822387695
Epoch: 10, Steps: 266 Train Loss: 30.2886 (Forecasting Loss:0.1469 + XiCon Loss:3.0142 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1247
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-06
	iters: 100, epoch: 11 | loss: 29.5439739
	speed: 0.0311s/iter; left time: 741.4537s
	iters: 200, epoch: 11 | loss: 29.8517742
	speed: 0.0290s/iter; left time: 687.4006s
Epoch: 11 cost time: 7.9755167961120605
Epoch: 11, Steps: 266 Train Loss: 30.3029 (Forecasting Loss:0.1469 + XiCon Loss:3.0156 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-06
	iters: 100, epoch: 12 | loss: 29.9157333
	speed: 0.0306s/iter; left time: 721.1829s
	iters: 200, epoch: 12 | loss: 29.4015789
	speed: 0.0286s/iter; left time: 670.5312s
Epoch: 12 cost time: 7.84262228012085
Epoch: 12, Steps: 266 Train Loss: 30.3087 (Forecasting Loss:0.1470 + XiCon Loss:3.0162 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-06
	iters: 100, epoch: 13 | loss: 31.0893230
	speed: 0.0304s/iter; left time: 707.7708s
	iters: 200, epoch: 13 | loss: 30.0217953
	speed: 0.0291s/iter; left time: 674.5670s
Epoch: 13 cost time: 7.81663966178894
Epoch: 13, Steps: 266 Train Loss: 30.2818 (Forecasting Loss:0.1469 + XiCon Loss:3.0135 x Lambda(10.0)), Vali MSE Loss: 0.1444 Test MSE Loss: 0.1246
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-06
	iters: 100, epoch: 14 | loss: 29.1378708
	speed: 0.0308s/iter; left time: 710.7355s
	iters: 200, epoch: 14 | loss: 29.4312592
	speed: 0.0282s/iter; left time: 647.0040s
Epoch: 14 cost time: 7.8491857051849365
Epoch: 14, Steps: 266 Train Loss: 30.2989 (Forecasting Loss:0.1469 + XiCon Loss:3.0152 x Lambda(10.0)), Vali MSE Loss: 0.1442 Test MSE Loss: 0.1246
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-07
	iters: 100, epoch: 15 | loss: 29.7327023
	speed: 0.0319s/iter; left time: 727.2489s
	iters: 200, epoch: 15 | loss: 30.6496391
	speed: 0.0289s/iter; left time: 655.8138s
Epoch: 15 cost time: 7.999812602996826
Epoch: 15, Steps: 266 Train Loss: 30.2849 (Forecasting Loss:0.1469 + XiCon Loss:3.0138 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-07
	iters: 100, epoch: 16 | loss: 30.4536114
	speed: 0.0307s/iter; left time: 690.7386s
	iters: 200, epoch: 16 | loss: 30.9031010
	speed: 0.0288s/iter; left time: 644.6675s
Epoch: 16 cost time: 7.828318119049072
Epoch: 16, Steps: 266 Train Loss: 30.3225 (Forecasting Loss:0.1469 + XiCon Loss:3.0176 x Lambda(10.0)), Vali MSE Loss: 0.1443 Test MSE Loss: 0.1246
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl96_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11425
test shape: (89, 128, 96, 1) (89, 128, 96, 1)
test shape: (11392, 96, 1) (11392, 96, 1)
mse:0.06516384333372116, mae:0.18534494936466217, mape:0.4498072564601898, mspe:8.124547004699707 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0646+-0.00038, MAE:0.1845+-0.00060, MAPE:0.4490+-0.00127, MSPE:8.1285+-0.04722, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[192], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=192, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.0089
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5798736
	speed: 0.0353s/iter; left time: 931.3636s
	iters: 200, epoch: 1 | loss: 3.5851147
	speed: 0.0298s/iter; left time: 782.6822s
Epoch: 1 cost time: 8.40192699432373
Epoch: 1, Steps: 265 Train Loss: 3.5738 (Forecasting Loss:0.3531 + XiCon Loss:3.2207 x Lambda(1.0)), Vali MSE Loss: 0.3365 Test MSE Loss: 0.2776
Validation loss decreased (inf --> 0.336486).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3807924
	speed: 0.0313s/iter; left time: 817.3529s
	iters: 200, epoch: 2 | loss: 3.3795860
	speed: 0.0308s/iter; left time: 802.7560s
Epoch: 2 cost time: 8.266944408416748
Epoch: 2, Steps: 265 Train Loss: 3.3971 (Forecasting Loss:0.2415 + XiCon Loss:3.1556 x Lambda(1.0)), Vali MSE Loss: 0.2168 Test MSE Loss: 0.1739
Validation loss decreased (0.336486 --> 0.216784).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2168648
	speed: 0.0318s/iter; left time: 823.1800s
	iters: 200, epoch: 3 | loss: 3.2447321
	speed: 0.0294s/iter; left time: 758.0243s
Epoch: 3 cost time: 8.044817447662354
Epoch: 3, Steps: 265 Train Loss: 3.2670 (Forecasting Loss:0.2144 + XiCon Loss:3.0526 x Lambda(1.0)), Vali MSE Loss: 0.2116 Test MSE Loss: 0.1708
Validation loss decreased (0.216784 --> 0.211608).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.1959264
	speed: 0.0313s/iter; left time: 800.2709s
	iters: 200, epoch: 4 | loss: 3.2476795
	speed: 0.0297s/iter; left time: 756.4169s
Epoch: 4 cost time: 7.985570669174194
Epoch: 4, Steps: 265 Train Loss: 3.2315 (Forecasting Loss:0.2110 + XiCon Loss:3.0205 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1699
Validation loss decreased (0.211608 --> 0.210005).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2143068
	speed: 0.0313s/iter; left time: 794.4099s
	iters: 200, epoch: 5 | loss: 3.2480869
	speed: 0.0300s/iter; left time: 758.0355s
Epoch: 5 cost time: 8.148942470550537
Epoch: 5, Steps: 265 Train Loss: 3.2180 (Forecasting Loss:0.2097 + XiCon Loss:3.0084 x Lambda(1.0)), Vali MSE Loss: 0.2092 Test MSE Loss: 0.1695
Validation loss decreased (0.210005 --> 0.209169).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2606287
	speed: 0.0314s/iter; left time: 788.1177s
	iters: 200, epoch: 6 | loss: 3.1625214
	speed: 0.0300s/iter; left time: 748.7067s
Epoch: 6 cost time: 8.072080135345459
Epoch: 6, Steps: 265 Train Loss: 3.2160 (Forecasting Loss:0.2091 + XiCon Loss:3.0068 x Lambda(1.0)), Vali MSE Loss: 0.2090 Test MSE Loss: 0.1693
Validation loss decreased (0.209169 --> 0.208966).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2226274
	speed: 0.0315s/iter; left time: 781.2331s
	iters: 200, epoch: 7 | loss: 3.2588804
	speed: 0.0299s/iter; left time: 738.1119s
Epoch: 7 cost time: 8.164922714233398
Epoch: 7, Steps: 265 Train Loss: 3.2143 (Forecasting Loss:0.2090 + XiCon Loss:3.0053 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1692
Validation loss decreased (0.208966 --> 0.208938).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2295380
	speed: 0.0310s/iter; left time: 759.8042s
	iters: 200, epoch: 8 | loss: 3.2320778
	speed: 0.0289s/iter; left time: 706.7814s
Epoch: 8 cost time: 7.948383331298828
Epoch: 8, Steps: 265 Train Loss: 3.2126 (Forecasting Loss:0.2088 + XiCon Loss:3.0038 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
Validation loss decreased (0.208938 --> 0.208786).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2090294
	speed: 0.0311s/iter; left time: 754.8332s
	iters: 200, epoch: 9 | loss: 3.2152503
	speed: 0.0294s/iter; left time: 711.4705s
Epoch: 9 cost time: 8.02034044265747
Epoch: 9, Steps: 265 Train Loss: 3.2133 (Forecasting Loss:0.2086 + XiCon Loss:3.0047 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1692
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2406898
	speed: 0.0307s/iter; left time: 736.5271s
	iters: 200, epoch: 10 | loss: 3.2084441
	speed: 0.0302s/iter; left time: 723.0562s
Epoch: 10 cost time: 8.121346712112427
Epoch: 10, Steps: 265 Train Loss: 3.2098 (Forecasting Loss:0.2087 + XiCon Loss:3.0011 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1691
Validation loss decreased (0.208786 --> 0.208629).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2093050
	speed: 0.0314s/iter; left time: 746.5479s
	iters: 200, epoch: 11 | loss: 3.1830361
	speed: 0.0299s/iter; left time: 706.4725s
Epoch: 11 cost time: 8.044634103775024
Epoch: 11, Steps: 265 Train Loss: 3.2135 (Forecasting Loss:0.2086 + XiCon Loss:3.0049 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1691
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2239568
	speed: 0.0316s/iter; left time: 743.1420s
	iters: 200, epoch: 12 | loss: 3.2190733
	speed: 0.0303s/iter; left time: 708.2479s
Epoch: 12 cost time: 8.238919019699097
Epoch: 12, Steps: 265 Train Loss: 3.2126 (Forecasting Loss:0.2086 + XiCon Loss:3.0040 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1691
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2169003
	speed: 0.0311s/iter; left time: 722.3915s
	iters: 200, epoch: 13 | loss: 3.1951859
	speed: 0.0299s/iter; left time: 690.2893s
Epoch: 13 cost time: 8.045637130737305
Epoch: 13, Steps: 265 Train Loss: 3.2112 (Forecasting Loss:0.2085 + XiCon Loss:3.0027 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1691
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2075129
	speed: 0.0315s/iter; left time: 722.8277s
	iters: 200, epoch: 14 | loss: 3.2339246
	speed: 0.0298s/iter; left time: 681.2516s
Epoch: 14 cost time: 8.152239084243774
Epoch: 14, Steps: 265 Train Loss: 3.2111 (Forecasting Loss:0.2086 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1691
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2086680
	speed: 0.0316s/iter; left time: 716.7753s
	iters: 200, epoch: 15 | loss: 3.2168298
	speed: 0.0297s/iter; left time: 671.4988s
Epoch: 15 cost time: 8.106669425964355
Epoch: 15, Steps: 265 Train Loss: 3.2111 (Forecasting Loss:0.2085 + XiCon Loss:3.0026 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1691
Validation loss decreased (0.208629 --> 0.208628).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2381706
	speed: 0.0316s/iter; left time: 709.7069s
	iters: 200, epoch: 16 | loss: 3.2340291
	speed: 0.0295s/iter; left time: 659.5704s
Epoch: 16 cost time: 8.074684381484985
Epoch: 16, Steps: 265 Train Loss: 3.2132 (Forecasting Loss:0.2086 + XiCon Loss:3.0046 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1691
Validation loss decreased (0.208628 --> 0.208559).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2488065
	speed: 0.0322s/iter; left time: 713.7000s
	iters: 200, epoch: 17 | loss: 3.2538121
	speed: 0.0309s/iter; left time: 680.8696s
Epoch: 17 cost time: 8.324635982513428
Epoch: 17, Steps: 265 Train Loss: 3.2114 (Forecasting Loss:0.2085 + XiCon Loss:3.0029 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1691
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2510619
	speed: 0.0312s/iter; left time: 683.1169s
	iters: 200, epoch: 18 | loss: 3.2441072
	speed: 0.0296s/iter; left time: 645.2091s
Epoch: 18 cost time: 8.0380539894104
Epoch: 18, Steps: 265 Train Loss: 3.2099 (Forecasting Loss:0.2085 + XiCon Loss:3.0014 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1691
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2017903
	speed: 0.0321s/iter; left time: 693.8093s
	iters: 200, epoch: 19 | loss: 3.2136893
	speed: 0.0306s/iter; left time: 658.2104s
Epoch: 19 cost time: 8.246346712112427
Epoch: 19, Steps: 265 Train Loss: 3.2110 (Forecasting Loss:0.2085 + XiCon Loss:3.0024 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1691
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.1596501
	speed: 0.0317s/iter; left time: 678.0769s
	iters: 200, epoch: 20 | loss: 3.2127979
	speed: 0.0296s/iter; left time: 630.3673s
Epoch: 20 cost time: 8.098796606063843
Epoch: 20, Steps: 265 Train Loss: 3.2105 (Forecasting Loss:0.2086 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1691
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2362678
	speed: 0.0316s/iter; left time: 667.6010s
	iters: 200, epoch: 21 | loss: 3.1910977
	speed: 0.0294s/iter; left time: 618.1595s
Epoch: 21 cost time: 8.061737060546875
Epoch: 21, Steps: 265 Train Loss: 3.2112 (Forecasting Loss:0.2085 + XiCon Loss:3.0027 x Lambda(1.0)), Vali MSE Loss: 0.2086 Test MSE Loss: 0.1691
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2329118
	speed: 0.0326s/iter; left time: 679.9382s
	iters: 200, epoch: 22 | loss: 3.2204058
	speed: 0.0313s/iter; left time: 649.6015s
Epoch: 22 cost time: 8.409721374511719
Epoch: 22, Steps: 265 Train Loss: 3.2107 (Forecasting Loss:0.2084 + XiCon Loss:3.0023 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1691
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2414126
	speed: 0.0329s/iter; left time: 677.0361s
	iters: 200, epoch: 23 | loss: 3.1930678
	speed: 0.0296s/iter; left time: 605.0198s
Epoch: 23 cost time: 8.149984121322632
Epoch: 23, Steps: 265 Train Loss: 3.2109 (Forecasting Loss:0.2086 + XiCon Loss:3.0024 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1691
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2138054
	speed: 0.0314s/iter; left time: 638.3280s
	iters: 200, epoch: 24 | loss: 3.2211127
	speed: 0.0292s/iter; left time: 589.3030s
Epoch: 24 cost time: 8.030375242233276
Epoch: 24, Steps: 265 Train Loss: 3.2103 (Forecasting Loss:0.2087 + XiCon Loss:3.0016 x Lambda(1.0)), Vali MSE Loss: 0.2088 Test MSE Loss: 0.1691
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2180352
	speed: 0.0321s/iter; left time: 643.6292s
	iters: 200, epoch: 25 | loss: 3.1961098
	speed: 0.0297s/iter; left time: 591.4631s
Epoch: 25 cost time: 8.14121127128601
Epoch: 25, Steps: 265 Train Loss: 3.2137 (Forecasting Loss:0.2086 + XiCon Loss:3.0051 x Lambda(1.0)), Vali MSE Loss: 0.2089 Test MSE Loss: 0.1691
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2064052
	speed: 0.0322s/iter; left time: 636.1897s
	iters: 200, epoch: 26 | loss: 3.2222109
	speed: 0.0293s/iter; left time: 577.4633s
Epoch: 26 cost time: 8.110770225524902
Epoch: 26, Steps: 265 Train Loss: 3.2122 (Forecasting Loss:0.2086 + XiCon Loss:3.0037 x Lambda(1.0)), Vali MSE Loss: 0.2087 Test MSE Loss: 0.1691
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09873984754085541, mae:0.23951824009418488, mape:0.5686953663825989, mspe:11.788305282592773 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.0711
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5580251
	speed: 0.0348s/iter; left time: 919.2404s
	iters: 200, epoch: 1 | loss: 3.6113884
	speed: 0.0323s/iter; left time: 849.1703s
Epoch: 1 cost time: 8.78813624382019
Epoch: 1, Steps: 265 Train Loss: 3.5963 (Forecasting Loss:0.3608 + XiCon Loss:3.2355 x Lambda(1.0)), Vali MSE Loss: 0.3356 Test MSE Loss: 0.2830
Validation loss decreased (inf --> 0.335581).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3917968
	speed: 0.0317s/iter; left time: 828.3953s
	iters: 200, epoch: 2 | loss: 3.3545866
	speed: 0.0302s/iter; left time: 786.3047s
Epoch: 2 cost time: 8.109774112701416
Epoch: 2, Steps: 265 Train Loss: 3.4024 (Forecasting Loss:0.2416 + XiCon Loss:3.1608 x Lambda(1.0)), Vali MSE Loss: 0.2191 Test MSE Loss: 0.1723
Validation loss decreased (0.335581 --> 0.219070).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.2408674
	speed: 0.0318s/iter; left time: 823.0528s
	iters: 200, epoch: 3 | loss: 3.2370789
	speed: 0.0295s/iter; left time: 759.0174s
Epoch: 3 cost time: 8.130822658538818
Epoch: 3, Steps: 265 Train Loss: 3.2600 (Forecasting Loss:0.2135 + XiCon Loss:3.0465 x Lambda(1.0)), Vali MSE Loss: 0.2149 Test MSE Loss: 0.1691
Validation loss decreased (0.219070 --> 0.214850).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2122188
	speed: 0.0321s/iter; left time: 821.4090s
	iters: 200, epoch: 4 | loss: 3.2208052
	speed: 0.0299s/iter; left time: 763.2576s
Epoch: 4 cost time: 8.210546731948853
Epoch: 4, Steps: 265 Train Loss: 3.2303 (Forecasting Loss:0.2103 + XiCon Loss:3.0199 x Lambda(1.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1676
Validation loss decreased (0.214850 --> 0.212004).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.1764987
	speed: 0.0316s/iter; left time: 800.6054s
	iters: 200, epoch: 5 | loss: 3.2158945
	speed: 0.0305s/iter; left time: 770.9290s
Epoch: 5 cost time: 8.116656303405762
Epoch: 5, Steps: 265 Train Loss: 3.2185 (Forecasting Loss:0.2093 + XiCon Loss:3.0092 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1676
Validation loss decreased (0.212004 --> 0.211410).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2285941
	speed: 0.0325s/iter; left time: 816.0199s
	iters: 200, epoch: 6 | loss: 3.1887052
	speed: 0.0309s/iter; left time: 770.8152s
Epoch: 6 cost time: 8.399413108825684
Epoch: 6, Steps: 265 Train Loss: 3.2140 (Forecasting Loss:0.2087 + XiCon Loss:3.0053 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1672
Validation loss decreased (0.211410 --> 0.210916).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2057159
	speed: 0.0316s/iter; left time: 784.8920s
	iters: 200, epoch: 7 | loss: 3.1868162
	speed: 0.0292s/iter; left time: 721.6057s
Epoch: 7 cost time: 8.050881385803223
Epoch: 7, Steps: 265 Train Loss: 3.2127 (Forecasting Loss:0.2085 + XiCon Loss:3.0042 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1671
Validation loss decreased (0.210916 --> 0.210530).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.2546089
	speed: 0.0315s/iter; left time: 773.7327s
	iters: 200, epoch: 8 | loss: 3.2033205
	speed: 0.0292s/iter; left time: 713.7496s
Epoch: 8 cost time: 7.9585089683532715
Epoch: 8, Steps: 265 Train Loss: 3.2104 (Forecasting Loss:0.2084 + XiCon Loss:3.0020 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.1885068
	speed: 0.0317s/iter; left time: 768.5467s
	iters: 200, epoch: 9 | loss: 3.1675577
	speed: 0.0292s/iter; left time: 705.8818s
Epoch: 9 cost time: 8.086508512496948
Epoch: 9, Steps: 265 Train Loss: 3.2107 (Forecasting Loss:0.2082 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.1671801
	speed: 0.0323s/iter; left time: 775.8841s
	iters: 200, epoch: 10 | loss: 3.1911011
	speed: 0.0311s/iter; left time: 742.8003s
Epoch: 10 cost time: 8.277471780776978
Epoch: 10, Steps: 265 Train Loss: 3.2104 (Forecasting Loss:0.2083 + XiCon Loss:3.0022 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1670
Validation loss decreased (0.210530 --> 0.210276).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1954122
	speed: 0.0329s/iter; left time: 782.0155s
	iters: 200, epoch: 11 | loss: 3.1836205
	speed: 0.0311s/iter; left time: 736.4733s
Epoch: 11 cost time: 8.477458000183105
Epoch: 11, Steps: 265 Train Loss: 3.2113 (Forecasting Loss:0.2081 + XiCon Loss:3.0032 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1761649
	speed: 0.0316s/iter; left time: 742.2565s
	iters: 200, epoch: 12 | loss: 3.1773961
	speed: 0.0289s/iter; left time: 676.1557s
Epoch: 12 cost time: 7.994302749633789
Epoch: 12, Steps: 265 Train Loss: 3.2093 (Forecasting Loss:0.2082 + XiCon Loss:3.0011 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1670
Validation loss decreased (0.210276 --> 0.210213).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2250195
	speed: 0.0315s/iter; left time: 730.3027s
	iters: 200, epoch: 13 | loss: 3.2009571
	speed: 0.0296s/iter; left time: 685.1357s
Epoch: 13 cost time: 8.052307367324829
Epoch: 13, Steps: 265 Train Loss: 3.2106 (Forecasting Loss:0.2082 + XiCon Loss:3.0024 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.2266092
	speed: 0.0324s/iter; left time: 742.9140s
	iters: 200, epoch: 14 | loss: 3.2189307
	speed: 0.0297s/iter; left time: 677.7824s
Epoch: 14 cost time: 8.177212238311768
Epoch: 14, Steps: 265 Train Loss: 3.2113 (Forecasting Loss:0.2081 + XiCon Loss:3.0032 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2312059
	speed: 0.0314s/iter; left time: 712.0620s
	iters: 200, epoch: 15 | loss: 3.2104487
	speed: 0.0289s/iter; left time: 652.7763s
Epoch: 15 cost time: 7.948914527893066
Epoch: 15, Steps: 265 Train Loss: 3.2100 (Forecasting Loss:0.2082 + XiCon Loss:3.0019 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.1978517
	speed: 0.0322s/iter; left time: 721.8741s
	iters: 200, epoch: 16 | loss: 3.1968088
	speed: 0.0305s/iter; left time: 681.5817s
Epoch: 16 cost time: 8.290596008300781
Epoch: 16, Steps: 265 Train Loss: 3.2090 (Forecasting Loss:0.2081 + XiCon Loss:3.0009 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1670
Validation loss decreased (0.210213 --> 0.210172).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2251556
	speed: 0.0317s/iter; left time: 703.2184s
	iters: 200, epoch: 17 | loss: 3.2327948
	speed: 0.0293s/iter; left time: 645.7290s
Epoch: 17 cost time: 8.046079397201538
Epoch: 17, Steps: 265 Train Loss: 3.2115 (Forecasting Loss:0.2083 + XiCon Loss:3.0032 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2168508
	speed: 0.0311s/iter; left time: 681.5067s
	iters: 200, epoch: 18 | loss: 3.2122753
	speed: 0.0299s/iter; left time: 650.8154s
Epoch: 18 cost time: 8.037705659866333
Epoch: 18, Steps: 265 Train Loss: 3.2088 (Forecasting Loss:0.2082 + XiCon Loss:3.0006 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2403231
	speed: 0.0323s/iter; left time: 699.3414s
	iters: 200, epoch: 19 | loss: 3.2176504
	speed: 0.0295s/iter; left time: 634.8674s
Epoch: 19 cost time: 8.090433835983276
Epoch: 19, Steps: 265 Train Loss: 3.2099 (Forecasting Loss:0.2083 + XiCon Loss:3.0016 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1670
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2327039
	speed: 0.0319s/iter; left time: 681.0294s
	iters: 200, epoch: 20 | loss: 3.1623805
	speed: 0.0294s/iter; left time: 625.8576s
Epoch: 20 cost time: 8.068400859832764
Epoch: 20, Steps: 265 Train Loss: 3.2103 (Forecasting Loss:0.2081 + XiCon Loss:3.0022 x Lambda(1.0)), Vali MSE Loss: 0.2101 Test MSE Loss: 0.1670
Validation loss decreased (0.210172 --> 0.210131).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2006972
	speed: 0.0324s/iter; left time: 683.7888s
	iters: 200, epoch: 21 | loss: 3.2150736
	speed: 0.0314s/iter; left time: 660.2483s
Epoch: 21 cost time: 8.45932412147522
Epoch: 21, Steps: 265 Train Loss: 3.2104 (Forecasting Loss:0.2081 + XiCon Loss:3.0023 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2588768
	speed: 0.0322s/iter; left time: 671.2494s
	iters: 200, epoch: 22 | loss: 3.1744895
	speed: 0.0292s/iter; left time: 605.5992s
Epoch: 22 cost time: 8.015876293182373
Epoch: 22, Steps: 265 Train Loss: 3.2103 (Forecasting Loss:0.2082 + XiCon Loss:3.0021 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1670
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2660806
	speed: 0.0318s/iter; left time: 655.1276s
	iters: 200, epoch: 23 | loss: 3.2241607
	speed: 0.0293s/iter; left time: 600.7063s
Epoch: 23 cost time: 8.030627489089966
Epoch: 23, Steps: 265 Train Loss: 3.2085 (Forecasting Loss:0.2081 + XiCon Loss:3.0004 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1670
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2338672
	speed: 0.0316s/iter; left time: 641.9337s
	iters: 200, epoch: 24 | loss: 3.1918945
	speed: 0.0306s/iter; left time: 618.9113s
Epoch: 24 cost time: 8.191253662109375
Epoch: 24, Steps: 265 Train Loss: 3.2115 (Forecasting Loss:0.2082 + XiCon Loss:3.0032 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1670
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2330852
	speed: 0.0318s/iter; left time: 637.2388s
	iters: 200, epoch: 25 | loss: 3.1933668
	speed: 0.0292s/iter; left time: 581.3826s
Epoch: 25 cost time: 8.092362403869629
Epoch: 25, Steps: 265 Train Loss: 3.2101 (Forecasting Loss:0.2081 + XiCon Loss:3.0021 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2125912
	speed: 0.0311s/iter; left time: 615.0860s
	iters: 200, epoch: 26 | loss: 3.2195992
	speed: 0.0315s/iter; left time: 619.6400s
Epoch: 26 cost time: 8.301248550415039
Epoch: 26, Steps: 265 Train Loss: 3.2118 (Forecasting Loss:0.2082 + XiCon Loss:3.0036 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1670
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 3.2190385
	speed: 0.0322s/iter; left time: 628.3224s
	iters: 200, epoch: 27 | loss: 3.2198281
	speed: 0.0293s/iter; left time: 568.7907s
Epoch: 27 cost time: 8.109640121459961
Epoch: 27, Steps: 265 Train Loss: 3.2116 (Forecasting Loss:0.2082 + XiCon Loss:3.0034 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1670
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 3.2062781
	speed: 0.0323s/iter; left time: 622.5692s
	iters: 200, epoch: 28 | loss: 3.1805530
	speed: 0.0310s/iter; left time: 593.4542s
Epoch: 28 cost time: 8.317423582077026
Epoch: 28, Steps: 265 Train Loss: 3.2096 (Forecasting Loss:0.2081 + XiCon Loss:3.0015 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1670
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 3.2343187
	speed: 0.0322s/iter; left time: 611.6205s
	iters: 200, epoch: 29 | loss: 3.1612482
	speed: 0.0298s/iter; left time: 561.8240s
Epoch: 29 cost time: 8.15979552268982
Epoch: 29, Steps: 265 Train Loss: 3.2079 (Forecasting Loss:0.2082 + XiCon Loss:2.9997 x Lambda(1.0)), Vali MSE Loss: 0.2102 Test MSE Loss: 0.1670
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 3.2021298
	speed: 0.0318s/iter; left time: 595.9598s
	iters: 200, epoch: 30 | loss: 3.2133660
	speed: 0.0294s/iter; left time: 547.1988s
Epoch: 30 cost time: 8.088008165359497
Epoch: 30, Steps: 265 Train Loss: 3.2104 (Forecasting Loss:0.2080 + XiCon Loss:3.0025 x Lambda(1.0)), Vali MSE Loss: 0.2103 Test MSE Loss: 0.1670
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09704416245222092, mae:0.23696687817573547, mape:0.5691720247268677, mspe:12.106053352355957 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.8035
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.5428102
	speed: 0.0346s/iter; left time: 912.7830s
	iters: 200, epoch: 1 | loss: 3.5073376
	speed: 0.0315s/iter; left time: 828.6093s
Epoch: 1 cost time: 8.731843948364258
Epoch: 1, Steps: 265 Train Loss: 3.5650 (Forecasting Loss:0.3468 + XiCon Loss:3.2181 x Lambda(1.0)), Vali MSE Loss: 0.3251 Test MSE Loss: 0.2714
Validation loss decreased (inf --> 0.325130).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3774061
	speed: 0.0316s/iter; left time: 826.3460s
	iters: 200, epoch: 2 | loss: 3.3220518
	speed: 0.0298s/iter; left time: 775.2139s
Epoch: 2 cost time: 8.10063362121582
Epoch: 2, Steps: 265 Train Loss: 3.3763 (Forecasting Loss:0.2399 + XiCon Loss:3.1364 x Lambda(1.0)), Vali MSE Loss: 0.2208 Test MSE Loss: 0.1733
Validation loss decreased (0.325130 --> 0.220774).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3068643
	speed: 0.0308s/iter; left time: 795.8398s
	iters: 200, epoch: 3 | loss: 3.2392218
	speed: 0.0296s/iter; left time: 762.2958s
Epoch: 3 cost time: 7.959847688674927
Epoch: 3, Steps: 265 Train Loss: 3.2535 (Forecasting Loss:0.2145 + XiCon Loss:3.0390 x Lambda(1.0)), Vali MSE Loss: 0.2162 Test MSE Loss: 0.1704
Validation loss decreased (0.220774 --> 0.216152).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2297673
	speed: 0.0315s/iter; left time: 807.6727s
	iters: 200, epoch: 4 | loss: 3.2048767
	speed: 0.0299s/iter; left time: 762.7645s
Epoch: 4 cost time: 8.067574739456177
Epoch: 4, Steps: 265 Train Loss: 3.2369 (Forecasting Loss:0.2111 + XiCon Loss:3.0258 x Lambda(1.0)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1695
Validation loss decreased (0.216152 --> 0.214097).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2224061
	speed: 0.0315s/iter; left time: 799.1617s
	iters: 200, epoch: 5 | loss: 3.2383299
	speed: 0.0302s/iter; left time: 762.8246s
Epoch: 5 cost time: 8.255043029785156
Epoch: 5, Steps: 265 Train Loss: 3.2292 (Forecasting Loss:0.2098 + XiCon Loss:3.0194 x Lambda(1.0)), Vali MSE Loss: 0.2136 Test MSE Loss: 0.1691
Validation loss decreased (0.214097 --> 0.213634).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2878373
	speed: 0.0317s/iter; left time: 794.1581s
	iters: 200, epoch: 6 | loss: 3.2507236
	speed: 0.0301s/iter; left time: 752.7070s
Epoch: 6 cost time: 8.136580228805542
Epoch: 6, Steps: 265 Train Loss: 3.2229 (Forecasting Loss:0.2090 + XiCon Loss:3.0138 x Lambda(1.0)), Vali MSE Loss: 0.2131 Test MSE Loss: 0.1690
Validation loss decreased (0.213634 --> 0.213126).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2813435
	speed: 0.0321s/iter; left time: 795.5867s
	iters: 200, epoch: 7 | loss: 3.2347507
	speed: 0.0286s/iter; left time: 705.5662s
Epoch: 7 cost time: 7.975196123123169
Epoch: 7, Steps: 265 Train Loss: 3.2226 (Forecasting Loss:0.2087 + XiCon Loss:3.0140 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1689
Validation loss decreased (0.213126 --> 0.212797).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1996300
	speed: 0.0319s/iter; left time: 783.3169s
	iters: 200, epoch: 8 | loss: 3.1880918
	speed: 0.0304s/iter; left time: 743.7195s
Epoch: 8 cost time: 8.167886972427368
Epoch: 8, Steps: 265 Train Loss: 3.2210 (Forecasting Loss:0.2085 + XiCon Loss:3.0125 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1689
Validation loss decreased (0.212797 --> 0.212749).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2432652
	speed: 0.0316s/iter; left time: 766.1264s
	iters: 200, epoch: 9 | loss: 3.2013726
	speed: 0.0295s/iter; left time: 713.5544s
Epoch: 9 cost time: 8.053000450134277
Epoch: 9, Steps: 265 Train Loss: 3.2208 (Forecasting Loss:0.2085 + XiCon Loss:3.0124 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1689
Validation loss decreased (0.212749 --> 0.212711).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2194242
	speed: 0.0308s/iter; left time: 740.6815s
	iters: 200, epoch: 10 | loss: 3.2002141
	speed: 0.0299s/iter; left time: 715.4816s
Epoch: 10 cost time: 8.065925121307373
Epoch: 10, Steps: 265 Train Loss: 3.2200 (Forecasting Loss:0.2085 + XiCon Loss:3.0115 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1688
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.2398932
	speed: 0.0315s/iter; left time: 749.0949s
	iters: 200, epoch: 11 | loss: 3.2008491
	speed: 0.0293s/iter; left time: 693.7420s
Epoch: 11 cost time: 8.010475397109985
Epoch: 11, Steps: 265 Train Loss: 3.2196 (Forecasting Loss:0.2084 + XiCon Loss:3.0111 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.1643236
	speed: 0.0319s/iter; left time: 748.0361s
	iters: 200, epoch: 12 | loss: 3.2102284
	speed: 0.0304s/iter; left time: 710.4638s
Epoch: 12 cost time: 8.25158166885376
Epoch: 12, Steps: 265 Train Loss: 3.2193 (Forecasting Loss:0.2084 + XiCon Loss:3.0108 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1688
Validation loss decreased (0.212711 --> 0.212554).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.1975324
	speed: 0.0320s/iter; left time: 743.2674s
	iters: 200, epoch: 13 | loss: 3.2478178
	speed: 0.0294s/iter; left time: 680.2694s
Epoch: 13 cost time: 8.012863636016846
Epoch: 13, Steps: 265 Train Loss: 3.2198 (Forecasting Loss:0.2085 + XiCon Loss:3.0113 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1688
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1764767
	speed: 0.0322s/iter; left time: 739.2510s
	iters: 200, epoch: 14 | loss: 3.1841717
	speed: 0.0294s/iter; left time: 672.7001s
Epoch: 14 cost time: 8.15476679801941
Epoch: 14, Steps: 265 Train Loss: 3.2196 (Forecasting Loss:0.2084 + XiCon Loss:3.0112 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2086420
	speed: 0.0319s/iter; left time: 723.9023s
	iters: 200, epoch: 15 | loss: 3.2459128
	speed: 0.0308s/iter; left time: 694.9582s
Epoch: 15 cost time: 8.400620698928833
Epoch: 15, Steps: 265 Train Loss: 3.2209 (Forecasting Loss:0.2085 + XiCon Loss:3.0124 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1688
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2156954
	speed: 0.0317s/iter; left time: 711.7614s
	iters: 200, epoch: 16 | loss: 3.2285073
	speed: 0.0294s/iter; left time: 655.4196s
Epoch: 16 cost time: 8.071935892105103
Epoch: 16, Steps: 265 Train Loss: 3.2200 (Forecasting Loss:0.2084 + XiCon Loss:3.0116 x Lambda(1.0)), Vali MSE Loss: 0.2123 Test MSE Loss: 0.1688
Validation loss decreased (0.212554 --> 0.212264).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2001672
	speed: 0.0316s/iter; left time: 699.4886s
	iters: 200, epoch: 17 | loss: 3.2063091
	speed: 0.0299s/iter; left time: 659.7976s
Epoch: 17 cost time: 8.04954218864441
Epoch: 17, Steps: 265 Train Loss: 3.2211 (Forecasting Loss:0.2085 + XiCon Loss:3.0126 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1688
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.1875851
	speed: 0.0325s/iter; left time: 712.7104s
	iters: 200, epoch: 18 | loss: 3.2517540
	speed: 0.0294s/iter; left time: 640.8639s
Epoch: 18 cost time: 8.168445110321045
Epoch: 18, Steps: 265 Train Loss: 3.2196 (Forecasting Loss:0.2084 + XiCon Loss:3.0112 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1688
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.2289686
	speed: 0.0321s/iter; left time: 694.9000s
	iters: 200, epoch: 19 | loss: 3.2214668
	speed: 0.0300s/iter; left time: 645.6637s
Epoch: 19 cost time: 8.153352737426758
Epoch: 19, Steps: 265 Train Loss: 3.2229 (Forecasting Loss:0.2084 + XiCon Loss:3.0145 x Lambda(1.0)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1688
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2456591
	speed: 0.0318s/iter; left time: 679.0515s
	iters: 200, epoch: 20 | loss: 3.2115552
	speed: 0.0305s/iter; left time: 648.3853s
Epoch: 20 cost time: 8.258149147033691
Epoch: 20, Steps: 265 Train Loss: 3.2200 (Forecasting Loss:0.2083 + XiCon Loss:3.0117 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1688
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2039566
	speed: 0.0320s/iter; left time: 674.3321s
	iters: 200, epoch: 21 | loss: 3.2211502
	speed: 0.0296s/iter; left time: 622.2331s
Epoch: 21 cost time: 8.167248964309692
Epoch: 21, Steps: 265 Train Loss: 3.2202 (Forecasting Loss:0.2085 + XiCon Loss:3.0118 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1688
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2456524
	speed: 0.0315s/iter; left time: 657.0948s
	iters: 200, epoch: 22 | loss: 3.1887782
	speed: 0.0295s/iter; left time: 611.9206s
Epoch: 22 cost time: 8.017683029174805
Epoch: 22, Steps: 265 Train Loss: 3.2207 (Forecasting Loss:0.2084 + XiCon Loss:3.0123 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1688
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.1897693
	speed: 0.0319s/iter; left time: 656.9064s
	iters: 200, epoch: 23 | loss: 3.1711507
	speed: 0.0295s/iter; left time: 604.6475s
Epoch: 23 cost time: 8.060990333557129
Epoch: 23, Steps: 265 Train Loss: 3.2206 (Forecasting Loss:0.2084 + XiCon Loss:3.0122 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1688
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 3.2302046
	speed: 0.0314s/iter; left time: 636.6205s
	iters: 200, epoch: 24 | loss: 3.1821871
	speed: 0.0297s/iter; left time: 600.2396s
Epoch: 24 cost time: 8.073797225952148
Epoch: 24, Steps: 265 Train Loss: 3.2223 (Forecasting Loss:0.2085 + XiCon Loss:3.0138 x Lambda(1.0)), Vali MSE Loss: 0.2126 Test MSE Loss: 0.1688
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 3.2190161
	speed: 0.0325s/iter; left time: 651.8101s
	iters: 200, epoch: 25 | loss: 3.2449973
	speed: 0.0312s/iter; left time: 621.6576s
Epoch: 25 cost time: 8.434415817260742
Epoch: 25, Steps: 265 Train Loss: 3.2202 (Forecasting Loss:0.2084 + XiCon Loss:3.0118 x Lambda(1.0)), Vali MSE Loss: 0.2127 Test MSE Loss: 0.1688
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 3.2021224
	speed: 0.0322s/iter; left time: 636.7600s
	iters: 200, epoch: 26 | loss: 3.2211518
	speed: 0.0295s/iter; left time: 580.3079s
Epoch: 26 cost time: 8.070128440856934
Epoch: 26, Steps: 265 Train Loss: 3.2208 (Forecasting Loss:0.2085 + XiCon Loss:3.0123 x Lambda(1.0)), Vali MSE Loss: 0.2130 Test MSE Loss: 0.1688
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09906727075576782, mae:0.23860874772071838, mape:0.5703787803649902, mspe:11.923086166381836 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9232
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.6115084
	speed: 0.0329s/iter; left time: 868.1662s
	iters: 200, epoch: 1 | loss: 3.5669310
	speed: 0.0291s/iter; left time: 765.0531s
Epoch: 1 cost time: 8.127630710601807
Epoch: 1, Steps: 265 Train Loss: 3.5912 (Forecasting Loss:0.3611 + XiCon Loss:3.2300 x Lambda(1.0)), Vali MSE Loss: 0.3315 Test MSE Loss: 0.2837
Validation loss decreased (inf --> 0.331493).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.4133246
	speed: 0.0318s/iter; left time: 830.2161s
	iters: 200, epoch: 2 | loss: 3.2915125
	speed: 0.0308s/iter; left time: 802.9479s
Epoch: 2 cost time: 8.309895277023315
Epoch: 2, Steps: 265 Train Loss: 3.3797 (Forecasting Loss:0.2384 + XiCon Loss:3.1413 x Lambda(1.0)), Vali MSE Loss: 0.2221 Test MSE Loss: 0.1732
Validation loss decreased (0.331493 --> 0.222069).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.1891339
	speed: 0.0316s/iter; left time: 817.2530s
	iters: 200, epoch: 3 | loss: 3.2598629
	speed: 0.0286s/iter; left time: 737.8369s
Epoch: 3 cost time: 8.017638921737671
Epoch: 3, Steps: 265 Train Loss: 3.2463 (Forecasting Loss:0.2124 + XiCon Loss:3.0338 x Lambda(1.0)), Vali MSE Loss: 0.2142 Test MSE Loss: 0.1699
Validation loss decreased (0.222069 --> 0.214178).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2118249
	speed: 0.0311s/iter; left time: 795.9097s
	iters: 200, epoch: 4 | loss: 3.1624219
	speed: 0.0295s/iter; left time: 752.9441s
Epoch: 4 cost time: 7.9755470752716064
Epoch: 4, Steps: 265 Train Loss: 3.2168 (Forecasting Loss:0.2100 + XiCon Loss:3.0068 x Lambda(1.0)), Vali MSE Loss: 0.2120 Test MSE Loss: 0.1686
Validation loss decreased (0.214178 --> 0.212014).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2114775
	speed: 0.0317s/iter; left time: 802.8637s
	iters: 200, epoch: 5 | loss: 3.2114797
	speed: 0.0292s/iter; left time: 737.3563s
Epoch: 5 cost time: 8.01645040512085
Epoch: 5, Steps: 265 Train Loss: 3.2092 (Forecasting Loss:0.2089 + XiCon Loss:3.0004 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1682
Validation loss decreased (0.212014 --> 0.210861).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.1782229
	speed: 0.0318s/iter; left time: 798.1237s
	iters: 200, epoch: 6 | loss: 3.2105200
	speed: 0.0296s/iter; left time: 739.5247s
Epoch: 6 cost time: 8.069000244140625
Epoch: 6, Steps: 265 Train Loss: 3.2051 (Forecasting Loss:0.2081 + XiCon Loss:2.9969 x Lambda(1.0)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1685
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2003696
	speed: 0.0314s/iter; left time: 780.1355s
	iters: 200, epoch: 7 | loss: 3.2312858
	speed: 0.0304s/iter; left time: 751.6526s
Epoch: 7 cost time: 8.218276739120483
Epoch: 7, Steps: 265 Train Loss: 3.2034 (Forecasting Loss:0.2078 + XiCon Loss:2.9956 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1684
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1833363
	speed: 0.0320s/iter; left time: 786.4205s
	iters: 200, epoch: 8 | loss: 3.1934254
	speed: 0.0302s/iter; left time: 739.4110s
Epoch: 8 cost time: 8.149246215820312
Epoch: 8, Steps: 265 Train Loss: 3.2028 (Forecasting Loss:0.2079 + XiCon Loss:2.9949 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2008388
	speed: 0.0324s/iter; left time: 786.5036s
	iters: 200, epoch: 9 | loss: 3.2096014
	speed: 0.0301s/iter; left time: 727.8642s
Epoch: 9 cost time: 8.240406513214111
Epoch: 9, Steps: 265 Train Loss: 3.2030 (Forecasting Loss:0.2076 + XiCon Loss:2.9953 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1684
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2079716
	speed: 0.0318s/iter; left time: 763.7423s
	iters: 200, epoch: 10 | loss: 3.1848950
	speed: 0.0300s/iter; left time: 717.3969s
Epoch: 10 cost time: 8.175282955169678
Epoch: 10, Steps: 265 Train Loss: 3.2034 (Forecasting Loss:0.2076 + XiCon Loss:2.9958 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1797738
	speed: 0.0315s/iter; left time: 748.5749s
	iters: 200, epoch: 11 | loss: 3.2073576
	speed: 0.0294s/iter; left time: 696.3738s
Epoch: 11 cost time: 8.042179346084595
Epoch: 11, Steps: 265 Train Loss: 3.2020 (Forecasting Loss:0.2076 + XiCon Loss:2.9944 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2163246
	speed: 0.0325s/iter; left time: 763.8284s
	iters: 200, epoch: 12 | loss: 3.2385731
	speed: 0.0313s/iter; left time: 731.5973s
Epoch: 12 cost time: 8.443676471710205
Epoch: 12, Steps: 265 Train Loss: 3.2041 (Forecasting Loss:0.2077 + XiCon Loss:2.9964 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2573600
	speed: 0.0316s/iter; left time: 734.6492s
	iters: 200, epoch: 13 | loss: 3.2186570
	speed: 0.0293s/iter; left time: 677.5167s
Epoch: 13 cost time: 7.9873366355896
Epoch: 13, Steps: 265 Train Loss: 3.2009 (Forecasting Loss:0.2077 + XiCon Loss:2.9933 x Lambda(1.0)), Vali MSE Loss: 0.2110 Test MSE Loss: 0.1683
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1801054
	speed: 0.0318s/iter; left time: 729.7520s
	iters: 200, epoch: 14 | loss: 3.1864369
	speed: 0.0288s/iter; left time: 658.8217s
Epoch: 14 cost time: 8.054682493209839
Epoch: 14, Steps: 265 Train Loss: 3.2012 (Forecasting Loss:0.2075 + XiCon Loss:2.9938 x Lambda(1.0)), Vali MSE Loss: 0.2109 Test MSE Loss: 0.1683
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2214937
	speed: 0.0319s/iter; left time: 723.7173s
	iters: 200, epoch: 15 | loss: 3.1939862
	speed: 0.0303s/iter; left time: 684.1714s
Epoch: 15 cost time: 8.131135940551758
Epoch: 15, Steps: 265 Train Loss: 3.1998 (Forecasting Loss:0.2075 + XiCon Loss:2.9923 x Lambda(1.0)), Vali MSE Loss: 0.2111 Test MSE Loss: 0.1683
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.09855090081691742, mae:0.2379262000322342, mape:0.5730289816856384, mspe:11.808350563049316 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:137921
train 34033
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9214
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 34033
val 11329
test 11329
	iters: 100, epoch: 1 | loss: 3.6216247
	speed: 0.0346s/iter; left time: 912.3554s
	iters: 200, epoch: 1 | loss: 3.5374584
	speed: 0.0317s/iter; left time: 832.9400s
Epoch: 1 cost time: 8.68988823890686
Epoch: 1, Steps: 265 Train Loss: 3.5726 (Forecasting Loss:0.3534 + XiCon Loss:3.2192 x Lambda(1.0)), Vali MSE Loss: 0.3383 Test MSE Loss: 0.2800
Validation loss decreased (inf --> 0.338274).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 3.3977528
	speed: 0.0329s/iter; left time: 859.2954s
	iters: 200, epoch: 2 | loss: 3.3102529
	speed: 0.0295s/iter; left time: 767.6649s
Epoch: 2 cost time: 8.113804578781128
Epoch: 2, Steps: 265 Train Loss: 3.4123 (Forecasting Loss:0.2418 + XiCon Loss:3.1705 x Lambda(1.0)), Vali MSE Loss: 0.2198 Test MSE Loss: 0.1732
Validation loss decreased (0.338274 --> 0.219839).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 3.3014712
	speed: 0.0315s/iter; left time: 815.6684s
	iters: 200, epoch: 3 | loss: 3.1909497
	speed: 0.0305s/iter; left time: 785.7681s
Epoch: 3 cost time: 8.185785055160522
Epoch: 3, Steps: 265 Train Loss: 3.2727 (Forecasting Loss:0.2145 + XiCon Loss:3.0582 x Lambda(1.0)), Vali MSE Loss: 0.2150 Test MSE Loss: 0.1696
Validation loss decreased (0.219839 --> 0.214983).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 3.2431471
	speed: 0.0323s/iter; left time: 828.2939s
	iters: 200, epoch: 4 | loss: 3.2020547
	speed: 0.0300s/iter; left time: 764.0159s
Epoch: 4 cost time: 8.195472240447998
Epoch: 4, Steps: 265 Train Loss: 3.2376 (Forecasting Loss:0.2111 + XiCon Loss:3.0265 x Lambda(1.0)), Vali MSE Loss: 0.2125 Test MSE Loss: 0.1685
Validation loss decreased (0.214983 --> 0.212493).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 3.2159967
	speed: 0.0325s/iter; left time: 822.5946s
	iters: 200, epoch: 5 | loss: 3.2564824
	speed: 0.0295s/iter; left time: 743.9859s
Epoch: 5 cost time: 8.119240760803223
Epoch: 5, Steps: 265 Train Loss: 3.2280 (Forecasting Loss:0.2097 + XiCon Loss:3.0183 x Lambda(1.0)), Vali MSE Loss: 0.2114 Test MSE Loss: 0.1681
Validation loss decreased (0.212493 --> 0.211379).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 3.2211504
	speed: 0.0324s/iter; left time: 813.2892s
	iters: 200, epoch: 6 | loss: 3.2277837
	speed: 0.0292s/iter; left time: 729.5351s
Epoch: 6 cost time: 8.10239863395691
Epoch: 6, Steps: 265 Train Loss: 3.2243 (Forecasting Loss:0.2090 + XiCon Loss:3.0154 x Lambda(1.0)), Vali MSE Loss: 0.2112 Test MSE Loss: 0.1679
Validation loss decreased (0.211379 --> 0.211174).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 3.2297430
	speed: 0.0313s/iter; left time: 775.9936s
	iters: 200, epoch: 7 | loss: 3.2083490
	speed: 0.0298s/iter; left time: 737.6122s
Epoch: 7 cost time: 8.10309386253357
Epoch: 7, Steps: 265 Train Loss: 3.2228 (Forecasting Loss:0.2086 + XiCon Loss:3.0143 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1678
Validation loss decreased (0.211174 --> 0.210819).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 3.1939211
	speed: 0.0313s/iter; left time: 769.3751s
	iters: 200, epoch: 8 | loss: 3.2254815
	speed: 0.0300s/iter; left time: 733.7494s
Epoch: 8 cost time: 8.108154058456421
Epoch: 8, Steps: 265 Train Loss: 3.2184 (Forecasting Loss:0.2085 + XiCon Loss:3.0099 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
Validation loss decreased (0.210819 --> 0.210708).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 3.2078915
	speed: 0.0323s/iter; left time: 783.8161s
	iters: 200, epoch: 9 | loss: 3.2434039
	speed: 0.0303s/iter; left time: 733.7619s
Epoch: 9 cost time: 8.308769941329956
Epoch: 9, Steps: 265 Train Loss: 3.2185 (Forecasting Loss:0.2084 + XiCon Loss:3.0102 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1678
Validation loss decreased (0.210708 --> 0.210542).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 3.2111905
	speed: 0.0315s/iter; left time: 755.9712s
	iters: 200, epoch: 10 | loss: 3.2333956
	speed: 0.0301s/iter; left time: 720.5811s
Epoch: 10 cost time: 8.184587001800537
Epoch: 10, Steps: 265 Train Loss: 3.2185 (Forecasting Loss:0.2084 + XiCon Loss:3.0101 x Lambda(1.0)), Vali MSE Loss: 0.2108 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 3.1641378
	speed: 0.0321s/iter; left time: 762.2612s
	iters: 200, epoch: 11 | loss: 3.2016797
	speed: 0.0288s/iter; left time: 680.8815s
Epoch: 11 cost time: 7.994698762893677
Epoch: 11, Steps: 265 Train Loss: 3.2181 (Forecasting Loss:0.2083 + XiCon Loss:3.0098 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1678
Validation loss decreased (0.210542 --> 0.210406).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 3.2369041
	speed: 0.0326s/iter; left time: 765.7152s
	iters: 200, epoch: 12 | loss: 3.1962726
	speed: 0.0299s/iter; left time: 698.1635s
Epoch: 12 cost time: 8.183327913284302
Epoch: 12, Steps: 265 Train Loss: 3.2166 (Forecasting Loss:0.2083 + XiCon Loss:3.0083 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 3.2341173
	speed: 0.0312s/iter; left time: 725.4136s
	iters: 200, epoch: 13 | loss: 3.2641835
	speed: 0.0303s/iter; left time: 699.8310s
Epoch: 13 cost time: 8.155189514160156
Epoch: 13, Steps: 265 Train Loss: 3.2194 (Forecasting Loss:0.2083 + XiCon Loss:3.0110 x Lambda(1.0)), Vali MSE Loss: 0.2100 Test MSE Loss: 0.1678
Validation loss decreased (0.210406 --> 0.210018).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 3.1984265
	speed: 0.0319s/iter; left time: 733.4150s
	iters: 200, epoch: 14 | loss: 3.1750162
	speed: 0.0296s/iter; left time: 677.3541s
Epoch: 14 cost time: 8.103723049163818
Epoch: 14, Steps: 265 Train Loss: 3.2170 (Forecasting Loss:0.2082 + XiCon Loss:3.0087 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 3.2279482
	speed: 0.0319s/iter; left time: 723.5175s
	iters: 200, epoch: 15 | loss: 3.2050493
	speed: 0.0317s/iter; left time: 716.1379s
Epoch: 15 cost time: 8.444897890090942
Epoch: 15, Steps: 265 Train Loss: 3.2173 (Forecasting Loss:0.2084 + XiCon Loss:3.0090 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1678
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 3.2283037
	speed: 0.0326s/iter; left time: 730.2894s
	iters: 200, epoch: 16 | loss: 3.2311969
	speed: 0.0302s/iter; left time: 674.3417s
Epoch: 16 cost time: 8.278335809707642
Epoch: 16, Steps: 265 Train Loss: 3.2174 (Forecasting Loss:0.2083 + XiCon Loss:3.0090 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 3.2091236
	speed: 0.0315s/iter; left time: 697.5175s
	iters: 200, epoch: 17 | loss: 3.2300398
	speed: 0.0302s/iter; left time: 665.3147s
Epoch: 17 cost time: 8.16864562034607
Epoch: 17, Steps: 265 Train Loss: 3.2181 (Forecasting Loss:0.2082 + XiCon Loss:3.0099 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 3.2366128
	speed: 0.0318s/iter; left time: 697.2338s
	iters: 200, epoch: 18 | loss: 3.1918821
	speed: 0.0302s/iter; left time: 659.0493s
Epoch: 18 cost time: 8.257804870605469
Epoch: 18, Steps: 265 Train Loss: 3.2215 (Forecasting Loss:0.2082 + XiCon Loss:3.0133 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 3.1922073
	speed: 0.0321s/iter; left time: 693.4335s
	iters: 200, epoch: 19 | loss: 3.2341740
	speed: 0.0294s/iter; left time: 632.4315s
Epoch: 19 cost time: 8.122969627380371
Epoch: 19, Steps: 265 Train Loss: 3.2171 (Forecasting Loss:0.2083 + XiCon Loss:3.0088 x Lambda(1.0)), Vali MSE Loss: 0.2106 Test MSE Loss: 0.1678
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 3.2303066
	speed: 0.0325s/iter; left time: 694.6362s
	iters: 200, epoch: 20 | loss: 3.2052665
	speed: 0.0304s/iter; left time: 646.3405s
Epoch: 20 cost time: 8.31810450553894
Epoch: 20, Steps: 265 Train Loss: 3.2189 (Forecasting Loss:0.2083 + XiCon Loss:3.0107 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1678
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 3.2521939
	speed: 0.0315s/iter; left time: 664.4531s
	iters: 200, epoch: 21 | loss: 3.2085903
	speed: 0.0301s/iter; left time: 632.6612s
Epoch: 21 cost time: 8.114105939865112
Epoch: 21, Steps: 265 Train Loss: 3.2193 (Forecasting Loss:0.2083 + XiCon Loss:3.0110 x Lambda(1.0)), Vali MSE Loss: 0.2107 Test MSE Loss: 0.1678
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 3.2136140
	speed: 0.0329s/iter; left time: 685.7809s
	iters: 200, epoch: 22 | loss: 3.2137120
	speed: 0.0303s/iter; left time: 629.0005s
Epoch: 22 cost time: 8.249905586242676
Epoch: 22, Steps: 265 Train Loss: 3.2187 (Forecasting Loss:0.2083 + XiCon Loss:3.0103 x Lambda(1.0)), Vali MSE Loss: 0.2104 Test MSE Loss: 0.1678
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 3.2429318
	speed: 0.0315s/iter; left time: 647.6602s
	iters: 200, epoch: 23 | loss: 3.1749849
	speed: 0.0296s/iter; left time: 605.9060s
Epoch: 23 cost time: 8.072236061096191
Epoch: 23, Steps: 265 Train Loss: 3.2187 (Forecasting Loss:0.2082 + XiCon Loss:3.0105 x Lambda(1.0)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1678
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl192_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11329
test shape: (88, 128, 192, 1) (88, 128, 192, 1)
test shape: (11264, 192, 1) (11264, 192, 1)
mse:0.0979059487581253, mae:0.23760806024074554, mape:0.5653942227363586, mspe:11.781198501586914 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0983+-0.00100, MAE:0.2381+-0.00121, MAPE:0.5693+-0.00344, MSPE:11.8814+-0.17143, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=336, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.1558
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5863249
	speed: 0.0396s/iter; left time: 1040.8690s
	iters: 200, epoch: 1 | loss: 3.4945788
	speed: 0.0342s/iter; left time: 895.2751s
Epoch: 1 cost time: 9.579460620880127
Epoch: 1, Steps: 264 Train Loss: 3.5458 (Forecasting Loss:0.3356 + XiCon Loss:3.2102 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2336
Validation loss decreased (inf --> 0.296760).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2074256
	speed: 0.0346s/iter; left time: 901.9125s
	iters: 200, epoch: 2 | loss: 3.2170994
	speed: 0.0319s/iter; left time: 827.1326s
Epoch: 2 cost time: 8.77585768699646
Epoch: 2, Steps: 264 Train Loss: 3.2803 (Forecasting Loss:0.2522 + XiCon Loss:3.0281 x Lambda(1.0)), Vali MSE Loss: 0.2515 Test MSE Loss: 0.1955
Validation loss decreased (0.296760 --> 0.251519).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2046876
	speed: 0.0340s/iter; left time: 875.4567s
	iters: 200, epoch: 3 | loss: 3.1744049
	speed: 0.0322s/iter; left time: 827.5827s
Epoch: 3 cost time: 8.678377628326416
Epoch: 3, Steps: 264 Train Loss: 3.2170 (Forecasting Loss:0.2435 + XiCon Loss:2.9735 x Lambda(1.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1924
Validation loss decreased (0.251519 --> 0.247614).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.2866030
	speed: 0.0344s/iter; left time: 877.2461s
	iters: 200, epoch: 4 | loss: 3.3797891
	speed: 0.0328s/iter; left time: 834.0870s
Epoch: 4 cost time: 8.82811975479126
Epoch: 4, Steps: 264 Train Loss: 3.3309 (Forecasting Loss:0.2439 + XiCon Loss:3.0870 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1926
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3752813
	speed: 0.0348s/iter; left time: 879.1248s
	iters: 200, epoch: 5 | loss: 3.4249144
	speed: 0.0329s/iter; left time: 826.1141s
Epoch: 5 cost time: 8.882740020751953
Epoch: 5, Steps: 264 Train Loss: 3.3588 (Forecasting Loss:0.2432 + XiCon Loss:3.1157 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1920
Validation loss decreased (0.247614 --> 0.245652).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3758066
	speed: 0.0341s/iter; left time: 853.0085s
	iters: 200, epoch: 6 | loss: 3.4187050
	speed: 0.0321s/iter; left time: 798.0867s
Epoch: 6 cost time: 8.671396970748901
Epoch: 6, Steps: 264 Train Loss: 3.3628 (Forecasting Loss:0.2428 + XiCon Loss:3.1200 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1917
Validation loss decreased (0.245652 --> 0.245538).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3321052
	speed: 0.0341s/iter; left time: 843.6234s
	iters: 200, epoch: 7 | loss: 3.3553236
	speed: 0.0312s/iter; left time: 768.0324s
Epoch: 7 cost time: 8.631347179412842
Epoch: 7, Steps: 264 Train Loss: 3.3668 (Forecasting Loss:0.2424 + XiCon Loss:3.1245 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1917
Validation loss decreased (0.245538 --> 0.245313).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3657134
	speed: 0.0350s/iter; left time: 856.1744s
	iters: 200, epoch: 8 | loss: 3.2770317
	speed: 0.0321s/iter; left time: 780.7402s
Epoch: 8 cost time: 8.81559157371521
Epoch: 8, Steps: 264 Train Loss: 3.3675 (Forecasting Loss:0.2424 + XiCon Loss:3.1251 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1917
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3921480
	speed: 0.0345s/iter; left time: 834.2947s
	iters: 200, epoch: 9 | loss: 3.4931872
	speed: 0.0326s/iter; left time: 784.8934s
Epoch: 9 cost time: 8.781646966934204
Epoch: 9, Steps: 264 Train Loss: 3.3653 (Forecasting Loss:0.2421 + XiCon Loss:3.1231 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1917
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3991010
	speed: 0.0337s/iter; left time: 805.5664s
	iters: 200, epoch: 10 | loss: 3.2940323
	speed: 0.0320s/iter; left time: 762.4239s
Epoch: 10 cost time: 8.666072368621826
Epoch: 10, Steps: 264 Train Loss: 3.3590 (Forecasting Loss:0.2422 + XiCon Loss:3.1167 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1917
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3136168
	speed: 0.0339s/iter; left time: 801.8000s
	iters: 200, epoch: 11 | loss: 3.3156357
	speed: 0.0331s/iter; left time: 779.6443s
Epoch: 11 cost time: 8.784945011138916
Epoch: 11, Steps: 264 Train Loss: 3.3626 (Forecasting Loss:0.2424 + XiCon Loss:3.1203 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1917
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5010507
	speed: 0.0342s/iter; left time: 801.1938s
	iters: 200, epoch: 12 | loss: 3.3550465
	speed: 0.0322s/iter; left time: 750.3072s
Epoch: 12 cost time: 8.72367811203003
Epoch: 12, Steps: 264 Train Loss: 3.3611 (Forecasting Loss:0.2421 + XiCon Loss:3.1190 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1917
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4063041
	speed: 0.0343s/iter; left time: 792.7754s
	iters: 200, epoch: 13 | loss: 3.4148345
	speed: 0.0321s/iter; left time: 738.8751s
Epoch: 13 cost time: 8.65857481956482
Epoch: 13, Steps: 264 Train Loss: 3.3629 (Forecasting Loss:0.2419 + XiCon Loss:3.1209 x Lambda(1.0)), Vali MSE Loss: 0.2458 Test MSE Loss: 0.1917
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4689538
	speed: 0.0333s/iter; left time: 761.8724s
	iters: 200, epoch: 14 | loss: 3.3181083
	speed: 0.0323s/iter; left time: 734.9620s
Epoch: 14 cost time: 8.645638704299927
Epoch: 14, Steps: 264 Train Loss: 3.3638 (Forecasting Loss:0.2420 + XiCon Loss:3.1218 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1917
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.3668318
	speed: 0.0341s/iter; left time: 770.7225s
	iters: 200, epoch: 15 | loss: 3.2793655
	speed: 0.0325s/iter; left time: 731.2489s
Epoch: 15 cost time: 8.71593451499939
Epoch: 15, Steps: 264 Train Loss: 3.3606 (Forecasting Loss:0.2422 + XiCon Loss:3.1184 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1917
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3945062
	speed: 0.0347s/iter; left time: 774.5412s
	iters: 200, epoch: 16 | loss: 3.3575208
	speed: 0.0329s/iter; left time: 732.5373s
Epoch: 16 cost time: 8.874649286270142
Epoch: 16, Steps: 264 Train Loss: 3.3646 (Forecasting Loss:0.2423 + XiCon Loss:3.1224 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1917
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.3655384
	speed: 0.0351s/iter; left time: 774.0557s
	iters: 200, epoch: 17 | loss: 3.4279022
	speed: 0.0325s/iter; left time: 714.0450s
Epoch: 17 cost time: 8.903487920761108
Epoch: 17, Steps: 264 Train Loss: 3.3712 (Forecasting Loss:0.2422 + XiCon Loss:3.1290 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1917
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.11992403119802475, mae:0.2635476887226105, mape:0.6355918645858765, mspe:14.62488842010498 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.9638
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.6243935
	speed: 0.0364s/iter; left time: 957.6629s
	iters: 200, epoch: 1 | loss: 3.5323219
	speed: 0.0327s/iter; left time: 857.5764s
Epoch: 1 cost time: 8.963198184967041
Epoch: 1, Steps: 264 Train Loss: 3.5595 (Forecasting Loss:0.3346 + XiCon Loss:3.2249 x Lambda(1.0)), Vali MSE Loss: 0.2940 Test MSE Loss: 0.2320
Validation loss decreased (inf --> 0.293987).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2482624
	speed: 0.0337s/iter; left time: 876.3801s
	iters: 200, epoch: 2 | loss: 3.2457087
	speed: 0.0353s/iter; left time: 916.2621s
Epoch: 2 cost time: 9.280906677246094
Epoch: 2, Steps: 264 Train Loss: 3.3084 (Forecasting Loss:0.2526 + XiCon Loss:3.0559 x Lambda(1.0)), Vali MSE Loss: 0.2526 Test MSE Loss: 0.1963
Validation loss decreased (0.293987 --> 0.252561).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3671217
	speed: 0.0380s/iter; left time: 979.2488s
	iters: 200, epoch: 3 | loss: 3.4766142
	speed: 0.0354s/iter; left time: 909.7314s
Epoch: 3 cost time: 9.637539625167847
Epoch: 3, Steps: 264 Train Loss: 3.3812 (Forecasting Loss:0.2442 + XiCon Loss:3.1370 x Lambda(1.0)), Vali MSE Loss: 0.2487 Test MSE Loss: 0.1951
Validation loss decreased (0.252561 --> 0.248731).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.5231271
	speed: 0.0375s/iter; left time: 957.5081s
	iters: 200, epoch: 4 | loss: 3.4997077
	speed: 0.0359s/iter; left time: 912.9547s
Epoch: 4 cost time: 9.587890148162842
Epoch: 4, Steps: 264 Train Loss: 3.4247 (Forecasting Loss:0.2426 + XiCon Loss:3.1822 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.1941
Validation loss decreased (0.248731 --> 0.247976).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4821527
	speed: 0.0376s/iter; left time: 949.7784s
	iters: 200, epoch: 5 | loss: 3.3720560
	speed: 0.0352s/iter; left time: 884.5991s
Epoch: 5 cost time: 9.56304931640625
Epoch: 5, Steps: 264 Train Loss: 3.4386 (Forecasting Loss:0.2416 + XiCon Loss:3.1971 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1936
Validation loss decreased (0.247976 --> 0.247668).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3714733
	speed: 0.0375s/iter; left time: 936.1893s
	iters: 200, epoch: 6 | loss: 3.4098215
	speed: 0.0356s/iter; left time: 886.6118s
Epoch: 6 cost time: 9.534260034561157
Epoch: 6, Steps: 264 Train Loss: 3.4493 (Forecasting Loss:0.2411 + XiCon Loss:3.2083 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1937
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4380047
	speed: 0.0376s/iter; left time: 928.9740s
	iters: 200, epoch: 7 | loss: 3.4317620
	speed: 0.0345s/iter; left time: 850.3742s
Epoch: 7 cost time: 9.565980195999146
Epoch: 7, Steps: 264 Train Loss: 3.4427 (Forecasting Loss:0.2410 + XiCon Loss:3.2018 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1939
Validation loss decreased (0.247668 --> 0.247396).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3878446
	speed: 0.0370s/iter; left time: 905.9363s
	iters: 200, epoch: 8 | loss: 3.5692935
	speed: 0.0345s/iter; left time: 840.8631s
Epoch: 8 cost time: 9.397720575332642
Epoch: 8, Steps: 264 Train Loss: 3.4433 (Forecasting Loss:0.2407 + XiCon Loss:3.2026 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1939
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4670856
	speed: 0.0375s/iter; left time: 906.3452s
	iters: 200, epoch: 9 | loss: 3.3907514
	speed: 0.0356s/iter; left time: 857.8721s
Epoch: 9 cost time: 9.606279611587524
Epoch: 9, Steps: 264 Train Loss: 3.4464 (Forecasting Loss:0.2407 + XiCon Loss:3.2057 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4913874
	speed: 0.0376s/iter; left time: 900.0616s
	iters: 200, epoch: 10 | loss: 3.4577026
	speed: 0.0354s/iter; left time: 843.1206s
Epoch: 10 cost time: 9.581207990646362
Epoch: 10, Steps: 264 Train Loss: 3.4454 (Forecasting Loss:0.2409 + XiCon Loss:3.2045 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3820822
	speed: 0.0376s/iter; left time: 888.9379s
	iters: 200, epoch: 11 | loss: 3.4375451
	speed: 0.0356s/iter; left time: 838.1822s
Epoch: 11 cost time: 9.62570309638977
Epoch: 11, Steps: 264 Train Loss: 3.4460 (Forecasting Loss:0.2406 + XiCon Loss:3.2053 x Lambda(1.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1938
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3822277
	speed: 0.0379s/iter; left time: 886.2190s
	iters: 200, epoch: 12 | loss: 3.4809706
	speed: 0.0352s/iter; left time: 821.1666s
Epoch: 12 cost time: 9.52385663986206
Epoch: 12, Steps: 264 Train Loss: 3.4498 (Forecasting Loss:0.2406 + XiCon Loss:3.2092 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4039958
	speed: 0.0376s/iter; left time: 869.5120s
	iters: 200, epoch: 13 | loss: 3.4348571
	speed: 0.0354s/iter; left time: 814.5353s
Epoch: 13 cost time: 9.593393564224243
Epoch: 13, Steps: 264 Train Loss: 3.4493 (Forecasting Loss:0.2405 + XiCon Loss:3.2088 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
Validation loss decreased (0.247396 --> 0.247391).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.3764496
	speed: 0.0367s/iter; left time: 839.8548s
	iters: 200, epoch: 14 | loss: 3.4401200
	speed: 0.0354s/iter; left time: 806.4792s
Epoch: 14 cost time: 9.508965969085693
Epoch: 14, Steps: 264 Train Loss: 3.4470 (Forecasting Loss:0.2405 + XiCon Loss:3.2065 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4564066
	speed: 0.0381s/iter; left time: 861.5778s
	iters: 200, epoch: 15 | loss: 3.4892254
	speed: 0.0354s/iter; left time: 796.5020s
Epoch: 15 cost time: 9.575568914413452
Epoch: 15, Steps: 264 Train Loss: 3.4460 (Forecasting Loss:0.2405 + XiCon Loss:3.2055 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4636517
	speed: 0.0379s/iter; left time: 846.5722s
	iters: 200, epoch: 16 | loss: 3.4181440
	speed: 0.0343s/iter; left time: 763.7415s
Epoch: 16 cost time: 9.505417108535767
Epoch: 16, Steps: 264 Train Loss: 3.4442 (Forecasting Loss:0.2405 + XiCon Loss:3.2037 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.4304726
	speed: 0.0375s/iter; left time: 828.7210s
	iters: 200, epoch: 17 | loss: 3.5351706
	speed: 0.0357s/iter; left time: 783.7294s
Epoch: 17 cost time: 9.574517250061035
Epoch: 17, Steps: 264 Train Loss: 3.4443 (Forecasting Loss:0.2407 + XiCon Loss:3.2036 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.6216345
	speed: 0.0371s/iter; left time: 808.4385s
	iters: 200, epoch: 18 | loss: 3.3791578
	speed: 0.0351s/iter; left time: 762.5805s
Epoch: 18 cost time: 9.500899314880371
Epoch: 18, Steps: 264 Train Loss: 3.4474 (Forecasting Loss:0.2406 + XiCon Loss:3.2068 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4687243
	speed: 0.0376s/iter; left time: 810.7085s
	iters: 200, epoch: 19 | loss: 3.5038273
	speed: 0.0356s/iter; left time: 764.0215s
Epoch: 19 cost time: 9.645268201828003
Epoch: 19, Steps: 264 Train Loss: 3.4443 (Forecasting Loss:0.2406 + XiCon Loss:3.2036 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.4358275
	speed: 0.0379s/iter; left time: 807.5480s
	iters: 200, epoch: 20 | loss: 3.3153119
	speed: 0.0353s/iter; left time: 747.1671s
Epoch: 20 cost time: 9.571143865585327
Epoch: 20, Steps: 264 Train Loss: 3.4441 (Forecasting Loss:0.2406 + XiCon Loss:3.2035 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.5028818
	speed: 0.0374s/iter; left time: 786.0825s
	iters: 200, epoch: 21 | loss: 3.5024316
	speed: 0.0347s/iter; left time: 725.9978s
Epoch: 21 cost time: 9.520780563354492
Epoch: 21, Steps: 264 Train Loss: 3.4449 (Forecasting Loss:0.2406 + XiCon Loss:3.2043 x Lambda(1.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.1938
Validation loss decreased (0.247391 --> 0.247319).  Saving model ...
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.3708777
	speed: 0.0366s/iter; left time: 759.1384s
	iters: 200, epoch: 22 | loss: 3.3775761
	speed: 0.0352s/iter; left time: 727.7227s
Epoch: 22 cost time: 9.477419376373291
Epoch: 22, Steps: 264 Train Loss: 3.4443 (Forecasting Loss:0.2406 + XiCon Loss:3.2037 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.3621516
	speed: 0.0369s/iter; left time: 755.8947s
	iters: 200, epoch: 23 | loss: 3.3786490
	speed: 0.0355s/iter; left time: 724.5467s
Epoch: 23 cost time: 9.458616018295288
Epoch: 23, Steps: 264 Train Loss: 3.4513 (Forecasting Loss:0.2407 + XiCon Loss:3.2106 x Lambda(1.0)), Vali MSE Loss: 0.2471 Test MSE Loss: 0.1938
Validation loss decreased (0.247319 --> 0.247094).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.5035770
	speed: 0.0384s/iter; left time: 776.0687s
	iters: 200, epoch: 24 | loss: 3.4324610
	speed: 0.0364s/iter; left time: 732.8287s
Epoch: 24 cost time: 9.705485343933105
Epoch: 24, Steps: 264 Train Loss: 3.4520 (Forecasting Loss:0.2406 + XiCon Loss:3.2113 x Lambda(1.0)), Vali MSE Loss: 0.2477 Test MSE Loss: 0.1938
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.4387443
	speed: 0.0374s/iter; left time: 745.8704s
	iters: 200, epoch: 25 | loss: 3.4152009
	speed: 0.0354s/iter; left time: 703.0867s
Epoch: 25 cost time: 9.525471925735474
Epoch: 25, Steps: 264 Train Loss: 3.4426 (Forecasting Loss:0.2407 + XiCon Loss:3.2019 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.4384985
	speed: 0.0369s/iter; left time: 727.8997s
	iters: 200, epoch: 26 | loss: 3.3443389
	speed: 0.0352s/iter; left time: 690.4484s
Epoch: 26 cost time: 9.51780915260315
Epoch: 26, Steps: 264 Train Loss: 3.4414 (Forecasting Loss:0.2407 + XiCon Loss:3.2007 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.5578990
	speed: 0.0380s/iter; left time: 737.9152s
	iters: 200, epoch: 27 | loss: 3.4988220
	speed: 0.0352s/iter; left time: 681.1517s
Epoch: 27 cost time: 9.613792181015015
Epoch: 27, Steps: 264 Train Loss: 3.4448 (Forecasting Loss:0.2408 + XiCon Loss:3.2040 x Lambda(1.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1938
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.4527655
	speed: 0.0371s/iter; left time: 712.0819s
	iters: 200, epoch: 28 | loss: 3.4935822
	speed: 0.0355s/iter; left time: 677.5851s
Epoch: 28 cost time: 9.54029393196106
Epoch: 28, Steps: 264 Train Loss: 3.4457 (Forecasting Loss:0.2406 + XiCon Loss:3.2051 x Lambda(1.0)), Vali MSE Loss: 0.2473 Test MSE Loss: 0.1938
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
	iters: 100, epoch: 29 | loss: 3.4734755
	speed: 0.0375s/iter; left time: 709.3272s
	iters: 200, epoch: 29 | loss: 3.4330978
	speed: 0.0351s/iter; left time: 659.8711s
Epoch: 29 cost time: 9.59079909324646
Epoch: 29, Steps: 264 Train Loss: 3.4501 (Forecasting Loss:0.2405 + XiCon Loss:3.2096 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-12
	iters: 100, epoch: 30 | loss: 3.4901659
	speed: 0.0368s/iter; left time: 686.9641s
	iters: 200, epoch: 30 | loss: 3.4334693
	speed: 0.0351s/iter; left time: 650.4011s
Epoch: 30 cost time: 9.4845871925354
Epoch: 30, Steps: 264 Train Loss: 3.4474 (Forecasting Loss:0.2406 + XiCon Loss:3.2068 x Lambda(1.0)), Vali MSE Loss: 0.2476 Test MSE Loss: 0.1938
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-13
	iters: 100, epoch: 31 | loss: 3.4976275
	speed: 0.0376s/iter; left time: 691.5660s
	iters: 200, epoch: 31 | loss: 3.3873043
	speed: 0.0352s/iter; left time: 643.4650s
Epoch: 31 cost time: 9.489780187606812
Epoch: 31, Steps: 264 Train Loss: 3.4510 (Forecasting Loss:0.2407 + XiCon Loss:3.2104 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1938
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-13
	iters: 100, epoch: 32 | loss: 3.4210472
	speed: 0.0376s/iter; left time: 681.4382s
	iters: 200, epoch: 32 | loss: 3.3547926
	speed: 0.0346s/iter; left time: 624.1998s
Epoch: 32 cost time: 9.433500528335571
Epoch: 32, Steps: 264 Train Loss: 3.4426 (Forecasting Loss:0.2407 + XiCon Loss:3.2019 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-13
	iters: 100, epoch: 33 | loss: 3.4359112
	speed: 0.0379s/iter; left time: 676.1739s
	iters: 200, epoch: 33 | loss: 3.5413404
	speed: 0.0353s/iter; left time: 626.5405s
Epoch: 33 cost time: 9.555932521820068
Epoch: 33, Steps: 264 Train Loss: 3.4505 (Forecasting Loss:0.2406 + XiCon Loss:3.2099 x Lambda(1.0)), Vali MSE Loss: 0.2474 Test MSE Loss: 0.1938
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12210925668478012, mae:0.26541537046432495, mape:0.6189342141151428, mspe:13.79898738861084 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.5918
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5475712
	speed: 0.0363s/iter; left time: 954.7766s
	iters: 200, epoch: 1 | loss: 3.5127578
	speed: 0.0326s/iter; left time: 854.5898s
Epoch: 1 cost time: 8.98284649848938
Epoch: 1, Steps: 264 Train Loss: 3.5470 (Forecasting Loss:0.3340 + XiCon Loss:3.2130 x Lambda(1.0)), Vali MSE Loss: 0.2968 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.296849).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2648110
	speed: 0.0340s/iter; left time: 886.5328s
	iters: 200, epoch: 2 | loss: 3.2019587
	speed: 0.0322s/iter; left time: 835.8981s
Epoch: 2 cost time: 8.687972784042358
Epoch: 2, Steps: 264 Train Loss: 3.2822 (Forecasting Loss:0.2528 + XiCon Loss:3.0294 x Lambda(1.0)), Vali MSE Loss: 0.2468 Test MSE Loss: 0.1944
Validation loss decreased (0.296849 --> 0.246799).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2770514
	speed: 0.0340s/iter; left time: 877.0405s
	iters: 200, epoch: 3 | loss: 3.5081213
	speed: 0.0320s/iter; left time: 822.4481s
Epoch: 3 cost time: 8.67697787284851
Epoch: 3, Steps: 264 Train Loss: 3.3491 (Forecasting Loss:0.2446 + XiCon Loss:3.1045 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1926
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.2762146
	speed: 0.0347s/iter; left time: 883.9660s
	iters: 200, epoch: 4 | loss: 3.3601232
	speed: 0.0319s/iter; left time: 810.9315s
Epoch: 4 cost time: 8.80506181716919
Epoch: 4, Steps: 264 Train Loss: 3.3584 (Forecasting Loss:0.2437 + XiCon Loss:3.1147 x Lambda(1.0)), Vali MSE Loss: 0.2459 Test MSE Loss: 0.1913
Validation loss decreased (0.246799 --> 0.245889).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.2836044
	speed: 0.0345s/iter; left time: 871.8163s
	iters: 200, epoch: 5 | loss: 3.2174051
	speed: 0.0321s/iter; left time: 807.8393s
Epoch: 5 cost time: 8.710595607757568
Epoch: 5, Steps: 264 Train Loss: 3.3381 (Forecasting Loss:0.2434 + XiCon Loss:3.0948 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1907
Validation loss decreased (0.245889 --> 0.245395).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3752201
	speed: 0.0346s/iter; left time: 864.0129s
	iters: 200, epoch: 6 | loss: 3.3570206
	speed: 0.0319s/iter; left time: 794.1848s
Epoch: 6 cost time: 8.723259449005127
Epoch: 6, Steps: 264 Train Loss: 3.3347 (Forecasting Loss:0.2431 + XiCon Loss:3.0916 x Lambda(1.0)), Vali MSE Loss: 0.2452 Test MSE Loss: 0.1905
Validation loss decreased (0.245395 --> 0.245229).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.2870219
	speed: 0.0345s/iter; left time: 851.8816s
	iters: 200, epoch: 7 | loss: 3.3567533
	speed: 0.0320s/iter; left time: 788.9067s
Epoch: 7 cost time: 8.801891326904297
Epoch: 7, Steps: 264 Train Loss: 3.3400 (Forecasting Loss:0.2429 + XiCon Loss:3.0971 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1906
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3480911
	speed: 0.0351s/iter; left time: 859.2881s
	iters: 200, epoch: 8 | loss: 3.3317590
	speed: 0.0319s/iter; left time: 775.8378s
Epoch: 8 cost time: 8.79601240158081
Epoch: 8, Steps: 264 Train Loss: 3.3266 (Forecasting Loss:0.2426 + XiCon Loss:3.0840 x Lambda(1.0)), Vali MSE Loss: 0.2453 Test MSE Loss: 0.1905
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3637111
	speed: 0.0351s/iter; left time: 849.6955s
	iters: 200, epoch: 9 | loss: 3.3749156
	speed: 0.0324s/iter; left time: 780.1972s
Epoch: 9 cost time: 8.823396921157837
Epoch: 9, Steps: 264 Train Loss: 3.3275 (Forecasting Loss:0.2425 + XiCon Loss:3.0850 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1905
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3844378
	speed: 0.0343s/iter; left time: 820.8574s
	iters: 200, epoch: 10 | loss: 3.2946692
	speed: 0.0317s/iter; left time: 756.2801s
Epoch: 10 cost time: 8.711260318756104
Epoch: 10, Steps: 264 Train Loss: 3.3363 (Forecasting Loss:0.2426 + XiCon Loss:3.0936 x Lambda(1.0)), Vali MSE Loss: 0.2457 Test MSE Loss: 0.1905
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3084676
	speed: 0.0347s/iter; left time: 820.7393s
	iters: 200, epoch: 11 | loss: 3.2891548
	speed: 0.0328s/iter; left time: 772.7635s
Epoch: 11 cost time: 8.847188949584961
Epoch: 11, Steps: 264 Train Loss: 3.3321 (Forecasting Loss:0.2427 + XiCon Loss:3.0894 x Lambda(1.0)), Vali MSE Loss: 0.2454 Test MSE Loss: 0.1905
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3537915
	speed: 0.0349s/iter; left time: 816.0814s
	iters: 200, epoch: 12 | loss: 3.3602486
	speed: 0.0324s/iter; left time: 754.4019s
Epoch: 12 cost time: 8.791929960250854
Epoch: 12, Steps: 264 Train Loss: 3.3330 (Forecasting Loss:0.2426 + XiCon Loss:3.0904 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1905
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.2703044
	speed: 0.0347s/iter; left time: 801.8551s
	iters: 200, epoch: 13 | loss: 3.3229175
	speed: 0.0329s/iter; left time: 757.4685s
Epoch: 13 cost time: 8.87722373008728
Epoch: 13, Steps: 264 Train Loss: 3.3301 (Forecasting Loss:0.2426 + XiCon Loss:3.0875 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1905
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4227257
	speed: 0.0349s/iter; left time: 798.8862s
	iters: 200, epoch: 14 | loss: 3.3154187
	speed: 0.0328s/iter; left time: 746.0130s
Epoch: 14 cost time: 8.934343338012695
Epoch: 14, Steps: 264 Train Loss: 3.3336 (Forecasting Loss:0.2427 + XiCon Loss:3.0909 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1905
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.2451873
	speed: 0.0348s/iter; left time: 786.8278s
	iters: 200, epoch: 15 | loss: 3.3470395
	speed: 0.0323s/iter; left time: 727.2267s
Epoch: 15 cost time: 8.809808492660522
Epoch: 15, Steps: 264 Train Loss: 3.3326 (Forecasting Loss:0.2426 + XiCon Loss:3.0899 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1905
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.2554040
	speed: 0.0346s/iter; left time: 773.2961s
	iters: 200, epoch: 16 | loss: 3.3124912
	speed: 0.0323s/iter; left time: 717.6702s
Epoch: 16 cost time: 8.793634414672852
Epoch: 16, Steps: 264 Train Loss: 3.3363 (Forecasting Loss:0.2426 + XiCon Loss:3.0938 x Lambda(1.0)), Vali MSE Loss: 0.2456 Test MSE Loss: 0.1905
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.11857102066278458, mae:0.26239481568336487, mape:0.6329790949821472, mspe:14.636381149291992 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 16.6051
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5358410
	speed: 0.0369s/iter; left time: 971.7823s
	iters: 200, epoch: 1 | loss: 3.5124459
	speed: 0.0333s/iter; left time: 873.5494s
Epoch: 1 cost time: 9.215996742248535
Epoch: 1, Steps: 264 Train Loss: 3.5384 (Forecasting Loss:0.3384 + XiCon Loss:3.2000 x Lambda(1.0)), Vali MSE Loss: 0.2923 Test MSE Loss: 0.2329
Validation loss decreased (inf --> 0.292318).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3581419
	speed: 0.0341s/iter; left time: 888.6782s
	iters: 200, epoch: 2 | loss: 3.1823082
	speed: 0.0317s/iter; left time: 821.2094s
Epoch: 2 cost time: 8.669162511825562
Epoch: 2, Steps: 264 Train Loss: 3.2759 (Forecasting Loss:0.2518 + XiCon Loss:3.0241 x Lambda(1.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1967
Validation loss decreased (0.292318 --> 0.251707).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2226655
	speed: 0.0345s/iter; left time: 888.5996s
	iters: 200, epoch: 3 | loss: 3.3048911
	speed: 0.0327s/iter; left time: 839.3994s
Epoch: 3 cost time: 8.838999271392822
Epoch: 3, Steps: 264 Train Loss: 3.2916 (Forecasting Loss:0.2450 + XiCon Loss:3.0466 x Lambda(1.0)), Vali MSE Loss: 0.2447 Test MSE Loss: 0.1951
Validation loss decreased (0.251707 --> 0.244664).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3052225
	speed: 0.0348s/iter; left time: 888.1134s
	iters: 200, epoch: 4 | loss: 3.3195894
	speed: 0.0331s/iter; left time: 842.2322s
Epoch: 4 cost time: 8.890824317932129
Epoch: 4, Steps: 264 Train Loss: 3.3305 (Forecasting Loss:0.2425 + XiCon Loss:3.0880 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1953
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3547754
	speed: 0.0350s/iter; left time: 884.3591s
	iters: 200, epoch: 5 | loss: 3.2515621
	speed: 0.0315s/iter; left time: 791.5439s
Epoch: 5 cost time: 8.74513053894043
Epoch: 5, Steps: 264 Train Loss: 3.3274 (Forecasting Loss:0.2408 + XiCon Loss:3.0866 x Lambda(1.0)), Vali MSE Loss: 0.2475 Test MSE Loss: 0.1953
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.2992718
	speed: 0.0351s/iter; left time: 876.1261s
	iters: 200, epoch: 6 | loss: 3.3511047
	speed: 0.0315s/iter; left time: 784.5623s
Epoch: 6 cost time: 8.764666080474854
Epoch: 6, Steps: 264 Train Loss: 3.3257 (Forecasting Loss:0.2401 + XiCon Loss:3.0856 x Lambda(1.0)), Vali MSE Loss: 0.2480 Test MSE Loss: 0.1955
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4154146
	speed: 0.0341s/iter; left time: 843.7855s
	iters: 200, epoch: 7 | loss: 3.3713553
	speed: 0.0317s/iter; left time: 780.3538s
Epoch: 7 cost time: 8.626667261123657
Epoch: 7, Steps: 264 Train Loss: 3.3213 (Forecasting Loss:0.2395 + XiCon Loss:3.0818 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1959
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.2857440
	speed: 0.0350s/iter; left time: 854.9441s
	iters: 200, epoch: 8 | loss: 3.3656387
	speed: 0.0324s/iter; left time: 789.6578s
Epoch: 8 cost time: 8.839600801467896
Epoch: 8, Steps: 264 Train Loss: 3.3260 (Forecasting Loss:0.2392 + XiCon Loss:3.0868 x Lambda(1.0)), Vali MSE Loss: 0.2482 Test MSE Loss: 0.1958
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3043137
	speed: 0.0343s/iter; left time: 829.6141s
	iters: 200, epoch: 9 | loss: 3.4148624
	speed: 0.0318s/iter; left time: 766.2341s
Epoch: 9 cost time: 8.687530040740967
Epoch: 9, Steps: 264 Train Loss: 3.3260 (Forecasting Loss:0.2391 + XiCon Loss:3.0869 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1958
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.3432961
	speed: 0.0346s/iter; left time: 827.2582s
	iters: 200, epoch: 10 | loss: 3.2296610
	speed: 0.0320s/iter; left time: 761.3289s
Epoch: 10 cost time: 8.677496671676636
Epoch: 10, Steps: 264 Train Loss: 3.3185 (Forecasting Loss:0.2392 + XiCon Loss:3.0793 x Lambda(1.0)), Vali MSE Loss: 0.2485 Test MSE Loss: 0.1958
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.2808430
	speed: 0.0338s/iter; left time: 800.2460s
	iters: 200, epoch: 11 | loss: 3.3358185
	speed: 0.0320s/iter; left time: 753.1521s
Epoch: 11 cost time: 8.625932216644287
Epoch: 11, Steps: 264 Train Loss: 3.3222 (Forecasting Loss:0.2391 + XiCon Loss:3.0831 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1958
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4283063
	speed: 0.0341s/iter; left time: 798.8638s
	iters: 200, epoch: 12 | loss: 3.3288405
	speed: 0.0325s/iter; left time: 757.0182s
Epoch: 12 cost time: 8.740230560302734
Epoch: 12, Steps: 264 Train Loss: 3.3297 (Forecasting Loss:0.2390 + XiCon Loss:3.0907 x Lambda(1.0)), Vali MSE Loss: 0.2484 Test MSE Loss: 0.1958
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.2405415
	speed: 0.0348s/iter; left time: 805.1782s
	iters: 200, epoch: 13 | loss: 3.4004266
	speed: 0.0326s/iter; left time: 750.2118s
Epoch: 13 cost time: 8.819736003875732
Epoch: 13, Steps: 264 Train Loss: 3.3243 (Forecasting Loss:0.2392 + XiCon Loss:3.0851 x Lambda(1.0)), Vali MSE Loss: 0.2483 Test MSE Loss: 0.1958
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.12254253029823303, mae:0.26760080456733704, mape:0.6536489129066467, mspe:15.729572296142578 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:234977
train 33889
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.4794
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33889
val 11185
test 11185
	iters: 100, epoch: 1 | loss: 3.5754859
	speed: 0.0364s/iter; left time: 958.3411s
	iters: 200, epoch: 1 | loss: 3.5164418
	speed: 0.0331s/iter; left time: 867.8758s
Epoch: 1 cost time: 9.036312103271484
Epoch: 1, Steps: 264 Train Loss: 3.5518 (Forecasting Loss:0.3400 + XiCon Loss:3.2119 x Lambda(1.0)), Vali MSE Loss: 0.3036 Test MSE Loss: 0.2379
Validation loss decreased (inf --> 0.303552).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2423434
	speed: 0.0346s/iter; left time: 901.2517s
	iters: 200, epoch: 2 | loss: 3.2669740
	speed: 0.0319s/iter; left time: 827.8506s
Epoch: 2 cost time: 8.744246482849121
Epoch: 2, Steps: 264 Train Loss: 3.2698 (Forecasting Loss:0.2502 + XiCon Loss:3.0196 x Lambda(1.0)), Vali MSE Loss: 0.2517 Test MSE Loss: 0.1986
Validation loss decreased (0.303552 --> 0.251740).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.1983614
	speed: 0.0346s/iter; left time: 892.9868s
	iters: 200, epoch: 3 | loss: 3.2424707
	speed: 0.0325s/iter; left time: 834.7462s
Epoch: 3 cost time: 8.848271369934082
Epoch: 3, Steps: 264 Train Loss: 3.2046 (Forecasting Loss:0.2392 + XiCon Loss:2.9654 x Lambda(1.0)), Vali MSE Loss: 0.2522 Test MSE Loss: 0.2010
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.2576873
	speed: 0.0345s/iter; left time: 880.4476s
	iters: 200, epoch: 4 | loss: 3.2170513
	speed: 0.0326s/iter; left time: 828.0637s
Epoch: 4 cost time: 8.80614185333252
Epoch: 4, Steps: 264 Train Loss: 3.1913 (Forecasting Loss:0.2372 + XiCon Loss:2.9541 x Lambda(1.0)), Vali MSE Loss: 0.2455 Test MSE Loss: 0.1963
Validation loss decreased (0.251740 --> 0.245513).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.1761973
	speed: 0.0347s/iter; left time: 875.2090s
	iters: 200, epoch: 5 | loss: 3.1716559
	speed: 0.0327s/iter; left time: 822.8884s
Epoch: 5 cost time: 8.86195683479309
Epoch: 5, Steps: 264 Train Loss: 3.1872 (Forecasting Loss:0.2369 + XiCon Loss:2.9503 x Lambda(1.0)), Vali MSE Loss: 0.2445 Test MSE Loss: 0.1955
Validation loss decreased (0.245513 --> 0.244510).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.2009583
	speed: 0.0349s/iter; left time: 870.9908s
	iters: 200, epoch: 6 | loss: 3.2004282
	speed: 0.0323s/iter; left time: 802.4500s
Epoch: 6 cost time: 8.802180290222168
Epoch: 6, Steps: 264 Train Loss: 3.1897 (Forecasting Loss:0.2369 + XiCon Loss:2.9528 x Lambda(1.0)), Vali MSE Loss: 0.2438 Test MSE Loss: 0.1949
Validation loss decreased (0.244510 --> 0.243807).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.1937673
	speed: 0.0345s/iter; left time: 852.2733s
	iters: 200, epoch: 7 | loss: 3.1883423
	speed: 0.0332s/iter; left time: 818.0650s
Epoch: 7 cost time: 8.98388123512268
Epoch: 7, Steps: 264 Train Loss: 3.1929 (Forecasting Loss:0.2374 + XiCon Loss:2.9555 x Lambda(1.0)), Vali MSE Loss: 0.2444 Test MSE Loss: 0.1952
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.1803868
	speed: 0.0355s/iter; left time: 869.2423s
	iters: 200, epoch: 8 | loss: 3.1806083
	speed: 0.0334s/iter; left time: 813.7926s
Epoch: 8 cost time: 9.032526969909668
Epoch: 8, Steps: 264 Train Loss: 3.1922 (Forecasting Loss:0.2377 + XiCon Loss:2.9546 x Lambda(1.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1949
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.1990499
	speed: 0.0353s/iter; left time: 853.7223s
	iters: 200, epoch: 9 | loss: 3.1750398
	speed: 0.0334s/iter; left time: 803.4789s
Epoch: 9 cost time: 9.0050950050354
Epoch: 9, Steps: 264 Train Loss: 3.1946 (Forecasting Loss:0.2375 + XiCon Loss:2.9571 x Lambda(1.0)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1948
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.1717663
	speed: 0.0361s/iter; left time: 862.8353s
	iters: 200, epoch: 10 | loss: 3.1784232
	speed: 0.0331s/iter; left time: 787.8637s
Epoch: 10 cost time: 9.032554149627686
Epoch: 10, Steps: 264 Train Loss: 3.1931 (Forecasting Loss:0.2377 + XiCon Loss:2.9555 x Lambda(1.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1948
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.2146626
	speed: 0.0350s/iter; left time: 827.0766s
	iters: 200, epoch: 11 | loss: 3.1782830
	speed: 0.0327s/iter; left time: 771.5003s
Epoch: 11 cost time: 8.909828424453735
Epoch: 11, Steps: 264 Train Loss: 3.1956 (Forecasting Loss:0.2378 + XiCon Loss:2.9578 x Lambda(1.0)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1949
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.1514640
	speed: 0.0358s/iter; left time: 837.7697s
	iters: 200, epoch: 12 | loss: 3.2210407
	speed: 0.0340s/iter; left time: 793.0445s
Epoch: 12 cost time: 9.095133781433105
Epoch: 12, Steps: 264 Train Loss: 3.1960 (Forecasting Loss:0.2377 + XiCon Loss:2.9583 x Lambda(1.0)), Vali MSE Loss: 0.2439 Test MSE Loss: 0.1949
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.2260768
	speed: 0.0352s/iter; left time: 814.4157s
	iters: 200, epoch: 13 | loss: 3.1815777
	speed: 0.0330s/iter; left time: 760.9437s
Epoch: 13 cost time: 8.969117641448975
Epoch: 13, Steps: 264 Train Loss: 3.1960 (Forecasting Loss:0.2376 + XiCon Loss:2.9585 x Lambda(1.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1949
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.1601300
	speed: 0.0354s/iter; left time: 810.6451s
	iters: 200, epoch: 14 | loss: 3.2098536
	speed: 0.0332s/iter; left time: 755.4250s
Epoch: 14 cost time: 9.014230966567993
Epoch: 14, Steps: 264 Train Loss: 3.1943 (Forecasting Loss:0.2376 + XiCon Loss:2.9567 x Lambda(1.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1949
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.2009039
	speed: 0.0352s/iter; left time: 795.4912s
	iters: 200, epoch: 15 | loss: 3.1832616
	speed: 0.0331s/iter; left time: 745.2789s
Epoch: 15 cost time: 8.935983419418335
Epoch: 15, Steps: 264 Train Loss: 3.1950 (Forecasting Loss:0.2377 + XiCon Loss:2.9573 x Lambda(1.0)), Vali MSE Loss: 0.2440 Test MSE Loss: 0.1949
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.2137511
	speed: 0.0357s/iter; left time: 798.4063s
	iters: 200, epoch: 16 | loss: 3.2328019
	speed: 0.0332s/iter; left time: 738.6099s
Epoch: 16 cost time: 9.01561450958252
Epoch: 16, Steps: 264 Train Loss: 3.1954 (Forecasting Loss:0.2375 + XiCon Loss:2.9578 x Lambda(1.0)), Vali MSE Loss: 0.2441 Test MSE Loss: 0.1949
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl336_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 11185
test shape: (87, 128, 336, 1) (87, 128, 336, 1)
test shape: (11136, 336, 1) (11136, 336, 1)
mse:0.1228715255856514, mae:0.2669883668422699, mape:0.629187285900116, mspe:14.150335311889648 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1212+-0.00232, MAE:0.2652+-0.00275, MAPE:0.6341+-0.01570, MSPE:14.5880+-0.90415, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=1.0, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='ETTm2', root_path='./dataset/ETT-small', data_path='ETTm2.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=4, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0005, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.01, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.2096
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.5842495
	speed: 0.0514s/iter; left time: 1337.6807s
	iters: 200, epoch: 1 | loss: 3.5172722
	speed: 0.0450s/iter; left time: 1165.8231s
Epoch: 1 cost time: 12.426219463348389
Epoch: 1, Steps: 261 Train Loss: 3.5872 (Forecasting Loss:0.3722 + XiCon Loss:3.2150 x Lambda(1.0)), Vali MSE Loss: 0.3241 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.324123).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3199081
	speed: 0.0472s/iter; left time: 1215.0779s
	iters: 200, epoch: 2 | loss: 3.2748623
	speed: 0.0447s/iter; left time: 1145.7547s
Epoch: 2 cost time: 11.963155508041382
Epoch: 2, Steps: 261 Train Loss: 3.3313 (Forecasting Loss:0.2979 + XiCon Loss:3.0334 x Lambda(1.0)), Vali MSE Loss: 0.2987 Test MSE Loss: 0.2455
Validation loss decreased (0.324123 --> 0.298661).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.2527118
	speed: 0.0473s/iter; left time: 1205.7101s
	iters: 200, epoch: 3 | loss: 3.4314253
	speed: 0.0456s/iter; left time: 1157.5535s
Epoch: 3 cost time: 12.12794804573059
Epoch: 3, Steps: 261 Train Loss: 3.3149 (Forecasting Loss:0.2944 + XiCon Loss:3.0205 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.2426
Validation loss decreased (0.298661 --> 0.282654).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4414160
	speed: 0.0473s/iter; left time: 1193.2127s
	iters: 200, epoch: 4 | loss: 3.3846979
	speed: 0.0457s/iter; left time: 1148.0476s
Epoch: 4 cost time: 12.076896667480469
Epoch: 4, Steps: 261 Train Loss: 3.4173 (Forecasting Loss:0.2920 + XiCon Loss:3.1254 x Lambda(1.0)), Vali MSE Loss: 0.2871 Test MSE Loss: 0.2445
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.5275638
	speed: 0.0478s/iter; left time: 1193.0654s
	iters: 200, epoch: 5 | loss: 3.4711392
	speed: 0.0461s/iter; left time: 1146.6196s
Epoch: 5 cost time: 12.223954677581787
Epoch: 5, Steps: 261 Train Loss: 3.4228 (Forecasting Loss:0.2907 + XiCon Loss:3.1321 x Lambda(1.0)), Vali MSE Loss: 0.2855 Test MSE Loss: 0.2434
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4614866
	speed: 0.0477s/iter; left time: 1178.2967s
	iters: 200, epoch: 6 | loss: 3.3229177
	speed: 0.0456s/iter; left time: 1122.6718s
Epoch: 6 cost time: 12.178344488143921
Epoch: 6, Steps: 261 Train Loss: 3.4161 (Forecasting Loss:0.2901 + XiCon Loss:3.1261 x Lambda(1.0)), Vali MSE Loss: 0.2836 Test MSE Loss: 0.2427
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4246671
	speed: 0.0482s/iter; left time: 1176.8453s
	iters: 200, epoch: 7 | loss: 3.3588297
	speed: 0.0456s/iter; left time: 1109.8809s
Epoch: 7 cost time: 12.33234167098999
Epoch: 7, Steps: 261 Train Loss: 3.4214 (Forecasting Loss:0.2896 + XiCon Loss:3.1317 x Lambda(1.0)), Vali MSE Loss: 0.2831 Test MSE Loss: 0.2426
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.3979578
	speed: 0.0482s/iter; left time: 1165.1851s
	iters: 200, epoch: 8 | loss: 3.4088342
	speed: 0.0458s/iter; left time: 1102.1201s
Epoch: 8 cost time: 12.189844131469727
Epoch: 8, Steps: 261 Train Loss: 3.4127 (Forecasting Loss:0.2899 + XiCon Loss:3.1228 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2429
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3404391
	speed: 0.0493s/iter; left time: 1178.6206s
	iters: 200, epoch: 9 | loss: 3.3520925
	speed: 0.0455s/iter; left time: 1083.7667s
Epoch: 9 cost time: 12.358832359313965
Epoch: 9, Steps: 261 Train Loss: 3.4261 (Forecasting Loss:0.2897 + XiCon Loss:3.1364 x Lambda(1.0)), Vali MSE Loss: 0.2839 Test MSE Loss: 0.2429
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4254568
	speed: 0.0477s/iter; left time: 1128.2911s
	iters: 200, epoch: 10 | loss: 3.3694339
	speed: 0.0451s/iter; left time: 1061.4205s
Epoch: 10 cost time: 12.038691282272339
Epoch: 10, Steps: 261 Train Loss: 3.4201 (Forecasting Loss:0.2897 + XiCon Loss:3.1304 x Lambda(1.0)), Vali MSE Loss: 0.2834 Test MSE Loss: 0.2428
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.3837948
	speed: 0.0479s/iter; left time: 1119.5394s
	iters: 200, epoch: 11 | loss: 3.3675754
	speed: 0.0461s/iter; left time: 1073.4168s
Epoch: 11 cost time: 12.190276384353638
Epoch: 11, Steps: 261 Train Loss: 3.4203 (Forecasting Loss:0.2896 + XiCon Loss:3.1307 x Lambda(1.0)), Vali MSE Loss: 0.2835 Test MSE Loss: 0.2428
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4186330
	speed: 0.0502s/iter; left time: 1161.3205s
	iters: 200, epoch: 12 | loss: 3.5654416
	speed: 0.0458s/iter; left time: 1054.6804s
Epoch: 12 cost time: 12.454522371292114
Epoch: 12, Steps: 261 Train Loss: 3.4199 (Forecasting Loss:0.2895 + XiCon Loss:3.1303 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2429
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4790864
	speed: 0.0480s/iter; left time: 1098.4828s
	iters: 200, epoch: 13 | loss: 3.3997540
	speed: 0.0470s/iter; left time: 1069.1166s
Epoch: 13 cost time: 12.380602359771729
Epoch: 13, Steps: 261 Train Loss: 3.4165 (Forecasting Loss:0.2896 + XiCon Loss:3.1269 x Lambda(1.0)), Vali MSE Loss: 0.2838 Test MSE Loss: 0.2429
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.16782665252685547, mae:0.3174399137496948, mape:0.7161147594451904, mspe:19.909208297729492 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.3165
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.6194651
	speed: 0.0495s/iter; left time: 1287.0871s
	iters: 200, epoch: 1 | loss: 3.5672314
	speed: 0.0453s/iter; left time: 1174.1971s
Epoch: 1 cost time: 12.302252531051636
Epoch: 1, Steps: 261 Train Loss: 3.6011 (Forecasting Loss:0.3712 + XiCon Loss:3.2299 x Lambda(1.0)), Vali MSE Loss: 0.3239 Test MSE Loss: 0.2808
Validation loss decreased (inf --> 0.323899).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3156018
	speed: 0.0478s/iter; left time: 1229.5863s
	iters: 200, epoch: 2 | loss: 3.2697093
	speed: 0.0455s/iter; left time: 1165.7507s
Epoch: 2 cost time: 12.191001653671265
Epoch: 2, Steps: 261 Train Loss: 3.3318 (Forecasting Loss:0.2995 + XiCon Loss:3.0323 x Lambda(1.0)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.2511
Validation loss decreased (0.323899 --> 0.284831).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3477635
	speed: 0.0481s/iter; left time: 1225.4395s
	iters: 200, epoch: 3 | loss: 3.4697766
	speed: 0.0462s/iter; left time: 1171.3663s
Epoch: 3 cost time: 12.211138725280762
Epoch: 3, Steps: 261 Train Loss: 3.3960 (Forecasting Loss:0.2927 + XiCon Loss:3.1034 x Lambda(1.0)), Vali MSE Loss: 0.2848 Test MSE Loss: 0.2473
Validation loss decreased (0.284831 --> 0.284804).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4549975
	speed: 0.0480s/iter; left time: 1209.9920s
	iters: 200, epoch: 4 | loss: 3.4096613
	speed: 0.0465s/iter; left time: 1168.9533s
Epoch: 4 cost time: 12.298004150390625
Epoch: 4, Steps: 261 Train Loss: 3.4148 (Forecasting Loss:0.2906 + XiCon Loss:3.1242 x Lambda(1.0)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.2456
Validation loss decreased (0.284804 --> 0.282811).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3878820
	speed: 0.0502s/iter; left time: 1253.6359s
	iters: 200, epoch: 5 | loss: 3.3591092
	speed: 0.0486s/iter; left time: 1207.3550s
Epoch: 5 cost time: 12.96712589263916
Epoch: 5, Steps: 261 Train Loss: 3.4107 (Forecasting Loss:0.2895 + XiCon Loss:3.1212 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.2441
Validation loss decreased (0.282811 --> 0.282727).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4304848
	speed: 0.0516s/iter; left time: 1273.8831s
	iters: 200, epoch: 6 | loss: 3.3610196
	speed: 0.0497s/iter; left time: 1221.6471s
Epoch: 6 cost time: 13.229549646377563
Epoch: 6, Steps: 261 Train Loss: 3.3995 (Forecasting Loss:0.2892 + XiCon Loss:3.1103 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2445
Validation loss decreased (0.282727 --> 0.281715).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3265381
	speed: 0.0528s/iter; left time: 1288.9648s
	iters: 200, epoch: 7 | loss: 3.4639981
	speed: 0.0501s/iter; left time: 1219.9292s
Epoch: 7 cost time: 13.341863870620728
Epoch: 7, Steps: 261 Train Loss: 3.3960 (Forecasting Loss:0.2887 + XiCon Loss:3.1074 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2443
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4167097
	speed: 0.0533s/iter; left time: 1289.1536s
	iters: 200, epoch: 8 | loss: 3.4461453
	speed: 0.0505s/iter; left time: 1215.8854s
Epoch: 8 cost time: 13.515880823135376
Epoch: 8, Steps: 261 Train Loss: 3.3996 (Forecasting Loss:0.2885 + XiCon Loss:3.1111 x Lambda(1.0)), Vali MSE Loss: 0.2818 Test MSE Loss: 0.2440
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4964757
	speed: 0.0532s/iter; left time: 1271.9316s
	iters: 200, epoch: 9 | loss: 3.4053431
	speed: 0.0511s/iter; left time: 1217.8461s
Epoch: 9 cost time: 13.588861227035522
Epoch: 9, Steps: 261 Train Loss: 3.3948 (Forecasting Loss:0.2884 + XiCon Loss:3.1065 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2440
Validation loss decreased (0.281715 --> 0.281631).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4379222
	speed: 0.0540s/iter; left time: 1277.3171s
	iters: 200, epoch: 10 | loss: 3.4827185
	speed: 0.0508s/iter; left time: 1195.4574s
Epoch: 10 cost time: 13.564395427703857
Epoch: 10, Steps: 261 Train Loss: 3.4042 (Forecasting Loss:0.2886 + XiCon Loss:3.1156 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2440
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.5121856
	speed: 0.0532s/iter; left time: 1244.3147s
	iters: 200, epoch: 11 | loss: 3.4214516
	speed: 0.0519s/iter; left time: 1208.8714s
Epoch: 11 cost time: 13.715648174285889
Epoch: 11, Steps: 261 Train Loss: 3.3944 (Forecasting Loss:0.2886 + XiCon Loss:3.1058 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.2802892
	speed: 0.0533s/iter; left time: 1233.1169s
	iters: 200, epoch: 12 | loss: 3.4132400
	speed: 0.0510s/iter; left time: 1174.2903s
Epoch: 12 cost time: 13.563864469528198
Epoch: 12, Steps: 261 Train Loss: 3.3941 (Forecasting Loss:0.2885 + XiCon Loss:3.1056 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
Validation loss decreased (0.281631 --> 0.281622).  Saving model ...
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.3942909
	speed: 0.0535s/iter; left time: 1222.7297s
	iters: 200, epoch: 13 | loss: 3.3155704
	speed: 0.0514s/iter; left time: 1170.9279s
Epoch: 13 cost time: 13.686007499694824
Epoch: 13, Steps: 261 Train Loss: 3.3955 (Forecasting Loss:0.2884 + XiCon Loss:3.1071 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
Validation loss decreased (0.281622 --> 0.281598).  Saving model ...
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.2908995
	speed: 0.0538s/iter; left time: 1216.0713s
	iters: 200, epoch: 14 | loss: 3.4519911
	speed: 0.0512s/iter; left time: 1153.1883s
Epoch: 14 cost time: 13.736571788787842
Epoch: 14, Steps: 261 Train Loss: 3.3950 (Forecasting Loss:0.2885 + XiCon Loss:3.1065 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
Validation loss decreased (0.281598 --> 0.281552).  Saving model ...
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4457181
	speed: 0.0532s/iter; left time: 1189.5721s
	iters: 200, epoch: 15 | loss: 3.3456547
	speed: 0.0512s/iter; left time: 1139.8313s
Epoch: 15 cost time: 13.637838363647461
Epoch: 15, Steps: 261 Train Loss: 3.3951 (Forecasting Loss:0.2886 + XiCon Loss:3.1065 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4531136
	speed: 0.0537s/iter; left time: 1185.3049s
	iters: 200, epoch: 16 | loss: 3.3210607
	speed: 0.0515s/iter; left time: 1131.9081s
Epoch: 16 cost time: 13.653959512710571
Epoch: 16, Steps: 261 Train Loss: 3.3991 (Forecasting Loss:0.2885 + XiCon Loss:3.1106 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5219476
	speed: 0.0532s/iter; left time: 1161.1209s
	iters: 200, epoch: 17 | loss: 3.3920860
	speed: 0.0506s/iter; left time: 1100.1544s
Epoch: 17 cost time: 13.51289439201355
Epoch: 17, Steps: 261 Train Loss: 3.3949 (Forecasting Loss:0.2884 + XiCon Loss:3.1065 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.3376508
	speed: 0.0531s/iter; left time: 1144.1200s
	iters: 200, epoch: 18 | loss: 3.5295100
	speed: 0.0514s/iter; left time: 1102.1894s
Epoch: 18 cost time: 13.592119455337524
Epoch: 18, Steps: 261 Train Loss: 3.3978 (Forecasting Loss:0.2883 + XiCon Loss:3.1095 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2439
Validation loss decreased (0.281552 --> 0.281361).  Saving model ...
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4378896
	speed: 0.0536s/iter; left time: 1140.8646s
	iters: 200, epoch: 19 | loss: 3.3806670
	speed: 0.0510s/iter; left time: 1080.9413s
Epoch: 19 cost time: 13.687139511108398
Epoch: 19, Steps: 261 Train Loss: 3.3955 (Forecasting Loss:0.2885 + XiCon Loss:3.1070 x Lambda(1.0)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.2439
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-09
	iters: 100, epoch: 20 | loss: 3.4447880
	speed: 0.0538s/iter; left time: 1131.6735s
	iters: 200, epoch: 20 | loss: 3.4327788
	speed: 0.0519s/iter; left time: 1085.9613s
Epoch: 20 cost time: 13.75162386894226
Epoch: 20, Steps: 261 Train Loss: 3.3934 (Forecasting Loss:0.2884 + XiCon Loss:3.1049 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2439
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-10
	iters: 100, epoch: 21 | loss: 3.3771799
	speed: 0.0537s/iter; left time: 1115.8140s
	iters: 200, epoch: 21 | loss: 3.3400893
	speed: 0.0518s/iter; left time: 1070.3178s
Epoch: 21 cost time: 13.748733520507812
Epoch: 21, Steps: 261 Train Loss: 3.3937 (Forecasting Loss:0.2884 + XiCon Loss:3.1053 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-10
	iters: 100, epoch: 22 | loss: 3.3415189
	speed: 0.0531s/iter; left time: 1090.1677s
	iters: 200, epoch: 22 | loss: 3.4513640
	speed: 0.0512s/iter; left time: 1044.7061s
Epoch: 22 cost time: 13.546537160873413
Epoch: 22, Steps: 261 Train Loss: 3.3964 (Forecasting Loss:0.2884 + XiCon Loss:3.1080 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-10
	iters: 100, epoch: 23 | loss: 3.4167485
	speed: 0.0534s/iter; left time: 1082.1745s
	iters: 200, epoch: 23 | loss: 3.4539146
	speed: 0.0508s/iter; left time: 1024.5152s
Epoch: 23 cost time: 13.572977542877197
Epoch: 23, Steps: 261 Train Loss: 3.3942 (Forecasting Loss:0.2884 + XiCon Loss:3.1058 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078125e-10
	iters: 100, epoch: 24 | loss: 3.3207188
	speed: 0.0540s/iter; left time: 1079.7601s
	iters: 200, epoch: 24 | loss: 3.4713621
	speed: 0.0521s/iter; left time: 1035.9991s
Epoch: 24 cost time: 13.772335052490234
Epoch: 24, Steps: 261 Train Loss: 3.3916 (Forecasting Loss:0.2886 + XiCon Loss:3.1030 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-11
	iters: 100, epoch: 25 | loss: 3.4566727
	speed: 0.0533s/iter; left time: 1052.7098s
	iters: 200, epoch: 25 | loss: 3.5243897
	speed: 0.0514s/iter; left time: 1008.7829s
Epoch: 25 cost time: 13.623273372650146
Epoch: 25, Steps: 261 Train Loss: 3.3957 (Forecasting Loss:0.2884 + XiCon Loss:3.1072 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.980232238769531e-11
	iters: 100, epoch: 26 | loss: 3.4479980
	speed: 0.0540s/iter; left time: 1051.5268s
	iters: 200, epoch: 26 | loss: 3.3903883
	speed: 0.0507s/iter; left time: 983.2744s
Epoch: 26 cost time: 13.623717784881592
Epoch: 26, Steps: 261 Train Loss: 3.3921 (Forecasting Loss:0.2885 + XiCon Loss:3.1036 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2439
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-11
	iters: 100, epoch: 27 | loss: 3.3515470
	speed: 0.0540s/iter; left time: 1037.1850s
	iters: 200, epoch: 27 | loss: 3.3926396
	speed: 0.0506s/iter; left time: 967.7265s
Epoch: 27 cost time: 13.624498128890991
Epoch: 27, Steps: 261 Train Loss: 3.3997 (Forecasting Loss:0.2883 + XiCon Loss:3.1113 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2439
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923828e-12
	iters: 100, epoch: 28 | loss: 3.5208721
	speed: 0.0533s/iter; left time: 1009.7290s
	iters: 200, epoch: 28 | loss: 3.2940941
	speed: 0.0522s/iter; left time: 984.8668s
Epoch: 28 cost time: 13.73477840423584
Epoch: 28, Steps: 261 Train Loss: 3.4003 (Forecasting Loss:0.2884 + XiCon Loss:3.1120 x Lambda(1.0)), Vali MSE Loss: 0.2815 Test MSE Loss: 0.2439
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17001695930957794, mae:0.317777544260025, mape:0.7069483399391174, mspe:19.005752563476562 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.4834
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.5736802
	speed: 0.0453s/iter; left time: 1176.6383s
	iters: 200, epoch: 1 | loss: 3.5481567
	speed: 0.0422s/iter; left time: 1091.8801s
Epoch: 1 cost time: 11.283949375152588
Epoch: 1, Steps: 261 Train Loss: 3.5869 (Forecasting Loss:0.3723 + XiCon Loss:3.2146 x Lambda(1.0)), Vali MSE Loss: 0.3194 Test MSE Loss: 0.2811
Validation loss decreased (inf --> 0.319374).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3115296
	speed: 0.0446s/iter; left time: 1148.7328s
	iters: 200, epoch: 2 | loss: 3.3366723
	speed: 0.0417s/iter; left time: 1069.3951s
Epoch: 2 cost time: 11.17402195930481
Epoch: 2, Steps: 261 Train Loss: 3.3979 (Forecasting Loss:0.2999 + XiCon Loss:3.0980 x Lambda(1.0)), Vali MSE Loss: 0.2885 Test MSE Loss: 0.2483
Validation loss decreased (0.319374 --> 0.288466).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4558196
	speed: 0.0449s/iter; left time: 1144.8549s
	iters: 200, epoch: 3 | loss: 3.4685028
	speed: 0.0413s/iter; left time: 1048.5001s
Epoch: 3 cost time: 11.142015218734741
Epoch: 3, Steps: 261 Train Loss: 3.4708 (Forecasting Loss:0.2898 + XiCon Loss:3.1810 x Lambda(1.0)), Vali MSE Loss: 0.2852 Test MSE Loss: 0.2518
Validation loss decreased (0.288466 --> 0.285170).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3586431
	speed: 0.0448s/iter; left time: 1129.0044s
	iters: 200, epoch: 4 | loss: 3.4626415
	speed: 0.0416s/iter; left time: 1045.3285s
Epoch: 4 cost time: 11.169623613357544
Epoch: 4, Steps: 261 Train Loss: 3.4609 (Forecasting Loss:0.2863 + XiCon Loss:3.1746 x Lambda(1.0)), Vali MSE Loss: 0.2824 Test MSE Loss: 0.2538
Validation loss decreased (0.285170 --> 0.282352).  Saving model ...
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4579372
	speed: 0.0450s/iter; left time: 1123.3730s
	iters: 200, epoch: 5 | loss: 3.4179759
	speed: 0.0418s/iter; left time: 1040.2042s
Epoch: 5 cost time: 11.281533241271973
Epoch: 5, Steps: 261 Train Loss: 3.4586 (Forecasting Loss:0.2851 + XiCon Loss:3.1735 x Lambda(1.0)), Vali MSE Loss: 0.2828 Test MSE Loss: 0.2530
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4598403
	speed: 0.0448s/iter; left time: 1105.5719s
	iters: 200, epoch: 6 | loss: 3.4179192
	speed: 0.0422s/iter; left time: 1038.3732s
Epoch: 6 cost time: 11.231269598007202
Epoch: 6, Steps: 261 Train Loss: 3.4523 (Forecasting Loss:0.2849 + XiCon Loss:3.1674 x Lambda(1.0)), Vali MSE Loss: 0.2829 Test MSE Loss: 0.2530
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3516748
	speed: 0.0455s/iter; left time: 1112.2002s
	iters: 200, epoch: 7 | loss: 3.4067619
	speed: 0.0422s/iter; left time: 1026.7216s
Epoch: 7 cost time: 11.316386461257935
Epoch: 7, Steps: 261 Train Loss: 3.4498 (Forecasting Loss:0.2843 + XiCon Loss:3.1655 x Lambda(1.0)), Vali MSE Loss: 0.2827 Test MSE Loss: 0.2533
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4437001
	speed: 0.0450s/iter; left time: 1088.4647s
	iters: 200, epoch: 8 | loss: 3.4684055
	speed: 0.0424s/iter; left time: 1019.5989s
Epoch: 8 cost time: 11.311220169067383
Epoch: 8, Steps: 261 Train Loss: 3.4534 (Forecasting Loss:0.2840 + XiCon Loss:3.1694 x Lambda(1.0)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.2536
Validation loss decreased (0.282352 --> 0.282146).  Saving model ...
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.4712734
	speed: 0.0449s/iter; left time: 1074.1039s
	iters: 200, epoch: 9 | loss: 3.4322226
	speed: 0.0420s/iter; left time: 999.5042s
Epoch: 9 cost time: 11.217052698135376
Epoch: 9, Steps: 261 Train Loss: 3.4484 (Forecasting Loss:0.2839 + XiCon Loss:3.1645 x Lambda(1.0)), Vali MSE Loss: 0.2816 Test MSE Loss: 0.2537
Validation loss decreased (0.282146 --> 0.281628).  Saving model ...
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4591300
	speed: 0.0451s/iter; left time: 1066.6628s
	iters: 200, epoch: 10 | loss: 3.4398704
	speed: 0.0420s/iter; left time: 989.8994s
Epoch: 10 cost time: 11.243124723434448
Epoch: 10, Steps: 261 Train Loss: 3.4452 (Forecasting Loss:0.2842 + XiCon Loss:3.1610 x Lambda(1.0)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.2536
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4970777
	speed: 0.0451s/iter; left time: 1053.8510s
	iters: 200, epoch: 11 | loss: 3.4527290
	speed: 0.0415s/iter; left time: 967.5944s
Epoch: 11 cost time: 11.224606037139893
Epoch: 11, Steps: 261 Train Loss: 3.4533 (Forecasting Loss:0.2839 + XiCon Loss:3.1694 x Lambda(1.0)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.2536
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.4675016
	speed: 0.0444s/iter; left time: 1026.4809s
	iters: 200, epoch: 12 | loss: 3.4735165
	speed: 0.0418s/iter; left time: 963.1728s
Epoch: 12 cost time: 11.17346477508545
Epoch: 12, Steps: 261 Train Loss: 3.4548 (Forecasting Loss:0.2836 + XiCon Loss:3.1712 x Lambda(1.0)), Vali MSE Loss: 0.2821 Test MSE Loss: 0.2536
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.2696249
	speed: 0.0448s/iter; left time: 1025.1737s
	iters: 200, epoch: 13 | loss: 3.5004079
	speed: 0.0414s/iter; left time: 943.3323s
Epoch: 13 cost time: 11.21401071548462
Epoch: 13, Steps: 261 Train Loss: 3.4485 (Forecasting Loss:0.2839 + XiCon Loss:3.1646 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2536
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4690564
	speed: 0.0449s/iter; left time: 1014.4943s
	iters: 200, epoch: 14 | loss: 3.4954603
	speed: 0.0423s/iter; left time: 952.7540s
Epoch: 14 cost time: 11.260881662368774
Epoch: 14, Steps: 261 Train Loss: 3.4505 (Forecasting Loss:0.2840 + XiCon Loss:3.1665 x Lambda(1.0)), Vali MSE Loss: 0.2817 Test MSE Loss: 0.2536
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4295378
	speed: 0.0452s/iter; left time: 1010.6362s
	iters: 200, epoch: 15 | loss: 3.5105538
	speed: 0.0425s/iter; left time: 944.7005s
Epoch: 15 cost time: 11.303531169891357
Epoch: 15, Steps: 261 Train Loss: 3.4536 (Forecasting Loss:0.2838 + XiCon Loss:3.1698 x Lambda(1.0)), Vali MSE Loss: 0.2820 Test MSE Loss: 0.2536
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4211974
	speed: 0.0454s/iter; left time: 1001.9490s
	iters: 200, epoch: 16 | loss: 3.5921340
	speed: 0.0422s/iter; left time: 927.0893s
Epoch: 16 cost time: 11.342142105102539
Epoch: 16, Steps: 261 Train Loss: 3.4480 (Forecasting Loss:0.2842 + XiCon Loss:3.1637 x Lambda(1.0)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.2536
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.5615563
	speed: 0.0453s/iter; left time: 988.0197s
	iters: 200, epoch: 17 | loss: 3.5332308
	speed: 0.0415s/iter; left time: 901.3622s
Epoch: 17 cost time: 11.238946199417114
Epoch: 17, Steps: 261 Train Loss: 3.4507 (Forecasting Loss:0.2838 + XiCon Loss:3.1669 x Lambda(1.0)), Vali MSE Loss: 0.2819 Test MSE Loss: 0.2536
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-09
	iters: 100, epoch: 18 | loss: 3.3706081
	speed: 0.0453s/iter; left time: 976.2000s
	iters: 200, epoch: 18 | loss: 3.3365798
	speed: 0.0427s/iter; left time: 916.0051s
Epoch: 18 cost time: 11.342654943466187
Epoch: 18, Steps: 261 Train Loss: 3.4524 (Forecasting Loss:0.2838 + XiCon Loss:3.1685 x Lambda(1.0)), Vali MSE Loss: 0.2818 Test MSE Loss: 0.2536
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-09
	iters: 100, epoch: 19 | loss: 3.4880052
	speed: 0.0452s/iter; left time: 963.7191s
	iters: 200, epoch: 19 | loss: 3.4885273
	speed: 0.0427s/iter; left time: 905.3126s
Epoch: 19 cost time: 11.320674419403076
Epoch: 19, Steps: 261 Train Loss: 3.4437 (Forecasting Loss:0.2837 + XiCon Loss:3.1600 x Lambda(1.0)), Vali MSE Loss: 0.2818 Test MSE Loss: 0.2536
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17832085490226746, mae:0.32910457253456116, mape:0.7307865619659424, mspe:19.742246627807617 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 17.8736
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.5924859
	speed: 0.0445s/iter; left time: 1156.4867s
	iters: 200, epoch: 1 | loss: 3.5422778
	speed: 0.0413s/iter; left time: 1068.8745s
Epoch: 1 cost time: 11.082319021224976
Epoch: 1, Steps: 261 Train Loss: 3.5841 (Forecasting Loss:0.3720 + XiCon Loss:3.2120 x Lambda(1.0)), Vali MSE Loss: 0.3185 Test MSE Loss: 0.2805
Validation loss decreased (inf --> 0.318477).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.2656496
	speed: 0.0440s/iter; left time: 1133.8201s
	iters: 200, epoch: 2 | loss: 3.2957079
	speed: 0.0476s/iter; left time: 1219.6552s
Epoch: 2 cost time: 12.445098161697388
Epoch: 2, Steps: 261 Train Loss: 3.3406 (Forecasting Loss:0.2997 + XiCon Loss:3.0408 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2517
Validation loss decreased (0.318477 --> 0.288773).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.4206471
	speed: 0.0555s/iter; left time: 1414.2473s
	iters: 200, epoch: 3 | loss: 3.3972282
	speed: 0.0519s/iter; left time: 1317.8593s
Epoch: 3 cost time: 13.767023801803589
Epoch: 3, Steps: 261 Train Loss: 3.3947 (Forecasting Loss:0.2903 + XiCon Loss:3.1044 x Lambda(1.0)), Vali MSE Loss: 0.2956 Test MSE Loss: 0.2548
EarlyStopping counter: 1 out of 10
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.3475103
	speed: 0.0523s/iter; left time: 1319.8424s
	iters: 200, epoch: 4 | loss: 3.4059520
	speed: 0.0492s/iter; left time: 1234.7517s
Epoch: 4 cost time: 13.23469853401184
Epoch: 4, Steps: 261 Train Loss: 3.4169 (Forecasting Loss:0.2889 + XiCon Loss:3.1280 x Lambda(1.0)), Vali MSE Loss: 0.2898 Test MSE Loss: 0.2525
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.3243496
	speed: 0.0520s/iter; left time: 1297.0493s
	iters: 200, epoch: 5 | loss: 3.2925086
	speed: 0.0495s/iter; left time: 1229.6731s
Epoch: 5 cost time: 13.133183479309082
Epoch: 5, Steps: 261 Train Loss: 3.4073 (Forecasting Loss:0.2878 + XiCon Loss:3.1194 x Lambda(1.0)), Vali MSE Loss: 0.2899 Test MSE Loss: 0.2547
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.3993597
	speed: 0.0533s/iter; left time: 1316.8379s
	iters: 200, epoch: 6 | loss: 3.3947220
	speed: 0.0495s/iter; left time: 1218.6908s
Epoch: 6 cost time: 13.363688230514526
Epoch: 6, Steps: 261 Train Loss: 3.4053 (Forecasting Loss:0.2876 + XiCon Loss:3.1178 x Lambda(1.0)), Vali MSE Loss: 0.2883 Test MSE Loss: 0.2522
Validation loss decreased (0.288773 --> 0.288323).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.3330479
	speed: 0.0526s/iter; left time: 1284.9157s
	iters: 200, epoch: 7 | loss: 3.3563197
	speed: 0.0495s/iter; left time: 1205.4726s
Epoch: 7 cost time: 13.264413118362427
Epoch: 7, Steps: 261 Train Loss: 3.3979 (Forecasting Loss:0.2872 + XiCon Loss:3.1107 x Lambda(1.0)), Vali MSE Loss: 0.2892 Test MSE Loss: 0.2524
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4368849
	speed: 0.0518s/iter; left time: 1252.2689s
	iters: 200, epoch: 8 | loss: 3.3386972
	speed: 0.0494s/iter; left time: 1189.0849s
Epoch: 8 cost time: 13.141199350357056
Epoch: 8, Steps: 261 Train Loss: 3.4034 (Forecasting Loss:0.2873 + XiCon Loss:3.1161 x Lambda(1.0)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.2524
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.3890691
	speed: 0.0531s/iter; left time: 1269.9323s
	iters: 200, epoch: 9 | loss: 3.3828645
	speed: 0.0497s/iter; left time: 1183.3023s
Epoch: 9 cost time: 13.324095249176025
Epoch: 9, Steps: 261 Train Loss: 3.3991 (Forecasting Loss:0.2871 + XiCon Loss:3.1120 x Lambda(1.0)), Vali MSE Loss: 0.2889 Test MSE Loss: 0.2527
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4623911
	speed: 0.0529s/iter; left time: 1251.3477s
	iters: 200, epoch: 10 | loss: 3.3694217
	speed: 0.0494s/iter; left time: 1162.5849s
Epoch: 10 cost time: 13.32332444190979
Epoch: 10, Steps: 261 Train Loss: 3.3983 (Forecasting Loss:0.2873 + XiCon Loss:3.1111 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2526
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4049942
	speed: 0.0515s/iter; left time: 1205.1810s
	iters: 200, epoch: 11 | loss: 3.4343553
	speed: 0.0491s/iter; left time: 1142.4727s
Epoch: 11 cost time: 13.091543197631836
Epoch: 11, Steps: 261 Train Loss: 3.3962 (Forecasting Loss:0.2873 + XiCon Loss:3.1090 x Lambda(1.0)), Vali MSE Loss: 0.2890 Test MSE Loss: 0.2527
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.3519449
	speed: 0.0528s/iter; left time: 1222.2861s
	iters: 200, epoch: 12 | loss: 3.4481161
	speed: 0.0498s/iter; left time: 1147.7432s
Epoch: 12 cost time: 13.324216604232788
Epoch: 12, Steps: 261 Train Loss: 3.3970 (Forecasting Loss:0.2872 + XiCon Loss:3.1098 x Lambda(1.0)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2526
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4352393
	speed: 0.0527s/iter; left time: 1204.2702s
	iters: 200, epoch: 13 | loss: 3.3674254
	speed: 0.0499s/iter; left time: 1136.9087s
Epoch: 13 cost time: 13.313687562942505
Epoch: 13, Steps: 261 Train Loss: 3.4024 (Forecasting Loss:0.2871 + XiCon Loss:3.1153 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2526
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.5720458
	speed: 0.0525s/iter; left time: 1186.7449s
	iters: 200, epoch: 14 | loss: 3.3423715
	speed: 0.0500s/iter; left time: 1126.4610s
Epoch: 14 cost time: 13.357344150543213
Epoch: 14, Steps: 261 Train Loss: 3.3947 (Forecasting Loss:0.2873 + XiCon Loss:3.1074 x Lambda(1.0)), Vali MSE Loss: 0.2887 Test MSE Loss: 0.2526
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.3990030
	speed: 0.0528s/iter; left time: 1178.9138s
	iters: 200, epoch: 15 | loss: 3.4044943
	speed: 0.0505s/iter; left time: 1124.0714s
Epoch: 15 cost time: 13.38507628440857
Epoch: 15, Steps: 261 Train Loss: 3.3987 (Forecasting Loss:0.2874 + XiCon Loss:3.1113 x Lambda(1.0)), Vali MSE Loss: 0.2886 Test MSE Loss: 0.2526
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.3910885
	speed: 0.0526s/iter; left time: 1162.2297s
	iters: 200, epoch: 16 | loss: 3.4604712
	speed: 0.0496s/iter; left time: 1090.3853s
Epoch: 16 cost time: 13.323644161224365
Epoch: 16, Steps: 261 Train Loss: 3.4053 (Forecasting Loss:0.2870 + XiCon Loss:3.1182 x Lambda(1.0)), Vali MSE Loss: 0.2888 Test MSE Loss: 0.2526
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17700526118278503, mae:0.32740557193756104, mape:0.7034175992012024, mspe:18.45761489868164 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:493793
train 33505
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99997625] ~ [3.57680367e-05 1.79375995e-05]
Xi-correlation values:[0.9999132  0.99727584] ~ [0. 1.]
Autocorrelation calculation time: 18.2499
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 33505
val 10801
test 10801
	iters: 100, epoch: 1 | loss: 3.5421524
	speed: 0.0444s/iter; left time: 1153.8142s
	iters: 200, epoch: 1 | loss: 3.5848277
	speed: 0.0412s/iter; left time: 1066.4853s
Epoch: 1 cost time: 11.07193636894226
Epoch: 1, Steps: 261 Train Loss: 3.5757 (Forecasting Loss:0.3697 + XiCon Loss:3.2060 x Lambda(1.0)), Vali MSE Loss: 0.3257 Test MSE Loss: 0.2813
Validation loss decreased (inf --> 0.325738).  Saving model ...
Updating learning rate to 0.0005
	iters: 100, epoch: 2 | loss: 3.3238325
	speed: 0.0440s/iter; left time: 1132.3228s
	iters: 200, epoch: 2 | loss: 3.2759225
	speed: 0.0404s/iter; left time: 1036.5675s
Epoch: 2 cost time: 10.93962049484253
Epoch: 2, Steps: 261 Train Loss: 3.3418 (Forecasting Loss:0.2978 + XiCon Loss:3.0440 x Lambda(1.0)), Vali MSE Loss: 0.2869 Test MSE Loss: 0.2421
Validation loss decreased (0.325738 --> 0.286876).  Saving model ...
Updating learning rate to 0.00025
	iters: 100, epoch: 3 | loss: 3.3916471
	speed: 0.0435s/iter; left time: 1109.5602s
	iters: 200, epoch: 3 | loss: 3.4343770
	speed: 0.0409s/iter; left time: 1038.3783s
Epoch: 3 cost time: 10.96658992767334
Epoch: 3, Steps: 261 Train Loss: 3.4148 (Forecasting Loss:0.2934 + XiCon Loss:3.1215 x Lambda(1.0)), Vali MSE Loss: 0.2812 Test MSE Loss: 0.2445
Validation loss decreased (0.286876 --> 0.281250).  Saving model ...
Updating learning rate to 0.000125
	iters: 100, epoch: 4 | loss: 3.4788015
	speed: 0.0434s/iter; left time: 1094.9959s
	iters: 200, epoch: 4 | loss: 3.4101133
	speed: 0.0405s/iter; left time: 1018.1078s
Epoch: 4 cost time: 10.90784764289856
Epoch: 4, Steps: 261 Train Loss: 3.4055 (Forecasting Loss:0.2918 + XiCon Loss:3.1137 x Lambda(1.0)), Vali MSE Loss: 0.2814 Test MSE Loss: 0.2463
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-05
	iters: 100, epoch: 5 | loss: 3.4198198
	speed: 0.0444s/iter; left time: 1107.9216s
	iters: 200, epoch: 5 | loss: 3.4225850
	speed: 0.0404s/iter; left time: 1004.6590s
Epoch: 5 cost time: 10.982001543045044
Epoch: 5, Steps: 261 Train Loss: 3.4101 (Forecasting Loss:0.2908 + XiCon Loss:3.1192 x Lambda(1.0)), Vali MSE Loss: 0.2809 Test MSE Loss: 0.2464
Validation loss decreased (0.281250 --> 0.280907).  Saving model ...
Updating learning rate to 3.125e-05
	iters: 100, epoch: 6 | loss: 3.4038363
	speed: 0.0436s/iter; left time: 1075.8381s
	iters: 200, epoch: 6 | loss: 3.4109674
	speed: 0.0405s/iter; left time: 995.5957s
Epoch: 6 cost time: 10.895606279373169
Epoch: 6, Steps: 261 Train Loss: 3.4116 (Forecasting Loss:0.2902 + XiCon Loss:3.1214 x Lambda(1.0)), Vali MSE Loss: 0.2798 Test MSE Loss: 0.2462
Validation loss decreased (0.280907 --> 0.279758).  Saving model ...
Updating learning rate to 1.5625e-05
	iters: 100, epoch: 7 | loss: 3.4404578
	speed: 0.0436s/iter; left time: 1066.2317s
	iters: 200, epoch: 7 | loss: 3.4422975
	speed: 0.0405s/iter; left time: 985.5565s
Epoch: 7 cost time: 10.925404071807861
Epoch: 7, Steps: 261 Train Loss: 3.4106 (Forecasting Loss:0.2899 + XiCon Loss:3.1207 x Lambda(1.0)), Vali MSE Loss: 0.2792 Test MSE Loss: 0.2461
Validation loss decreased (0.279758 --> 0.279227).  Saving model ...
Updating learning rate to 7.8125e-06
	iters: 100, epoch: 8 | loss: 3.4073496
	speed: 0.0438s/iter; left time: 1060.0157s
	iters: 200, epoch: 8 | loss: 3.6189198
	speed: 0.0412s/iter; left time: 991.7710s
Epoch: 8 cost time: 11.015876054763794
Epoch: 8, Steps: 261 Train Loss: 3.4140 (Forecasting Loss:0.2898 + XiCon Loss:3.1242 x Lambda(1.0)), Vali MSE Loss: 0.2794 Test MSE Loss: 0.2461
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
	iters: 100, epoch: 9 | loss: 3.5359933
	speed: 0.0439s/iter; left time: 1050.8928s
	iters: 200, epoch: 9 | loss: 3.4814563
	speed: 0.0408s/iter; left time: 970.6029s
Epoch: 9 cost time: 10.999704122543335
Epoch: 9, Steps: 261 Train Loss: 3.4181 (Forecasting Loss:0.2898 + XiCon Loss:3.1282 x Lambda(1.0)), Vali MSE Loss: 0.2797 Test MSE Loss: 0.2462
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-06
	iters: 100, epoch: 10 | loss: 3.4038856
	speed: 0.0437s/iter; left time: 1033.7568s
	iters: 200, epoch: 10 | loss: 3.4408352
	speed: 0.0406s/iter; left time: 957.2571s
Epoch: 10 cost time: 10.906238317489624
Epoch: 10, Steps: 261 Train Loss: 3.4103 (Forecasting Loss:0.2898 + XiCon Loss:3.1205 x Lambda(1.0)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.2462
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-07
	iters: 100, epoch: 11 | loss: 3.4188204
	speed: 0.0445s/iter; left time: 1039.8594s
	iters: 200, epoch: 11 | loss: 3.4796057
	speed: 0.0408s/iter; left time: 949.1971s
Epoch: 11 cost time: 11.034290790557861
Epoch: 11, Steps: 261 Train Loss: 3.4103 (Forecasting Loss:0.2896 + XiCon Loss:3.1208 x Lambda(1.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2462
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-07
	iters: 100, epoch: 12 | loss: 3.5166335
	speed: 0.0440s/iter; left time: 1016.9248s
	iters: 200, epoch: 12 | loss: 3.5002043
	speed: 0.0407s/iter; left time: 938.3805s
Epoch: 12 cost time: 10.97148060798645
Epoch: 12, Steps: 261 Train Loss: 3.4115 (Forecasting Loss:0.2898 + XiCon Loss:3.1217 x Lambda(1.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2462
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-07
	iters: 100, epoch: 13 | loss: 3.4222450
	speed: 0.0438s/iter; left time: 1000.6756s
	iters: 200, epoch: 13 | loss: 3.4119167
	speed: 0.0405s/iter; left time: 922.9968s
Epoch: 13 cost time: 10.947819232940674
Epoch: 13, Steps: 261 Train Loss: 3.4066 (Forecasting Loss:0.2897 + XiCon Loss:3.1169 x Lambda(1.0)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.2462
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-07
	iters: 100, epoch: 14 | loss: 3.4573543
	speed: 0.0439s/iter; left time: 992.9284s
	iters: 200, epoch: 14 | loss: 3.4439614
	speed: 0.0408s/iter; left time: 917.5334s
Epoch: 14 cost time: 10.963626861572266
Epoch: 14, Steps: 261 Train Loss: 3.4107 (Forecasting Loss:0.2895 + XiCon Loss:3.1212 x Lambda(1.0)), Vali MSE Loss: 0.2795 Test MSE Loss: 0.2462
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-08
	iters: 100, epoch: 15 | loss: 3.4125245
	speed: 0.0439s/iter; left time: 980.3382s
	iters: 200, epoch: 15 | loss: 3.3618987
	speed: 0.0410s/iter; left time: 912.7790s
Epoch: 15 cost time: 11.020524024963379
Epoch: 15, Steps: 261 Train Loss: 3.4108 (Forecasting Loss:0.2896 + XiCon Loss:3.1212 x Lambda(1.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2462
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-08
	iters: 100, epoch: 16 | loss: 3.4344239
	speed: 0.0437s/iter; left time: 964.6337s
	iters: 200, epoch: 16 | loss: 3.3292243
	speed: 0.0406s/iter; left time: 892.6656s
Epoch: 16 cost time: 10.909495115280151
Epoch: 16, Steps: 261 Train Loss: 3.4095 (Forecasting Loss:0.2895 + XiCon Loss:3.1200 x Lambda(1.0)), Vali MSE Loss: 0.2794 Test MSE Loss: 0.2462
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.52587890625e-08
	iters: 100, epoch: 17 | loss: 3.3549511
	speed: 0.0436s/iter; left time: 952.4373s
	iters: 200, epoch: 17 | loss: 3.4291637
	speed: 0.0414s/iter; left time: 898.7631s
Epoch: 17 cost time: 11.020279884338379
Epoch: 17, Steps: 261 Train Loss: 3.4159 (Forecasting Loss:0.2896 + XiCon Loss:3.1263 x Lambda(1.0)), Vali MSE Loss: 0.2796 Test MSE Loss: 0.2462
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_ETTm2_ftS_sl336_ll48_pl720_dm16_nh8_el4_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10801
test shape: (84, 128, 720, 1) (84, 128, 720, 1)
test shape: (10752, 720, 1) (10752, 720, 1)
mse:0.17192772030830383, mae:0.3203084170818329, mape:0.7093325853347778, mspe:19.356245040893555 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.1730+-0.00559, MAE:0.3224+-0.00681, MAPE:0.7133+-0.01342, MSPE:19.2942+-0.72558, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
