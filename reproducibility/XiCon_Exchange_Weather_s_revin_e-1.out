Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[48], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=48, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6725
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 1.2426609992980957
Epoch: 1, Steps: 69 Train Loss: 0.3160 (Forecasting Loss:0.1324 + XiCon Loss:1.8363 x Lambda(0.1)), Vali MSE Loss: 0.2847 Test MSE Loss: 0.1490
Validation loss decreased (inf --> 0.284668).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9033021926879883
Epoch: 2, Steps: 69 Train Loss: 0.2930 (Forecasting Loss:0.1100 + XiCon Loss:1.8302 x Lambda(0.1)), Vali MSE Loss: 0.2128 Test MSE Loss: 0.1202
Validation loss decreased (0.284668 --> 0.212763).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9563045501708984
Epoch: 3, Steps: 69 Train Loss: 0.2844 (Forecasting Loss:0.1011 + XiCon Loss:1.8337 x Lambda(0.1)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1181
Validation loss decreased (0.212763 --> 0.205348).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8985931873321533
Epoch: 4, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0991 + XiCon Loss:1.8228 x Lambda(0.1)), Vali MSE Loss: 0.2027 Test MSE Loss: 0.1167
Validation loss decreased (0.205348 --> 0.202655).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9442627429962158
Epoch: 5, Steps: 69 Train Loss: 0.2806 (Forecasting Loss:0.0982 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2016 Test MSE Loss: 0.1160
Validation loss decreased (0.202655 --> 0.201639).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9880869388580322
Epoch: 6, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0980 + XiCon Loss:1.8195 x Lambda(0.1)), Vali MSE Loss: 0.2011 Test MSE Loss: 0.1157
Validation loss decreased (0.201639 --> 0.201121).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.934175968170166
Epoch: 7, Steps: 69 Train Loss: 0.2804 (Forecasting Loss:0.0976 + XiCon Loss:1.8276 x Lambda(0.1)), Vali MSE Loss: 0.2008 Test MSE Loss: 0.1155
Validation loss decreased (0.201121 --> 0.200753).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9161555767059326
Epoch: 8, Steps: 69 Train Loss: 0.2791 (Forecasting Loss:0.0976 + XiCon Loss:1.8151 x Lambda(0.1)), Vali MSE Loss: 0.2007 Test MSE Loss: 0.1154
Validation loss decreased (0.200753 --> 0.200747).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8562531471252441
Epoch: 9, Steps: 69 Train Loss: 0.2793 (Forecasting Loss:0.0976 + XiCon Loss:1.8169 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200747 --> 0.200629).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9447681903839111
Epoch: 10, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0977 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200629 --> 0.200594).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9844715595245361
Epoch: 11, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0976 + XiCon Loss:1.8252 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200594 --> 0.200581).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9850718975067139
Epoch: 12, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0973 + XiCon Loss:1.8193 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200581 --> 0.200572).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9901182651519775
Epoch: 13, Steps: 69 Train Loss: 0.2796 (Forecasting Loss:0.0973 + XiCon Loss:1.8223 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200572 --> 0.200568).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8994183540344238
Epoch: 14, Steps: 69 Train Loss: 0.2796 (Forecasting Loss:0.0976 + XiCon Loss:1.8201 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200568 --> 0.200565).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9534471035003662
Epoch: 15, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0977 + XiCon Loss:1.8231 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200565 --> 0.200565).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.9803524017333984
Epoch: 16, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0975 + XiCon Loss:1.8222 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200565 --> 0.200564).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.8887083530426025
Epoch: 17, Steps: 69 Train Loss: 0.2793 (Forecasting Loss:0.0975 + XiCon Loss:1.8175 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.945676326751709
Epoch: 18, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0974 + XiCon Loss:1.8182 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9024474620819092
Epoch: 19, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0973 + XiCon Loss:1.8192 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9177415370941162
Epoch: 20, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0979 + XiCon Loss:1.8217 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9201419353485107
Epoch: 21, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0976 + XiCon Loss:1.8163 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8166611194610596
Epoch: 22, Steps: 69 Train Loss: 0.2791 (Forecasting Loss:0.0976 + XiCon Loss:1.8152 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.900862455368042
Epoch: 23, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0976 + XiCon Loss:1.8205 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9704279899597168
Epoch: 24, Steps: 69 Train Loss: 0.2789 (Forecasting Loss:0.0972 + XiCon Loss:1.8173 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
Validation loss decreased (0.200564 --> 0.200564).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8489673137664795
Epoch: 25, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0975 + XiCon Loss:1.8245 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9404537677764893
Epoch: 26, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0973 + XiCon Loss:1.8183 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9252052307128906
Epoch: 27, Steps: 69 Train Loss: 0.2794 (Forecasting Loss:0.0976 + XiCon Loss:1.8188 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.9197084903717041
Epoch: 28, Steps: 69 Train Loss: 0.2795 (Forecasting Loss:0.0975 + XiCon Loss:1.8204 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.0117101669311523
Epoch: 29, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0974 + XiCon Loss:1.8176 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8126745223999023
Epoch: 30, Steps: 69 Train Loss: 0.2795 (Forecasting Loss:0.0977 + XiCon Loss:1.8177 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9650325775146484
Epoch: 31, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0976 + XiCon Loss:1.8162 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.941577672958374
Epoch: 32, Steps: 69 Train Loss: 0.2794 (Forecasting Loss:0.0976 + XiCon Loss:1.8176 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8155407905578613
Epoch: 33, Steps: 69 Train Loss: 0.2792 (Forecasting Loss:0.0975 + XiCon Loss:1.8170 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9695339202880859
Epoch: 34, Steps: 69 Train Loss: 0.2794 (Forecasting Loss:0.0974 + XiCon Loss:1.8192 x Lambda(0.1)), Vali MSE Loss: 0.2006 Test MSE Loss: 0.1154
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.0539674311876297, mae:0.17681248486042023, mape:0.12338093668222427, mspe:0.03595804050564766 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5676
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.979233980178833
Epoch: 1, Steps: 69 Train Loss: 0.3186 (Forecasting Loss:0.1348 + XiCon Loss:1.8374 x Lambda(0.1)), Vali MSE Loss: 0.2896 Test MSE Loss: 0.1507
Validation loss decreased (inf --> 0.289562).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8438258171081543
Epoch: 2, Steps: 69 Train Loss: 0.2961 (Forecasting Loss:0.1123 + XiCon Loss:1.8385 x Lambda(0.1)), Vali MSE Loss: 0.2161 Test MSE Loss: 0.1211
Validation loss decreased (0.289562 --> 0.216094).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.000746488571167
Epoch: 3, Steps: 69 Train Loss: 0.2854 (Forecasting Loss:0.1025 + XiCon Loss:1.8295 x Lambda(0.1)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1186
Validation loss decreased (0.216094 --> 0.207347).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.9816577434539795
Epoch: 4, Steps: 69 Train Loss: 0.2831 (Forecasting Loss:0.1004 + XiCon Loss:1.8266 x Lambda(0.1)), Vali MSE Loss: 0.2053 Test MSE Loss: 0.1178
Validation loss decreased (0.207347 --> 0.205250).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9733333587646484
Epoch: 5, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0993 + XiCon Loss:1.8294 x Lambda(0.1)), Vali MSE Loss: 0.2041 Test MSE Loss: 0.1172
Validation loss decreased (0.205250 --> 0.204092).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9197871685028076
Epoch: 6, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0991 + XiCon Loss:1.8222 x Lambda(0.1)), Vali MSE Loss: 0.2039 Test MSE Loss: 0.1170
Validation loss decreased (0.204092 --> 0.203865).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.8520348072052002
Epoch: 7, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0990 + XiCon Loss:1.8188 x Lambda(0.1)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1170
Validation loss decreased (0.203865 --> 0.203525).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8418138027191162
Epoch: 8, Steps: 69 Train Loss: 0.2815 (Forecasting Loss:0.0990 + XiCon Loss:1.8255 x Lambda(0.1)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1170
Validation loss decreased (0.203525 --> 0.203472).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9320340156555176
Epoch: 9, Steps: 69 Train Loss: 0.2806 (Forecasting Loss:0.0987 + XiCon Loss:1.8198 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203472 --> 0.203435).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9593908786773682
Epoch: 10, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0988 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203435 --> 0.203416).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8969740867614746
Epoch: 11, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0987 + XiCon Loss:1.8207 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203416 --> 0.203393).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9463882446289062
Epoch: 12, Steps: 69 Train Loss: 0.2806 (Forecasting Loss:0.0984 + XiCon Loss:1.8214 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203393 --> 0.203390).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9207701683044434
Epoch: 13, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0987 + XiCon Loss:1.8220 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203390 --> 0.203387).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9386043548583984
Epoch: 14, Steps: 69 Train Loss: 0.2806 (Forecasting Loss:0.0985 + XiCon Loss:1.8209 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203387 --> 0.203383).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9794402122497559
Epoch: 15, Steps: 69 Train Loss: 0.2813 (Forecasting Loss:0.0987 + XiCon Loss:1.8266 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203383 --> 0.203383).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.867764949798584
Epoch: 16, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0988 + XiCon Loss:1.8232 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203383 --> 0.203383).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.9809119701385498
Epoch: 17, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0988 + XiCon Loss:1.8212 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203383 --> 0.203383).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.863339900970459
Epoch: 18, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0989 + XiCon Loss:1.8253 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203383 --> 0.203382).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9571628570556641
Epoch: 19, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0985 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9748146533966064
Epoch: 20, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0987 + XiCon Loss:1.8222 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9482207298278809
Epoch: 21, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0986 + XiCon Loss:1.8248 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9312953948974609
Epoch: 22, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0986 + XiCon Loss:1.8261 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9751625061035156
Epoch: 23, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0987 + XiCon Loss:1.8253 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8677327632904053
Epoch: 24, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0987 + XiCon Loss:1.8199 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8218600749969482
Epoch: 25, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0987 + XiCon Loss:1.8223 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8657114505767822
Epoch: 26, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0987 + XiCon Loss:1.8205 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.8555939197540283
Epoch: 27, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0988 + XiCon Loss:1.8247 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8285729885101318
Epoch: 28, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0988 + XiCon Loss:1.8199 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.8410863876342773
Epoch: 29, Steps: 69 Train Loss: 0.2815 (Forecasting Loss:0.0990 + XiCon Loss:1.8251 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8629565238952637
Epoch: 30, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0985 + XiCon Loss:1.8230 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8162932395935059
Epoch: 31, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0987 + XiCon Loss:1.8208 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8438878059387207
Epoch: 32, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0984 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8016397953033447
Epoch: 33, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0986 + XiCon Loss:1.8247 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8320109844207764
Epoch: 34, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0985 + XiCon Loss:1.8192 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8119721412658691
Epoch: 35, Steps: 69 Train Loss: 0.2813 (Forecasting Loss:0.0987 + XiCon Loss:1.8252 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8526041507720947
Epoch: 36, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0985 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.815321683883667
Epoch: 37, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0983 + XiCon Loss:1.8251 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8145112991333008
Epoch: 38, Steps: 69 Train Loss: 0.2806 (Forecasting Loss:0.0985 + XiCon Loss:1.8203 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8151345252990723
Epoch: 39, Steps: 69 Train Loss: 0.2813 (Forecasting Loss:0.0986 + XiCon Loss:1.8270 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8104736804962158
Epoch: 40, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0988 + XiCon Loss:1.8206 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8204667568206787
Epoch: 41, Steps: 69 Train Loss: 0.2813 (Forecasting Loss:0.0987 + XiCon Loss:1.8262 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.8281314373016357
Epoch: 42, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0987 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9211163520812988
Epoch: 43, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0986 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8337626457214355
Epoch: 44, Steps: 69 Train Loss: 0.2813 (Forecasting Loss:0.0988 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.858544111251831
Epoch: 45, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0989 + XiCon Loss:1.8231 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8272507190704346
Epoch: 46, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0986 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.9004471302032471
Epoch: 47, Steps: 69 Train Loss: 0.2803 (Forecasting Loss:0.0983 + XiCon Loss:1.8196 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.839033842086792
Epoch: 48, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0987 + XiCon Loss:1.8208 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8222405910491943
Epoch: 49, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0986 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.852452278137207
Epoch: 50, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0987 + XiCon Loss:1.8234 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.7935421466827393
Epoch: 51, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0984 + XiCon Loss:1.8233 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.8684287071228027
Epoch: 52, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0988 + XiCon Loss:1.8216 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8534302711486816
Epoch: 53, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0985 + XiCon Loss:1.8270 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.8515791893005371
Epoch: 54, Steps: 69 Train Loss: 0.2817 (Forecasting Loss:0.0990 + XiCon Loss:1.8267 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.8483695983886719
Epoch: 55, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0987 + XiCon Loss:1.8249 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8724403381347656
Epoch: 56, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0986 + XiCon Loss:1.8223 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.8855640888214111
Epoch: 57, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0987 + XiCon Loss:1.8225 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.817474365234375
Epoch: 58, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0985 + XiCon Loss:1.8239 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.807342529296875
Epoch: 59, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0988 + XiCon Loss:1.8199 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.8129591941833496
Epoch: 60, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0986 + XiCon Loss:1.8215 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.838165283203125
Epoch: 61, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0987 + XiCon Loss:1.8240 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 0.8253629207611084
Epoch: 62, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0986 + XiCon Loss:1.8209 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.8205716609954834
Epoch: 63, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0986 + XiCon Loss:1.8220 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 1.0166583061218262
Epoch: 64, Steps: 69 Train Loss: 0.2806 (Forecasting Loss:0.0986 + XiCon Loss:1.8198 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.866417407989502
Epoch: 65, Steps: 69 Train Loss: 0.2802 (Forecasting Loss:0.0986 + XiCon Loss:1.8165 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.8932132720947266
Epoch: 66, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0986 + XiCon Loss:1.8219 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.9179320335388184
Epoch: 67, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0985 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.9305868148803711
Epoch: 68, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0984 + XiCon Loss:1.8210 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.8090453147888184
Epoch: 69, Steps: 69 Train Loss: 0.2811 (Forecasting Loss:0.0986 + XiCon Loss:1.8251 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.9743325710296631
Epoch: 70, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0988 + XiCon Loss:1.8204 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 0.9170362949371338
Epoch: 71, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0987 + XiCon Loss:1.8267 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.9575140476226807
Epoch: 72, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0988 + XiCon Loss:1.8221 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.9374747276306152
Epoch: 73, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0985 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.8722891807556152
Epoch: 74, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0987 + XiCon Loss:1.8249 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 0.986670970916748
Epoch: 75, Steps: 69 Train Loss: 0.2812 (Forecasting Loss:0.0990 + XiCon Loss:1.8222 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.9425251483917236
Epoch: 76, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0986 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.8553764820098877
Epoch: 77, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0984 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 0.9519555568695068
Epoch: 78, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0987 + XiCon Loss:1.8238 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.86940598487854
Epoch: 79, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0987 + XiCon Loss:1.8216 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 0.9669852256774902
Epoch: 80, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0987 + XiCon Loss:1.8218 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.9426538944244385
Epoch: 81, Steps: 69 Train Loss: 0.2815 (Forecasting Loss:0.0988 + XiCon Loss:1.8273 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.890739917755127
Epoch: 82, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0986 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.9797217845916748
Epoch: 83, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0988 + XiCon Loss:1.8190 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 0.8276627063751221
Epoch: 84, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0986 + XiCon Loss:1.8217 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 0.9754598140716553
Epoch: 85, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0989 + XiCon Loss:1.8202 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.9208974838256836
Epoch: 86, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0985 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 0.9029452800750732
Epoch: 87, Steps: 69 Train Loss: 0.2804 (Forecasting Loss:0.0987 + XiCon Loss:1.8170 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 0.9263238906860352
Epoch: 88, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0986 + XiCon Loss:1.8228 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 0.8097398281097412
Epoch: 89, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0984 + XiCon Loss:1.8233 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 0.970548152923584
Epoch: 90, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0986 + XiCon Loss:1.8243 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 0.9305646419525146
Epoch: 91, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0989 + XiCon Loss:1.8257 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 8.077935669463161e-31
Epoch: 92 cost time: 0.9279038906097412
Epoch: 92, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0986 + XiCon Loss:1.8227 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.0389678347315805e-31
Epoch: 93 cost time: 0.9455733299255371
Epoch: 93, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0988 + XiCon Loss:1.8259 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.0194839173657903e-31
Epoch: 94 cost time: 0.8589768409729004
Epoch: 94, Steps: 69 Train Loss: 0.2813 (Forecasting Loss:0.0988 + XiCon Loss:1.8246 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.0097419586828951e-31
Epoch: 95 cost time: 1.0032734870910645
Epoch: 95, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0986 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 5.048709793414476e-32
Epoch: 96 cost time: 0.8681867122650146
Epoch: 96, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0988 + XiCon Loss:1.8199 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.524354896707238e-32
Epoch: 97 cost time: 0.9839718341827393
Epoch: 97, Steps: 69 Train Loss: 0.2810 (Forecasting Loss:0.0989 + XiCon Loss:1.8215 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.262177448353619e-32
Epoch: 98 cost time: 0.943239688873291
Epoch: 98, Steps: 69 Train Loss: 0.2807 (Forecasting Loss:0.0985 + XiCon Loss:1.8212 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.310887241768095e-33
Epoch: 99 cost time: 0.8965942859649658
Epoch: 99, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0990 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.155443620884047e-33
Epoch: 100 cost time: 0.9635791778564453
Epoch: 100, Steps: 69 Train Loss: 0.2808 (Forecasting Loss:0.0987 + XiCon Loss:1.8217 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1170
Validation loss decreased (0.203382 --> 0.203382).  Saving model ...
Updating learning rate to 1.5777218104420236e-33
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05507117137312889, mae:0.17883534729480743, mape:0.1247919425368309, mspe:0.03653756156563759 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7238
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.813103437423706
Epoch: 1, Steps: 69 Train Loss: 0.3145 (Forecasting Loss:0.1308 + XiCon Loss:1.8366 x Lambda(0.1)), Vali MSE Loss: 0.2810 Test MSE Loss: 0.1468
Validation loss decreased (inf --> 0.280977).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.8917703628540039
Epoch: 2, Steps: 69 Train Loss: 0.2947 (Forecasting Loss:0.1114 + XiCon Loss:1.8332 x Lambda(0.1)), Vali MSE Loss: 0.2141 Test MSE Loss: 0.1216
Validation loss decreased (0.280977 --> 0.214085).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 1.038440227508545
Epoch: 3, Steps: 69 Train Loss: 0.2841 (Forecasting Loss:0.1019 + XiCon Loss:1.8226 x Lambda(0.1)), Vali MSE Loss: 0.2075 Test MSE Loss: 0.1182
Validation loss decreased (0.214085 --> 0.207508).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 1.0652525424957275
Epoch: 4, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.1002 + XiCon Loss:1.8206 x Lambda(0.1)), Vali MSE Loss: 0.2050 Test MSE Loss: 0.1170
Validation loss decreased (0.207508 --> 0.204982).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9619081020355225
Epoch: 5, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0991 + XiCon Loss:1.8263 x Lambda(0.1)), Vali MSE Loss: 0.2042 Test MSE Loss: 0.1170
Validation loss decreased (0.204982 --> 0.204174).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.9131181240081787
Epoch: 6, Steps: 69 Train Loss: 0.2816 (Forecasting Loss:0.0990 + XiCon Loss:1.8263 x Lambda(0.1)), Vali MSE Loss: 0.2040 Test MSE Loss: 0.1167
Validation loss decreased (0.204174 --> 0.203966).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.9643054008483887
Epoch: 7, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0988 + XiCon Loss:1.8344 x Lambda(0.1)), Vali MSE Loss: 0.2035 Test MSE Loss: 0.1165
Validation loss decreased (0.203966 --> 0.203524).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.8987860679626465
Epoch: 8, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0986 + XiCon Loss:1.8323 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1163
Validation loss decreased (0.203524 --> 0.203407).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.9518678188323975
Epoch: 9, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0983 + XiCon Loss:1.8350 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1163
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9203677177429199
Epoch: 10, Steps: 69 Train Loss: 0.2825 (Forecasting Loss:0.0986 + XiCon Loss:1.8392 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1163
Validation loss decreased (0.203407 --> 0.203382).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9434747695922852
Epoch: 11, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0986 + XiCon Loss:1.8335 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203382 --> 0.203371).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9399590492248535
Epoch: 12, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0984 + XiCon Loss:1.8340 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203371 --> 0.203362).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.8102021217346191
Epoch: 13, Steps: 69 Train Loss: 0.2816 (Forecasting Loss:0.0985 + XiCon Loss:1.8314 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203362 --> 0.203360).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.9337739944458008
Epoch: 14, Steps: 69 Train Loss: 0.2819 (Forecasting Loss:0.0986 + XiCon Loss:1.8328 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203360 --> 0.203359).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9673957824707031
Epoch: 15, Steps: 69 Train Loss: 0.2816 (Forecasting Loss:0.0984 + XiCon Loss:1.8323 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203359 --> 0.203357).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8755667209625244
Epoch: 16, Steps: 69 Train Loss: 0.2825 (Forecasting Loss:0.0982 + XiCon Loss:1.8428 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.953075647354126
Epoch: 17, Steps: 69 Train Loss: 0.2823 (Forecasting Loss:0.0987 + XiCon Loss:1.8360 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.9510180950164795
Epoch: 18, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0985 + XiCon Loss:1.8367 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8991875648498535
Epoch: 19, Steps: 69 Train Loss: 0.2817 (Forecasting Loss:0.0983 + XiCon Loss:1.8335 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9096863269805908
Epoch: 20, Steps: 69 Train Loss: 0.2825 (Forecasting Loss:0.0986 + XiCon Loss:1.8393 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.8228578567504883
Epoch: 21, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0984 + XiCon Loss:1.8385 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.9982891082763672
Epoch: 22, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0986 + XiCon Loss:1.8363 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.9195001125335693
Epoch: 23, Steps: 69 Train Loss: 0.2819 (Forecasting Loss:0.0984 + XiCon Loss:1.8345 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9478509426116943
Epoch: 24, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0983 + XiCon Loss:1.8356 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.9667437076568604
Epoch: 25, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0983 + XiCon Loss:1.8371 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.8405771255493164
Epoch: 26, Steps: 69 Train Loss: 0.2823 (Forecasting Loss:0.0984 + XiCon Loss:1.8388 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.982907772064209
Epoch: 27, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0984 + XiCon Loss:1.8381 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8384323120117188
Epoch: 28, Steps: 69 Train Loss: 0.2824 (Forecasting Loss:0.0983 + XiCon Loss:1.8410 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.9409945011138916
Epoch: 29, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0984 + XiCon Loss:1.8360 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 1.0019817352294922
Epoch: 30, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0983 + XiCon Loss:1.8358 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8498387336730957
Epoch: 31, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0986 + XiCon Loss:1.8357 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9348363876342773
Epoch: 32, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0985 + XiCon Loss:1.8335 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.9219691753387451
Epoch: 33, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0983 + XiCon Loss:1.8377 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8586089611053467
Epoch: 34, Steps: 69 Train Loss: 0.2817 (Forecasting Loss:0.0986 + XiCon Loss:1.8309 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.9535746574401855
Epoch: 35, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0985 + XiCon Loss:1.8371 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8579440116882324
Epoch: 36, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0983 + XiCon Loss:1.8369 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9329643249511719
Epoch: 37, Steps: 69 Train Loss: 0.2821 (Forecasting Loss:0.0985 + XiCon Loss:1.8357 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.9263386726379395
Epoch: 38, Steps: 69 Train Loss: 0.2815 (Forecasting Loss:0.0980 + XiCon Loss:1.8347 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8236253261566162
Epoch: 39, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0985 + XiCon Loss:1.8370 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9761016368865967
Epoch: 40, Steps: 69 Train Loss: 0.2817 (Forecasting Loss:0.0985 + XiCon Loss:1.8325 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9433832168579102
Epoch: 41, Steps: 69 Train Loss: 0.2821 (Forecasting Loss:0.0985 + XiCon Loss:1.8362 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.9369251728057861
Epoch: 42, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0985 + XiCon Loss:1.8327 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.9324634075164795
Epoch: 43, Steps: 69 Train Loss: 0.2824 (Forecasting Loss:0.0984 + XiCon Loss:1.8397 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.9105832576751709
Epoch: 44, Steps: 69 Train Loss: 0.2823 (Forecasting Loss:0.0987 + XiCon Loss:1.8352 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.9479022026062012
Epoch: 45, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0985 + XiCon Loss:1.8358 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
Validation loss decreased (0.203357 --> 0.203357).  Saving model ...
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.9547159671783447
Epoch: 46, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0986 + XiCon Loss:1.8325 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8495678901672363
Epoch: 47, Steps: 69 Train Loss: 0.2814 (Forecasting Loss:0.0986 + XiCon Loss:1.8282 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.9112322330474854
Epoch: 48, Steps: 69 Train Loss: 0.2824 (Forecasting Loss:0.0986 + XiCon Loss:1.8382 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.941849946975708
Epoch: 49, Steps: 69 Train Loss: 0.2822 (Forecasting Loss:0.0986 + XiCon Loss:1.8356 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8466672897338867
Epoch: 50, Steps: 69 Train Loss: 0.2821 (Forecasting Loss:0.0982 + XiCon Loss:1.8387 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.9184973239898682
Epoch: 51, Steps: 69 Train Loss: 0.2818 (Forecasting Loss:0.0982 + XiCon Loss:1.8360 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 6 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.9673135280609131
Epoch: 52, Steps: 69 Train Loss: 0.2825 (Forecasting Loss:0.0985 + XiCon Loss:1.8404 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8453340530395508
Epoch: 53, Steps: 69 Train Loss: 0.2820 (Forecasting Loss:0.0985 + XiCon Loss:1.8349 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.9317491054534912
Epoch: 54, Steps: 69 Train Loss: 0.2816 (Forecasting Loss:0.0984 + XiCon Loss:1.8323 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.9712784290313721
Epoch: 55, Steps: 69 Train Loss: 0.2817 (Forecasting Loss:0.0984 + XiCon Loss:1.8332 x Lambda(0.1)), Vali MSE Loss: 0.2034 Test MSE Loss: 0.1162
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05457518994808197, mae:0.17788788676261902, mape:0.12414976954460144, mspe:0.03639940544962883 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5857
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.8457551002502441
Epoch: 1, Steps: 69 Train Loss: 0.3206 (Forecasting Loss:0.1367 + XiCon Loss:1.8384 x Lambda(0.1)), Vali MSE Loss: 0.2944 Test MSE Loss: 0.1512
Validation loss decreased (inf --> 0.294391).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9368863105773926
Epoch: 2, Steps: 69 Train Loss: 0.2960 (Forecasting Loss:0.1132 + XiCon Loss:1.8286 x Lambda(0.1)), Vali MSE Loss: 0.2113 Test MSE Loss: 0.1201
Validation loss decreased (0.294391 --> 0.211253).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.9476521015167236
Epoch: 3, Steps: 69 Train Loss: 0.2840 (Forecasting Loss:0.1013 + XiCon Loss:1.8264 x Lambda(0.1)), Vali MSE Loss: 0.2045 Test MSE Loss: 0.1170
Validation loss decreased (0.211253 --> 0.204549).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.8523476123809814
Epoch: 4, Steps: 69 Train Loss: 0.2809 (Forecasting Loss:0.0992 + XiCon Loss:1.8171 x Lambda(0.1)), Vali MSE Loss: 0.2029 Test MSE Loss: 0.1160
Validation loss decreased (0.204549 --> 0.202917).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.9417970180511475
Epoch: 5, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0982 + XiCon Loss:1.8174 x Lambda(0.1)), Vali MSE Loss: 0.2020 Test MSE Loss: 0.1157
Validation loss decreased (0.202917 --> 0.202004).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.8708372116088867
Epoch: 6, Steps: 69 Train Loss: 0.2802 (Forecasting Loss:0.0981 + XiCon Loss:1.8207 x Lambda(0.1)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1157
Validation loss decreased (0.202004 --> 0.201533).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 1.0049681663513184
Epoch: 7, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0979 + XiCon Loss:1.8198 x Lambda(0.1)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1155
Validation loss decreased (0.201533 --> 0.201514).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9703512191772461
Epoch: 8, Steps: 69 Train Loss: 0.2803 (Forecasting Loss:0.0979 + XiCon Loss:1.8233 x Lambda(0.1)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1155
Validation loss decreased (0.201514 --> 0.201472).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.866790771484375
Epoch: 9, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0978 + XiCon Loss:1.8195 x Lambda(0.1)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 1.0040640830993652
Epoch: 10, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0976 + XiCon Loss:1.8204 x Lambda(0.1)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1154
Validation loss decreased (0.201472 --> 0.201461).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.9309976100921631
Epoch: 11, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0979 + XiCon Loss:1.8187 x Lambda(0.1)), Vali MSE Loss: 0.2015 Test MSE Loss: 0.1154
Validation loss decreased (0.201461 --> 0.201450).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.9352884292602539
Epoch: 12, Steps: 69 Train Loss: 0.2795 (Forecasting Loss:0.0979 + XiCon Loss:1.8161 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201450 --> 0.201448).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 0.9909465312957764
Epoch: 13, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0982 + XiCon Loss:1.8182 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201448 --> 0.201446).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8866486549377441
Epoch: 14, Steps: 69 Train Loss: 0.2794 (Forecasting Loss:0.0977 + XiCon Loss:1.8174 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201446 --> 0.201445).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.9629414081573486
Epoch: 15, Steps: 69 Train Loss: 0.2802 (Forecasting Loss:0.0977 + XiCon Loss:1.8250 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201445 --> 0.201445).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.7954702377319336
Epoch: 16, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0979 + XiCon Loss:1.8207 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201445 --> 0.201444).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 1.00384521484375
Epoch: 17, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0980 + XiCon Loss:1.8253 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.964979887008667
Epoch: 18, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0980 + XiCon Loss:1.8197 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.9810194969177246
Epoch: 19, Steps: 69 Train Loss: 0.2795 (Forecasting Loss:0.0980 + XiCon Loss:1.8151 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.9323635101318359
Epoch: 20, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0978 + XiCon Loss:1.8207 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.9277191162109375
Epoch: 21, Steps: 69 Train Loss: 0.2803 (Forecasting Loss:0.0976 + XiCon Loss:1.8263 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 1.013179063796997
Epoch: 22, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0979 + XiCon Loss:1.8216 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8266642093658447
Epoch: 23, Steps: 69 Train Loss: 0.2794 (Forecasting Loss:0.0977 + XiCon Loss:1.8165 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.9394340515136719
Epoch: 24, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0978 + XiCon Loss:1.8193 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8682246208190918
Epoch: 25, Steps: 69 Train Loss: 0.2803 (Forecasting Loss:0.0981 + XiCon Loss:1.8220 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.9837501049041748
Epoch: 26, Steps: 69 Train Loss: 0.2802 (Forecasting Loss:0.0980 + XiCon Loss:1.8215 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.9669933319091797
Epoch: 27, Steps: 69 Train Loss: 0.2796 (Forecasting Loss:0.0981 + XiCon Loss:1.8155 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.865997314453125
Epoch: 28, Steps: 69 Train Loss: 0.2794 (Forecasting Loss:0.0974 + XiCon Loss:1.8203 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 1.0193696022033691
Epoch: 29, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0980 + XiCon Loss:1.8207 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8366796970367432
Epoch: 30, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0979 + XiCon Loss:1.8191 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.9724853038787842
Epoch: 31, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0978 + XiCon Loss:1.8229 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.9034430980682373
Epoch: 32, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0977 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.877525806427002
Epoch: 33, Steps: 69 Train Loss: 0.2802 (Forecasting Loss:0.0976 + XiCon Loss:1.8255 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.9367456436157227
Epoch: 34, Steps: 69 Train Loss: 0.2800 (Forecasting Loss:0.0980 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.9309799671173096
Epoch: 35, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0979 + XiCon Loss:1.8259 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8225784301757812
Epoch: 36, Steps: 69 Train Loss: 0.2795 (Forecasting Loss:0.0977 + XiCon Loss:1.8174 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.9545063972473145
Epoch: 37, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0977 + XiCon Loss:1.8220 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 1.0032076835632324
Epoch: 38, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0976 + XiCon Loss:1.8233 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.975975751876831
Epoch: 39, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0977 + XiCon Loss:1.8215 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.9383950233459473
Epoch: 40, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0979 + XiCon Loss:1.8217 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.8753478527069092
Epoch: 41, Steps: 69 Train Loss: 0.2796 (Forecasting Loss:0.0979 + XiCon Loss:1.8171 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.9609508514404297
Epoch: 42, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0979 + XiCon Loss:1.8214 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8315069675445557
Epoch: 43, Steps: 69 Train Loss: 0.2805 (Forecasting Loss:0.0979 + XiCon Loss:1.8262 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.9229061603546143
Epoch: 44, Steps: 69 Train Loss: 0.2796 (Forecasting Loss:0.0977 + XiCon Loss:1.8188 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.9378020763397217
Epoch: 45, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0977 + XiCon Loss:1.8220 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8502981662750244
Epoch: 46, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0979 + XiCon Loss:1.8181 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.9902050495147705
Epoch: 47, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0978 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.8752551078796387
Epoch: 48, Steps: 69 Train Loss: 0.2803 (Forecasting Loss:0.0978 + XiCon Loss:1.8242 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
Validation loss decreased (0.201444 --> 0.201444).  Saving model ...
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.9416470527648926
Epoch: 49, Steps: 69 Train Loss: 0.2799 (Forecasting Loss:0.0980 + XiCon Loss:1.8189 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.9274625778198242
Epoch: 50, Steps: 69 Train Loss: 0.2795 (Forecasting Loss:0.0975 + XiCon Loss:1.8192 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.956171989440918
Epoch: 51, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0978 + XiCon Loss:1.8230 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 3 out of 10
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.9682683944702148
Epoch: 52, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0978 + XiCon Loss:1.8229 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8154890537261963
Epoch: 53, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0977 + XiCon Loss:1.8205 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.9322471618652344
Epoch: 54, Steps: 69 Train Loss: 0.2798 (Forecasting Loss:0.0979 + XiCon Loss:1.8190 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.9049263000488281
Epoch: 55, Steps: 69 Train Loss: 0.2801 (Forecasting Loss:0.0978 + XiCon Loss:1.8233 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 7 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8214519023895264
Epoch: 56, Steps: 69 Train Loss: 0.2797 (Forecasting Loss:0.0978 + XiCon Loss:1.8187 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.9382181167602539
Epoch: 57, Steps: 69 Train Loss: 0.2796 (Forecasting Loss:0.0978 + XiCon Loss:1.8182 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.9120938777923584
Epoch: 58, Steps: 69 Train Loss: 0.2803 (Forecasting Loss:0.0977 + XiCon Loss:1.8259 x Lambda(0.1)), Vali MSE Loss: 0.2014 Test MSE Loss: 0.1154
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.05405188724398613, mae:0.17676743865013123, mape:0.12342263758182526, mspe:0.03609814494848251 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:8513
train 4457
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.7518
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4457
val 1472
test 1470
Epoch: 1 cost time: 0.9031167030334473
Epoch: 1, Steps: 69 Train Loss: 0.3139 (Forecasting Loss:0.1305 + XiCon Loss:1.8340 x Lambda(0.1)), Vali MSE Loss: 0.2801 Test MSE Loss: 0.1491
Validation loss decreased (inf --> 0.280073).  Saving model ...
Updating learning rate to 0.001
Epoch: 2 cost time: 0.9789612293243408
Epoch: 2, Steps: 69 Train Loss: 0.2925 (Forecasting Loss:0.1095 + XiCon Loss:1.8297 x Lambda(0.1)), Vali MSE Loss: 0.2105 Test MSE Loss: 0.1203
Validation loss decreased (0.280073 --> 0.210548).  Saving model ...
Updating learning rate to 0.0005
Epoch: 3 cost time: 0.856874942779541
Epoch: 3, Steps: 69 Train Loss: 0.2833 (Forecasting Loss:0.1008 + XiCon Loss:1.8247 x Lambda(0.1)), Vali MSE Loss: 0.2073 Test MSE Loss: 0.1195
Validation loss decreased (0.210548 --> 0.207265).  Saving model ...
Updating learning rate to 0.00025
Epoch: 4 cost time: 0.951075553894043
Epoch: 4, Steps: 69 Train Loss: 0.2848 (Forecasting Loss:0.0998 + XiCon Loss:1.8506 x Lambda(0.1)), Vali MSE Loss: 0.2059 Test MSE Loss: 0.1189
Validation loss decreased (0.207265 --> 0.205882).  Saving model ...
Updating learning rate to 0.000125
Epoch: 5 cost time: 0.929661750793457
Epoch: 5, Steps: 69 Train Loss: 0.2845 (Forecasting Loss:0.0990 + XiCon Loss:1.8541 x Lambda(0.1)), Vali MSE Loss: 0.2054 Test MSE Loss: 0.1186
Validation loss decreased (0.205882 --> 0.205394).  Saving model ...
Updating learning rate to 6.25e-05
Epoch: 6 cost time: 0.7850887775421143
Epoch: 6, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0990 + XiCon Loss:1.8670 x Lambda(0.1)), Vali MSE Loss: 0.2051 Test MSE Loss: 0.1185
Validation loss decreased (0.205394 --> 0.205073).  Saving model ...
Updating learning rate to 3.125e-05
Epoch: 7 cost time: 0.9559071063995361
Epoch: 7, Steps: 69 Train Loss: 0.2852 (Forecasting Loss:0.0989 + XiCon Loss:1.8634 x Lambda(0.1)), Vali MSE Loss: 0.2049 Test MSE Loss: 0.1185
Validation loss decreased (0.205073 --> 0.204864).  Saving model ...
Updating learning rate to 1.5625e-05
Epoch: 8 cost time: 0.9374630451202393
Epoch: 8, Steps: 69 Train Loss: 0.2855 (Forecasting Loss:0.0986 + XiCon Loss:1.8696 x Lambda(0.1)), Vali MSE Loss: 0.2048 Test MSE Loss: 0.1185
Validation loss decreased (0.204864 --> 0.204763).  Saving model ...
Updating learning rate to 7.8125e-06
Epoch: 9 cost time: 0.8300347328186035
Epoch: 9, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0988 + XiCon Loss:1.8765 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204763 --> 0.204739).  Saving model ...
Updating learning rate to 3.90625e-06
Epoch: 10 cost time: 0.9630966186523438
Epoch: 10, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0989 + XiCon Loss:1.8673 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204739 --> 0.204717).  Saving model ...
Updating learning rate to 1.953125e-06
Epoch: 11 cost time: 0.8945426940917969
Epoch: 11, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0989 + XiCon Loss:1.8676 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204717 --> 0.204708).  Saving model ...
Updating learning rate to 9.765625e-07
Epoch: 12 cost time: 0.8764731884002686
Epoch: 12, Steps: 69 Train Loss: 0.2863 (Forecasting Loss:0.0989 + XiCon Loss:1.8735 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204708 --> 0.204704).  Saving model ...
Updating learning rate to 4.8828125e-07
Epoch: 13 cost time: 1.011869192123413
Epoch: 13, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0988 + XiCon Loss:1.8769 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204704 --> 0.204700).  Saving model ...
Updating learning rate to 2.44140625e-07
Epoch: 14 cost time: 0.8443081378936768
Epoch: 14, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0987 + XiCon Loss:1.8779 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204700 --> 0.204699).  Saving model ...
Updating learning rate to 1.220703125e-07
Epoch: 15 cost time: 0.8591468334197998
Epoch: 15, Steps: 69 Train Loss: 0.2863 (Forecasting Loss:0.0989 + XiCon Loss:1.8741 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204699 --> 0.204698).  Saving model ...
Updating learning rate to 6.103515625e-08
Epoch: 16 cost time: 0.8767039775848389
Epoch: 16, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0988 + XiCon Loss:1.8731 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 3.0517578125e-08
Epoch: 17 cost time: 0.837500810623169
Epoch: 17, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0988 + XiCon Loss:1.8682 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.52587890625e-08
Epoch: 18 cost time: 0.809373140335083
Epoch: 18, Steps: 69 Train Loss: 0.2849 (Forecasting Loss:0.0987 + XiCon Loss:1.8628 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 7.62939453125e-09
Epoch: 19 cost time: 0.8766229152679443
Epoch: 19, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0990 + XiCon Loss:1.8661 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 3.814697265625e-09
Epoch: 20 cost time: 0.8686883449554443
Epoch: 20, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0990 + XiCon Loss:1.8680 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.9073486328125e-09
Epoch: 21 cost time: 0.895531177520752
Epoch: 21, Steps: 69 Train Loss: 0.2855 (Forecasting Loss:0.0987 + XiCon Loss:1.8674 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 9.5367431640625e-10
Epoch: 22 cost time: 0.8789465427398682
Epoch: 22, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0988 + XiCon Loss:1.8725 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 4.76837158203125e-10
Epoch: 23 cost time: 0.8942708969116211
Epoch: 23, Steps: 69 Train Loss: 0.2863 (Forecasting Loss:0.0988 + XiCon Loss:1.8749 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 2.384185791015625e-10
Epoch: 24 cost time: 0.8239970207214355
Epoch: 24, Steps: 69 Train Loss: 0.2860 (Forecasting Loss:0.0990 + XiCon Loss:1.8705 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.1920928955078125e-10
Epoch: 25 cost time: 0.8322851657867432
Epoch: 25, Steps: 69 Train Loss: 0.2855 (Forecasting Loss:0.0990 + XiCon Loss:1.8655 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 5.960464477539063e-11
Epoch: 26 cost time: 0.830695390701294
Epoch: 26, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0990 + XiCon Loss:1.8755 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 2.980232238769531e-11
Epoch: 27 cost time: 0.824932336807251
Epoch: 27, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0987 + XiCon Loss:1.8730 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.4901161193847657e-11
Epoch: 28 cost time: 0.8619916439056396
Epoch: 28, Steps: 69 Train Loss: 0.2854 (Forecasting Loss:0.0989 + XiCon Loss:1.8650 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 7.450580596923828e-12
Epoch: 29 cost time: 0.912468433380127
Epoch: 29, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0989 + XiCon Loss:1.8702 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-12
Epoch: 30 cost time: 0.8523910045623779
Epoch: 30, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0991 + XiCon Loss:1.8684 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.862645149230957e-12
Epoch: 31 cost time: 0.8234953880310059
Epoch: 31, Steps: 69 Train Loss: 0.2869 (Forecasting Loss:0.0991 + XiCon Loss:1.8772 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.313225746154785e-13
Epoch: 32 cost time: 0.8505859375
Epoch: 32, Steps: 69 Train Loss: 0.2870 (Forecasting Loss:0.0989 + XiCon Loss:1.8805 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 4.656612873077393e-13
Epoch: 33 cost time: 0.8948726654052734
Epoch: 33, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0987 + XiCon Loss:1.8707 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.3283064365386963e-13
Epoch: 34 cost time: 0.8246104717254639
Epoch: 34, Steps: 69 Train Loss: 0.2869 (Forecasting Loss:0.0988 + XiCon Loss:1.8807 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1641532182693482e-13
Epoch: 35 cost time: 0.8487796783447266
Epoch: 35, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0992 + XiCon Loss:1.8735 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.820766091346741e-14
Epoch: 36 cost time: 0.8655552864074707
Epoch: 36, Steps: 69 Train Loss: 0.2852 (Forecasting Loss:0.0985 + XiCon Loss:1.8669 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9103830456733704e-14
Epoch: 37 cost time: 0.8225765228271484
Epoch: 37, Steps: 69 Train Loss: 0.2864 (Forecasting Loss:0.0987 + XiCon Loss:1.8769 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.4551915228366852e-14
Epoch: 38 cost time: 0.8839015960693359
Epoch: 38, Steps: 69 Train Loss: 0.2866 (Forecasting Loss:0.0988 + XiCon Loss:1.8784 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 7.275957614183426e-15
Epoch: 39 cost time: 0.8742856979370117
Epoch: 39, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0989 + XiCon Loss:1.8699 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.637978807091713e-15
Epoch: 40 cost time: 0.8282785415649414
Epoch: 40, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0989 + XiCon Loss:1.8696 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.8189894035458565e-15
Epoch: 41 cost time: 0.9081754684448242
Epoch: 41, Steps: 69 Train Loss: 0.2853 (Forecasting Loss:0.0987 + XiCon Loss:1.8655 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.094947017729283e-16
Epoch: 42 cost time: 0.794865608215332
Epoch: 42, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0991 + XiCon Loss:1.8716 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.547473508864641e-16
Epoch: 43 cost time: 0.8582231998443604
Epoch: 43, Steps: 69 Train Loss: 0.2855 (Forecasting Loss:0.0988 + XiCon Loss:1.8666 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 2.2737367544323206e-16
Epoch: 44 cost time: 0.8524796962738037
Epoch: 44, Steps: 69 Train Loss: 0.2866 (Forecasting Loss:0.0989 + XiCon Loss:1.8769 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1368683772161603e-16
Epoch: 45 cost time: 0.8369865417480469
Epoch: 45, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0989 + XiCon Loss:1.8706 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.684341886080802e-17
Epoch: 46 cost time: 0.8056907653808594
Epoch: 46, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0989 + XiCon Loss:1.8685 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.842170943040401e-17
Epoch: 47 cost time: 0.8350017070770264
Epoch: 47, Steps: 69 Train Loss: 0.2866 (Forecasting Loss:0.0988 + XiCon Loss:1.8785 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.4210854715202004e-17
Epoch: 48 cost time: 0.7886395454406738
Epoch: 48, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0988 + XiCon Loss:1.8678 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 7.105427357601002e-18
Epoch: 49 cost time: 0.8318417072296143
Epoch: 49, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0987 + XiCon Loss:1.8715 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 3.552713678800501e-18
Epoch: 50 cost time: 0.8015639781951904
Epoch: 50, Steps: 69 Train Loss: 0.2864 (Forecasting Loss:0.0988 + XiCon Loss:1.8766 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7763568394002505e-18
Epoch: 51 cost time: 0.8409483432769775
Epoch: 51, Steps: 69 Train Loss: 0.2850 (Forecasting Loss:0.0988 + XiCon Loss:1.8621 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 8.881784197001253e-19
Epoch: 52 cost time: 0.811739444732666
Epoch: 52, Steps: 69 Train Loss: 0.2860 (Forecasting Loss:0.0989 + XiCon Loss:1.8711 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 4.440892098500626e-19
Epoch: 53 cost time: 0.8918943405151367
Epoch: 53, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0991 + XiCon Loss:1.8744 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.220446049250313e-19
Epoch: 54 cost time: 0.9889535903930664
Epoch: 54, Steps: 69 Train Loss: 0.2860 (Forecasting Loss:0.0990 + XiCon Loss:1.8706 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1102230246251566e-19
Epoch: 55 cost time: 0.8911573886871338
Epoch: 55, Steps: 69 Train Loss: 0.2853 (Forecasting Loss:0.0987 + XiCon Loss:1.8655 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.551115123125783e-20
Epoch: 56 cost time: 0.8236947059631348
Epoch: 56, Steps: 69 Train Loss: 0.2866 (Forecasting Loss:0.0990 + XiCon Loss:1.8762 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 2.7755575615628914e-20
Epoch: 57 cost time: 0.9623727798461914
Epoch: 57, Steps: 69 Train Loss: 0.2860 (Forecasting Loss:0.0989 + XiCon Loss:1.8713 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3877787807814457e-20
Epoch: 58 cost time: 0.9531424045562744
Epoch: 58, Steps: 69 Train Loss: 0.2863 (Forecasting Loss:0.0987 + XiCon Loss:1.8758 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 6.938893903907229e-21
Epoch: 59 cost time: 0.8379514217376709
Epoch: 59, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0989 + XiCon Loss:1.8672 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 3.469446951953614e-21
Epoch: 60 cost time: 0.9473803043365479
Epoch: 60, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0990 + XiCon Loss:1.8673 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.734723475976807e-21
Epoch: 61 cost time: 0.9453814029693604
Epoch: 61, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0990 + XiCon Loss:1.8717 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.673617379884036e-22
Epoch: 62 cost time: 0.8987820148468018
Epoch: 62, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0988 + XiCon Loss:1.8676 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.336808689942018e-22
Epoch: 63 cost time: 0.9458074569702148
Epoch: 63, Steps: 69 Train Loss: 0.2851 (Forecasting Loss:0.0989 + XiCon Loss:1.8628 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 2.168404344971009e-22
Epoch: 64 cost time: 0.8417227268218994
Epoch: 64, Steps: 69 Train Loss: 0.2859 (Forecasting Loss:0.0989 + XiCon Loss:1.8700 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.0842021724855045e-22
Epoch: 65 cost time: 0.9660053253173828
Epoch: 65, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0988 + XiCon Loss:1.8739 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.421010862427522e-23
Epoch: 66 cost time: 0.9359817504882812
Epoch: 66, Steps: 69 Train Loss: 0.2863 (Forecasting Loss:0.0988 + XiCon Loss:1.8742 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.710505431213761e-23
Epoch: 67 cost time: 0.9496133327484131
Epoch: 67, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0989 + XiCon Loss:1.8672 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3552527156068806e-23
Epoch: 68 cost time: 0.9339034557342529
Epoch: 68, Steps: 69 Train Loss: 0.2860 (Forecasting Loss:0.0989 + XiCon Loss:1.8710 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.776263578034403e-24
Epoch: 69 cost time: 0.8987455368041992
Epoch: 69, Steps: 69 Train Loss: 0.2864 (Forecasting Loss:0.0988 + XiCon Loss:1.8759 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.3881317890172014e-24
Epoch: 70 cost time: 0.9970252513885498
Epoch: 70, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0989 + XiCon Loss:1.8735 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.6940658945086007e-24
Epoch: 71 cost time: 0.9899137020111084
Epoch: 71, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0988 + XiCon Loss:1.8728 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 8.470329472543004e-25
Epoch: 72 cost time: 0.9853944778442383
Epoch: 72, Steps: 69 Train Loss: 0.2869 (Forecasting Loss:0.0989 + XiCon Loss:1.8798 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.235164736271502e-25
Epoch: 73 cost time: 0.9127533435821533
Epoch: 73, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0988 + XiCon Loss:1.8724 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.117582368135751e-25
Epoch: 74 cost time: 0.8156499862670898
Epoch: 74, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0988 + XiCon Loss:1.8746 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.0587911840678754e-25
Epoch: 75 cost time: 1.0011262893676758
Epoch: 75, Steps: 69 Train Loss: 0.2873 (Forecasting Loss:0.0990 + XiCon Loss:1.8835 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.293955920339377e-26
Epoch: 76 cost time: 0.9457380771636963
Epoch: 76, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0990 + XiCon Loss:1.8717 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.6469779601696886e-26
Epoch: 77 cost time: 0.8974711894989014
Epoch: 77, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0990 + XiCon Loss:1.8687 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.3234889800848443e-26
Epoch: 78 cost time: 0.9758260250091553
Epoch: 78, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0990 + XiCon Loss:1.8707 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.617444900424222e-27
Epoch: 79 cost time: 0.8023402690887451
Epoch: 79, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0988 + XiCon Loss:1.8722 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 3.308722450212111e-27
Epoch: 80 cost time: 0.9535074234008789
Epoch: 80, Steps: 69 Train Loss: 0.2849 (Forecasting Loss:0.0989 + XiCon Loss:1.8599 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6543612251060554e-27
Epoch: 81 cost time: 0.9659600257873535
Epoch: 81, Steps: 69 Train Loss: 0.2855 (Forecasting Loss:0.0986 + XiCon Loss:1.8689 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.271806125530277e-28
Epoch: 82 cost time: 0.8699204921722412
Epoch: 82, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0988 + XiCon Loss:1.8701 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 4.1359030627651385e-28
Epoch: 83 cost time: 0.9565484523773193
Epoch: 83, Steps: 69 Train Loss: 0.2851 (Forecasting Loss:0.0984 + XiCon Loss:1.8661 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0679515313825692e-28
Epoch: 84 cost time: 0.8814442157745361
Epoch: 84, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0990 + XiCon Loss:1.8712 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0339757656912846e-28
Epoch: 85 cost time: 0.9584894180297852
Epoch: 85, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0990 + XiCon Loss:1.8708 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.169878828456423e-29
Epoch: 86 cost time: 0.9549322128295898
Epoch: 86, Steps: 69 Train Loss: 0.2865 (Forecasting Loss:0.0990 + XiCon Loss:1.8749 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.5849394142282115e-29
Epoch: 87 cost time: 0.9397304058074951
Epoch: 87, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0987 + XiCon Loss:1.8713 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 1.2924697071141058e-29
Epoch: 88 cost time: 0.9858689308166504
Epoch: 88, Steps: 69 Train Loss: 0.2867 (Forecasting Loss:0.0988 + XiCon Loss:1.8790 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 6.462348535570529e-30
Epoch: 89 cost time: 0.8337783813476562
Epoch: 89, Steps: 69 Train Loss: 0.2855 (Forecasting Loss:0.0986 + XiCon Loss:1.8690 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 3.2311742677852644e-30
Epoch: 90 cost time: 0.9748985767364502
Epoch: 90, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0987 + XiCon Loss:1.8710 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.6155871338926322e-30
Epoch: 91 cost time: 0.9936466217041016
Epoch: 91, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0987 + XiCon Loss:1.8690 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 8.077935669463161e-31
Epoch: 92 cost time: 0.9582617282867432
Epoch: 92, Steps: 69 Train Loss: 0.2858 (Forecasting Loss:0.0989 + XiCon Loss:1.8691 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
Validation loss decreased (0.204698 --> 0.204698).  Saving model ...
Updating learning rate to 4.0389678347315805e-31
Epoch: 93 cost time: 0.9526383876800537
Epoch: 93, Steps: 69 Train Loss: 0.2863 (Forecasting Loss:0.0987 + XiCon Loss:1.8756 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.0194839173657903e-31
Epoch: 94 cost time: 0.8652589321136475
Epoch: 94, Steps: 69 Train Loss: 0.2862 (Forecasting Loss:0.0991 + XiCon Loss:1.8709 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.0097419586828951e-31
Epoch: 95 cost time: 0.9208745956420898
Epoch: 95, Steps: 69 Train Loss: 0.2857 (Forecasting Loss:0.0988 + XiCon Loss:1.8689 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.048709793414476e-32
Epoch: 96 cost time: 0.9206581115722656
Epoch: 96, Steps: 69 Train Loss: 0.2856 (Forecasting Loss:0.0986 + XiCon Loss:1.8698 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.524354896707238e-32
Epoch: 97 cost time: 0.8272664546966553
Epoch: 97, Steps: 69 Train Loss: 0.2866 (Forecasting Loss:0.0987 + XiCon Loss:1.8794 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.262177448353619e-32
Epoch: 98 cost time: 0.9786891937255859
Epoch: 98, Steps: 69 Train Loss: 0.2864 (Forecasting Loss:0.0989 + XiCon Loss:1.8751 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.310887241768095e-33
Epoch: 99 cost time: 0.9024312496185303
Epoch: 99, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0988 + XiCon Loss:1.8733 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.155443620884047e-33
Epoch: 100 cost time: 0.948239803314209
Epoch: 100, Steps: 69 Train Loss: 0.2861 (Forecasting Loss:0.0989 + XiCon Loss:1.8715 x Lambda(0.1)), Vali MSE Loss: 0.2047 Test MSE Loss: 0.1185
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.5777218104420236e-33
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl48_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1470
test shape: (22, 64, 48, 1) (22, 64, 48, 1)
test shape: (1408, 48, 1) (1408, 48, 1)
mse:0.056347303092479706, mae:0.18055373430252075, mape:0.12694300711154938, mspe:0.038439154624938965 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.0548+-0.00121, MAE:0.1782+-0.00196, MAPE:0.1245+-0.00182, MSPE:0.0367+-0.00125, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[48, 360], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=360, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6418
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.2925035953521729
Epoch: 1, Steps: 64 Train Loss: 0.6958 (Forecasting Loss:0.5016 + XiCon Loss:1.9424 x Lambda(0.1)), Vali MSE Loss: 0.9638 Test MSE Loss: 0.5134
Validation loss decreased (inf --> 0.963837).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.0566442012786865
Epoch: 2, Steps: 64 Train Loss: 0.6914 (Forecasting Loss:0.4973 + XiCon Loss:1.9412 x Lambda(0.1)), Vali MSE Loss: 0.9527 Test MSE Loss: 0.5066
Validation loss decreased (0.963837 --> 0.952727).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.039870262145996
Epoch: 3, Steps: 64 Train Loss: 0.6849 (Forecasting Loss:0.4908 + XiCon Loss:1.9409 x Lambda(0.1)), Vali MSE Loss: 0.9423 Test MSE Loss: 0.5039
Validation loss decreased (0.952727 --> 0.942346).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.8945856094360352
Epoch: 4, Steps: 64 Train Loss: 0.6826 (Forecasting Loss:0.4888 + XiCon Loss:1.9385 x Lambda(0.1)), Vali MSE Loss: 0.9448 Test MSE Loss: 0.5026
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.0022881031036377
Epoch: 5, Steps: 64 Train Loss: 0.6801 (Forecasting Loss:0.4861 + XiCon Loss:1.9395 x Lambda(0.1)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5019
Validation loss decreased (0.942346 --> 0.938287).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.939089298248291
Epoch: 6, Steps: 64 Train Loss: 0.6793 (Forecasting Loss:0.4854 + XiCon Loss:1.9398 x Lambda(0.1)), Vali MSE Loss: 0.9383 Test MSE Loss: 0.5016
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.0030176639556885
Epoch: 7, Steps: 64 Train Loss: 0.6794 (Forecasting Loss:0.4855 + XiCon Loss:1.9398 x Lambda(0.1)), Vali MSE Loss: 0.9364 Test MSE Loss: 0.5015
Validation loss decreased (0.938287 --> 0.936440).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.0080766677856445
Epoch: 8, Steps: 64 Train Loss: 0.6793 (Forecasting Loss:0.4851 + XiCon Loss:1.9412 x Lambda(0.1)), Vali MSE Loss: 0.9362 Test MSE Loss: 0.5014
Validation loss decreased (0.936440 --> 0.936198).  Saving model ...
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9597458839416504
Epoch: 9, Steps: 64 Train Loss: 0.6784 (Forecasting Loss:0.4844 + XiCon Loss:1.9400 x Lambda(0.1)), Vali MSE Loss: 0.9371 Test MSE Loss: 0.5013
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9649088382720947
Epoch: 10, Steps: 64 Train Loss: 0.6779 (Forecasting Loss:0.4840 + XiCon Loss:1.9394 x Lambda(0.1)), Vali MSE Loss: 0.9380 Test MSE Loss: 0.5013
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9704015254974365
Epoch: 11, Steps: 64 Train Loss: 0.6791 (Forecasting Loss:0.4852 + XiCon Loss:1.9386 x Lambda(0.1)), Vali MSE Loss: 0.9379 Test MSE Loss: 0.5013
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.0501976013183594
Epoch: 12, Steps: 64 Train Loss: 0.6790 (Forecasting Loss:0.4848 + XiCon Loss:1.9424 x Lambda(0.1)), Vali MSE Loss: 0.9375 Test MSE Loss: 0.5013
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.968482255935669
Epoch: 13, Steps: 64 Train Loss: 0.6789 (Forecasting Loss:0.4851 + XiCon Loss:1.9385 x Lambda(0.1)), Vali MSE Loss: 0.9391 Test MSE Loss: 0.5013
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9821450710296631
Epoch: 14, Steps: 64 Train Loss: 0.6783 (Forecasting Loss:0.4843 + XiCon Loss:1.9397 x Lambda(0.1)), Vali MSE Loss: 0.9381 Test MSE Loss: 0.5013
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.0455729961395264
Epoch: 15, Steps: 64 Train Loss: 0.6793 (Forecasting Loss:0.4854 + XiCon Loss:1.9381 x Lambda(0.1)), Vali MSE Loss: 0.9413 Test MSE Loss: 0.5013
EarlyStopping counter: 7 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.002046823501587
Epoch: 16, Steps: 64 Train Loss: 0.6783 (Forecasting Loss:0.4845 + XiCon Loss:1.9380 x Lambda(0.1)), Vali MSE Loss: 0.9377 Test MSE Loss: 0.5013
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.0526854991912842
Epoch: 17, Steps: 64 Train Loss: 0.6794 (Forecasting Loss:0.4854 + XiCon Loss:1.9401 x Lambda(0.1)), Vali MSE Loss: 0.9352 Test MSE Loss: 0.5013
Validation loss decreased (0.936198 --> 0.935201).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9848756790161133
Epoch: 18, Steps: 64 Train Loss: 0.6792 (Forecasting Loss:0.4853 + XiCon Loss:1.9394 x Lambda(0.1)), Vali MSE Loss: 0.9369 Test MSE Loss: 0.5013
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9714515209197998
Epoch: 19, Steps: 64 Train Loss: 0.6792 (Forecasting Loss:0.4852 + XiCon Loss:1.9396 x Lambda(0.1)), Vali MSE Loss: 0.9385 Test MSE Loss: 0.5013
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9188363552093506
Epoch: 20, Steps: 64 Train Loss: 0.6786 (Forecasting Loss:0.4848 + XiCon Loss:1.9381 x Lambda(0.1)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.5013
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.0554380416870117
Epoch: 21, Steps: 64 Train Loss: 0.6783 (Forecasting Loss:0.4842 + XiCon Loss:1.9403 x Lambda(0.1)), Vali MSE Loss: 0.9361 Test MSE Loss: 0.5013
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 0.9177501201629639
Epoch: 22, Steps: 64 Train Loss: 0.6785 (Forecasting Loss:0.4843 + XiCon Loss:1.9417 x Lambda(0.1)), Vali MSE Loss: 0.9372 Test MSE Loss: 0.5013
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9926960468292236
Epoch: 23, Steps: 64 Train Loss: 0.6781 (Forecasting Loss:0.4841 + XiCon Loss:1.9397 x Lambda(0.1)), Vali MSE Loss: 0.9367 Test MSE Loss: 0.5013
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 0.9996685981750488
Epoch: 24, Steps: 64 Train Loss: 0.6791 (Forecasting Loss:0.4853 + XiCon Loss:1.9380 x Lambda(0.1)), Vali MSE Loss: 0.9388 Test MSE Loss: 0.5013
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9030013084411621
Epoch: 25, Steps: 64 Train Loss: 0.6782 (Forecasting Loss:0.4842 + XiCon Loss:1.9400 x Lambda(0.1)), Vali MSE Loss: 0.9396 Test MSE Loss: 0.5013
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 0.9436516761779785
Epoch: 26, Steps: 64 Train Loss: 0.6782 (Forecasting Loss:0.4841 + XiCon Loss:1.9411 x Lambda(0.1)), Vali MSE Loss: 0.9374 Test MSE Loss: 0.5013
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9937431812286377
Epoch: 27, Steps: 64 Train Loss: 0.6786 (Forecasting Loss:0.4847 + XiCon Loss:1.9391 x Lambda(0.1)), Vali MSE Loss: 0.9393 Test MSE Loss: 0.5013
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.4696585237979889, mae:0.5329253077507019, mape:0.44919490814208984, mspe:0.5989973545074463 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6335
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.988149881362915
Epoch: 1, Steps: 64 Train Loss: 0.6866 (Forecasting Loss:0.4928 + XiCon Loss:1.9385 x Lambda(0.1)), Vali MSE Loss: 0.9329 Test MSE Loss: 0.5210
Validation loss decreased (inf --> 0.932949).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.0188910961151123
Epoch: 2, Steps: 64 Train Loss: 0.6839 (Forecasting Loss:0.4901 + XiCon Loss:1.9376 x Lambda(0.1)), Vali MSE Loss: 0.9151 Test MSE Loss: 0.5154
Validation loss decreased (0.932949 --> 0.915068).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 0.9691832065582275
Epoch: 3, Steps: 64 Train Loss: 0.6774 (Forecasting Loss:0.4836 + XiCon Loss:1.9378 x Lambda(0.1)), Vali MSE Loss: 0.9126 Test MSE Loss: 0.5129
Validation loss decreased (0.915068 --> 0.912592).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9817814826965332
Epoch: 4, Steps: 64 Train Loss: 0.6747 (Forecasting Loss:0.4807 + XiCon Loss:1.9399 x Lambda(0.1)), Vali MSE Loss: 0.9093 Test MSE Loss: 0.5118
Validation loss decreased (0.912592 --> 0.909261).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9855899810791016
Epoch: 5, Steps: 64 Train Loss: 0.6735 (Forecasting Loss:0.4795 + XiCon Loss:1.9396 x Lambda(0.1)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5112
Validation loss decreased (0.909261 --> 0.906530).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.0246026515960693
Epoch: 6, Steps: 64 Train Loss: 0.6733 (Forecasting Loss:0.4796 + XiCon Loss:1.9369 x Lambda(0.1)), Vali MSE Loss: 0.9087 Test MSE Loss: 0.5109
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.0087738037109375
Epoch: 7, Steps: 64 Train Loss: 0.6723 (Forecasting Loss:0.4786 + XiCon Loss:1.9370 x Lambda(0.1)), Vali MSE Loss: 0.9072 Test MSE Loss: 0.5108
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.9503974914550781
Epoch: 8, Steps: 64 Train Loss: 0.6719 (Forecasting Loss:0.4781 + XiCon Loss:1.9379 x Lambda(0.1)), Vali MSE Loss: 0.9066 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.008556604385376
Epoch: 9, Steps: 64 Train Loss: 0.6729 (Forecasting Loss:0.4790 + XiCon Loss:1.9389 x Lambda(0.1)), Vali MSE Loss: 0.9072 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.9192564487457275
Epoch: 10, Steps: 64 Train Loss: 0.6725 (Forecasting Loss:0.4785 + XiCon Loss:1.9402 x Lambda(0.1)), Vali MSE Loss: 0.9069 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9828331470489502
Epoch: 11, Steps: 64 Train Loss: 0.6713 (Forecasting Loss:0.4774 + XiCon Loss:1.9391 x Lambda(0.1)), Vali MSE Loss: 0.9076 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.0480570793151855
Epoch: 12, Steps: 64 Train Loss: 0.6724 (Forecasting Loss:0.4788 + XiCon Loss:1.9366 x Lambda(0.1)), Vali MSE Loss: 0.9056 Test MSE Loss: 0.5107
Validation loss decreased (0.906530 --> 0.905626).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8769404888153076
Epoch: 13, Steps: 64 Train Loss: 0.6712 (Forecasting Loss:0.4775 + XiCon Loss:1.9376 x Lambda(0.1)), Vali MSE Loss: 0.9054 Test MSE Loss: 0.5107
Validation loss decreased (0.905626 --> 0.905402).  Saving model ...
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9978582859039307
Epoch: 14, Steps: 64 Train Loss: 0.6715 (Forecasting Loss:0.4776 + XiCon Loss:1.9388 x Lambda(0.1)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.0349907875061035
Epoch: 15, Steps: 64 Train Loss: 0.6733 (Forecasting Loss:0.4797 + XiCon Loss:1.9366 x Lambda(0.1)), Vali MSE Loss: 0.9086 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.0362846851348877
Epoch: 16, Steps: 64 Train Loss: 0.6723 (Forecasting Loss:0.4786 + XiCon Loss:1.9375 x Lambda(0.1)), Vali MSE Loss: 0.9054 Test MSE Loss: 0.5107
Validation loss decreased (0.905402 --> 0.905383).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.0058720111846924
Epoch: 17, Steps: 64 Train Loss: 0.6719 (Forecasting Loss:0.4781 + XiCon Loss:1.9385 x Lambda(0.1)), Vali MSE Loss: 0.9027 Test MSE Loss: 0.5107
Validation loss decreased (0.905383 --> 0.902677).  Saving model ...
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9429311752319336
Epoch: 18, Steps: 64 Train Loss: 0.6716 (Forecasting Loss:0.4776 + XiCon Loss:1.9394 x Lambda(0.1)), Vali MSE Loss: 0.9078 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.9386210441589355
Epoch: 19, Steps: 64 Train Loss: 0.6724 (Forecasting Loss:0.4786 + XiCon Loss:1.9381 x Lambda(0.1)), Vali MSE Loss: 0.9034 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.0220274925231934
Epoch: 20, Steps: 64 Train Loss: 0.6718 (Forecasting Loss:0.4781 + XiCon Loss:1.9371 x Lambda(0.1)), Vali MSE Loss: 0.9079 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.0081799030303955
Epoch: 21, Steps: 64 Train Loss: 0.6715 (Forecasting Loss:0.4777 + XiCon Loss:1.9387 x Lambda(0.1)), Vali MSE Loss: 0.9068 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.0156116485595703
Epoch: 22, Steps: 64 Train Loss: 0.6718 (Forecasting Loss:0.4780 + XiCon Loss:1.9374 x Lambda(0.1)), Vali MSE Loss: 0.9004 Test MSE Loss: 0.5107
Validation loss decreased (0.902677 --> 0.900383).  Saving model ...
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9219989776611328
Epoch: 23, Steps: 64 Train Loss: 0.6715 (Forecasting Loss:0.4777 + XiCon Loss:1.9383 x Lambda(0.1)), Vali MSE Loss: 0.9045 Test MSE Loss: 0.5107
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 1.0275814533233643
Epoch: 24, Steps: 64 Train Loss: 0.6720 (Forecasting Loss:0.4782 + XiCon Loss:1.9377 x Lambda(0.1)), Vali MSE Loss: 0.9056 Test MSE Loss: 0.5107
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.9631941318511963
Epoch: 25, Steps: 64 Train Loss: 0.6711 (Forecasting Loss:0.4773 + XiCon Loss:1.9380 x Lambda(0.1)), Vali MSE Loss: 0.9020 Test MSE Loss: 0.5107
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 1.0578107833862305
Epoch: 26, Steps: 64 Train Loss: 0.6732 (Forecasting Loss:0.4794 + XiCon Loss:1.9380 x Lambda(0.1)), Vali MSE Loss: 0.9042 Test MSE Loss: 0.5107
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
Epoch: 27 cost time: 0.9932539463043213
Epoch: 27, Steps: 64 Train Loss: 0.6724 (Forecasting Loss:0.4786 + XiCon Loss:1.9380 x Lambda(0.1)), Vali MSE Loss: 0.9057 Test MSE Loss: 0.5107
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.4901161193847657e-12
Epoch: 28 cost time: 0.9244246482849121
Epoch: 28, Steps: 64 Train Loss: 0.6716 (Forecasting Loss:0.4778 + XiCon Loss:1.9376 x Lambda(0.1)), Vali MSE Loss: 0.9065 Test MSE Loss: 0.5107
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.450580596923828e-13
Epoch: 29 cost time: 1.0248985290527344
Epoch: 29, Steps: 64 Train Loss: 0.6721 (Forecasting Loss:0.4782 + XiCon Loss:1.9385 x Lambda(0.1)), Vali MSE Loss: 0.9060 Test MSE Loss: 0.5107
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.725290298461914e-13
Epoch: 30 cost time: 0.9152400493621826
Epoch: 30, Steps: 64 Train Loss: 0.6713 (Forecasting Loss:0.4775 + XiCon Loss:1.9378 x Lambda(0.1)), Vali MSE Loss: 0.9096 Test MSE Loss: 0.5107
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.862645149230957e-13
Epoch: 31 cost time: 0.983590841293335
Epoch: 31, Steps: 64 Train Loss: 0.6728 (Forecasting Loss:0.4789 + XiCon Loss:1.9388 x Lambda(0.1)), Vali MSE Loss: 0.9034 Test MSE Loss: 0.5107
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.313225746154786e-14
Epoch: 32 cost time: 1.004847764968872
Epoch: 32, Steps: 64 Train Loss: 0.6721 (Forecasting Loss:0.4783 + XiCon Loss:1.9372 x Lambda(0.1)), Vali MSE Loss: 0.9071 Test MSE Loss: 0.5107
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.48461517691612244, mae:0.5367332696914673, mape:0.45695024728775024, mspe:0.6298457980155945 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5712
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.9351491928100586
Epoch: 1, Steps: 64 Train Loss: 0.6954 (Forecasting Loss:0.5013 + XiCon Loss:1.9408 x Lambda(0.1)), Vali MSE Loss: 0.9739 Test MSE Loss: 0.5056
Validation loss decreased (inf --> 0.973859).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.032529592514038
Epoch: 2, Steps: 64 Train Loss: 0.6926 (Forecasting Loss:0.4982 + XiCon Loss:1.9440 x Lambda(0.1)), Vali MSE Loss: 0.9568 Test MSE Loss: 0.5003
Validation loss decreased (0.973859 --> 0.956797).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.0317864418029785
Epoch: 3, Steps: 64 Train Loss: 0.6849 (Forecasting Loss:0.4909 + XiCon Loss:1.9402 x Lambda(0.1)), Vali MSE Loss: 0.9491 Test MSE Loss: 0.4986
Validation loss decreased (0.956797 --> 0.949129).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.0047314167022705
Epoch: 4, Steps: 64 Train Loss: 0.6833 (Forecasting Loss:0.4891 + XiCon Loss:1.9423 x Lambda(0.1)), Vali MSE Loss: 0.9449 Test MSE Loss: 0.4981
Validation loss decreased (0.949129 --> 0.944879).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9779965877532959
Epoch: 5, Steps: 64 Train Loss: 0.6802 (Forecasting Loss:0.4861 + XiCon Loss:1.9407 x Lambda(0.1)), Vali MSE Loss: 0.9396 Test MSE Loss: 0.4979
Validation loss decreased (0.944879 --> 0.939613).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9400808811187744
Epoch: 6, Steps: 64 Train Loss: 0.6798 (Forecasting Loss:0.4857 + XiCon Loss:1.9406 x Lambda(0.1)), Vali MSE Loss: 0.9419 Test MSE Loss: 0.4979
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.003685712814331
Epoch: 7, Steps: 64 Train Loss: 0.6784 (Forecasting Loss:0.4842 + XiCon Loss:1.9415 x Lambda(0.1)), Vali MSE Loss: 0.9350 Test MSE Loss: 0.4979
Validation loss decreased (0.939613 --> 0.934961).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.0118722915649414
Epoch: 8, Steps: 64 Train Loss: 0.6790 (Forecasting Loss:0.4850 + XiCon Loss:1.9402 x Lambda(0.1)), Vali MSE Loss: 0.9370 Test MSE Loss: 0.4979
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.0295372009277344
Epoch: 9, Steps: 64 Train Loss: 0.6779 (Forecasting Loss:0.4837 + XiCon Loss:1.9420 x Lambda(0.1)), Vali MSE Loss: 0.9409 Test MSE Loss: 0.4979
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.0047805309295654
Epoch: 10, Steps: 64 Train Loss: 0.6775 (Forecasting Loss:0.4836 + XiCon Loss:1.9396 x Lambda(0.1)), Vali MSE Loss: 0.9332 Test MSE Loss: 0.4979
Validation loss decreased (0.934961 --> 0.933237).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.0823936462402344
Epoch: 11, Steps: 64 Train Loss: 0.6783 (Forecasting Loss:0.4842 + XiCon Loss:1.9414 x Lambda(0.1)), Vali MSE Loss: 0.9347 Test MSE Loss: 0.4978
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.093278408050537
Epoch: 12, Steps: 64 Train Loss: 0.6792 (Forecasting Loss:0.4848 + XiCon Loss:1.9438 x Lambda(0.1)), Vali MSE Loss: 0.9414 Test MSE Loss: 0.4978
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.9991075992584229
Epoch: 13, Steps: 64 Train Loss: 0.6786 (Forecasting Loss:0.4847 + XiCon Loss:1.9390 x Lambda(0.1)), Vali MSE Loss: 0.9374 Test MSE Loss: 0.4978
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.033010721206665
Epoch: 14, Steps: 64 Train Loss: 0.6788 (Forecasting Loss:0.4845 + XiCon Loss:1.9432 x Lambda(0.1)), Vali MSE Loss: 0.9356 Test MSE Loss: 0.4978
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9988951683044434
Epoch: 15, Steps: 64 Train Loss: 0.6782 (Forecasting Loss:0.4838 + XiCon Loss:1.9431 x Lambda(0.1)), Vali MSE Loss: 0.9373 Test MSE Loss: 0.4978
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.107578992843628
Epoch: 16, Steps: 64 Train Loss: 0.6789 (Forecasting Loss:0.4847 + XiCon Loss:1.9417 x Lambda(0.1)), Vali MSE Loss: 0.9392 Test MSE Loss: 0.4978
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9143836498260498
Epoch: 17, Steps: 64 Train Loss: 0.6791 (Forecasting Loss:0.4850 + XiCon Loss:1.9409 x Lambda(0.1)), Vali MSE Loss: 0.9374 Test MSE Loss: 0.4978
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.0229101181030273
Epoch: 18, Steps: 64 Train Loss: 0.6775 (Forecasting Loss:0.4836 + XiCon Loss:1.9391 x Lambda(0.1)), Vali MSE Loss: 0.9386 Test MSE Loss: 0.4978
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 0.986248254776001
Epoch: 19, Steps: 64 Train Loss: 0.6779 (Forecasting Loss:0.4838 + XiCon Loss:1.9411 x Lambda(0.1)), Vali MSE Loss: 0.9351 Test MSE Loss: 0.4978
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 0.9845006465911865
Epoch: 20, Steps: 64 Train Loss: 0.6780 (Forecasting Loss:0.4836 + XiCon Loss:1.9444 x Lambda(0.1)), Vali MSE Loss: 0.9333 Test MSE Loss: 0.4978
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.46524208784103394, mae:0.5304594039916992, mape:0.4462146461009979, mspe:0.5914402604103088 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.8012
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 1.0437049865722656
Epoch: 1, Steps: 64 Train Loss: 0.6890 (Forecasting Loss:0.4951 + XiCon Loss:1.9398 x Lambda(0.1)), Vali MSE Loss: 0.9334 Test MSE Loss: 0.5219
Validation loss decreased (inf --> 0.933366).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 0.9182741641998291
Epoch: 2, Steps: 64 Train Loss: 0.6840 (Forecasting Loss:0.4902 + XiCon Loss:1.9378 x Lambda(0.1)), Vali MSE Loss: 0.9170 Test MSE Loss: 0.5151
Validation loss decreased (0.933366 --> 0.917014).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.0752010345458984
Epoch: 3, Steps: 64 Train Loss: 0.6745 (Forecasting Loss:0.4804 + XiCon Loss:1.9405 x Lambda(0.1)), Vali MSE Loss: 0.9104 Test MSE Loss: 0.5109
Validation loss decreased (0.917014 --> 0.910396).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.936286211013794
Epoch: 4, Steps: 64 Train Loss: 0.6714 (Forecasting Loss:0.4774 + XiCon Loss:1.9397 x Lambda(0.1)), Vali MSE Loss: 0.9044 Test MSE Loss: 0.5087
Validation loss decreased (0.910396 --> 0.904429).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.0271189212799072
Epoch: 5, Steps: 64 Train Loss: 0.6696 (Forecasting Loss:0.4754 + XiCon Loss:1.9422 x Lambda(0.1)), Vali MSE Loss: 0.8985 Test MSE Loss: 0.5077
Validation loss decreased (0.904429 --> 0.898512).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.9992561340332031
Epoch: 6, Steps: 64 Train Loss: 0.6690 (Forecasting Loss:0.4751 + XiCon Loss:1.9386 x Lambda(0.1)), Vali MSE Loss: 0.8989 Test MSE Loss: 0.5072
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9776825904846191
Epoch: 7, Steps: 64 Train Loss: 0.6684 (Forecasting Loss:0.4743 + XiCon Loss:1.9411 x Lambda(0.1)), Vali MSE Loss: 0.9011 Test MSE Loss: 0.5070
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.0268785953521729
Epoch: 8, Steps: 64 Train Loss: 0.6669 (Forecasting Loss:0.4730 + XiCon Loss:1.9395 x Lambda(0.1)), Vali MSE Loss: 0.9007 Test MSE Loss: 0.5069
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.0271122455596924
Epoch: 9, Steps: 64 Train Loss: 0.6661 (Forecasting Loss:0.4722 + XiCon Loss:1.9391 x Lambda(0.1)), Vali MSE Loss: 0.8956 Test MSE Loss: 0.5068
Validation loss decreased (0.898512 --> 0.895607).  Saving model ...
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.0346901416778564
Epoch: 10, Steps: 64 Train Loss: 0.6670 (Forecasting Loss:0.4732 + XiCon Loss:1.9379 x Lambda(0.1)), Vali MSE Loss: 0.8988 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.8682208061218262
Epoch: 11, Steps: 64 Train Loss: 0.6672 (Forecasting Loss:0.4732 + XiCon Loss:1.9400 x Lambda(0.1)), Vali MSE Loss: 0.8981 Test MSE Loss: 0.5068
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9948852062225342
Epoch: 12, Steps: 64 Train Loss: 0.6670 (Forecasting Loss:0.4731 + XiCon Loss:1.9392 x Lambda(0.1)), Vali MSE Loss: 0.8976 Test MSE Loss: 0.5067
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.0481510162353516
Epoch: 13, Steps: 64 Train Loss: 0.6673 (Forecasting Loss:0.4730 + XiCon Loss:1.9429 x Lambda(0.1)), Vali MSE Loss: 0.8977 Test MSE Loss: 0.5067
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.995232343673706
Epoch: 14, Steps: 64 Train Loss: 0.6667 (Forecasting Loss:0.4728 + XiCon Loss:1.9394 x Lambda(0.1)), Vali MSE Loss: 0.9001 Test MSE Loss: 0.5067
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.0485506057739258
Epoch: 15, Steps: 64 Train Loss: 0.6675 (Forecasting Loss:0.4736 + XiCon Loss:1.9386 x Lambda(0.1)), Vali MSE Loss: 0.9005 Test MSE Loss: 0.5067
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.0085864067077637
Epoch: 16, Steps: 64 Train Loss: 0.6665 (Forecasting Loss:0.4725 + XiCon Loss:1.9395 x Lambda(0.1)), Vali MSE Loss: 0.8931 Test MSE Loss: 0.5067
Validation loss decreased (0.895607 --> 0.893058).  Saving model ...
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 0.9940786361694336
Epoch: 17, Steps: 64 Train Loss: 0.6667 (Forecasting Loss:0.4727 + XiCon Loss:1.9407 x Lambda(0.1)), Vali MSE Loss: 0.8977 Test MSE Loss: 0.5067
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 0.9722733497619629
Epoch: 18, Steps: 64 Train Loss: 0.6680 (Forecasting Loss:0.4741 + XiCon Loss:1.9393 x Lambda(0.1)), Vali MSE Loss: 0.8978 Test MSE Loss: 0.5067
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.0321917533874512
Epoch: 19, Steps: 64 Train Loss: 0.6677 (Forecasting Loss:0.4737 + XiCon Loss:1.9404 x Lambda(0.1)), Vali MSE Loss: 0.8999 Test MSE Loss: 0.5067
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.0151352882385254
Epoch: 20, Steps: 64 Train Loss: 0.6662 (Forecasting Loss:0.4724 + XiCon Loss:1.9377 x Lambda(0.1)), Vali MSE Loss: 0.8984 Test MSE Loss: 0.5067
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 0.9910860061645508
Epoch: 21, Steps: 64 Train Loss: 0.6674 (Forecasting Loss:0.4735 + XiCon Loss:1.9390 x Lambda(0.1)), Vali MSE Loss: 0.8975 Test MSE Loss: 0.5067
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.011169672012329
Epoch: 22, Steps: 64 Train Loss: 0.6669 (Forecasting Loss:0.4731 + XiCon Loss:1.9377 x Lambda(0.1)), Vali MSE Loss: 0.8979 Test MSE Loss: 0.5067
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
Epoch: 23 cost time: 0.9440779685974121
Epoch: 23, Steps: 64 Train Loss: 0.6665 (Forecasting Loss:0.4727 + XiCon Loss:1.9381 x Lambda(0.1)), Vali MSE Loss: 0.8962 Test MSE Loss: 0.5067
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
Epoch: 24 cost time: 1.046210527420044
Epoch: 24, Steps: 64 Train Loss: 0.6668 (Forecasting Loss:0.4728 + XiCon Loss:1.9399 x Lambda(0.1)), Vali MSE Loss: 0.8998 Test MSE Loss: 0.5067
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
Epoch: 25 cost time: 0.8598437309265137
Epoch: 25, Steps: 64 Train Loss: 0.6667 (Forecasting Loss:0.4727 + XiCon Loss:1.9402 x Lambda(0.1)), Vali MSE Loss: 0.8965 Test MSE Loss: 0.5067
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
Epoch: 26 cost time: 1.0681970119476318
Epoch: 26, Steps: 64 Train Loss: 0.6664 (Forecasting Loss:0.4726 + XiCon Loss:1.9379 x Lambda(0.1)), Vali MSE Loss: 0.8999 Test MSE Loss: 0.5067
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.48015159368515015, mae:0.5333341956138611, mape:0.4535726308822632, mspe:0.6206634640693665 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:37370
train 4145
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5717
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 4145
val 1160
test 1158
Epoch: 1 cost time: 0.959491491317749
Epoch: 1, Steps: 64 Train Loss: 0.6888 (Forecasting Loss:0.4949 + XiCon Loss:1.9398 x Lambda(0.1)), Vali MSE Loss: 0.9082 Test MSE Loss: 0.5475
Validation loss decreased (inf --> 0.908217).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.0039608478546143
Epoch: 2, Steps: 64 Train Loss: 0.6853 (Forecasting Loss:0.4914 + XiCon Loss:1.9394 x Lambda(0.1)), Vali MSE Loss: 0.8923 Test MSE Loss: 0.5398
Validation loss decreased (0.908217 --> 0.892268).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.0020427703857422
Epoch: 3, Steps: 64 Train Loss: 0.6804 (Forecasting Loss:0.4864 + XiCon Loss:1.9395 x Lambda(0.1)), Vali MSE Loss: 0.8927 Test MSE Loss: 0.5364
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 0.9824650287628174
Epoch: 4, Steps: 64 Train Loss: 0.6763 (Forecasting Loss:0.4825 + XiCon Loss:1.9378 x Lambda(0.1)), Vali MSE Loss: 0.8852 Test MSE Loss: 0.5347
Validation loss decreased (0.892268 --> 0.885235).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 0.9748492240905762
Epoch: 5, Steps: 64 Train Loss: 0.6754 (Forecasting Loss:0.4816 + XiCon Loss:1.9382 x Lambda(0.1)), Vali MSE Loss: 0.8837 Test MSE Loss: 0.5339
Validation loss decreased (0.885235 --> 0.883664).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 0.916450023651123
Epoch: 6, Steps: 64 Train Loss: 0.6738 (Forecasting Loss:0.4799 + XiCon Loss:1.9384 x Lambda(0.1)), Vali MSE Loss: 0.8861 Test MSE Loss: 0.5335
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 0.9378697872161865
Epoch: 7, Steps: 64 Train Loss: 0.6742 (Forecasting Loss:0.4801 + XiCon Loss:1.9407 x Lambda(0.1)), Vali MSE Loss: 0.8879 Test MSE Loss: 0.5333
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 0.8971550464630127
Epoch: 8, Steps: 64 Train Loss: 0.6764 (Forecasting Loss:0.4825 + XiCon Loss:1.9391 x Lambda(0.1)), Vali MSE Loss: 0.8896 Test MSE Loss: 0.5332
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 0.9029691219329834
Epoch: 9, Steps: 64 Train Loss: 0.6727 (Forecasting Loss:0.4788 + XiCon Loss:1.9391 x Lambda(0.1)), Vali MSE Loss: 0.8854 Test MSE Loss: 0.5332
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 0.898259162902832
Epoch: 10, Steps: 64 Train Loss: 0.6742 (Forecasting Loss:0.4804 + XiCon Loss:1.9380 x Lambda(0.1)), Vali MSE Loss: 0.8852 Test MSE Loss: 0.5331
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 0.9065814018249512
Epoch: 11, Steps: 64 Train Loss: 0.6750 (Forecasting Loss:0.4809 + XiCon Loss:1.9408 x Lambda(0.1)), Vali MSE Loss: 0.8841 Test MSE Loss: 0.5331
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 0.9189374446868896
Epoch: 12, Steps: 64 Train Loss: 0.6732 (Forecasting Loss:0.4793 + XiCon Loss:1.9393 x Lambda(0.1)), Vali MSE Loss: 0.8850 Test MSE Loss: 0.5331
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 0.8779408931732178
Epoch: 13, Steps: 64 Train Loss: 0.6747 (Forecasting Loss:0.4809 + XiCon Loss:1.9385 x Lambda(0.1)), Vali MSE Loss: 0.8864 Test MSE Loss: 0.5331
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 0.9004101753234863
Epoch: 14, Steps: 64 Train Loss: 0.6742 (Forecasting Loss:0.4802 + XiCon Loss:1.9401 x Lambda(0.1)), Vali MSE Loss: 0.8847 Test MSE Loss: 0.5331
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 0.9009325504302979
Epoch: 15, Steps: 64 Train Loss: 0.6748 (Forecasting Loss:0.4809 + XiCon Loss:1.9389 x Lambda(0.1)), Vali MSE Loss: 0.8849 Test MSE Loss: 0.5331
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl360_dm8_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 1158
test shape: (18, 64, 360, 1) (18, 64, 360, 1)
test shape: (1152, 360, 1) (1152, 360, 1)
mse:0.5172026753425598, mae:0.5505993366241455, mape:0.47536537051200867, mspe:0.6883264780044556 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.4834+-0.02539, MAE:0.5368+-0.00997, MAPE:0.4563+-0.01421, MSPE:0.6259+-0.04749, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=16, n_heads=8, e_layers=1, d_layers=1, d_ff=16, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=1e-05, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6488
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.470346450805664
Epoch: 1, Steps: 59 Train Loss: 1.1716 (Forecasting Loss:0.9906 + XiCon Loss:1.8097 x Lambda(0.1)), Vali MSE Loss: 1.2486 Test MSE Loss: 0.9828
Validation loss decreased (inf --> 1.248619).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.1636962890625
Epoch: 2, Steps: 59 Train Loss: 1.1711 (Forecasting Loss:0.9903 + XiCon Loss:1.8080 x Lambda(0.1)), Vali MSE Loss: 1.2526 Test MSE Loss: 0.9825
EarlyStopping counter: 1 out of 10
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.1537361145019531
Epoch: 3, Steps: 59 Train Loss: 1.1702 (Forecasting Loss:0.9891 + XiCon Loss:1.8110 x Lambda(0.1)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9823
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.148310661315918
Epoch: 4, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9889 + XiCon Loss:1.8071 x Lambda(0.1)), Vali MSE Loss: 1.2468 Test MSE Loss: 0.9822
Validation loss decreased (1.248619 --> 1.246795).  Saving model ...
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.154972791671753
Epoch: 5, Steps: 59 Train Loss: 1.1701 (Forecasting Loss:0.9889 + XiCon Loss:1.8114 x Lambda(0.1)), Vali MSE Loss: 1.2509 Test MSE Loss: 0.9822
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2206130027770996
Epoch: 6, Steps: 59 Train Loss: 1.1705 (Forecasting Loss:0.9898 + XiCon Loss:1.8072 x Lambda(0.1)), Vali MSE Loss: 1.2459 Test MSE Loss: 0.9822
Validation loss decreased (1.246795 --> 1.245933).  Saving model ...
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.151653528213501
Epoch: 7, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9886 + XiCon Loss:1.8094 x Lambda(0.1)), Vali MSE Loss: 1.2449 Test MSE Loss: 0.9821
Validation loss decreased (1.245933 --> 1.244872).  Saving model ...
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.1769120693206787
Epoch: 8, Steps: 59 Train Loss: 1.1694 (Forecasting Loss:0.9880 + XiCon Loss:1.8140 x Lambda(0.1)), Vali MSE Loss: 1.2477 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.1922557353973389
Epoch: 9, Steps: 59 Train Loss: 1.1698 (Forecasting Loss:0.9889 + XiCon Loss:1.8093 x Lambda(0.1)), Vali MSE Loss: 1.2443 Test MSE Loss: 0.9821
Validation loss decreased (1.244872 --> 1.244332).  Saving model ...
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2023885250091553
Epoch: 10, Steps: 59 Train Loss: 1.1698 (Forecasting Loss:0.9888 + XiCon Loss:1.8101 x Lambda(0.1)), Vali MSE Loss: 1.2553 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.167806625366211
Epoch: 11, Steps: 59 Train Loss: 1.1686 (Forecasting Loss:0.9877 + XiCon Loss:1.8085 x Lambda(0.1)), Vali MSE Loss: 1.2445 Test MSE Loss: 0.9821
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.1561803817749023
Epoch: 12, Steps: 59 Train Loss: 1.1702 (Forecasting Loss:0.9886 + XiCon Loss:1.8156 x Lambda(0.1)), Vali MSE Loss: 1.2522 Test MSE Loss: 0.9821
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.1489264965057373
Epoch: 13, Steps: 59 Train Loss: 1.1697 (Forecasting Loss:0.9889 + XiCon Loss:1.8081 x Lambda(0.1)), Vali MSE Loss: 1.2455 Test MSE Loss: 0.9821
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.163184642791748
Epoch: 14, Steps: 59 Train Loss: 1.1695 (Forecasting Loss:0.9888 + XiCon Loss:1.8070 x Lambda(0.1)), Vali MSE Loss: 1.2448 Test MSE Loss: 0.9821
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.1750023365020752
Epoch: 15, Steps: 59 Train Loss: 1.1698 (Forecasting Loss:0.9887 + XiCon Loss:1.8110 x Lambda(0.1)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9821
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.1838657855987549
Epoch: 16, Steps: 59 Train Loss: 1.1704 (Forecasting Loss:0.9894 + XiCon Loss:1.8100 x Lambda(0.1)), Vali MSE Loss: 1.2489 Test MSE Loss: 0.9821
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.1905848979949951
Epoch: 17, Steps: 59 Train Loss: 1.1701 (Forecasting Loss:0.9888 + XiCon Loss:1.8128 x Lambda(0.1)), Vali MSE Loss: 1.2553 Test MSE Loss: 0.9821
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.167100429534912
Epoch: 18, Steps: 59 Train Loss: 1.1704 (Forecasting Loss:0.9895 + XiCon Loss:1.8087 x Lambda(0.1)), Vali MSE Loss: 1.2451 Test MSE Loss: 0.9821
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.1647977828979492
Epoch: 19, Steps: 59 Train Loss: 1.1710 (Forecasting Loss:0.9894 + XiCon Loss:1.8159 x Lambda(0.1)), Vali MSE Loss: 1.2415 Test MSE Loss: 0.9821
Validation loss decreased (1.244332 --> 1.241523).  Saving model ...
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.138761281967163
Epoch: 20, Steps: 59 Train Loss: 1.1700 (Forecasting Loss:0.9887 + XiCon Loss:1.8133 x Lambda(0.1)), Vali MSE Loss: 1.2438 Test MSE Loss: 0.9821
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.1706318855285645
Epoch: 21, Steps: 59 Train Loss: 1.1709 (Forecasting Loss:0.9897 + XiCon Loss:1.8115 x Lambda(0.1)), Vali MSE Loss: 1.2513 Test MSE Loss: 0.9821
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.1521360874176025
Epoch: 22, Steps: 59 Train Loss: 1.1708 (Forecasting Loss:0.9902 + XiCon Loss:1.8058 x Lambda(0.1)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9821
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-12
Epoch: 23 cost time: 1.149811029434204
Epoch: 23, Steps: 59 Train Loss: 1.1693 (Forecasting Loss:0.9879 + XiCon Loss:1.8136 x Lambda(0.1)), Vali MSE Loss: 1.2495 Test MSE Loss: 0.9821
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-12
Epoch: 24 cost time: 1.2966325283050537
Epoch: 24, Steps: 59 Train Loss: 1.1701 (Forecasting Loss:0.9892 + XiCon Loss:1.8084 x Lambda(0.1)), Vali MSE Loss: 1.2546 Test MSE Loss: 0.9821
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-12
Epoch: 25 cost time: 1.2064006328582764
Epoch: 25, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9889 + XiCon Loss:1.8069 x Lambda(0.1)), Vali MSE Loss: 1.2520 Test MSE Loss: 0.9821
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-13
Epoch: 26 cost time: 1.237255334854126
Epoch: 26, Steps: 59 Train Loss: 1.1697 (Forecasting Loss:0.9890 + XiCon Loss:1.8072 x Lambda(0.1)), Vali MSE Loss: 1.2573 Test MSE Loss: 0.9821
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695315e-13
Epoch: 27 cost time: 1.2448883056640625
Epoch: 27, Steps: 59 Train Loss: 1.1698 (Forecasting Loss:0.9886 + XiCon Loss:1.8118 x Lambda(0.1)), Vali MSE Loss: 1.2485 Test MSE Loss: 0.9821
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4901161193847657e-13
Epoch: 28 cost time: 1.2373433113098145
Epoch: 28, Steps: 59 Train Loss: 1.1706 (Forecasting Loss:0.9900 + XiCon Loss:1.8054 x Lambda(0.1)), Vali MSE Loss: 1.2507 Test MSE Loss: 0.9821
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.450580596923829e-14
Epoch: 29 cost time: 1.2725956439971924
Epoch: 29, Steps: 59 Train Loss: 1.1695 (Forecasting Loss:0.9885 + XiCon Loss:1.8100 x Lambda(0.1)), Vali MSE Loss: 1.2525 Test MSE Loss: 0.9821
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1455743312835693, mae:0.8186997175216675, mape:0.7821470499038696, mspe:1.8304511308670044 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5896
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.3917813301086426
Epoch: 1, Steps: 59 Train Loss: 1.1698 (Forecasting Loss:0.9892 + XiCon Loss:1.8061 x Lambda(0.1)), Vali MSE Loss: 1.2368 Test MSE Loss: 0.9934
Validation loss decreased (inf --> 1.236817).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2634296417236328
Epoch: 2, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9886 + XiCon Loss:1.8102 x Lambda(0.1)), Vali MSE Loss: 1.2343 Test MSE Loss: 0.9931
Validation loss decreased (1.236817 --> 1.234277).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2730166912078857
Epoch: 3, Steps: 59 Train Loss: 1.1677 (Forecasting Loss:0.9873 + XiCon Loss:1.8037 x Lambda(0.1)), Vali MSE Loss: 1.2390 Test MSE Loss: 0.9930
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.343261480331421
Epoch: 4, Steps: 59 Train Loss: 1.1694 (Forecasting Loss:0.9879 + XiCon Loss:1.8153 x Lambda(0.1)), Vali MSE Loss: 1.2405 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2464468479156494
Epoch: 5, Steps: 59 Train Loss: 1.1691 (Forecasting Loss:0.9885 + XiCon Loss:1.8057 x Lambda(0.1)), Vali MSE Loss: 1.2295 Test MSE Loss: 0.9929
Validation loss decreased (1.234277 --> 1.229549).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2263355255126953
Epoch: 6, Steps: 59 Train Loss: 1.1694 (Forecasting Loss:0.9884 + XiCon Loss:1.8095 x Lambda(0.1)), Vali MSE Loss: 1.2380 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.3192033767700195
Epoch: 7, Steps: 59 Train Loss: 1.1669 (Forecasting Loss:0.9858 + XiCon Loss:1.8111 x Lambda(0.1)), Vali MSE Loss: 1.2339 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2381458282470703
Epoch: 8, Steps: 59 Train Loss: 1.1680 (Forecasting Loss:0.9868 + XiCon Loss:1.8128 x Lambda(0.1)), Vali MSE Loss: 1.2318 Test MSE Loss: 0.9929
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2341101169586182
Epoch: 9, Steps: 59 Train Loss: 1.1678 (Forecasting Loss:0.9867 + XiCon Loss:1.8108 x Lambda(0.1)), Vali MSE Loss: 1.2311 Test MSE Loss: 0.9929
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2541165351867676
Epoch: 10, Steps: 59 Train Loss: 1.1684 (Forecasting Loss:0.9879 + XiCon Loss:1.8049 x Lambda(0.1)), Vali MSE Loss: 1.2336 Test MSE Loss: 0.9929
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2485215663909912
Epoch: 11, Steps: 59 Train Loss: 1.1681 (Forecasting Loss:0.9873 + XiCon Loss:1.8078 x Lambda(0.1)), Vali MSE Loss: 1.2398 Test MSE Loss: 0.9929
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.3404731750488281
Epoch: 12, Steps: 59 Train Loss: 1.1686 (Forecasting Loss:0.9877 + XiCon Loss:1.8089 x Lambda(0.1)), Vali MSE Loss: 1.2261 Test MSE Loss: 0.9929
Validation loss decreased (1.229549 --> 1.226144).  Saving model ...
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2749476432800293
Epoch: 13, Steps: 59 Train Loss: 1.1695 (Forecasting Loss:0.9882 + XiCon Loss:1.8134 x Lambda(0.1)), Vali MSE Loss: 1.2305 Test MSE Loss: 0.9929
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.2850966453552246
Epoch: 14, Steps: 59 Train Loss: 1.1689 (Forecasting Loss:0.9877 + XiCon Loss:1.8118 x Lambda(0.1)), Vali MSE Loss: 1.2351 Test MSE Loss: 0.9929
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.2456297874450684
Epoch: 15, Steps: 59 Train Loss: 1.1693 (Forecasting Loss:0.9882 + XiCon Loss:1.8104 x Lambda(0.1)), Vali MSE Loss: 1.2264 Test MSE Loss: 0.9929
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-10
Epoch: 16 cost time: 1.2825953960418701
Epoch: 16, Steps: 59 Train Loss: 1.1679 (Forecasting Loss:0.9869 + XiCon Loss:1.8104 x Lambda(0.1)), Vali MSE Loss: 1.2417 Test MSE Loss: 0.9929
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-10
Epoch: 17 cost time: 1.3044226169586182
Epoch: 17, Steps: 59 Train Loss: 1.1686 (Forecasting Loss:0.9874 + XiCon Loss:1.8113 x Lambda(0.1)), Vali MSE Loss: 1.2281 Test MSE Loss: 0.9929
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-10
Epoch: 18 cost time: 1.2706549167633057
Epoch: 18, Steps: 59 Train Loss: 1.1688 (Forecasting Loss:0.9880 + XiCon Loss:1.8079 x Lambda(0.1)), Vali MSE Loss: 1.2300 Test MSE Loss: 0.9929
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-11
Epoch: 19 cost time: 1.2770137786865234
Epoch: 19, Steps: 59 Train Loss: 1.1685 (Forecasting Loss:0.9874 + XiCon Loss:1.8107 x Lambda(0.1)), Vali MSE Loss: 1.2359 Test MSE Loss: 0.9929
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-11
Epoch: 20 cost time: 1.266897201538086
Epoch: 20, Steps: 59 Train Loss: 1.1681 (Forecasting Loss:0.9874 + XiCon Loss:1.8064 x Lambda(0.1)), Vali MSE Loss: 1.2331 Test MSE Loss: 0.9929
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-11
Epoch: 21 cost time: 1.2610399723052979
Epoch: 21, Steps: 59 Train Loss: 1.1680 (Forecasting Loss:0.9875 + XiCon Loss:1.8045 x Lambda(0.1)), Vali MSE Loss: 1.2453 Test MSE Loss: 0.9929
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-12
Epoch: 22 cost time: 1.2605881690979004
Epoch: 22, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9885 + XiCon Loss:1.8108 x Lambda(0.1)), Vali MSE Loss: 1.2298 Test MSE Loss: 0.9929
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.161300539970398, mae:0.8244640231132507, mape:0.7876735925674438, mspe:1.8508543968200684 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6504
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.2904469966888428
Epoch: 1, Steps: 59 Train Loss: 1.1705 (Forecasting Loss:0.9902 + XiCon Loss:1.8027 x Lambda(0.1)), Vali MSE Loss: 1.2476 Test MSE Loss: 0.9847
Validation loss decreased (inf --> 1.247572).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.3041620254516602
Epoch: 2, Steps: 59 Train Loss: 1.1718 (Forecasting Loss:0.9905 + XiCon Loss:1.8124 x Lambda(0.1)), Vali MSE Loss: 1.2353 Test MSE Loss: 0.9843
Validation loss decreased (1.247572 --> 1.235335).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.3077764511108398
Epoch: 3, Steps: 59 Train Loss: 1.1700 (Forecasting Loss:0.9897 + XiCon Loss:1.8024 x Lambda(0.1)), Vali MSE Loss: 1.2344 Test MSE Loss: 0.9841
Validation loss decreased (1.235335 --> 1.234446).  Saving model ...
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2802481651306152
Epoch: 4, Steps: 59 Train Loss: 1.1691 (Forecasting Loss:0.9882 + XiCon Loss:1.8087 x Lambda(0.1)), Vali MSE Loss: 1.2537 Test MSE Loss: 0.9841
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2672615051269531
Epoch: 5, Steps: 59 Train Loss: 1.1691 (Forecasting Loss:0.9884 + XiCon Loss:1.8064 x Lambda(0.1)), Vali MSE Loss: 1.2452 Test MSE Loss: 0.9840
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2862858772277832
Epoch: 6, Steps: 59 Train Loss: 1.1705 (Forecasting Loss:0.9891 + XiCon Loss:1.8130 x Lambda(0.1)), Vali MSE Loss: 1.2438 Test MSE Loss: 0.9840
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2429225444793701
Epoch: 7, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9891 + XiCon Loss:1.8048 x Lambda(0.1)), Vali MSE Loss: 1.2494 Test MSE Loss: 0.9840
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2757811546325684
Epoch: 8, Steps: 59 Train Loss: 1.1687 (Forecasting Loss:0.9880 + XiCon Loss:1.8066 x Lambda(0.1)), Vali MSE Loss: 1.2578 Test MSE Loss: 0.9840
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2621674537658691
Epoch: 9, Steps: 59 Train Loss: 1.1685 (Forecasting Loss:0.9874 + XiCon Loss:1.8113 x Lambda(0.1)), Vali MSE Loss: 1.2502 Test MSE Loss: 0.9840
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2684168815612793
Epoch: 10, Steps: 59 Train Loss: 1.1699 (Forecasting Loss:0.9890 + XiCon Loss:1.8092 x Lambda(0.1)), Vali MSE Loss: 1.2534 Test MSE Loss: 0.9840
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.2601346969604492
Epoch: 11, Steps: 59 Train Loss: 1.1688 (Forecasting Loss:0.9876 + XiCon Loss:1.8116 x Lambda(0.1)), Vali MSE Loss: 1.2471 Test MSE Loss: 0.9840
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.294055461883545
Epoch: 12, Steps: 59 Train Loss: 1.1684 (Forecasting Loss:0.9882 + XiCon Loss:1.8018 x Lambda(0.1)), Vali MSE Loss: 1.2407 Test MSE Loss: 0.9840
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2891132831573486
Epoch: 13, Steps: 59 Train Loss: 1.1692 (Forecasting Loss:0.9886 + XiCon Loss:1.8056 x Lambda(0.1)), Vali MSE Loss: 1.2568 Test MSE Loss: 0.9840
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1478869915008545, mae:0.8203794360160828, mape:0.7830183506011963, mspe:1.8312407732009888 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5988
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.342787742614746
Epoch: 1, Steps: 59 Train Loss: 1.1700 (Forecasting Loss:0.9890 + XiCon Loss:1.8102 x Lambda(0.1)), Vali MSE Loss: 1.2400 Test MSE Loss: 0.9959
Validation loss decreased (inf --> 1.240049).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.276726484298706
Epoch: 2, Steps: 59 Train Loss: 1.1707 (Forecasting Loss:0.9898 + XiCon Loss:1.8087 x Lambda(0.1)), Vali MSE Loss: 1.2225 Test MSE Loss: 0.9958
Validation loss decreased (1.240049 --> 1.222507).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.2630598545074463
Epoch: 3, Steps: 59 Train Loss: 1.1685 (Forecasting Loss:0.9878 + XiCon Loss:1.8077 x Lambda(0.1)), Vali MSE Loss: 1.2320 Test MSE Loss: 0.9957
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.293928861618042
Epoch: 4, Steps: 59 Train Loss: 1.1696 (Forecasting Loss:0.9888 + XiCon Loss:1.8078 x Lambda(0.1)), Vali MSE Loss: 1.2313 Test MSE Loss: 0.9957
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2848381996154785
Epoch: 5, Steps: 59 Train Loss: 1.1693 (Forecasting Loss:0.9883 + XiCon Loss:1.8094 x Lambda(0.1)), Vali MSE Loss: 1.2232 Test MSE Loss: 0.9957
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.2670016288757324
Epoch: 6, Steps: 59 Train Loss: 1.1700 (Forecasting Loss:0.9890 + XiCon Loss:1.8109 x Lambda(0.1)), Vali MSE Loss: 1.2341 Test MSE Loss: 0.9956
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.3936436176300049
Epoch: 7, Steps: 59 Train Loss: 1.1692 (Forecasting Loss:0.9881 + XiCon Loss:1.8116 x Lambda(0.1)), Vali MSE Loss: 1.2251 Test MSE Loss: 0.9956
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2596495151519775
Epoch: 8, Steps: 59 Train Loss: 1.1688 (Forecasting Loss:0.9873 + XiCon Loss:1.8146 x Lambda(0.1)), Vali MSE Loss: 1.2238 Test MSE Loss: 0.9956
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2491154670715332
Epoch: 9, Steps: 59 Train Loss: 1.1684 (Forecasting Loss:0.9873 + XiCon Loss:1.8104 x Lambda(0.1)), Vali MSE Loss: 1.2346 Test MSE Loss: 0.9956
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2529759407043457
Epoch: 10, Steps: 59 Train Loss: 1.1687 (Forecasting Loss:0.9882 + XiCon Loss:1.8046 x Lambda(0.1)), Vali MSE Loss: 1.2328 Test MSE Loss: 0.9956
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.244629144668579
Epoch: 11, Steps: 59 Train Loss: 1.1675 (Forecasting Loss:0.9864 + XiCon Loss:1.8116 x Lambda(0.1)), Vali MSE Loss: 1.2318 Test MSE Loss: 0.9956
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2883071899414062
Epoch: 12, Steps: 59 Train Loss: 1.1693 (Forecasting Loss:0.9881 + XiCon Loss:1.8116 x Lambda(0.1)), Vali MSE Loss: 1.2322 Test MSE Loss: 0.9956
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.16544771194458, mae:0.8261314630508423, mape:0.789111852645874, mspe:1.8550541400909424 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:74369
train 3785
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6926
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3785
val 800
test 798
Epoch: 1 cost time: 1.3253858089447021
Epoch: 1, Steps: 59 Train Loss: 1.1747 (Forecasting Loss:0.9941 + XiCon Loss:1.8055 x Lambda(0.1)), Vali MSE Loss: 1.2756 Test MSE Loss: 0.9658
Validation loss decreased (inf --> 1.275611).  Saving model ...
Updating learning rate to 1e-05
Epoch: 2 cost time: 1.2723345756530762
Epoch: 2, Steps: 59 Train Loss: 1.1738 (Forecasting Loss:0.9928 + XiCon Loss:1.8094 x Lambda(0.1)), Vali MSE Loss: 1.2744 Test MSE Loss: 0.9658
Validation loss decreased (1.275611 --> 1.274429).  Saving model ...
Updating learning rate to 5e-06
Epoch: 3 cost time: 1.27183198928833
Epoch: 3, Steps: 59 Train Loss: 1.1743 (Forecasting Loss:0.9934 + XiCon Loss:1.8089 x Lambda(0.1)), Vali MSE Loss: 1.2848 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-06
Epoch: 4 cost time: 1.2776572704315186
Epoch: 4, Steps: 59 Train Loss: 1.1725 (Forecasting Loss:0.9923 + XiCon Loss:1.8025 x Lambda(0.1)), Vali MSE Loss: 1.2802 Test MSE Loss: 0.9658
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-06
Epoch: 5 cost time: 1.2527718544006348
Epoch: 5, Steps: 59 Train Loss: 1.1736 (Forecasting Loss:0.9928 + XiCon Loss:1.8086 x Lambda(0.1)), Vali MSE Loss: 1.2741 Test MSE Loss: 0.9658
Validation loss decreased (1.274429 --> 1.274143).  Saving model ...
Updating learning rate to 6.25e-07
Epoch: 6 cost time: 1.3295443058013916
Epoch: 6, Steps: 59 Train Loss: 1.1742 (Forecasting Loss:0.9934 + XiCon Loss:1.8073 x Lambda(0.1)), Vali MSE Loss: 1.2844 Test MSE Loss: 0.9658
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-07
Epoch: 7 cost time: 1.2376465797424316
Epoch: 7, Steps: 59 Train Loss: 1.1731 (Forecasting Loss:0.9924 + XiCon Loss:1.8065 x Lambda(0.1)), Vali MSE Loss: 1.2774 Test MSE Loss: 0.9658
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-07
Epoch: 8 cost time: 1.2724254131317139
Epoch: 8, Steps: 59 Train Loss: 1.1725 (Forecasting Loss:0.9920 + XiCon Loss:1.8049 x Lambda(0.1)), Vali MSE Loss: 1.2823 Test MSE Loss: 0.9658
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-08
Epoch: 9 cost time: 1.2684540748596191
Epoch: 9, Steps: 59 Train Loss: 1.1739 (Forecasting Loss:0.9931 + XiCon Loss:1.8079 x Lambda(0.1)), Vali MSE Loss: 1.2885 Test MSE Loss: 0.9658
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-08
Epoch: 10 cost time: 1.2858095169067383
Epoch: 10, Steps: 59 Train Loss: 1.1727 (Forecasting Loss:0.9923 + XiCon Loss:1.8039 x Lambda(0.1)), Vali MSE Loss: 1.2791 Test MSE Loss: 0.9658
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-08
Epoch: 11 cost time: 1.246788501739502
Epoch: 11, Steps: 59 Train Loss: 1.1736 (Forecasting Loss:0.9927 + XiCon Loss:1.8090 x Lambda(0.1)), Vali MSE Loss: 1.2747 Test MSE Loss: 0.9658
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-09
Epoch: 12 cost time: 1.2993342876434326
Epoch: 12, Steps: 59 Train Loss: 1.1731 (Forecasting Loss:0.9933 + XiCon Loss:1.7982 x Lambda(0.1)), Vali MSE Loss: 1.2766 Test MSE Loss: 0.9658
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-09
Epoch: 13 cost time: 1.2302720546722412
Epoch: 13, Steps: 59 Train Loss: 1.1728 (Forecasting Loss:0.9921 + XiCon Loss:1.8062 x Lambda(0.1)), Vali MSE Loss: 1.2819 Test MSE Loss: 0.9658
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-09
Epoch: 14 cost time: 1.3194787502288818
Epoch: 14, Steps: 59 Train Loss: 1.1731 (Forecasting Loss:0.9917 + XiCon Loss:1.8146 x Lambda(0.1)), Vali MSE Loss: 1.2817 Test MSE Loss: 0.9658
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-09
Epoch: 15 cost time: 1.2857568264007568
Epoch: 15, Steps: 59 Train Loss: 1.1730 (Forecasting Loss:0.9928 + XiCon Loss:1.8028 x Lambda(0.1)), Vali MSE Loss: 1.2800 Test MSE Loss: 0.9658
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl720_dm16_nh8_el1_dl1_df16_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 798
test shape: (12, 64, 720, 1) (12, 64, 720, 1)
test shape: (768, 720, 1) (768, 720, 1)
mse:1.1206905841827393, mae:0.8108737468719482, mape:0.7731555104255676, mspe:1.7926894426345825 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.1482+-0.02180, MAE:0.8201+-0.00741, MAPE:0.7830+-0.00777, MSPE:1.8321+-0.03064, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[48, 540, 1080], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='exchange_rate', root_path='./dataset/exchange_rate', data_path='exchange_rate.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=48, label_len=24, pred_len=1080, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=1, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6759
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.9724507331848145
Epoch: 1, Steps: 53 Train Loss: 1.6690 (Forecasting Loss:1.4862 + XiCon Loss:1.8276 x Lambda(0.1)), Vali MSE Loss: 1.8587 Test MSE Loss: 0.9063
Validation loss decreased (inf --> 1.858724).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.613736629486084
Epoch: 2, Steps: 53 Train Loss: 1.6621 (Forecasting Loss:1.4798 + XiCon Loss:1.8230 x Lambda(0.1)), Vali MSE Loss: 1.8414 Test MSE Loss: 0.9182
Validation loss decreased (1.858724 --> 1.841442).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.595865249633789
Epoch: 3, Steps: 53 Train Loss: 1.6561 (Forecasting Loss:1.4737 + XiCon Loss:1.8239 x Lambda(0.1)), Vali MSE Loss: 1.8451 Test MSE Loss: 0.9228
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.6149814128875732
Epoch: 4, Steps: 53 Train Loss: 1.6543 (Forecasting Loss:1.4717 + XiCon Loss:1.8259 x Lambda(0.1)), Vali MSE Loss: 1.8424 Test MSE Loss: 0.9250
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6095876693725586
Epoch: 5, Steps: 53 Train Loss: 1.6502 (Forecasting Loss:1.4674 + XiCon Loss:1.8284 x Lambda(0.1)), Vali MSE Loss: 1.8229 Test MSE Loss: 0.9260
Validation loss decreased (1.841442 --> 1.822858).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6028881072998047
Epoch: 6, Steps: 53 Train Loss: 1.6525 (Forecasting Loss:1.4701 + XiCon Loss:1.8246 x Lambda(0.1)), Vali MSE Loss: 1.8259 Test MSE Loss: 0.9266
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.608649492263794
Epoch: 7, Steps: 53 Train Loss: 1.6491 (Forecasting Loss:1.4668 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 1.7963 Test MSE Loss: 0.9269
Validation loss decreased (1.822858 --> 1.796346).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5866103172302246
Epoch: 8, Steps: 53 Train Loss: 1.6475 (Forecasting Loss:1.4657 + XiCon Loss:1.8187 x Lambda(0.1)), Vali MSE Loss: 1.8524 Test MSE Loss: 0.9270
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.629866361618042
Epoch: 9, Steps: 53 Train Loss: 1.6486 (Forecasting Loss:1.4667 + XiCon Loss:1.8190 x Lambda(0.1)), Vali MSE Loss: 1.8147 Test MSE Loss: 0.9271
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.6973652839660645
Epoch: 10, Steps: 53 Train Loss: 1.6506 (Forecasting Loss:1.4682 + XiCon Loss:1.8240 x Lambda(0.1)), Vali MSE Loss: 1.8543 Test MSE Loss: 0.9271
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.7305946350097656
Epoch: 11, Steps: 53 Train Loss: 1.6473 (Forecasting Loss:1.4649 + XiCon Loss:1.8237 x Lambda(0.1)), Vali MSE Loss: 1.8365 Test MSE Loss: 0.9271
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.7062523365020752
Epoch: 12, Steps: 53 Train Loss: 1.6480 (Forecasting Loss:1.4660 + XiCon Loss:1.8203 x Lambda(0.1)), Vali MSE Loss: 1.8127 Test MSE Loss: 0.9271
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6931273937225342
Epoch: 13, Steps: 53 Train Loss: 1.6496 (Forecasting Loss:1.4667 + XiCon Loss:1.8292 x Lambda(0.1)), Vali MSE Loss: 1.8496 Test MSE Loss: 0.9271
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.7081899642944336
Epoch: 14, Steps: 53 Train Loss: 1.6502 (Forecasting Loss:1.4679 + XiCon Loss:1.8233 x Lambda(0.1)), Vali MSE Loss: 1.8041 Test MSE Loss: 0.9271
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.716062307357788
Epoch: 15, Steps: 53 Train Loss: 1.6469 (Forecasting Loss:1.4647 + XiCon Loss:1.8225 x Lambda(0.1)), Vali MSE Loss: 1.8463 Test MSE Loss: 0.9271
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.7105028629302979
Epoch: 16, Steps: 53 Train Loss: 1.6473 (Forecasting Loss:1.4655 + XiCon Loss:1.8184 x Lambda(0.1)), Vali MSE Loss: 1.8264 Test MSE Loss: 0.9271
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.7060396671295166
Epoch: 17, Steps: 53 Train Loss: 1.6492 (Forecasting Loss:1.4672 + XiCon Loss:1.8200 x Lambda(0.1)), Vali MSE Loss: 1.8433 Test MSE Loss: 0.9271
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0581330060958862, mae:0.7955676913261414, mape:0.7948112487792969, mspe:1.7963939905166626 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.6227
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6337192058563232
Epoch: 1, Steps: 53 Train Loss: 1.6656 (Forecasting Loss:1.4830 + XiCon Loss:1.8255 x Lambda(0.1)), Vali MSE Loss: 1.8282 Test MSE Loss: 0.9301
Validation loss decreased (inf --> 1.828228).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.634145736694336
Epoch: 2, Steps: 53 Train Loss: 1.6613 (Forecasting Loss:1.4788 + XiCon Loss:1.8250 x Lambda(0.1)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9332
Validation loss decreased (1.828228 --> 1.821750).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.6372106075286865
Epoch: 3, Steps: 53 Train Loss: 1.6557 (Forecasting Loss:1.4730 + XiCon Loss:1.8269 x Lambda(0.1)), Vali MSE Loss: 1.7989 Test MSE Loss: 0.9348
Validation loss decreased (1.821750 --> 1.798851).  Saving model ...
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.594059705734253
Epoch: 4, Steps: 53 Train Loss: 1.6548 (Forecasting Loss:1.4713 + XiCon Loss:1.8350 x Lambda(0.1)), Vali MSE Loss: 1.8007 Test MSE Loss: 0.9356
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5738232135772705
Epoch: 5, Steps: 53 Train Loss: 1.6570 (Forecasting Loss:1.4741 + XiCon Loss:1.8281 x Lambda(0.1)), Vali MSE Loss: 1.8217 Test MSE Loss: 0.9361
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5922574996948242
Epoch: 6, Steps: 53 Train Loss: 1.6518 (Forecasting Loss:1.4691 + XiCon Loss:1.8273 x Lambda(0.1)), Vali MSE Loss: 1.8083 Test MSE Loss: 0.9363
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6013221740722656
Epoch: 7, Steps: 53 Train Loss: 1.6505 (Forecasting Loss:1.4677 + XiCon Loss:1.8282 x Lambda(0.1)), Vali MSE Loss: 1.7827 Test MSE Loss: 0.9364
Validation loss decreased (1.798851 --> 1.782685).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6551580429077148
Epoch: 8, Steps: 53 Train Loss: 1.6520 (Forecasting Loss:1.4690 + XiCon Loss:1.8300 x Lambda(0.1)), Vali MSE Loss: 1.8251 Test MSE Loss: 0.9364
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.6134707927703857
Epoch: 9, Steps: 53 Train Loss: 1.6476 (Forecasting Loss:1.4651 + XiCon Loss:1.8246 x Lambda(0.1)), Vali MSE Loss: 1.8224 Test MSE Loss: 0.9364
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.5948166847229004
Epoch: 10, Steps: 53 Train Loss: 1.6534 (Forecasting Loss:1.4705 + XiCon Loss:1.8289 x Lambda(0.1)), Vali MSE Loss: 1.8325 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5987555980682373
Epoch: 11, Steps: 53 Train Loss: 1.6519 (Forecasting Loss:1.4694 + XiCon Loss:1.8253 x Lambda(0.1)), Vali MSE Loss: 1.8406 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.644458532333374
Epoch: 12, Steps: 53 Train Loss: 1.6521 (Forecasting Loss:1.4688 + XiCon Loss:1.8328 x Lambda(0.1)), Vali MSE Loss: 1.7661 Test MSE Loss: 0.9365
Validation loss decreased (1.782685 --> 1.766075).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6443278789520264
Epoch: 13, Steps: 53 Train Loss: 1.6528 (Forecasting Loss:1.4697 + XiCon Loss:1.8309 x Lambda(0.1)), Vali MSE Loss: 1.8091 Test MSE Loss: 0.9365
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.7206134796142578
Epoch: 14, Steps: 53 Train Loss: 1.6528 (Forecasting Loss:1.4703 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 1.8040 Test MSE Loss: 0.9365
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6798040866851807
Epoch: 15, Steps: 53 Train Loss: 1.6494 (Forecasting Loss:1.4668 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 1.7980 Test MSE Loss: 0.9365
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.6488797664642334
Epoch: 16, Steps: 53 Train Loss: 1.6533 (Forecasting Loss:1.4705 + XiCon Loss:1.8271 x Lambda(0.1)), Vali MSE Loss: 1.7910 Test MSE Loss: 0.9365
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.635251760482788
Epoch: 17, Steps: 53 Train Loss: 1.6507 (Forecasting Loss:1.4679 + XiCon Loss:1.8277 x Lambda(0.1)), Vali MSE Loss: 1.8299 Test MSE Loss: 0.9365
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.6265294551849365
Epoch: 18, Steps: 53 Train Loss: 1.6513 (Forecasting Loss:1.4684 + XiCon Loss:1.8289 x Lambda(0.1)), Vali MSE Loss: 1.8234 Test MSE Loss: 0.9365
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.6030068397521973
Epoch: 19, Steps: 53 Train Loss: 1.6545 (Forecasting Loss:1.4716 + XiCon Loss:1.8290 x Lambda(0.1)), Vali MSE Loss: 1.8128 Test MSE Loss: 0.9365
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.6425483226776123
Epoch: 20, Steps: 53 Train Loss: 1.6501 (Forecasting Loss:1.4675 + XiCon Loss:1.8261 x Lambda(0.1)), Vali MSE Loss: 1.8118 Test MSE Loss: 0.9365
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.6024353504180908
Epoch: 21, Steps: 53 Train Loss: 1.6513 (Forecasting Loss:1.4688 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 1.8081 Test MSE Loss: 0.9365
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.6111927032470703
Epoch: 22, Steps: 53 Train Loss: 1.6533 (Forecasting Loss:1.4704 + XiCon Loss:1.8289 x Lambda(0.1)), Vali MSE Loss: 1.8224 Test MSE Loss: 0.9365
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0729568004608154, mae:0.7999805808067322, mape:0.8005019426345825, mspe:1.8210256099700928 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5779
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.637646198272705
Epoch: 1, Steps: 53 Train Loss: 1.6689 (Forecasting Loss:1.4859 + XiCon Loss:1.8300 x Lambda(0.1)), Vali MSE Loss: 1.8992 Test MSE Loss: 0.9118
Validation loss decreased (inf --> 1.899225).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.660926342010498
Epoch: 2, Steps: 53 Train Loss: 1.6666 (Forecasting Loss:1.4836 + XiCon Loss:1.8292 x Lambda(0.1)), Vali MSE Loss: 1.8448 Test MSE Loss: 0.9161
Validation loss decreased (1.899225 --> 1.844775).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.725106954574585
Epoch: 3, Steps: 53 Train Loss: 1.6629 (Forecasting Loss:1.4805 + XiCon Loss:1.8240 x Lambda(0.1)), Vali MSE Loss: 1.8756 Test MSE Loss: 0.9186
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.6963412761688232
Epoch: 4, Steps: 53 Train Loss: 1.6516 (Forecasting Loss:1.4686 + XiCon Loss:1.8302 x Lambda(0.1)), Vali MSE Loss: 1.8565 Test MSE Loss: 0.9199
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.6591193675994873
Epoch: 5, Steps: 53 Train Loss: 1.6555 (Forecasting Loss:1.4727 + XiCon Loss:1.8278 x Lambda(0.1)), Vali MSE Loss: 1.8090 Test MSE Loss: 0.9206
Validation loss decreased (1.844775 --> 1.809025).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.714773416519165
Epoch: 6, Steps: 53 Train Loss: 1.6558 (Forecasting Loss:1.4731 + XiCon Loss:1.8267 x Lambda(0.1)), Vali MSE Loss: 1.8718 Test MSE Loss: 0.9210
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.6012787818908691
Epoch: 7, Steps: 53 Train Loss: 1.6576 (Forecasting Loss:1.4745 + XiCon Loss:1.8310 x Lambda(0.1)), Vali MSE Loss: 1.8674 Test MSE Loss: 0.9212
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6206302642822266
Epoch: 8, Steps: 53 Train Loss: 1.6549 (Forecasting Loss:1.4725 + XiCon Loss:1.8240 x Lambda(0.1)), Vali MSE Loss: 1.8521 Test MSE Loss: 0.9213
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5687193870544434
Epoch: 9, Steps: 53 Train Loss: 1.6543 (Forecasting Loss:1.4719 + XiCon Loss:1.8236 x Lambda(0.1)), Vali MSE Loss: 1.8343 Test MSE Loss: 0.9213
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.6438937187194824
Epoch: 10, Steps: 53 Train Loss: 1.6514 (Forecasting Loss:1.4682 + XiCon Loss:1.8312 x Lambda(0.1)), Vali MSE Loss: 1.8585 Test MSE Loss: 0.9214
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.60990571975708
Epoch: 11, Steps: 53 Train Loss: 1.6560 (Forecasting Loss:1.4731 + XiCon Loss:1.8298 x Lambda(0.1)), Vali MSE Loss: 1.8447 Test MSE Loss: 0.9214
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5954504013061523
Epoch: 12, Steps: 53 Train Loss: 1.6515 (Forecasting Loss:1.4690 + XiCon Loss:1.8248 x Lambda(0.1)), Vali MSE Loss: 1.8314 Test MSE Loss: 0.9214
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.6152682304382324
Epoch: 13, Steps: 53 Train Loss: 1.6511 (Forecasting Loss:1.4682 + XiCon Loss:1.8290 x Lambda(0.1)), Vali MSE Loss: 1.8584 Test MSE Loss: 0.9214
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.606980800628662
Epoch: 14, Steps: 53 Train Loss: 1.6520 (Forecasting Loss:1.4690 + XiCon Loss:1.8301 x Lambda(0.1)), Vali MSE Loss: 1.8336 Test MSE Loss: 0.9214
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.6164910793304443
Epoch: 15, Steps: 53 Train Loss: 1.6519 (Forecasting Loss:1.4694 + XiCon Loss:1.8252 x Lambda(0.1)), Vali MSE Loss: 1.8908 Test MSE Loss: 0.9214
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0489158630371094, mae:0.7923353314399719, mape:0.7911276817321777, mspe:1.779982328414917 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5740
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.6240780353546143
Epoch: 1, Steps: 53 Train Loss: 1.6827 (Forecasting Loss:1.4999 + XiCon Loss:1.8280 x Lambda(0.1)), Vali MSE Loss: 1.9955 Test MSE Loss: 0.8645
Validation loss decreased (inf --> 1.995502).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.5690550804138184
Epoch: 2, Steps: 53 Train Loss: 1.6804 (Forecasting Loss:1.4971 + XiCon Loss:1.8331 x Lambda(0.1)), Vali MSE Loss: 1.9517 Test MSE Loss: 0.8742
Validation loss decreased (1.995502 --> 1.951716).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5561811923980713
Epoch: 3, Steps: 53 Train Loss: 1.6727 (Forecasting Loss:1.4898 + XiCon Loss:1.8290 x Lambda(0.1)), Vali MSE Loss: 1.9642 Test MSE Loss: 0.8828
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.555201768875122
Epoch: 4, Steps: 53 Train Loss: 1.6636 (Forecasting Loss:1.4809 + XiCon Loss:1.8270 x Lambda(0.1)), Vali MSE Loss: 1.9473 Test MSE Loss: 0.8887
Validation loss decreased (1.951716 --> 1.947338).  Saving model ...
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5856082439422607
Epoch: 5, Steps: 53 Train Loss: 1.6572 (Forecasting Loss:1.4745 + XiCon Loss:1.8268 x Lambda(0.1)), Vali MSE Loss: 1.9099 Test MSE Loss: 0.8921
Validation loss decreased (1.947338 --> 1.909925).  Saving model ...
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.5293457508087158
Epoch: 6, Steps: 53 Train Loss: 1.6579 (Forecasting Loss:1.4753 + XiCon Loss:1.8260 x Lambda(0.1)), Vali MSE Loss: 1.9529 Test MSE Loss: 0.8940
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.5885517597198486
Epoch: 7, Steps: 53 Train Loss: 1.6611 (Forecasting Loss:1.4776 + XiCon Loss:1.8344 x Lambda(0.1)), Vali MSE Loss: 1.9025 Test MSE Loss: 0.8949
Validation loss decreased (1.909925 --> 1.902510).  Saving model ...
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.5691559314727783
Epoch: 8, Steps: 53 Train Loss: 1.6566 (Forecasting Loss:1.4737 + XiCon Loss:1.8290 x Lambda(0.1)), Vali MSE Loss: 1.9125 Test MSE Loss: 0.8954
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.5123581886291504
Epoch: 9, Steps: 53 Train Loss: 1.6567 (Forecasting Loss:1.4738 + XiCon Loss:1.8286 x Lambda(0.1)), Vali MSE Loss: 1.9147 Test MSE Loss: 0.8956
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.534691333770752
Epoch: 10, Steps: 53 Train Loss: 1.6581 (Forecasting Loss:1.4750 + XiCon Loss:1.8312 x Lambda(0.1)), Vali MSE Loss: 1.8912 Test MSE Loss: 0.8957
Validation loss decreased (1.902510 --> 1.891249).  Saving model ...
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.5463974475860596
Epoch: 11, Steps: 53 Train Loss: 1.6571 (Forecasting Loss:1.4746 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 1.9054 Test MSE Loss: 0.8958
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.5436375141143799
Epoch: 12, Steps: 53 Train Loss: 1.6564 (Forecasting Loss:1.4740 + XiCon Loss:1.8243 x Lambda(0.1)), Vali MSE Loss: 1.8726 Test MSE Loss: 0.8958
Validation loss decreased (1.891249 --> 1.872612).  Saving model ...
Updating learning rate to 4.8828125e-08
Epoch: 13 cost time: 1.5114123821258545
Epoch: 13, Steps: 53 Train Loss: 1.6581 (Forecasting Loss:1.4749 + XiCon Loss:1.8316 x Lambda(0.1)), Vali MSE Loss: 1.9039 Test MSE Loss: 0.8958
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
Epoch: 14 cost time: 1.5255424976348877
Epoch: 14, Steps: 53 Train Loss: 1.6593 (Forecasting Loss:1.4768 + XiCon Loss:1.8252 x Lambda(0.1)), Vali MSE Loss: 1.9080 Test MSE Loss: 0.8958
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
Epoch: 15 cost time: 1.693681001663208
Epoch: 15, Steps: 53 Train Loss: 1.6594 (Forecasting Loss:1.4767 + XiCon Loss:1.8270 x Lambda(0.1)), Vali MSE Loss: 1.9072 Test MSE Loss: 0.8958
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
Epoch: 16 cost time: 1.5685570240020752
Epoch: 16, Steps: 53 Train Loss: 1.6562 (Forecasting Loss:1.4735 + XiCon Loss:1.8267 x Lambda(0.1)), Vali MSE Loss: 1.8978 Test MSE Loss: 0.8958
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
Epoch: 17 cost time: 1.5668702125549316
Epoch: 17, Steps: 53 Train Loss: 1.6549 (Forecasting Loss:1.4723 + XiCon Loss:1.8258 x Lambda(0.1)), Vali MSE Loss: 1.9176 Test MSE Loss: 0.8958
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
Epoch: 18 cost time: 1.5499327182769775
Epoch: 18, Steps: 53 Train Loss: 1.6565 (Forecasting Loss:1.4730 + XiCon Loss:1.8348 x Lambda(0.1)), Vali MSE Loss: 1.9322 Test MSE Loss: 0.8958
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.62939453125e-10
Epoch: 19 cost time: 1.5376918315887451
Epoch: 19, Steps: 53 Train Loss: 1.6535 (Forecasting Loss:1.4701 + XiCon Loss:1.8332 x Lambda(0.1)), Vali MSE Loss: 1.8962 Test MSE Loss: 0.8958
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.814697265625e-10
Epoch: 20 cost time: 1.538550853729248
Epoch: 20, Steps: 53 Train Loss: 1.6591 (Forecasting Loss:1.4763 + XiCon Loss:1.8278 x Lambda(0.1)), Vali MSE Loss: 1.9136 Test MSE Loss: 0.8958
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.9073486328125e-10
Epoch: 21 cost time: 1.6516380310058594
Epoch: 21, Steps: 53 Train Loss: 1.6562 (Forecasting Loss:1.4731 + XiCon Loss:1.8319 x Lambda(0.1)), Vali MSE Loss: 1.8797 Test MSE Loss: 0.8958
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.5367431640625e-11
Epoch: 22 cost time: 1.5593204498291016
Epoch: 22, Steps: 53 Train Loss: 1.6584 (Forecasting Loss:1.4753 + XiCon Loss:1.8318 x Lambda(0.1)), Vali MSE Loss: 1.9074 Test MSE Loss: 0.8958
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.0115267038345337, mae:0.7800968885421753, mape:0.7759758234024048, mspe:1.7184942960739136 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:106867
train 3425
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99959654] ~ [5.99339309e-05 2.99100055e-05]
Xi-correlation values:[0.99934109 0.99311935] ~ [0. 1.]
Autocorrelation calculation time: 0.5728
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 3425
val 440
test 438
Epoch: 1 cost time: 1.5410175323486328
Epoch: 1, Steps: 53 Train Loss: 1.6590 (Forecasting Loss:1.4763 + XiCon Loss:1.8260 x Lambda(0.1)), Vali MSE Loss: 1.7407 Test MSE Loss: 0.9553
Validation loss decreased (inf --> 1.740656).  Saving model ...
Updating learning rate to 0.0001
Epoch: 2 cost time: 1.538541555404663
Epoch: 2, Steps: 53 Train Loss: 1.6559 (Forecasting Loss:1.4731 + XiCon Loss:1.8279 x Lambda(0.1)), Vali MSE Loss: 1.7205 Test MSE Loss: 0.9607
Validation loss decreased (1.740656 --> 1.720533).  Saving model ...
Updating learning rate to 5e-05
Epoch: 3 cost time: 1.5316061973571777
Epoch: 3, Steps: 53 Train Loss: 1.6482 (Forecasting Loss:1.4659 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 1.7406 Test MSE Loss: 0.9645
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.5e-05
Epoch: 4 cost time: 1.5117332935333252
Epoch: 4, Steps: 53 Train Loss: 1.6461 (Forecasting Loss:1.4635 + XiCon Loss:1.8268 x Lambda(0.1)), Vali MSE Loss: 1.7426 Test MSE Loss: 0.9665
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.25e-05
Epoch: 5 cost time: 1.5435786247253418
Epoch: 5, Steps: 53 Train Loss: 1.6448 (Forecasting Loss:1.4618 + XiCon Loss:1.8299 x Lambda(0.1)), Vali MSE Loss: 1.7446 Test MSE Loss: 0.9676
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.25e-06
Epoch: 6 cost time: 1.6600918769836426
Epoch: 6, Steps: 53 Train Loss: 1.6445 (Forecasting Loss:1.4617 + XiCon Loss:1.8279 x Lambda(0.1)), Vali MSE Loss: 1.7540 Test MSE Loss: 0.9681
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.125e-06
Epoch: 7 cost time: 1.7694401741027832
Epoch: 7, Steps: 53 Train Loss: 1.6455 (Forecasting Loss:1.4631 + XiCon Loss:1.8235 x Lambda(0.1)), Vali MSE Loss: 1.7537 Test MSE Loss: 0.9684
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.5625e-06
Epoch: 8 cost time: 1.6040327548980713
Epoch: 8, Steps: 53 Train Loss: 1.6430 (Forecasting Loss:1.4604 + XiCon Loss:1.8260 x Lambda(0.1)), Vali MSE Loss: 1.7245 Test MSE Loss: 0.9685
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.8125e-07
Epoch: 9 cost time: 1.604196310043335
Epoch: 9, Steps: 53 Train Loss: 1.6449 (Forecasting Loss:1.4620 + XiCon Loss:1.8287 x Lambda(0.1)), Vali MSE Loss: 1.7699 Test MSE Loss: 0.9686
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.90625e-07
Epoch: 10 cost time: 1.6116971969604492
Epoch: 10, Steps: 53 Train Loss: 1.6418 (Forecasting Loss:1.4593 + XiCon Loss:1.8254 x Lambda(0.1)), Vali MSE Loss: 1.7455 Test MSE Loss: 0.9686
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.953125e-07
Epoch: 11 cost time: 1.6206495761871338
Epoch: 11, Steps: 53 Train Loss: 1.6448 (Forecasting Loss:1.4618 + XiCon Loss:1.8301 x Lambda(0.1)), Vali MSE Loss: 1.7521 Test MSE Loss: 0.9686
EarlyStopping counter: 9 out of 10
Updating learning rate to 9.765625e-08
Epoch: 12 cost time: 1.6238408088684082
Epoch: 12, Steps: 53 Train Loss: 1.6421 (Forecasting Loss:1.4584 + XiCon Loss:1.8373 x Lambda(0.1)), Vali MSE Loss: 1.7510 Test MSE Loss: 0.9686
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_exchange_rate_ftS_sl48_ll24_pl1080_dm8_nh8_el1_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 438
test shape: (6, 64, 1080, 1) (6, 64, 1080, 1)
test shape: (384, 1080, 1) (384, 1080, 1)
mse:1.108956217765808, mae:0.8124955296516418, mape:0.8144654035568237, mspe:1.8785196542739868 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.0601+-0.04408, MAE:0.7961+-0.01462, MAPE:0.7954+-0.01740, MSPE:1.7989+-0.07256, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=96, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=64, patience=10, learning_rate=0.0003, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.7, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.5594
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.1305908
	speed: 0.0177s/iter; left time: 858.7104s
	iters: 200, epoch: 1 | loss: 1.0528907
	speed: 0.0126s/iter; left time: 609.4543s
	iters: 300, epoch: 1 | loss: 0.8047067
	speed: 0.0133s/iter; left time: 643.8472s
	iters: 400, epoch: 1 | loss: 0.8549258
	speed: 0.0136s/iter; left time: 656.6685s
Epoch: 1 cost time: 6.7713541984558105
Epoch: 1, Steps: 487 Train Loss: 0.9908 (Forecasting Loss:0.7417 + XiCon Loss:2.4903 x Lambda(0.1)), Vali MSE Loss: 1.0367 Test MSE Loss: 0.6312
Validation loss decreased (inf --> 1.036739).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.7458671
	speed: 0.0157s/iter; left time: 754.6329s
	iters: 200, epoch: 2 | loss: 0.7078639
	speed: 0.0160s/iter; left time: 768.0160s
	iters: 300, epoch: 2 | loss: 0.7492877
	speed: 0.0129s/iter; left time: 619.2944s
	iters: 400, epoch: 2 | loss: 0.6576678
	speed: 0.0126s/iter; left time: 601.2994s
Epoch: 2 cost time: 6.86630916595459
Epoch: 2, Steps: 487 Train Loss: 0.6823 (Forecasting Loss:0.4347 + XiCon Loss:2.4767 x Lambda(0.1)), Vali MSE Loss: 0.7451 Test MSE Loss: 0.5274
Validation loss decreased (1.036739 --> 0.745129).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.5711720
	speed: 0.0167s/iter; left time: 797.7148s
	iters: 200, epoch: 3 | loss: 0.6631786
	speed: 0.0126s/iter; left time: 599.0103s
	iters: 300, epoch: 3 | loss: 0.7411177
	speed: 0.0133s/iter; left time: 629.2096s
	iters: 400, epoch: 3 | loss: 0.5899611
	speed: 0.0132s/iter; left time: 622.3504s
Epoch: 3 cost time: 6.651510953903198
Epoch: 3, Steps: 487 Train Loss: 0.6508 (Forecasting Loss:0.4050 + XiCon Loss:2.4583 x Lambda(0.1)), Vali MSE Loss: 0.7362 Test MSE Loss: 0.5192
Validation loss decreased (0.745129 --> 0.736201).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.7243726
	speed: 0.0145s/iter; left time: 684.1105s
	iters: 200, epoch: 4 | loss: 0.6551639
	speed: 0.0126s/iter; left time: 591.2230s
	iters: 300, epoch: 4 | loss: 0.6846583
	speed: 0.0128s/iter; left time: 598.6695s
	iters: 400, epoch: 4 | loss: 0.5751271
	speed: 0.0126s/iter; left time: 590.9597s
Epoch: 4 cost time: 6.413577556610107
Epoch: 4, Steps: 487 Train Loss: 0.6446 (Forecasting Loss:0.3993 + XiCon Loss:2.4527 x Lambda(0.1)), Vali MSE Loss: 0.7286 Test MSE Loss: 0.5129
Validation loss decreased (0.736201 --> 0.728586).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.6684065
	speed: 0.0154s/iter; left time: 719.0329s
	iters: 200, epoch: 5 | loss: 0.7549816
	speed: 0.0133s/iter; left time: 617.5202s
	iters: 300, epoch: 5 | loss: 0.6122496
	speed: 0.0126s/iter; left time: 586.3983s
	iters: 400, epoch: 5 | loss: 0.6226172
	speed: 0.0132s/iter; left time: 613.1143s
Epoch: 5 cost time: 6.671767950057983
Epoch: 5, Steps: 487 Train Loss: 0.6417 (Forecasting Loss:0.3968 + XiCon Loss:2.4490 x Lambda(0.1)), Vali MSE Loss: 0.7263 Test MSE Loss: 0.5086
Validation loss decreased (0.728586 --> 0.726261).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.6505791
	speed: 0.0152s/iter; left time: 700.5302s
	iters: 200, epoch: 6 | loss: 0.6799507
	speed: 0.0128s/iter; left time: 591.9127s
	iters: 300, epoch: 6 | loss: 0.6575764
	speed: 0.0129s/iter; left time: 590.6954s
	iters: 400, epoch: 6 | loss: 0.5975223
	speed: 0.0128s/iter; left time: 586.1833s
Epoch: 6 cost time: 6.502630233764648
Epoch: 6, Steps: 487 Train Loss: 0.6404 (Forecasting Loss:0.3958 + XiCon Loss:2.4462 x Lambda(0.1)), Vali MSE Loss: 0.7271 Test MSE Loss: 0.5102
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.6460381
	speed: 0.0162s/iter; left time: 742.0116s
	iters: 200, epoch: 7 | loss: 0.5447840
	speed: 0.0130s/iter; left time: 593.8290s
	iters: 300, epoch: 7 | loss: 0.6977500
	speed: 0.0131s/iter; left time: 595.9568s
	iters: 400, epoch: 7 | loss: 0.6275061
	speed: 0.0129s/iter; left time: 586.8770s
Epoch: 7 cost time: 6.829223394393921
Epoch: 7, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3952 + XiCon Loss:2.4449 x Lambda(0.1)), Vali MSE Loss: 0.7261 Test MSE Loss: 0.5093
Validation loss decreased (0.726261 --> 0.726063).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.6051843
	speed: 0.0150s/iter; left time: 677.1820s
	iters: 200, epoch: 8 | loss: 0.5686761
	speed: 0.0127s/iter; left time: 574.1151s
	iters: 300, epoch: 8 | loss: 0.6310862
	speed: 0.0155s/iter; left time: 697.8490s
	iters: 400, epoch: 8 | loss: 0.6934407
	speed: 0.0126s/iter; left time: 565.8036s
Epoch: 8 cost time: 6.719856262207031
Epoch: 8, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3949 + XiCon Loss:2.4459 x Lambda(0.1)), Vali MSE Loss: 0.7259 Test MSE Loss: 0.5090
Validation loss decreased (0.726063 --> 0.725947).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.7860537
	speed: 0.0168s/iter; left time: 748.9106s
	iters: 200, epoch: 9 | loss: 0.5696084
	speed: 0.0129s/iter; left time: 576.0439s
	iters: 300, epoch: 9 | loss: 0.6683038
	speed: 0.0133s/iter; left time: 590.8405s
	iters: 400, epoch: 9 | loss: 0.6576545
	speed: 0.0125s/iter; left time: 553.0762s
Epoch: 9 cost time: 6.782361745834351
Epoch: 9, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3946 + XiCon Loss:2.4484 x Lambda(0.1)), Vali MSE Loss: 0.7257 Test MSE Loss: 0.5089
Validation loss decreased (0.725947 --> 0.725653).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.5729436
	speed: 0.0157s/iter; left time: 692.9442s
	iters: 200, epoch: 10 | loss: 0.6098359
	speed: 0.0131s/iter; left time: 576.7440s
	iters: 300, epoch: 10 | loss: 0.5964311
	speed: 0.0130s/iter; left time: 571.8697s
	iters: 400, epoch: 10 | loss: 0.5462939
	speed: 0.0120s/iter; left time: 525.9870s
Epoch: 10 cost time: 6.563600778579712
Epoch: 10, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3946 + XiCon Loss:2.4490 x Lambda(0.1)), Vali MSE Loss: 0.7257 Test MSE Loss: 0.5088
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.5871577
	speed: 0.0160s/iter; left time: 701.0955s
	iters: 200, epoch: 11 | loss: 0.5686888
	speed: 0.0128s/iter; left time: 558.0649s
	iters: 300, epoch: 11 | loss: 0.6647312
	speed: 0.0137s/iter; left time: 595.8521s
	iters: 400, epoch: 11 | loss: 0.6066465
	speed: 0.0133s/iter; left time: 577.6979s
Epoch: 11 cost time: 6.787354469299316
Epoch: 11, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3947 + XiCon Loss:2.4476 x Lambda(0.1)), Vali MSE Loss: 0.7253 Test MSE Loss: 0.5088
Validation loss decreased (0.725653 --> 0.725312).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.6765364
	speed: 0.0149s/iter; left time: 642.5471s
	iters: 200, epoch: 12 | loss: 0.5898743
	speed: 0.0138s/iter; left time: 593.5858s
	iters: 300, epoch: 12 | loss: 0.6111088
	speed: 0.0137s/iter; left time: 588.7822s
	iters: 400, epoch: 12 | loss: 0.6088352
	speed: 0.0126s/iter; left time: 541.6101s
Epoch: 12 cost time: 6.659837484359741
Epoch: 12, Steps: 487 Train Loss: 0.6391 (Forecasting Loss:0.3945 + XiCon Loss:2.4458 x Lambda(0.1)), Vali MSE Loss: 0.7260 Test MSE Loss: 0.5088
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.7689397
	speed: 0.0163s/iter; left time: 697.0678s
	iters: 200, epoch: 13 | loss: 0.6374557
	speed: 0.0140s/iter; left time: 595.4291s
	iters: 300, epoch: 13 | loss: 0.6095831
	speed: 0.0123s/iter; left time: 521.9438s
	iters: 400, epoch: 13 | loss: 0.5513213
	speed: 0.0134s/iter; left time: 568.1562s
Epoch: 13 cost time: 6.734536409378052
Epoch: 13, Steps: 487 Train Loss: 0.6389 (Forecasting Loss:0.3944 + XiCon Loss:2.4452 x Lambda(0.1)), Vali MSE Loss: 0.7260 Test MSE Loss: 0.5087
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.6793035
	speed: 0.0170s/iter; left time: 719.0848s
	iters: 200, epoch: 14 | loss: 0.7062186
	speed: 0.0132s/iter; left time: 556.0256s
	iters: 300, epoch: 14 | loss: 0.5731688
	speed: 0.0133s/iter; left time: 561.2670s
	iters: 400, epoch: 14 | loss: 0.5789856
	speed: 0.0131s/iter; left time: 549.1923s
Epoch: 14 cost time: 6.942042589187622
Epoch: 14, Steps: 487 Train Loss: 0.6394 (Forecasting Loss:0.3947 + XiCon Loss:2.4477 x Lambda(0.1)), Vali MSE Loss: 0.7259 Test MSE Loss: 0.5087
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.6179804
	speed: 0.0160s/iter; left time: 668.7497s
	iters: 200, epoch: 15 | loss: 0.6257139
	speed: 0.0130s/iter; left time: 543.5204s
	iters: 300, epoch: 15 | loss: 0.6830784
	speed: 0.0133s/iter; left time: 553.4089s
	iters: 400, epoch: 15 | loss: 0.6400410
	speed: 0.0129s/iter; left time: 534.0762s
Epoch: 15 cost time: 6.726412773132324
Epoch: 15, Steps: 487 Train Loss: 0.6392 (Forecasting Loss:0.3944 + XiCon Loss:2.4476 x Lambda(0.1)), Vali MSE Loss: 0.7255 Test MSE Loss: 0.5087
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.6957501
	speed: 0.0155s/iter; left time: 639.0581s
	iters: 200, epoch: 16 | loss: 0.7233575
	speed: 0.0134s/iter; left time: 551.7337s
	iters: 300, epoch: 16 | loss: 0.6238022
	speed: 0.0131s/iter; left time: 538.1327s
	iters: 400, epoch: 16 | loss: 0.6571972
	speed: 0.0132s/iter; left time: 542.2642s
Epoch: 16 cost time: 6.73201584815979
Epoch: 16, Steps: 487 Train Loss: 0.6389 (Forecasting Loss:0.3946 + XiCon Loss:2.4429 x Lambda(0.1)), Vali MSE Loss: 0.7260 Test MSE Loss: 0.5087
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.6165742
	speed: 0.0163s/iter; left time: 664.8566s
	iters: 200, epoch: 17 | loss: 0.6077782
	speed: 0.0124s/iter; left time: 506.7059s
	iters: 300, epoch: 17 | loss: 0.7015084
	speed: 0.0128s/iter; left time: 517.9970s
	iters: 400, epoch: 17 | loss: 0.6643301
	speed: 0.0129s/iter; left time: 522.2434s
Epoch: 17 cost time: 6.595335483551025
Epoch: 17, Steps: 487 Train Loss: 0.6392 (Forecasting Loss:0.3945 + XiCon Loss:2.4470 x Lambda(0.1)), Vali MSE Loss: 0.7254 Test MSE Loss: 0.5087
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.5877408
	speed: 0.0148s/iter; left time: 594.9370s
	iters: 200, epoch: 18 | loss: 0.6650311
	speed: 0.0135s/iter; left time: 542.3891s
	iters: 300, epoch: 18 | loss: 0.5886550
	speed: 0.0133s/iter; left time: 532.4409s
	iters: 400, epoch: 18 | loss: 0.5665172
	speed: 0.0137s/iter; left time: 548.4193s
Epoch: 18 cost time: 6.700865268707275
Epoch: 18, Steps: 487 Train Loss: 0.6392 (Forecasting Loss:0.3943 + XiCon Loss:2.4485 x Lambda(0.1)), Vali MSE Loss: 0.7252 Test MSE Loss: 0.5087
Validation loss decreased (0.725312 --> 0.725174).  Saving model ...
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.6234633
	speed: 0.0159s/iter; left time: 632.3015s
	iters: 200, epoch: 19 | loss: 0.6417267
	speed: 0.0135s/iter; left time: 536.1155s
	iters: 300, epoch: 19 | loss: 0.6327426
	speed: 0.0126s/iter; left time: 497.8957s
	iters: 400, epoch: 19 | loss: 0.6707567
	speed: 0.0131s/iter; left time: 516.9456s
Epoch: 19 cost time: 6.634018421173096
Epoch: 19, Steps: 487 Train Loss: 0.6388 (Forecasting Loss:0.3943 + XiCon Loss:2.4451 x Lambda(0.1)), Vali MSE Loss: 0.7253 Test MSE Loss: 0.5087
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.6321208
	speed: 0.0169s/iter; left time: 665.8351s
	iters: 200, epoch: 20 | loss: 0.6235086
	speed: 0.0133s/iter; left time: 520.5235s
	iters: 300, epoch: 20 | loss: 0.5551893
	speed: 0.0123s/iter; left time: 480.8259s
	iters: 400, epoch: 20 | loss: 0.6165229
	speed: 0.0137s/iter; left time: 536.1200s
Epoch: 20 cost time: 6.816102027893066
Epoch: 20, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3946 + XiCon Loss:2.4499 x Lambda(0.1)), Vali MSE Loss: 0.7256 Test MSE Loss: 0.5087
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.5456024
	speed: 0.0162s/iter; left time: 629.0630s
	iters: 200, epoch: 21 | loss: 0.6312828
	speed: 0.0130s/iter; left time: 504.3134s
	iters: 300, epoch: 21 | loss: 0.5662779
	speed: 0.0129s/iter; left time: 497.5775s
	iters: 400, epoch: 21 | loss: 0.6508791
	speed: 0.0133s/iter; left time: 512.6954s
Epoch: 21 cost time: 6.685486555099487
Epoch: 21, Steps: 487 Train Loss: 0.6393 (Forecasting Loss:0.3947 + XiCon Loss:2.4457 x Lambda(0.1)), Vali MSE Loss: 0.7258 Test MSE Loss: 0.5087
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.6493747
	speed: 0.0155s/iter; left time: 594.6474s
	iters: 200, epoch: 22 | loss: 0.6751409
	speed: 0.0137s/iter; left time: 525.7256s
	iters: 300, epoch: 22 | loss: 0.7110989
	speed: 0.0127s/iter; left time: 485.0695s
	iters: 400, epoch: 22 | loss: 0.6080687
	speed: 0.0135s/iter; left time: 513.1867s
Epoch: 22 cost time: 6.700191020965576
Epoch: 22, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3947 + XiCon Loss:2.4505 x Lambda(0.1)), Vali MSE Loss: 0.7257 Test MSE Loss: 0.5087
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.7079949
	speed: 0.0153s/iter; left time: 577.9771s
	iters: 200, epoch: 23 | loss: 0.6078314
	speed: 0.0129s/iter; left time: 486.4448s
	iters: 300, epoch: 23 | loss: 0.6029404
	speed: 0.0127s/iter; left time: 478.5792s
	iters: 400, epoch: 23 | loss: 0.6737264
	speed: 0.0128s/iter; left time: 482.0499s
Epoch: 23 cost time: 6.4992592334747314
Epoch: 23, Steps: 487 Train Loss: 0.6389 (Forecasting Loss:0.3944 + XiCon Loss:2.4445 x Lambda(0.1)), Vali MSE Loss: 0.7256 Test MSE Loss: 0.5087
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.7227735
	speed: 0.0156s/iter; left time: 582.3854s
	iters: 200, epoch: 24 | loss: 0.6309639
	speed: 0.0130s/iter; left time: 485.1378s
	iters: 300, epoch: 24 | loss: 0.6710607
	speed: 0.0133s/iter; left time: 495.8963s
	iters: 400, epoch: 24 | loss: 0.5612923
	speed: 0.0136s/iter; left time: 503.5560s
Epoch: 24 cost time: 6.604882001876831
Epoch: 24, Steps: 487 Train Loss: 0.6392 (Forecasting Loss:0.3944 + XiCon Loss:2.4480 x Lambda(0.1)), Vali MSE Loss: 0.7258 Test MSE Loss: 0.5087
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.6278867
	speed: 0.0151s/iter; left time: 557.0907s
	iters: 200, epoch: 25 | loss: 0.6537651
	speed: 0.0130s/iter; left time: 477.7170s
	iters: 300, epoch: 25 | loss: 0.6072711
	speed: 0.0128s/iter; left time: 470.6892s
	iters: 400, epoch: 25 | loss: 0.6518841
	speed: 0.0139s/iter; left time: 508.5048s
Epoch: 25 cost time: 6.657312393188477
Epoch: 25, Steps: 487 Train Loss: 0.6391 (Forecasting Loss:0.3944 + XiCon Loss:2.4461 x Lambda(0.1)), Vali MSE Loss: 0.7251 Test MSE Loss: 0.5087
Validation loss decreased (0.725174 --> 0.725093).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.6097829
	speed: 0.0149s/iter; left time: 544.1492s
	iters: 200, epoch: 26 | loss: 0.6073968
	speed: 0.0135s/iter; left time: 489.5841s
	iters: 300, epoch: 26 | loss: 0.7290945
	speed: 0.0135s/iter; left time: 488.8030s
	iters: 400, epoch: 26 | loss: 0.5645802
	speed: 0.0123s/iter; left time: 444.5994s
Epoch: 26 cost time: 6.593429088592529
Epoch: 26, Steps: 487 Train Loss: 0.6394 (Forecasting Loss:0.3945 + XiCon Loss:2.4492 x Lambda(0.1)), Vali MSE Loss: 0.7259 Test MSE Loss: 0.5087
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.6209014
	speed: 0.0155s/iter; left time: 558.5683s
	iters: 200, epoch: 27 | loss: 0.6555988
	speed: 0.0128s/iter; left time: 458.2662s
	iters: 300, epoch: 27 | loss: 0.5732220
	speed: 0.0132s/iter; left time: 470.7859s
	iters: 400, epoch: 27 | loss: 0.5813775
	speed: 0.0143s/iter; left time: 509.1704s
Epoch: 27 cost time: 6.641549587249756
Epoch: 27, Steps: 487 Train Loss: 0.6393 (Forecasting Loss:0.3947 + XiCon Loss:2.4462 x Lambda(0.1)), Vali MSE Loss: 0.7256 Test MSE Loss: 0.5087
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.6472795
	speed: 0.0150s/iter; left time: 530.6574s
	iters: 200, epoch: 28 | loss: 0.6338688
	speed: 0.0127s/iter; left time: 449.5967s
	iters: 300, epoch: 28 | loss: 0.6485106
	speed: 0.0137s/iter; left time: 482.2992s
	iters: 400, epoch: 28 | loss: 0.6267066
	speed: 0.0125s/iter; left time: 440.9231s
Epoch: 28 cost time: 6.600990533828735
Epoch: 28, Steps: 487 Train Loss: 0.6390 (Forecasting Loss:0.3944 + XiCon Loss:2.4462 x Lambda(0.1)), Vali MSE Loss: 0.7257 Test MSE Loss: 0.5087
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.5868038
	speed: 0.0143s/iter; left time: 498.3229s
	iters: 200, epoch: 29 | loss: 0.7002269
	speed: 0.0124s/iter; left time: 432.4926s
	iters: 300, epoch: 29 | loss: 0.6537262
	speed: 0.0116s/iter; left time: 403.0785s
	iters: 400, epoch: 29 | loss: 0.6490272
	speed: 0.0117s/iter; left time: 404.2406s
Epoch: 29 cost time: 6.0295023918151855
Epoch: 29, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3946 + XiCon Loss:2.4482 x Lambda(0.1)), Vali MSE Loss: 0.7256 Test MSE Loss: 0.5087
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.6137764
	speed: 0.0146s/iter; left time: 502.9741s
	iters: 200, epoch: 30 | loss: 0.6463813
	speed: 0.0125s/iter; left time: 428.7733s
	iters: 300, epoch: 30 | loss: 0.6910747
	speed: 0.0116s/iter; left time: 397.1295s
	iters: 400, epoch: 30 | loss: 0.6261165
	speed: 0.0113s/iter; left time: 386.1384s
Epoch: 30 cost time: 6.047781467437744
Epoch: 30, Steps: 487 Train Loss: 0.6394 (Forecasting Loss:0.3944 + XiCon Loss:2.4497 x Lambda(0.1)), Vali MSE Loss: 0.7259 Test MSE Loss: 0.5087
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.7280090
	speed: 0.0146s/iter; left time: 497.0757s
	iters: 200, epoch: 31 | loss: 0.5606261
	speed: 0.0119s/iter; left time: 402.0127s
	iters: 300, epoch: 31 | loss: 0.6488515
	speed: 0.0113s/iter; left time: 382.6829s
	iters: 400, epoch: 31 | loss: 0.5762984
	speed: 0.0111s/iter; left time: 372.6377s
Epoch: 31 cost time: 5.8776774406433105
Epoch: 31, Steps: 487 Train Loss: 0.6392 (Forecasting Loss:0.3944 + XiCon Loss:2.4478 x Lambda(0.1)), Vali MSE Loss: 0.7252 Test MSE Loss: 0.5087
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.6329151
	speed: 0.0153s/iter; left time: 511.7881s
	iters: 200, epoch: 32 | loss: 0.7131349
	speed: 0.0117s/iter; left time: 390.5895s
	iters: 300, epoch: 32 | loss: 0.5821580
	speed: 0.0117s/iter; left time: 389.7284s
	iters: 400, epoch: 32 | loss: 0.5506716
	speed: 0.0114s/iter; left time: 379.9853s
Epoch: 32 cost time: 6.055145502090454
Epoch: 32, Steps: 487 Train Loss: 0.6388 (Forecasting Loss:0.3942 + XiCon Loss:2.4459 x Lambda(0.1)), Vali MSE Loss: 0.7257 Test MSE Loss: 0.5087
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.6003978
	speed: 0.0141s/iter; left time: 465.3886s
	iters: 200, epoch: 33 | loss: 0.5629377
	speed: 0.0119s/iter; left time: 391.1367s
	iters: 300, epoch: 33 | loss: 0.6436244
	speed: 0.0117s/iter; left time: 384.1915s
	iters: 400, epoch: 33 | loss: 0.7154851
	speed: 0.0115s/iter; left time: 375.8646s
Epoch: 33 cost time: 5.93602728843689
Epoch: 33, Steps: 487 Train Loss: 0.6392 (Forecasting Loss:0.3945 + XiCon Loss:2.4472 x Lambda(0.1)), Vali MSE Loss: 0.7258 Test MSE Loss: 0.5087
EarlyStopping counter: 8 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.6393119
	speed: 0.0145s/iter; left time: 470.1641s
	iters: 200, epoch: 34 | loss: 0.6878468
	speed: 0.0123s/iter; left time: 398.9403s
	iters: 300, epoch: 34 | loss: 0.5945193
	speed: 0.0113s/iter; left time: 364.3597s
	iters: 400, epoch: 34 | loss: 0.6153936
	speed: 0.0114s/iter; left time: 366.6615s
Epoch: 34 cost time: 5.973106384277344
Epoch: 34, Steps: 487 Train Loss: 0.6389 (Forecasting Loss:0.3944 + XiCon Loss:2.4460 x Lambda(0.1)), Vali MSE Loss: 0.7252 Test MSE Loss: 0.5087
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.6257777
	speed: 0.0146s/iter; left time: 468.1620s
	iters: 200, epoch: 35 | loss: 0.5603929
	speed: 0.0141s/iter; left time: 450.6536s
	iters: 300, epoch: 35 | loss: 0.6324481
	speed: 0.0132s/iter; left time: 421.8622s
	iters: 400, epoch: 35 | loss: 0.6479414
	speed: 0.0134s/iter; left time: 424.1505s
Epoch: 35 cost time: 6.702240705490112
Epoch: 35, Steps: 487 Train Loss: 0.6394 (Forecasting Loss:0.3944 + XiCon Loss:2.4495 x Lambda(0.1)), Vali MSE Loss: 0.7258 Test MSE Loss: 0.5087
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5143753886222839, mae:0.5031051635742188, mape:3.5015289783477783, mspe:1144.3321533203125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7068
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 0.9206856
	speed: 0.0164s/iter; left time: 798.1066s
	iters: 200, epoch: 1 | loss: 1.1187791
	speed: 0.0146s/iter; left time: 708.8710s
	iters: 300, epoch: 1 | loss: 0.8025618
	speed: 0.0148s/iter; left time: 718.2686s
	iters: 400, epoch: 1 | loss: 0.7407376
	speed: 0.0158s/iter; left time: 761.2407s
Epoch: 1 cost time: 7.483026504516602
Epoch: 1, Steps: 487 Train Loss: 0.9828 (Forecasting Loss:0.7349 + XiCon Loss:2.4787 x Lambda(0.1)), Vali MSE Loss: 1.0309 Test MSE Loss: 0.6260
Validation loss decreased (inf --> 1.030891).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.7334055
	speed: 0.0179s/iter; left time: 858.9308s
	iters: 200, epoch: 2 | loss: 0.7354445
	speed: 0.0151s/iter; left time: 724.5321s
	iters: 300, epoch: 2 | loss: 0.6496887
	speed: 0.0142s/iter; left time: 681.2726s
	iters: 400, epoch: 2 | loss: 0.7253771
	speed: 0.0160s/iter; left time: 764.1037s
Epoch: 2 cost time: 7.667728662490845
Epoch: 2, Steps: 487 Train Loss: 0.6857 (Forecasting Loss:0.4383 + XiCon Loss:2.4739 x Lambda(0.1)), Vali MSE Loss: 0.7330 Test MSE Loss: 0.5283
Validation loss decreased (1.030891 --> 0.732995).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.6665964
	speed: 0.0184s/iter; left time: 876.7714s
	iters: 200, epoch: 3 | loss: 0.6319320
	speed: 0.0152s/iter; left time: 720.2157s
	iters: 300, epoch: 3 | loss: 0.6672289
	speed: 0.0153s/iter; left time: 727.2254s
	iters: 400, epoch: 3 | loss: 0.6050907
	speed: 0.0153s/iter; left time: 725.3467s
Epoch: 3 cost time: 7.761583566665649
Epoch: 3, Steps: 487 Train Loss: 0.6497 (Forecasting Loss:0.4054 + XiCon Loss:2.4423 x Lambda(0.1)), Vali MSE Loss: 0.7192 Test MSE Loss: 0.5210
Validation loss decreased (0.732995 --> 0.719226).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.7675893
	speed: 0.0173s/iter; left time: 815.7340s
	iters: 200, epoch: 4 | loss: 0.6122580
	speed: 0.0152s/iter; left time: 715.7844s
	iters: 300, epoch: 4 | loss: 0.7538657
	speed: 0.0140s/iter; left time: 657.3905s
	iters: 400, epoch: 4 | loss: 0.7470756
	speed: 0.0163s/iter; left time: 765.2470s
Epoch: 4 cost time: 7.604187250137329
Epoch: 4, Steps: 487 Train Loss: 0.6428 (Forecasting Loss:0.3998 + XiCon Loss:2.4302 x Lambda(0.1)), Vali MSE Loss: 0.7134 Test MSE Loss: 0.5198
Validation loss decreased (0.719226 --> 0.713403).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.6133958
	speed: 0.0170s/iter; left time: 792.0384s
	iters: 200, epoch: 5 | loss: 0.6568984
	speed: 0.0152s/iter; left time: 707.3697s
	iters: 300, epoch: 5 | loss: 0.6218671
	speed: 0.0155s/iter; left time: 720.0196s
	iters: 400, epoch: 5 | loss: 0.5493464
	speed: 0.0151s/iter; left time: 699.2851s
Epoch: 5 cost time: 7.670278787612915
Epoch: 5, Steps: 487 Train Loss: 0.6407 (Forecasting Loss:0.3975 + XiCon Loss:2.4320 x Lambda(0.1)), Vali MSE Loss: 0.7112 Test MSE Loss: 0.5178
Validation loss decreased (0.713403 --> 0.711209).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.5804549
	speed: 0.0173s/iter; left time: 797.2165s
	iters: 200, epoch: 6 | loss: 0.6017826
	speed: 0.0157s/iter; left time: 722.4383s
	iters: 300, epoch: 6 | loss: 0.5548587
	speed: 0.0146s/iter; left time: 672.3738s
	iters: 400, epoch: 6 | loss: 0.6617248
	speed: 0.0147s/iter; left time: 674.8471s
Epoch: 6 cost time: 7.54640531539917
Epoch: 6, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3963 + XiCon Loss:2.4327 x Lambda(0.1)), Vali MSE Loss: 0.7090 Test MSE Loss: 0.5170
Validation loss decreased (0.711209 --> 0.709013).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.6062827
	speed: 0.0163s/iter; left time: 744.4326s
	iters: 200, epoch: 7 | loss: 0.5885725
	speed: 0.0145s/iter; left time: 660.8899s
	iters: 300, epoch: 7 | loss: 0.7134175
	speed: 0.0160s/iter; left time: 728.8273s
	iters: 400, epoch: 7 | loss: 0.5972897
	speed: 0.0149s/iter; left time: 676.9649s
Epoch: 7 cost time: 7.538367509841919
Epoch: 7, Steps: 487 Train Loss: 0.6382 (Forecasting Loss:0.3957 + XiCon Loss:2.4255 x Lambda(0.1)), Vali MSE Loss: 0.7087 Test MSE Loss: 0.5171
Validation loss decreased (0.709013 --> 0.708655).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.6794676
	speed: 0.0169s/iter; left time: 762.2674s
	iters: 200, epoch: 8 | loss: 0.6623173
	speed: 0.0144s/iter; left time: 649.3113s
	iters: 300, epoch: 8 | loss: 0.6020202
	speed: 0.0147s/iter; left time: 663.4037s
	iters: 400, epoch: 8 | loss: 0.5415590
	speed: 0.0153s/iter; left time: 685.9941s
Epoch: 8 cost time: 7.406598091125488
Epoch: 8, Steps: 487 Train Loss: 0.6378 (Forecasting Loss:0.3953 + XiCon Loss:2.4248 x Lambda(0.1)), Vali MSE Loss: 0.7084 Test MSE Loss: 0.5169
Validation loss decreased (0.708655 --> 0.708396).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.6180811
	speed: 0.0172s/iter; left time: 768.2976s
	iters: 200, epoch: 9 | loss: 0.6286709
	speed: 0.0146s/iter; left time: 651.9243s
	iters: 300, epoch: 9 | loss: 0.6106324
	speed: 0.0157s/iter; left time: 699.2540s
	iters: 400, epoch: 9 | loss: 0.7251639
	speed: 0.0152s/iter; left time: 674.6512s
Epoch: 9 cost time: 7.626717805862427
Epoch: 9, Steps: 487 Train Loss: 0.6374 (Forecasting Loss:0.3950 + XiCon Loss:2.4242 x Lambda(0.1)), Vali MSE Loss: 0.7078 Test MSE Loss: 0.5168
Validation loss decreased (0.708396 --> 0.707766).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.6362404
	speed: 0.0169s/iter; left time: 745.9350s
	iters: 200, epoch: 10 | loss: 0.6353376
	speed: 0.0141s/iter; left time: 623.2332s
	iters: 300, epoch: 10 | loss: 0.5125738
	speed: 0.0159s/iter; left time: 701.1855s
	iters: 400, epoch: 10 | loss: 0.6370031
	speed: 0.0145s/iter; left time: 637.1421s
Epoch: 10 cost time: 7.548492193222046
Epoch: 10, Steps: 487 Train Loss: 0.6376 (Forecasting Loss:0.3952 + XiCon Loss:2.4246 x Lambda(0.1)), Vali MSE Loss: 0.7086 Test MSE Loss: 0.5168
EarlyStopping counter: 1 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.5522842
	speed: 0.0166s/iter; left time: 727.4910s
	iters: 200, epoch: 11 | loss: 0.5984260
	speed: 0.0146s/iter; left time: 638.3031s
	iters: 300, epoch: 11 | loss: 0.6038079
	speed: 0.0161s/iter; left time: 699.2081s
	iters: 400, epoch: 11 | loss: 0.7607756
	speed: 0.0152s/iter; left time: 658.9146s
Epoch: 11 cost time: 7.625722885131836
Epoch: 11, Steps: 487 Train Loss: 0.6366 (Forecasting Loss:0.3948 + XiCon Loss:2.4175 x Lambda(0.1)), Vali MSE Loss: 0.7087 Test MSE Loss: 0.5168
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.6155476
	speed: 0.0168s/iter; left time: 726.8690s
	iters: 200, epoch: 12 | loss: 0.6416574
	speed: 0.0160s/iter; left time: 689.7160s
	iters: 300, epoch: 12 | loss: 0.6631763
	speed: 0.0148s/iter; left time: 636.4560s
	iters: 400, epoch: 12 | loss: 0.6500888
	speed: 0.0143s/iter; left time: 612.8687s
Epoch: 12 cost time: 7.478363752365112
Epoch: 12, Steps: 487 Train Loss: 0.6374 (Forecasting Loss:0.3950 + XiCon Loss:2.4240 x Lambda(0.1)), Vali MSE Loss: 0.7086 Test MSE Loss: 0.5168
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.6406935
	speed: 0.0173s/iter; left time: 738.5960s
	iters: 200, epoch: 13 | loss: 0.7150062
	speed: 0.0143s/iter; left time: 608.9031s
	iters: 300, epoch: 13 | loss: 0.6061216
	speed: 0.0159s/iter; left time: 674.9407s
	iters: 400, epoch: 13 | loss: 0.6147469
	speed: 0.0153s/iter; left time: 649.4042s
Epoch: 13 cost time: 7.579259634017944
Epoch: 13, Steps: 487 Train Loss: 0.6380 (Forecasting Loss:0.3952 + XiCon Loss:2.4284 x Lambda(0.1)), Vali MSE Loss: 0.7084 Test MSE Loss: 0.5168
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.6298311
	speed: 0.0169s/iter; left time: 716.0302s
	iters: 200, epoch: 14 | loss: 0.6458491
	speed: 0.0141s/iter; left time: 595.9382s
	iters: 300, epoch: 14 | loss: 0.6006657
	speed: 0.0155s/iter; left time: 654.0813s
	iters: 400, epoch: 14 | loss: 0.6370035
	speed: 0.0152s/iter; left time: 636.1112s
Epoch: 14 cost time: 7.487109899520874
Epoch: 14, Steps: 487 Train Loss: 0.6376 (Forecasting Loss:0.3950 + XiCon Loss:2.4263 x Lambda(0.1)), Vali MSE Loss: 0.7085 Test MSE Loss: 0.5168
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.7033037
	speed: 0.0173s/iter; left time: 724.6945s
	iters: 200, epoch: 15 | loss: 0.6590877
	speed: 0.0146s/iter; left time: 608.2562s
	iters: 300, epoch: 15 | loss: 0.6561334
	speed: 0.0151s/iter; left time: 629.0389s
	iters: 400, epoch: 15 | loss: 0.6080775
	speed: 0.0162s/iter; left time: 670.0468s
Epoch: 15 cost time: 7.741085767745972
Epoch: 15, Steps: 487 Train Loss: 0.6368 (Forecasting Loss:0.3947 + XiCon Loss:2.4203 x Lambda(0.1)), Vali MSE Loss: 0.7084 Test MSE Loss: 0.5168
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.6572491
	speed: 0.0171s/iter; left time: 705.4393s
	iters: 200, epoch: 16 | loss: 0.6786306
	speed: 0.0141s/iter; left time: 579.8074s
	iters: 300, epoch: 16 | loss: 0.6185734
	speed: 0.0150s/iter; left time: 615.5678s
	iters: 400, epoch: 16 | loss: 0.6952347
	speed: 0.0153s/iter; left time: 627.9626s
Epoch: 16 cost time: 7.492024183273315
Epoch: 16, Steps: 487 Train Loss: 0.6372 (Forecasting Loss:0.3949 + XiCon Loss:2.4234 x Lambda(0.1)), Vali MSE Loss: 0.7087 Test MSE Loss: 0.5168
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.6273581
	speed: 0.0165s/iter; left time: 672.8976s
	iters: 200, epoch: 17 | loss: 0.6743759
	speed: 0.0147s/iter; left time: 597.5494s
	iters: 300, epoch: 17 | loss: 0.6495250
	speed: 0.0159s/iter; left time: 644.4028s
	iters: 400, epoch: 17 | loss: 0.6900896
	speed: 0.0158s/iter; left time: 641.1733s
Epoch: 17 cost time: 7.583092451095581
Epoch: 17, Steps: 487 Train Loss: 0.6376 (Forecasting Loss:0.3950 + XiCon Loss:2.4253 x Lambda(0.1)), Vali MSE Loss: 0.7084 Test MSE Loss: 0.5168
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.6674998
	speed: 0.0175s/iter; left time: 706.1616s
	iters: 200, epoch: 18 | loss: 0.6494949
	speed: 0.0151s/iter; left time: 608.5781s
	iters: 300, epoch: 18 | loss: 0.8189688
	speed: 0.0148s/iter; left time: 593.7510s
	iters: 400, epoch: 18 | loss: 0.6445881
	speed: 0.0165s/iter; left time: 658.3665s
Epoch: 18 cost time: 7.656457185745239
Epoch: 18, Steps: 487 Train Loss: 0.6371 (Forecasting Loss:0.3949 + XiCon Loss:2.4221 x Lambda(0.1)), Vali MSE Loss: 0.7081 Test MSE Loss: 0.5168
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.5376377
	speed: 0.0176s/iter; left time: 699.5238s
	iters: 200, epoch: 19 | loss: 0.7100958
	speed: 0.0146s/iter; left time: 579.2864s
	iters: 300, epoch: 19 | loss: 0.6622980
	speed: 0.0147s/iter; left time: 583.3345s
	iters: 400, epoch: 19 | loss: 0.5756501
	speed: 0.0162s/iter; left time: 639.3260s
Epoch: 19 cost time: 7.616653680801392
Epoch: 19, Steps: 487 Train Loss: 0.6375 (Forecasting Loss:0.3951 + XiCon Loss:2.4241 x Lambda(0.1)), Vali MSE Loss: 0.7087 Test MSE Loss: 0.5168
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.523888111114502, mae:0.5096791386604309, mape:3.4702677726745605, mspe:1095.19921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.6816
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.3663231
	speed: 0.0163s/iter; left time: 792.8713s
	iters: 200, epoch: 1 | loss: 1.0155380
	speed: 0.0140s/iter; left time: 680.9323s
	iters: 300, epoch: 1 | loss: 0.9398404
	speed: 0.0162s/iter; left time: 785.2299s
	iters: 400, epoch: 1 | loss: 0.9829046
	speed: 0.0151s/iter; left time: 728.0346s
Epoch: 1 cost time: 7.470930576324463
Epoch: 1, Steps: 487 Train Loss: 1.0907 (Forecasting Loss:0.8409 + XiCon Loss:2.4974 x Lambda(0.1)), Vali MSE Loss: 1.1921 Test MSE Loss: 0.6743
Validation loss decreased (inf --> 1.192066).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.6842154
	speed: 0.0168s/iter; left time: 805.9648s
	iters: 200, epoch: 2 | loss: 0.6681737
	speed: 0.0152s/iter; left time: 731.4470s
	iters: 300, epoch: 2 | loss: 0.6171717
	speed: 0.0153s/iter; left time: 735.0016s
	iters: 400, epoch: 2 | loss: 0.7602654
	speed: 0.0154s/iter; left time: 738.1863s
Epoch: 2 cost time: 7.636233568191528
Epoch: 2, Steps: 487 Train Loss: 0.7000 (Forecasting Loss:0.4524 + XiCon Loss:2.4758 x Lambda(0.1)), Vali MSE Loss: 0.7531 Test MSE Loss: 0.5341
Validation loss decreased (1.192066 --> 0.753083).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.6940277
	speed: 0.0163s/iter; left time: 773.9813s
	iters: 200, epoch: 3 | loss: 0.6249618
	speed: 0.0156s/iter; left time: 740.8714s
	iters: 300, epoch: 3 | loss: 0.5694554
	speed: 0.0153s/iter; left time: 724.6474s
	iters: 400, epoch: 3 | loss: 0.6223513
	speed: 0.0145s/iter; left time: 688.5868s
Epoch: 3 cost time: 7.517237901687622
Epoch: 3, Steps: 487 Train Loss: 0.6534 (Forecasting Loss:0.4073 + XiCon Loss:2.4605 x Lambda(0.1)), Vali MSE Loss: 0.7428 Test MSE Loss: 0.5300
Validation loss decreased (0.753083 --> 0.742766).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.6206238
	speed: 0.0173s/iter; left time: 814.3424s
	iters: 200, epoch: 4 | loss: 0.5811073
	speed: 0.0161s/iter; left time: 758.4328s
	iters: 300, epoch: 4 | loss: 0.6401495
	speed: 0.0144s/iter; left time: 678.0862s
	iters: 400, epoch: 4 | loss: 0.7037588
	speed: 0.0148s/iter; left time: 692.9141s
Epoch: 4 cost time: 7.596758127212524
Epoch: 4, Steps: 487 Train Loss: 0.6465 (Forecasting Loss:0.4016 + XiCon Loss:2.4491 x Lambda(0.1)), Vali MSE Loss: 0.7352 Test MSE Loss: 0.5248
Validation loss decreased (0.742766 --> 0.735192).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.6182849
	speed: 0.0163s/iter; left time: 759.7076s
	iters: 200, epoch: 5 | loss: 0.6120008
	speed: 0.0158s/iter; left time: 736.8547s
	iters: 300, epoch: 5 | loss: 0.6473950
	speed: 0.0151s/iter; left time: 703.0507s
	iters: 400, epoch: 5 | loss: 0.6676608
	speed: 0.0150s/iter; left time: 697.3489s
Epoch: 5 cost time: 7.561089515686035
Epoch: 5, Steps: 487 Train Loss: 0.6443 (Forecasting Loss:0.3993 + XiCon Loss:2.4499 x Lambda(0.1)), Vali MSE Loss: 0.7354 Test MSE Loss: 0.5219
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.6310498
	speed: 0.0166s/iter; left time: 766.8883s
	iters: 200, epoch: 6 | loss: 0.6087369
	speed: 0.0138s/iter; left time: 636.1297s
	iters: 300, epoch: 6 | loss: 0.6285453
	speed: 0.0164s/iter; left time: 752.6381s
	iters: 400, epoch: 6 | loss: 0.6141214
	speed: 0.0145s/iter; left time: 666.1562s
Epoch: 6 cost time: 7.467060804367065
Epoch: 6, Steps: 487 Train Loss: 0.6427 (Forecasting Loss:0.3979 + XiCon Loss:2.4483 x Lambda(0.1)), Vali MSE Loss: 0.7324 Test MSE Loss: 0.5208
Validation loss decreased (0.735192 --> 0.732369).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.6147678
	speed: 0.0164s/iter; left time: 749.2987s
	iters: 200, epoch: 7 | loss: 0.6252007
	speed: 0.0154s/iter; left time: 704.1537s
	iters: 300, epoch: 7 | loss: 0.6942437
	speed: 0.0146s/iter; left time: 662.8985s
	iters: 400, epoch: 7 | loss: 0.6607907
	speed: 0.0139s/iter; left time: 631.6661s
Epoch: 7 cost time: 7.278464317321777
Epoch: 7, Steps: 487 Train Loss: 0.6425 (Forecasting Loss:0.3975 + XiCon Loss:2.4504 x Lambda(0.1)), Vali MSE Loss: 0.7323 Test MSE Loss: 0.5202
Validation loss decreased (0.732369 --> 0.732308).  Saving model ...
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.6613505
	speed: 0.0160s/iter; left time: 724.3640s
	iters: 200, epoch: 8 | loss: 0.6101391
	speed: 0.0132s/iter; left time: 596.5652s
	iters: 300, epoch: 8 | loss: 0.6428245
	speed: 0.0135s/iter; left time: 605.4473s
	iters: 400, epoch: 8 | loss: 0.5800458
	speed: 0.0137s/iter; left time: 616.0719s
Epoch: 8 cost time: 6.877194166183472
Epoch: 8, Steps: 487 Train Loss: 0.6420 (Forecasting Loss:0.3972 + XiCon Loss:2.4471 x Lambda(0.1)), Vali MSE Loss: 0.7331 Test MSE Loss: 0.5202
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.7140876
	speed: 0.0154s/iter; left time: 686.7947s
	iters: 200, epoch: 9 | loss: 0.6371913
	speed: 0.0140s/iter; left time: 623.7805s
	iters: 300, epoch: 9 | loss: 0.7011724
	speed: 0.0140s/iter; left time: 620.9060s
	iters: 400, epoch: 9 | loss: 0.5633986
	speed: 0.0140s/iter; left time: 620.1393s
Epoch: 9 cost time: 6.9645161628723145
Epoch: 9, Steps: 487 Train Loss: 0.6420 (Forecasting Loss:0.3971 + XiCon Loss:2.4488 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5202
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.7357910
	speed: 0.0151s/iter; left time: 665.9090s
	iters: 200, epoch: 10 | loss: 0.6599451
	speed: 0.0136s/iter; left time: 598.8656s
	iters: 300, epoch: 10 | loss: 0.5954812
	speed: 0.0136s/iter; left time: 596.5139s
	iters: 400, epoch: 10 | loss: 0.5866051
	speed: 0.0136s/iter; left time: 596.2383s
Epoch: 10 cost time: 6.832773923873901
Epoch: 10, Steps: 487 Train Loss: 0.6415 (Forecasting Loss:0.3968 + XiCon Loss:2.4466 x Lambda(0.1)), Vali MSE Loss: 0.7325 Test MSE Loss: 0.5201
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.6454841
	speed: 0.0163s/iter; left time: 710.9551s
	iters: 200, epoch: 11 | loss: 0.6068206
	speed: 0.0139s/iter; left time: 604.7045s
	iters: 300, epoch: 11 | loss: 0.6618458
	speed: 0.0134s/iter; left time: 585.2220s
	iters: 400, epoch: 11 | loss: 0.6001564
	speed: 0.0145s/iter; left time: 627.5916s
Epoch: 11 cost time: 7.066886901855469
Epoch: 11, Steps: 487 Train Loss: 0.6418 (Forecasting Loss:0.3971 + XiCon Loss:2.4478 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5201
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.6129009
	speed: 0.0155s/iter; left time: 671.9021s
	iters: 200, epoch: 12 | loss: 0.7275345
	speed: 0.0132s/iter; left time: 570.5183s
	iters: 300, epoch: 12 | loss: 0.6036158
	speed: 0.0134s/iter; left time: 578.3991s
	iters: 400, epoch: 12 | loss: 0.6895711
	speed: 0.0139s/iter; left time: 598.2688s
Epoch: 12 cost time: 6.868685245513916
Epoch: 12, Steps: 487 Train Loss: 0.6419 (Forecasting Loss:0.3972 + XiCon Loss:2.4467 x Lambda(0.1)), Vali MSE Loss: 0.7324 Test MSE Loss: 0.5201
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.5723901
	speed: 0.0154s/iter; left time: 658.5542s
	iters: 200, epoch: 13 | loss: 0.6693107
	speed: 0.0137s/iter; left time: 584.2424s
	iters: 300, epoch: 13 | loss: 0.6721752
	speed: 0.0138s/iter; left time: 588.6906s
	iters: 400, epoch: 13 | loss: 0.5731657
	speed: 0.0137s/iter; left time: 580.1876s
Epoch: 13 cost time: 6.899105548858643
Epoch: 13, Steps: 487 Train Loss: 0.6416 (Forecasting Loss:0.3969 + XiCon Loss:2.4467 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5201
EarlyStopping counter: 6 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.6470262
	speed: 0.0155s/iter; left time: 655.0432s
	iters: 200, epoch: 14 | loss: 0.7282187
	speed: 0.0135s/iter; left time: 567.1985s
	iters: 300, epoch: 14 | loss: 0.5913717
	speed: 0.0135s/iter; left time: 566.9971s
	iters: 400, epoch: 14 | loss: 0.8017679
	speed: 0.0165s/iter; left time: 690.4662s
Epoch: 14 cost time: 7.304508209228516
Epoch: 14, Steps: 487 Train Loss: 0.6413 (Forecasting Loss:0.3970 + XiCon Loss:2.4435 x Lambda(0.1)), Vali MSE Loss: 0.7321 Test MSE Loss: 0.5201
Validation loss decreased (0.732308 --> 0.732084).  Saving model ...
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.6136256
	speed: 0.0172s/iter; left time: 720.5405s
	iters: 200, epoch: 15 | loss: 0.6641154
	speed: 0.0145s/iter; left time: 605.1965s
	iters: 300, epoch: 15 | loss: 0.6494025
	speed: 0.0148s/iter; left time: 617.1337s
	iters: 400, epoch: 15 | loss: 0.5585710
	speed: 0.0158s/iter; left time: 654.7643s
Epoch: 15 cost time: 7.661983013153076
Epoch: 15, Steps: 487 Train Loss: 0.6417 (Forecasting Loss:0.3971 + XiCon Loss:2.4459 x Lambda(0.1)), Vali MSE Loss: 0.7323 Test MSE Loss: 0.5201
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.5667110
	speed: 0.0177s/iter; left time: 729.4521s
	iters: 200, epoch: 16 | loss: 0.6250300
	speed: 0.0148s/iter; left time: 607.8605s
	iters: 300, epoch: 16 | loss: 0.6132140
	speed: 0.0153s/iter; left time: 629.6787s
	iters: 400, epoch: 16 | loss: 0.6737274
	speed: 0.0160s/iter; left time: 657.7785s
Epoch: 16 cost time: 7.736504554748535
Epoch: 16, Steps: 487 Train Loss: 0.6416 (Forecasting Loss:0.3967 + XiCon Loss:2.4489 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5201
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.6233587
	speed: 0.0175s/iter; left time: 715.5523s
	iters: 200, epoch: 17 | loss: 0.6731231
	speed: 0.0151s/iter; left time: 613.0873s
	iters: 300, epoch: 17 | loss: 0.6680176
	speed: 0.0143s/iter; left time: 582.6355s
	iters: 400, epoch: 17 | loss: 0.5596790
	speed: 0.0158s/iter; left time: 641.1746s
Epoch: 17 cost time: 7.623377799987793
Epoch: 17, Steps: 487 Train Loss: 0.6421 (Forecasting Loss:0.3971 + XiCon Loss:2.4499 x Lambda(0.1)), Vali MSE Loss: 0.7327 Test MSE Loss: 0.5201
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.5976698
	speed: 0.0172s/iter; left time: 694.1831s
	iters: 200, epoch: 18 | loss: 0.7420967
	speed: 0.0142s/iter; left time: 571.2517s
	iters: 300, epoch: 18 | loss: 0.6386877
	speed: 0.0147s/iter; left time: 587.9387s
	iters: 400, epoch: 18 | loss: 0.7109254
	speed: 0.0148s/iter; left time: 593.3877s
Epoch: 18 cost time: 7.510960817337036
Epoch: 18, Steps: 487 Train Loss: 0.6413 (Forecasting Loss:0.3969 + XiCon Loss:2.4442 x Lambda(0.1)), Vali MSE Loss: 0.7325 Test MSE Loss: 0.5201
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.5658790
	speed: 0.0184s/iter; left time: 731.2957s
	iters: 200, epoch: 19 | loss: 0.6198105
	speed: 0.0143s/iter; left time: 567.0517s
	iters: 300, epoch: 19 | loss: 0.6527988
	speed: 0.0145s/iter; left time: 574.3446s
	iters: 400, epoch: 19 | loss: 0.7104545
	speed: 0.0144s/iter; left time: 570.4282s
Epoch: 19 cost time: 7.4480743408203125
Epoch: 19, Steps: 487 Train Loss: 0.6416 (Forecasting Loss:0.3971 + XiCon Loss:2.4443 x Lambda(0.1)), Vali MSE Loss: 0.7329 Test MSE Loss: 0.5201
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.5683278
	speed: 0.0164s/iter; left time: 647.1438s
	iters: 200, epoch: 20 | loss: 0.6686142
	speed: 0.0157s/iter; left time: 617.9074s
	iters: 300, epoch: 20 | loss: 0.6114028
	speed: 0.0145s/iter; left time: 566.0118s
	iters: 400, epoch: 20 | loss: 0.6487582
	speed: 0.0151s/iter; left time: 588.9572s
Epoch: 20 cost time: 7.481149911880493
Epoch: 20, Steps: 487 Train Loss: 0.6418 (Forecasting Loss:0.3970 + XiCon Loss:2.4480 x Lambda(0.1)), Vali MSE Loss: 0.7323 Test MSE Loss: 0.5201
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.6809373
	speed: 0.0168s/iter; left time: 651.3968s
	iters: 200, epoch: 21 | loss: 0.6392893
	speed: 0.0152s/iter; left time: 589.7939s
	iters: 300, epoch: 21 | loss: 0.6572754
	speed: 0.0150s/iter; left time: 581.1045s
	iters: 400, epoch: 21 | loss: 0.6697172
	speed: 0.0146s/iter; left time: 563.6951s
Epoch: 21 cost time: 7.524491548538208
Epoch: 21, Steps: 487 Train Loss: 0.6417 (Forecasting Loss:0.3967 + XiCon Loss:2.4499 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5201
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.7161810
	speed: 0.0164s/iter; left time: 630.5747s
	iters: 200, epoch: 22 | loss: 0.6420696
	speed: 0.0147s/iter; left time: 561.5432s
	iters: 300, epoch: 22 | loss: 0.6803085
	speed: 0.0158s/iter; left time: 601.7029s
	iters: 400, epoch: 22 | loss: 0.6127620
	speed: 0.0153s/iter; left time: 583.7814s
Epoch: 22 cost time: 7.599498748779297
Epoch: 22, Steps: 487 Train Loss: 0.6416 (Forecasting Loss:0.3968 + XiCon Loss:2.4483 x Lambda(0.1)), Vali MSE Loss: 0.7319 Test MSE Loss: 0.5201
Validation loss decreased (0.732084 --> 0.731905).  Saving model ...
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.6469433
	speed: 0.0171s/iter; left time: 646.3186s
	iters: 200, epoch: 23 | loss: 0.6451039
	speed: 0.0162s/iter; left time: 611.9543s
	iters: 300, epoch: 23 | loss: 0.6059526
	speed: 0.0146s/iter; left time: 550.5246s
	iters: 400, epoch: 23 | loss: 0.6213658
	speed: 0.0151s/iter; left time: 567.2740s
Epoch: 23 cost time: 7.681890487670898
Epoch: 23, Steps: 487 Train Loss: 0.6419 (Forecasting Loss:0.3967 + XiCon Loss:2.4520 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5201
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.6228338
	speed: 0.0167s/iter; left time: 625.0980s
	iters: 200, epoch: 24 | loss: 0.6015249
	speed: 0.0157s/iter; left time: 585.0719s
	iters: 300, epoch: 24 | loss: 0.6018770
	speed: 0.0151s/iter; left time: 561.8929s
	iters: 400, epoch: 24 | loss: 0.7172929
	speed: 0.0148s/iter; left time: 547.5144s
Epoch: 24 cost time: 7.560851573944092
Epoch: 24, Steps: 487 Train Loss: 0.6416 (Forecasting Loss:0.3967 + XiCon Loss:2.4487 x Lambda(0.1)), Vali MSE Loss: 0.7328 Test MSE Loss: 0.5201
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.6841759
	speed: 0.0163s/iter; left time: 599.9845s
	iters: 200, epoch: 25 | loss: 0.5207083
	speed: 0.0139s/iter; left time: 512.5933s
	iters: 300, epoch: 25 | loss: 0.5995446
	speed: 0.0159s/iter; left time: 581.9293s
	iters: 400, epoch: 25 | loss: 0.6094901
	speed: 0.0154s/iter; left time: 563.0058s
Epoch: 25 cost time: 7.502023458480835
Epoch: 25, Steps: 487 Train Loss: 0.6418 (Forecasting Loss:0.3970 + XiCon Loss:2.4481 x Lambda(0.1)), Vali MSE Loss: 0.7326 Test MSE Loss: 0.5201
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.6316913
	speed: 0.0165s/iter; left time: 601.2604s
	iters: 200, epoch: 26 | loss: 0.6389428
	speed: 0.0152s/iter; left time: 552.0188s
	iters: 300, epoch: 26 | loss: 0.6119673
	speed: 0.0160s/iter; left time: 580.8901s
	iters: 400, epoch: 26 | loss: 0.6615753
	speed: 0.0149s/iter; left time: 539.7239s
Epoch: 26 cost time: 7.597110271453857
Epoch: 26, Steps: 487 Train Loss: 0.6421 (Forecasting Loss:0.3968 + XiCon Loss:2.4523 x Lambda(0.1)), Vali MSE Loss: 0.7320 Test MSE Loss: 0.5201
EarlyStopping counter: 4 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.5921549
	speed: 0.0166s/iter; left time: 598.2665s
	iters: 200, epoch: 27 | loss: 0.6089632
	speed: 0.0139s/iter; left time: 499.5159s
	iters: 300, epoch: 27 | loss: 0.6974600
	speed: 0.0144s/iter; left time: 513.0890s
	iters: 400, epoch: 27 | loss: 0.6881605
	speed: 0.0161s/iter; left time: 573.5895s
Epoch: 27 cost time: 7.452340602874756
Epoch: 27, Steps: 487 Train Loss: 0.6414 (Forecasting Loss:0.3968 + XiCon Loss:2.4459 x Lambda(0.1)), Vali MSE Loss: 0.7323 Test MSE Loss: 0.5201
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.6465923
	speed: 0.0173s/iter; left time: 612.6231s
	iters: 200, epoch: 28 | loss: 0.6576229
	speed: 0.0150s/iter; left time: 531.8417s
	iters: 300, epoch: 28 | loss: 0.6401006
	speed: 0.0158s/iter; left time: 557.9736s
	iters: 400, epoch: 28 | loss: 0.6094480
	speed: 0.0155s/iter; left time: 546.2254s
Epoch: 28 cost time: 7.7283713817596436
Epoch: 28, Steps: 487 Train Loss: 0.6423 (Forecasting Loss:0.3971 + XiCon Loss:2.4524 x Lambda(0.1)), Vali MSE Loss: 0.7322 Test MSE Loss: 0.5201
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.6689644
	speed: 0.0164s/iter; left time: 574.6360s
	iters: 200, epoch: 29 | loss: 0.6364528
	speed: 0.0141s/iter; left time: 491.7667s
	iters: 300, epoch: 29 | loss: 0.7206599
	speed: 0.0142s/iter; left time: 492.2434s
	iters: 400, epoch: 29 | loss: 0.7111082
	speed: 0.0159s/iter; left time: 552.2682s
Epoch: 29 cost time: 7.3701958656311035
Epoch: 29, Steps: 487 Train Loss: 0.6419 (Forecasting Loss:0.3971 + XiCon Loss:2.4484 x Lambda(0.1)), Vali MSE Loss: 0.7322 Test MSE Loss: 0.5201
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.7148632
	speed: 0.0172s/iter; left time: 591.6169s
	iters: 200, epoch: 30 | loss: 0.6453385
	speed: 0.0142s/iter; left time: 487.4744s
	iters: 300, epoch: 30 | loss: 0.7324611
	speed: 0.0150s/iter; left time: 513.2248s
	iters: 400, epoch: 30 | loss: 0.6418063
	speed: 0.0160s/iter; left time: 545.7998s
Epoch: 30 cost time: 7.538539171218872
Epoch: 30, Steps: 487 Train Loss: 0.6411 (Forecasting Loss:0.3969 + XiCon Loss:2.4429 x Lambda(0.1)), Vali MSE Loss: 0.7320 Test MSE Loss: 0.5201
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.6527582
	speed: 0.0179s/iter; left time: 608.7170s
	iters: 200, epoch: 31 | loss: 0.5433301
	speed: 0.0148s/iter; left time: 502.1886s
	iters: 300, epoch: 31 | loss: 0.6098831
	speed: 0.0147s/iter; left time: 497.8568s
	iters: 400, epoch: 31 | loss: 0.6620754
	speed: 0.0143s/iter; left time: 480.7238s
Epoch: 31 cost time: 7.58422064781189
Epoch: 31, Steps: 487 Train Loss: 0.6420 (Forecasting Loss:0.3968 + XiCon Loss:2.4520 x Lambda(0.1)), Vali MSE Loss: 0.7318 Test MSE Loss: 0.5201
Validation loss decreased (0.731905 --> 0.731771).  Saving model ...
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.6047813
	speed: 0.0172s/iter; left time: 575.6667s
	iters: 200, epoch: 32 | loss: 0.6134056
	speed: 0.0155s/iter; left time: 517.6090s
	iters: 300, epoch: 32 | loss: 0.5651107
	speed: 0.0150s/iter; left time: 500.0360s
	iters: 400, epoch: 32 | loss: 0.5430478
	speed: 0.0145s/iter; left time: 480.2462s
Epoch: 32 cost time: 7.715130805969238
Epoch: 32, Steps: 487 Train Loss: 0.6409 (Forecasting Loss:0.3968 + XiCon Loss:2.4406 x Lambda(0.1)), Vali MSE Loss: 0.7328 Test MSE Loss: 0.5201
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.5910196
	speed: 0.0174s/iter; left time: 574.1287s
	iters: 200, epoch: 33 | loss: 0.6860610
	speed: 0.0145s/iter; left time: 476.0474s
	iters: 300, epoch: 33 | loss: 0.6451312
	speed: 0.0153s/iter; left time: 501.1568s
	iters: 400, epoch: 33 | loss: 0.6011982
	speed: 0.0147s/iter; left time: 480.3830s
Epoch: 33 cost time: 7.5793776512146
Epoch: 33, Steps: 487 Train Loss: 0.6417 (Forecasting Loss:0.3969 + XiCon Loss:2.4475 x Lambda(0.1)), Vali MSE Loss: 0.7328 Test MSE Loss: 0.5201
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.6754543
	speed: 0.0169s/iter; left time: 548.7620s
	iters: 200, epoch: 34 | loss: 0.7135270
	speed: 0.0157s/iter; left time: 508.5196s
	iters: 300, epoch: 34 | loss: 0.6102076
	speed: 0.0145s/iter; left time: 469.3565s
	iters: 400, epoch: 34 | loss: 0.6365784
	speed: 0.0156s/iter; left time: 501.7058s
Epoch: 34 cost time: 7.648015737533569
Epoch: 34, Steps: 487 Train Loss: 0.6419 (Forecasting Loss:0.3969 + XiCon Loss:2.4504 x Lambda(0.1)), Vali MSE Loss: 0.7329 Test MSE Loss: 0.5201
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.5899121
	speed: 0.0163s/iter; left time: 523.1740s
	iters: 200, epoch: 35 | loss: 0.5680566
	speed: 0.0154s/iter; left time: 490.5296s
	iters: 300, epoch: 35 | loss: 0.5863869
	speed: 0.0147s/iter; left time: 466.8879s
	iters: 400, epoch: 35 | loss: 0.6315566
	speed: 0.0152s/iter; left time: 483.7154s
Epoch: 35 cost time: 7.493422985076904
Epoch: 35, Steps: 487 Train Loss: 0.6418 (Forecasting Loss:0.3968 + XiCon Loss:2.4497 x Lambda(0.1)), Vali MSE Loss: 0.7321 Test MSE Loss: 0.5201
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.6954490
	speed: 0.0161s/iter; left time: 506.8531s
	iters: 200, epoch: 36 | loss: 0.6931978
	speed: 0.0163s/iter; left time: 513.1692s
	iters: 300, epoch: 36 | loss: 0.6080400
	speed: 0.0153s/iter; left time: 479.0936s
	iters: 400, epoch: 36 | loss: 0.6911669
	speed: 0.0155s/iter; left time: 483.6887s
Epoch: 36 cost time: 7.828469514846802
Epoch: 36, Steps: 487 Train Loss: 0.6418 (Forecasting Loss:0.3972 + XiCon Loss:2.4465 x Lambda(0.1)), Vali MSE Loss: 0.7325 Test MSE Loss: 0.5201
EarlyStopping counter: 5 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.6316589
	speed: 0.0171s/iter; left time: 530.8767s
	iters: 200, epoch: 37 | loss: 0.5668468
	speed: 0.0150s/iter; left time: 465.3859s
	iters: 300, epoch: 37 | loss: 0.6321952
	speed: 0.0147s/iter; left time: 453.0368s
	iters: 400, epoch: 37 | loss: 0.6938800
	speed: 0.0154s/iter; left time: 474.1170s
Epoch: 37 cost time: 7.498330593109131
Epoch: 37, Steps: 487 Train Loss: 0.6419 (Forecasting Loss:0.3969 + XiCon Loss:2.4502 x Lambda(0.1)), Vali MSE Loss: 0.7323 Test MSE Loss: 0.5201
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.6202971
	speed: 0.0163s/iter; left time: 497.4561s
	iters: 200, epoch: 38 | loss: 0.6472448
	speed: 0.0142s/iter; left time: 431.8281s
	iters: 300, epoch: 38 | loss: 0.6407512
	speed: 0.0154s/iter; left time: 469.3769s
	iters: 400, epoch: 38 | loss: 0.5955948
	speed: 0.0161s/iter; left time: 487.3841s
Epoch: 38 cost time: 7.558868169784546
Epoch: 38, Steps: 487 Train Loss: 0.6421 (Forecasting Loss:0.3970 + XiCon Loss:2.4512 x Lambda(0.1)), Vali MSE Loss: 0.7324 Test MSE Loss: 0.5201
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.6142961
	speed: 0.0165s/iter; left time: 496.9730s
	iters: 200, epoch: 39 | loss: 0.6076424
	speed: 0.0150s/iter; left time: 450.7707s
	iters: 300, epoch: 39 | loss: 0.6440434
	speed: 0.0142s/iter; left time: 425.0834s
	iters: 400, epoch: 39 | loss: 0.6495352
	speed: 0.0155s/iter; left time: 462.3535s
Epoch: 39 cost time: 7.468735456466675
Epoch: 39, Steps: 487 Train Loss: 0.6412 (Forecasting Loss:0.3968 + XiCon Loss:2.4440 x Lambda(0.1)), Vali MSE Loss: 0.7322 Test MSE Loss: 0.5201
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.7089409
	speed: 0.0181s/iter; left time: 535.5928s
	iters: 200, epoch: 40 | loss: 0.6244014
	speed: 0.0153s/iter; left time: 452.7190s
	iters: 300, epoch: 40 | loss: 0.6447284
	speed: 0.0144s/iter; left time: 424.0815s
	iters: 400, epoch: 40 | loss: 0.5479133
	speed: 0.0150s/iter; left time: 438.4557s
Epoch: 40 cost time: 7.6355321407318115
Epoch: 40, Steps: 487 Train Loss: 0.6416 (Forecasting Loss:0.3971 + XiCon Loss:2.4450 x Lambda(0.1)), Vali MSE Loss: 0.7324 Test MSE Loss: 0.5201
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.6951752
	speed: 0.0176s/iter; left time: 511.4599s
	iters: 200, epoch: 41 | loss: 0.5588380
	speed: 0.0142s/iter; left time: 412.5817s
	iters: 300, epoch: 41 | loss: 0.6184351
	speed: 0.0142s/iter; left time: 411.6921s
	iters: 400, epoch: 41 | loss: 0.6148615
	speed: 0.0146s/iter; left time: 419.8216s
Epoch: 41 cost time: 7.540576934814453
Epoch: 41, Steps: 487 Train Loss: 0.6414 (Forecasting Loss:0.3968 + XiCon Loss:2.4454 x Lambda(0.1)), Vali MSE Loss: 0.7325 Test MSE Loss: 0.5201
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.528610110282898, mae:0.5115456581115723, mape:3.505112886428833, mspe:1130.834228515625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7060
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.3311334
	speed: 0.0161s/iter; left time: 781.0401s
	iters: 200, epoch: 1 | loss: 1.0780470
	speed: 0.0133s/iter; left time: 646.2216s
	iters: 300, epoch: 1 | loss: 0.9948655
	speed: 0.0133s/iter; left time: 642.3828s
	iters: 400, epoch: 1 | loss: 1.0485070
	speed: 0.0133s/iter; left time: 641.4810s
Epoch: 1 cost time: 6.827032566070557
Epoch: 1, Steps: 487 Train Loss: 1.0462 (Forecasting Loss:0.8011 + XiCon Loss:2.4508 x Lambda(0.1)), Vali MSE Loss: 1.0991 Test MSE Loss: 0.6611
Validation loss decreased (inf --> 1.099075).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.7969549
	speed: 0.0156s/iter; left time: 750.8382s
	iters: 200, epoch: 2 | loss: 0.6632175
	speed: 0.0134s/iter; left time: 644.3032s
	iters: 300, epoch: 2 | loss: 0.6419891
	speed: 0.0133s/iter; left time: 638.4853s
	iters: 400, epoch: 2 | loss: 0.5993329
	speed: 0.0137s/iter; left time: 657.2405s
Epoch: 2 cost time: 6.791881084442139
Epoch: 2, Steps: 487 Train Loss: 0.6795 (Forecasting Loss:0.4351 + XiCon Loss:2.4438 x Lambda(0.1)), Vali MSE Loss: 0.7541 Test MSE Loss: 0.5175
Validation loss decreased (1.099075 --> 0.754104).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.6668277
	speed: 0.0148s/iter; left time: 704.3097s
	iters: 200, epoch: 3 | loss: 0.6677707
	speed: 0.0128s/iter; left time: 610.1692s
	iters: 300, epoch: 3 | loss: 0.6447081
	speed: 0.0130s/iter; left time: 616.2603s
	iters: 400, epoch: 3 | loss: 0.6872038
	speed: 0.0135s/iter; left time: 636.7795s
Epoch: 3 cost time: 6.612340688705444
Epoch: 3, Steps: 487 Train Loss: 0.6459 (Forecasting Loss:0.4021 + XiCon Loss:2.4388 x Lambda(0.1)), Vali MSE Loss: 0.7474 Test MSE Loss: 0.5103
Validation loss decreased (0.754104 --> 0.747371).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.6420453
	speed: 0.0157s/iter; left time: 740.0863s
	iters: 200, epoch: 4 | loss: 0.6430837
	speed: 0.0137s/iter; left time: 644.0359s
	iters: 300, epoch: 4 | loss: 0.7200557
	speed: 0.0129s/iter; left time: 605.2846s
	iters: 400, epoch: 4 | loss: 0.5794367
	speed: 0.0138s/iter; left time: 644.9779s
Epoch: 4 cost time: 6.853008985519409
Epoch: 4, Steps: 487 Train Loss: 0.6410 (Forecasting Loss:0.3971 + XiCon Loss:2.4382 x Lambda(0.1)), Vali MSE Loss: 0.7391 Test MSE Loss: 0.5082
Validation loss decreased (0.747371 --> 0.739115).  Saving model ...
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.6236126
	speed: 0.0155s/iter; left time: 721.6241s
	iters: 200, epoch: 5 | loss: 0.6791873
	speed: 0.0127s/iter; left time: 592.2698s
	iters: 300, epoch: 5 | loss: 0.6649675
	speed: 0.0136s/iter; left time: 633.6537s
	iters: 400, epoch: 5 | loss: 0.6413581
	speed: 0.0131s/iter; left time: 607.7089s
Epoch: 5 cost time: 6.702279090881348
Epoch: 5, Steps: 487 Train Loss: 0.6389 (Forecasting Loss:0.3949 + XiCon Loss:2.4392 x Lambda(0.1)), Vali MSE Loss: 0.7370 Test MSE Loss: 0.5080
Validation loss decreased (0.739115 --> 0.736988).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.6438295
	speed: 0.0147s/iter; left time: 677.0141s
	iters: 200, epoch: 6 | loss: 0.6010637
	speed: 0.0130s/iter; left time: 598.2586s
	iters: 300, epoch: 6 | loss: 0.6939778
	speed: 0.0138s/iter; left time: 632.9589s
	iters: 400, epoch: 6 | loss: 0.7525842
	speed: 0.0137s/iter; left time: 627.4121s
Epoch: 6 cost time: 6.781557321548462
Epoch: 6, Steps: 487 Train Loss: 0.6376 (Forecasting Loss:0.3939 + XiCon Loss:2.4367 x Lambda(0.1)), Vali MSE Loss: 0.7356 Test MSE Loss: 0.5075
Validation loss decreased (0.736988 --> 0.735562).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.6251699
	speed: 0.0152s/iter; left time: 696.1695s
	iters: 200, epoch: 7 | loss: 0.5859172
	speed: 0.0124s/iter; left time: 564.9181s
	iters: 300, epoch: 7 | loss: 0.6217728
	speed: 0.0132s/iter; left time: 598.6461s
	iters: 400, epoch: 7 | loss: 0.6224556
	speed: 0.0135s/iter; left time: 611.7314s
Epoch: 7 cost time: 6.706559181213379
Epoch: 7, Steps: 487 Train Loss: 0.6365 (Forecasting Loss:0.3934 + XiCon Loss:2.4309 x Lambda(0.1)), Vali MSE Loss: 0.7357 Test MSE Loss: 0.5071
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.6681994
	speed: 0.0164s/iter; left time: 740.1610s
	iters: 200, epoch: 8 | loss: 0.7026522
	speed: 0.0136s/iter; left time: 613.9099s
	iters: 300, epoch: 8 | loss: 0.6260357
	speed: 0.0147s/iter; left time: 662.4452s
	iters: 400, epoch: 8 | loss: 0.5810648
	speed: 0.0152s/iter; left time: 684.1852s
Epoch: 8 cost time: 7.292299270629883
Epoch: 8, Steps: 487 Train Loss: 0.6363 (Forecasting Loss:0.3931 + XiCon Loss:2.4317 x Lambda(0.1)), Vali MSE Loss: 0.7351 Test MSE Loss: 0.5068
Validation loss decreased (0.735562 --> 0.735060).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.6285648
	speed: 0.0173s/iter; left time: 772.0314s
	iters: 200, epoch: 9 | loss: 0.6122345
	speed: 0.0146s/iter; left time: 650.9496s
	iters: 300, epoch: 9 | loss: 0.6627395
	speed: 0.0163s/iter; left time: 726.7279s
	iters: 400, epoch: 9 | loss: 0.6586535
	speed: 0.0143s/iter; left time: 634.0601s
Epoch: 9 cost time: 7.595714330673218
Epoch: 9, Steps: 487 Train Loss: 0.6367 (Forecasting Loss:0.3931 + XiCon Loss:2.4357 x Lambda(0.1)), Vali MSE Loss: 0.7352 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.6530383
	speed: 0.0151s/iter; left time: 665.9695s
	iters: 200, epoch: 10 | loss: 0.6483722
	speed: 0.0138s/iter; left time: 610.9709s
	iters: 300, epoch: 10 | loss: 0.7188941
	speed: 0.0145s/iter; left time: 637.6390s
	iters: 400, epoch: 10 | loss: 0.6654441
	speed: 0.0158s/iter; left time: 692.2303s
Epoch: 10 cost time: 7.2422590255737305
Epoch: 10, Steps: 487 Train Loss: 0.6361 (Forecasting Loss:0.3929 + XiCon Loss:2.4316 x Lambda(0.1)), Vali MSE Loss: 0.7350 Test MSE Loss: 0.5068
Validation loss decreased (0.735060 --> 0.735038).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.6208830
	speed: 0.0175s/iter; left time: 763.9708s
	iters: 200, epoch: 11 | loss: 0.5794538
	speed: 0.0144s/iter; left time: 630.1817s
	iters: 300, epoch: 11 | loss: 0.5905263
	speed: 0.0139s/iter; left time: 605.5454s
	iters: 400, epoch: 11 | loss: 0.5882416
	speed: 0.0163s/iter; left time: 708.7124s
Epoch: 11 cost time: 7.609911203384399
Epoch: 11, Steps: 487 Train Loss: 0.6361 (Forecasting Loss:0.3928 + XiCon Loss:2.4327 x Lambda(0.1)), Vali MSE Loss: 0.7349 Test MSE Loss: 0.5068
Validation loss decreased (0.735038 --> 0.734865).  Saving model ...
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.7302982
	speed: 0.0167s/iter; left time: 721.8418s
	iters: 200, epoch: 12 | loss: 0.6296399
	speed: 0.0137s/iter; left time: 589.2518s
	iters: 300, epoch: 12 | loss: 0.6913245
	speed: 0.0145s/iter; left time: 623.7412s
	iters: 400, epoch: 12 | loss: 0.5911196
	speed: 0.0144s/iter; left time: 620.3824s
Epoch: 12 cost time: 7.387051343917847
Epoch: 12, Steps: 487 Train Loss: 0.6366 (Forecasting Loss:0.3929 + XiCon Loss:2.4374 x Lambda(0.1)), Vali MSE Loss: 0.7349 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.6659544
	speed: 0.0169s/iter; left time: 724.5135s
	iters: 200, epoch: 13 | loss: 0.6327572
	speed: 0.0144s/iter; left time: 615.8351s
	iters: 300, epoch: 13 | loss: 0.5562752
	speed: 0.0141s/iter; left time: 598.0781s
	iters: 400, epoch: 13 | loss: 0.6288425
	speed: 0.0149s/iter; left time: 630.8911s
Epoch: 13 cost time: 7.419353485107422
Epoch: 13, Steps: 487 Train Loss: 0.6360 (Forecasting Loss:0.3928 + XiCon Loss:2.4320 x Lambda(0.1)), Vali MSE Loss: 0.7349 Test MSE Loss: 0.5068
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.6047405
	speed: 0.0159s/iter; left time: 673.2272s
	iters: 200, epoch: 14 | loss: 0.5669035
	speed: 0.0153s/iter; left time: 645.5520s
	iters: 300, epoch: 14 | loss: 0.5748121
	speed: 0.0146s/iter; left time: 614.7493s
	iters: 400, epoch: 14 | loss: 0.6278359
	speed: 0.0144s/iter; left time: 605.9258s
Epoch: 14 cost time: 7.340636730194092
Epoch: 14, Steps: 487 Train Loss: 0.6359 (Forecasting Loss:0.3927 + XiCon Loss:2.4325 x Lambda(0.1)), Vali MSE Loss: 0.7350 Test MSE Loss: 0.5068
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.6546911
	speed: 0.0162s/iter; left time: 677.0399s
	iters: 200, epoch: 15 | loss: 0.6318403
	speed: 0.0146s/iter; left time: 608.5045s
	iters: 300, epoch: 15 | loss: 0.7618189
	speed: 0.0151s/iter; left time: 628.3448s
	iters: 400, epoch: 15 | loss: 0.5930805
	speed: 0.0152s/iter; left time: 630.3317s
Epoch: 15 cost time: 7.428147315979004
Epoch: 15, Steps: 487 Train Loss: 0.6362 (Forecasting Loss:0.3932 + XiCon Loss:2.4301 x Lambda(0.1)), Vali MSE Loss: 0.7348 Test MSE Loss: 0.5068
Validation loss decreased (0.734865 --> 0.734817).  Saving model ...
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.5917428
	speed: 0.0161s/iter; left time: 666.0687s
	iters: 200, epoch: 16 | loss: 0.5715168
	speed: 0.0149s/iter; left time: 612.7938s
	iters: 300, epoch: 16 | loss: 0.6187472
	speed: 0.0148s/iter; left time: 609.4392s
	iters: 400, epoch: 16 | loss: 0.6065110
	speed: 0.0148s/iter; left time: 608.5441s
Epoch: 16 cost time: 7.411000490188599
Epoch: 16, Steps: 487 Train Loss: 0.6357 (Forecasting Loss:0.3928 + XiCon Loss:2.4287 x Lambda(0.1)), Vali MSE Loss: 0.7353 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.6246734
	speed: 0.0160s/iter; left time: 652.4614s
	iters: 200, epoch: 17 | loss: 0.6207807
	speed: 0.0139s/iter; left time: 565.8506s
	iters: 300, epoch: 17 | loss: 0.6361459
	speed: 0.0158s/iter; left time: 642.6438s
	iters: 400, epoch: 17 | loss: 0.6523948
	speed: 0.0143s/iter; left time: 577.2875s
Epoch: 17 cost time: 7.384411811828613
Epoch: 17, Steps: 487 Train Loss: 0.6367 (Forecasting Loss:0.3928 + XiCon Loss:2.4391 x Lambda(0.1)), Vali MSE Loss: 0.7350 Test MSE Loss: 0.5068
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.7253217
	speed: 0.0161s/iter; left time: 647.2865s
	iters: 200, epoch: 18 | loss: 0.6564172
	speed: 0.0142s/iter; left time: 570.2477s
	iters: 300, epoch: 18 | loss: 0.5913951
	speed: 0.0148s/iter; left time: 593.8513s
	iters: 400, epoch: 18 | loss: 0.5778389
	speed: 0.0161s/iter; left time: 643.2459s
Epoch: 18 cost time: 7.397942304611206
Epoch: 18, Steps: 487 Train Loss: 0.6363 (Forecasting Loss:0.3929 + XiCon Loss:2.4341 x Lambda(0.1)), Vali MSE Loss: 0.7348 Test MSE Loss: 0.5068
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.6557050
	speed: 0.0181s/iter; left time: 719.2193s
	iters: 200, epoch: 19 | loss: 0.6281664
	speed: 0.0145s/iter; left time: 578.0182s
	iters: 300, epoch: 19 | loss: 0.5411683
	speed: 0.0147s/iter; left time: 582.3182s
	iters: 400, epoch: 19 | loss: 0.6987086
	speed: 0.0147s/iter; left time: 581.6932s
Epoch: 19 cost time: 7.596118211746216
Epoch: 19, Steps: 487 Train Loss: 0.6365 (Forecasting Loss:0.3930 + XiCon Loss:2.4353 x Lambda(0.1)), Vali MSE Loss: 0.7350 Test MSE Loss: 0.5068
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.6553426
	speed: 0.0182s/iter; left time: 714.2338s
	iters: 200, epoch: 20 | loss: 0.6103617
	speed: 0.0145s/iter; left time: 570.8451s
	iters: 300, epoch: 20 | loss: 0.5859594
	speed: 0.0139s/iter; left time: 544.9262s
	iters: 400, epoch: 20 | loss: 0.5800465
	speed: 0.0146s/iter; left time: 570.3001s
Epoch: 20 cost time: 7.522003650665283
Epoch: 20, Steps: 487 Train Loss: 0.6364 (Forecasting Loss:0.3930 + XiCon Loss:2.4342 x Lambda(0.1)), Vali MSE Loss: 0.7348 Test MSE Loss: 0.5068
Validation loss decreased (0.734817 --> 0.734808).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.6648171
	speed: 0.0167s/iter; left time: 649.4617s
	iters: 200, epoch: 21 | loss: 0.6346766
	speed: 0.0151s/iter; left time: 585.2350s
	iters: 300, epoch: 21 | loss: 0.5714952
	speed: 0.0146s/iter; left time: 562.5450s
	iters: 400, epoch: 21 | loss: 0.6005958
	speed: 0.0145s/iter; left time: 558.8161s
Epoch: 21 cost time: 7.518456220626831
Epoch: 21, Steps: 487 Train Loss: 0.6366 (Forecasting Loss:0.3928 + XiCon Loss:2.4384 x Lambda(0.1)), Vali MSE Loss: 0.7353 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.6315762
	speed: 0.0166s/iter; left time: 636.2906s
	iters: 200, epoch: 22 | loss: 0.6483102
	speed: 0.0154s/iter; left time: 587.8349s
	iters: 300, epoch: 22 | loss: 0.6708511
	speed: 0.0152s/iter; left time: 579.0598s
	iters: 400, epoch: 22 | loss: 0.6109251
	speed: 0.0145s/iter; left time: 552.8541s
Epoch: 22 cost time: 7.576045036315918
Epoch: 22, Steps: 487 Train Loss: 0.6365 (Forecasting Loss:0.3928 + XiCon Loss:2.4370 x Lambda(0.1)), Vali MSE Loss: 0.7349 Test MSE Loss: 0.5068
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.5803864
	speed: 0.0168s/iter; left time: 636.2204s
	iters: 200, epoch: 23 | loss: 0.5986623
	speed: 0.0151s/iter; left time: 569.9715s
	iters: 300, epoch: 23 | loss: 0.6879199
	speed: 0.0140s/iter; left time: 526.6260s
	iters: 400, epoch: 23 | loss: 0.6551269
	speed: 0.0145s/iter; left time: 546.0108s
Epoch: 23 cost time: 7.33429217338562
Epoch: 23, Steps: 487 Train Loss: 0.6364 (Forecasting Loss:0.3928 + XiCon Loss:2.4357 x Lambda(0.1)), Vali MSE Loss: 0.7348 Test MSE Loss: 0.5068
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.6548370
	speed: 0.0158s/iter; left time: 592.7077s
	iters: 200, epoch: 24 | loss: 0.6880090
	speed: 0.0155s/iter; left time: 578.0048s
	iters: 300, epoch: 24 | loss: 0.5613812
	speed: 0.0139s/iter; left time: 516.9118s
	iters: 400, epoch: 24 | loss: 0.6703624
	speed: 0.0153s/iter; left time: 566.5503s
Epoch: 24 cost time: 7.432190895080566
Epoch: 24, Steps: 487 Train Loss: 0.6360 (Forecasting Loss:0.3929 + XiCon Loss:2.4308 x Lambda(0.1)), Vali MSE Loss: 0.7351 Test MSE Loss: 0.5068
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.6217523
	speed: 0.0160s/iter; left time: 591.1306s
	iters: 200, epoch: 25 | loss: 0.5816810
	speed: 0.0158s/iter; left time: 582.1345s
	iters: 300, epoch: 25 | loss: 0.6360419
	speed: 0.0143s/iter; left time: 525.2862s
	iters: 400, epoch: 25 | loss: 0.6642529
	speed: 0.0148s/iter; left time: 542.2666s
Epoch: 25 cost time: 7.403982877731323
Epoch: 25, Steps: 487 Train Loss: 0.6365 (Forecasting Loss:0.3928 + XiCon Loss:2.4371 x Lambda(0.1)), Vali MSE Loss: 0.7345 Test MSE Loss: 0.5068
Validation loss decreased (0.734808 --> 0.734467).  Saving model ...
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.6297290
	speed: 0.0163s/iter; left time: 594.6698s
	iters: 200, epoch: 26 | loss: 0.5878819
	speed: 0.0139s/iter; left time: 503.8828s
	iters: 300, epoch: 26 | loss: 0.6678293
	speed: 0.0147s/iter; left time: 531.2996s
	iters: 400, epoch: 26 | loss: 0.6940047
	speed: 0.0163s/iter; left time: 587.5817s
Epoch: 26 cost time: 7.44163703918457
Epoch: 26, Steps: 487 Train Loss: 0.6359 (Forecasting Loss:0.3927 + XiCon Loss:2.4322 x Lambda(0.1)), Vali MSE Loss: 0.7353 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.6386833
	speed: 0.0161s/iter; left time: 579.2901s
	iters: 200, epoch: 27 | loss: 0.6802908
	speed: 0.0137s/iter; left time: 489.4867s
	iters: 300, epoch: 27 | loss: 0.5849209
	speed: 0.0142s/iter; left time: 506.7955s
	iters: 400, epoch: 27 | loss: 0.6353890
	speed: 0.0155s/iter; left time: 551.5269s
Epoch: 27 cost time: 7.288722038269043
Epoch: 27, Steps: 487 Train Loss: 0.6364 (Forecasting Loss:0.3928 + XiCon Loss:2.4366 x Lambda(0.1)), Vali MSE Loss: 0.7351 Test MSE Loss: 0.5068
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.6131487
	speed: 0.0180s/iter; left time: 638.9259s
	iters: 200, epoch: 28 | loss: 0.6043928
	speed: 0.0149s/iter; left time: 525.9889s
	iters: 300, epoch: 28 | loss: 0.5938846
	speed: 0.0148s/iter; left time: 521.1410s
	iters: 400, epoch: 28 | loss: 0.6620671
	speed: 0.0153s/iter; left time: 538.5893s
Epoch: 28 cost time: 7.696321964263916
Epoch: 28, Steps: 487 Train Loss: 0.6363 (Forecasting Loss:0.3929 + XiCon Loss:2.4334 x Lambda(0.1)), Vali MSE Loss: 0.7344 Test MSE Loss: 0.5068
Validation loss decreased (0.734467 --> 0.734369).  Saving model ...
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.6889539
	speed: 0.0175s/iter; left time: 612.4870s
	iters: 200, epoch: 29 | loss: 0.6427252
	speed: 0.0139s/iter; left time: 484.1063s
	iters: 300, epoch: 29 | loss: 0.6046697
	speed: 0.0153s/iter; left time: 532.5314s
	iters: 400, epoch: 29 | loss: 0.6449865
	speed: 0.0146s/iter; left time: 507.8049s
Epoch: 29 cost time: 7.547019004821777
Epoch: 29, Steps: 487 Train Loss: 0.6362 (Forecasting Loss:0.3928 + XiCon Loss:2.4336 x Lambda(0.1)), Vali MSE Loss: 0.7346 Test MSE Loss: 0.5068
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.6895134
	speed: 0.0154s/iter; left time: 532.1976s
	iters: 200, epoch: 30 | loss: 0.6678916
	speed: 0.0159s/iter; left time: 544.9143s
	iters: 300, epoch: 30 | loss: 0.6226678
	speed: 0.0136s/iter; left time: 467.1980s
	iters: 400, epoch: 30 | loss: 0.6031682
	speed: 0.0146s/iter; left time: 498.6314s
Epoch: 30 cost time: 7.2578558921813965
Epoch: 30, Steps: 487 Train Loss: 0.6366 (Forecasting Loss:0.3929 + XiCon Loss:2.4378 x Lambda(0.1)), Vali MSE Loss: 0.7350 Test MSE Loss: 0.5068
EarlyStopping counter: 2 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.5817753
	speed: 0.0163s/iter; left time: 554.9056s
	iters: 200, epoch: 31 | loss: 0.5405260
	speed: 0.0140s/iter; left time: 474.2616s
	iters: 300, epoch: 31 | loss: 0.6790712
	speed: 0.0144s/iter; left time: 486.9046s
	iters: 400, epoch: 31 | loss: 0.6314443
	speed: 0.0146s/iter; left time: 492.5219s
Epoch: 31 cost time: 7.222747802734375
Epoch: 31, Steps: 487 Train Loss: 0.6362 (Forecasting Loss:0.3928 + XiCon Loss:2.4330 x Lambda(0.1)), Vali MSE Loss: 0.7350 Test MSE Loss: 0.5068
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.6900342
	speed: 0.0159s/iter; left time: 532.3352s
	iters: 200, epoch: 32 | loss: 0.7086990
	speed: 0.0145s/iter; left time: 484.0889s
	iters: 300, epoch: 32 | loss: 0.6166202
	speed: 0.0149s/iter; left time: 497.0633s
	iters: 400, epoch: 32 | loss: 0.6407966
	speed: 0.0145s/iter; left time: 480.6645s
Epoch: 32 cost time: 7.324850082397461
Epoch: 32, Steps: 487 Train Loss: 0.6364 (Forecasting Loss:0.3929 + XiCon Loss:2.4349 x Lambda(0.1)), Vali MSE Loss: 0.7348 Test MSE Loss: 0.5068
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.6656592
	speed: 0.0161s/iter; left time: 532.6978s
	iters: 200, epoch: 33 | loss: 0.6675533
	speed: 0.0148s/iter; left time: 488.6473s
	iters: 300, epoch: 33 | loss: 0.6006814
	speed: 0.0143s/iter; left time: 469.4164s
	iters: 400, epoch: 33 | loss: 0.5829831
	speed: 0.0160s/iter; left time: 522.4940s
Epoch: 33 cost time: 7.413498640060425
Epoch: 33, Steps: 487 Train Loss: 0.6358 (Forecasting Loss:0.3927 + XiCon Loss:2.4311 x Lambda(0.1)), Vali MSE Loss: 0.7349 Test MSE Loss: 0.5068
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.5899981
	speed: 0.0169s/iter; left time: 548.1949s
	iters: 200, epoch: 34 | loss: 0.6562842
	speed: 0.0142s/iter; left time: 461.5294s
	iters: 300, epoch: 34 | loss: 0.5508907
	speed: 0.0144s/iter; left time: 465.9834s
	iters: 400, epoch: 34 | loss: 0.5895750
	speed: 0.0148s/iter; left time: 478.4493s
Epoch: 34 cost time: 7.327008008956909
Epoch: 34, Steps: 487 Train Loss: 0.6362 (Forecasting Loss:0.3930 + XiCon Loss:2.4327 x Lambda(0.1)), Vali MSE Loss: 0.7353 Test MSE Loss: 0.5068
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.6300071
	speed: 0.0163s/iter; left time: 521.5018s
	iters: 200, epoch: 35 | loss: 0.6571912
	speed: 0.0162s/iter; left time: 518.5182s
	iters: 300, epoch: 35 | loss: 0.5930129
	speed: 0.0142s/iter; left time: 453.1949s
	iters: 400, epoch: 35 | loss: 0.5845299
	speed: 0.0149s/iter; left time: 474.1915s
Epoch: 35 cost time: 7.550615072250366
Epoch: 35, Steps: 487 Train Loss: 0.6363 (Forecasting Loss:0.3931 + XiCon Loss:2.4322 x Lambda(0.1)), Vali MSE Loss: 0.7347 Test MSE Loss: 0.5068
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.6043219
	speed: 0.0157s/iter; left time: 494.6585s
	iters: 200, epoch: 36 | loss: 0.7217280
	speed: 0.0135s/iter; left time: 424.2660s
	iters: 300, epoch: 36 | loss: 0.5874156
	speed: 0.0155s/iter; left time: 487.4748s
	iters: 400, epoch: 36 | loss: 0.6754065
	speed: 0.0147s/iter; left time: 458.7478s
Epoch: 36 cost time: 7.238430023193359
Epoch: 36, Steps: 487 Train Loss: 0.6360 (Forecasting Loss:0.3926 + XiCon Loss:2.4337 x Lambda(0.1)), Vali MSE Loss: 0.7346 Test MSE Loss: 0.5068
EarlyStopping counter: 8 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.5959784
	speed: 0.0163s/iter; left time: 507.4018s
	iters: 200, epoch: 37 | loss: 0.6438854
	speed: 0.0139s/iter; left time: 431.1520s
	iters: 300, epoch: 37 | loss: 0.6798638
	speed: 0.0133s/iter; left time: 411.7065s
	iters: 400, epoch: 37 | loss: 0.6236455
	speed: 0.0140s/iter; left time: 431.7284s
Epoch: 37 cost time: 6.9575700759887695
Epoch: 37, Steps: 487 Train Loss: 0.6360 (Forecasting Loss:0.3929 + XiCon Loss:2.4310 x Lambda(0.1)), Vali MSE Loss: 0.7348 Test MSE Loss: 0.5068
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.5834467
	speed: 0.0151s/iter; left time: 462.2646s
	iters: 200, epoch: 38 | loss: 0.5763840
	speed: 0.0131s/iter; left time: 399.9821s
	iters: 300, epoch: 38 | loss: 0.6565477
	speed: 0.0136s/iter; left time: 414.6344s
	iters: 400, epoch: 38 | loss: 0.6683498
	speed: 0.0134s/iter; left time: 406.9170s
Epoch: 38 cost time: 6.808685302734375
Epoch: 38, Steps: 487 Train Loss: 0.6367 (Forecasting Loss:0.3928 + XiCon Loss:2.4391 x Lambda(0.1)), Vali MSE Loss: 0.7351 Test MSE Loss: 0.5068
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5113699436187744, mae:0.5021573305130005, mape:3.5771946907043457, mspe:1185.0189208984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:64985
train 31186
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.6802
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 31186
val 10445
test 10444
	iters: 100, epoch: 1 | loss: 1.0970827
	speed: 0.0177s/iter; left time: 860.0298s
	iters: 200, epoch: 1 | loss: 1.0705167
	speed: 0.0140s/iter; left time: 678.9762s
	iters: 300, epoch: 1 | loss: 0.9604070
	speed: 0.0137s/iter; left time: 663.4104s
	iters: 400, epoch: 1 | loss: 0.8927429
	speed: 0.0135s/iter; left time: 650.1666s
Epoch: 1 cost time: 7.11918830871582
Epoch: 1, Steps: 487 Train Loss: 1.0016 (Forecasting Loss:0.7529 + XiCon Loss:2.4874 x Lambda(0.1)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.6213
Validation loss decreased (inf --> 1.005162).  Saving model ...
Updating learning rate to 0.0003
	iters: 100, epoch: 2 | loss: 0.7537156
	speed: 0.0156s/iter; left time: 748.7082s
	iters: 200, epoch: 2 | loss: 0.6563854
	speed: 0.0141s/iter; left time: 675.9076s
	iters: 300, epoch: 2 | loss: 0.8010609
	speed: 0.0141s/iter; left time: 675.6273s
	iters: 400, epoch: 2 | loss: 0.6307924
	speed: 0.0142s/iter; left time: 678.8342s
Epoch: 2 cost time: 7.018053293228149
Epoch: 2, Steps: 487 Train Loss: 0.6832 (Forecasting Loss:0.4360 + XiCon Loss:2.4716 x Lambda(0.1)), Vali MSE Loss: 0.7632 Test MSE Loss: 0.5396
Validation loss decreased (1.005162 --> 0.763160).  Saving model ...
Updating learning rate to 0.00015
	iters: 100, epoch: 3 | loss: 0.6947121
	speed: 0.0159s/iter; left time: 756.0445s
	iters: 200, epoch: 3 | loss: 0.6186813
	speed: 0.0132s/iter; left time: 627.8382s
	iters: 300, epoch: 3 | loss: 0.7310644
	speed: 0.0133s/iter; left time: 632.1530s
	iters: 400, epoch: 3 | loss: 0.5966345
	speed: 0.0138s/iter; left time: 651.2738s
Epoch: 3 cost time: 6.850701332092285
Epoch: 3, Steps: 487 Train Loss: 0.6516 (Forecasting Loss:0.4060 + XiCon Loss:2.4554 x Lambda(0.1)), Vali MSE Loss: 0.7475 Test MSE Loss: 0.5200
Validation loss decreased (0.763160 --> 0.747490).  Saving model ...
Updating learning rate to 7.5e-05
	iters: 100, epoch: 4 | loss: 0.7368401
	speed: 0.0160s/iter; left time: 755.2424s
	iters: 200, epoch: 4 | loss: 0.6401993
	speed: 0.0142s/iter; left time: 669.8443s
	iters: 300, epoch: 4 | loss: 0.6293778
	speed: 0.0165s/iter; left time: 775.1861s
	iters: 400, epoch: 4 | loss: 0.5406941
	speed: 0.0157s/iter; left time: 736.6186s
Epoch: 4 cost time: 7.5716307163238525
Epoch: 4, Steps: 487 Train Loss: 0.6445 (Forecasting Loss:0.4001 + XiCon Loss:2.4435 x Lambda(0.1)), Vali MSE Loss: 0.7484 Test MSE Loss: 0.5190
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.75e-05
	iters: 100, epoch: 5 | loss: 0.6120601
	speed: 0.0163s/iter; left time: 760.1772s
	iters: 200, epoch: 5 | loss: 0.6990426
	speed: 0.0159s/iter; left time: 742.4392s
	iters: 300, epoch: 5 | loss: 0.6289231
	speed: 0.0144s/iter; left time: 670.9267s
	iters: 400, epoch: 5 | loss: 0.6953344
	speed: 0.0147s/iter; left time: 680.5326s
Epoch: 5 cost time: 7.4567718505859375
Epoch: 5, Steps: 487 Train Loss: 0.6424 (Forecasting Loss:0.3980 + XiCon Loss:2.4432 x Lambda(0.1)), Vali MSE Loss: 0.7403 Test MSE Loss: 0.5140
Validation loss decreased (0.747490 --> 0.740278).  Saving model ...
Updating learning rate to 1.875e-05
	iters: 100, epoch: 6 | loss: 0.6937941
	speed: 0.0187s/iter; left time: 862.8348s
	iters: 200, epoch: 6 | loss: 0.6722210
	speed: 0.0148s/iter; left time: 679.8038s
	iters: 300, epoch: 6 | loss: 0.8083887
	speed: 0.0150s/iter; left time: 689.0824s
	iters: 400, epoch: 6 | loss: 0.7092776
	speed: 0.0175s/iter; left time: 802.9452s
Epoch: 6 cost time: 7.928987741470337
Epoch: 6, Steps: 487 Train Loss: 0.6414 (Forecasting Loss:0.3969 + XiCon Loss:2.4455 x Lambda(0.1)), Vali MSE Loss: 0.7392 Test MSE Loss: 0.5130
Validation loss decreased (0.740278 --> 0.739173).  Saving model ...
Updating learning rate to 9.375e-06
	iters: 100, epoch: 7 | loss: 0.5685609
	speed: 0.0173s/iter; left time: 791.2458s
	iters: 200, epoch: 7 | loss: 0.6117112
	speed: 0.0143s/iter; left time: 652.6962s
	iters: 300, epoch: 7 | loss: 0.5600681
	speed: 0.0142s/iter; left time: 646.5087s
	iters: 400, epoch: 7 | loss: 0.6027600
	speed: 0.0144s/iter; left time: 654.7829s
Epoch: 7 cost time: 7.50438380241394
Epoch: 7, Steps: 487 Train Loss: 0.6403 (Forecasting Loss:0.3964 + XiCon Loss:2.4392 x Lambda(0.1)), Vali MSE Loss: 0.7394 Test MSE Loss: 0.5140
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.6875e-06
	iters: 100, epoch: 8 | loss: 0.5956187
	speed: 0.0181s/iter; left time: 820.0190s
	iters: 200, epoch: 8 | loss: 0.6344121
	speed: 0.0142s/iter; left time: 640.8927s
	iters: 300, epoch: 8 | loss: 0.7843673
	speed: 0.0151s/iter; left time: 678.2720s
	iters: 400, epoch: 8 | loss: 0.6690583
	speed: 0.0160s/iter; left time: 718.6978s
Epoch: 8 cost time: 7.795768737792969
Epoch: 8, Steps: 487 Train Loss: 0.6401 (Forecasting Loss:0.3959 + XiCon Loss:2.4411 x Lambda(0.1)), Vali MSE Loss: 0.7387 Test MSE Loss: 0.5132
Validation loss decreased (0.739173 --> 0.738718).  Saving model ...
Updating learning rate to 2.34375e-06
	iters: 100, epoch: 9 | loss: 0.5977458
	speed: 0.0181s/iter; left time: 808.0687s
	iters: 200, epoch: 9 | loss: 0.7206941
	speed: 0.0150s/iter; left time: 668.2558s
	iters: 300, epoch: 9 | loss: 0.7159524
	speed: 0.0144s/iter; left time: 640.4029s
	iters: 400, epoch: 9 | loss: 0.6510754
	speed: 0.0161s/iter; left time: 717.1333s
Epoch: 9 cost time: 7.7106547355651855
Epoch: 9, Steps: 487 Train Loss: 0.6400 (Forecasting Loss:0.3958 + XiCon Loss:2.4418 x Lambda(0.1)), Vali MSE Loss: 0.7387 Test MSE Loss: 0.5134
Validation loss decreased (0.738718 --> 0.738692).  Saving model ...
Updating learning rate to 1.171875e-06
	iters: 100, epoch: 10 | loss: 0.6065031
	speed: 0.0177s/iter; left time: 782.5667s
	iters: 200, epoch: 10 | loss: 0.6953645
	speed: 0.0148s/iter; left time: 650.9854s
	iters: 300, epoch: 10 | loss: 0.6121695
	speed: 0.0147s/iter; left time: 646.8085s
	iters: 400, epoch: 10 | loss: 0.6535245
	speed: 0.0161s/iter; left time: 707.7011s
Epoch: 10 cost time: 7.650254249572754
Epoch: 10, Steps: 487 Train Loss: 0.6402 (Forecasting Loss:0.3958 + XiCon Loss:2.4442 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
Validation loss decreased (0.738692 --> 0.738592).  Saving model ...
Updating learning rate to 5.859375e-07
	iters: 100, epoch: 11 | loss: 0.6200377
	speed: 0.0174s/iter; left time: 761.6804s
	iters: 200, epoch: 11 | loss: 0.6473327
	speed: 0.0144s/iter; left time: 627.4623s
	iters: 300, epoch: 11 | loss: 0.5759507
	speed: 0.0157s/iter; left time: 681.7051s
	iters: 400, epoch: 11 | loss: 0.6438154
	speed: 0.0157s/iter; left time: 681.5695s
Epoch: 11 cost time: 7.639400959014893
Epoch: 11, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3957 + XiCon Loss:2.4399 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9296875e-07
	iters: 100, epoch: 12 | loss: 0.6749865
	speed: 0.0168s/iter; left time: 725.0591s
	iters: 200, epoch: 12 | loss: 0.5154184
	speed: 0.0144s/iter; left time: 623.2473s
	iters: 300, epoch: 12 | loss: 0.6428491
	speed: 0.0161s/iter; left time: 691.5922s
	iters: 400, epoch: 12 | loss: 0.6795809
	speed: 0.0147s/iter; left time: 632.6745s
Epoch: 12 cost time: 7.580505132675171
Epoch: 12, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3959 + XiCon Loss:2.4365 x Lambda(0.1)), Vali MSE Loss: 0.7383 Test MSE Loss: 0.5132
Validation loss decreased (0.738592 --> 0.738252).  Saving model ...
Updating learning rate to 1.46484375e-07
	iters: 100, epoch: 13 | loss: 0.6093825
	speed: 0.0161s/iter; left time: 688.2852s
	iters: 200, epoch: 13 | loss: 0.5710343
	speed: 0.0153s/iter; left time: 654.4502s
	iters: 300, epoch: 13 | loss: 0.6263294
	speed: 0.0148s/iter; left time: 628.3607s
	iters: 400, epoch: 13 | loss: 0.6185300
	speed: 0.0147s/iter; left time: 625.5796s
Epoch: 13 cost time: 7.424774646759033
Epoch: 13, Steps: 487 Train Loss: 0.6401 (Forecasting Loss:0.3957 + XiCon Loss:2.4432 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.32421875e-08
	iters: 100, epoch: 14 | loss: 0.6017146
	speed: 0.0168s/iter; left time: 708.1871s
	iters: 200, epoch: 14 | loss: 0.5801357
	speed: 0.0157s/iter; left time: 660.2992s
	iters: 300, epoch: 14 | loss: 0.6296917
	speed: 0.0149s/iter; left time: 627.7758s
	iters: 400, epoch: 14 | loss: 0.6050459
	speed: 0.0152s/iter; left time: 639.6718s
Epoch: 14 cost time: 7.588134288787842
Epoch: 14, Steps: 487 Train Loss: 0.6398 (Forecasting Loss:0.3955 + XiCon Loss:2.4430 x Lambda(0.1)), Vali MSE Loss: 0.7388 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.662109375e-08
	iters: 100, epoch: 15 | loss: 0.6411564
	speed: 0.0165s/iter; left time: 688.6024s
	iters: 200, epoch: 15 | loss: 0.6148456
	speed: 0.0154s/iter; left time: 640.4915s
	iters: 300, epoch: 15 | loss: 0.6444375
	speed: 0.0156s/iter; left time: 648.1381s
	iters: 400, epoch: 15 | loss: 0.6961782
	speed: 0.0147s/iter; left time: 608.9298s
Epoch: 15 cost time: 7.66666841506958
Epoch: 15, Steps: 487 Train Loss: 0.6402 (Forecasting Loss:0.3958 + XiCon Loss:2.4446 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.8310546875e-08
	iters: 100, epoch: 16 | loss: 0.6638116
	speed: 0.0170s/iter; left time: 702.5318s
	iters: 200, epoch: 16 | loss: 0.6136954
	speed: 0.0157s/iter; left time: 648.0063s
	iters: 300, epoch: 16 | loss: 0.6967992
	speed: 0.0149s/iter; left time: 610.4515s
	iters: 400, epoch: 16 | loss: 0.6442463
	speed: 0.0145s/iter; left time: 594.5408s
Epoch: 16 cost time: 7.568292140960693
Epoch: 16, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3958 + XiCon Loss:2.4388 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.1552734375e-09
	iters: 100, epoch: 17 | loss: 0.5610129
	speed: 0.0171s/iter; left time: 696.2174s
	iters: 200, epoch: 17 | loss: 0.6170658
	speed: 0.0156s/iter; left time: 635.7465s
	iters: 300, epoch: 17 | loss: 0.5927286
	speed: 0.0152s/iter; left time: 617.3298s
	iters: 400, epoch: 17 | loss: 0.5513548
	speed: 0.0145s/iter; left time: 587.1498s
Epoch: 17 cost time: 7.610142946243286
Epoch: 17, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3957 + XiCon Loss:2.4388 x Lambda(0.1)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5132
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.57763671875e-09
	iters: 100, epoch: 18 | loss: 0.6484901
	speed: 0.0161s/iter; left time: 651.1188s
	iters: 200, epoch: 18 | loss: 0.6294391
	speed: 0.0158s/iter; left time: 636.3178s
	iters: 300, epoch: 18 | loss: 0.6564407
	speed: 0.0144s/iter; left time: 577.7163s
	iters: 400, epoch: 18 | loss: 0.5548127
	speed: 0.0150s/iter; left time: 599.1064s
Epoch: 18 cost time: 7.493900537490845
Epoch: 18, Steps: 487 Train Loss: 0.6399 (Forecasting Loss:0.3957 + XiCon Loss:2.4413 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.288818359375e-09
	iters: 100, epoch: 19 | loss: 0.6644775
	speed: 0.0160s/iter; left time: 637.3235s
	iters: 200, epoch: 19 | loss: 0.6857013
	speed: 0.0140s/iter; left time: 557.9425s
	iters: 300, epoch: 19 | loss: 0.5769544
	speed: 0.0125s/iter; left time: 495.8424s
	iters: 400, epoch: 19 | loss: 0.7147326
	speed: 0.0134s/iter; left time: 528.9111s
Epoch: 19 cost time: 6.619766712188721
Epoch: 19, Steps: 487 Train Loss: 0.6395 (Forecasting Loss:0.3956 + XiCon Loss:2.4394 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1444091796875e-09
	iters: 100, epoch: 20 | loss: 0.6281449
	speed: 0.0180s/iter; left time: 709.9798s
	iters: 200, epoch: 20 | loss: 0.5734440
	speed: 0.0140s/iter; left time: 548.0176s
	iters: 300, epoch: 20 | loss: 0.7745953
	speed: 0.0146s/iter; left time: 570.4016s
	iters: 400, epoch: 20 | loss: 0.6616074
	speed: 0.0146s/iter; left time: 569.7072s
Epoch: 20 cost time: 7.4692840576171875
Epoch: 20, Steps: 487 Train Loss: 0.6398 (Forecasting Loss:0.3956 + XiCon Loss:2.4420 x Lambda(0.1)), Vali MSE Loss: 0.7380 Test MSE Loss: 0.5132
Validation loss decreased (0.738252 --> 0.737951).  Saving model ...
Updating learning rate to 5.7220458984375e-10
	iters: 100, epoch: 21 | loss: 0.6616192
	speed: 0.0176s/iter; left time: 684.0252s
	iters: 200, epoch: 21 | loss: 0.5828850
	speed: 0.0150s/iter; left time: 579.8950s
	iters: 300, epoch: 21 | loss: 0.5769235
	speed: 0.0149s/iter; left time: 574.7150s
	iters: 400, epoch: 21 | loss: 0.6312570
	speed: 0.0153s/iter; left time: 589.7050s
Epoch: 21 cost time: 7.870484113693237
Epoch: 21, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3956 + XiCon Loss:2.4403 x Lambda(0.1)), Vali MSE Loss: 0.7388 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.86102294921875e-10
	iters: 100, epoch: 22 | loss: 0.6446228
	speed: 0.0179s/iter; left time: 685.8522s
	iters: 200, epoch: 22 | loss: 0.6176559
	speed: 0.0146s/iter; left time: 558.3414s
	iters: 300, epoch: 22 | loss: 0.6115751
	speed: 0.0148s/iter; left time: 566.1635s
	iters: 400, epoch: 22 | loss: 0.6305668
	speed: 0.0148s/iter; left time: 562.6443s
Epoch: 22 cost time: 7.569043397903442
Epoch: 22, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3958 + XiCon Loss:2.4384 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.430511474609375e-10
	iters: 100, epoch: 23 | loss: 0.6467692
	speed: 0.0170s/iter; left time: 645.7850s
	iters: 200, epoch: 23 | loss: 0.6932860
	speed: 0.0159s/iter; left time: 600.2802s
	iters: 300, epoch: 23 | loss: 0.6754844
	speed: 0.0143s/iter; left time: 540.6898s
	iters: 400, epoch: 23 | loss: 0.6781814
	speed: 0.0147s/iter; left time: 553.8090s
Epoch: 23 cost time: 7.507266521453857
Epoch: 23, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3958 + XiCon Loss:2.4390 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.152557373046874e-11
	iters: 100, epoch: 24 | loss: 0.6701394
	speed: 0.0165s/iter; left time: 617.6592s
	iters: 200, epoch: 24 | loss: 0.6691820
	speed: 0.0147s/iter; left time: 548.0112s
	iters: 300, epoch: 24 | loss: 0.6365262
	speed: 0.0150s/iter; left time: 556.7133s
	iters: 400, epoch: 24 | loss: 0.6116958
	speed: 0.0149s/iter; left time: 554.6314s
Epoch: 24 cost time: 7.423072576522827
Epoch: 24, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3959 + XiCon Loss:2.4378 x Lambda(0.1)), Vali MSE Loss: 0.7378 Test MSE Loss: 0.5132
Validation loss decreased (0.737951 --> 0.737847).  Saving model ...
Updating learning rate to 3.576278686523437e-11
	iters: 100, epoch: 25 | loss: 0.6818257
	speed: 0.0178s/iter; left time: 658.7662s
	iters: 200, epoch: 25 | loss: 0.6694149
	speed: 0.0152s/iter; left time: 560.6668s
	iters: 300, epoch: 25 | loss: 0.6476555
	speed: 0.0148s/iter; left time: 543.0417s
	iters: 400, epoch: 25 | loss: 0.6915676
	speed: 0.0160s/iter; left time: 586.2997s
Epoch: 25 cost time: 7.656398773193359
Epoch: 25, Steps: 487 Train Loss: 0.6402 (Forecasting Loss:0.3958 + XiCon Loss:2.4432 x Lambda(0.1)), Vali MSE Loss: 0.7381 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.7881393432617186e-11
	iters: 100, epoch: 26 | loss: 0.7199430
	speed: 0.0185s/iter; left time: 673.4869s
	iters: 200, epoch: 26 | loss: 0.6605310
	speed: 0.0152s/iter; left time: 552.0885s
	iters: 300, epoch: 26 | loss: 0.5846488
	speed: 0.0147s/iter; left time: 533.4096s
	iters: 400, epoch: 26 | loss: 0.6219912
	speed: 0.0163s/iter; left time: 588.7971s
Epoch: 26 cost time: 7.7923784255981445
Epoch: 26, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3955 + XiCon Loss:2.4400 x Lambda(0.1)), Vali MSE Loss: 0.7387 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.940696716308593e-12
	iters: 100, epoch: 27 | loss: 0.6803445
	speed: 0.0172s/iter; left time: 618.6674s
	iters: 200, epoch: 27 | loss: 0.7958857
	speed: 0.0147s/iter; left time: 527.4543s
	iters: 300, epoch: 27 | loss: 0.6230667
	speed: 0.0144s/iter; left time: 514.3154s
	iters: 400, epoch: 27 | loss: 0.5746360
	speed: 0.0162s/iter; left time: 577.8993s
Epoch: 27 cost time: 7.644764184951782
Epoch: 27, Steps: 487 Train Loss: 0.6398 (Forecasting Loss:0.3957 + XiCon Loss:2.4404 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.4703483581542965e-12
	iters: 100, epoch: 28 | loss: 0.5656362
	speed: 0.0179s/iter; left time: 634.6416s
	iters: 200, epoch: 28 | loss: 0.5902145
	speed: 0.0154s/iter; left time: 544.7242s
	iters: 300, epoch: 28 | loss: 0.6711880
	speed: 0.0148s/iter; left time: 523.1074s
	iters: 400, epoch: 28 | loss: 0.6688946
	speed: 0.0158s/iter; left time: 556.4594s
Epoch: 28 cost time: 7.7285871505737305
Epoch: 28, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3957 + XiCon Loss:2.4391 x Lambda(0.1)), Vali MSE Loss: 0.7381 Test MSE Loss: 0.5132
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2351741790771482e-12
	iters: 100, epoch: 29 | loss: 0.5990277
	speed: 0.0176s/iter; left time: 615.8540s
	iters: 200, epoch: 29 | loss: 0.6178501
	speed: 0.0143s/iter; left time: 499.2319s
	iters: 300, epoch: 29 | loss: 0.6670699
	speed: 0.0148s/iter; left time: 513.2267s
	iters: 400, epoch: 29 | loss: 0.6104449
	speed: 0.0154s/iter; left time: 535.5693s
Epoch: 29 cost time: 7.601816654205322
Epoch: 29, Steps: 487 Train Loss: 0.6398 (Forecasting Loss:0.3957 + XiCon Loss:2.4413 x Lambda(0.1)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5132
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1175870895385741e-12
	iters: 100, epoch: 30 | loss: 0.6122053
	speed: 0.0173s/iter; left time: 597.1555s
	iters: 200, epoch: 30 | loss: 0.6121433
	speed: 0.0154s/iter; left time: 528.0020s
	iters: 300, epoch: 30 | loss: 0.5553563
	speed: 0.0143s/iter; left time: 490.7955s
	iters: 400, epoch: 30 | loss: 0.6053551
	speed: 0.0151s/iter; left time: 517.0071s
Epoch: 30 cost time: 7.510817289352417
Epoch: 30, Steps: 487 Train Loss: 0.6399 (Forecasting Loss:0.3955 + XiCon Loss:2.4443 x Lambda(0.1)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5132
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.587935447692871e-13
	iters: 100, epoch: 31 | loss: 0.6231486
	speed: 0.0181s/iter; left time: 615.8737s
	iters: 200, epoch: 31 | loss: 0.6317965
	speed: 0.0143s/iter; left time: 484.5620s
	iters: 300, epoch: 31 | loss: 0.5394424
	speed: 0.0143s/iter; left time: 482.1894s
	iters: 400, epoch: 31 | loss: 0.5997554
	speed: 0.0146s/iter; left time: 492.7812s
Epoch: 31 cost time: 7.403850555419922
Epoch: 31, Steps: 487 Train Loss: 0.6400 (Forecasting Loss:0.3956 + XiCon Loss:2.4440 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7939677238464353e-13
	iters: 100, epoch: 32 | loss: 0.6355599
	speed: 0.0169s/iter; left time: 565.5779s
	iters: 200, epoch: 32 | loss: 0.6709970
	speed: 0.0172s/iter; left time: 572.9282s
	iters: 300, epoch: 32 | loss: 0.5883150
	speed: 0.0149s/iter; left time: 497.6150s
	iters: 400, epoch: 32 | loss: 0.6763121
	speed: 0.0148s/iter; left time: 492.8435s
Epoch: 32 cost time: 7.805782318115234
Epoch: 32, Steps: 487 Train Loss: 0.6402 (Forecasting Loss:0.3956 + XiCon Loss:2.4457 x Lambda(0.1)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5132
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3969838619232177e-13
	iters: 100, epoch: 33 | loss: 0.6289577
	speed: 0.0167s/iter; left time: 551.9316s
	iters: 200, epoch: 33 | loss: 0.6937773
	speed: 0.0132s/iter; left time: 435.4268s
	iters: 300, epoch: 33 | loss: 0.5949855
	speed: 0.0137s/iter; left time: 448.5269s
	iters: 400, epoch: 33 | loss: 0.6931128
	speed: 0.0137s/iter; left time: 449.5020s
Epoch: 33 cost time: 6.991523265838623
Epoch: 33, Steps: 487 Train Loss: 0.6397 (Forecasting Loss:0.3957 + XiCon Loss:2.4399 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.984919309616088e-14
	iters: 100, epoch: 34 | loss: 0.6305049
	speed: 0.0158s/iter; left time: 515.5460s
	iters: 200, epoch: 34 | loss: 0.6881279
	speed: 0.0137s/iter; left time: 444.1325s
	iters: 300, epoch: 34 | loss: 0.6561126
	speed: 0.0135s/iter; left time: 438.0032s
	iters: 400, epoch: 34 | loss: 0.6416197
	speed: 0.0143s/iter; left time: 460.0463s
Epoch: 34 cost time: 6.978156089782715
Epoch: 34, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3955 + XiCon Loss:2.4415 x Lambda(0.1)), Vali MSE Loss: 0.7375 Test MSE Loss: 0.5132
Validation loss decreased (0.737847 --> 0.737530).  Saving model ...
Updating learning rate to 3.492459654808044e-14
	iters: 100, epoch: 35 | loss: 0.6229351
	speed: 0.0154s/iter; left time: 493.7247s
	iters: 200, epoch: 35 | loss: 0.6040444
	speed: 0.0134s/iter; left time: 427.3115s
	iters: 300, epoch: 35 | loss: 0.6804110
	speed: 0.0137s/iter; left time: 436.2279s
	iters: 400, epoch: 35 | loss: 0.5857643
	speed: 0.0134s/iter; left time: 426.4371s
Epoch: 35 cost time: 6.8112473487854
Epoch: 35, Steps: 487 Train Loss: 0.6403 (Forecasting Loss:0.3956 + XiCon Loss:2.4463 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.746229827404022e-14
	iters: 100, epoch: 36 | loss: 0.7144395
	speed: 0.0157s/iter; left time: 496.2812s
	iters: 200, epoch: 36 | loss: 0.5685620
	speed: 0.0137s/iter; left time: 430.6371s
	iters: 300, epoch: 36 | loss: 0.5834423
	speed: 0.0134s/iter; left time: 421.7037s
	iters: 400, epoch: 36 | loss: 0.6337016
	speed: 0.0146s/iter; left time: 456.1129s
Epoch: 36 cost time: 7.107926607131958
Epoch: 36, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3955 + XiCon Loss:2.4412 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 2 out of 10
Updating learning rate to 8.73114913702011e-15
	iters: 100, epoch: 37 | loss: 0.6909227
	speed: 0.0153s/iter; left time: 474.3089s
	iters: 200, epoch: 37 | loss: 0.6241558
	speed: 0.0134s/iter; left time: 415.0764s
	iters: 300, epoch: 37 | loss: 0.6124872
	speed: 0.0135s/iter; left time: 415.6483s
	iters: 400, epoch: 37 | loss: 0.7286891
	speed: 0.0138s/iter; left time: 424.4142s
Epoch: 37 cost time: 6.798771858215332
Epoch: 37, Steps: 487 Train Loss: 0.6399 (Forecasting Loss:0.3957 + XiCon Loss:2.4422 x Lambda(0.1)), Vali MSE Loss: 0.7387 Test MSE Loss: 0.5132
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.365574568510055e-15
	iters: 100, epoch: 38 | loss: 0.6080315
	speed: 0.0159s/iter; left time: 485.8435s
	iters: 200, epoch: 38 | loss: 0.6540048
	speed: 0.0135s/iter; left time: 412.4914s
	iters: 300, epoch: 38 | loss: 0.6251613
	speed: 0.0137s/iter; left time: 414.9886s
	iters: 400, epoch: 38 | loss: 0.6807695
	speed: 0.0144s/iter; left time: 435.7457s
Epoch: 38 cost time: 6.945652008056641
Epoch: 38, Steps: 487 Train Loss: 0.6402 (Forecasting Loss:0.3956 + XiCon Loss:2.4458 x Lambda(0.1)), Vali MSE Loss: 0.7387 Test MSE Loss: 0.5132
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.1827872842550276e-15
	iters: 100, epoch: 39 | loss: 0.7085989
	speed: 0.0154s/iter; left time: 464.1847s
	iters: 200, epoch: 39 | loss: 0.5889428
	speed: 0.0140s/iter; left time: 420.0756s
	iters: 300, epoch: 39 | loss: 0.6944714
	speed: 0.0129s/iter; left time: 384.7131s
	iters: 400, epoch: 39 | loss: 0.6378882
	speed: 0.0134s/iter; left time: 400.6170s
Epoch: 39 cost time: 6.801332712173462
Epoch: 39, Steps: 487 Train Loss: 0.6400 (Forecasting Loss:0.3957 + XiCon Loss:2.4429 x Lambda(0.1)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5132
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.0913936421275138e-15
	iters: 100, epoch: 40 | loss: 0.7112027
	speed: 0.0165s/iter; left time: 487.3905s
	iters: 200, epoch: 40 | loss: 0.6578704
	speed: 0.0154s/iter; left time: 454.2052s
	iters: 300, epoch: 40 | loss: 0.6329905
	speed: 0.0169s/iter; left time: 497.1496s
	iters: 400, epoch: 40 | loss: 0.6934447
	speed: 0.0145s/iter; left time: 423.8077s
Epoch: 40 cost time: 7.645487308502197
Epoch: 40, Steps: 487 Train Loss: 0.6398 (Forecasting Loss:0.3959 + XiCon Loss:2.4392 x Lambda(0.1)), Vali MSE Loss: 0.7384 Test MSE Loss: 0.5132
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.456968210637569e-16
	iters: 100, epoch: 41 | loss: 0.6233339
	speed: 0.0171s/iter; left time: 499.2632s
	iters: 200, epoch: 41 | loss: 0.6122776
	speed: 0.0139s/iter; left time: 404.6520s
	iters: 300, epoch: 41 | loss: 0.6707106
	speed: 0.0143s/iter; left time: 412.1958s
	iters: 400, epoch: 41 | loss: 0.6362965
	speed: 0.0152s/iter; left time: 438.7406s
Epoch: 41 cost time: 7.348833322525024
Epoch: 41, Steps: 487 Train Loss: 0.6396 (Forecasting Loss:0.3957 + XiCon Loss:2.4396 x Lambda(0.1)), Vali MSE Loss: 0.7383 Test MSE Loss: 0.5132
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.7284841053187845e-16
	iters: 100, epoch: 42 | loss: 0.5822900
	speed: 0.0172s/iter; left time: 493.3396s
	iters: 200, epoch: 42 | loss: 0.5953749
	speed: 0.0154s/iter; left time: 439.0925s
	iters: 300, epoch: 42 | loss: 0.6715204
	speed: 0.0149s/iter; left time: 422.7286s
	iters: 400, epoch: 42 | loss: 0.7193711
	speed: 0.0147s/iter; left time: 417.6099s
Epoch: 42 cost time: 7.523226261138916
Epoch: 42, Steps: 487 Train Loss: 0.6399 (Forecasting Loss:0.3957 + XiCon Loss:2.4423 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.3642420526593922e-16
	iters: 100, epoch: 43 | loss: 0.6091059
	speed: 0.0169s/iter; left time: 476.7665s
	iters: 200, epoch: 43 | loss: 0.7029588
	speed: 0.0156s/iter; left time: 437.8915s
	iters: 300, epoch: 43 | loss: 0.6371309
	speed: 0.0147s/iter; left time: 411.2820s
	iters: 400, epoch: 43 | loss: 0.6583397
	speed: 0.0146s/iter; left time: 405.4450s
Epoch: 43 cost time: 7.524911165237427
Epoch: 43, Steps: 487 Train Loss: 0.6406 (Forecasting Loss:0.3958 + XiCon Loss:2.4475 x Lambda(0.1)), Vali MSE Loss: 0.7386 Test MSE Loss: 0.5132
EarlyStopping counter: 9 out of 10
Updating learning rate to 6.821210263296961e-17
	iters: 100, epoch: 44 | loss: 0.6380388
	speed: 0.0165s/iter; left time: 457.5397s
	iters: 200, epoch: 44 | loss: 0.6886173
	speed: 0.0138s/iter; left time: 380.2826s
	iters: 300, epoch: 44 | loss: 0.7448344
	speed: 0.0160s/iter; left time: 440.2040s
	iters: 400, epoch: 44 | loss: 0.6924086
	speed: 0.0148s/iter; left time: 404.6249s
Epoch: 44 cost time: 7.44266939163208
Epoch: 44, Steps: 487 Train Loss: 0.6398 (Forecasting Loss:0.3956 + XiCon Loss:2.4417 x Lambda(0.1)), Vali MSE Loss: 0.7385 Test MSE Loss: 0.5132
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl96_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 10444
test shape: (163, 64, 96, 1) (163, 64, 96, 1)
test shape: (10432, 96, 1) (10432, 96, 1)
mse:0.5202363729476929, mae:0.506108283996582, mape:3.4682347774505615, mspe:1085.6961669921875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.5197+-0.00867, MAE:0.5065+-0.00505, MAPE:3.5045+-0.05476, MSPE:1128.2161+-49.63241, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=720, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=4, n_heads=8, e_layers=1, d_layers=1, d_ff=4, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.05, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.9661
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.1951497
	speed: 0.0322s/iter; left time: 762.3591s
	iters: 200, epoch: 1 | loss: 1.2123905
	speed: 0.0269s/iter; left time: 634.1904s
Epoch: 1 cost time: 6.995362043380737
Epoch: 1, Steps: 238 Train Loss: 1.2389 (Forecasting Loss:0.9803 + XiCon Loss:2.5861 x Lambda(0.1)), Vali MSE Loss: 1.7554 Test MSE Loss: 0.9668
Validation loss decreased (inf --> 1.755402).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8641312
	speed: 0.0316s/iter; left time: 740.7987s
	iters: 200, epoch: 2 | loss: 0.8433481
	speed: 0.0299s/iter; left time: 698.3371s
Epoch: 2 cost time: 7.290333032608032
Epoch: 2, Steps: 238 Train Loss: 0.8750 (Forecasting Loss:0.6170 + XiCon Loss:2.5801 x Lambda(0.1)), Vali MSE Loss: 1.0370 Test MSE Loss: 0.8578
Validation loss decreased (1.755402 --> 1.036970).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8171476
	speed: 0.0331s/iter; left time: 768.4978s
	iters: 200, epoch: 3 | loss: 0.8247418
	speed: 0.0292s/iter; left time: 676.1483s
Epoch: 3 cost time: 7.489511251449585
Epoch: 3, Steps: 238 Train Loss: 0.8104 (Forecasting Loss:0.5527 + XiCon Loss:2.5763 x Lambda(0.1)), Vali MSE Loss: 1.0181 Test MSE Loss: 0.8512
Validation loss decreased (1.036970 --> 1.018051).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7892025
	speed: 0.0278s/iter; left time: 640.1254s
	iters: 200, epoch: 4 | loss: 0.7607497
	speed: 0.0238s/iter; left time: 544.6925s
Epoch: 4 cost time: 6.102465391159058
Epoch: 4, Steps: 238 Train Loss: 0.8016 (Forecasting Loss:0.5446 + XiCon Loss:2.5696 x Lambda(0.1)), Vali MSE Loss: 1.0107 Test MSE Loss: 0.8491
Validation loss decreased (1.018051 --> 1.010661).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7816517
	speed: 0.0276s/iter; left time: 627.8916s
	iters: 200, epoch: 5 | loss: 0.8214524
	speed: 0.0262s/iter; left time: 593.3681s
Epoch: 5 cost time: 6.431457757949829
Epoch: 5, Steps: 238 Train Loss: 0.7984 (Forecasting Loss:0.5414 + XiCon Loss:2.5701 x Lambda(0.1)), Vali MSE Loss: 1.0077 Test MSE Loss: 0.8488
Validation loss decreased (1.010661 --> 1.007654).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7893913
	speed: 0.0296s/iter; left time: 665.7134s
	iters: 200, epoch: 6 | loss: 0.7959208
	speed: 0.0259s/iter; left time: 580.4565s
Epoch: 6 cost time: 6.617818832397461
Epoch: 6, Steps: 238 Train Loss: 0.7965 (Forecasting Loss:0.5400 + XiCon Loss:2.5655 x Lambda(0.1)), Vali MSE Loss: 1.0063 Test MSE Loss: 0.8485
Validation loss decreased (1.007654 --> 1.006340).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7851579
	speed: 0.0283s/iter; left time: 631.2294s
	iters: 200, epoch: 7 | loss: 0.8001525
	speed: 0.0258s/iter; left time: 572.7968s
Epoch: 7 cost time: 6.459777116775513
Epoch: 7, Steps: 238 Train Loss: 0.7961 (Forecasting Loss:0.5391 + XiCon Loss:2.5699 x Lambda(0.1)), Vali MSE Loss: 1.0047 Test MSE Loss: 0.8484
Validation loss decreased (1.006340 --> 1.004654).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7511884
	speed: 0.0283s/iter; left time: 623.4983s
	iters: 200, epoch: 8 | loss: 0.8192241
	speed: 0.0264s/iter; left time: 578.8886s
Epoch: 8 cost time: 6.4755589962005615
Epoch: 8, Steps: 238 Train Loss: 0.7951 (Forecasting Loss:0.5387 + XiCon Loss:2.5645 x Lambda(0.1)), Vali MSE Loss: 1.0046 Test MSE Loss: 0.8484
Validation loss decreased (1.004654 --> 1.004588).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8297967
	speed: 0.0276s/iter; left time: 601.9381s
	iters: 200, epoch: 9 | loss: 0.8373777
	speed: 0.0277s/iter; left time: 601.9310s
Epoch: 9 cost time: 6.4564735889434814
Epoch: 9, Steps: 238 Train Loss: 0.7956 (Forecasting Loss:0.5386 + XiCon Loss:2.5691 x Lambda(0.1)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7882658
	speed: 0.0283s/iter; left time: 609.6061s
	iters: 200, epoch: 10 | loss: 0.8137341
	speed: 0.0278s/iter; left time: 596.4283s
Epoch: 10 cost time: 6.648828983306885
Epoch: 10, Steps: 238 Train Loss: 0.7956 (Forecasting Loss:0.5385 + XiCon Loss:2.5715 x Lambda(0.1)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8483
Validation loss decreased (1.004588 --> 1.004537).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.7557136
	speed: 0.0279s/iter; left time: 595.8541s
	iters: 200, epoch: 11 | loss: 0.8161269
	speed: 0.0270s/iter; left time: 572.1013s
Epoch: 11 cost time: 6.46769905090332
Epoch: 11, Steps: 238 Train Loss: 0.7948 (Forecasting Loss:0.5382 + XiCon Loss:2.5661 x Lambda(0.1)), Vali MSE Loss: 1.0038 Test MSE Loss: 0.8483
Validation loss decreased (1.004537 --> 1.003754).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8126105
	speed: 0.0289s/iter; left time: 609.8827s
	iters: 200, epoch: 12 | loss: 0.7637058
	speed: 0.0266s/iter; left time: 557.4979s
Epoch: 12 cost time: 6.570499420166016
Epoch: 12, Steps: 238 Train Loss: 0.7950 (Forecasting Loss:0.5382 + XiCon Loss:2.5680 x Lambda(0.1)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.7995274
	speed: 0.0284s/iter; left time: 592.7554s
	iters: 200, epoch: 13 | loss: 0.7881963
	speed: 0.0283s/iter; left time: 588.1049s
Epoch: 13 cost time: 6.6535420417785645
Epoch: 13, Steps: 238 Train Loss: 0.7951 (Forecasting Loss:0.5383 + XiCon Loss:2.5676 x Lambda(0.1)), Vali MSE Loss: 1.0053 Test MSE Loss: 0.8483
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.7101691
	speed: 0.0277s/iter; left time: 571.5454s
	iters: 200, epoch: 14 | loss: 0.7953254
	speed: 0.0237s/iter; left time: 486.7500s
Epoch: 14 cost time: 6.102772235870361
Epoch: 14, Steps: 238 Train Loss: 0.7946 (Forecasting Loss:0.5382 + XiCon Loss:2.5644 x Lambda(0.1)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8483
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.7959381
	speed: 0.0285s/iter; left time: 579.8934s
	iters: 200, epoch: 15 | loss: 0.7912291
	speed: 0.0258s/iter; left time: 521.9325s
Epoch: 15 cost time: 6.484126329421997
Epoch: 15, Steps: 238 Train Loss: 0.7943 (Forecasting Loss:0.5382 + XiCon Loss:2.5613 x Lambda(0.1)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.7620847
	speed: 0.0296s/iter; left time: 595.7703s
	iters: 200, epoch: 16 | loss: 0.7898450
	speed: 0.0270s/iter; left time: 540.6591s
Epoch: 16 cost time: 6.723396301269531
Epoch: 16, Steps: 238 Train Loss: 0.7949 (Forecasting Loss:0.5385 + XiCon Loss:2.5636 x Lambda(0.1)), Vali MSE Loss: 1.0045 Test MSE Loss: 0.8483
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.7857102
	speed: 0.0286s/iter; left time: 569.6720s
	iters: 200, epoch: 17 | loss: 0.7881622
	speed: 0.0260s/iter; left time: 514.5802s
Epoch: 17 cost time: 6.397814512252808
Epoch: 17, Steps: 238 Train Loss: 0.7952 (Forecasting Loss:0.5380 + XiCon Loss:2.5717 x Lambda(0.1)), Vali MSE Loss: 1.0052 Test MSE Loss: 0.8483
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.7573244
	speed: 0.0274s/iter; left time: 538.4081s
	iters: 200, epoch: 18 | loss: 0.7300758
	speed: 0.0248s/iter; left time: 483.9888s
Epoch: 18 cost time: 6.254980802536011
Epoch: 18, Steps: 238 Train Loss: 0.7948 (Forecasting Loss:0.5382 + XiCon Loss:2.5657 x Lambda(0.1)), Vali MSE Loss: 1.0050 Test MSE Loss: 0.8483
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8010367
	speed: 0.0281s/iter; left time: 546.4513s
	iters: 200, epoch: 19 | loss: 0.7927405
	speed: 0.0263s/iter; left time: 508.0743s
Epoch: 19 cost time: 6.373603343963623
Epoch: 19, Steps: 238 Train Loss: 0.7949 (Forecasting Loss:0.5384 + XiCon Loss:2.5655 x Lambda(0.1)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.7732332
	speed: 0.0275s/iter; left time: 526.8431s
	iters: 200, epoch: 20 | loss: 0.8040337
	speed: 0.0256s/iter; left time: 488.0862s
Epoch: 20 cost time: 6.34520959854126
Epoch: 20, Steps: 238 Train Loss: 0.7952 (Forecasting Loss:0.5381 + XiCon Loss:2.5706 x Lambda(0.1)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.7539915
	speed: 0.0276s/iter; left time: 522.9287s
	iters: 200, epoch: 21 | loss: 0.8038673
	speed: 0.0257s/iter; left time: 484.5954s
Epoch: 21 cost time: 6.389797210693359
Epoch: 21, Steps: 238 Train Loss: 0.7952 (Forecasting Loss:0.5384 + XiCon Loss:2.5676 x Lambda(0.1)), Vali MSE Loss: 1.0049 Test MSE Loss: 0.8483
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9774503111839294, mae:0.7191919684410095, mape:4.776634216308594, mspe:2687.556396484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.0304
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.3361694
	speed: 0.0300s/iter; left time: 710.0816s
	iters: 200, epoch: 1 | loss: 1.4126679
	speed: 0.0268s/iter; left time: 631.3647s
Epoch: 1 cost time: 6.667604923248291
Epoch: 1, Steps: 238 Train Loss: 1.3570 (Forecasting Loss:1.0993 + XiCon Loss:2.5767 x Lambda(0.1)), Vali MSE Loss: 1.9679 Test MSE Loss: 1.0362
Validation loss decreased (inf --> 1.967903).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8828408
	speed: 0.0283s/iter; left time: 664.7068s
	iters: 200, epoch: 2 | loss: 0.7958674
	speed: 0.0262s/iter; left time: 612.2278s
Epoch: 2 cost time: 6.491455078125
Epoch: 2, Steps: 238 Train Loss: 0.8883 (Forecasting Loss:0.6316 + XiCon Loss:2.5668 x Lambda(0.1)), Vali MSE Loss: 1.0212 Test MSE Loss: 0.8590
Validation loss decreased (1.967903 --> 1.021230).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8000363
	speed: 0.0256s/iter; left time: 594.2187s
	iters: 200, epoch: 3 | loss: 0.7825907
	speed: 0.0238s/iter; left time: 549.6098s
Epoch: 3 cost time: 5.897806406021118
Epoch: 3, Steps: 238 Train Loss: 0.8073 (Forecasting Loss:0.5515 + XiCon Loss:2.5583 x Lambda(0.1)), Vali MSE Loss: 0.9999 Test MSE Loss: 0.8533
Validation loss decreased (1.021230 --> 0.999892).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7345934
	speed: 0.0267s/iter; left time: 614.7157s
	iters: 200, epoch: 4 | loss: 0.8241317
	speed: 0.0239s/iter; left time: 546.6953s
Epoch: 4 cost time: 6.05853533744812
Epoch: 4, Steps: 238 Train Loss: 0.7987 (Forecasting Loss:0.5430 + XiCon Loss:2.5575 x Lambda(0.1)), Vali MSE Loss: 0.9935 Test MSE Loss: 0.8521
Validation loss decreased (0.999892 --> 0.993497).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8170897
	speed: 0.0263s/iter; left time: 599.4045s
	iters: 200, epoch: 5 | loss: 0.7789048
	speed: 0.0236s/iter; left time: 534.5534s
Epoch: 5 cost time: 5.9383087158203125
Epoch: 5, Steps: 238 Train Loss: 0.7949 (Forecasting Loss:0.5396 + XiCon Loss:2.5521 x Lambda(0.1)), Vali MSE Loss: 0.9884 Test MSE Loss: 0.8514
Validation loss decreased (0.993497 --> 0.988428).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7693009
	speed: 0.0264s/iter; left time: 593.4708s
	iters: 200, epoch: 6 | loss: 0.8105635
	speed: 0.0235s/iter; left time: 526.5984s
Epoch: 6 cost time: 5.92413592338562
Epoch: 6, Steps: 238 Train Loss: 0.7939 (Forecasting Loss:0.5384 + XiCon Loss:2.5547 x Lambda(0.1)), Vali MSE Loss: 0.9874 Test MSE Loss: 0.8514
Validation loss decreased (0.988428 --> 0.987422).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7956201
	speed: 0.0266s/iter; left time: 592.5700s
	iters: 200, epoch: 7 | loss: 0.7611441
	speed: 0.0236s/iter; left time: 523.5083s
Epoch: 7 cost time: 5.971855640411377
Epoch: 7, Steps: 238 Train Loss: 0.7925 (Forecasting Loss:0.5374 + XiCon Loss:2.5510 x Lambda(0.1)), Vali MSE Loss: 0.9865 Test MSE Loss: 0.8512
Validation loss decreased (0.987422 --> 0.986483).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8049043
	speed: 0.0258s/iter; left time: 568.0365s
	iters: 200, epoch: 8 | loss: 0.7575681
	speed: 0.0244s/iter; left time: 536.1137s
Epoch: 8 cost time: 5.959676504135132
Epoch: 8, Steps: 238 Train Loss: 0.7925 (Forecasting Loss:0.5373 + XiCon Loss:2.5514 x Lambda(0.1)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8512
Validation loss decreased (0.986483 --> 0.986417).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7810804
	speed: 0.0262s/iter; left time: 570.7601s
	iters: 200, epoch: 9 | loss: 0.8306646
	speed: 0.0241s/iter; left time: 523.2289s
Epoch: 9 cost time: 5.97725772857666
Epoch: 9, Steps: 238 Train Loss: 0.7922 (Forecasting Loss:0.5370 + XiCon Loss:2.5529 x Lambda(0.1)), Vali MSE Loss: 0.9854 Test MSE Loss: 0.8512
Validation loss decreased (0.986417 --> 0.985385).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7881476
	speed: 0.0254s/iter; left time: 548.4275s
	iters: 200, epoch: 10 | loss: 0.8606192
	speed: 0.0244s/iter; left time: 522.9540s
Epoch: 10 cost time: 5.970015048980713
Epoch: 10, Steps: 238 Train Loss: 0.7919 (Forecasting Loss:0.5368 + XiCon Loss:2.5511 x Lambda(0.1)), Vali MSE Loss: 0.9850 Test MSE Loss: 0.8511
Validation loss decreased (0.985385 --> 0.985008).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8006630
	speed: 0.0261s/iter; left time: 555.9563s
	iters: 200, epoch: 11 | loss: 0.8380553
	speed: 0.0238s/iter; left time: 504.4449s
Epoch: 11 cost time: 5.925187826156616
Epoch: 11, Steps: 238 Train Loss: 0.7918 (Forecasting Loss:0.5367 + XiCon Loss:2.5505 x Lambda(0.1)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8511
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8039176
	speed: 0.0258s/iter; left time: 543.7862s
	iters: 200, epoch: 12 | loss: 0.7527634
	speed: 0.0239s/iter; left time: 502.1219s
Epoch: 12 cost time: 5.897481918334961
Epoch: 12, Steps: 238 Train Loss: 0.7916 (Forecasting Loss:0.5366 + XiCon Loss:2.5495 x Lambda(0.1)), Vali MSE Loss: 0.9852 Test MSE Loss: 0.8511
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.7711569
	speed: 0.0258s/iter; left time: 538.1382s
	iters: 200, epoch: 13 | loss: 0.7877524
	speed: 0.0228s/iter; left time: 472.2169s
Epoch: 13 cost time: 5.772057771682739
Epoch: 13, Steps: 238 Train Loss: 0.7918 (Forecasting Loss:0.5365 + XiCon Loss:2.5536 x Lambda(0.1)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8511
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.7387276
	speed: 0.0262s/iter; left time: 540.8013s
	iters: 200, epoch: 14 | loss: 0.7760671
	speed: 0.0236s/iter; left time: 483.4882s
Epoch: 14 cost time: 5.898108720779419
Epoch: 14, Steps: 238 Train Loss: 0.7922 (Forecasting Loss:0.5366 + XiCon Loss:2.5560 x Lambda(0.1)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8511
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.7853778
	speed: 0.0273s/iter; left time: 555.9379s
	iters: 200, epoch: 15 | loss: 0.7238716
	speed: 0.0252s/iter; left time: 510.1247s
Epoch: 15 cost time: 6.258713006973267
Epoch: 15, Steps: 238 Train Loss: 0.7919 (Forecasting Loss:0.5365 + XiCon Loss:2.5541 x Lambda(0.1)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8511
EarlyStopping counter: 5 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8195417
	speed: 0.0560s/iter; left time: 1128.2260s
	iters: 200, epoch: 16 | loss: 0.8170902
	speed: 0.0822s/iter; left time: 1647.1132s
Epoch: 16 cost time: 16.817177295684814
Epoch: 16, Steps: 238 Train Loss: 0.7920 (Forecasting Loss:0.5367 + XiCon Loss:2.5539 x Lambda(0.1)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8511
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.7676646
	speed: 0.0919s/iter; left time: 1828.0703s
	iters: 200, epoch: 17 | loss: 0.8236767
	speed: 0.0876s/iter; left time: 1734.8162s
Epoch: 17 cost time: 21.221530437469482
Epoch: 17, Steps: 238 Train Loss: 0.7916 (Forecasting Loss:0.5368 + XiCon Loss:2.5478 x Lambda(0.1)), Vali MSE Loss: 0.9853 Test MSE Loss: 0.8511
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8069746
	speed: 0.0999s/iter; left time: 1962.6656s
	iters: 200, epoch: 18 | loss: 0.8986194
	speed: 0.0889s/iter; left time: 1737.6774s
Epoch: 18 cost time: 22.543500661849976
Epoch: 18, Steps: 238 Train Loss: 0.7919 (Forecasting Loss:0.5369 + XiCon Loss:2.5498 x Lambda(0.1)), Vali MSE Loss: 0.9851 Test MSE Loss: 0.8511
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.7895941
	speed: 0.0919s/iter; left time: 1784.6728s
	iters: 200, epoch: 19 | loss: 0.7884978
	speed: 0.0853s/iter; left time: 1646.8829s
Epoch: 19 cost time: 21.058974504470825
Epoch: 19, Steps: 238 Train Loss: 0.7922 (Forecasting Loss:0.5366 + XiCon Loss:2.5560 x Lambda(0.1)), Vali MSE Loss: 0.9853 Test MSE Loss: 0.8511
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8006401
	speed: 0.0890s/iter; left time: 1706.9812s
	iters: 200, epoch: 20 | loss: 0.8057921
	speed: 0.0796s/iter; left time: 1519.6325s
Epoch: 20 cost time: 19.84194326400757
Epoch: 20, Steps: 238 Train Loss: 0.7920 (Forecasting Loss:0.5367 + XiCon Loss:2.5523 x Lambda(0.1)), Vali MSE Loss: 0.9850 Test MSE Loss: 0.8511
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9806621074676514, mae:0.721598207950592, mape:4.7694292068481445, mspe:2670.94873046875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 25.8310
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.2380176
	speed: 0.0678s/iter; left time: 1607.6075s
	iters: 200, epoch: 1 | loss: 1.2226236
	speed: 0.0605s/iter; left time: 1428.5064s
Epoch: 1 cost time: 15.220041275024414
Epoch: 1, Steps: 238 Train Loss: 1.2590 (Forecasting Loss:1.0009 + XiCon Loss:2.5810 x Lambda(0.1)), Vali MSE Loss: 1.7925 Test MSE Loss: 0.9697
Validation loss decreased (inf --> 1.792500).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8714542
	speed: 0.0565s/iter; left time: 1325.5777s
	iters: 200, epoch: 2 | loss: 0.7923445
	speed: 0.0360s/iter; left time: 841.9325s
Epoch: 2 cost time: 10.530690670013428
Epoch: 2, Steps: 238 Train Loss: 0.8772 (Forecasting Loss:0.6190 + XiCon Loss:2.5821 x Lambda(0.1)), Vali MSE Loss: 1.0415 Test MSE Loss: 0.8611
Validation loss decreased (1.792500 --> 1.041515).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8347754
	speed: 0.0417s/iter; left time: 968.0895s
	iters: 200, epoch: 3 | loss: 0.8301568
	speed: 0.0372s/iter; left time: 860.1158s
Epoch: 3 cost time: 9.278934478759766
Epoch: 3, Steps: 238 Train Loss: 0.8089 (Forecasting Loss:0.5526 + XiCon Loss:2.5639 x Lambda(0.1)), Vali MSE Loss: 1.0194 Test MSE Loss: 0.8555
Validation loss decreased (1.041515 --> 1.019357).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8349082
	speed: 0.0315s/iter; left time: 723.4413s
	iters: 200, epoch: 4 | loss: 0.8214751
	speed: 0.0276s/iter; left time: 631.5148s
Epoch: 4 cost time: 7.0014636516571045
Epoch: 4, Steps: 238 Train Loss: 0.8010 (Forecasting Loss:0.5442 + XiCon Loss:2.5679 x Lambda(0.1)), Vali MSE Loss: 1.0134 Test MSE Loss: 0.8541
Validation loss decreased (1.019357 --> 1.013397).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7959628
	speed: 0.0315s/iter; left time: 715.9839s
	iters: 200, epoch: 5 | loss: 0.7655674
	speed: 0.0269s/iter; left time: 609.5176s
Epoch: 5 cost time: 6.8952317237854
Epoch: 5, Steps: 238 Train Loss: 0.7974 (Forecasting Loss:0.5406 + XiCon Loss:2.5676 x Lambda(0.1)), Vali MSE Loss: 1.0101 Test MSE Loss: 0.8536
Validation loss decreased (1.013397 --> 1.010056).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7857176
	speed: 0.0307s/iter; left time: 690.9288s
	iters: 200, epoch: 6 | loss: 0.7755597
	speed: 0.0259s/iter; left time: 581.4961s
Epoch: 6 cost time: 6.634761333465576
Epoch: 6, Steps: 238 Train Loss: 0.7955 (Forecasting Loss:0.5394 + XiCon Loss:2.5614 x Lambda(0.1)), Vali MSE Loss: 1.0086 Test MSE Loss: 0.8533
Validation loss decreased (1.010056 --> 1.008556).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8412932
	speed: 0.0286s/iter; left time: 636.4974s
	iters: 200, epoch: 7 | loss: 0.7857790
	speed: 0.0246s/iter; left time: 546.1310s
Epoch: 7 cost time: 6.278766870498657
Epoch: 7, Steps: 238 Train Loss: 0.7949 (Forecasting Loss:0.5385 + XiCon Loss:2.5634 x Lambda(0.1)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8532
Validation loss decreased (1.008556 --> 1.007518).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8335332
	speed: 0.0266s/iter; left time: 586.0108s
	iters: 200, epoch: 8 | loss: 0.7560001
	speed: 0.0228s/iter; left time: 500.3854s
Epoch: 8 cost time: 5.831881761550903
Epoch: 8, Steps: 238 Train Loss: 0.7949 (Forecasting Loss:0.5382 + XiCon Loss:2.5675 x Lambda(0.1)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8531
Validation loss decreased (1.007518 --> 1.007194).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7523214
	speed: 0.0259s/iter; left time: 564.5282s
	iters: 200, epoch: 9 | loss: 0.8277885
	speed: 0.0235s/iter; left time: 509.2827s
Epoch: 9 cost time: 5.870288372039795
Epoch: 9, Steps: 238 Train Loss: 0.7944 (Forecasting Loss:0.5378 + XiCon Loss:2.5657 x Lambda(0.1)), Vali MSE Loss: 1.0066 Test MSE Loss: 0.8531
Validation loss decreased (1.007194 --> 1.006603).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7846574
	speed: 0.0264s/iter; left time: 569.8591s
	iters: 200, epoch: 10 | loss: 0.8364314
	speed: 0.0226s/iter; left time: 485.3813s
Epoch: 10 cost time: 5.810161590576172
Epoch: 10, Steps: 238 Train Loss: 0.7942 (Forecasting Loss:0.5377 + XiCon Loss:2.5650 x Lambda(0.1)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8531
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.7767881
	speed: 0.0271s/iter; left time: 577.2720s
	iters: 200, epoch: 11 | loss: 0.8428138
	speed: 0.0220s/iter; left time: 466.1160s
Epoch: 11 cost time: 5.79676365852356
Epoch: 11, Steps: 238 Train Loss: 0.7943 (Forecasting Loss:0.5377 + XiCon Loss:2.5657 x Lambda(0.1)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8531
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.7880499
	speed: 0.0262s/iter; left time: 552.9982s
	iters: 200, epoch: 12 | loss: 0.7954016
	speed: 0.0224s/iter; left time: 469.9690s
Epoch: 12 cost time: 5.718832969665527
Epoch: 12, Steps: 238 Train Loss: 0.7940 (Forecasting Loss:0.5375 + XiCon Loss:2.5651 x Lambda(0.1)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8531
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.7853214
	speed: 0.0260s/iter; left time: 542.8204s
	iters: 200, epoch: 13 | loss: 0.7472749
	speed: 0.0221s/iter; left time: 457.8279s
Epoch: 13 cost time: 5.693962335586548
Epoch: 13, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5376 + XiCon Loss:2.5643 x Lambda(0.1)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8531
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8214732
	speed: 0.0253s/iter; left time: 521.1748s
	iters: 200, epoch: 14 | loss: 0.8156101
	speed: 0.0218s/iter; left time: 446.8945s
Epoch: 14 cost time: 5.542719125747681
Epoch: 14, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5377 + XiCon Loss:2.5635 x Lambda(0.1)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8531
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8415711
	speed: 0.0251s/iter; left time: 511.4175s
	iters: 200, epoch: 15 | loss: 0.8123871
	speed: 0.0213s/iter; left time: 432.7174s
Epoch: 15 cost time: 5.4709391593933105
Epoch: 15, Steps: 238 Train Loss: 0.7942 (Forecasting Loss:0.5378 + XiCon Loss:2.5638 x Lambda(0.1)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8531
EarlyStopping counter: 6 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.7895029
	speed: 0.0248s/iter; left time: 499.3681s
	iters: 200, epoch: 16 | loss: 0.7283064
	speed: 0.0216s/iter; left time: 433.4125s
Epoch: 16 cost time: 5.508247375488281
Epoch: 16, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5377 + XiCon Loss:2.5644 x Lambda(0.1)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8531
EarlyStopping counter: 7 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8529375
	speed: 0.0248s/iter; left time: 493.2262s
	iters: 200, epoch: 17 | loss: 0.7645186
	speed: 0.0207s/iter; left time: 410.1790s
Epoch: 17 cost time: 5.376140117645264
Epoch: 17, Steps: 238 Train Loss: 0.7940 (Forecasting Loss:0.5377 + XiCon Loss:2.5631 x Lambda(0.1)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8531
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.7771133
	speed: 0.0258s/iter; left time: 506.6382s
	iters: 200, epoch: 18 | loss: 0.7695367
	speed: 0.0210s/iter; left time: 410.8680s
Epoch: 18 cost time: 5.490798711776733
Epoch: 18, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5376 + XiCon Loss:2.5655 x Lambda(0.1)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8531
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.7788867
	speed: 0.0247s/iter; left time: 479.4603s
	iters: 200, epoch: 19 | loss: 0.7923169
	speed: 0.0213s/iter; left time: 411.4711s
Epoch: 19 cost time: 5.428048849105835
Epoch: 19, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5375 + XiCon Loss:2.5660 x Lambda(0.1)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8531
Validation loss decreased (1.006603 --> 1.006530).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8229979
	speed: 0.0246s/iter; left time: 470.9858s
	iters: 200, epoch: 20 | loss: 0.7844386
	speed: 0.0203s/iter; left time: 386.5139s
Epoch: 20 cost time: 5.287158966064453
Epoch: 20, Steps: 238 Train Loss: 0.7936 (Forecasting Loss:0.5375 + XiCon Loss:2.5601 x Lambda(0.1)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8531
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8040031
	speed: 0.0241s/iter; left time: 455.7369s
	iters: 200, epoch: 21 | loss: 0.8201007
	speed: 0.0204s/iter; left time: 385.1207s
Epoch: 21 cost time: 5.26334023475647
Epoch: 21, Steps: 238 Train Loss: 0.7936 (Forecasting Loss:0.5376 + XiCon Loss:2.5592 x Lambda(0.1)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8531
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.7405981
	speed: 0.0243s/iter; left time: 454.8862s
	iters: 200, epoch: 22 | loss: 0.7584704
	speed: 0.0202s/iter; left time: 374.9712s
Epoch: 22 cost time: 5.2414610385894775
Epoch: 22, Steps: 238 Train Loss: 0.7934 (Forecasting Loss:0.5376 + XiCon Loss:2.5578 x Lambda(0.1)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8531
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.7692107
	speed: 0.0250s/iter; left time: 460.9463s
	iters: 200, epoch: 23 | loss: 0.8254234
	speed: 0.0204s/iter; left time: 374.2762s
Epoch: 23 cost time: 5.342518091201782
Epoch: 23, Steps: 238 Train Loss: 0.7943 (Forecasting Loss:0.5377 + XiCon Loss:2.5667 x Lambda(0.1)), Vali MSE Loss: 1.0072 Test MSE Loss: 0.8531
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8159365
	speed: 0.0236s/iter; left time: 430.0238s
	iters: 200, epoch: 24 | loss: 0.7915591
	speed: 0.0209s/iter; left time: 379.7009s
Epoch: 24 cost time: 5.241513729095459
Epoch: 24, Steps: 238 Train Loss: 0.7943 (Forecasting Loss:0.5377 + XiCon Loss:2.5659 x Lambda(0.1)), Vali MSE Loss: 1.0078 Test MSE Loss: 0.8531
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.7907565
	speed: 0.0244s/iter; left time: 438.1724s
	iters: 200, epoch: 25 | loss: 0.8165207
	speed: 0.0203s/iter; left time: 362.8246s
Epoch: 25 cost time: 5.265771865844727
Epoch: 25, Steps: 238 Train Loss: 0.7937 (Forecasting Loss:0.5375 + XiCon Loss:2.5621 x Lambda(0.1)), Vali MSE Loss: 1.0079 Test MSE Loss: 0.8531
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.7736636
	speed: 0.0234s/iter; left time: 415.3492s
	iters: 200, epoch: 26 | loss: 0.8470541
	speed: 0.0202s/iter; left time: 355.7341s
Epoch: 26 cost time: 5.13230037689209
Epoch: 26, Steps: 238 Train Loss: 0.7940 (Forecasting Loss:0.5377 + XiCon Loss:2.5634 x Lambda(0.1)), Vali MSE Loss: 1.0065 Test MSE Loss: 0.8531
Validation loss decreased (1.006530 --> 1.006498).  Saving model ...
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.7665021
	speed: 0.0245s/iter; left time: 428.5919s
	iters: 200, epoch: 27 | loss: 0.8573406
	speed: 0.0222s/iter; left time: 385.8461s
Epoch: 27 cost time: 5.574853420257568
Epoch: 27, Steps: 238 Train Loss: 0.7945 (Forecasting Loss:0.5376 + XiCon Loss:2.5692 x Lambda(0.1)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8531
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.7931975
	speed: 0.0266s/iter; left time: 459.3541s
	iters: 200, epoch: 28 | loss: 0.8189722
	speed: 0.0216s/iter; left time: 371.8281s
Epoch: 28 cost time: 5.723598480224609
Epoch: 28, Steps: 238 Train Loss: 0.7939 (Forecasting Loss:0.5377 + XiCon Loss:2.5616 x Lambda(0.1)), Vali MSE Loss: 1.0066 Test MSE Loss: 0.8531
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.8120978
	speed: 0.0257s/iter; left time: 437.7450s
	iters: 200, epoch: 29 | loss: 0.7582412
	speed: 0.0237s/iter; left time: 401.4122s
Epoch: 29 cost time: 5.856777191162109
Epoch: 29, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5376 + XiCon Loss:2.5654 x Lambda(0.1)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8531
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.7961857
	speed: 0.0263s/iter; left time: 440.9740s
	iters: 200, epoch: 30 | loss: 0.8234994
	speed: 0.0245s/iter; left time: 408.3883s
Epoch: 30 cost time: 5.965544700622559
Epoch: 30, Steps: 238 Train Loss: 0.7936 (Forecasting Loss:0.5378 + XiCon Loss:2.5584 x Lambda(0.1)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8531
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.7899595
	speed: 0.0260s/iter; left time: 430.1007s
	iters: 200, epoch: 31 | loss: 0.7611152
	speed: 0.0230s/iter; left time: 379.1473s
Epoch: 31 cost time: 5.807342529296875
Epoch: 31, Steps: 238 Train Loss: 0.7939 (Forecasting Loss:0.5375 + XiCon Loss:2.5636 x Lambda(0.1)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8531
Validation loss decreased (1.006498 --> 1.006437).  Saving model ...
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.8233128
	speed: 0.0266s/iter; left time: 434.1605s
	iters: 200, epoch: 32 | loss: 0.7812359
	speed: 0.0230s/iter; left time: 373.1433s
Epoch: 32 cost time: 5.865708589553833
Epoch: 32, Steps: 238 Train Loss: 0.7937 (Forecasting Loss:0.5377 + XiCon Loss:2.5607 x Lambda(0.1)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8531
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.7976050
	speed: 0.0259s/iter; left time: 416.6125s
	iters: 200, epoch: 33 | loss: 0.7878846
	speed: 0.0238s/iter; left time: 380.8542s
Epoch: 33 cost time: 5.8981873989105225
Epoch: 33, Steps: 238 Train Loss: 0.7942 (Forecasting Loss:0.5376 + XiCon Loss:2.5652 x Lambda(0.1)), Vali MSE Loss: 1.0066 Test MSE Loss: 0.8531
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.7969552
	speed: 0.0257s/iter; left time: 407.9878s
	iters: 200, epoch: 34 | loss: 0.7724073
	speed: 0.0233s/iter; left time: 366.2040s
Epoch: 34 cost time: 5.744467496871948
Epoch: 34, Steps: 238 Train Loss: 0.7942 (Forecasting Loss:0.5378 + XiCon Loss:2.5645 x Lambda(0.1)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8531
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.7764777
	speed: 0.0258s/iter; left time: 402.5061s
	iters: 200, epoch: 35 | loss: 0.7757226
	speed: 0.0217s/iter; left time: 337.1901s
Epoch: 35 cost time: 5.6436145305633545
Epoch: 35, Steps: 238 Train Loss: 0.7937 (Forecasting Loss:0.5377 + XiCon Loss:2.5603 x Lambda(0.1)), Vali MSE Loss: 1.0070 Test MSE Loss: 0.8531
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.7671962
	speed: 0.0274s/iter; left time: 420.9302s
	iters: 200, epoch: 36 | loss: 0.7477407
	speed: 0.0227s/iter; left time: 346.9021s
Epoch: 36 cost time: 5.957789659500122
Epoch: 36, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5377 + XiCon Loss:2.5632 x Lambda(0.1)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8531
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.8188921
	speed: 0.0267s/iter; left time: 404.0381s
	iters: 200, epoch: 37 | loss: 0.8849649
	speed: 0.0226s/iter; left time: 339.0516s
Epoch: 37 cost time: 5.819177150726318
Epoch: 37, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5377 + XiCon Loss:2.5639 x Lambda(0.1)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8531
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.7743541
	speed: 0.0264s/iter; left time: 392.9630s
	iters: 200, epoch: 38 | loss: 0.7684104
	speed: 0.0233s/iter; left time: 345.2181s
Epoch: 38 cost time: 5.910775661468506
Epoch: 38, Steps: 238 Train Loss: 0.7945 (Forecasting Loss:0.5375 + XiCon Loss:2.5702 x Lambda(0.1)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8531
Validation loss decreased (1.006437 --> 1.006371).  Saving model ...
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.8242092
	speed: 0.0261s/iter; left time: 382.7902s
	iters: 200, epoch: 39 | loss: 0.7643989
	speed: 0.0226s/iter; left time: 328.4189s
Epoch: 39 cost time: 5.741744041442871
Epoch: 39, Steps: 238 Train Loss: 0.7944 (Forecasting Loss:0.5377 + XiCon Loss:2.5672 x Lambda(0.1)), Vali MSE Loss: 1.0060 Test MSE Loss: 0.8531
Validation loss decreased (1.006371 --> 1.006029).  Saving model ...
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.7595338
	speed: 0.0268s/iter; left time: 386.4513s
	iters: 200, epoch: 40 | loss: 0.8163437
	speed: 0.0240s/iter; left time: 343.1759s
Epoch: 40 cost time: 5.8630218505859375
Epoch: 40, Steps: 238 Train Loss: 0.7943 (Forecasting Loss:0.5378 + XiCon Loss:2.5652 x Lambda(0.1)), Vali MSE Loss: 1.0075 Test MSE Loss: 0.8531
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.8189894035458566e-16
	iters: 100, epoch: 41 | loss: 0.7899905
	speed: 0.0262s/iter; left time: 371.6231s
	iters: 200, epoch: 41 | loss: 0.7745290
	speed: 0.0230s/iter; left time: 324.2648s
Epoch: 41 cost time: 5.784605503082275
Epoch: 41, Steps: 238 Train Loss: 0.7944 (Forecasting Loss:0.5377 + XiCon Loss:2.5671 x Lambda(0.1)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8531
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.094947017729283e-17
	iters: 100, epoch: 42 | loss: 0.7904086
	speed: 0.0269s/iter; left time: 375.0406s
	iters: 200, epoch: 42 | loss: 0.8033262
	speed: 0.0221s/iter; left time: 305.7670s
Epoch: 42 cost time: 5.89451003074646
Epoch: 42, Steps: 238 Train Loss: 0.7943 (Forecasting Loss:0.5378 + XiCon Loss:2.5656 x Lambda(0.1)), Vali MSE Loss: 1.0064 Test MSE Loss: 0.8531
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.5474735088646414e-17
	iters: 100, epoch: 43 | loss: 0.7660500
	speed: 0.0267s/iter; left time: 365.9252s
	iters: 200, epoch: 43 | loss: 0.8025891
	speed: 0.0234s/iter; left time: 318.9871s
Epoch: 43 cost time: 5.914720296859741
Epoch: 43, Steps: 238 Train Loss: 0.7942 (Forecasting Loss:0.5376 + XiCon Loss:2.5657 x Lambda(0.1)), Vali MSE Loss: 1.0073 Test MSE Loss: 0.8531
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.2737367544323207e-17
	iters: 100, epoch: 44 | loss: 0.8108521
	speed: 0.0267s/iter; left time: 359.6412s
	iters: 200, epoch: 44 | loss: 0.7765200
	speed: 0.0239s/iter; left time: 319.6605s
Epoch: 44 cost time: 5.950188636779785
Epoch: 44, Steps: 238 Train Loss: 0.7939 (Forecasting Loss:0.5376 + XiCon Loss:2.5627 x Lambda(0.1)), Vali MSE Loss: 1.0067 Test MSE Loss: 0.8531
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1368683772161604e-17
	iters: 100, epoch: 45 | loss: 0.7492043
	speed: 0.0264s/iter; left time: 348.8321s
	iters: 200, epoch: 45 | loss: 0.7857572
	speed: 0.0235s/iter; left time: 308.8062s
Epoch: 45 cost time: 5.9941325187683105
Epoch: 45, Steps: 238 Train Loss: 0.7944 (Forecasting Loss:0.5375 + XiCon Loss:2.5691 x Lambda(0.1)), Vali MSE Loss: 1.0077 Test MSE Loss: 0.8531
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.684341886080802e-18
	iters: 100, epoch: 46 | loss: 0.8179932
	speed: 0.0264s/iter; left time: 343.3426s
	iters: 200, epoch: 46 | loss: 0.8201995
	speed: 0.0240s/iter; left time: 309.0991s
Epoch: 46 cost time: 5.9591145515441895
Epoch: 46, Steps: 238 Train Loss: 0.7944 (Forecasting Loss:0.5378 + XiCon Loss:2.5663 x Lambda(0.1)), Vali MSE Loss: 1.0071 Test MSE Loss: 0.8531
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.842170943040401e-18
	iters: 100, epoch: 47 | loss: 0.7654595
	speed: 0.0259s/iter; left time: 329.9366s
	iters: 200, epoch: 47 | loss: 0.8001400
	speed: 0.0238s/iter; left time: 301.0203s
Epoch: 47 cost time: 5.756462574005127
Epoch: 47, Steps: 238 Train Loss: 0.7945 (Forecasting Loss:0.5377 + XiCon Loss:2.5676 x Lambda(0.1)), Vali MSE Loss: 1.0076 Test MSE Loss: 0.8531
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.4210854715202004e-18
	iters: 100, epoch: 48 | loss: 0.8191004
	speed: 0.0266s/iter; left time: 333.0439s
	iters: 200, epoch: 48 | loss: 0.8145050
	speed: 0.0230s/iter; left time: 285.0316s
Epoch: 48 cost time: 5.863961219787598
Epoch: 48, Steps: 238 Train Loss: 0.7946 (Forecasting Loss:0.5377 + XiCon Loss:2.5689 x Lambda(0.1)), Vali MSE Loss: 1.0069 Test MSE Loss: 0.8531
EarlyStopping counter: 9 out of 10
Updating learning rate to 7.105427357601002e-19
	iters: 100, epoch: 49 | loss: 0.7828472
	speed: 0.0272s/iter; left time: 333.5433s
	iters: 200, epoch: 49 | loss: 0.8326049
	speed: 0.0218s/iter; left time: 265.9165s
Epoch: 49 cost time: 5.870746850967407
Epoch: 49, Steps: 238 Train Loss: 0.7941 (Forecasting Loss:0.5376 + XiCon Loss:2.5653 x Lambda(0.1)), Vali MSE Loss: 1.0068 Test MSE Loss: 0.8531
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9843260049819946, mae:0.7218258380889893, mape:4.797213554382324, mspe:2740.155517578125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7355
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.2493354
	speed: 0.0277s/iter; left time: 656.5124s
	iters: 200, epoch: 1 | loss: 1.1664442
	speed: 0.0250s/iter; left time: 588.8548s
Epoch: 1 cost time: 6.2600812911987305
Epoch: 1, Steps: 238 Train Loss: 1.2447 (Forecasting Loss:0.9872 + XiCon Loss:2.5758 x Lambda(0.1)), Vali MSE Loss: 1.7718 Test MSE Loss: 0.9677
Validation loss decreased (inf --> 1.771783).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8709649
	speed: 0.0272s/iter; left time: 639.3469s
	iters: 200, epoch: 2 | loss: 0.7939517
	speed: 0.0252s/iter; left time: 589.2683s
Epoch: 2 cost time: 6.25527024269104
Epoch: 2, Steps: 238 Train Loss: 0.8737 (Forecasting Loss:0.6169 + XiCon Loss:2.5682 x Lambda(0.1)), Vali MSE Loss: 1.0390 Test MSE Loss: 0.8531
Validation loss decreased (1.771783 --> 1.038995).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7691146
	speed: 0.0267s/iter; left time: 620.7112s
	iters: 200, epoch: 3 | loss: 0.8421232
	speed: 0.0252s/iter; left time: 581.6172s
Epoch: 3 cost time: 6.181905746459961
Epoch: 3, Steps: 238 Train Loss: 0.8056 (Forecasting Loss:0.5496 + XiCon Loss:2.5605 x Lambda(0.1)), Vali MSE Loss: 1.0165 Test MSE Loss: 0.8454
Validation loss decreased (1.038995 --> 1.016501).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7759659
	speed: 0.0271s/iter; left time: 623.4353s
	iters: 200, epoch: 4 | loss: 0.7811171
	speed: 0.0246s/iter; left time: 562.6697s
Epoch: 4 cost time: 6.205894470214844
Epoch: 4, Steps: 238 Train Loss: 0.7959 (Forecasting Loss:0.5401 + XiCon Loss:2.5580 x Lambda(0.1)), Vali MSE Loss: 1.0095 Test MSE Loss: 0.8436
Validation loss decreased (1.016501 --> 1.009473).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7824865
	speed: 0.0279s/iter; left time: 633.6390s
	iters: 200, epoch: 5 | loss: 0.8244421
	speed: 0.0245s/iter; left time: 554.2277s
Epoch: 5 cost time: 6.249703407287598
Epoch: 5, Steps: 238 Train Loss: 0.7914 (Forecasting Loss:0.5360 + XiCon Loss:2.5542 x Lambda(0.1)), Vali MSE Loss: 1.0058 Test MSE Loss: 0.8430
Validation loss decreased (1.009473 --> 1.005810).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.7419094
	speed: 0.0271s/iter; left time: 609.5592s
	iters: 200, epoch: 6 | loss: 0.8333135
	speed: 0.0245s/iter; left time: 549.2761s
Epoch: 6 cost time: 6.156560897827148
Epoch: 6, Steps: 238 Train Loss: 0.7889 (Forecasting Loss:0.5341 + XiCon Loss:2.5485 x Lambda(0.1)), Vali MSE Loss: 1.0044 Test MSE Loss: 0.8429
Validation loss decreased (1.005810 --> 1.004411).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7646073
	speed: 0.0270s/iter; left time: 600.7047s
	iters: 200, epoch: 7 | loss: 0.7525356
	speed: 0.0249s/iter; left time: 552.6460s
Epoch: 7 cost time: 6.076783180236816
Epoch: 7, Steps: 238 Train Loss: 0.7885 (Forecasting Loss:0.5331 + XiCon Loss:2.5537 x Lambda(0.1)), Vali MSE Loss: 1.0029 Test MSE Loss: 0.8428
Validation loss decreased (1.004411 --> 1.002863).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7900137
	speed: 0.0274s/iter; left time: 603.3750s
	iters: 200, epoch: 8 | loss: 0.7505378
	speed: 0.0253s/iter; left time: 555.6654s
Epoch: 8 cost time: 6.219707012176514
Epoch: 8, Steps: 238 Train Loss: 0.7884 (Forecasting Loss:0.5327 + XiCon Loss:2.5564 x Lambda(0.1)), Vali MSE Loss: 1.0031 Test MSE Loss: 0.8428
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8248268
	speed: 0.0268s/iter; left time: 585.2246s
	iters: 200, epoch: 9 | loss: 0.8202730
	speed: 0.0249s/iter; left time: 540.5630s
Epoch: 9 cost time: 6.234449148178101
Epoch: 9, Steps: 238 Train Loss: 0.7877 (Forecasting Loss:0.5326 + XiCon Loss:2.5509 x Lambda(0.1)), Vali MSE Loss: 1.0027 Test MSE Loss: 0.8427
Validation loss decreased (1.002863 --> 1.002656).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7367239
	speed: 0.0272s/iter; left time: 586.1066s
	iters: 200, epoch: 10 | loss: 0.8137001
	speed: 0.0256s/iter; left time: 548.5788s
Epoch: 10 cost time: 6.284529685974121
Epoch: 10, Steps: 238 Train Loss: 0.7877 (Forecasting Loss:0.5324 + XiCon Loss:2.5532 x Lambda(0.1)), Vali MSE Loss: 1.0028 Test MSE Loss: 0.8427
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8330123
	speed: 0.0268s/iter; left time: 570.4888s
	iters: 200, epoch: 11 | loss: 0.7846265
	speed: 0.0244s/iter; left time: 517.2547s
Epoch: 11 cost time: 6.061675310134888
Epoch: 11, Steps: 238 Train Loss: 0.7880 (Forecasting Loss:0.5324 + XiCon Loss:2.5567 x Lambda(0.1)), Vali MSE Loss: 1.0023 Test MSE Loss: 0.8427
Validation loss decreased (1.002656 --> 1.002287).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.7524098
	speed: 0.0269s/iter; left time: 566.8359s
	iters: 200, epoch: 12 | loss: 0.7807236
	speed: 0.0252s/iter; left time: 529.2264s
Epoch: 12 cost time: 6.23310399055481
Epoch: 12, Steps: 238 Train Loss: 0.7877 (Forecasting Loss:0.5323 + XiCon Loss:2.5537 x Lambda(0.1)), Vali MSE Loss: 1.0019 Test MSE Loss: 0.8427
Validation loss decreased (1.002287 --> 1.001882).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8178777
	speed: 0.0274s/iter; left time: 570.1426s
	iters: 200, epoch: 13 | loss: 0.7720579
	speed: 0.0251s/iter; left time: 519.7235s
Epoch: 13 cost time: 6.181811094284058
Epoch: 13, Steps: 238 Train Loss: 0.7878 (Forecasting Loss:0.5324 + XiCon Loss:2.5542 x Lambda(0.1)), Vali MSE Loss: 1.0024 Test MSE Loss: 0.8427
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8269210
	speed: 0.0264s/iter; left time: 544.0024s
	iters: 200, epoch: 14 | loss: 0.8212947
	speed: 0.0255s/iter; left time: 523.0759s
Epoch: 14 cost time: 6.139655590057373
Epoch: 14, Steps: 238 Train Loss: 0.7873 (Forecasting Loss:0.5325 + XiCon Loss:2.5479 x Lambda(0.1)), Vali MSE Loss: 1.0024 Test MSE Loss: 0.8427
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.7961594
	speed: 0.0258s/iter; left time: 524.6828s
	iters: 200, epoch: 15 | loss: 0.8014910
	speed: 0.0236s/iter; left time: 478.7889s
Epoch: 15 cost time: 5.869348764419556
Epoch: 15, Steps: 238 Train Loss: 0.7878 (Forecasting Loss:0.5323 + XiCon Loss:2.5555 x Lambda(0.1)), Vali MSE Loss: 1.0024 Test MSE Loss: 0.8427
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.7657526
	speed: 0.0256s/iter; left time: 514.3570s
	iters: 200, epoch: 16 | loss: 0.7589123
	speed: 0.0238s/iter; left time: 477.4954s
Epoch: 16 cost time: 5.840561628341675
Epoch: 16, Steps: 238 Train Loss: 0.7877 (Forecasting Loss:0.5322 + XiCon Loss:2.5550 x Lambda(0.1)), Vali MSE Loss: 1.0012 Test MSE Loss: 0.8427
Validation loss decreased (1.001882 --> 1.001186).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8064674
	speed: 0.0255s/iter; left time: 507.4305s
	iters: 200, epoch: 17 | loss: 0.7731200
	speed: 0.0233s/iter; left time: 460.6226s
Epoch: 17 cost time: 5.811651706695557
Epoch: 17, Steps: 238 Train Loss: 0.7875 (Forecasting Loss:0.5322 + XiCon Loss:2.5529 x Lambda(0.1)), Vali MSE Loss: 1.0019 Test MSE Loss: 0.8427
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8051802
	speed: 0.0254s/iter; left time: 498.3656s
	iters: 200, epoch: 18 | loss: 0.7400016
	speed: 0.0243s/iter; left time: 474.7920s
Epoch: 18 cost time: 6.030221939086914
Epoch: 18, Steps: 238 Train Loss: 0.7875 (Forecasting Loss:0.5324 + XiCon Loss:2.5503 x Lambda(0.1)), Vali MSE Loss: 1.0031 Test MSE Loss: 0.8427
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8039348
	speed: 0.0257s/iter; left time: 498.4837s
	iters: 200, epoch: 19 | loss: 0.8610627
	speed: 0.0233s/iter; left time: 450.6228s
Epoch: 19 cost time: 5.81257963180542
Epoch: 19, Steps: 238 Train Loss: 0.7883 (Forecasting Loss:0.5325 + XiCon Loss:2.5579 x Lambda(0.1)), Vali MSE Loss: 1.0019 Test MSE Loss: 0.8427
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.7864321
	speed: 0.0253s/iter; left time: 486.1745s
	iters: 200, epoch: 20 | loss: 0.7879938
	speed: 0.0237s/iter; left time: 451.2689s
Epoch: 20 cost time: 5.815598011016846
Epoch: 20, Steps: 238 Train Loss: 0.7879 (Forecasting Loss:0.5324 + XiCon Loss:2.5543 x Lambda(0.1)), Vali MSE Loss: 1.0020 Test MSE Loss: 0.8427
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8049897
	speed: 0.0254s/iter; left time: 481.0349s
	iters: 200, epoch: 21 | loss: 0.8048413
	speed: 0.0235s/iter; left time: 442.2319s
Epoch: 21 cost time: 5.801839113235474
Epoch: 21, Steps: 238 Train Loss: 0.7881 (Forecasting Loss:0.5324 + XiCon Loss:2.5567 x Lambda(0.1)), Vali MSE Loss: 1.0024 Test MSE Loss: 0.8427
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.7573342
	speed: 0.0249s/iter; left time: 465.9541s
	iters: 200, epoch: 22 | loss: 0.7685616
	speed: 0.0234s/iter; left time: 435.4795s
Epoch: 22 cost time: 5.714662551879883
Epoch: 22, Steps: 238 Train Loss: 0.7875 (Forecasting Loss:0.5325 + XiCon Loss:2.5502 x Lambda(0.1)), Vali MSE Loss: 1.0021 Test MSE Loss: 0.8427
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.7804089
	speed: 0.0271s/iter; left time: 499.5518s
	iters: 200, epoch: 23 | loss: 0.7641640
	speed: 0.0249s/iter; left time: 456.4117s
Epoch: 23 cost time: 6.149141550064087
Epoch: 23, Steps: 238 Train Loss: 0.7873 (Forecasting Loss:0.5323 + XiCon Loss:2.5498 x Lambda(0.1)), Vali MSE Loss: 1.0021 Test MSE Loss: 0.8427
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.7771403
	speed: 0.0267s/iter; left time: 487.4613s
	iters: 200, epoch: 24 | loss: 0.8363292
	speed: 0.0246s/iter; left time: 445.0633s
Epoch: 24 cost time: 6.1387200355529785
Epoch: 24, Steps: 238 Train Loss: 0.7876 (Forecasting Loss:0.5326 + XiCon Loss:2.5499 x Lambda(0.1)), Vali MSE Loss: 1.0029 Test MSE Loss: 0.8427
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8506947
	speed: 0.0277s/iter; left time: 498.9939s
	iters: 200, epoch: 25 | loss: 0.7959329
	speed: 0.0247s/iter; left time: 441.7994s
Epoch: 25 cost time: 6.275472640991211
Epoch: 25, Steps: 238 Train Loss: 0.7877 (Forecasting Loss:0.5324 + XiCon Loss:2.5530 x Lambda(0.1)), Vali MSE Loss: 1.0027 Test MSE Loss: 0.8427
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.7795599
	speed: 0.0265s/iter; left time: 471.1961s
	iters: 200, epoch: 26 | loss: 0.8151271
	speed: 0.0259s/iter; left time: 457.5717s
Epoch: 26 cost time: 6.2977564334869385
Epoch: 26, Steps: 238 Train Loss: 0.7875 (Forecasting Loss:0.5325 + XiCon Loss:2.5494 x Lambda(0.1)), Vali MSE Loss: 1.0027 Test MSE Loss: 0.8427
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9690591096878052, mae:0.7164004445075989, mape:4.6616973876953125, mspe:2553.092041015625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:485561
train 30562
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.7182
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 30562
val 9821
test 9820
	iters: 100, epoch: 1 | loss: 1.4053935
	speed: 0.0258s/iter; left time: 611.7350s
	iters: 200, epoch: 1 | loss: 1.4962909
	speed: 0.0236s/iter; left time: 556.1937s
Epoch: 1 cost time: 5.838167428970337
Epoch: 1, Steps: 238 Train Loss: 1.4445 (Forecasting Loss:1.1891 + XiCon Loss:2.5540 x Lambda(0.1)), Vali MSE Loss: 2.1383 Test MSE Loss: 1.0909
Validation loss decreased (inf --> 2.138325).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8577245
	speed: 0.0257s/iter; left time: 603.7114s
	iters: 200, epoch: 2 | loss: 0.7856668
	speed: 0.0236s/iter; left time: 552.2747s
Epoch: 2 cost time: 5.873085260391235
Epoch: 2, Steps: 238 Train Loss: 0.8978 (Forecasting Loss:0.6425 + XiCon Loss:2.5534 x Lambda(0.1)), Vali MSE Loss: 1.0201 Test MSE Loss: 0.8679
Validation loss decreased (2.138325 --> 1.020059).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.7938834
	speed: 0.0257s/iter; left time: 597.2411s
	iters: 200, epoch: 3 | loss: 0.7553703
	speed: 0.0236s/iter; left time: 545.1000s
Epoch: 3 cost time: 5.750146389007568
Epoch: 3, Steps: 238 Train Loss: 0.8066 (Forecasting Loss:0.5510 + XiCon Loss:2.5559 x Lambda(0.1)), Vali MSE Loss: 0.9995 Test MSE Loss: 0.8634
Validation loss decreased (1.020059 --> 0.999533).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.7768620
	speed: 0.0256s/iter; left time: 589.3482s
	iters: 200, epoch: 4 | loss: 0.7922199
	speed: 0.0236s/iter; left time: 539.8466s
Epoch: 4 cost time: 5.804195165634155
Epoch: 4, Steps: 238 Train Loss: 0.7968 (Forecasting Loss:0.5422 + XiCon Loss:2.5456 x Lambda(0.1)), Vali MSE Loss: 0.9928 Test MSE Loss: 0.8622
Validation loss decreased (0.999533 --> 0.992785).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.7345853
	speed: 0.0262s/iter; left time: 595.2412s
	iters: 200, epoch: 5 | loss: 0.7432112
	speed: 0.0225s/iter; left time: 510.4862s
Epoch: 5 cost time: 5.854570627212524
Epoch: 5, Steps: 238 Train Loss: 0.7936 (Forecasting Loss:0.5388 + XiCon Loss:2.5482 x Lambda(0.1)), Vali MSE Loss: 0.9887 Test MSE Loss: 0.8619
Validation loss decreased (0.992785 --> 0.988653).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8074793
	speed: 0.0269s/iter; left time: 606.6099s
	iters: 200, epoch: 6 | loss: 0.8086382
	speed: 0.0231s/iter; left time: 518.2848s
Epoch: 6 cost time: 5.905708074569702
Epoch: 6, Steps: 238 Train Loss: 0.7923 (Forecasting Loss:0.5372 + XiCon Loss:2.5510 x Lambda(0.1)), Vali MSE Loss: 0.9871 Test MSE Loss: 0.8617
Validation loss decreased (0.988653 --> 0.987059).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.7576153
	speed: 0.0262s/iter; left time: 584.2917s
	iters: 200, epoch: 7 | loss: 0.7731416
	speed: 0.0231s/iter; left time: 512.5423s
Epoch: 7 cost time: 5.8994104862213135
Epoch: 7, Steps: 238 Train Loss: 0.7917 (Forecasting Loss:0.5362 + XiCon Loss:2.5546 x Lambda(0.1)), Vali MSE Loss: 0.9876 Test MSE Loss: 0.8615
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.7749614
	speed: 0.0257s/iter; left time: 566.2828s
	iters: 200, epoch: 8 | loss: 0.7831113
	speed: 0.0233s/iter; left time: 511.6999s
Epoch: 8 cost time: 5.870545148849487
Epoch: 8, Steps: 238 Train Loss: 0.7909 (Forecasting Loss:0.5356 + XiCon Loss:2.5524 x Lambda(0.1)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8615
Validation loss decreased (0.987059 --> 0.985926).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.7816992
	speed: 0.0259s/iter; left time: 564.2247s
	iters: 200, epoch: 9 | loss: 0.7786444
	speed: 0.0228s/iter; left time: 494.3029s
Epoch: 9 cost time: 5.722661256790161
Epoch: 9, Steps: 238 Train Loss: 0.7905 (Forecasting Loss:0.5353 + XiCon Loss:2.5515 x Lambda(0.1)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8615
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.7879226
	speed: 0.0259s/iter; left time: 558.8032s
	iters: 200, epoch: 10 | loss: 0.7228532
	speed: 0.0227s/iter; left time: 488.1687s
Epoch: 10 cost time: 5.7772135734558105
Epoch: 10, Steps: 238 Train Loss: 0.7908 (Forecasting Loss:0.5356 + XiCon Loss:2.5525 x Lambda(0.1)), Vali MSE Loss: 0.9868 Test MSE Loss: 0.8615
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.7944406
	speed: 0.0258s/iter; left time: 549.2584s
	iters: 200, epoch: 11 | loss: 0.7793324
	speed: 0.0229s/iter; left time: 485.5316s
Epoch: 11 cost time: 5.810999870300293
Epoch: 11, Steps: 238 Train Loss: 0.7909 (Forecasting Loss:0.5354 + XiCon Loss:2.5545 x Lambda(0.1)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8615
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8314790
	speed: 0.0257s/iter; left time: 542.1793s
	iters: 200, epoch: 12 | loss: 0.7733294
	speed: 0.0232s/iter; left time: 486.8877s
Epoch: 12 cost time: 5.772842645645142
Epoch: 12, Steps: 238 Train Loss: 0.7904 (Forecasting Loss:0.5353 + XiCon Loss:2.5505 x Lambda(0.1)), Vali MSE Loss: 0.9864 Test MSE Loss: 0.8615
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.7499663
	speed: 0.0273s/iter; left time: 569.8644s
	iters: 200, epoch: 13 | loss: 0.7951204
	speed: 0.0232s/iter; left time: 481.2627s
Epoch: 13 cost time: 6.011897325515747
Epoch: 13, Steps: 238 Train Loss: 0.7910 (Forecasting Loss:0.5356 + XiCon Loss:2.5536 x Lambda(0.1)), Vali MSE Loss: 0.9856 Test MSE Loss: 0.8615
Validation loss decreased (0.985926 --> 0.985590).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8052292
	speed: 0.0266s/iter; left time: 547.8364s
	iters: 200, epoch: 14 | loss: 0.7632916
	speed: 0.0238s/iter; left time: 487.2682s
Epoch: 14 cost time: 5.922454833984375
Epoch: 14, Steps: 238 Train Loss: 0.7907 (Forecasting Loss:0.5353 + XiCon Loss:2.5538 x Lambda(0.1)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8615
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.7719011
	speed: 0.0253s/iter; left time: 516.2076s
	iters: 200, epoch: 15 | loss: 0.7881327
	speed: 0.0236s/iter; left time: 477.7118s
Epoch: 15 cost time: 5.713211536407471
Epoch: 15, Steps: 238 Train Loss: 0.7903 (Forecasting Loss:0.5352 + XiCon Loss:2.5510 x Lambda(0.1)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8615
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.7820621
	speed: 0.0261s/iter; left time: 525.0263s
	iters: 200, epoch: 16 | loss: 0.7718427
	speed: 0.0236s/iter; left time: 472.1877s
Epoch: 16 cost time: 5.870277166366577
Epoch: 16, Steps: 238 Train Loss: 0.7901 (Forecasting Loss:0.5354 + XiCon Loss:2.5466 x Lambda(0.1)), Vali MSE Loss: 0.9858 Test MSE Loss: 0.8615
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.7628736
	speed: 0.0254s/iter; left time: 505.2163s
	iters: 200, epoch: 17 | loss: 0.8121109
	speed: 0.0222s/iter; left time: 440.2294s
Epoch: 17 cost time: 5.78203010559082
Epoch: 17, Steps: 238 Train Loss: 0.7906 (Forecasting Loss:0.5354 + XiCon Loss:2.5518 x Lambda(0.1)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8615
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.7893339
	speed: 0.0261s/iter; left time: 512.6355s
	iters: 200, epoch: 18 | loss: 0.7915152
	speed: 0.0234s/iter; left time: 456.7498s
Epoch: 18 cost time: 5.870100736618042
Epoch: 18, Steps: 238 Train Loss: 0.7904 (Forecasting Loss:0.5355 + XiCon Loss:2.5492 x Lambda(0.1)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8615
EarlyStopping counter: 5 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8296507
	speed: 0.0256s/iter; left time: 497.8202s
	iters: 200, epoch: 19 | loss: 0.7735111
	speed: 0.0238s/iter; left time: 460.3380s
Epoch: 19 cost time: 5.844130992889404
Epoch: 19, Steps: 238 Train Loss: 0.7901 (Forecasting Loss:0.5353 + XiCon Loss:2.5472 x Lambda(0.1)), Vali MSE Loss: 0.9860 Test MSE Loss: 0.8615
EarlyStopping counter: 6 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8105576
	speed: 0.0262s/iter; left time: 501.9725s
	iters: 200, epoch: 20 | loss: 0.7883232
	speed: 0.0227s/iter; left time: 432.5827s
Epoch: 20 cost time: 5.809509992599487
Epoch: 20, Steps: 238 Train Loss: 0.7908 (Forecasting Loss:0.5351 + XiCon Loss:2.5569 x Lambda(0.1)), Vali MSE Loss: 0.9859 Test MSE Loss: 0.8615
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.7896225
	speed: 0.0258s/iter; left time: 487.9183s
	iters: 200, epoch: 21 | loss: 0.7726882
	speed: 0.0237s/iter; left time: 446.6528s
Epoch: 21 cost time: 5.819810628890991
Epoch: 21, Steps: 238 Train Loss: 0.7901 (Forecasting Loss:0.5352 + XiCon Loss:2.5488 x Lambda(0.1)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8615
EarlyStopping counter: 8 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.7805086
	speed: 0.0262s/iter; left time: 490.3484s
	iters: 200, epoch: 22 | loss: 0.8272083
	speed: 0.0233s/iter; left time: 433.7679s
Epoch: 22 cost time: 5.769479513168335
Epoch: 22, Steps: 238 Train Loss: 0.7902 (Forecasting Loss:0.5353 + XiCon Loss:2.5493 x Lambda(0.1)), Vali MSE Loss: 0.9861 Test MSE Loss: 0.8615
EarlyStopping counter: 9 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.7378738
	speed: 0.0262s/iter; left time: 483.6570s
	iters: 200, epoch: 23 | loss: 0.7782183
	speed: 0.0225s/iter; left time: 412.8206s
Epoch: 23 cost time: 5.7379467487335205
Epoch: 23, Steps: 238 Train Loss: 0.7900 (Forecasting Loss:0.5352 + XiCon Loss:2.5486 x Lambda(0.1)), Vali MSE Loss: 0.9863 Test MSE Loss: 0.8615
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl720_dm4_nh8_el1_dl1_df4_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9820
test shape: (76, 128, 720, 1) (76, 128, 720, 1)
test shape: (9728, 720, 1) (9728, 720, 1)
mse:0.9956713318824768, mae:0.7272443175315857, mape:4.8667778968811035, mspe:2803.189208984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:0.9814+-0.01211, MAE:0.7213+-0.00497, MAPE:4.7744+-0.09163, MSPE:2690.9883+-115.20607, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[336], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=1440, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.5, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.6800
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.2457478
	speed: 0.0379s/iter; left time: 879.6462s
	iters: 200, epoch: 1 | loss: 1.1984088
	speed: 0.0308s/iter; left time: 712.4931s
Epoch: 1 cost time: 7.924687623977661
Epoch: 1, Steps: 233 Train Loss: 1.3008 (Forecasting Loss:1.0189 + XiCon Loss:2.8189 x Lambda(0.1)), Vali MSE Loss: 1.8607 Test MSE Loss: 1.2485
Validation loss decreased (inf --> 1.860654).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8772419
	speed: 0.0331s/iter; left time: 760.1106s
	iters: 200, epoch: 2 | loss: 0.9493645
	speed: 0.0327s/iter; left time: 747.4355s
Epoch: 2 cost time: 7.637731075286865
Epoch: 2, Steps: 233 Train Loss: 0.9331 (Forecasting Loss:0.6523 + XiCon Loss:2.8079 x Lambda(0.1)), Vali MSE Loss: 1.1266 Test MSE Loss: 1.1494
Validation loss decreased (1.860654 --> 1.126573).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.9051456
	speed: 0.0334s/iter; left time: 758.4256s
	iters: 200, epoch: 3 | loss: 0.8493310
	speed: 0.0317s/iter; left time: 718.3888s
Epoch: 3 cost time: 7.5457048416137695
Epoch: 3, Steps: 233 Train Loss: 0.8670 (Forecasting Loss:0.5884 + XiCon Loss:2.7853 x Lambda(0.1)), Vali MSE Loss: 1.1040 Test MSE Loss: 1.1431
Validation loss decreased (1.126573 --> 1.103999).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8688866
	speed: 0.0341s/iter; left time: 767.8438s
	iters: 200, epoch: 4 | loss: 0.8756561
	speed: 0.0310s/iter; left time: 693.6617s
Epoch: 4 cost time: 7.603726148605347
Epoch: 4, Steps: 233 Train Loss: 0.8572 (Forecasting Loss:0.5806 + XiCon Loss:2.7668 x Lambda(0.1)), Vali MSE Loss: 1.0965 Test MSE Loss: 1.1404
Validation loss decreased (1.103999 --> 1.096543).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8428000
	speed: 0.0349s/iter; left time: 777.4358s
	iters: 200, epoch: 5 | loss: 0.8451679
	speed: 0.0304s/iter; left time: 673.8499s
Epoch: 5 cost time: 7.5807578563690186
Epoch: 5, Steps: 233 Train Loss: 0.8533 (Forecasting Loss:0.5775 + XiCon Loss:2.7581 x Lambda(0.1)), Vali MSE Loss: 1.0934 Test MSE Loss: 1.1394
Validation loss decreased (1.096543 --> 1.093350).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8711591
	speed: 0.0329s/iter; left time: 725.7801s
	iters: 200, epoch: 6 | loss: 0.8789273
	speed: 0.0293s/iter; left time: 643.1320s
Epoch: 6 cost time: 7.214450120925903
Epoch: 6, Steps: 233 Train Loss: 0.8515 (Forecasting Loss:0.5761 + XiCon Loss:2.7549 x Lambda(0.1)), Vali MSE Loss: 1.0916 Test MSE Loss: 1.1392
Validation loss decreased (1.093350 --> 1.091591).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8381399
	speed: 0.0323s/iter; left time: 705.1390s
	iters: 200, epoch: 7 | loss: 0.8950413
	speed: 0.0291s/iter; left time: 630.8050s
Epoch: 7 cost time: 7.142794847488403
Epoch: 7, Steps: 233 Train Loss: 0.8502 (Forecasting Loss:0.5753 + XiCon Loss:2.7489 x Lambda(0.1)), Vali MSE Loss: 1.0908 Test MSE Loss: 1.1391
Validation loss decreased (1.091591 --> 1.090823).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8204043
	speed: 0.0309s/iter; left time: 666.8087s
	iters: 200, epoch: 8 | loss: 0.8602479
	speed: 0.0291s/iter; left time: 625.2318s
Epoch: 8 cost time: 7.026880979537964
Epoch: 8, Steps: 233 Train Loss: 0.8500 (Forecasting Loss:0.5749 + XiCon Loss:2.7513 x Lambda(0.1)), Vali MSE Loss: 1.0907 Test MSE Loss: 1.1390
Validation loss decreased (1.090823 --> 1.090665).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8940777
	speed: 0.0319s/iter; left time: 680.0626s
	iters: 200, epoch: 9 | loss: 0.8950201
	speed: 0.0312s/iter; left time: 662.9484s
Epoch: 9 cost time: 7.31414794921875
Epoch: 9, Steps: 233 Train Loss: 0.8499 (Forecasting Loss:0.5747 + XiCon Loss:2.7520 x Lambda(0.1)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1390
Validation loss decreased (1.090665 --> 1.090199).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8115995
	speed: 0.0321s/iter; left time: 678.0404s
	iters: 200, epoch: 10 | loss: 0.8395221
	speed: 0.0291s/iter; left time: 611.2400s
Epoch: 10 cost time: 7.1207098960876465
Epoch: 10, Steps: 233 Train Loss: 0.8495 (Forecasting Loss:0.5746 + XiCon Loss:2.7481 x Lambda(0.1)), Vali MSE Loss: 1.0903 Test MSE Loss: 1.1390
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8319376
	speed: 0.0319s/iter; left time: 665.0297s
	iters: 200, epoch: 11 | loss: 0.8572218
	speed: 0.0290s/iter; left time: 602.2241s
Epoch: 11 cost time: 7.084000587463379
Epoch: 11, Steps: 233 Train Loss: 0.8491 (Forecasting Loss:0.5746 + XiCon Loss:2.7456 x Lambda(0.1)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1389
Validation loss decreased (1.090199 --> 1.089976).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8569999
	speed: 0.0325s/iter; left time: 670.0552s
	iters: 200, epoch: 12 | loss: 0.8552115
	speed: 0.0288s/iter; left time: 590.7220s
Epoch: 12 cost time: 7.111021995544434
Epoch: 12, Steps: 233 Train Loss: 0.8490 (Forecasting Loss:0.5745 + XiCon Loss:2.7445 x Lambda(0.1)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1389
Validation loss decreased (1.089976 --> 1.089814).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8397272
	speed: 0.0359s/iter; left time: 732.0130s
	iters: 200, epoch: 13 | loss: 0.8591053
	speed: 0.0309s/iter; left time: 627.1072s
Epoch: 13 cost time: 7.760853290557861
Epoch: 13, Steps: 233 Train Loss: 0.8494 (Forecasting Loss:0.5745 + XiCon Loss:2.7489 x Lambda(0.1)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1389
Validation loss decreased (1.089814 --> 1.089751).  Saving model ...
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8641213
	speed: 0.0325s/iter; left time: 656.3228s
	iters: 200, epoch: 14 | loss: 0.8455279
	speed: 0.0317s/iter; left time: 636.1634s
Epoch: 14 cost time: 7.427906513214111
Epoch: 14, Steps: 233 Train Loss: 0.8488 (Forecasting Loss:0.5745 + XiCon Loss:2.7434 x Lambda(0.1)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8330662
	speed: 0.0328s/iter; left time: 653.6580s
	iters: 200, epoch: 15 | loss: 0.8899242
	speed: 0.0309s/iter; left time: 613.9661s
Epoch: 15 cost time: 7.483505010604858
Epoch: 15, Steps: 233 Train Loss: 0.8491 (Forecasting Loss:0.5745 + XiCon Loss:2.7457 x Lambda(0.1)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8660001
	speed: 0.0340s/iter; left time: 669.4001s
	iters: 200, epoch: 16 | loss: 0.8720630
	speed: 0.0309s/iter; left time: 605.1208s
Epoch: 16 cost time: 7.630995988845825
Epoch: 16, Steps: 233 Train Loss: 0.8491 (Forecasting Loss:0.5745 + XiCon Loss:2.7457 x Lambda(0.1)), Vali MSE Loss: 1.0894 Test MSE Loss: 1.1389
Validation loss decreased (1.089751 --> 1.089354).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8337579
	speed: 0.0342s/iter; left time: 666.2395s
	iters: 200, epoch: 17 | loss: 0.8328938
	speed: 0.0317s/iter; left time: 614.5761s
Epoch: 17 cost time: 7.644671440124512
Epoch: 17, Steps: 233 Train Loss: 0.8488 (Forecasting Loss:0.5745 + XiCon Loss:2.7436 x Lambda(0.1)), Vali MSE Loss: 1.0898 Test MSE Loss: 1.1389
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8905966
	speed: 0.0340s/iter; left time: 654.8847s
	iters: 200, epoch: 18 | loss: 0.8509990
	speed: 0.0305s/iter; left time: 583.9394s
Epoch: 18 cost time: 7.49868106842041
Epoch: 18, Steps: 233 Train Loss: 0.8492 (Forecasting Loss:0.5745 + XiCon Loss:2.7471 x Lambda(0.1)), Vali MSE Loss: 1.0896 Test MSE Loss: 1.1389
EarlyStopping counter: 2 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8347874
	speed: 0.0341s/iter; left time: 647.2383s
	iters: 200, epoch: 19 | loss: 0.9298413
	speed: 0.0323s/iter; left time: 611.0750s
Epoch: 19 cost time: 7.6754021644592285
Epoch: 19, Steps: 233 Train Loss: 0.8493 (Forecasting Loss:0.5745 + XiCon Loss:2.7482 x Lambda(0.1)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1389
EarlyStopping counter: 3 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8195928
	speed: 0.0347s/iter; left time: 650.5797s
	iters: 200, epoch: 20 | loss: 0.8231300
	speed: 0.0307s/iter; left time: 572.8596s
Epoch: 20 cost time: 7.584221124649048
Epoch: 20, Steps: 233 Train Loss: 0.8491 (Forecasting Loss:0.5745 + XiCon Loss:2.7466 x Lambda(0.1)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1389
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8476027
	speed: 0.0344s/iter; left time: 638.4899s
	iters: 200, epoch: 21 | loss: 0.8277388
	speed: 0.0311s/iter; left time: 574.0007s
Epoch: 21 cost time: 7.641648054122925
Epoch: 21, Steps: 233 Train Loss: 0.8493 (Forecasting Loss:0.5746 + XiCon Loss:2.7473 x Lambda(0.1)), Vali MSE Loss: 1.0902 Test MSE Loss: 1.1389
EarlyStopping counter: 5 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8222162
	speed: 0.0345s/iter; left time: 631.1943s
	iters: 200, epoch: 22 | loss: 0.8283448
	speed: 0.0304s/iter; left time: 554.2268s
Epoch: 22 cost time: 7.61593222618103
Epoch: 22, Steps: 233 Train Loss: 0.8494 (Forecasting Loss:0.5746 + XiCon Loss:2.7484 x Lambda(0.1)), Vali MSE Loss: 1.0897 Test MSE Loss: 1.1389
EarlyStopping counter: 6 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.7900927
	speed: 0.0337s/iter; left time: 610.0303s
	iters: 200, epoch: 23 | loss: 0.8447794
	speed: 0.0308s/iter; left time: 552.7649s
Epoch: 23 cost time: 7.572413682937622
Epoch: 23, Steps: 233 Train Loss: 0.8489 (Forecasting Loss:0.5745 + XiCon Loss:2.7437 x Lambda(0.1)), Vali MSE Loss: 1.0897 Test MSE Loss: 1.1389
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8393109
	speed: 0.0332s/iter; left time: 592.3144s
	iters: 200, epoch: 24 | loss: 0.8205863
	speed: 0.0315s/iter; left time: 559.3840s
Epoch: 24 cost time: 7.570295810699463
Epoch: 24, Steps: 233 Train Loss: 0.8493 (Forecasting Loss:0.5745 + XiCon Loss:2.7483 x Lambda(0.1)), Vali MSE Loss: 1.0899 Test MSE Loss: 1.1389
EarlyStopping counter: 8 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8457798
	speed: 0.0347s/iter; left time: 610.1538s
	iters: 200, epoch: 25 | loss: 0.8284292
	speed: 0.0309s/iter; left time: 541.2236s
Epoch: 25 cost time: 7.6690673828125
Epoch: 25, Steps: 233 Train Loss: 0.8497 (Forecasting Loss:0.5745 + XiCon Loss:2.7515 x Lambda(0.1)), Vali MSE Loss: 1.0901 Test MSE Loss: 1.1389
EarlyStopping counter: 9 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8183724
	speed: 0.0337s/iter; left time: 585.9372s
	iters: 200, epoch: 26 | loss: 0.8851013
	speed: 0.0318s/iter; left time: 548.8180s
Epoch: 26 cost time: 7.5716869831085205
Epoch: 26, Steps: 233 Train Loss: 0.8486 (Forecasting Loss:0.5745 + XiCon Loss:2.7412 x Lambda(0.1)), Vali MSE Loss: 1.0900 Test MSE Loss: 1.1389
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3981599807739258, mae:0.879712700843811, mape:6.156443119049072, mspe:4566.3759765625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.2650
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.4282675
	speed: 0.0348s/iter; left time: 808.3071s
	iters: 200, epoch: 1 | loss: 1.4043474
	speed: 0.0307s/iter; left time: 709.5474s
Epoch: 1 cost time: 7.65318489074707
Epoch: 1, Steps: 233 Train Loss: 1.4183 (Forecasting Loss:1.1342 + XiCon Loss:2.8413 x Lambda(0.1)), Vali MSE Loss: 2.0412 Test MSE Loss: 1.3315
Validation loss decreased (inf --> 2.041246).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9690146
	speed: 0.0343s/iter; left time: 787.0185s
	iters: 200, epoch: 2 | loss: 0.8771522
	speed: 0.0311s/iter; left time: 710.5117s
Epoch: 2 cost time: 7.5863566398620605
Epoch: 2, Steps: 233 Train Loss: 0.9437 (Forecasting Loss:0.6601 + XiCon Loss:2.8356 x Lambda(0.1)), Vali MSE Loss: 1.1153 Test MSE Loss: 1.1430
Validation loss decreased (2.041246 --> 1.115259).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8610544
	speed: 0.0351s/iter; left time: 797.3873s
	iters: 200, epoch: 3 | loss: 0.8498204
	speed: 0.0319s/iter; left time: 722.4769s
Epoch: 3 cost time: 7.6890342235565186
Epoch: 3, Steps: 233 Train Loss: 0.8706 (Forecasting Loss:0.5876 + XiCon Loss:2.8301 x Lambda(0.1)), Vali MSE Loss: 1.0925 Test MSE Loss: 1.1382
Validation loss decreased (1.115259 --> 1.092529).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.9208814
	speed: 0.0342s/iter; left time: 768.8131s
	iters: 200, epoch: 4 | loss: 0.8417633
	speed: 0.0312s/iter; left time: 699.4855s
Epoch: 4 cost time: 7.6172850131988525
Epoch: 4, Steps: 233 Train Loss: 0.8616 (Forecasting Loss:0.5793 + XiCon Loss:2.8236 x Lambda(0.1)), Vali MSE Loss: 1.0855 Test MSE Loss: 1.1366
Validation loss decreased (1.092529 --> 1.085450).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9333571
	speed: 0.0348s/iter; left time: 773.8844s
	iters: 200, epoch: 5 | loss: 0.8314805
	speed: 0.0319s/iter; left time: 706.4206s
Epoch: 5 cost time: 7.7230024337768555
Epoch: 5, Steps: 233 Train Loss: 0.8586 (Forecasting Loss:0.5759 + XiCon Loss:2.8263 x Lambda(0.1)), Vali MSE Loss: 1.0809 Test MSE Loss: 1.1366
Validation loss decreased (1.085450 --> 1.080862).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.9169152
	speed: 0.0336s/iter; left time: 740.4268s
	iters: 200, epoch: 6 | loss: 0.8929397
	speed: 0.0310s/iter; left time: 680.3742s
Epoch: 6 cost time: 7.4851038455963135
Epoch: 6, Steps: 233 Train Loss: 0.8569 (Forecasting Loss:0.5743 + XiCon Loss:2.8257 x Lambda(0.1)), Vali MSE Loss: 1.0798 Test MSE Loss: 1.1357
Validation loss decreased (1.080862 --> 1.079752).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8630399
	speed: 0.0339s/iter; left time: 738.9437s
	iters: 200, epoch: 7 | loss: 0.8383851
	speed: 0.0321s/iter; left time: 695.9597s
Epoch: 7 cost time: 7.6250083446502686
Epoch: 7, Steps: 233 Train Loss: 0.8559 (Forecasting Loss:0.5737 + XiCon Loss:2.8221 x Lambda(0.1)), Vali MSE Loss: 1.0784 Test MSE Loss: 1.1359
Validation loss decreased (1.079752 --> 1.078359).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8521396
	speed: 0.0334s/iter; left time: 719.4964s
	iters: 200, epoch: 8 | loss: 0.9010086
	speed: 0.0319s/iter; left time: 685.2864s
Epoch: 8 cost time: 7.580429553985596
Epoch: 8, Steps: 233 Train Loss: 0.8553 (Forecasting Loss:0.5731 + XiCon Loss:2.8221 x Lambda(0.1)), Vali MSE Loss: 1.0778 Test MSE Loss: 1.1359
Validation loss decreased (1.078359 --> 1.077796).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8336916
	speed: 0.0325s/iter; left time: 693.4589s
	iters: 200, epoch: 9 | loss: 0.8401337
	speed: 0.0316s/iter; left time: 670.2088s
Epoch: 9 cost time: 7.469735383987427
Epoch: 9, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5729 + XiCon Loss:2.8179 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1359
Validation loss decreased (1.077796 --> 1.077450).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8678235
	speed: 0.0342s/iter; left time: 721.7223s
	iters: 200, epoch: 10 | loss: 0.8635046
	speed: 0.0322s/iter; left time: 676.2376s
Epoch: 10 cost time: 7.725174188613892
Epoch: 10, Steps: 233 Train Loss: 0.8558 (Forecasting Loss:0.5730 + XiCon Loss:2.8282 x Lambda(0.1)), Vali MSE Loss: 1.0776 Test MSE Loss: 1.1358
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.7943904
	speed: 0.0337s/iter; left time: 703.1199s
	iters: 200, epoch: 11 | loss: 0.8556469
	speed: 0.0311s/iter; left time: 645.8537s
Epoch: 11 cost time: 7.578040361404419
Epoch: 11, Steps: 233 Train Loss: 0.8546 (Forecasting Loss:0.5729 + XiCon Loss:2.8176 x Lambda(0.1)), Vali MSE Loss: 1.0775 Test MSE Loss: 1.1358
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8392261
	speed: 0.0334s/iter; left time: 688.5750s
	iters: 200, epoch: 12 | loss: 0.8462355
	speed: 0.0320s/iter; left time: 657.6958s
Epoch: 12 cost time: 7.597749710083008
Epoch: 12, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5728 + XiCon Loss:2.8192 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
Validation loss decreased (1.077450 --> 1.077386).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8658460
	speed: 0.0337s/iter; left time: 686.9523s
	iters: 200, epoch: 13 | loss: 0.8711044
	speed: 0.0312s/iter; left time: 633.6708s
Epoch: 13 cost time: 7.661489963531494
Epoch: 13, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5728 + XiCon Loss:2.8192 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8431535
	speed: 0.0333s/iter; left time: 671.2571s
	iters: 200, epoch: 14 | loss: 0.8500156
	speed: 0.0316s/iter; left time: 633.7434s
Epoch: 14 cost time: 7.5378875732421875
Epoch: 14, Steps: 233 Train Loss: 0.8545 (Forecasting Loss:0.5729 + XiCon Loss:2.8160 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
Validation loss decreased (1.077386 --> 1.077353).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8648597
	speed: 0.0334s/iter; left time: 665.9366s
	iters: 200, epoch: 15 | loss: 0.8245077
	speed: 0.0315s/iter; left time: 624.4475s
Epoch: 15 cost time: 7.489423036575317
Epoch: 15, Steps: 233 Train Loss: 0.8546 (Forecasting Loss:0.5727 + XiCon Loss:2.8189 x Lambda(0.1)), Vali MSE Loss: 1.0776 Test MSE Loss: 1.1358
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8618095
	speed: 0.0315s/iter; left time: 619.7548s
	iters: 200, epoch: 16 | loss: 0.8903785
	speed: 0.0301s/iter; left time: 589.3459s
Epoch: 16 cost time: 7.1555914878845215
Epoch: 16, Steps: 233 Train Loss: 0.8549 (Forecasting Loss:0.5728 + XiCon Loss:2.8203 x Lambda(0.1)), Vali MSE Loss: 1.0775 Test MSE Loss: 1.1358
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8307145
	speed: 0.0320s/iter; left time: 623.0168s
	iters: 200, epoch: 17 | loss: 0.8081781
	speed: 0.0291s/iter; left time: 563.4066s
Epoch: 17 cost time: 7.144401550292969
Epoch: 17, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5727 + XiCon Loss:2.8210 x Lambda(0.1)), Vali MSE Loss: 1.0775 Test MSE Loss: 1.1358
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8985938
	speed: 0.0304s/iter; left time: 584.1307s
	iters: 200, epoch: 18 | loss: 0.8314941
	speed: 0.0293s/iter; left time: 560.5035s
Epoch: 18 cost time: 6.938126087188721
Epoch: 18, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5728 + XiCon Loss:2.8221 x Lambda(0.1)), Vali MSE Loss: 1.0775 Test MSE Loss: 1.1358
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8225791
	speed: 0.0329s/iter; left time: 624.9516s
	iters: 200, epoch: 19 | loss: 0.8499854
	speed: 0.0293s/iter; left time: 554.2512s
Epoch: 19 cost time: 7.215031147003174
Epoch: 19, Steps: 233 Train Loss: 0.8551 (Forecasting Loss:0.5728 + XiCon Loss:2.8231 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8959299
	speed: 0.0309s/iter; left time: 579.7586s
	iters: 200, epoch: 20 | loss: 0.8256794
	speed: 0.0296s/iter; left time: 552.8319s
Epoch: 20 cost time: 7.05921483039856
Epoch: 20, Steps: 233 Train Loss: 0.8546 (Forecasting Loss:0.5728 + XiCon Loss:2.8175 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8218641
	speed: 0.0319s/iter; left time: 591.3075s
	iters: 200, epoch: 21 | loss: 0.8490260
	speed: 0.0290s/iter; left time: 534.5698s
Epoch: 21 cost time: 7.073367595672607
Epoch: 21, Steps: 233 Train Loss: 0.8551 (Forecasting Loss:0.5730 + XiCon Loss:2.8214 x Lambda(0.1)), Vali MSE Loss: 1.0772 Test MSE Loss: 1.1358
Validation loss decreased (1.077353 --> 1.077211).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8821553
	speed: 0.0314s/iter; left time: 575.6458s
	iters: 200, epoch: 22 | loss: 0.8707298
	speed: 0.0326s/iter; left time: 593.8272s
Epoch: 22 cost time: 7.457108020782471
Epoch: 22, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5728 + XiCon Loss:2.8190 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8394691
	speed: 0.0340s/iter; left time: 614.6767s
	iters: 200, epoch: 23 | loss: 0.8828323
	speed: 0.0325s/iter; left time: 583.9291s
Epoch: 23 cost time: 7.802685976028442
Epoch: 23, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5729 + XiCon Loss:2.8213 x Lambda(0.1)), Vali MSE Loss: 1.0774 Test MSE Loss: 1.1358
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8391995
	speed: 0.0349s/iter; left time: 622.3705s
	iters: 200, epoch: 24 | loss: 0.8192933
	speed: 0.0343s/iter; left time: 608.3941s
Epoch: 24 cost time: 8.00993037223816
Epoch: 24, Steps: 233 Train Loss: 0.8551 (Forecasting Loss:0.5727 + XiCon Loss:2.8235 x Lambda(0.1)), Vali MSE Loss: 1.0773 Test MSE Loss: 1.1358
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.9207302
	speed: 0.0332s/iter; left time: 584.7190s
	iters: 200, epoch: 25 | loss: 0.8673079
	speed: 0.0325s/iter; left time: 569.7975s
Epoch: 25 cost time: 7.653777599334717
Epoch: 25, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5727 + XiCon Loss:2.8211 x Lambda(0.1)), Vali MSE Loss: 1.0771 Test MSE Loss: 1.1358
Validation loss decreased (1.077211 --> 1.077122).  Saving model ...
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8723016
	speed: 0.0353s/iter; left time: 613.4854s
	iters: 200, epoch: 26 | loss: 0.8284718
	speed: 0.0307s/iter; left time: 530.8514s
Epoch: 26 cost time: 7.704507350921631
Epoch: 26, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5728 + XiCon Loss:2.8200 x Lambda(0.1)), Vali MSE Loss: 1.0775 Test MSE Loss: 1.1358
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.8483864
	speed: 0.0336s/iter; left time: 576.6692s
	iters: 200, epoch: 27 | loss: 0.9038982
	speed: 0.0334s/iter; left time: 569.3791s
Epoch: 27 cost time: 7.863593816757202
Epoch: 27, Steps: 233 Train Loss: 0.8552 (Forecasting Loss:0.5729 + XiCon Loss:2.8228 x Lambda(0.1)), Vali MSE Loss: 1.0773 Test MSE Loss: 1.1358
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.7906307
	speed: 0.0356s/iter; left time: 601.9021s
	iters: 200, epoch: 28 | loss: 0.8602709
	speed: 0.0400s/iter; left time: 672.2425s
Epoch: 28 cost time: 8.76868224143982
Epoch: 28, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5727 + XiCon Loss:2.8195 x Lambda(0.1)), Vali MSE Loss: 1.0773 Test MSE Loss: 1.1358
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.8677292
	speed: 0.0359s/iter; left time: 598.7620s
	iters: 200, epoch: 29 | loss: 0.8456452
	speed: 0.0324s/iter; left time: 536.4396s
Epoch: 29 cost time: 8.104172945022583
Epoch: 29, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5728 + XiCon Loss:2.8222 x Lambda(0.1)), Vali MSE Loss: 1.0777 Test MSE Loss: 1.1358
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.8700326
	speed: 0.0400s/iter; left time: 658.2874s
	iters: 200, epoch: 30 | loss: 0.8895762
	speed: 0.0351s/iter; left time: 573.8431s
Epoch: 30 cost time: 8.668169260025024
Epoch: 30, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5729 + XiCon Loss:2.8194 x Lambda(0.1)), Vali MSE Loss: 1.0772 Test MSE Loss: 1.1358
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.8264705
	speed: 0.0367s/iter; left time: 595.0669s
	iters: 200, epoch: 31 | loss: 0.8429903
	speed: 0.0384s/iter; left time: 618.3344s
Epoch: 31 cost time: 8.833078384399414
Epoch: 31, Steps: 233 Train Loss: 0.8546 (Forecasting Loss:0.5727 + XiCon Loss:2.8195 x Lambda(0.1)), Vali MSE Loss: 1.0777 Test MSE Loss: 1.1358
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.8758613
	speed: 0.0373s/iter; left time: 595.8231s
	iters: 200, epoch: 32 | loss: 0.8832703
	speed: 0.0319s/iter; left time: 506.7049s
Epoch: 32 cost time: 8.08927869796753
Epoch: 32, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5727 + XiCon Loss:2.8199 x Lambda(0.1)), Vali MSE Loss: 1.0775 Test MSE Loss: 1.1358
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.8197106
	speed: 0.0334s/iter; left time: 525.8991s
	iters: 200, epoch: 33 | loss: 0.8696158
	speed: 0.0337s/iter; left time: 527.8816s
Epoch: 33 cost time: 7.9253363609313965
Epoch: 33, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5729 + XiCon Loss:2.8185 x Lambda(0.1)), Vali MSE Loss: 1.0776 Test MSE Loss: 1.1358
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.8305039
	speed: 0.0375s/iter; left time: 581.0734s
	iters: 200, epoch: 34 | loss: 0.8314754
	speed: 0.0342s/iter; left time: 527.8270s
Epoch: 34 cost time: 8.350315809249878
Epoch: 34, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5729 + XiCon Loss:2.8190 x Lambda(0.1)), Vali MSE Loss: 1.0777 Test MSE Loss: 1.1358
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.8520807
	speed: 0.0358s/iter; left time: 547.2338s
	iters: 200, epoch: 35 | loss: 0.8681263
	speed: 0.0330s/iter; left time: 500.7118s
Epoch: 35 cost time: 8.00141954421997
Epoch: 35, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5727 + XiCon Loss:2.8228 x Lambda(0.1)), Vali MSE Loss: 1.0773 Test MSE Loss: 1.1358
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3938391208648682, mae:0.8778255581855774, mape:6.114231109619141, mspe:4484.07958984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.9191
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.4313798
	speed: 0.0323s/iter; left time: 750.1148s
	iters: 200, epoch: 1 | loss: 1.2488630
	speed: 0.0285s/iter; left time: 657.3653s
Epoch: 1 cost time: 7.058247089385986
Epoch: 1, Steps: 233 Train Loss: 1.2984 (Forecasting Loss:1.0137 + XiCon Loss:2.8473 x Lambda(0.1)), Vali MSE Loss: 1.8334 Test MSE Loss: 1.2546
Validation loss decreased (inf --> 1.833362).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9251966
	speed: 0.0308s/iter; left time: 706.2824s
	iters: 200, epoch: 2 | loss: 0.8408725
	speed: 0.0276s/iter; left time: 631.2604s
Epoch: 2 cost time: 6.821299076080322
Epoch: 2, Steps: 233 Train Loss: 0.9365 (Forecasting Loss:0.6530 + XiCon Loss:2.8349 x Lambda(0.1)), Vali MSE Loss: 1.1222 Test MSE Loss: 1.1458
Validation loss decreased (1.833362 --> 1.122224).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8572621
	speed: 0.0310s/iter; left time: 704.8611s
	iters: 200, epoch: 3 | loss: 0.8455147
	speed: 0.0287s/iter; left time: 649.1920s
Epoch: 3 cost time: 6.954176902770996
Epoch: 3, Steps: 233 Train Loss: 0.8699 (Forecasting Loss:0.5887 + XiCon Loss:2.8123 x Lambda(0.1)), Vali MSE Loss: 1.1012 Test MSE Loss: 1.1377
Validation loss decreased (1.122224 --> 1.101236).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8983883
	speed: 0.0302s/iter; left time: 679.2810s
	iters: 200, epoch: 4 | loss: 0.8765453
	speed: 0.0282s/iter; left time: 632.4747s
Epoch: 4 cost time: 6.823911190032959
Epoch: 4, Steps: 233 Train Loss: 0.8607 (Forecasting Loss:0.5803 + XiCon Loss:2.8042 x Lambda(0.1)), Vali MSE Loss: 1.0932 Test MSE Loss: 1.1358
Validation loss decreased (1.101236 --> 1.093233).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8221604
	speed: 0.0322s/iter; left time: 716.6861s
	iters: 200, epoch: 5 | loss: 0.8116323
	speed: 0.0280s/iter; left time: 619.8128s
Epoch: 5 cost time: 6.989985942840576
Epoch: 5, Steps: 233 Train Loss: 0.8565 (Forecasting Loss:0.5769 + XiCon Loss:2.7967 x Lambda(0.1)), Vali MSE Loss: 1.0894 Test MSE Loss: 1.1351
Validation loss decreased (1.093233 --> 1.089450).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8604746
	speed: 0.0313s/iter; left time: 690.5447s
	iters: 200, epoch: 6 | loss: 0.8680217
	speed: 0.0286s/iter; left time: 626.4534s
Epoch: 6 cost time: 6.9492528438568115
Epoch: 6, Steps: 233 Train Loss: 0.8552 (Forecasting Loss:0.5752 + XiCon Loss:2.7994 x Lambda(0.1)), Vali MSE Loss: 1.0878 Test MSE Loss: 1.1348
Validation loss decreased (1.089450 --> 1.087779).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8058364
	speed: 0.0326s/iter; left time: 710.5253s
	iters: 200, epoch: 7 | loss: 0.9009713
	speed: 0.0272s/iter; left time: 590.8760s
Epoch: 7 cost time: 6.8842432498931885
Epoch: 7, Steps: 233 Train Loss: 0.8538 (Forecasting Loss:0.5745 + XiCon Loss:2.7934 x Lambda(0.1)), Vali MSE Loss: 1.0869 Test MSE Loss: 1.1346
Validation loss decreased (1.087779 --> 1.086926).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8518461
	speed: 0.0310s/iter; left time: 669.1214s
	iters: 200, epoch: 8 | loss: 0.8354584
	speed: 0.0282s/iter; left time: 606.4538s
Epoch: 8 cost time: 6.781286954879761
Epoch: 8, Steps: 233 Train Loss: 0.8532 (Forecasting Loss:0.5740 + XiCon Loss:2.7919 x Lambda(0.1)), Vali MSE Loss: 1.0865 Test MSE Loss: 1.1346
Validation loss decreased (1.086926 --> 1.086499).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8746246
	speed: 0.0309s/iter; left time: 659.2097s
	iters: 200, epoch: 9 | loss: 0.8335099
	speed: 0.0287s/iter; left time: 610.4744s
Epoch: 9 cost time: 6.8948705196380615
Epoch: 9, Steps: 233 Train Loss: 0.8539 (Forecasting Loss:0.5738 + XiCon Loss:2.8005 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
Validation loss decreased (1.086499 --> 1.086163).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8226578
	speed: 0.0325s/iter; left time: 685.1523s
	iters: 200, epoch: 10 | loss: 0.8564993
	speed: 0.0300s/iter; left time: 630.4266s
Epoch: 10 cost time: 7.225998401641846
Epoch: 10, Steps: 233 Train Loss: 0.8534 (Forecasting Loss:0.5738 + XiCon Loss:2.7960 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8506979
	speed: 0.0327s/iter; left time: 682.7033s
	iters: 200, epoch: 11 | loss: 0.8620758
	speed: 0.0293s/iter; left time: 608.0417s
Epoch: 11 cost time: 7.1841514110565186
Epoch: 11, Steps: 233 Train Loss: 0.8529 (Forecasting Loss:0.5737 + XiCon Loss:2.7912 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
Validation loss decreased (1.086163 --> 1.086075).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8207927
	speed: 0.0328s/iter; left time: 676.5904s
	iters: 200, epoch: 12 | loss: 0.8280748
	speed: 0.0289s/iter; left time: 593.6874s
Epoch: 12 cost time: 7.207561254501343
Epoch: 12, Steps: 233 Train Loss: 0.8528 (Forecasting Loss:0.5736 + XiCon Loss:2.7918 x Lambda(0.1)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1345
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8971071
	speed: 0.0319s/iter; left time: 650.2371s
	iters: 200, epoch: 13 | loss: 0.8471309
	speed: 0.0301s/iter; left time: 610.4341s
Epoch: 13 cost time: 7.079802751541138
Epoch: 13, Steps: 233 Train Loss: 0.8531 (Forecasting Loss:0.5737 + XiCon Loss:2.7943 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8562205
	speed: 0.0314s/iter; left time: 632.8942s
	iters: 200, epoch: 14 | loss: 0.8761560
	speed: 0.0299s/iter; left time: 599.5560s
Epoch: 14 cost time: 7.182372093200684
Epoch: 14, Steps: 233 Train Loss: 0.8527 (Forecasting Loss:0.5736 + XiCon Loss:2.7908 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8114954
	speed: 0.0327s/iter; left time: 652.3094s
	iters: 200, epoch: 15 | loss: 0.8598617
	speed: 0.0285s/iter; left time: 565.5351s
Epoch: 15 cost time: 7.114818811416626
Epoch: 15, Steps: 233 Train Loss: 0.8529 (Forecasting Loss:0.5737 + XiCon Loss:2.7919 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8544098
	speed: 0.0321s/iter; left time: 631.9251s
	iters: 200, epoch: 16 | loss: 0.8436906
	speed: 0.0265s/iter; left time: 520.0018s
Epoch: 16 cost time: 6.779895305633545
Epoch: 16, Steps: 233 Train Loss: 0.8531 (Forecasting Loss:0.5737 + XiCon Loss:2.7940 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8023517
	speed: 0.0295s/iter; left time: 574.0602s
	iters: 200, epoch: 17 | loss: 0.8248038
	speed: 0.0260s/iter; left time: 504.4964s
Epoch: 17 cost time: 6.473327159881592
Epoch: 17, Steps: 233 Train Loss: 0.8531 (Forecasting Loss:0.5737 + XiCon Loss:2.7941 x Lambda(0.1)), Vali MSE Loss: 1.0860 Test MSE Loss: 1.1345
Validation loss decreased (1.086075 --> 1.086043).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8569961
	speed: 0.0301s/iter; left time: 578.4608s
	iters: 200, epoch: 18 | loss: 0.8354212
	speed: 0.0261s/iter; left time: 500.0073s
Epoch: 18 cost time: 6.540401220321655
Epoch: 18, Steps: 233 Train Loss: 0.8526 (Forecasting Loss:0.5736 + XiCon Loss:2.7895 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8423333
	speed: 0.0293s/iter; left time: 557.5879s
	iters: 200, epoch: 19 | loss: 0.8693342
	speed: 0.0267s/iter; left time: 504.7286s
Epoch: 19 cost time: 6.501798868179321
Epoch: 19, Steps: 233 Train Loss: 0.8531 (Forecasting Loss:0.5736 + XiCon Loss:2.7945 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8733553
	speed: 0.0280s/iter; left time: 524.8453s
	iters: 200, epoch: 20 | loss: 0.8280246
	speed: 0.0248s/iter; left time: 462.2903s
Epoch: 20 cost time: 6.134007453918457
Epoch: 20, Steps: 233 Train Loss: 0.8529 (Forecasting Loss:0.5737 + XiCon Loss:2.7922 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.9328523
	speed: 0.0278s/iter; left time: 515.4714s
	iters: 200, epoch: 21 | loss: 0.7961690
	speed: 0.0254s/iter; left time: 468.8354s
Epoch: 21 cost time: 6.170105695724487
Epoch: 21, Steps: 233 Train Loss: 0.8534 (Forecasting Loss:0.5736 + XiCon Loss:2.7979 x Lambda(0.1)), Vali MSE Loss: 1.0859 Test MSE Loss: 1.1345
Validation loss decreased (1.086043 --> 1.085923).  Saving model ...
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8052348
	speed: 0.0284s/iter; left time: 519.1877s
	iters: 200, epoch: 22 | loss: 0.8422849
	speed: 0.0249s/iter; left time: 452.9582s
Epoch: 22 cost time: 6.181593179702759
Epoch: 22, Steps: 233 Train Loss: 0.8531 (Forecasting Loss:0.5736 + XiCon Loss:2.7950 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8470037
	speed: 0.0277s/iter; left time: 500.4142s
	iters: 200, epoch: 23 | loss: 0.9008323
	speed: 0.0245s/iter; left time: 440.5639s
Epoch: 23 cost time: 6.136070251464844
Epoch: 23, Steps: 233 Train Loss: 0.8527 (Forecasting Loss:0.5736 + XiCon Loss:2.7907 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8080347
	speed: 0.0304s/iter; left time: 542.2581s
	iters: 200, epoch: 24 | loss: 0.8681172
	speed: 0.0282s/iter; left time: 500.3782s
Epoch: 24 cost time: 6.777389287948608
Epoch: 24, Steps: 233 Train Loss: 0.8530 (Forecasting Loss:0.5736 + XiCon Loss:2.7932 x Lambda(0.1)), Vali MSE Loss: 1.0863 Test MSE Loss: 1.1345
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.9078678
	speed: 0.0302s/iter; left time: 531.9720s
	iters: 200, epoch: 25 | loss: 0.7810872
	speed: 0.0271s/iter; left time: 473.7187s
Epoch: 25 cost time: 6.675729036331177
Epoch: 25, Steps: 233 Train Loss: 0.8527 (Forecasting Loss:0.5737 + XiCon Loss:2.7906 x Lambda(0.1)), Vali MSE Loss: 1.0860 Test MSE Loss: 1.1345
EarlyStopping counter: 4 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8726702
	speed: 0.0308s/iter; left time: 535.0600s
	iters: 200, epoch: 26 | loss: 0.8590599
	speed: 0.0278s/iter; left time: 479.4339s
Epoch: 26 cost time: 6.831488370895386
Epoch: 26, Steps: 233 Train Loss: 0.8525 (Forecasting Loss:0.5737 + XiCon Loss:2.7889 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.8493767
	speed: 0.0315s/iter; left time: 540.6035s
	iters: 200, epoch: 27 | loss: 0.8889561
	speed: 0.0274s/iter; left time: 467.0104s
Epoch: 27 cost time: 6.80621075630188
Epoch: 27, Steps: 233 Train Loss: 0.8521 (Forecasting Loss:0.5736 + XiCon Loss:2.7858 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.8432299
	speed: 0.0315s/iter; left time: 532.2006s
	iters: 200, epoch: 28 | loss: 0.8604711
	speed: 0.0277s/iter; left time: 465.0014s
Epoch: 28 cost time: 6.774772882461548
Epoch: 28, Steps: 233 Train Loss: 0.8530 (Forecasting Loss:0.5736 + XiCon Loss:2.7941 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 7 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.8296615
	speed: 0.0302s/iter; left time: 503.4452s
	iters: 200, epoch: 29 | loss: 0.8515463
	speed: 0.0274s/iter; left time: 455.0369s
Epoch: 29 cost time: 6.756997585296631
Epoch: 29, Steps: 233 Train Loss: 0.8533 (Forecasting Loss:0.5736 + XiCon Loss:2.7971 x Lambda(0.1)), Vali MSE Loss: 1.0862 Test MSE Loss: 1.1345
EarlyStopping counter: 8 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.8648541
	speed: 0.0300s/iter; left time: 493.4244s
	iters: 200, epoch: 30 | loss: 0.8053505
	speed: 0.0268s/iter; left time: 437.7007s
Epoch: 30 cost time: 6.59704065322876
Epoch: 30, Steps: 233 Train Loss: 0.8528 (Forecasting Loss:0.5736 + XiCon Loss:2.7928 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.8085688
	speed: 0.0311s/iter; left time: 503.3672s
	iters: 200, epoch: 31 | loss: 0.8387890
	speed: 0.0276s/iter; left time: 444.7175s
Epoch: 31 cost time: 6.737637758255005
Epoch: 31, Steps: 233 Train Loss: 0.8530 (Forecasting Loss:0.5737 + XiCon Loss:2.7938 x Lambda(0.1)), Vali MSE Loss: 1.0861 Test MSE Loss: 1.1345
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3905205726623535, mae:0.878459632396698, mape:6.154521942138672, mspe:4532.7138671875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.3959
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.3068808
	speed: 0.0307s/iter; left time: 711.5206s
	iters: 200, epoch: 1 | loss: 1.2693650
	speed: 0.0271s/iter; left time: 625.9961s
Epoch: 1 cost time: 6.701830148696899
Epoch: 1, Steps: 233 Train Loss: 1.3144 (Forecasting Loss:1.0277 + XiCon Loss:2.8669 x Lambda(0.1)), Vali MSE Loss: 1.8646 Test MSE Loss: 1.2525
Validation loss decreased (inf --> 1.864578).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9060869
	speed: 0.0303s/iter; left time: 696.2535s
	iters: 200, epoch: 2 | loss: 0.8842900
	speed: 0.0271s/iter; left time: 620.3031s
Epoch: 2 cost time: 6.695608854293823
Epoch: 2, Steps: 233 Train Loss: 0.9397 (Forecasting Loss:0.6548 + XiCon Loss:2.8492 x Lambda(0.1)), Vali MSE Loss: 1.1221 Test MSE Loss: 1.1476
Validation loss decreased (1.864578 --> 1.122066).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8820391
	speed: 0.0311s/iter; left time: 707.4832s
	iters: 200, epoch: 3 | loss: 0.9245008
	speed: 0.0272s/iter; left time: 615.9421s
Epoch: 3 cost time: 6.764355421066284
Epoch: 3, Steps: 233 Train Loss: 0.8723 (Forecasting Loss:0.5897 + XiCon Loss:2.8256 x Lambda(0.1)), Vali MSE Loss: 1.1038 Test MSE Loss: 1.1406
Validation loss decreased (1.122066 --> 1.103805).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8253545
	speed: 0.0302s/iter; left time: 680.6482s
	iters: 200, epoch: 4 | loss: 0.8865326
	speed: 0.0273s/iter; left time: 612.5367s
Epoch: 4 cost time: 6.692788600921631
Epoch: 4, Steps: 233 Train Loss: 0.8625 (Forecasting Loss:0.5817 + XiCon Loss:2.8079 x Lambda(0.1)), Vali MSE Loss: 1.0969 Test MSE Loss: 1.1384
Validation loss decreased (1.103805 --> 1.096919).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8306081
	speed: 0.0310s/iter; left time: 690.1522s
	iters: 200, epoch: 5 | loss: 0.8417755
	speed: 0.0275s/iter; left time: 609.4899s
Epoch: 5 cost time: 6.830668926239014
Epoch: 5, Steps: 233 Train Loss: 0.8585 (Forecasting Loss:0.5784 + XiCon Loss:2.8008 x Lambda(0.1)), Vali MSE Loss: 1.0943 Test MSE Loss: 1.1377
Validation loss decreased (1.096919 --> 1.094288).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8380049
	speed: 0.0301s/iter; left time: 662.3582s
	iters: 200, epoch: 6 | loss: 0.8847524
	speed: 0.0277s/iter; left time: 608.2501s
Epoch: 6 cost time: 6.720200061798096
Epoch: 6, Steps: 233 Train Loss: 0.8572 (Forecasting Loss:0.5769 + XiCon Loss:2.8024 x Lambda(0.1)), Vali MSE Loss: 1.0929 Test MSE Loss: 1.1375
Validation loss decreased (1.094288 --> 1.092893).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8665619
	speed: 0.0307s/iter; left time: 669.0500s
	iters: 200, epoch: 7 | loss: 0.8856944
	speed: 0.0269s/iter; left time: 584.0601s
Epoch: 7 cost time: 6.6508543491363525
Epoch: 7, Steps: 233 Train Loss: 0.8557 (Forecasting Loss:0.5762 + XiCon Loss:2.7951 x Lambda(0.1)), Vali MSE Loss: 1.0921 Test MSE Loss: 1.1374
Validation loss decreased (1.092893 --> 1.092112).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8792993
	speed: 0.0298s/iter; left time: 642.3667s
	iters: 200, epoch: 8 | loss: 0.8493934
	speed: 0.0267s/iter; left time: 573.3118s
Epoch: 8 cost time: 6.687934875488281
Epoch: 8, Steps: 233 Train Loss: 0.8552 (Forecasting Loss:0.5758 + XiCon Loss:2.7934 x Lambda(0.1)), Vali MSE Loss: 1.0919 Test MSE Loss: 1.1373
Validation loss decreased (1.092112 --> 1.091936).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8748785
	speed: 0.0306s/iter; left time: 653.4780s
	iters: 200, epoch: 9 | loss: 0.9117109
	speed: 0.0283s/iter; left time: 600.5957s
Epoch: 9 cost time: 6.8137047290802
Epoch: 9, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5755 + XiCon Loss:2.7926 x Lambda(0.1)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1373
Validation loss decreased (1.091936 --> 1.091529).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8705853
	speed: 0.0296s/iter; left time: 624.9019s
	iters: 200, epoch: 10 | loss: 0.8372654
	speed: 0.0270s/iter; left time: 567.4185s
Epoch: 10 cost time: 6.588115692138672
Epoch: 10, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5754 + XiCon Loss:2.7959 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
Validation loss decreased (1.091529 --> 1.091420).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8471445
	speed: 0.0308s/iter; left time: 643.5481s
	iters: 200, epoch: 11 | loss: 0.8591881
	speed: 0.0268s/iter; left time: 557.2534s
Epoch: 11 cost time: 6.703257083892822
Epoch: 11, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5754 + XiCon Loss:2.7965 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
Validation loss decreased (1.091420 --> 1.091351).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8824707
	speed: 0.0296s/iter; left time: 611.2412s
	iters: 200, epoch: 12 | loss: 0.8053852
	speed: 0.0274s/iter; left time: 563.7291s
Epoch: 12 cost time: 6.613227128982544
Epoch: 12, Steps: 233 Train Loss: 0.8551 (Forecasting Loss:0.5753 + XiCon Loss:2.7976 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8739310
	speed: 0.0303s/iter; left time: 619.2313s
	iters: 200, epoch: 13 | loss: 0.8405777
	speed: 0.0266s/iter; left time: 539.4896s
Epoch: 13 cost time: 6.627889633178711
Epoch: 13, Steps: 233 Train Loss: 0.8545 (Forecasting Loss:0.5753 + XiCon Loss:2.7913 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8340888
	speed: 0.0310s/iter; left time: 625.5214s
	iters: 200, epoch: 14 | loss: 0.9125974
	speed: 0.0270s/iter; left time: 541.7722s
Epoch: 14 cost time: 6.784473419189453
Epoch: 14, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5753 + XiCon Loss:2.7941 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8859503
	speed: 0.0299s/iter; left time: 595.4985s
	iters: 200, epoch: 15 | loss: 0.8602254
	speed: 0.0269s/iter; left time: 533.2199s
Epoch: 15 cost time: 6.585430383682251
Epoch: 15, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5753 + XiCon Loss:2.7942 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8612202
	speed: 0.0298s/iter; left time: 586.7209s
	iters: 200, epoch: 16 | loss: 0.8666705
	speed: 0.0270s/iter; left time: 530.1842s
Epoch: 16 cost time: 6.614255905151367
Epoch: 16, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5753 + XiCon Loss:2.7951 x Lambda(0.1)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1372
Validation loss decreased (1.091351 --> 1.091117).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.7678547
	speed: 0.0312s/iter; left time: 607.7742s
	iters: 200, epoch: 17 | loss: 0.9420637
	speed: 0.0270s/iter; left time: 522.8013s
Epoch: 17 cost time: 6.723597764968872
Epoch: 17, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5753 + XiCon Loss:2.7967 x Lambda(0.1)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1372
Validation loss decreased (1.091117 --> 1.091113).  Saving model ...
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8532795
	speed: 0.0304s/iter; left time: 584.6875s
	iters: 200, epoch: 18 | loss: 0.8455741
	speed: 0.0275s/iter; left time: 525.7748s
Epoch: 18 cost time: 6.704751253128052
Epoch: 18, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5753 + XiCon Loss:2.7953 x Lambda(0.1)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1372
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8689359
	speed: 0.0309s/iter; left time: 587.5058s
	iters: 200, epoch: 19 | loss: 0.9218974
	speed: 0.0271s/iter; left time: 512.1478s
Epoch: 19 cost time: 6.771160125732422
Epoch: 19, Steps: 233 Train Loss: 0.8548 (Forecasting Loss:0.5753 + XiCon Loss:2.7948 x Lambda(0.1)), Vali MSE Loss: 1.0911 Test MSE Loss: 1.1372
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.9186299
	speed: 0.0303s/iter; left time: 568.7011s
	iters: 200, epoch: 20 | loss: 0.8768396
	speed: 0.0273s/iter; left time: 510.3254s
Epoch: 20 cost time: 6.705576419830322
Epoch: 20, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5753 + XiCon Loss:2.7972 x Lambda(0.1)), Vali MSE Loss: 1.0914 Test MSE Loss: 1.1372
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8332412
	speed: 0.0306s/iter; left time: 567.8017s
	iters: 200, epoch: 21 | loss: 0.8480115
	speed: 0.0267s/iter; left time: 492.3442s
Epoch: 21 cost time: 6.587249279022217
Epoch: 21, Steps: 233 Train Loss: 0.8541 (Forecasting Loss:0.5753 + XiCon Loss:2.7881 x Lambda(0.1)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1372
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8657033
	speed: 0.0294s/iter; left time: 538.4366s
	iters: 200, epoch: 22 | loss: 0.8124116
	speed: 0.0270s/iter; left time: 492.4283s
Epoch: 22 cost time: 6.619282245635986
Epoch: 22, Steps: 233 Train Loss: 0.8546 (Forecasting Loss:0.5753 + XiCon Loss:2.7925 x Lambda(0.1)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1372
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8243599
	speed: 0.0311s/iter; left time: 562.1707s
	iters: 200, epoch: 23 | loss: 0.8622704
	speed: 0.0276s/iter; left time: 495.3795s
Epoch: 23 cost time: 6.818688869476318
Epoch: 23, Steps: 233 Train Loss: 0.8545 (Forecasting Loss:0.5752 + XiCon Loss:2.7923 x Lambda(0.1)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1372
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8510901
	speed: 0.0295s/iter; left time: 525.6914s
	iters: 200, epoch: 24 | loss: 0.8705868
	speed: 0.0276s/iter; left time: 488.9879s
Epoch: 24 cost time: 6.5615315437316895
Epoch: 24, Steps: 233 Train Loss: 0.8541 (Forecasting Loss:0.5753 + XiCon Loss:2.7880 x Lambda(0.1)), Vali MSE Loss: 1.0913 Test MSE Loss: 1.1372
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8194256
	speed: 0.0282s/iter; left time: 496.0682s
	iters: 200, epoch: 25 | loss: 0.8558238
	speed: 0.0249s/iter; left time: 436.3801s
Epoch: 25 cost time: 6.161350250244141
Epoch: 25, Steps: 233 Train Loss: 0.8547 (Forecasting Loss:0.5753 + XiCon Loss:2.7941 x Lambda(0.1)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1372
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8971779
	speed: 0.0278s/iter; left time: 483.8758s
	iters: 200, epoch: 26 | loss: 0.8634090
	speed: 0.0251s/iter; left time: 434.3510s
Epoch: 26 cost time: 6.167200803756714
Epoch: 26, Steps: 233 Train Loss: 0.8550 (Forecasting Loss:0.5752 + XiCon Loss:2.7970 x Lambda(0.1)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1372
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.8859385
	speed: 0.0280s/iter; left time: 479.5218s
	iters: 200, epoch: 27 | loss: 0.8201903
	speed: 0.0247s/iter; left time: 420.6881s
Epoch: 27 cost time: 6.108217716217041
Epoch: 27, Steps: 233 Train Loss: 0.8544 (Forecasting Loss:0.5753 + XiCon Loss:2.7914 x Lambda(0.1)), Vali MSE Loss: 1.0915 Test MSE Loss: 1.1372
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.3958745002746582, mae:0.8785854578018188, mape:6.129356384277344, mspe:4520.875 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:971969
train 29842
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.0736
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29842
val 9101
test 9100
	iters: 100, epoch: 1 | loss: 1.4142146
	speed: 0.0294s/iter; left time: 681.9007s
	iters: 200, epoch: 1 | loss: 1.2791361
	speed: 0.0250s/iter; left time: 577.2728s
Epoch: 1 cost time: 6.300394296646118
Epoch: 1, Steps: 233 Train Loss: 1.3108 (Forecasting Loss:1.0267 + XiCon Loss:2.8406 x Lambda(0.1)), Vali MSE Loss: 1.8512 Test MSE Loss: 1.2635
Validation loss decreased (inf --> 1.851171).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8735585
	speed: 0.0295s/iter; left time: 678.1876s
	iters: 200, epoch: 2 | loss: 0.8924712
	speed: 0.0248s/iter; left time: 567.5079s
Epoch: 2 cost time: 6.266016244888306
Epoch: 2, Steps: 233 Train Loss: 0.9347 (Forecasting Loss:0.6511 + XiCon Loss:2.8358 x Lambda(0.1)), Vali MSE Loss: 1.1126 Test MSE Loss: 1.1478
Validation loss decreased (1.851171 --> 1.112636).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8347158
	speed: 0.0333s/iter; left time: 757.2111s
	iters: 200, epoch: 3 | loss: 0.8503603
	speed: 0.0272s/iter; left time: 616.0745s
Epoch: 3 cost time: 6.901593923568726
Epoch: 3, Steps: 233 Train Loss: 0.8683 (Forecasting Loss:0.5862 + XiCon Loss:2.8210 x Lambda(0.1)), Vali MSE Loss: 1.0866 Test MSE Loss: 1.1434
Validation loss decreased (1.112636 --> 1.086609).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8526921
	speed: 0.0321s/iter; left time: 721.6954s
	iters: 200, epoch: 4 | loss: 0.8086826
	speed: 0.0269s/iter; left time: 601.5360s
Epoch: 4 cost time: 6.881971120834351
Epoch: 4, Steps: 233 Train Loss: 0.8590 (Forecasting Loss:0.5774 + XiCon Loss:2.8157 x Lambda(0.1)), Vali MSE Loss: 1.0758 Test MSE Loss: 1.1424
Validation loss decreased (1.086609 --> 1.075825).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8314465
	speed: 0.0324s/iter; left time: 721.7916s
	iters: 200, epoch: 5 | loss: 0.8823910
	speed: 0.0271s/iter; left time: 600.2397s
Epoch: 5 cost time: 6.8823323249816895
Epoch: 5, Steps: 233 Train Loss: 0.8554 (Forecasting Loss:0.5737 + XiCon Loss:2.8165 x Lambda(0.1)), Vali MSE Loss: 1.0706 Test MSE Loss: 1.1426
Validation loss decreased (1.075825 --> 1.070643).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8870504
	speed: 0.0309s/iter; left time: 680.2870s
	iters: 200, epoch: 6 | loss: 0.7973871
	speed: 0.0278s/iter; left time: 609.4496s
Epoch: 6 cost time: 6.707726240158081
Epoch: 6, Steps: 233 Train Loss: 0.8535 (Forecasting Loss:0.5720 + XiCon Loss:2.8156 x Lambda(0.1)), Vali MSE Loss: 1.0680 Test MSE Loss: 1.1425
Validation loss decreased (1.070643 --> 1.068031).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8285502
	speed: 0.0307s/iter; left time: 670.3142s
	iters: 200, epoch: 7 | loss: 0.8598552
	speed: 0.0273s/iter; left time: 593.1337s
Epoch: 7 cost time: 6.779510259628296
Epoch: 7, Steps: 233 Train Loss: 0.8528 (Forecasting Loss:0.5711 + XiCon Loss:2.8169 x Lambda(0.1)), Vali MSE Loss: 1.0666 Test MSE Loss: 1.1426
Validation loss decreased (1.068031 --> 1.066640).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8555574
	speed: 0.0313s/iter; left time: 674.4786s
	iters: 200, epoch: 8 | loss: 0.8528785
	speed: 0.0283s/iter; left time: 607.4680s
Epoch: 8 cost time: 6.894082546234131
Epoch: 8, Steps: 233 Train Loss: 0.8520 (Forecasting Loss:0.5707 + XiCon Loss:2.8130 x Lambda(0.1)), Vali MSE Loss: 1.0658 Test MSE Loss: 1.1427
Validation loss decreased (1.066640 --> 1.065846).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8713507
	speed: 0.0311s/iter; left time: 663.3766s
	iters: 200, epoch: 9 | loss: 0.8381323
	speed: 0.0274s/iter; left time: 582.5837s
Epoch: 9 cost time: 6.7619240283966064
Epoch: 9, Steps: 233 Train Loss: 0.8518 (Forecasting Loss:0.5703 + XiCon Loss:2.8147 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1428
Validation loss decreased (1.065846 --> 1.065348).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8676449
	speed: 0.0314s/iter; left time: 661.8199s
	iters: 200, epoch: 10 | loss: 0.8363250
	speed: 0.0274s/iter; left time: 574.7812s
Epoch: 10 cost time: 6.777585029602051
Epoch: 10, Steps: 233 Train Loss: 0.8516 (Forecasting Loss:0.5702 + XiCon Loss:2.8132 x Lambda(0.1)), Vali MSE Loss: 1.0655 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8727174
	speed: 0.0311s/iter; left time: 649.7537s
	iters: 200, epoch: 11 | loss: 0.8413754
	speed: 0.0278s/iter; left time: 577.4522s
Epoch: 11 cost time: 6.732956409454346
Epoch: 11, Steps: 233 Train Loss: 0.8516 (Forecasting Loss:0.5702 + XiCon Loss:2.8140 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1428
Validation loss decreased (1.065348 --> 1.065335).  Saving model ...
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8528838
	speed: 0.0308s/iter; left time: 635.8203s
	iters: 200, epoch: 12 | loss: 0.8551226
	speed: 0.0268s/iter; left time: 550.0275s
Epoch: 12 cost time: 6.736916780471802
Epoch: 12, Steps: 233 Train Loss: 0.8517 (Forecasting Loss:0.5702 + XiCon Loss:2.8147 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
Validation loss decreased (1.065335 --> 1.065207).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8481277
	speed: 0.0316s/iter; left time: 644.8222s
	iters: 200, epoch: 13 | loss: 0.8345749
	speed: 0.0276s/iter; left time: 561.3838s
Epoch: 13 cost time: 6.919375896453857
Epoch: 13, Steps: 233 Train Loss: 0.8511 (Forecasting Loss:0.5702 + XiCon Loss:2.8093 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8679060
	speed: 0.0316s/iter; left time: 638.1707s
	iters: 200, epoch: 14 | loss: 0.8351065
	speed: 0.0278s/iter; left time: 558.3217s
Epoch: 14 cost time: 6.860635280609131
Epoch: 14, Steps: 233 Train Loss: 0.8520 (Forecasting Loss:0.5701 + XiCon Loss:2.8184 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
Validation loss decreased (1.065207 --> 1.065189).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8724667
	speed: 0.0317s/iter; left time: 632.8287s
	iters: 200, epoch: 15 | loss: 0.8179823
	speed: 0.0271s/iter; left time: 537.9687s
Epoch: 15 cost time: 6.855112075805664
Epoch: 15, Steps: 233 Train Loss: 0.8514 (Forecasting Loss:0.5701 + XiCon Loss:2.8127 x Lambda(0.1)), Vali MSE Loss: 1.0654 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8930188
	speed: 0.0319s/iter; left time: 629.2648s
	iters: 200, epoch: 16 | loss: 0.8454353
	speed: 0.0270s/iter; left time: 530.1117s
Epoch: 16 cost time: 6.75874400138855
Epoch: 16, Steps: 233 Train Loss: 0.8519 (Forecasting Loss:0.5702 + XiCon Loss:2.8174 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
Validation loss decreased (1.065189 --> 1.065174).  Saving model ...
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8706156
	speed: 0.0299s/iter; left time: 582.1186s
	iters: 200, epoch: 17 | loss: 0.8504430
	speed: 0.0271s/iter; left time: 524.1297s
Epoch: 17 cost time: 6.6587231159210205
Epoch: 17, Steps: 233 Train Loss: 0.8512 (Forecasting Loss:0.5700 + XiCon Loss:2.8112 x Lambda(0.1)), Vali MSE Loss: 1.0654 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8422972
	speed: 0.0326s/iter; left time: 627.6638s
	iters: 200, epoch: 18 | loss: 0.8998061
	speed: 0.0274s/iter; left time: 525.0355s
Epoch: 18 cost time: 6.968037366867065
Epoch: 18, Steps: 233 Train Loss: 0.8516 (Forecasting Loss:0.5702 + XiCon Loss:2.8143 x Lambda(0.1)), Vali MSE Loss: 1.0651 Test MSE Loss: 1.1427
Validation loss decreased (1.065174 --> 1.065131).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8572520
	speed: 0.0310s/iter; left time: 589.6287s
	iters: 200, epoch: 19 | loss: 0.8584824
	speed: 0.0277s/iter; left time: 523.2048s
Epoch: 19 cost time: 6.8016064167022705
Epoch: 19, Steps: 233 Train Loss: 0.8517 (Forecasting Loss:0.5701 + XiCon Loss:2.8161 x Lambda(0.1)), Vali MSE Loss: 1.0650 Test MSE Loss: 1.1427
Validation loss decreased (1.065131 --> 1.065049).  Saving model ...
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8291664
	speed: 0.0318s/iter; left time: 597.9083s
	iters: 200, epoch: 20 | loss: 0.8963283
	speed: 0.0277s/iter; left time: 516.4032s
Epoch: 20 cost time: 6.903971910476685
Epoch: 20, Steps: 233 Train Loss: 0.8511 (Forecasting Loss:0.5701 + XiCon Loss:2.8103 x Lambda(0.1)), Vali MSE Loss: 1.0651 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8422407
	speed: 0.0316s/iter; left time: 585.9696s
	iters: 200, epoch: 21 | loss: 0.8709575
	speed: 0.0275s/iter; left time: 507.9215s
Epoch: 21 cost time: 6.739690780639648
Epoch: 21, Steps: 233 Train Loss: 0.8517 (Forecasting Loss:0.5701 + XiCon Loss:2.8163 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8193969
	speed: 0.0308s/iter; left time: 563.2295s
	iters: 200, epoch: 22 | loss: 0.8474282
	speed: 0.0287s/iter; left time: 522.1298s
Epoch: 22 cost time: 6.803329944610596
Epoch: 22, Steps: 233 Train Loss: 0.8513 (Forecasting Loss:0.5701 + XiCon Loss:2.8120 x Lambda(0.1)), Vali MSE Loss: 1.0654 Test MSE Loss: 1.1427
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8202702
	speed: 0.0307s/iter; left time: 554.0407s
	iters: 200, epoch: 23 | loss: 0.8225987
	speed: 0.0268s/iter; left time: 481.8928s
Epoch: 23 cost time: 6.6585469245910645
Epoch: 23, Steps: 233 Train Loss: 0.8519 (Forecasting Loss:0.5701 + XiCon Loss:2.8173 x Lambda(0.1)), Vali MSE Loss: 1.0651 Test MSE Loss: 1.1427
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8378189
	speed: 0.0319s/iter; left time: 569.6228s
	iters: 200, epoch: 24 | loss: 0.8795149
	speed: 0.0272s/iter; left time: 482.9059s
Epoch: 24 cost time: 6.829202651977539
Epoch: 24, Steps: 233 Train Loss: 0.8514 (Forecasting Loss:0.5702 + XiCon Loss:2.8129 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8704542
	speed: 0.0324s/iter; left time: 571.4028s
	iters: 200, epoch: 25 | loss: 0.8523311
	speed: 0.0271s/iter; left time: 474.2275s
Epoch: 25 cost time: 6.89049506187439
Epoch: 25, Steps: 233 Train Loss: 0.8520 (Forecasting Loss:0.5701 + XiCon Loss:2.8186 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1427
EarlyStopping counter: 6 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8104594
	speed: 0.0313s/iter; left time: 544.0240s
	iters: 200, epoch: 26 | loss: 0.8337787
	speed: 0.0274s/iter; left time: 473.4423s
Epoch: 26 cost time: 6.7559239864349365
Epoch: 26, Steps: 233 Train Loss: 0.8517 (Forecasting Loss:0.5701 + XiCon Loss:2.8161 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 7 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.8468353
	speed: 0.0305s/iter; left time: 523.4041s
	iters: 200, epoch: 27 | loss: 0.8576155
	speed: 0.0278s/iter; left time: 473.6952s
Epoch: 27 cost time: 6.801064729690552
Epoch: 27, Steps: 233 Train Loss: 0.8521 (Forecasting Loss:0.5701 + XiCon Loss:2.8190 x Lambda(0.1)), Vali MSE Loss: 1.0650 Test MSE Loss: 1.1427
Validation loss decreased (1.065049 --> 1.065047).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.8818395
	speed: 0.0308s/iter; left time: 520.6555s
	iters: 200, epoch: 28 | loss: 0.8309766
	speed: 0.0269s/iter; left time: 452.5686s
Epoch: 28 cost time: 6.716672658920288
Epoch: 28, Steps: 233 Train Loss: 0.8519 (Forecasting Loss:0.5702 + XiCon Loss:2.8170 x Lambda(0.1)), Vali MSE Loss: 1.0650 Test MSE Loss: 1.1427
Validation loss decreased (1.065047 --> 1.065027).  Saving model ...
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.8525921
	speed: 0.0311s/iter; left time: 517.8591s
	iters: 200, epoch: 29 | loss: 0.8761145
	speed: 0.0278s/iter; left time: 461.3538s
Epoch: 29 cost time: 6.827193737030029
Epoch: 29, Steps: 233 Train Loss: 0.8511 (Forecasting Loss:0.5702 + XiCon Loss:2.8096 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.8758256
	speed: 0.0311s/iter; left time: 511.5494s
	iters: 200, epoch: 30 | loss: 0.8632972
	speed: 0.0273s/iter; left time: 446.8729s
Epoch: 30 cost time: 6.680434703826904
Epoch: 30, Steps: 233 Train Loss: 0.8519 (Forecasting Loss:0.5701 + XiCon Loss:2.8178 x Lambda(0.1)), Vali MSE Loss: 1.0648 Test MSE Loss: 1.1427
Validation loss decreased (1.065027 --> 1.064811).  Saving model ...
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.8377252
	speed: 0.0310s/iter; left time: 502.3815s
	iters: 200, epoch: 31 | loss: 0.9056084
	speed: 0.0278s/iter; left time: 447.6362s
Epoch: 31 cost time: 6.823643445968628
Epoch: 31, Steps: 233 Train Loss: 0.8514 (Forecasting Loss:0.5701 + XiCon Loss:2.8133 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1427
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.8426194
	speed: 0.0313s/iter; left time: 500.8628s
	iters: 200, epoch: 32 | loss: 0.8364481
	speed: 0.0271s/iter; left time: 430.0578s
Epoch: 32 cost time: 6.836527109146118
Epoch: 32, Steps: 233 Train Loss: 0.8514 (Forecasting Loss:0.5701 + XiCon Loss:2.8132 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.8669780
	speed: 0.0306s/iter; left time: 482.3457s
	iters: 200, epoch: 33 | loss: 0.8653455
	speed: 0.0271s/iter; left time: 423.6312s
Epoch: 33 cost time: 6.717719554901123
Epoch: 33, Steps: 233 Train Loss: 0.8517 (Forecasting Loss:0.5702 + XiCon Loss:2.8150 x Lambda(0.1)), Vali MSE Loss: 1.0653 Test MSE Loss: 1.1427
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.8664055
	speed: 0.0318s/iter; left time: 492.8968s
	iters: 200, epoch: 34 | loss: 0.8253661
	speed: 0.0269s/iter; left time: 415.1598s
Epoch: 34 cost time: 6.841781377792358
Epoch: 34, Steps: 233 Train Loss: 0.8518 (Forecasting Loss:0.5703 + XiCon Loss:2.8155 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.8739982
	speed: 0.0316s/iter; left time: 482.4413s
	iters: 200, epoch: 35 | loss: 0.8493972
	speed: 0.0279s/iter; left time: 423.4888s
Epoch: 35 cost time: 6.817636966705322
Epoch: 35, Steps: 233 Train Loss: 0.8513 (Forecasting Loss:0.5701 + XiCon Loss:2.8118 x Lambda(0.1)), Vali MSE Loss: 1.0654 Test MSE Loss: 1.1427
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.8790632
	speed: 0.0309s/iter; left time: 465.4754s
	iters: 200, epoch: 36 | loss: 0.8114974
	speed: 0.0269s/iter; left time: 402.2412s
Epoch: 36 cost time: 6.657468557357788
Epoch: 36, Steps: 233 Train Loss: 0.8510 (Forecasting Loss:0.5702 + XiCon Loss:2.8077 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.8897825
	speed: 0.0288s/iter; left time: 425.9519s
	iters: 200, epoch: 37 | loss: 0.8332323
	speed: 0.0250s/iter; left time: 367.8730s
Epoch: 37 cost time: 6.24291467666626
Epoch: 37, Steps: 233 Train Loss: 0.8520 (Forecasting Loss:0.5701 + XiCon Loss:2.8183 x Lambda(0.1)), Vali MSE Loss: 1.0652 Test MSE Loss: 1.1427
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4551915228366853e-15
	iters: 100, epoch: 38 | loss: 0.8614922
	speed: 0.0281s/iter; left time: 409.5419s
	iters: 200, epoch: 38 | loss: 0.8889832
	speed: 0.0249s/iter; left time: 360.5539s
Epoch: 38 cost time: 6.152971506118774
Epoch: 38, Steps: 233 Train Loss: 0.8521 (Forecasting Loss:0.5702 + XiCon Loss:2.8188 x Lambda(0.1)), Vali MSE Loss: 1.0651 Test MSE Loss: 1.1427
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.275957614183426e-16
	iters: 100, epoch: 39 | loss: 0.8851880
	speed: 0.0287s/iter; left time: 412.3138s
	iters: 200, epoch: 39 | loss: 0.8187428
	speed: 0.0254s/iter; left time: 361.6292s
Epoch: 39 cost time: 6.283583402633667
Epoch: 39, Steps: 233 Train Loss: 0.8514 (Forecasting Loss:0.5702 + XiCon Loss:2.8121 x Lambda(0.1)), Vali MSE Loss: 1.0654 Test MSE Loss: 1.1427
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.637978807091713e-16
	iters: 100, epoch: 40 | loss: 0.7835416
	speed: 0.0293s/iter; left time: 413.2319s
	iters: 200, epoch: 40 | loss: 0.8170838
	speed: 0.0266s/iter; left time: 373.2239s
Epoch: 40 cost time: 6.456906318664551
Epoch: 40, Steps: 233 Train Loss: 0.8515 (Forecasting Loss:0.5701 + XiCon Loss:2.8146 x Lambda(0.1)), Vali MSE Loss: 1.0651 Test MSE Loss: 1.1427
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl1440_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 9100
test shape: (71, 128, 1440, 1) (71, 128, 1440, 1)
test shape: (9088, 1440, 1) (9088, 1440, 1)
mse:1.4025789499282837, mae:0.8829143047332764, mape:6.21936559677124, mspe:4650.25048828125 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.3962+-0.00564, MAE:0.8795+-0.00252, MAPE:6.1548+-0.04992, MSPE:4550.8584+-78.05520, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
Args in experiment:
Namespace(wnorm='ReVIN', lambda=0.1, multiscales=[720], train_ratio=0.6, save=False, task_name='long_term_forecast', is_training=1, model_id='XiCon_exp', model='XiCon', data='weather', root_path='./dataset/weather', data_path='weather.csv', features='S', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=336, label_len=48, pred_len=2160, seasonal_patterns='Monthly', mask_rate=0.25, anomaly_ratio=0.25, patch_len=16, stride=8, affine=0, subtract_last=0, mixer_kernel_size=8, head_dropout=0.0, top_k=5, num_kernels=6, enc_in=1, dec_in=7, c_out=1, d_model=8, n_heads=8, e_layers=2, d_layers=1, d_ff=8, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, num_workers=10, itr=5, train_epochs=100, batch_size=128, patience=10, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', pct_start=0.3, loss_flag=2, use_amp=False, cpu_worker=None, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', p_hidden_dims=[128, 128], p_hidden_layers=2, omega=0.3, XiCon=True, AutoCon=False)
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 16.8618
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.3732398
	speed: 0.0546s/iter; left time: 1234.3845s
	iters: 200, epoch: 1 | loss: 1.2700181
	speed: 0.0505s/iter; left time: 1137.2167s
Epoch: 1 cost time: 11.94255542755127
Epoch: 1, Steps: 227 Train Loss: 1.2956 (Forecasting Loss:1.0262 + XiCon Loss:2.6946 x Lambda(0.1)), Vali MSE Loss: 1.9360 Test MSE Loss: 1.3864
Validation loss decreased (inf --> 1.936023).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8975098
	speed: 0.0527s/iter; left time: 1178.9138s
	iters: 200, epoch: 2 | loss: 0.8808733
	speed: 0.0509s/iter; left time: 1133.7027s
Epoch: 2 cost time: 11.725842714309692
Epoch: 2, Steps: 227 Train Loss: 0.9374 (Forecasting Loss:0.6690 + XiCon Loss:2.6844 x Lambda(0.1)), Vali MSE Loss: 1.2112 Test MSE Loss: 1.2838
Validation loss decreased (1.936023 --> 1.211200).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8833808
	speed: 0.0521s/iter; left time: 1154.4813s
	iters: 200, epoch: 3 | loss: 0.8933349
	speed: 0.0500s/iter; left time: 1102.6121s
Epoch: 3 cost time: 11.602726221084595
Epoch: 3, Steps: 227 Train Loss: 0.8723 (Forecasting Loss:0.6062 + XiCon Loss:2.6610 x Lambda(0.1)), Vali MSE Loss: 1.1885 Test MSE Loss: 1.2755
Validation loss decreased (1.211200 --> 1.188455).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8465983
	speed: 0.0560s/iter; left time: 1227.1687s
	iters: 200, epoch: 4 | loss: 0.8370775
	speed: 0.0502s/iter; left time: 1095.8817s
Epoch: 4 cost time: 12.028285264968872
Epoch: 4, Steps: 227 Train Loss: 0.8628 (Forecasting Loss:0.5985 + XiCon Loss:2.6426 x Lambda(0.1)), Vali MSE Loss: 1.1826 Test MSE Loss: 1.2735
Validation loss decreased (1.188455 --> 1.182595).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8447491
	speed: 0.0542s/iter; left time: 1176.4143s
	iters: 200, epoch: 5 | loss: 0.8942808
	speed: 0.0519s/iter; left time: 1121.3954s
Epoch: 5 cost time: 11.98393964767456
Epoch: 5, Steps: 227 Train Loss: 0.8588 (Forecasting Loss:0.5955 + XiCon Loss:2.6333 x Lambda(0.1)), Vali MSE Loss: 1.1799 Test MSE Loss: 1.2725
Validation loss decreased (1.182595 --> 1.179853).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8464690
	speed: 0.0533s/iter; left time: 1144.9604s
	iters: 200, epoch: 6 | loss: 0.8700500
	speed: 0.0526s/iter; left time: 1124.0165s
Epoch: 6 cost time: 12.171884775161743
Epoch: 6, Steps: 227 Train Loss: 0.8562 (Forecasting Loss:0.5941 + XiCon Loss:2.6209 x Lambda(0.1)), Vali MSE Loss: 1.1780 Test MSE Loss: 1.2721
Validation loss decreased (1.179853 --> 1.177993).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8096747
	speed: 0.0535s/iter; left time: 1135.8924s
	iters: 200, epoch: 7 | loss: 0.8248435
	speed: 0.0508s/iter; left time: 1073.4346s
Epoch: 7 cost time: 11.8084237575531
Epoch: 7, Steps: 227 Train Loss: 0.8556 (Forecasting Loss:0.5933 + XiCon Loss:2.6223 x Lambda(0.1)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2719
Validation loss decreased (1.177993 --> 1.177383).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8821841
	speed: 0.0544s/iter; left time: 1142.7547s
	iters: 200, epoch: 8 | loss: 0.9245015
	speed: 0.0548s/iter; left time: 1146.7563s
Epoch: 8 cost time: 12.331448078155518
Epoch: 8, Steps: 227 Train Loss: 0.8549 (Forecasting Loss:0.5929 + XiCon Loss:2.6201 x Lambda(0.1)), Vali MSE Loss: 1.1765 Test MSE Loss: 1.2718
Validation loss decreased (1.177383 --> 1.176536).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8452418
	speed: 0.0538s/iter; left time: 1119.1711s
	iters: 200, epoch: 9 | loss: 0.8775740
	speed: 0.0515s/iter; left time: 1065.6456s
Epoch: 9 cost time: 11.914730787277222
Epoch: 9, Steps: 227 Train Loss: 0.8549 (Forecasting Loss:0.5927 + XiCon Loss:2.6223 x Lambda(0.1)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8157866
	speed: 0.0546s/iter; left time: 1122.7455s
	iters: 200, epoch: 10 | loss: 0.8556271
	speed: 0.0514s/iter; left time: 1051.1559s
Epoch: 10 cost time: 12.030113220214844
Epoch: 10, Steps: 227 Train Loss: 0.8545 (Forecasting Loss:0.5927 + XiCon Loss:2.6183 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2717
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8528448
	speed: 0.0538s/iter; left time: 1094.1653s
	iters: 200, epoch: 11 | loss: 0.8767554
	speed: 0.0517s/iter; left time: 1046.3521s
Epoch: 11 cost time: 12.074463844299316
Epoch: 11, Steps: 227 Train Loss: 0.8546 (Forecasting Loss:0.5924 + XiCon Loss:2.6215 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2717
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8482695
	speed: 0.0541s/iter; left time: 1087.5706s
	iters: 200, epoch: 12 | loss: 0.8460315
	speed: 0.0521s/iter; left time: 1041.3885s
Epoch: 12 cost time: 12.248911619186401
Epoch: 12, Steps: 227 Train Loss: 0.8544 (Forecasting Loss:0.5925 + XiCon Loss:2.6191 x Lambda(0.1)), Vali MSE Loss: 1.1762 Test MSE Loss: 1.2717
Validation loss decreased (1.176536 --> 1.176223).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8057112
	speed: 0.0540s/iter; left time: 1073.9909s
	iters: 200, epoch: 13 | loss: 0.8380798
	speed: 0.0520s/iter; left time: 1027.8352s
Epoch: 13 cost time: 12.072259426116943
Epoch: 13, Steps: 227 Train Loss: 0.8545 (Forecasting Loss:0.5927 + XiCon Loss:2.6182 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8696496
	speed: 0.0543s/iter; left time: 1066.7065s
	iters: 200, epoch: 14 | loss: 0.8371092
	speed: 0.0504s/iter; left time: 984.5118s
Epoch: 14 cost time: 11.865607023239136
Epoch: 14, Steps: 227 Train Loss: 0.8544 (Forecasting Loss:0.5927 + XiCon Loss:2.6179 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2717
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8080561
	speed: 0.0539s/iter; left time: 1047.6507s
	iters: 200, epoch: 15 | loss: 0.8523176
	speed: 0.0510s/iter; left time: 985.9324s
Epoch: 15 cost time: 12.044016122817993
Epoch: 15, Steps: 227 Train Loss: 0.8543 (Forecasting Loss:0.5927 + XiCon Loss:2.6162 x Lambda(0.1)), Vali MSE Loss: 1.1772 Test MSE Loss: 1.2717
EarlyStopping counter: 3 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8555537
	speed: 0.0570s/iter; left time: 1094.1607s
	iters: 200, epoch: 16 | loss: 0.8573902
	speed: 0.0518s/iter; left time: 989.0466s
Epoch: 16 cost time: 12.498421907424927
Epoch: 16, Steps: 227 Train Loss: 0.8547 (Forecasting Loss:0.5924 + XiCon Loss:2.6223 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2717
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8877144
	speed: 0.0553s/iter; left time: 1048.6698s
	iters: 200, epoch: 17 | loss: 0.8296111
	speed: 0.0510s/iter; left time: 963.0958s
Epoch: 17 cost time: 12.167224168777466
Epoch: 17, Steps: 227 Train Loss: 0.8540 (Forecasting Loss:0.5925 + XiCon Loss:2.6146 x Lambda(0.1)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2717
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8346840
	speed: 0.0522s/iter; left time: 978.4847s
	iters: 200, epoch: 18 | loss: 0.8731079
	speed: 0.0523s/iter; left time: 974.4583s
Epoch: 18 cost time: 11.889071226119995
Epoch: 18, Steps: 227 Train Loss: 0.8545 (Forecasting Loss:0.5926 + XiCon Loss:2.6185 x Lambda(0.1)), Vali MSE Loss: 1.1761 Test MSE Loss: 1.2717
Validation loss decreased (1.176223 --> 1.176086).  Saving model ...
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8981827
	speed: 0.0543s/iter; left time: 1004.9176s
	iters: 200, epoch: 19 | loss: 0.8863608
	speed: 0.0527s/iter; left time: 970.8903s
Epoch: 19 cost time: 12.179641723632812
Epoch: 19, Steps: 227 Train Loss: 0.8548 (Forecasting Loss:0.5925 + XiCon Loss:2.6229 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8018390
	speed: 0.0533s/iter; left time: 974.3332s
	iters: 200, epoch: 20 | loss: 0.8106259
	speed: 0.0515s/iter; left time: 936.4860s
Epoch: 20 cost time: 11.893337965011597
Epoch: 20, Steps: 227 Train Loss: 0.8547 (Forecasting Loss:0.5926 + XiCon Loss:2.6216 x Lambda(0.1)), Vali MSE Loss: 1.1765 Test MSE Loss: 1.2717
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8709390
	speed: 0.0508s/iter; left time: 917.3389s
	iters: 200, epoch: 21 | loss: 0.8443279
	speed: 0.0527s/iter; left time: 945.8905s
Epoch: 21 cost time: 11.715388774871826
Epoch: 21, Steps: 227 Train Loss: 0.8548 (Forecasting Loss:0.5926 + XiCon Loss:2.6219 x Lambda(0.1)), Vali MSE Loss: 1.1763 Test MSE Loss: 1.2717
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8439221
	speed: 0.0510s/iter; left time: 909.7429s
	iters: 200, epoch: 22 | loss: 0.9038042
	speed: 0.0502s/iter; left time: 889.7610s
Epoch: 22 cost time: 11.508172273635864
Epoch: 22, Steps: 227 Train Loss: 0.8546 (Forecasting Loss:0.5926 + XiCon Loss:2.6198 x Lambda(0.1)), Vali MSE Loss: 1.1761 Test MSE Loss: 1.2717
Validation loss decreased (1.176086 --> 1.176051).  Saving model ...
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.9063216
	speed: 0.0516s/iter; left time: 908.1619s
	iters: 200, epoch: 23 | loss: 0.8502508
	speed: 0.0474s/iter; left time: 830.6287s
Epoch: 23 cost time: 11.285822868347168
Epoch: 23, Steps: 227 Train Loss: 0.8548 (Forecasting Loss:0.5925 + XiCon Loss:2.6231 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8494667
	speed: 0.0499s/iter; left time: 866.9916s
	iters: 200, epoch: 24 | loss: 0.8706851
	speed: 0.0482s/iter; left time: 832.9362s
Epoch: 24 cost time: 11.17794394493103
Epoch: 24, Steps: 227 Train Loss: 0.8547 (Forecasting Loss:0.5927 + XiCon Loss:2.6204 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2717
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8286482
	speed: 0.0564s/iter; left time: 967.4971s
	iters: 200, epoch: 25 | loss: 0.8889147
	speed: 0.0517s/iter; left time: 881.7949s
Epoch: 25 cost time: 12.249371528625488
Epoch: 25, Steps: 227 Train Loss: 0.8547 (Forecasting Loss:0.5926 + XiCon Loss:2.6212 x Lambda(0.1)), Vali MSE Loss: 1.1768 Test MSE Loss: 1.2717
EarlyStopping counter: 3 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8621873
	speed: 0.0529s/iter; left time: 894.7012s
	iters: 200, epoch: 26 | loss: 0.8285054
	speed: 0.0508s/iter; left time: 854.6013s
Epoch: 26 cost time: 11.732697010040283
Epoch: 26, Steps: 227 Train Loss: 0.8543 (Forecasting Loss:0.5925 + XiCon Loss:2.6186 x Lambda(0.1)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2717
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.8763531
	speed: 0.0558s/iter; left time: 931.2128s
	iters: 200, epoch: 27 | loss: 0.8534458
	speed: 0.0511s/iter; left time: 848.8582s
Epoch: 27 cost time: 12.11952018737793
Epoch: 27, Steps: 227 Train Loss: 0.8546 (Forecasting Loss:0.5925 + XiCon Loss:2.6211 x Lambda(0.1)), Vali MSE Loss: 1.1755 Test MSE Loss: 1.2717
Validation loss decreased (1.176051 --> 1.175549).  Saving model ...
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.8673133
	speed: 0.0562s/iter; left time: 925.8718s
	iters: 200, epoch: 28 | loss: 0.8965296
	speed: 0.0506s/iter; left time: 827.9219s
Epoch: 28 cost time: 12.201447486877441
Epoch: 28, Steps: 227 Train Loss: 0.8548 (Forecasting Loss:0.5926 + XiCon Loss:2.6227 x Lambda(0.1)), Vali MSE Loss: 1.1761 Test MSE Loss: 1.2717
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.8254989
	speed: 0.0561s/iter; left time: 911.9569s
	iters: 200, epoch: 29 | loss: 0.8752980
	speed: 0.0527s/iter; left time: 850.7768s
Epoch: 29 cost time: 12.297034740447998
Epoch: 29, Steps: 227 Train Loss: 0.8545 (Forecasting Loss:0.5927 + XiCon Loss:2.6176 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2717
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.8762898
	speed: 0.0531s/iter; left time: 850.6261s
	iters: 200, epoch: 30 | loss: 0.8428600
	speed: 0.0529s/iter; left time: 842.3147s
Epoch: 30 cost time: 11.98807168006897
Epoch: 30, Steps: 227 Train Loss: 0.8541 (Forecasting Loss:0.5925 + XiCon Loss:2.6156 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2717
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.862645149230957e-13
	iters: 100, epoch: 31 | loss: 0.8396937
	speed: 0.0553s/iter; left time: 872.9880s
	iters: 200, epoch: 31 | loss: 0.8715178
	speed: 0.0526s/iter; left time: 825.4963s
Epoch: 31 cost time: 12.268092155456543
Epoch: 31, Steps: 227 Train Loss: 0.8546 (Forecasting Loss:0.5927 + XiCon Loss:2.6193 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2717
EarlyStopping counter: 4 out of 10
Updating learning rate to 9.313225746154786e-14
	iters: 100, epoch: 32 | loss: 0.8648744
	speed: 0.0558s/iter; left time: 867.8283s
	iters: 200, epoch: 32 | loss: 0.8295387
	speed: 0.0502s/iter; left time: 776.5178s
Epoch: 32 cost time: 11.998185157775879
Epoch: 32, Steps: 227 Train Loss: 0.8544 (Forecasting Loss:0.5926 + XiCon Loss:2.6182 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2717
EarlyStopping counter: 5 out of 10
Updating learning rate to 4.656612873077393e-14
	iters: 100, epoch: 33 | loss: 0.8559814
	speed: 0.0529s/iter; left time: 811.5305s
	iters: 200, epoch: 33 | loss: 0.8759443
	speed: 0.0512s/iter; left time: 779.9011s
Epoch: 33 cost time: 11.845393419265747
Epoch: 33, Steps: 227 Train Loss: 0.8544 (Forecasting Loss:0.5926 + XiCon Loss:2.6178 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2717
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.3283064365386964e-14
	iters: 100, epoch: 34 | loss: 0.8332719
	speed: 0.0546s/iter; left time: 825.5178s
	iters: 200, epoch: 34 | loss: 0.8323946
	speed: 0.0534s/iter; left time: 801.3854s
Epoch: 34 cost time: 12.188668251037598
Epoch: 34, Steps: 227 Train Loss: 0.8547 (Forecasting Loss:0.5925 + XiCon Loss:2.6216 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2717
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.1641532182693482e-14
	iters: 100, epoch: 35 | loss: 0.8471105
	speed: 0.0571s/iter; left time: 849.5130s
	iters: 200, epoch: 35 | loss: 0.8351889
	speed: 0.0515s/iter; left time: 760.7775s
Epoch: 35 cost time: 12.24287748336792
Epoch: 35, Steps: 227 Train Loss: 0.8545 (Forecasting Loss:0.5926 + XiCon Loss:2.6197 x Lambda(0.1)), Vali MSE Loss: 1.1763 Test MSE Loss: 1.2717
EarlyStopping counter: 8 out of 10
Updating learning rate to 5.820766091346741e-15
	iters: 100, epoch: 36 | loss: 0.8456618
	speed: 0.0535s/iter; left time: 783.8562s
	iters: 200, epoch: 36 | loss: 0.8226458
	speed: 0.0511s/iter; left time: 743.5065s
Epoch: 36 cost time: 11.90155029296875
Epoch: 36, Steps: 227 Train Loss: 0.8549 (Forecasting Loss:0.5927 + XiCon Loss:2.6218 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2717
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.9103830456733705e-15
	iters: 100, epoch: 37 | loss: 0.8675991
	speed: 0.0537s/iter; left time: 774.6031s
	iters: 200, epoch: 37 | loss: 0.8614198
	speed: 0.0534s/iter; left time: 764.7264s
Epoch: 37 cost time: 12.158208847045898
Epoch: 37, Steps: 227 Train Loss: 0.8548 (Forecasting Loss:0.5925 + XiCon Loss:2.6230 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2717
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5889610052108765, mae:0.9544356465339661, mape:6.253726482391357, mspe:4839.9677734375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.8369
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.3067687
	speed: 0.0494s/iter; left time: 1115.7748s
	iters: 200, epoch: 1 | loss: 1.2727275
	speed: 0.0460s/iter; left time: 1036.1405s
Epoch: 1 cost time: 10.813131332397461
Epoch: 1, Steps: 227 Train Loss: 1.2952 (Forecasting Loss:1.0243 + XiCon Loss:2.7088 x Lambda(0.1)), Vali MSE Loss: 1.9321 Test MSE Loss: 1.3819
Validation loss decreased (inf --> 1.932085).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8758402
	speed: 0.0495s/iter; left time: 1107.7036s
	iters: 200, epoch: 2 | loss: 0.8677331
	speed: 0.0456s/iter; left time: 1015.5397s
Epoch: 2 cost time: 10.78812289237976
Epoch: 2, Steps: 227 Train Loss: 0.9399 (Forecasting Loss:0.6693 + XiCon Loss:2.7058 x Lambda(0.1)), Vali MSE Loss: 1.2130 Test MSE Loss: 1.2808
Validation loss decreased (1.932085 --> 1.212971).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8920062
	speed: 0.0481s/iter; left time: 1066.2277s
	iters: 200, epoch: 3 | loss: 0.8773075
	speed: 0.0480s/iter; left time: 1057.5362s
Epoch: 3 cost time: 10.88840651512146
Epoch: 3, Steps: 227 Train Loss: 0.8767 (Forecasting Loss:0.6074 + XiCon Loss:2.6935 x Lambda(0.1)), Vali MSE Loss: 1.1940 Test MSE Loss: 1.2734
Validation loss decreased (1.212971 --> 1.193954).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8509057
	speed: 0.0492s/iter; left time: 1079.5287s
	iters: 200, epoch: 4 | loss: 0.8073270
	speed: 0.0467s/iter; left time: 1018.9020s
Epoch: 4 cost time: 10.884668827056885
Epoch: 4, Steps: 227 Train Loss: 0.8687 (Forecasting Loss:0.6000 + XiCon Loss:2.6863 x Lambda(0.1)), Vali MSE Loss: 1.1877 Test MSE Loss: 1.2717
Validation loss decreased (1.193954 --> 1.187665).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8567014
	speed: 0.0544s/iter; left time: 1181.0244s
	iters: 200, epoch: 5 | loss: 0.9117997
	speed: 0.0490s/iter; left time: 1057.3018s
Epoch: 5 cost time: 11.720507144927979
Epoch: 5, Steps: 227 Train Loss: 0.8655 (Forecasting Loss:0.5971 + XiCon Loss:2.6840 x Lambda(0.1)), Vali MSE Loss: 1.1850 Test MSE Loss: 1.2710
Validation loss decreased (1.187665 --> 1.185031).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8536844
	speed: 0.0494s/iter; left time: 1060.0361s
	iters: 200, epoch: 6 | loss: 0.8416867
	speed: 0.0464s/iter; left time: 991.4640s
Epoch: 6 cost time: 10.864061117172241
Epoch: 6, Steps: 227 Train Loss: 0.8637 (Forecasting Loss:0.5957 + XiCon Loss:2.6800 x Lambda(0.1)), Vali MSE Loss: 1.1832 Test MSE Loss: 1.2707
Validation loss decreased (1.185031 --> 1.183235).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8547127
	speed: 0.0484s/iter; left time: 1027.3096s
	iters: 200, epoch: 7 | loss: 0.8809043
	speed: 0.0442s/iter; left time: 933.9010s
Epoch: 7 cost time: 10.493180990219116
Epoch: 7, Steps: 227 Train Loss: 0.8632 (Forecasting Loss:0.5949 + XiCon Loss:2.6832 x Lambda(0.1)), Vali MSE Loss: 1.1829 Test MSE Loss: 1.2706
Validation loss decreased (1.183235 --> 1.182902).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8700988
	speed: 0.0461s/iter; left time: 968.5475s
	iters: 200, epoch: 8 | loss: 0.9064184
	speed: 0.0433s/iter; left time: 906.2947s
Epoch: 8 cost time: 10.321394205093384
Epoch: 8, Steps: 227 Train Loss: 0.8633 (Forecasting Loss:0.5947 + XiCon Loss:2.6861 x Lambda(0.1)), Vali MSE Loss: 1.1825 Test MSE Loss: 1.2705
Validation loss decreased (1.182902 --> 1.182456).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8407645
	speed: 0.0484s/iter; left time: 1006.0118s
	iters: 200, epoch: 9 | loss: 0.8611175
	speed: 0.0460s/iter; left time: 952.2338s
Epoch: 9 cost time: 10.640289783477783
Epoch: 9, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5945 + XiCon Loss:2.6803 x Lambda(0.1)), Vali MSE Loss: 1.1812 Test MSE Loss: 1.2704
Validation loss decreased (1.182456 --> 1.181231).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8077416
	speed: 0.0470s/iter; left time: 966.6854s
	iters: 200, epoch: 10 | loss: 0.8573840
	speed: 0.0432s/iter; left time: 882.8191s
Epoch: 10 cost time: 10.247496843338013
Epoch: 10, Steps: 227 Train Loss: 0.8627 (Forecasting Loss:0.5943 + XiCon Loss:2.6841 x Lambda(0.1)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2704
EarlyStopping counter: 1 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8559942
	speed: 0.0507s/iter; left time: 1029.8506s
	iters: 200, epoch: 11 | loss: 0.8836534
	speed: 0.0444s/iter; left time: 898.8690s
Epoch: 11 cost time: 10.754674196243286
Epoch: 11, Steps: 227 Train Loss: 0.8624 (Forecasting Loss:0.5942 + XiCon Loss:2.6818 x Lambda(0.1)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2704
EarlyStopping counter: 2 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8873562
	speed: 0.0499s/iter; left time: 1002.3675s
	iters: 200, epoch: 12 | loss: 0.8371056
	speed: 0.0472s/iter; left time: 944.3926s
Epoch: 12 cost time: 11.061754703521729
Epoch: 12, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5942 + XiCon Loss:2.6828 x Lambda(0.1)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2704
EarlyStopping counter: 3 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8743157
	speed: 0.0514s/iter; left time: 1021.6860s
	iters: 200, epoch: 13 | loss: 0.8277570
	speed: 0.0472s/iter; left time: 934.1792s
Epoch: 13 cost time: 11.146401643753052
Epoch: 13, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5943 + XiCon Loss:2.6821 x Lambda(0.1)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2704
EarlyStopping counter: 4 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8787265
	speed: 0.0499s/iter; left time: 980.7294s
	iters: 200, epoch: 14 | loss: 0.8909670
	speed: 0.0476s/iter; left time: 930.3489s
Epoch: 14 cost time: 11.036790370941162
Epoch: 14, Steps: 227 Train Loss: 0.8622 (Forecasting Loss:0.5943 + XiCon Loss:2.6792 x Lambda(0.1)), Vali MSE Loss: 1.1823 Test MSE Loss: 1.2704
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8669986
	speed: 0.0510s/iter; left time: 990.2034s
	iters: 200, epoch: 15 | loss: 0.9043808
	speed: 0.0457s/iter; left time: 883.7461s
Epoch: 15 cost time: 11.012157678604126
Epoch: 15, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5941 + XiCon Loss:2.6837 x Lambda(0.1)), Vali MSE Loss: 1.1809 Test MSE Loss: 1.2704
Validation loss decreased (1.181231 --> 1.180943).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8618219
	speed: 0.0496s/iter; left time: 952.9704s
	iters: 200, epoch: 16 | loss: 0.8507532
	speed: 0.0497s/iter; left time: 949.8253s
Epoch: 16 cost time: 11.28434944152832
Epoch: 16, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5941 + XiCon Loss:2.6838 x Lambda(0.1)), Vali MSE Loss: 1.1817 Test MSE Loss: 1.2704
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8688445
	speed: 0.0487s/iter; left time: 924.7081s
	iters: 200, epoch: 17 | loss: 0.8719831
	speed: 0.0494s/iter; left time: 931.3911s
Epoch: 17 cost time: 11.094022274017334
Epoch: 17, Steps: 227 Train Loss: 0.8626 (Forecasting Loss:0.5942 + XiCon Loss:2.6839 x Lambda(0.1)), Vali MSE Loss: 1.1819 Test MSE Loss: 1.2704
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8812506
	speed: 0.0515s/iter; left time: 964.5761s
	iters: 200, epoch: 18 | loss: 0.8364801
	speed: 0.0472s/iter; left time: 879.4613s
Epoch: 18 cost time: 11.167208909988403
Epoch: 18, Steps: 227 Train Loss: 0.8621 (Forecasting Loss:0.5942 + XiCon Loss:2.6790 x Lambda(0.1)), Vali MSE Loss: 1.1822 Test MSE Loss: 1.2704
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8869897
	speed: 0.0493s/iter; left time: 913.1313s
	iters: 200, epoch: 19 | loss: 0.8578215
	speed: 0.0478s/iter; left time: 879.8251s
Epoch: 19 cost time: 11.008059024810791
Epoch: 19, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5941 + XiCon Loss:2.6833 x Lambda(0.1)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2704
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8366329
	speed: 0.0501s/iter; left time: 916.9540s
	iters: 200, epoch: 20 | loss: 0.8788332
	speed: 0.0469s/iter; left time: 853.0188s
Epoch: 20 cost time: 11.014705896377563
Epoch: 20, Steps: 227 Train Loss: 0.8627 (Forecasting Loss:0.5942 + XiCon Loss:2.6846 x Lambda(0.1)), Vali MSE Loss: 1.1823 Test MSE Loss: 1.2704
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8514934
	speed: 0.0510s/iter; left time: 920.9092s
	iters: 200, epoch: 21 | loss: 0.8583157
	speed: 0.0477s/iter; left time: 856.3711s
Epoch: 21 cost time: 11.140835285186768
Epoch: 21, Steps: 227 Train Loss: 0.8622 (Forecasting Loss:0.5942 + XiCon Loss:2.6805 x Lambda(0.1)), Vali MSE Loss: 1.1818 Test MSE Loss: 1.2704
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8740488
	speed: 0.0519s/iter; left time: 925.2779s
	iters: 200, epoch: 22 | loss: 0.8492107
	speed: 0.0477s/iter; left time: 846.5583s
Epoch: 22 cost time: 11.328453063964844
Epoch: 22, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5941 + XiCon Loss:2.6837 x Lambda(0.1)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2704
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8815621
	speed: 0.0505s/iter; left time: 888.6534s
	iters: 200, epoch: 23 | loss: 0.8786715
	speed: 0.0465s/iter; left time: 814.8148s
Epoch: 23 cost time: 10.981699228286743
Epoch: 23, Steps: 227 Train Loss: 0.8619 (Forecasting Loss:0.5942 + XiCon Loss:2.6775 x Lambda(0.1)), Vali MSE Loss: 1.1814 Test MSE Loss: 1.2704
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8740900
	speed: 0.0513s/iter; left time: 891.6566s
	iters: 200, epoch: 24 | loss: 0.8598089
	speed: 0.0479s/iter; left time: 827.0355s
Epoch: 24 cost time: 11.253073692321777
Epoch: 24, Steps: 227 Train Loss: 0.8619 (Forecasting Loss:0.5941 + XiCon Loss:2.6788 x Lambda(0.1)), Vali MSE Loss: 1.1820 Test MSE Loss: 1.2704
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8427044
	speed: 0.0507s/iter; left time: 870.2584s
	iters: 200, epoch: 25 | loss: 0.8569919
	speed: 0.0472s/iter; left time: 805.5064s
Epoch: 25 cost time: 11.073180675506592
Epoch: 25, Steps: 227 Train Loss: 0.8623 (Forecasting Loss:0.5942 + XiCon Loss:2.6808 x Lambda(0.1)), Vali MSE Loss: 1.1813 Test MSE Loss: 1.2704
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_1<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.587647557258606, mae:0.9531157612800598, mape:6.213857650756836, mspe:4758.68994140625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.2556
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.3138682
	speed: 0.0496s/iter; left time: 1121.4049s
	iters: 200, epoch: 1 | loss: 1.3346887
	speed: 0.0456s/iter; left time: 1026.0670s
Epoch: 1 cost time: 10.867193937301636
Epoch: 1, Steps: 227 Train Loss: 1.3119 (Forecasting Loss:1.0399 + XiCon Loss:2.7206 x Lambda(0.1)), Vali MSE Loss: 1.9467 Test MSE Loss: 1.3970
Validation loss decreased (inf --> 1.946652).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8569121
	speed: 0.0483s/iter; left time: 1081.2639s
	iters: 200, epoch: 2 | loss: 0.8740473
	speed: 0.0458s/iter; left time: 1020.4967s
Epoch: 2 cost time: 10.671630620956421
Epoch: 2, Steps: 227 Train Loss: 0.9416 (Forecasting Loss:0.6705 + XiCon Loss:2.7106 x Lambda(0.1)), Vali MSE Loss: 1.2032 Test MSE Loss: 1.2778
Validation loss decreased (1.946652 --> 1.203234).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8998396
	speed: 0.0493s/iter; left time: 1091.7283s
	iters: 200, epoch: 3 | loss: 0.8760990
	speed: 0.0495s/iter; left time: 1091.6960s
Epoch: 3 cost time: 11.181895971298218
Epoch: 3, Steps: 227 Train Loss: 0.8753 (Forecasting Loss:0.6059 + XiCon Loss:2.6936 x Lambda(0.1)), Vali MSE Loss: 1.1821 Test MSE Loss: 1.2715
Validation loss decreased (1.203234 --> 1.182145).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8588331
	speed: 0.0496s/iter; left time: 1086.9993s
	iters: 200, epoch: 4 | loss: 0.8727888
	speed: 0.0486s/iter; left time: 1059.5834s
Epoch: 4 cost time: 11.106549978256226
Epoch: 4, Steps: 227 Train Loss: 0.8662 (Forecasting Loss:0.5980 + XiCon Loss:2.6820 x Lambda(0.1)), Vali MSE Loss: 1.1765 Test MSE Loss: 1.2708
Validation loss decreased (1.182145 --> 1.176549).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8281419
	speed: 0.0514s/iter; left time: 1115.7490s
	iters: 200, epoch: 5 | loss: 0.8844064
	speed: 0.0490s/iter; left time: 1057.4810s
Epoch: 5 cost time: 11.335259675979614
Epoch: 5, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5949 + XiCon Loss:2.6766 x Lambda(0.1)), Vali MSE Loss: 1.1726 Test MSE Loss: 1.2701
Validation loss decreased (1.176549 --> 1.172609).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8894908
	speed: 0.0482s/iter; left time: 1034.7977s
	iters: 200, epoch: 6 | loss: 0.8789045
	speed: 0.0443s/iter; left time: 946.6944s
Epoch: 6 cost time: 10.511672258377075
Epoch: 6, Steps: 227 Train Loss: 0.8610 (Forecasting Loss:0.5935 + XiCon Loss:2.6747 x Lambda(0.1)), Vali MSE Loss: 1.1718 Test MSE Loss: 1.2697
Validation loss decreased (1.172609 --> 1.171826).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8616573
	speed: 0.0474s/iter; left time: 1006.2106s
	iters: 200, epoch: 7 | loss: 0.8307243
	speed: 0.0443s/iter; left time: 937.4488s
Epoch: 7 cost time: 10.43173599243164
Epoch: 7, Steps: 227 Train Loss: 0.8599 (Forecasting Loss:0.5927 + XiCon Loss:2.6717 x Lambda(0.1)), Vali MSE Loss: 1.1709 Test MSE Loss: 1.2696
Validation loss decreased (1.171826 --> 1.170905).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.9007365
	speed: 0.0469s/iter; left time: 985.9947s
	iters: 200, epoch: 8 | loss: 0.8431555
	speed: 0.0460s/iter; left time: 962.8789s
Epoch: 8 cost time: 10.572376251220703
Epoch: 8, Steps: 227 Train Loss: 0.8593 (Forecasting Loss:0.5924 + XiCon Loss:2.6688 x Lambda(0.1)), Vali MSE Loss: 1.1701 Test MSE Loss: 1.2696
Validation loss decreased (1.170905 --> 1.170122).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8526777
	speed: 0.0492s/iter; left time: 1022.6298s
	iters: 200, epoch: 9 | loss: 0.8093523
	speed: 0.0457s/iter; left time: 944.5096s
Epoch: 9 cost time: 10.882544755935669
Epoch: 9, Steps: 227 Train Loss: 0.8595 (Forecasting Loss:0.5923 + XiCon Loss:2.6718 x Lambda(0.1)), Vali MSE Loss: 1.1702 Test MSE Loss: 1.2696
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8467910
	speed: 0.0486s/iter; left time: 998.4015s
	iters: 200, epoch: 10 | loss: 0.8973769
	speed: 0.0429s/iter; left time: 877.8535s
Epoch: 10 cost time: 10.561761856079102
Epoch: 10, Steps: 227 Train Loss: 0.8591 (Forecasting Loss:0.5921 + XiCon Loss:2.6695 x Lambda(0.1)), Vali MSE Loss: 1.1702 Test MSE Loss: 1.2695
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8300185
	speed: 0.0496s/iter; left time: 1007.6115s
	iters: 200, epoch: 11 | loss: 0.8410116
	speed: 0.0485s/iter; left time: 982.0285s
Epoch: 11 cost time: 11.10296630859375
Epoch: 11, Steps: 227 Train Loss: 0.8594 (Forecasting Loss:0.5919 + XiCon Loss:2.6744 x Lambda(0.1)), Vali MSE Loss: 1.1701 Test MSE Loss: 1.2695
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8496784
	speed: 0.0526s/iter; left time: 1056.5442s
	iters: 200, epoch: 12 | loss: 0.8632154
	speed: 0.0474s/iter; left time: 948.5291s
Epoch: 12 cost time: 11.500762701034546
Epoch: 12, Steps: 227 Train Loss: 0.8594 (Forecasting Loss:0.5920 + XiCon Loss:2.6742 x Lambda(0.1)), Vali MSE Loss: 1.1702 Test MSE Loss: 1.2695
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8539597
	speed: 0.0515s/iter; left time: 1024.3935s
	iters: 200, epoch: 13 | loss: 0.8944203
	speed: 0.0476s/iter; left time: 940.5591s
Epoch: 13 cost time: 11.202965497970581
Epoch: 13, Steps: 227 Train Loss: 0.8592 (Forecasting Loss:0.5918 + XiCon Loss:2.6738 x Lambda(0.1)), Vali MSE Loss: 1.1702 Test MSE Loss: 1.2695
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8603359
	speed: 0.0500s/iter; left time: 983.3870s
	iters: 200, epoch: 14 | loss: 0.8865834
	speed: 0.0484s/iter; left time: 946.0662s
Epoch: 14 cost time: 11.17885136604309
Epoch: 14, Steps: 227 Train Loss: 0.8588 (Forecasting Loss:0.5921 + XiCon Loss:2.6671 x Lambda(0.1)), Vali MSE Loss: 1.1697 Test MSE Loss: 1.2695
Validation loss decreased (1.170122 --> 1.169731).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8828620
	speed: 0.0505s/iter; left time: 980.8784s
	iters: 200, epoch: 15 | loss: 0.8742726
	speed: 0.0477s/iter; left time: 922.2777s
Epoch: 15 cost time: 11.296247720718384
Epoch: 15, Steps: 227 Train Loss: 0.8587 (Forecasting Loss:0.5919 + XiCon Loss:2.6678 x Lambda(0.1)), Vali MSE Loss: 1.1695 Test MSE Loss: 1.2695
Validation loss decreased (1.169731 --> 1.169511).  Saving model ...
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8538321
	speed: 0.0513s/iter; left time: 985.0297s
	iters: 200, epoch: 16 | loss: 0.8247069
	speed: 0.0480s/iter; left time: 916.7117s
Epoch: 16 cost time: 11.18641972541809
Epoch: 16, Steps: 227 Train Loss: 0.8591 (Forecasting Loss:0.5919 + XiCon Loss:2.6719 x Lambda(0.1)), Vali MSE Loss: 1.1703 Test MSE Loss: 1.2695
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.9151924
	speed: 0.0513s/iter; left time: 973.4958s
	iters: 200, epoch: 17 | loss: 0.8349044
	speed: 0.0470s/iter; left time: 887.4116s
Epoch: 17 cost time: 11.254815816879272
Epoch: 17, Steps: 227 Train Loss: 0.8590 (Forecasting Loss:0.5920 + XiCon Loss:2.6704 x Lambda(0.1)), Vali MSE Loss: 1.1698 Test MSE Loss: 1.2695
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8797557
	speed: 0.0512s/iter; left time: 959.8445s
	iters: 200, epoch: 18 | loss: 0.8618758
	speed: 0.0482s/iter; left time: 899.4453s
Epoch: 18 cost time: 11.25450849533081
Epoch: 18, Steps: 227 Train Loss: 0.8587 (Forecasting Loss:0.5920 + XiCon Loss:2.6670 x Lambda(0.1)), Vali MSE Loss: 1.1695 Test MSE Loss: 1.2695
EarlyStopping counter: 3 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8474981
	speed: 0.0508s/iter; left time: 941.0243s
	iters: 200, epoch: 19 | loss: 0.8771728
	speed: 0.0465s/iter; left time: 856.9335s
Epoch: 19 cost time: 11.01844072341919
Epoch: 19, Steps: 227 Train Loss: 0.8594 (Forecasting Loss:0.5921 + XiCon Loss:2.6732 x Lambda(0.1)), Vali MSE Loss: 1.1699 Test MSE Loss: 1.2695
EarlyStopping counter: 4 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.7948637
	speed: 0.0494s/iter; left time: 904.3034s
	iters: 200, epoch: 20 | loss: 0.8719919
	speed: 0.0468s/iter; left time: 851.8881s
Epoch: 20 cost time: 10.933925867080688
Epoch: 20, Steps: 227 Train Loss: 0.8591 (Forecasting Loss:0.5920 + XiCon Loss:2.6711 x Lambda(0.1)), Vali MSE Loss: 1.1699 Test MSE Loss: 1.2695
EarlyStopping counter: 5 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8630062
	speed: 0.0496s/iter; left time: 896.5659s
	iters: 200, epoch: 21 | loss: 0.8801616
	speed: 0.0453s/iter; left time: 813.5933s
Epoch: 21 cost time: 10.763304233551025
Epoch: 21, Steps: 227 Train Loss: 0.8588 (Forecasting Loss:0.5918 + XiCon Loss:2.6698 x Lambda(0.1)), Vali MSE Loss: 1.1697 Test MSE Loss: 1.2695
EarlyStopping counter: 6 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.9001802
	speed: 0.0519s/iter; left time: 925.1770s
	iters: 200, epoch: 22 | loss: 0.8765407
	speed: 0.0480s/iter; left time: 851.1559s
Epoch: 22 cost time: 11.324967622756958
Epoch: 22, Steps: 227 Train Loss: 0.8590 (Forecasting Loss:0.5920 + XiCon Loss:2.6694 x Lambda(0.1)), Vali MSE Loss: 1.1700 Test MSE Loss: 1.2695
EarlyStopping counter: 7 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8420686
	speed: 0.0520s/iter; left time: 915.4798s
	iters: 200, epoch: 23 | loss: 0.8829280
	speed: 0.0483s/iter; left time: 845.5580s
Epoch: 23 cost time: 11.376947164535522
Epoch: 23, Steps: 227 Train Loss: 0.8590 (Forecasting Loss:0.5919 + XiCon Loss:2.6708 x Lambda(0.1)), Vali MSE Loss: 1.1698 Test MSE Loss: 1.2695
EarlyStopping counter: 8 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8274450
	speed: 0.0515s/iter; left time: 895.8553s
	iters: 200, epoch: 24 | loss: 0.8828118
	speed: 0.0471s/iter; left time: 813.5100s
Epoch: 24 cost time: 11.16853642463684
Epoch: 24, Steps: 227 Train Loss: 0.8589 (Forecasting Loss:0.5919 + XiCon Loss:2.6702 x Lambda(0.1)), Vali MSE Loss: 1.1698 Test MSE Loss: 1.2695
EarlyStopping counter: 9 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8381860
	speed: 0.0485s/iter; left time: 832.1374s
	iters: 200, epoch: 25 | loss: 0.8635176
	speed: 0.0463s/iter; left time: 789.5718s
Epoch: 25 cost time: 10.771329164505005
Epoch: 25, Steps: 227 Train Loss: 0.8590 (Forecasting Loss:0.5920 + XiCon Loss:2.6702 x Lambda(0.1)), Vali MSE Loss: 1.1697 Test MSE Loss: 1.2695
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_2<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5859904289245605, mae:0.953069269657135, mape:6.192535400390625, mspe:4715.697265625 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 18.1720
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.4048287
	speed: 0.0523s/iter; left time: 1182.0632s
	iters: 200, epoch: 1 | loss: 1.2222215
	speed: 0.0479s/iter; left time: 1077.1042s
Epoch: 1 cost time: 11.30808687210083
Epoch: 1, Steps: 227 Train Loss: 1.3057 (Forecasting Loss:1.0340 + XiCon Loss:2.7167 x Lambda(0.1)), Vali MSE Loss: 1.9435 Test MSE Loss: 1.3890
Validation loss decreased (inf --> 1.943491).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.9221957
	speed: 0.0509s/iter; left time: 1137.8131s
	iters: 200, epoch: 2 | loss: 0.9208901
	speed: 0.0475s/iter; left time: 1057.8338s
Epoch: 2 cost time: 11.15867567062378
Epoch: 2, Steps: 227 Train Loss: 0.9418 (Forecasting Loss:0.6721 + XiCon Loss:2.6969 x Lambda(0.1)), Vali MSE Loss: 1.2091 Test MSE Loss: 1.2784
Validation loss decreased (1.943491 --> 1.209098).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8604394
	speed: 0.0529s/iter; left time: 1172.2881s
	iters: 200, epoch: 3 | loss: 0.8629996
	speed: 0.0478s/iter; left time: 1053.8090s
Epoch: 3 cost time: 11.348339796066284
Epoch: 3, Steps: 227 Train Loss: 0.8754 (Forecasting Loss:0.6069 + XiCon Loss:2.6848 x Lambda(0.1)), Vali MSE Loss: 1.1890 Test MSE Loss: 1.2713
Validation loss decreased (1.209098 --> 1.189040).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8750874
	speed: 0.0516s/iter; left time: 1132.0886s
	iters: 200, epoch: 4 | loss: 0.9063926
	speed: 0.0493s/iter; left time: 1076.7784s
Epoch: 4 cost time: 11.47543716430664
Epoch: 4, Steps: 227 Train Loss: 0.8670 (Forecasting Loss:0.5990 + XiCon Loss:2.6807 x Lambda(0.1)), Vali MSE Loss: 1.1825 Test MSE Loss: 1.2690
Validation loss decreased (1.189040 --> 1.182493).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.9084363
	speed: 0.0544s/iter; left time: 1180.6023s
	iters: 200, epoch: 5 | loss: 0.8701835
	speed: 0.0451s/iter; left time: 973.9099s
Epoch: 5 cost time: 11.224043607711792
Epoch: 5, Steps: 227 Train Loss: 0.8637 (Forecasting Loss:0.5958 + XiCon Loss:2.6787 x Lambda(0.1)), Vali MSE Loss: 1.1796 Test MSE Loss: 1.2682
Validation loss decreased (1.182493 --> 1.179622).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8836167
	speed: 0.0513s/iter; left time: 1100.6747s
	iters: 200, epoch: 6 | loss: 0.8667988
	speed: 0.0479s/iter; left time: 1023.0863s
Epoch: 6 cost time: 11.232045888900757
Epoch: 6, Steps: 227 Train Loss: 0.8623 (Forecasting Loss:0.5943 + XiCon Loss:2.6802 x Lambda(0.1)), Vali MSE Loss: 1.1777 Test MSE Loss: 1.2678
Validation loss decreased (1.179622 --> 1.177705).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8332045
	speed: 0.0513s/iter; left time: 1088.5541s
	iters: 200, epoch: 7 | loss: 0.9016980
	speed: 0.0482s/iter; left time: 1018.7754s
Epoch: 7 cost time: 11.200554609298706
Epoch: 7, Steps: 227 Train Loss: 0.8615 (Forecasting Loss:0.5936 + XiCon Loss:2.6787 x Lambda(0.1)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2675
Validation loss decreased (1.177705 --> 1.177021).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8555512
	speed: 0.0489s/iter; left time: 1028.4075s
	iters: 200, epoch: 8 | loss: 0.8221302
	speed: 0.0483s/iter; left time: 1010.5480s
Epoch: 8 cost time: 11.032759428024292
Epoch: 8, Steps: 227 Train Loss: 0.8608 (Forecasting Loss:0.5932 + XiCon Loss:2.6752 x Lambda(0.1)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2674
EarlyStopping counter: 1 out of 10
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8538858
	speed: 0.0508s/iter; left time: 1056.0749s
	iters: 200, epoch: 9 | loss: 0.8570172
	speed: 0.0482s/iter; left time: 998.0196s
Epoch: 9 cost time: 11.27986741065979
Epoch: 9, Steps: 227 Train Loss: 0.8604 (Forecasting Loss:0.5930 + XiCon Loss:2.6735 x Lambda(0.1)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2674
Validation loss decreased (1.177021 --> 1.176985).  Saving model ...
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8332693
	speed: 0.0525s/iter; left time: 1078.4525s
	iters: 200, epoch: 10 | loss: 0.8508276
	speed: 0.0499s/iter; left time: 1020.7002s
Epoch: 10 cost time: 11.560060024261475
Epoch: 10, Steps: 227 Train Loss: 0.8604 (Forecasting Loss:0.5929 + XiCon Loss:2.6757 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2674
Validation loss decreased (1.176985 --> 1.176617).  Saving model ...
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.8563191
	speed: 0.0525s/iter; left time: 1067.6706s
	iters: 200, epoch: 11 | loss: 0.9008917
	speed: 0.0486s/iter; left time: 983.0487s
Epoch: 11 cost time: 11.592926740646362
Epoch: 11, Steps: 227 Train Loss: 0.8604 (Forecasting Loss:0.5928 + XiCon Loss:2.6764 x Lambda(0.1)), Vali MSE Loss: 1.1771 Test MSE Loss: 1.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8739308
	speed: 0.0541s/iter; left time: 1086.8713s
	iters: 200, epoch: 12 | loss: 0.8510482
	speed: 0.0514s/iter; left time: 1028.5709s
Epoch: 12 cost time: 11.905545949935913
Epoch: 12, Steps: 227 Train Loss: 0.8599 (Forecasting Loss:0.5926 + XiCon Loss:2.6729 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2673
Validation loss decreased (1.176617 --> 1.176572).  Saving model ...
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8954811
	speed: 0.0537s/iter; left time: 1067.4039s
	iters: 200, epoch: 13 | loss: 0.8566728
	speed: 0.0470s/iter; left time: 929.6221s
Epoch: 13 cost time: 11.437630653381348
Epoch: 13, Steps: 227 Train Loss: 0.8609 (Forecasting Loss:0.5928 + XiCon Loss:2.6807 x Lambda(0.1)), Vali MSE Loss: 1.1773 Test MSE Loss: 1.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8750359
	speed: 0.0531s/iter; left time: 1043.3136s
	iters: 200, epoch: 14 | loss: 0.8377091
	speed: 0.0485s/iter; left time: 947.5457s
Epoch: 14 cost time: 11.433359861373901
Epoch: 14, Steps: 227 Train Loss: 0.8603 (Forecasting Loss:0.5928 + XiCon Loss:2.6745 x Lambda(0.1)), Vali MSE Loss: 1.1765 Test MSE Loss: 1.2673
Validation loss decreased (1.176572 --> 1.176545).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8261558
	speed: 0.0550s/iter; left time: 1067.8520s
	iters: 200, epoch: 15 | loss: 0.8687748
	speed: 0.0512s/iter; left time: 990.0830s
Epoch: 15 cost time: 11.90054440498352
Epoch: 15, Steps: 227 Train Loss: 0.8609 (Forecasting Loss:0.5927 + XiCon Loss:2.6815 x Lambda(0.1)), Vali MSE Loss: 1.1773 Test MSE Loss: 1.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8384307
	speed: 0.0511s/iter; left time: 979.9685s
	iters: 200, epoch: 16 | loss: 0.8550495
	speed: 0.0471s/iter; left time: 899.1641s
Epoch: 16 cost time: 11.110146284103394
Epoch: 16, Steps: 227 Train Loss: 0.8602 (Forecasting Loss:0.5927 + XiCon Loss:2.6743 x Lambda(0.1)), Vali MSE Loss: 1.1770 Test MSE Loss: 1.2673
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8657039
	speed: 0.0536s/iter; left time: 1016.5558s
	iters: 200, epoch: 17 | loss: 0.8661968
	speed: 0.0520s/iter; left time: 982.1070s
Epoch: 17 cost time: 11.886622667312622
Epoch: 17, Steps: 227 Train Loss: 0.8604 (Forecasting Loss:0.5928 + XiCon Loss:2.6759 x Lambda(0.1)), Vali MSE Loss: 1.1771 Test MSE Loss: 1.2673
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8552409
	speed: 0.0520s/iter; left time: 975.5084s
	iters: 200, epoch: 18 | loss: 0.8552274
	speed: 0.0496s/iter; left time: 924.8252s
Epoch: 18 cost time: 11.485543489456177
Epoch: 18, Steps: 227 Train Loss: 0.8605 (Forecasting Loss:0.5929 + XiCon Loss:2.6763 x Lambda(0.1)), Vali MSE Loss: 1.1766 Test MSE Loss: 1.2673
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8437157
	speed: 0.0521s/iter; left time: 964.4597s
	iters: 200, epoch: 19 | loss: 0.8560659
	speed: 0.0495s/iter; left time: 912.2366s
Epoch: 19 cost time: 11.566622018814087
Epoch: 19, Steps: 227 Train Loss: 0.8600 (Forecasting Loss:0.5927 + XiCon Loss:2.6731 x Lambda(0.1)), Vali MSE Loss: 1.1771 Test MSE Loss: 1.2673
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8254446
	speed: 0.0554s/iter; left time: 1013.3760s
	iters: 200, epoch: 20 | loss: 0.8709435
	speed: 0.0495s/iter; left time: 899.9207s
Epoch: 20 cost time: 11.82456374168396
Epoch: 20, Steps: 227 Train Loss: 0.8603 (Forecasting Loss:0.5927 + XiCon Loss:2.6761 x Lambda(0.1)), Vali MSE Loss: 1.1764 Test MSE Loss: 1.2673
Validation loss decreased (1.176545 --> 1.176398).  Saving model ...
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8755059
	speed: 0.0538s/iter; left time: 970.8494s
	iters: 200, epoch: 21 | loss: 0.8411729
	speed: 0.0484s/iter; left time: 868.9107s
Epoch: 21 cost time: 11.555255651473999
Epoch: 21, Steps: 227 Train Loss: 0.8608 (Forecasting Loss:0.5929 + XiCon Loss:2.6787 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2673
EarlyStopping counter: 1 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8504505
	speed: 0.0535s/iter; left time: 954.5238s
	iters: 200, epoch: 22 | loss: 0.8490665
	speed: 0.0513s/iter; left time: 909.3522s
Epoch: 22 cost time: 11.991157531738281
Epoch: 22, Steps: 227 Train Loss: 0.8601 (Forecasting Loss:0.5928 + XiCon Loss:2.6732 x Lambda(0.1)), Vali MSE Loss: 1.1768 Test MSE Loss: 1.2673
EarlyStopping counter: 2 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8704388
	speed: 0.0515s/iter; left time: 907.0346s
	iters: 200, epoch: 23 | loss: 0.8891579
	speed: 0.0463s/iter; left time: 810.8631s
Epoch: 23 cost time: 11.217969179153442
Epoch: 23, Steps: 227 Train Loss: 0.8608 (Forecasting Loss:0.5928 + XiCon Loss:2.6802 x Lambda(0.1)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2673
EarlyStopping counter: 3 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8571690
	speed: 0.0539s/iter; left time: 936.5264s
	iters: 200, epoch: 24 | loss: 0.8721337
	speed: 0.0478s/iter; left time: 826.1568s
Epoch: 24 cost time: 11.485023736953735
Epoch: 24, Steps: 227 Train Loss: 0.8602 (Forecasting Loss:0.5928 + XiCon Loss:2.6741 x Lambda(0.1)), Vali MSE Loss: 1.1768 Test MSE Loss: 1.2673
EarlyStopping counter: 4 out of 10
Updating learning rate to 1.1920928955078126e-11
	iters: 100, epoch: 25 | loss: 0.8902529
	speed: 0.0528s/iter; left time: 905.8250s
	iters: 200, epoch: 25 | loss: 0.8726068
	speed: 0.0485s/iter; left time: 826.7479s
Epoch: 25 cost time: 11.415777206420898
Epoch: 25, Steps: 227 Train Loss: 0.8604 (Forecasting Loss:0.5926 + XiCon Loss:2.6786 x Lambda(0.1)), Vali MSE Loss: 1.1767 Test MSE Loss: 1.2673
EarlyStopping counter: 5 out of 10
Updating learning rate to 5.960464477539063e-12
	iters: 100, epoch: 26 | loss: 0.8717539
	speed: 0.0537s/iter; left time: 908.7442s
	iters: 200, epoch: 26 | loss: 0.8318645
	speed: 0.0472s/iter; left time: 794.9414s
Epoch: 26 cost time: 11.414958000183105
Epoch: 26, Steps: 227 Train Loss: 0.8602 (Forecasting Loss:0.5927 + XiCon Loss:2.6754 x Lambda(0.1)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2673
EarlyStopping counter: 6 out of 10
Updating learning rate to 2.9802322387695314e-12
	iters: 100, epoch: 27 | loss: 0.7864537
	speed: 0.0541s/iter; left time: 903.8071s
	iters: 200, epoch: 27 | loss: 0.8654309
	speed: 0.0499s/iter; left time: 827.8919s
Epoch: 27 cost time: 11.734458208084106
Epoch: 27, Steps: 227 Train Loss: 0.8605 (Forecasting Loss:0.5927 + XiCon Loss:2.6778 x Lambda(0.1)), Vali MSE Loss: 1.1772 Test MSE Loss: 1.2673
EarlyStopping counter: 7 out of 10
Updating learning rate to 1.4901161193847657e-12
	iters: 100, epoch: 28 | loss: 0.8917120
	speed: 0.0526s/iter; left time: 867.0015s
	iters: 200, epoch: 28 | loss: 0.8281434
	speed: 0.0507s/iter; left time: 830.4442s
Epoch: 28 cost time: 11.721574306488037
Epoch: 28, Steps: 227 Train Loss: 0.8604 (Forecasting Loss:0.5927 + XiCon Loss:2.6773 x Lambda(0.1)), Vali MSE Loss: 1.1771 Test MSE Loss: 1.2673
EarlyStopping counter: 8 out of 10
Updating learning rate to 7.450580596923828e-13
	iters: 100, epoch: 29 | loss: 0.8711103
	speed: 0.0535s/iter; left time: 869.5748s
	iters: 200, epoch: 29 | loss: 0.7975106
	speed: 0.0495s/iter; left time: 798.8903s
Epoch: 29 cost time: 11.739559650421143
Epoch: 29, Steps: 227 Train Loss: 0.8601 (Forecasting Loss:0.5929 + XiCon Loss:2.6725 x Lambda(0.1)), Vali MSE Loss: 1.1769 Test MSE Loss: 1.2673
EarlyStopping counter: 9 out of 10
Updating learning rate to 3.725290298461914e-13
	iters: 100, epoch: 30 | loss: 0.8436326
	speed: 0.0521s/iter; left time: 834.8776s
	iters: 200, epoch: 30 | loss: 0.8396993
	speed: 0.0491s/iter; left time: 780.8739s
Epoch: 30 cost time: 11.427953720092773
Epoch: 30, Steps: 227 Train Loss: 0.8603 (Forecasting Loss:0.5927 + XiCon Loss:2.6764 x Lambda(0.1)), Vali MSE Loss: 1.1774 Test MSE Loss: 1.2673
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_3<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5820921659469604, mae:0.9525707960128784, mape:6.238840579986572, mspe:4797.84521484375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
Use GPU: cuda:0
TimeFeatureEmbedding-wo-freq:   []
model parameters:1457249
train 29122
number of available CPU:  16
Auto-correlation values(abs):[1.         0.99989358] ~ [-8.79208186e-05 -4.37837325e-05]
Xi-correlation values:[0.99990512 0.9890204 ] ~ [0. 1.]
Autocorrelation calculation time: 17.3396
>>>>>>>start training : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4>>>>>>>>>>>>>>>>>>>>>>>>>>
train 29122
val 8381
test 8380
	iters: 100, epoch: 1 | loss: 1.3438940
	speed: 0.0480s/iter; left time: 1084.3478s
	iters: 200, epoch: 1 | loss: 1.2120559
	speed: 0.0431s/iter; left time: 969.6888s
Epoch: 1 cost time: 10.310787916183472
Epoch: 1, Steps: 227 Train Loss: 1.3073 (Forecasting Loss:1.0351 + XiCon Loss:2.7223 x Lambda(0.1)), Vali MSE Loss: 1.9644 Test MSE Loss: 1.3849
Validation loss decreased (inf --> 1.964437).  Saving model ...
Updating learning rate to 0.0001
	iters: 100, epoch: 2 | loss: 0.8692619
	speed: 0.0458s/iter; left time: 1024.7018s
	iters: 200, epoch: 2 | loss: 0.9084971
	speed: 0.0430s/iter; left time: 958.7885s
Epoch: 2 cost time: 10.104385614395142
Epoch: 2, Steps: 227 Train Loss: 0.9423 (Forecasting Loss:0.6714 + XiCon Loss:2.7093 x Lambda(0.1)), Vali MSE Loss: 1.2174 Test MSE Loss: 1.2816
Validation loss decreased (1.964437 --> 1.217402).  Saving model ...
Updating learning rate to 5e-05
	iters: 100, epoch: 3 | loss: 0.8837436
	speed: 0.0479s/iter; left time: 1060.1880s
	iters: 200, epoch: 3 | loss: 0.8295480
	speed: 0.0438s/iter; left time: 966.2859s
Epoch: 3 cost time: 10.377260684967041
Epoch: 3, Steps: 227 Train Loss: 0.8771 (Forecasting Loss:0.6083 + XiCon Loss:2.6881 x Lambda(0.1)), Vali MSE Loss: 1.1983 Test MSE Loss: 1.2749
Validation loss decreased (1.217402 --> 1.198265).  Saving model ...
Updating learning rate to 2.5e-05
	iters: 100, epoch: 4 | loss: 0.8599310
	speed: 0.0479s/iter; left time: 1050.8218s
	iters: 200, epoch: 4 | loss: 0.8558079
	speed: 0.0431s/iter; left time: 940.8020s
Epoch: 4 cost time: 10.307499408721924
Epoch: 4, Steps: 227 Train Loss: 0.8686 (Forecasting Loss:0.6005 + XiCon Loss:2.6806 x Lambda(0.1)), Vali MSE Loss: 1.1905 Test MSE Loss: 1.2732
Validation loss decreased (1.198265 --> 1.190541).  Saving model ...
Updating learning rate to 1.25e-05
	iters: 100, epoch: 5 | loss: 0.8628924
	speed: 0.0481s/iter; left time: 1043.4398s
	iters: 200, epoch: 5 | loss: 0.8594089
	speed: 0.0469s/iter; left time: 1012.7896s
Epoch: 5 cost time: 10.736606121063232
Epoch: 5, Steps: 227 Train Loss: 0.8649 (Forecasting Loss:0.5974 + XiCon Loss:2.6749 x Lambda(0.1)), Vali MSE Loss: 1.1872 Test MSE Loss: 1.2725
Validation loss decreased (1.190541 --> 1.187221).  Saving model ...
Updating learning rate to 6.25e-06
	iters: 100, epoch: 6 | loss: 0.8866620
	speed: 0.1132s/iter; left time: 2429.6087s
	iters: 200, epoch: 6 | loss: 0.8923072
	speed: 0.1077s/iter; left time: 2300.8973s
Epoch: 6 cost time: 25.112659454345703
Epoch: 6, Steps: 227 Train Loss: 0.8635 (Forecasting Loss:0.5962 + XiCon Loss:2.6728 x Lambda(0.1)), Vali MSE Loss: 1.1858 Test MSE Loss: 1.2722
Validation loss decreased (1.187221 --> 1.185776).  Saving model ...
Updating learning rate to 3.125e-06
	iters: 100, epoch: 7 | loss: 0.8615130
	speed: 0.1051s/iter; left time: 2233.0149s
	iters: 200, epoch: 7 | loss: 0.9343555
	speed: 0.1055s/iter; left time: 2230.5299s
Epoch: 7 cost time: 24.084187984466553
Epoch: 7, Steps: 227 Train Loss: 0.8628 (Forecasting Loss:0.5956 + XiCon Loss:2.6724 x Lambda(0.1)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2721
Validation loss decreased (1.185776 --> 1.184653).  Saving model ...
Updating learning rate to 1.5625e-06
	iters: 100, epoch: 8 | loss: 0.8323140
	speed: 0.1269s/iter; left time: 2667.3232s
	iters: 200, epoch: 8 | loss: 0.8974965
	speed: 0.1190s/iter; left time: 2488.9604s
Epoch: 8 cost time: 27.85794997215271
Epoch: 8, Steps: 227 Train Loss: 0.8625 (Forecasting Loss:0.5952 + XiCon Loss:2.6723 x Lambda(0.1)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2721
Validation loss decreased (1.184653 --> 1.184490).  Saving model ...
Updating learning rate to 7.8125e-07
	iters: 100, epoch: 9 | loss: 0.8655952
	speed: 0.1155s/iter; left time: 2399.7135s
	iters: 200, epoch: 9 | loss: 0.8500741
	speed: 0.1027s/iter; left time: 2123.9352s
Epoch: 9 cost time: 24.543906450271606
Epoch: 9, Steps: 227 Train Loss: 0.8620 (Forecasting Loss:0.5950 + XiCon Loss:2.6701 x Lambda(0.1)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 3.90625e-07
	iters: 100, epoch: 10 | loss: 0.8507221
	speed: 0.0951s/iter; left time: 1955.5684s
	iters: 200, epoch: 10 | loss: 0.8581935
	speed: 0.0887s/iter; left time: 1814.3071s
Epoch: 10 cost time: 20.726560592651367
Epoch: 10, Steps: 227 Train Loss: 0.8619 (Forecasting Loss:0.5947 + XiCon Loss:2.6724 x Lambda(0.1)), Vali MSE Loss: 1.1848 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 1.953125e-07
	iters: 100, epoch: 11 | loss: 0.9121720
	speed: 0.0871s/iter; left time: 1770.2493s
	iters: 200, epoch: 11 | loss: 0.8615193
	speed: 0.0822s/iter; left time: 1662.6811s
Epoch: 11 cost time: 19.09462547302246
Epoch: 11, Steps: 227 Train Loss: 0.8614 (Forecasting Loss:0.5946 + XiCon Loss:2.6681 x Lambda(0.1)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 9.765625e-08
	iters: 100, epoch: 12 | loss: 0.8848819
	speed: 0.0644s/iter; left time: 1294.3688s
	iters: 200, epoch: 12 | loss: 0.8794995
	speed: 0.0617s/iter; left time: 1234.3978s
Epoch: 12 cost time: 14.150699853897095
Epoch: 12, Steps: 227 Train Loss: 0.8615 (Forecasting Loss:0.5946 + XiCon Loss:2.6690 x Lambda(0.1)), Vali MSE Loss: 1.1849 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 4.8828125e-08
	iters: 100, epoch: 13 | loss: 0.8505809
	speed: 0.0519s/iter; left time: 1031.5615s
	iters: 200, epoch: 13 | loss: 0.8022681
	speed: 0.0492s/iter; left time: 973.9256s
Epoch: 13 cost time: 11.412881851196289
Epoch: 13, Steps: 227 Train Loss: 0.8616 (Forecasting Loss:0.5946 + XiCon Loss:2.6702 x Lambda(0.1)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 2.44140625e-08
	iters: 100, epoch: 14 | loss: 0.8859675
	speed: 0.0505s/iter; left time: 993.1231s
	iters: 200, epoch: 14 | loss: 0.8709478
	speed: 0.0446s/iter; left time: 872.4011s
Epoch: 14 cost time: 10.765088319778442
Epoch: 14, Steps: 227 Train Loss: 0.8619 (Forecasting Loss:0.5946 + XiCon Loss:2.6724 x Lambda(0.1)), Vali MSE Loss: 1.1837 Test MSE Loss: 1.2720
Validation loss decreased (1.184490 --> 1.183671).  Saving model ...
Updating learning rate to 1.220703125e-08
	iters: 100, epoch: 15 | loss: 0.8491552
	speed: 0.0494s/iter; left time: 959.1828s
	iters: 200, epoch: 15 | loss: 0.8600293
	speed: 0.0461s/iter; left time: 891.2051s
Epoch: 15 cost time: 10.807081460952759
Epoch: 15, Steps: 227 Train Loss: 0.8618 (Forecasting Loss:0.5947 + XiCon Loss:2.6713 x Lambda(0.1)), Vali MSE Loss: 1.1842 Test MSE Loss: 1.2720
EarlyStopping counter: 1 out of 10
Updating learning rate to 6.103515625e-09
	iters: 100, epoch: 16 | loss: 0.8508984
	speed: 0.0484s/iter; left time: 928.5434s
	iters: 200, epoch: 16 | loss: 0.8425409
	speed: 0.0450s/iter; left time: 858.5648s
Epoch: 16 cost time: 10.587944269180298
Epoch: 16, Steps: 227 Train Loss: 0.8618 (Forecasting Loss:0.5946 + XiCon Loss:2.6723 x Lambda(0.1)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2720
EarlyStopping counter: 2 out of 10
Updating learning rate to 3.0517578125e-09
	iters: 100, epoch: 17 | loss: 0.8422657
	speed: 0.0474s/iter; left time: 899.2656s
	iters: 200, epoch: 17 | loss: 0.8810984
	speed: 0.0452s/iter; left time: 852.8058s
Epoch: 17 cost time: 10.485097646713257
Epoch: 17, Steps: 227 Train Loss: 0.8616 (Forecasting Loss:0.5946 + XiCon Loss:2.6701 x Lambda(0.1)), Vali MSE Loss: 1.1845 Test MSE Loss: 1.2720
EarlyStopping counter: 3 out of 10
Updating learning rate to 1.52587890625e-09
	iters: 100, epoch: 18 | loss: 0.8669789
	speed: 0.0479s/iter; left time: 897.5952s
	iters: 200, epoch: 18 | loss: 0.8348829
	speed: 0.0431s/iter; left time: 803.3577s
Epoch: 18 cost time: 10.306951522827148
Epoch: 18, Steps: 227 Train Loss: 0.8616 (Forecasting Loss:0.5946 + XiCon Loss:2.6699 x Lambda(0.1)), Vali MSE Loss: 1.1844 Test MSE Loss: 1.2720
EarlyStopping counter: 4 out of 10
Updating learning rate to 7.62939453125e-10
	iters: 100, epoch: 19 | loss: 0.8287694
	speed: 0.0468s/iter; left time: 866.1597s
	iters: 200, epoch: 19 | loss: 0.8460286
	speed: 0.0436s/iter; left time: 802.8974s
Epoch: 19 cost time: 10.269857168197632
Epoch: 19, Steps: 227 Train Loss: 0.8616 (Forecasting Loss:0.5944 + XiCon Loss:2.6721 x Lambda(0.1)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2720
EarlyStopping counter: 5 out of 10
Updating learning rate to 3.814697265625e-10
	iters: 100, epoch: 20 | loss: 0.8059512
	speed: 0.0488s/iter; left time: 891.9361s
	iters: 200, epoch: 20 | loss: 0.8876734
	speed: 0.0433s/iter; left time: 786.8235s
Epoch: 20 cost time: 10.422081470489502
Epoch: 20, Steps: 227 Train Loss: 0.8618 (Forecasting Loss:0.5945 + XiCon Loss:2.6729 x Lambda(0.1)), Vali MSE Loss: 1.1847 Test MSE Loss: 1.2720
EarlyStopping counter: 6 out of 10
Updating learning rate to 1.9073486328125e-10
	iters: 100, epoch: 21 | loss: 0.8545434
	speed: 0.0470s/iter; left time: 848.2400s
	iters: 200, epoch: 21 | loss: 0.9079685
	speed: 0.0451s/iter; left time: 810.1428s
Epoch: 21 cost time: 10.49101734161377
Epoch: 21, Steps: 227 Train Loss: 0.8616 (Forecasting Loss:0.5946 + XiCon Loss:2.6708 x Lambda(0.1)), Vali MSE Loss: 1.1846 Test MSE Loss: 1.2720
EarlyStopping counter: 7 out of 10
Updating learning rate to 9.5367431640625e-11
	iters: 100, epoch: 22 | loss: 0.8615643
	speed: 0.0464s/iter; left time: 827.6566s
	iters: 200, epoch: 22 | loss: 0.8511370
	speed: 0.0427s/iter; left time: 757.7118s
Epoch: 22 cost time: 10.104137897491455
Epoch: 22, Steps: 227 Train Loss: 0.8617 (Forecasting Loss:0.5947 + XiCon Loss:2.6697 x Lambda(0.1)), Vali MSE Loss: 1.1843 Test MSE Loss: 1.2720
EarlyStopping counter: 8 out of 10
Updating learning rate to 4.76837158203125e-11
	iters: 100, epoch: 23 | loss: 0.8386174
	speed: 0.0465s/iter; left time: 819.0133s
	iters: 200, epoch: 23 | loss: 0.8973780
	speed: 0.0426s/iter; left time: 746.6335s
Epoch: 23 cost time: 10.146613359451294
Epoch: 23, Steps: 227 Train Loss: 0.8618 (Forecasting Loss:0.5947 + XiCon Loss:2.6711 x Lambda(0.1)), Vali MSE Loss: 1.1846 Test MSE Loss: 1.2720
EarlyStopping counter: 9 out of 10
Updating learning rate to 2.384185791015625e-11
	iters: 100, epoch: 24 | loss: 0.8468496
	speed: 0.0465s/iter; left time: 808.4600s
	iters: 200, epoch: 24 | loss: 0.8861847
	speed: 0.0428s/iter; left time: 740.1514s
Epoch: 24 cost time: 10.204445362091064
Epoch: 24, Steps: 227 Train Loss: 0.8619 (Forecasting Loss:0.5947 + XiCon Loss:2.6714 x Lambda(0.1)), Vali MSE Loss: 1.1849 Test MSE Loss: 1.2720
EarlyStopping counter: 10 out of 10
Early stopping
>>>>>>>testing : long_term_forecast_XiCon_exp_XiCon_weather_ftS_sl336_ll48_pl2160_dm8_nh8_el2_dl1_df8_fc1_ebtimeF_dtTrue_Exp_4<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<
test 8380
test shape: (65, 128, 2160, 1) (65, 128, 2160, 1)
test shape: (8320, 2160, 1) (8320, 2160, 1)
mse:1.5899927616119385, mae:0.9540349245071411, mape:6.221662998199463, mspe:4782.07958984375 dilate:0.0000000, Shapedtw:0.0000000, Temporaldtw:0.0000000
MSE:1.5869+-0.00384, MAE:0.9534+-0.00095, MAPE:6.2241+-0.02913, MSPE:4778.8564+-57.24235, SHAPEDTW:0.0000+-0.00000, TEMPDTW:0.0000+-0.00000
